{
    "submission_name": "t5-small",
    "param_count": 60506624,
    "dart_validation": {
        "predictions_file": "t5-small/dart_validation",
        "N": 1041
    },
    "common_gen_test": {
        "predictions_file": "t5-small/common_gen_test",
        "N": 1497
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.734521664779752,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.28753715874966074,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.30689059560851845,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.75439,
            "recall": 0.5119,
            "fmeasure": 0.60993
        },
        "rouge2": {
            "precision": 0.53704,
            "recall": 0.38827,
            "fmeasure": 0.44873
        },
        "rougeL": {
            "precision": 0.4386,
            "recall": 0.36111,
            "fmeasure": 0.39433
        },
        "rougeLsum": {
            "precision": 0.4386,
            "recall": 0.36111,
            "fmeasure": 0.39433
        },
        "nist": 2.2301329168617134,
        "bleu": 36.25967,
        "meteor": 0.26038166427928383,
        "bleurt": -0.2068,
        "nubia": {
            "semantic_relation": 3.93197,
            "contradiction": 98.95261,
            "irrelevancy": 0.77995,
            "logical_agreement": 0.26745,
            "grammar_ref": 3.5675,
            "grammar_hyp": 3.95798,
            "nubia_score": 0.5964
        },
        "bertscore": {
            "precision": 0.93178,
            "recall": 0.87789,
            "f1": 0.90404
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 69,
        "mean_pred_length": 17.25,
        "std_pred_length": 4.02336923485777,
        "median_pred_length": 16.5,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.7536231884057971,
        "vocab_size-1": 52,
        "unique-1": 42,
        "entropy-1": 5.519695609197141,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 60,
        "unique-2": 55,
        "entropy-2": 5.868521659182305,
        "cond_entropy-2": 0.32090897904487575,
        "distinct-3": 0.9672131147540983,
        "vocab_size-3": 59,
        "unique-3": 57,
        "entropy-3": 5.86516356707108,
        "cond_entropy-3": -0.009663262350814238,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 3.344772040064913,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8135593220338984,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.471377583150136,
        "distinct-2-nopunct": 0.9272727272727272,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.635905168070111,
        "cond_entropy-2-nopunct": 0.17625598246264382,
        "distinct-3-nopunct": 0.9803921568627451,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.63320965569699,
        "cond_entropy-3-nopunct": -0.010895155866889458,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.4,
            "3": 0.7551020408163265
        },
        "rouge1": {
            "precision": 0.78835,
            "recall": 0.81128,
            "fmeasure": 0.78829
        },
        "rouge2": {
            "precision": 0.61649,
            "recall": 0.65729,
            "fmeasure": 0.62779
        },
        "rougeL": {
            "precision": 0.69356,
            "recall": 0.71583,
            "fmeasure": 0.69932
        },
        "rougeLsum": {
            "precision": 0.69356,
            "recall": 0.71583,
            "fmeasure": 0.69932
        },
        "nist": 5.508232918488559,
        "bleu": 56.89292,
        "meteor": 0.40712560036471723,
        "bleurt": 0.33612,
        "nubia": {
            "semantic_relation": 3.99977,
            "contradiction": 20.83294,
            "irrelevancy": 25.25948,
            "logical_agreement": 53.90758,
            "grammar_ref": 5.56433,
            "grammar_hyp": 5.04427,
            "nubia_score": 0.69118
        },
        "bertscore": {
            "precision": 0.95044,
            "recall": 0.93391,
            "f1": 0.93876
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.75,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.53846,
            "fmeasure": 0.53846
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.68519,
            "fmeasure": 0.57246
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.68519,
            "fmeasure": 0.57246
        },
        "nist": 3.29605570194661,
        "bleu": 32.00286,
        "meteor": 0.39108176034024106,
        "bleurt": 0.51344,
        "nubia": {
            "semantic_relation": 4.68771,
            "contradiction": 0.11421,
            "irrelevancy": 33.6528,
            "logical_agreement": 66.23299,
            "grammar_ref": 4.76643,
            "grammar_hyp": 4.10097,
            "nubia_score": 0.96154
        },
        "bertscore": {
            "precision": 0.94838,
            "recall": 0.94985,
            "f1": 0.94912
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.011365041826379,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.32961067210860195,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.38461538461538464
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.14286,
            "fmeasure": 0.14286
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.26667,
            "fmeasure": 0.26667
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.26667,
            "fmeasure": 0.26667
        },
        "nist": 0.8571428571428571,
        "bleu": 2.71568,
        "meteor": 0.13922356091030788,
        "bleurt": -0.69643,
        "nubia": {
            "semantic_relation": 3.09269,
            "contradiction": 1.84977,
            "irrelevancy": 97.30111,
            "logical_agreement": 0.84912,
            "grammar_ref": 5.57252,
            "grammar_hyp": 3.59049,
            "nubia_score": 0.55159
        },
        "bertscore": {
            "precision": 0.66664,
            "recall": 0.8081,
            "f1": 0.73059
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 157,
        "mean_pred_length": 22.428571428571427,
        "std_pred_length": 7.5754706191787715,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 37,
        "distinct-1": 0.5222929936305732,
        "vocab_size-1": 82,
        "unique-1": 57,
        "entropy-1": 5.701294417963204,
        "distinct-2": 0.8466666666666667,
        "vocab_size-2": 127,
        "unique-2": 113,
        "entropy-2": 6.858925734126773,
        "cond_entropy-2": 1.1173558584391905,
        "distinct-3": 0.9300699300699301,
        "vocab_size-3": 133,
        "unique-3": 127,
        "entropy-3": 6.9894900222567165,
        "cond_entropy-3": 0.12544066994598008,
        "total_length-nopunct": 126,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 4.840306956027833,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6190476190476191,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.957410927753748,
        "distinct-2-nopunct": 0.8991596638655462,
        "vocab_size-2-nopunct": 107,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.67410631367357,
        "cond_entropy-2-nopunct": 0.7270499436896984,
        "distinct-3-nopunct": 0.9732142857142857,
        "vocab_size-3-nopunct": 109,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.7537834934861625,
        "cond_entropy-3-nopunct": 0.07561450255761085,
        "msttr-100": 0.53,
        "msttr-100_nopunct": 0.63,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.45,
            "3": 0.5108695652173914
        },
        "rouge1": {
            "precision": 0.72163,
            "recall": 0.46178,
            "fmeasure": 0.55072
        },
        "rouge2": {
            "precision": 0.4182,
            "recall": 0.27147,
            "fmeasure": 0.32052
        },
        "rougeL": {
            "precision": 0.58296,
            "recall": 0.38793,
            "fmeasure": 0.45718
        },
        "rougeLsum": {
            "precision": 0.58296,
            "recall": 0.38793,
            "fmeasure": 0.45718
        },
        "nist": 2.7462472034867424,
        "bleu": 21.08244,
        "meteor": 0.2391791517883085,
        "bleurt": -0.15006,
        "nubia": {
            "semantic_relation": 2.85435,
            "contradiction": 10.56542,
            "irrelevancy": 42.63959,
            "logical_agreement": 46.79499,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.33977,
            "nubia_score": 0.37514
        },
        "bertscore": {
            "precision": 0.89843,
            "recall": 0.83911,
            "f1": 0.86694
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 5,
        "mean_pred_length": 5.0,
        "std_pred_length": 0.0,
        "median_pred_length": 5.0,
        "min_pred_length": 5,
        "max_pred_length": 5,
        "distinct-1": 1.0,
        "vocab_size-1": 5,
        "unique-1": 5,
        "entropy-1": 2.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 4,
        "unique-2": 4,
        "entropy-2": 2.0,
        "cond_entropy-2": -0.32192809488736235,
        "distinct-3": 1.0,
        "vocab_size-3": 3,
        "unique-3": 3,
        "entropy-3": 1.584962500721156,
        "cond_entropy-3": -0.4150374992788437,
        "total_length-nopunct": 4,
        "mean_pred_length-nopunct": 4.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 4,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 4,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 3,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 1.584962500721156,
        "cond_entropy-2-nopunct": -0.4150374992788437,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 2,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 1.0,
        "cond_entropy-3-nopunct": -0.5849625007211562,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.53333
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.38889,
            "fmeasure": 0.41667
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.53333
        },
        "nist": 0.4024128570092264,
        "bleu": 23.64354,
        "meteor": 0.304248192370908,
        "bleurt": -0.61924,
        "nubia": {
            "semantic_relation": 3.03298,
            "contradiction": 76.23416,
            "irrelevancy": 19.52128,
            "logical_agreement": 4.24456,
            "grammar_ref": 6.66832,
            "grammar_hyp": 6.72731,
            "nubia_score": 0.2656
        },
        "bertscore": {
            "precision": 0.92021,
            "recall": 0.91091,
            "f1": 0.91554
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "t5-small/totto_test",
        "N": 14,
        "total_length": 213,
        "mean_pred_length": 15.214285714285714,
        "std_pred_length": 5.115502648512535,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6150234741784038,
        "vocab_size-1": 131,
        "unique-1": 107,
        "entropy-1": 6.466041695921121,
        "distinct-2": 0.9246231155778895,
        "vocab_size-2": 184,
        "unique-2": 174,
        "entropy-2": 7.4474211810742945,
        "cond_entropy-2": 0.8986763192807867,
        "distinct-3": 0.9621621621621622,
        "vocab_size-3": 178,
        "unique-3": 171,
        "entropy-3": 7.455705784840625,
        "cond_entropy-3": 0.011791891077545512,
        "total_length-nopunct": 185,
        "mean_pred_length-nopunct": 13.214285714285714,
        "std_pred_length-nopunct": 4.798490408876695,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6810810810810811,
        "vocab_size-1-nopunct": 126,
        "unique-1-nopunct": 106,
        "entropy-1-nopunct": 6.485990398604959,
        "distinct-2-nopunct": 0.9181286549707602,
        "vocab_size-2-nopunct": 157,
        "unique-2-nopunct": 148,
        "entropy-2-nopunct": 7.2093643017022435,
        "cond_entropy-2-nopunct": 0.7914176157683924,
        "distinct-3-nopunct": 0.9617834394904459,
        "vocab_size-3-nopunct": 151,
        "unique-3-nopunct": 145,
        "entropy-3-nopunct": 7.218187627872514,
        "cond_entropy-3-nopunct": 0.01467577830129075,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.2962962962962963,
            "3": 0.6588235294117647
        },
        "rouge1": {
            "precision": 0.73412,
            "recall": 0.64984,
            "fmeasure": 0.6777
        },
        "rouge2": {
            "precision": 0.504,
            "recall": 0.43723,
            "fmeasure": 0.46139
        },
        "rougeL": {
            "precision": 0.6385,
            "recall": 0.56693,
            "fmeasure": 0.58995
        },
        "rougeLsum": {
            "precision": 0.6385,
            "recall": 0.56693,
            "fmeasure": 0.58995
        },
        "nist": 4.808207548191145,
        "bleu": 36.74382,
        "meteor": 0.35707093035210297,
        "bleurt": 0.19467,
        "nubia": {
            "semantic_relation": 4.17752,
            "contradiction": 12.08347,
            "irrelevancy": 19.31493,
            "logical_agreement": 68.6016,
            "grammar_ref": 4.7817,
            "grammar_hyp": 5.01002,
            "nubia_score": 0.7073
        },
        "bertscore": {
            "precision": 0.91801,
            "recall": 0.905,
            "f1": 0.91027
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.6901165175936654,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.3347176276348774,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.4565647621309536,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.38295629088933336,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.57333,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.54762,
            "recall": 0.36905,
            "fmeasure": 0.43484
        },
        "rougeL": {
            "precision": 0.51111,
            "recall": 0.35111,
            "fmeasure": 0.41111
        },
        "rougeLsum": {
            "precision": 0.51111,
            "recall": 0.35111,
            "fmeasure": 0.41111
        },
        "nist": 2.6845896032578844,
        "bleu": 32.37723,
        "meteor": 0.30242125481739657,
        "bleurt": -0.44441,
        "nubia": {
            "semantic_relation": 3.11874,
            "contradiction": 2.48689,
            "irrelevancy": 70.23329,
            "logical_agreement": 27.27982,
            "grammar_ref": 4.19943,
            "grammar_hyp": 4.09504,
            "nubia_score": 0.40182
        },
        "bertscore": {
            "precision": 0.92172,
            "recall": 0.83578,
            "f1": 0.87665
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "t5-small/totto_test",
        "N": 14,
        "total_length": 207,
        "mean_pred_length": 14.785714285714286,
        "std_pred_length": 5.518521689062484,
        "median_pred_length": 13.5,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6473429951690821,
        "vocab_size-1": 134,
        "unique-1": 109,
        "entropy-1": 6.637317868102968,
        "distinct-2": 0.9430051813471503,
        "vocab_size-2": 182,
        "unique-2": 174,
        "entropy-2": 7.466733397338058,
        "cond_entropy-2": 0.6954655652237804,
        "distinct-3": 0.9776536312849162,
        "vocab_size-3": 175,
        "unique-3": 172,
        "entropy-3": 7.434905791218642,
        "cond_entropy-3": -0.02199447227015398,
        "total_length-nopunct": 176,
        "mean_pred_length-nopunct": 12.571428571428571,
        "std_pred_length-nopunct": 3.976974544878587,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7215909090909091,
        "vocab_size-1-nopunct": 127,
        "unique-1-nopunct": 106,
        "entropy-1-nopunct": 6.7036945113038175,
        "distinct-2-nopunct": 0.9753086419753086,
        "vocab_size-2-nopunct": 158,
        "unique-2-nopunct": 155,
        "entropy-2-nopunct": 7.285807487439152,
        "cond_entropy-2-nopunct": 0.6109613027221574,
        "distinct-3-nopunct": 0.9932432432432432,
        "vocab_size-3-nopunct": 147,
        "unique-3-nopunct": 146,
        "entropy-3-nopunct": 7.195939852115433,
        "cond_entropy-3-nopunct": -0.0847555054843002,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2033898305084746,
            "2": 0.10869565217391304,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.68486,
            "recall": 0.52468,
            "fmeasure": 0.57263
        },
        "rouge2": {
            "precision": 0.37897,
            "recall": 0.29361,
            "fmeasure": 0.3162
        },
        "rougeL": {
            "precision": 0.58743,
            "recall": 0.47428,
            "fmeasure": 0.50239
        },
        "rougeLsum": {
            "precision": 0.58743,
            "recall": 0.47428,
            "fmeasure": 0.50239
        },
        "nist": 3.2195847598564398,
        "bleu": 23.02835,
        "meteor": 0.256930836699832,
        "bleurt": -0.11923,
        "nubia": {
            "semantic_relation": 3.5066,
            "contradiction": 23.9627,
            "irrelevancy": 20.46782,
            "logical_agreement": 55.56949,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.76679,
            "nubia_score": 0.50894
        },
        "bertscore": {
            "precision": 0.87773,
            "recall": 0.86354,
            "f1": 0.86589
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 99,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.856267428111155,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.7171717171717171,
        "vocab_size-1": 71,
        "unique-1": 58,
        "entropy-1": 5.859006493751432,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 90,
        "unique-2": 89,
        "entropy-2": 6.453137305731692,
        "cond_entropy-2": 0.5470566265820817,
        "distinct-3": 1.0,
        "vocab_size-3": 87,
        "unique-3": 87,
        "entropy-3": 6.442943495848723,
        "cond_entropy-3": -0.004261292270797225,
        "total_length-nopunct": 84,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.5118845842842465,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7738095238095238,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.7463095357967315,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.182838116298154,
        "cond_entropy-2-nopunct": 0.4734009820641338,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.1699250014423175,
        "cond_entropy-3-nopunct": -0.004366106308824739,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.3333333333333333,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.86971,
            "recall": 0.73617,
            "fmeasure": 0.78853
        },
        "rouge2": {
            "precision": 0.64524,
            "recall": 0.55656,
            "fmeasure": 0.58944
        },
        "rougeL": {
            "precision": 0.81078,
            "recall": 0.70123,
            "fmeasure": 0.74286
        },
        "rougeLsum": {
            "precision": 0.81078,
            "recall": 0.70123,
            "fmeasure": 0.74286
        },
        "nist": 4.462099052661033,
        "bleu": 41.45268,
        "meteor": 0.3787273521539954,
        "bleurt": 0.20317,
        "nubia": {
            "semantic_relation": 4.27506,
            "contradiction": 10.53048,
            "irrelevancy": 34.9555,
            "logical_agreement": 54.51402,
            "grammar_ref": 5.04309,
            "grammar_hyp": 5.02812,
            "nubia_score": 0.72094
        },
        "bertscore": {
            "precision": 0.94432,
            "recall": 0.93329,
            "f1": 0.93863
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "t5-small/totto_test",
        "N": 47,
        "total_length": 758,
        "mean_pred_length": 16.127659574468087,
        "std_pred_length": 4.344803799289816,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.4182058047493404,
        "vocab_size-1": 317,
        "unique-1": 227,
        "entropy-1": 7.198874335844536,
        "distinct-2": 0.7341772151898734,
        "vocab_size-2": 522,
        "unique-2": 455,
        "entropy-2": 8.659470512726616,
        "cond_entropy-2": 1.320930798787837,
        "distinct-3": 0.8463855421686747,
        "vocab_size-3": 562,
        "unique-3": 523,
        "entropy-3": 8.927754788679984,
        "cond_entropy-3": 0.285780618844089,
        "total_length-nopunct": 641,
        "mean_pred_length-nopunct": 13.638297872340425,
        "std_pred_length-nopunct": 3.755424626328962,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.48517940717628705,
        "vocab_size-1-nopunct": 311,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.371052671296822,
        "distinct-2-nopunct": 0.7592592592592593,
        "vocab_size-2-nopunct": 451,
        "unique-2-nopunct": 402,
        "entropy-2-nopunct": 8.460775322730752,
        "cond_entropy-2-nopunct": 1.175292431567464,
        "distinct-3-nopunct": 0.8592321755027422,
        "vocab_size-3-nopunct": 470,
        "unique-3-nopunct": 441,
        "entropy-3-nopunct": 8.685778547908907,
        "cond_entropy-3-nopunct": 0.2734669690788092,
        "msttr-100": 0.66571,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23448275862068965,
            "2": 0.381294964028777,
            "3": 0.7354838709677419
        },
        "rouge1": {
            "precision": 0.70442,
            "recall": 0.71898,
            "fmeasure": 0.699
        },
        "rouge2": {
            "precision": 0.46831,
            "recall": 0.47399,
            "fmeasure": 0.46375
        },
        "rougeL": {
            "precision": 0.60931,
            "recall": 0.6292,
            "fmeasure": 0.60848
        },
        "rougeLsum": {
            "precision": 0.60931,
            "recall": 0.6292,
            "fmeasure": 0.60848
        },
        "nist": 6.299753274520583,
        "bleu": 43.36198,
        "meteor": 0.3719577385236609,
        "bleurt": 0.27466,
        "nubia": {
            "semantic_relation": 3.95332,
            "contradiction": 13.4399,
            "irrelevancy": 36.78741,
            "logical_agreement": 49.77269,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.37426,
            "nubia_score": 0.66879
        },
        "bertscore": {
            "precision": 0.91281,
            "recall": 0.92071,
            "f1": 0.91521
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "t5-small/totto_test",
        "N": 54,
        "total_length": 823,
        "mean_pred_length": 15.24074074074074,
        "std_pred_length": 4.705926858701833,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.511543134872418,
        "vocab_size-1": 421,
        "unique-1": 332,
        "entropy-1": 7.690821501280839,
        "distinct-2": 0.871261378413524,
        "vocab_size-2": 670,
        "unique-2": 613,
        "entropy-2": 9.238342587707553,
        "cond_entropy-2": 1.3276993272802822,
        "distinct-3": 0.965034965034965,
        "vocab_size-3": 690,
        "unique-3": 668,
        "entropy-3": 9.408016372222288,
        "cond_entropy-3": 0.1820078387995132,
        "total_length-nopunct": 731,
        "mean_pred_length-nopunct": 13.537037037037036,
        "std_pred_length-nopunct": 4.408379911381584,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5636114911080712,
        "vocab_size-1-nopunct": 412,
        "unique-1-nopunct": 328,
        "entropy-1-nopunct": 7.865514842654211,
        "distinct-2-nopunct": 0.8759231905465288,
        "vocab_size-2-nopunct": 593,
        "unique-2-nopunct": 546,
        "entropy-2-nopunct": 9.057768767313414,
        "cond_entropy-2-nopunct": 1.2341114188759954,
        "distinct-3-nopunct": 0.9678972712680578,
        "vocab_size-3-nopunct": 603,
        "unique-3-nopunct": 584,
        "entropy-3-nopunct": 9.217671198124766,
        "cond_entropy-3-nopunct": 0.17056557019837165,
        "msttr-100": 0.74375,
        "msttr-100_nopunct": 0.78714,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26256983240223464,
            "2": 0.37714285714285717,
            "3": 0.6903225806451613
        },
        "rouge1": {
            "precision": 0.76846,
            "recall": 0.68535,
            "fmeasure": 0.71011
        },
        "rouge2": {
            "precision": 0.53752,
            "recall": 0.48921,
            "fmeasure": 0.50073
        },
        "rougeL": {
            "precision": 0.65191,
            "recall": 0.58973,
            "fmeasure": 0.60647
        },
        "rougeLsum": {
            "precision": 0.65191,
            "recall": 0.58973,
            "fmeasure": 0.60647
        },
        "nist": 6.4745173179881395,
        "bleu": 41.67495,
        "meteor": 0.3681629496588249,
        "bleurt": 0.17872,
        "nubia": {
            "semantic_relation": 4.11119,
            "contradiction": 12.0335,
            "irrelevancy": 28.64965,
            "logical_agreement": 59.31685,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.74449,
            "nubia_score": 0.68608
        },
        "bertscore": {
            "precision": 0.92845,
            "recall": 0.91492,
            "f1": 0.92049
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 75,
        "mean_pred_length": 12.5,
        "std_pred_length": 4.9916597106239795,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 50,
        "unique-1": 39,
        "entropy-1": 5.350494650750191,
        "distinct-2": 0.782608695652174,
        "vocab_size-2": 54,
        "unique-2": 47,
        "entropy-2": 5.564904529179223,
        "cond_entropy-2": 0.12253022283538198,
        "distinct-3": 0.8412698412698413,
        "vocab_size-3": 53,
        "unique-3": 48,
        "entropy-3": 5.592126550381024,
        "cond_entropy-3": -0.047988779344339205,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 11.166666666666666,
        "std_pred_length-nopunct": 4.524623986832743,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7014925373134329,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.286019600808658,
        "distinct-2-nopunct": 0.8032786885245902,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.446970534213262,
        "cond_entropy-2-nopunct": 0.090138106156974,
        "distinct-3-nopunct": 0.8727272727272727,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.485638577043012,
        "cond_entropy-3-nopunct": -0.054011942259380524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6486486486486487
        },
        "rouge1": {
            "precision": 0.82707,
            "recall": 0.77823,
            "fmeasure": 0.79619
        },
        "rouge2": {
            "precision": 0.68519,
            "recall": 0.6619,
            "fmeasure": 0.67075
        },
        "rougeL": {
            "precision": 0.79198,
            "recall": 0.75168,
            "fmeasure": 0.76667
        },
        "rougeLsum": {
            "precision": 0.79198,
            "recall": 0.75168,
            "fmeasure": 0.76667
        },
        "nist": 3.835401574484113,
        "bleu": 42.14915,
        "meteor": 0.3647284244458618,
        "bleurt": 0.55568,
        "nubia": {
            "semantic_relation": 4.39241,
            "contradiction": 5.51737,
            "irrelevancy": 19.9423,
            "logical_agreement": 74.54033,
            "grammar_ref": 5.92578,
            "grammar_hyp": 6.02493,
            "nubia_score": 0.77466
        },
        "bertscore": {
            "precision": 0.95843,
            "recall": 0.94342,
            "f1": 0.95054
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 125,
        "mean_pred_length": 20.833333333333332,
        "std_pred_length": 3.287180487219337,
        "median_pred_length": 22.0,
        "min_pred_length": 15,
        "max_pred_length": 24,
        "distinct-1": 0.704,
        "vocab_size-1": 88,
        "unique-1": 70,
        "entropy-1": 6.145119702118166,
        "distinct-2": 0.957983193277311,
        "vocab_size-2": 114,
        "unique-2": 109,
        "entropy-2": 6.810784149862564,
        "cond_entropy-2": 0.6902357712340178,
        "distinct-3": 0.9911504424778761,
        "vocab_size-3": 112,
        "unique-3": 111,
        "entropy-3": 6.802479847370959,
        "cond_entropy-3": -0.003842340715764773,
        "total_length-nopunct": 108,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 3.415650255319866,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.212949307598824,
        "distinct-2-nopunct": 0.9901960784313726,
        "vocab_size-2-nopunct": 101,
        "unique-2-nopunct": 100,
        "entropy-2-nopunct": 6.652817498834245,
        "cond_entropy-2-nopunct": 0.45620806051645535,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 96,
        "entropy-3-nopunct": 6.5849625007211605,
        "cond_entropy-3-nopunct": -0.06662950791700592,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.2222222222222222,
            "3": 0.5221238938053098
        },
        "rouge1": {
            "precision": 0.72256,
            "recall": 0.46455,
            "fmeasure": 0.55137
        },
        "rouge2": {
            "precision": 0.49532,
            "recall": 0.31935,
            "fmeasure": 0.38132
        },
        "rougeL": {
            "precision": 0.62456,
            "recall": 0.39807,
            "fmeasure": 0.4739
        },
        "rougeLsum": {
            "precision": 0.62456,
            "recall": 0.39807,
            "fmeasure": 0.4739
        },
        "nist": 1.8114242442751805,
        "bleu": 22.80661,
        "meteor": 0.2546570142581759,
        "bleurt": -0.20508,
        "nubia": {
            "semantic_relation": 2.83714,
            "contradiction": 26.62054,
            "irrelevancy": 22.302,
            "logical_agreement": 51.07746,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.69557,
            "nubia_score": 0.38648
        },
        "bertscore": {
            "precision": 0.88848,
            "recall": 0.83384,
            "f1": 0.85728
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "t5-small/totto_test",
        "N": 48,
        "total_length": 697,
        "mean_pred_length": 14.520833333333334,
        "std_pred_length": 4.128102789283339,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5466284074605452,
        "vocab_size-1": 381,
        "unique-1": 321,
        "entropy-1": 7.502404658166946,
        "distinct-2": 0.9075500770416025,
        "vocab_size-2": 589,
        "unique-2": 552,
        "entropy-2": 9.10848048798893,
        "cond_entropy-2": 1.3796202023792277,
        "distinct-3": 0.9750415973377704,
        "vocab_size-3": 586,
        "unique-3": 573,
        "entropy-3": 9.178792270554304,
        "cond_entropy-3": 0.07772880941779561,
        "total_length-nopunct": 612,
        "mean_pred_length-nopunct": 12.75,
        "std_pred_length-nopunct": 3.939648884524271,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6143790849673203,
        "vocab_size-1-nopunct": 376,
        "unique-1-nopunct": 320,
        "entropy-1-nopunct": 7.715952694341727,
        "distinct-2-nopunct": 0.9078014184397163,
        "vocab_size-2-nopunct": 512,
        "unique-2-nopunct": 481,
        "entropy-2-nopunct": 8.901798076117997,
        "cond_entropy-2-nopunct": 1.2892304653137736,
        "distinct-3-nopunct": 0.9806201550387597,
        "vocab_size-3-nopunct": 506,
        "unique-3-nopunct": 497,
        "entropy-3-nopunct": 8.971004605225223,
        "cond_entropy-3-nopunct": 0.08744714395499259,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.77333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19463087248322147,
            "2": 0.38125,
            "3": 0.7425742574257426
        },
        "rouge1": {
            "precision": 0.793,
            "recall": 0.71394,
            "fmeasure": 0.74148
        },
        "rouge2": {
            "precision": 0.52991,
            "recall": 0.48805,
            "fmeasure": 0.50086
        },
        "rougeL": {
            "precision": 0.63856,
            "recall": 0.58102,
            "fmeasure": 0.60026
        },
        "rougeLsum": {
            "precision": 0.63856,
            "recall": 0.58102,
            "fmeasure": 0.60026
        },
        "nist": 6.629343525724911,
        "bleu": 44.01912,
        "meteor": 0.37439955381099255,
        "bleurt": 0.21671,
        "nubia": {
            "semantic_relation": 4.18448,
            "contradiction": 4.71893,
            "irrelevancy": 22.0614,
            "logical_agreement": 73.21968,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.88137,
            "nubia_score": 0.71364
        },
        "bertscore": {
            "precision": 0.9303,
            "recall": 0.92301,
            "f1": 0.92529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "t5-small/totto_test",
        "N": 83,
        "total_length": 1352,
        "mean_pred_length": 16.289156626506024,
        "std_pred_length": 4.691777273860763,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5007396449704142,
        "vocab_size-1": 677,
        "unique-1": 553,
        "entropy-1": 8.13929865771412,
        "distinct-2": 0.8668242710795903,
        "vocab_size-2": 1100,
        "unique-2": 1008,
        "entropy-2": 9.941267118524495,
        "cond_entropy-2": 1.6098568231774124,
        "distinct-3": 0.9645868465430016,
        "vocab_size-3": 1144,
        "unique-3": 1110,
        "entropy-3": 10.134729968235543,
        "cond_entropy-3": 0.19920187081494972,
        "total_length-nopunct": 1185,
        "mean_pred_length-nopunct": 14.27710843373494,
        "std_pred_length-nopunct": 4.399652924460292,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5645569620253165,
        "vocab_size-1-nopunct": 669,
        "unique-1-nopunct": 552,
        "entropy-1-nopunct": 8.380209122615236,
        "distinct-2-nopunct": 0.868421052631579,
        "vocab_size-2-nopunct": 957,
        "unique-2-nopunct": 884,
        "entropy-2-nopunct": 9.729326968543566,
        "cond_entropy-2-nopunct": 1.4373637953390765,
        "distinct-3-nopunct": 0.9646712463199215,
        "vocab_size-3-nopunct": 983,
        "unique-3-nopunct": 955,
        "entropy-3-nopunct": 9.914911079046664,
        "cond_entropy-3-nopunct": 0.21233216528473645,
        "msttr-100": 0.73308,
        "msttr-100_nopunct": 0.78455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2620967741935484,
            "2": 0.44715447154471544,
            "3": 0.7553418803418803
        },
        "rouge1": {
            "precision": 0.76624,
            "recall": 0.70898,
            "fmeasure": 0.72615
        },
        "rouge2": {
            "precision": 0.53619,
            "recall": 0.49229,
            "fmeasure": 0.50573
        },
        "rougeL": {
            "precision": 0.65903,
            "recall": 0.61188,
            "fmeasure": 0.62493
        },
        "rougeLsum": {
            "precision": 0.65903,
            "recall": 0.61188,
            "fmeasure": 0.62493
        },
        "nist": 7.310648633713307,
        "bleu": 45.75878,
        "meteor": 0.3836178974526207,
        "bleurt": 0.19518,
        "nubia": {
            "semantic_relation": 4.18735,
            "contradiction": 11.58863,
            "irrelevancy": 27.99719,
            "logical_agreement": 60.41418,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.72827,
            "nubia_score": 0.7054
        },
        "bertscore": {
            "precision": 0.93099,
            "recall": 0.92021,
            "f1": 0.92383
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "t5-small/totto_test",
        "N": 169,
        "total_length": 2706,
        "mean_pred_length": 16.011834319526628,
        "std_pred_length": 4.846749860394733,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.4042867701404287,
        "vocab_size-1": 1094,
        "unique-1": 859,
        "entropy-1": 8.33060640822874,
        "distinct-2": 0.770595191170674,
        "vocab_size-2": 1955,
        "unique-2": 1748,
        "entropy-2": 10.553459549141733,
        "cond_entropy-2": 1.9983696125736037,
        "distinct-3": 0.894847972972973,
        "vocab_size-3": 2119,
        "unique-3": 2011,
        "entropy-3": 10.8885609009339,
        "cond_entropy-3": 0.3534729734759947,
        "total_length-nopunct": 2343,
        "mean_pred_length-nopunct": 13.863905325443787,
        "std_pred_length-nopunct": 4.402708837007367,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4626547161758429,
        "vocab_size-1-nopunct": 1084,
        "unique-1-nopunct": 858,
        "entropy-1-nopunct": 8.631762028566666,
        "distinct-2-nopunct": 0.7939282428702852,
        "vocab_size-2-nopunct": 1726,
        "unique-2-nopunct": 1575,
        "entropy-2-nopunct": 10.38352021727455,
        "cond_entropy-2-nopunct": 1.8764728647896236,
        "distinct-3-nopunct": 0.9042394014962594,
        "vocab_size-3-nopunct": 1813,
        "unique-3-nopunct": 1734,
        "entropy-3-nopunct": 10.673411145587611,
        "cond_entropy-3-nopunct": 0.33474535339418876,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.75783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20502092050209206,
            "2": 0.42921348314606744,
            "3": 0.7414529914529915
        },
        "rouge1": {
            "precision": 0.76567,
            "recall": 0.72084,
            "fmeasure": 0.73036
        },
        "rouge2": {
            "precision": 0.54308,
            "recall": 0.50725,
            "fmeasure": 0.51588
        },
        "rougeL": {
            "precision": 0.6657,
            "recall": 0.62639,
            "fmeasure": 0.63485
        },
        "rougeLsum": {
            "precision": 0.6657,
            "recall": 0.62639,
            "fmeasure": 0.63485
        },
        "nist": 7.58239383322751,
        "bleu": 43.35618,
        "meteor": 0.3738595001079396,
        "bleurt": 0.23596,
        "nubia": {
            "semantic_relation": 4.12058,
            "contradiction": 11.54826,
            "irrelevancy": 29.94873,
            "logical_agreement": 58.50301,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.80515,
            "nubia_score": 0.69379
        },
        "bertscore": {
            "precision": 0.92536,
            "recall": 0.91772,
            "f1": 0.92015
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "t5-small/totto_test",
        "N": 114,
        "total_length": 1769,
        "mean_pred_length": 15.517543859649123,
        "std_pred_length": 4.766904280926452,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.47258338044092707,
        "vocab_size-1": 836,
        "unique-1": 659,
        "entropy-1": 8.329025216917941,
        "distinct-2": 0.8489425981873112,
        "vocab_size-2": 1405,
        "unique-2": 1264,
        "entropy-2": 10.289190386761792,
        "cond_entropy-2": 1.7551436579225639,
        "distinct-3": 0.945489941596366,
        "vocab_size-3": 1457,
        "unique-3": 1385,
        "entropy-3": 10.473561689675622,
        "cond_entropy-3": 0.1913432188795634,
        "total_length-nopunct": 1549,
        "mean_pred_length-nopunct": 13.587719298245615,
        "std_pred_length-nopunct": 4.489385929775885,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5326016785022595,
        "vocab_size-1-nopunct": 825,
        "unique-1-nopunct": 655,
        "entropy-1-nopunct": 8.60867392911622,
        "distinct-2-nopunct": 0.8592334494773519,
        "vocab_size-2-nopunct": 1233,
        "unique-2-nopunct": 1126,
        "entropy-2-nopunct": 10.097444978201338,
        "cond_entropy-2-nopunct": 1.5666250458835296,
        "distinct-3-nopunct": 0.9492808478425435,
        "vocab_size-3-nopunct": 1254,
        "unique-3-nopunct": 1197,
        "entropy-3-nopunct": 10.25887267858586,
        "cond_entropy-3-nopunct": 0.18646065787743088,
        "msttr-100": 0.72882,
        "msttr-100_nopunct": 0.776,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25066666666666665,
            "2": 0.4729064039408867,
            "3": 0.7139061116031886
        },
        "rouge1": {
            "precision": 0.7348,
            "recall": 0.68435,
            "fmeasure": 0.69402
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.45736,
            "fmeasure": 0.45932
        },
        "rougeL": {
            "precision": 0.60765,
            "recall": 0.57661,
            "fmeasure": 0.57902
        },
        "rougeLsum": {
            "precision": 0.60765,
            "recall": 0.57661,
            "fmeasure": 0.57902
        },
        "nist": 7.203250361183615,
        "bleu": 39.10692,
        "meteor": 0.3624652960613115,
        "bleurt": 0.15926,
        "nubia": {
            "semantic_relation": 4.13312,
            "contradiction": 9.6266,
            "irrelevancy": 32.15272,
            "logical_agreement": 58.22068,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.89724,
            "nubia_score": 0.67568
        },
        "bertscore": {
            "precision": 0.91945,
            "recall": 0.90908,
            "f1": 0.91285
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 16,
        "unique-1": 11,
        "entropy-1": 3.879664004902594,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 18,
        "unique-2": 15,
        "entropy-2": 4.106603137064474,
        "cond_entropy-2": 0.25454711376829503,
        "distinct-3": 0.9,
        "vocab_size-3": 18,
        "unique-3": 16,
        "entropy-3": 4.1219280948873624,
        "cond_entropy-3": 0.02961067210860201,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.879664004902594,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.106603137064474,
        "cond_entropy-2-nopunct": 0.25454711376829503,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.1219280948873624,
        "cond_entropy-3-nopunct": 0.02961067210860201,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.44524,
            "fmeasure": 0.56387
        },
        "rouge2": {
            "precision": 0.40476,
            "recall": 0.23242,
            "fmeasure": 0.29472
        },
        "rougeL": {
            "precision": 0.61364,
            "recall": 0.35238,
            "fmeasure": 0.44682
        },
        "rougeLsum": {
            "precision": 0.61364,
            "recall": 0.35238,
            "fmeasure": 0.44682
        },
        "nist": 0.22010482479948024,
        "bleu": 10.80133,
        "meteor": 0.19349253847742187,
        "bleurt": -0.36746,
        "nubia": {
            "semantic_relation": 3.15048,
            "contradiction": 4.32252,
            "irrelevancy": 5.30579,
            "logical_agreement": 90.3717,
            "grammar_ref": 3.72412,
            "grammar_hyp": 5.14624,
            "nubia_score": 0.2622
        },
        "bertscore": {
            "precision": 0.9285,
            "recall": 0.74121,
            "f1": 0.82435
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 5.0,
        "median_pred_length": 18.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.6944444444444444,
        "vocab_size-1": 25,
        "unique-1": 17,
        "entropy-1": 4.4585460993746215,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.5531155008208745,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.024962841250339412,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7931034482758621,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.444187891679297,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.680813428089397,
        "cond_entropy-2-nopunct": 0.23023984036922984,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.031031312388743945,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.5333333333333333
        },
        "rouge1": {
            "precision": 0.69853,
            "recall": 0.54637,
            "fmeasure": 0.61242
        },
        "rouge2": {
            "precision": 0.29261,
            "recall": 0.22105,
            "fmeasure": 0.25072
        },
        "rougeL": {
            "precision": 0.45588,
            "recall": 0.35605,
            "fmeasure": 0.39935
        },
        "rougeLsum": {
            "precision": 0.45588,
            "recall": 0.35605,
            "fmeasure": 0.39935
        },
        "nist": 3.1337351264968936,
        "bleu": 12.15477,
        "meteor": 0.27015119637806206,
        "bleurt": -0.03674,
        "nubia": {
            "semantic_relation": 3.33367,
            "contradiction": 54.9844,
            "irrelevancy": 40.24845,
            "logical_agreement": 4.76715,
            "grammar_ref": 4.80653,
            "grammar_hyp": 4.5332,
            "nubia_score": 0.42425
        },
        "bertscore": {
            "precision": 0.91178,
            "recall": 0.87964,
            "f1": 0.89445
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 51,
        "mean_pred_length": 12.75,
        "std_pred_length": 1.0897247358851685,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.7058823529411765,
        "vocab_size-1": 36,
        "unique-1": 27,
        "entropy-1": 4.959395381646002,
        "distinct-2": 0.851063829787234,
        "vocab_size-2": 40,
        "unique-2": 33,
        "entropy-2": 5.256716511252108,
        "cond_entropy-2": 0.18779176452742452,
        "distinct-3": 0.8604651162790697,
        "vocab_size-3": 37,
        "unique-3": 31,
        "entropy-3": 5.147194987260237,
        "cond_entropy-3": -0.08181246906856271,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.8660254037844386,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.906941782652658,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 5.058984089445428,
        "cond_entropy-2-nopunct": 0.18695851378365905,
        "distinct-3-nopunct": 0.8421052631578947,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.932138039759376,
        "cond_entropy-3-nopunct": -0.11807411986149066,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.5428571428571428,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.60073,
            "recall": 0.67745,
            "fmeasure": 0.59353
        },
        "rouge2": {
            "precision": 0.33894,
            "recall": 0.35399,
            "fmeasure": 0.32113
        },
        "rougeL": {
            "precision": 0.57097,
            "recall": 0.66703,
            "fmeasure": 0.57654
        },
        "rougeLsum": {
            "precision": 0.57097,
            "recall": 0.66703,
            "fmeasure": 0.57654
        },
        "nist": 3.5737888515913507,
        "bleu": 21.66646,
        "meteor": 0.29481882516194036,
        "bleurt": -0.21126,
        "nubia": {
            "semantic_relation": 3.33281,
            "contradiction": 28.29996,
            "irrelevancy": 60.80851,
            "logical_agreement": 10.89153,
            "grammar_ref": 5.36601,
            "grammar_hyp": 4.58694,
            "nubia_score": 0.48214
        },
        "bertscore": {
            "precision": 0.86416,
            "recall": 0.86581,
            "f1": 0.85789
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "t5-small/totto_test",
        "N": 24,
        "total_length": 390,
        "mean_pred_length": 16.25,
        "std_pred_length": 4.054318685056714,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.5846153846153846,
        "vocab_size-1": 228,
        "unique-1": 190,
        "entropy-1": 7.003830527470054,
        "distinct-2": 0.9098360655737705,
        "vocab_size-2": 333,
        "unique-2": 313,
        "entropy-2": 8.289822694942306,
        "cond_entropy-2": 1.1602162581642088,
        "distinct-3": 0.9766081871345029,
        "vocab_size-3": 334,
        "unique-3": 326,
        "entropy-3": 8.371068889154895,
        "cond_entropy-3": 0.09709722181547284,
        "total_length-nopunct": 341,
        "mean_pred_length-nopunct": 14.208333333333334,
        "std_pred_length-nopunct": 3.904902545376631,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6510263929618768,
        "vocab_size-1-nopunct": 222,
        "unique-1-nopunct": 188,
        "entropy-1-nopunct": 7.1508267739617,
        "distinct-2-nopunct": 0.8990536277602523,
        "vocab_size-2-nopunct": 285,
        "unique-2-nopunct": 266,
        "entropy-2-nopunct": 8.05385627158091,
        "cond_entropy-2-nopunct": 0.9771615884691512,
        "distinct-3-nopunct": 0.9761092150170648,
        "vocab_size-3-nopunct": 286,
        "unique-3-nopunct": 279,
        "entropy-3-nopunct": 8.146975284456422,
        "cond_entropy-3-nopunct": 0.11396401698952054,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09821428571428571,
            "2": 0.44086021505376344,
            "3": 0.8065843621399177
        },
        "rouge1": {
            "precision": 0.73613,
            "recall": 0.67834,
            "fmeasure": 0.69724
        },
        "rouge2": {
            "precision": 0.44283,
            "recall": 0.39948,
            "fmeasure": 0.41288
        },
        "rougeL": {
            "precision": 0.59617,
            "recall": 0.55313,
            "fmeasure": 0.5659
        },
        "rougeLsum": {
            "precision": 0.59617,
            "recall": 0.55313,
            "fmeasure": 0.5659
        },
        "nist": 6.085943807881611,
        "bleu": 38.37816,
        "meteor": 0.375453410172747,
        "bleurt": 0.05194,
        "nubia": {
            "semantic_relation": 4.06595,
            "contradiction": 4.32758,
            "irrelevancy": 37.86885,
            "logical_agreement": 57.80357,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.59457,
            "nubia_score": 0.69108
        },
        "bertscore": {
            "precision": 0.91451,
            "recall": 0.90525,
            "f1": 0.90904
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "t5-small/totto_test",
        "N": 57,
        "total_length": 853,
        "mean_pred_length": 14.964912280701755,
        "std_pred_length": 4.356744770158715,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5076201641266119,
        "vocab_size-1": 433,
        "unique-1": 344,
        "entropy-1": 7.627897045310871,
        "distinct-2": 0.8693467336683417,
        "vocab_size-2": 692,
        "unique-2": 643,
        "entropy-2": 9.256704103730806,
        "cond_entropy-2": 1.4071602719462633,
        "distinct-3": 0.9607577807848444,
        "vocab_size-3": 710,
        "unique-3": 691,
        "entropy-3": 9.43807767863268,
        "cond_entropy-3": 0.19308598282950262,
        "total_length-nopunct": 758,
        "mean_pred_length-nopunct": 13.298245614035087,
        "std_pred_length-nopunct": 3.8931559933807627,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5633245382585752,
        "vocab_size-1-nopunct": 427,
        "unique-1-nopunct": 342,
        "entropy-1-nopunct": 7.801901626151341,
        "distinct-2-nopunct": 0.8730385164051355,
        "vocab_size-2-nopunct": 612,
        "unique-2-nopunct": 573,
        "entropy-2-nopunct": 9.071442040742607,
        "cond_entropy-2-nopunct": 1.3545712220235904,
        "distinct-3-nopunct": 0.9611801242236024,
        "vocab_size-3-nopunct": 619,
        "unique-3-nopunct": 603,
        "entropy-3-nopunct": 9.239682580750992,
        "cond_entropy-3-nopunct": 0.19582474779770942,
        "msttr-100": 0.71875,
        "msttr-100_nopunct": 0.76429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2073732718894009,
            "2": 0.45365853658536587,
            "3": 0.6755218216318786
        },
        "rouge1": {
            "precision": 0.69772,
            "recall": 0.64844,
            "fmeasure": 0.65788
        },
        "rouge2": {
            "precision": 0.46444,
            "recall": 0.43374,
            "fmeasure": 0.43787
        },
        "rougeL": {
            "precision": 0.6031,
            "recall": 0.56063,
            "fmeasure": 0.56802
        },
        "rougeLsum": {
            "precision": 0.6031,
            "recall": 0.56063,
            "fmeasure": 0.56802
        },
        "nist": 6.18515415085494,
        "bleu": 37.48583,
        "meteor": 0.34755242573893164,
        "bleurt": 0.11298,
        "nubia": {
            "semantic_relation": 3.88252,
            "contradiction": 13.43355,
            "irrelevancy": 40.01724,
            "logical_agreement": 46.5492,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.75938,
            "nubia_score": 0.63109
        },
        "bertscore": {
            "precision": 0.90941,
            "recall": 0.90696,
            "f1": 0.90592
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 94,
        "mean_pred_length": 18.8,
        "std_pred_length": 2.6381811916545836,
        "median_pred_length": 20.0,
        "min_pred_length": 14,
        "max_pred_length": 21,
        "distinct-1": 0.6170212765957447,
        "vocab_size-1": 58,
        "unique-1": 45,
        "entropy-1": 5.385097794317029,
        "distinct-2": 0.8764044943820225,
        "vocab_size-2": 78,
        "unique-2": 69,
        "entropy-2": 6.211578655636889,
        "cond_entropy-2": 0.8631380836353787,
        "distinct-3": 0.9642857142857143,
        "vocab_size-3": 81,
        "unique-3": 78,
        "entropy-3": 6.320888851350189,
        "cond_entropy-3": 0.10122417043530228,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 15.4,
        "std_pred_length-nopunct": 1.3564659966250536,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7012987012987013,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.53134250844697,
        "distinct-2-nopunct": 0.9305555555555556,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 6.020551563912268,
        "cond_entropy-2-nopunct": 0.504379300750273,
        "distinct-3-nopunct": 0.9850746268656716,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.03623844418911,
        "cond_entropy-3-nopunct": 0.011908778599989445,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.09523809523809523,
            "3": 0.36
        },
        "rouge1": {
            "precision": 0.50049,
            "recall": 0.34943,
            "fmeasure": 0.37481
        },
        "rouge2": {
            "precision": 0.25358,
            "recall": 0.20274,
            "fmeasure": 0.19739
        },
        "rougeL": {
            "precision": 0.37996,
            "recall": 0.29428,
            "fmeasure": 0.30086
        },
        "rougeLsum": {
            "precision": 0.37996,
            "recall": 0.29428,
            "fmeasure": 0.30086
        },
        "nist": 1.1948007950688493,
        "bleu": 14.51673,
        "meteor": 0.16411662402448915,
        "bleurt": -0.75413,
        "nubia": {
            "semantic_relation": 2.45066,
            "contradiction": 38.94227,
            "irrelevancy": 31.6887,
            "logical_agreement": 29.36903,
            "grammar_ref": 3.87874,
            "grammar_hyp": 3.68427,
            "nubia_score": 0.25847
        },
        "bertscore": {
            "precision": 0.78467,
            "recall": 0.76785,
            "f1": 0.77396
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 79,
        "mean_pred_length": 15.8,
        "std_pred_length": 3.059411708155671,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.7341772151898734,
        "vocab_size-1": 58,
        "unique-1": 49,
        "entropy-1": 5.55334767836515,
        "distinct-2": 0.9594594594594594,
        "vocab_size-2": 71,
        "unique-2": 68,
        "entropy-2": 6.128372284547874,
        "cond_entropy-2": 0.5772841041332406,
        "distinct-3": 1.0,
        "vocab_size-3": 69,
        "unique-3": 69,
        "entropy-3": 6.108524456778164,
        "cond_entropy-3": -0.013972387111650157,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 2.939387691339814,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.6645968485714695,
        "distinct-2-nopunct": 0.9841269841269841,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.945533891753889,
        "cond_entropy-2-nopunct": 0.273466685447074,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.1020575490619997,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.36363636363636365,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.47377,
            "recall": 0.38596,
            "fmeasure": 0.40951
        },
        "rouge2": {
            "precision": 0.28944,
            "recall": 0.20414,
            "fmeasure": 0.23075
        },
        "rougeL": {
            "precision": 0.39532,
            "recall": 0.31981,
            "fmeasure": 0.3394
        },
        "rougeLsum": {
            "precision": 0.39532,
            "recall": 0.31981,
            "fmeasure": 0.3394
        },
        "nist": 2.820546929240482,
        "bleu": 16.4907,
        "meteor": 0.19609408004772969,
        "bleurt": -0.35932,
        "nubia": {
            "semantic_relation": 2.9214,
            "contradiction": 27.91375,
            "irrelevancy": 50.00903,
            "logical_agreement": 22.07722,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.51573,
            "nubia_score": 0.37307
        },
        "bertscore": {
            "precision": 0.80838,
            "recall": 0.81403,
            "f1": 0.80551
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "t5-small/totto_test",
        "N": 12,
        "total_length": 158,
        "mean_pred_length": 13.166666666666666,
        "std_pred_length": 5.997684738482194,
        "median_pred_length": 13.5,
        "min_pred_length": 4,
        "max_pred_length": 23,
        "distinct-1": 0.689873417721519,
        "vocab_size-1": 109,
        "unique-1": 87,
        "entropy-1": 6.476811030803074,
        "distinct-2": 0.910958904109589,
        "vocab_size-2": 133,
        "unique-2": 123,
        "entropy-2": 6.996230980068444,
        "cond_entropy-2": 0.44594153936184683,
        "distinct-3": 0.9776119402985075,
        "vocab_size-3": 131,
        "unique-3": 128,
        "entropy-3": 7.021313071054795,
        "cond_entropy-3": 0.03495614282022087,
        "total_length-nopunct": 142,
        "mean_pred_length-nopunct": 11.833333333333334,
        "std_pred_length-nopunct": 5.785518319236594,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7394366197183099,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.506379186854748,
        "distinct-2-nopunct": 0.9307692307692308,
        "vocab_size-2-nopunct": 121,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.872292620687479,
        "cond_entropy-2-nopunct": 0.4099166276158061,
        "distinct-3-nopunct": 0.9915254237288136,
        "vocab_size-3-nopunct": 117,
        "unique-3-nopunct": 116,
        "entropy-3-nopunct": 6.86569389681946,
        "cond_entropy-3-nopunct": 0.0001885838276829109,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.175,
            "3": 0.5923076923076923
        },
        "rouge1": {
            "precision": 0.70967,
            "recall": 0.57499,
            "fmeasure": 0.61359
        },
        "rouge2": {
            "precision": 0.4561,
            "recall": 0.35519,
            "fmeasure": 0.38494
        },
        "rougeL": {
            "precision": 0.56203,
            "recall": 0.45157,
            "fmeasure": 0.48438
        },
        "rougeLsum": {
            "precision": 0.56203,
            "recall": 0.45157,
            "fmeasure": 0.48438
        },
        "nist": 2.96446692677542,
        "bleu": 23.53144,
        "meteor": 0.2749495113179723,
        "bleurt": -0.08144,
        "nubia": {
            "semantic_relation": 3.75416,
            "contradiction": 29.47127,
            "irrelevancy": 22.28167,
            "logical_agreement": 48.24706,
            "grammar_ref": 4.67736,
            "grammar_hyp": 5.06334,
            "nubia_score": 0.59132
        },
        "bertscore": {
            "precision": 0.90144,
            "recall": 0.87101,
            "f1": 0.88439
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "t5-small/totto_test",
        "N": 59,
        "total_length": 915,
        "mean_pred_length": 15.508474576271187,
        "std_pred_length": 4.126692282992055,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.4666666666666667,
        "vocab_size-1": 427,
        "unique-1": 340,
        "entropy-1": 7.563441904989234,
        "distinct-2": 0.8002336448598131,
        "vocab_size-2": 685,
        "unique-2": 614,
        "entropy-2": 9.167424720595669,
        "cond_entropy-2": 1.4067342023167877,
        "distinct-3": 0.8946047678795483,
        "vocab_size-3": 713,
        "unique-3": 674,
        "entropy-3": 9.3576809461723,
        "cond_entropy-3": 0.21099479982971533,
        "total_length-nopunct": 805,
        "mean_pred_length-nopunct": 13.64406779661017,
        "std_pred_length-nopunct": 3.726964102206035,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5192546583850932,
        "vocab_size-1-nopunct": 418,
        "unique-1-nopunct": 337,
        "entropy-1-nopunct": 7.722509167864379,
        "distinct-2-nopunct": 0.8042895442359249,
        "vocab_size-2-nopunct": 600,
        "unique-2-nopunct": 545,
        "entropy-2-nopunct": 8.965673716948947,
        "cond_entropy-2-nopunct": 1.332793108643675,
        "distinct-3-nopunct": 0.8981077147016011,
        "vocab_size-3-nopunct": 617,
        "unique-3-nopunct": 585,
        "entropy-3-nopunct": 9.15254991342917,
        "cond_entropy-3-nopunct": 0.21297287596904116,
        "msttr-100": 0.70111,
        "msttr-100_nopunct": 0.74125,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3584905660377358,
            "2": 0.44360902255639095,
            "3": 0.7355242566510172
        },
        "rouge1": {
            "precision": 0.74576,
            "recall": 0.70282,
            "fmeasure": 0.7134
        },
        "rouge2": {
            "precision": 0.50677,
            "recall": 0.47353,
            "fmeasure": 0.48258
        },
        "rougeL": {
            "precision": 0.65003,
            "recall": 0.6116,
            "fmeasure": 0.6213
        },
        "rougeLsum": {
            "precision": 0.65003,
            "recall": 0.6116,
            "fmeasure": 0.6213
        },
        "nist": 7.030849716161028,
        "bleu": 44.10338,
        "meteor": 0.3721868169902999,
        "bleurt": 0.20911,
        "nubia": {
            "semantic_relation": 4.11168,
            "contradiction": 7.71303,
            "irrelevancy": 34.96706,
            "logical_agreement": 57.31992,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.62221,
            "nubia_score": 0.69915
        },
        "bertscore": {
            "precision": 0.92822,
            "recall": 0.91797,
            "f1": 0.92184
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.43478260869565216,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 2.625671327604699,
        "distinct-2": 0.7272727272727273,
        "vocab_size-2": 16,
        "unique-2": 15,
        "entropy-2": 3.566182325255331,
        "cond_entropy-2": 0.8904151171257388,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": 0.8686707781606645,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.5625,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 2.5,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 1.3068905956085186,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666
        },
        "rouge1": {
            "precision": 0.1875,
            "recall": 0.17708,
            "fmeasure": 0.18199
        },
        "rouge2": {
            "precision": 0.06667,
            "recall": 0.06275,
            "fmeasure": 0.06458
        },
        "rougeL": {
            "precision": 0.1875,
            "recall": 0.17708,
            "fmeasure": 0.18199
        },
        "rougeLsum": {
            "precision": 0.1875,
            "recall": 0.17708,
            "fmeasure": 0.18199
        },
        "nist": 0.4671209800143807,
        "bleu": 3.64467,
        "meteor": 0.10580571784207027,
        "bleurt": -0.55018,
        "nubia": {
            "semantic_relation": 1.29051,
            "contradiction": 11.63463,
            "irrelevancy": 63.16069,
            "logical_agreement": 25.20468,
            "grammar_ref": 4.60656,
            "grammar_hyp": 2.38883,
            "nubia_score": 0.18672
        },
        "bertscore": {
            "precision": 0.77052,
            "recall": 0.70436,
            "f1": 0.73596
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.54762,
            "recall": 0.49405,
            "fmeasure": 0.49437
        },
        "rouge2": {
            "precision": 0.17949,
            "recall": 0.24048,
            "fmeasure": 0.19394
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.4623,
            "fmeasure": 0.45628
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.4623,
            "fmeasure": 0.45628
        },
        "nist": 2.714441774144809,
        "bleu": 16.15323,
        "meteor": 0.24194559162682736,
        "bleurt": -0.38412,
        "nubia": {
            "semantic_relation": 2.54603,
            "contradiction": 49.90255,
            "irrelevancy": 49.0868,
            "logical_agreement": 1.01065,
            "grammar_ref": 5.89248,
            "grammar_hyp": 5.41269,
            "nubia_score": 0.22661
        },
        "bertscore": {
            "precision": 0.82683,
            "recall": 0.88974,
            "f1": 0.84588
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.6086956521739131,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.4082800232568733,
        "distinct-2": 0.7727272727272727,
        "vocab_size-2": 17,
        "unique-2": 12,
        "entropy-2": 4.004886164091842,
        "cond_entropy-2": 0.6473007741440675,
        "distinct-3": 0.9047619047619048,
        "vocab_size-3": 19,
        "unique-3": 17,
        "entropy-3": 4.201841232302569,
        "cond_entropy-3": 0.21860008985574894,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.3068905956085186,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.375,
            "recall": 0.425,
            "fmeasure": 0.38675
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.2193,
            "fmeasure": 0.18382
        },
        "rougeL": {
            "precision": 0.3125,
            "recall": 0.375,
            "fmeasure": 0.3312
        },
        "rougeLsum": {
            "precision": 0.3125,
            "recall": 0.375,
            "fmeasure": 0.3312
        },
        "nist": 1.6304388109665713,
        "bleu": 11.23817,
        "meteor": 0.25975851672606026,
        "bleurt": -0.38819,
        "nubia": {
            "semantic_relation": 2.97775,
            "contradiction": 14.22005,
            "irrelevancy": 79.78136,
            "logical_agreement": 5.99859,
            "grammar_ref": 5.69136,
            "grammar_hyp": 3.98757,
            "nubia_score": 0.4411
        },
        "bertscore": {
            "precision": 0.74441,
            "recall": 0.8671,
            "f1": 0.80109
        }
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "t5-small/totto_test",
        "N": 105,
        "total_length": 1553,
        "mean_pred_length": 14.790476190476191,
        "std_pred_length": 4.823938793924353,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 27,
        "distinct-1": 0.4558918222794591,
        "vocab_size-1": 708,
        "unique-1": 563,
        "entropy-1": 7.910430290095057,
        "distinct-2": 0.8335635359116023,
        "vocab_size-2": 1207,
        "unique-2": 1096,
        "entropy-2": 10.000880053195818,
        "cond_entropy-2": 1.8421155289697033,
        "distinct-3": 0.9381980640357409,
        "vocab_size-3": 1260,
        "unique-3": 1210,
        "entropy-3": 10.243624751433721,
        "cond_entropy-3": 0.2710779540493473,
        "total_length-nopunct": 1360,
        "mean_pred_length-nopunct": 12.952380952380953,
        "std_pred_length-nopunct": 4.5447635013768,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5147058823529411,
        "vocab_size-1-nopunct": 700,
        "unique-1-nopunct": 561,
        "entropy-1-nopunct": 8.20877782066952,
        "distinct-2-nopunct": 0.8446215139442231,
        "vocab_size-2-nopunct": 1060,
        "unique-2-nopunct": 975,
        "entropy-2-nopunct": 9.807496215742992,
        "cond_entropy-2-nopunct": 1.7249886191015584,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 1100,
        "unique-3-nopunct": 1067,
        "entropy-3-nopunct": 10.066854023665142,
        "cond_entropy-3-nopunct": 0.2919164670302354,
        "msttr-100": 0.70467,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2088607594936709,
            "2": 0.3220338983050847,
            "3": 0.7421007685738685
        },
        "rouge1": {
            "precision": 0.80333,
            "recall": 0.71708,
            "fmeasure": 0.74614
        },
        "rouge2": {
            "precision": 0.54988,
            "recall": 0.48859,
            "fmeasure": 0.50765
        },
        "rougeL": {
            "precision": 0.68872,
            "recall": 0.61992,
            "fmeasure": 0.64202
        },
        "rougeLsum": {
            "precision": 0.68872,
            "recall": 0.61992,
            "fmeasure": 0.64202
        },
        "nist": 7.317781046817482,
        "bleu": 43.55593,
        "meteor": 0.3739696596712212,
        "bleurt": 0.28533,
        "nubia": {
            "semantic_relation": 4.31171,
            "contradiction": 8.86912,
            "irrelevancy": 24.53565,
            "logical_agreement": 66.59523,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.17297,
            "nubia_score": 0.73519
        },
        "bertscore": {
            "precision": 0.93396,
            "recall": 0.9227,
            "f1": 0.92725
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "t5-small/totto_test",
        "N": 56,
        "total_length": 881,
        "mean_pred_length": 15.732142857142858,
        "std_pred_length": 3.7866828275859987,
        "median_pred_length": 15.5,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.5187287173666288,
        "vocab_size-1": 457,
        "unique-1": 371,
        "entropy-1": 7.772536667963361,
        "distinct-2": 0.8775757575757576,
        "vocab_size-2": 724,
        "unique-2": 669,
        "entropy-2": 9.375882002539056,
        "cond_entropy-2": 1.3999267427129716,
        "distinct-3": 0.9583875162548765,
        "vocab_size-3": 737,
        "unique-3": 717,
        "entropy-3": 9.488173594228481,
        "cond_entropy-3": 0.13243804834637052,
        "total_length-nopunct": 766,
        "mean_pred_length-nopunct": 13.678571428571429,
        "std_pred_length-nopunct": 3.5612354540501356,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5848563968668408,
        "vocab_size-1-nopunct": 448,
        "unique-1-nopunct": 369,
        "entropy-1-nopunct": 7.979098413277738,
        "distinct-2-nopunct": 0.8788732394366198,
        "vocab_size-2-nopunct": 624,
        "unique-2-nopunct": 578,
        "entropy-2-nopunct": 9.158035351108332,
        "cond_entropy-2-nopunct": 1.2789058685834562,
        "distinct-3-nopunct": 0.9587155963302753,
        "vocab_size-3-nopunct": 627,
        "unique-3-nopunct": 610,
        "entropy-3-nopunct": 9.254730116053826,
        "cond_entropy-3-nopunct": 0.11896362174029117,
        "msttr-100": 0.7425,
        "msttr-100_nopunct": 0.78571,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18518518518518517,
            "2": 0.4240506329113924,
            "3": 0.7118380062305296
        },
        "rouge1": {
            "precision": 0.75771,
            "recall": 0.68302,
            "fmeasure": 0.70745
        },
        "rouge2": {
            "precision": 0.49951,
            "recall": 0.44837,
            "fmeasure": 0.46524
        },
        "rougeL": {
            "precision": 0.65242,
            "recall": 0.59186,
            "fmeasure": 0.61152
        },
        "rougeLsum": {
            "precision": 0.65242,
            "recall": 0.59186,
            "fmeasure": 0.61152
        },
        "nist": 6.546793693129393,
        "bleu": 39.74034,
        "meteor": 0.36261695933097965,
        "bleurt": 0.20571,
        "nubia": {
            "semantic_relation": 4.14634,
            "contradiction": 8.69044,
            "irrelevancy": 32.49898,
            "logical_agreement": 58.81058,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.93315,
            "nubia_score": 0.68362
        },
        "bertscore": {
            "precision": 0.91833,
            "recall": 0.9097,
            "f1": 0.91248
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.3157894736842105,
        "vocab_size-1": 6,
        "unique-1": 3,
        "entropy-1": 2.1426643555488485,
        "distinct-2": 0.3888888888888889,
        "vocab_size-2": 7,
        "unique-2": 3,
        "entropy-2": 2.57243125132212,
        "cond_entropy-2": 0.3800592934340897,
        "distinct-3": 0.5294117647058824,
        "vocab_size-3": 9,
        "unique-3": 4,
        "entropy-3": 2.9842341646524884,
        "cond_entropy-3": 0.3881260751021446,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.45454545454545453,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 2.004886164091843,
        "distinct-2-nopunct": 0.7,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.721928094887362,
        "cond_entropy-2-nopunct": 0.662496476250065,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.94770277922009,
        "cond_entropy-3-nopunct": 0.18133023988828356,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10526315789473684,
            "2": 0.045454545454545456
        },
        "rouge1": {
            "precision": 0.23684,
            "recall": 0.10455,
            "fmeasure": 0.14231
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.02778,
            "fmeasure": 0.04167
        },
        "rougeL": {
            "precision": 0.18421,
            "recall": 0.07879,
            "fmeasure": 0.10838
        },
        "rougeLsum": {
            "precision": 0.18421,
            "recall": 0.07879,
            "fmeasure": 0.10838
        },
        "nist": 0.12408140565404617,
        "bleu": 5.29435,
        "meteor": 0.08635938161951769,
        "bleurt": -1.0015,
        "nubia": {
            "semantic_relation": 2.90929,
            "contradiction": 5.01028,
            "irrelevancy": 29.84372,
            "logical_agreement": 65.14599,
            "grammar_ref": 4.34131,
            "grammar_hyp": 2.26759,
            "nubia_score": 0.6416
        },
        "bertscore": {
            "precision": 0.84443,
            "recall": 0.67799,
            "f1": 0.73845
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 110,
        "mean_pred_length": 22.0,
        "std_pred_length": 2.449489742783178,
        "median_pred_length": 22.0,
        "min_pred_length": 19,
        "max_pred_length": 26,
        "distinct-1": 0.7090909090909091,
        "vocab_size-1": 78,
        "unique-1": 66,
        "entropy-1": 5.960626305001994,
        "distinct-2": 0.9142857142857143,
        "vocab_size-2": 96,
        "unique-2": 90,
        "entropy-2": 6.516579922407414,
        "cond_entropy-2": 0.5648463987499209,
        "distinct-3": 0.99,
        "vocab_size-3": 99,
        "unique-3": 98,
        "entropy-3": 6.62385618977474,
        "cond_entropy-3": 0.11715954713023727,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 19.4,
        "std_pred_length-nopunct": 3.3823069050575527,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7525773195876289,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 5.93722547169751,
        "distinct-2-nopunct": 0.9130434782608695,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.319704483207422,
        "cond_entropy-2-nopunct": 0.3840389229338871,
        "distinct-3-nopunct": 0.9885057471264368,
        "vocab_size-3-nopunct": 86,
        "unique-3-nopunct": 85,
        "entropy-3-nopunct": 6.419954990101596,
        "cond_entropy-3-nopunct": 0.11196645360968593,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.25,
            "3": 0.49382716049382713
        },
        "rouge1": {
            "precision": 0.64236,
            "recall": 0.47111,
            "fmeasure": 0.52726
        },
        "rouge2": {
            "precision": 0.34572,
            "recall": 0.24737,
            "fmeasure": 0.2771
        },
        "rougeL": {
            "precision": 0.47624,
            "recall": 0.35896,
            "fmeasure": 0.39506
        },
        "rougeLsum": {
            "precision": 0.47624,
            "recall": 0.35896,
            "fmeasure": 0.39506
        },
        "nist": 1.6427793593862654,
        "bleu": 16.83846,
        "meteor": 0.21675146400716677,
        "bleurt": -0.36837,
        "nubia": {
            "semantic_relation": 2.88641,
            "contradiction": 6.34303,
            "irrelevancy": 37.57031,
            "logical_agreement": 56.08666,
            "grammar_ref": 4.13756,
            "grammar_hyp": 3.64467,
            "nubia_score": 0.42284
        },
        "bertscore": {
            "precision": 0.84716,
            "recall": 0.82774,
            "f1": 0.83593
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.68354236243323,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.43253122228823104,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.32323142879762,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.5258134337464763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.26667,
            "recall": 0.28356,
            "fmeasure": 0.27381
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.07639,
            "fmeasure": 0.0735
        },
        "rougeL": {
            "precision": 0.24444,
            "recall": 0.23379,
            "fmeasure": 0.2381
        },
        "rougeLsum": {
            "precision": 0.24444,
            "recall": 0.23379,
            "fmeasure": 0.2381
        },
        "nist": 1.1076685432222044,
        "bleu": 5.10928,
        "meteor": 0.11169995011102074,
        "bleurt": -0.81869,
        "nubia": {
            "semantic_relation": 1.00179,
            "contradiction": 62.65993,
            "irrelevancy": 35.75781,
            "logical_agreement": 1.58227,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.69895,
            "nubia_score": 0.09206
        },
        "bertscore": {
            "precision": 0.67619,
            "recall": 0.65373,
            "f1": 0.66477
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.71795,
            "recall": 0.68132,
            "fmeasure": 0.69896
        },
        "rouge2": {
            "precision": 0.36111,
            "recall": 0.33974,
            "fmeasure": 0.35
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.45055,
            "fmeasure": 0.45584
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.45055,
            "fmeasure": 0.45584
        },
        "nist": 3.096365091377973,
        "bleu": 16.09792,
        "meteor": 0.3609097105462528,
        "bleurt": -0.31619,
        "nubia": {
            "semantic_relation": 2.7495,
            "contradiction": 0.21206,
            "irrelevancy": 44.58521,
            "logical_agreement": 55.20273,
            "grammar_ref": 4.48671,
            "grammar_hyp": 3.54017,
            "nubia_score": 0.46766
        },
        "bertscore": {
            "precision": 0.8866,
            "recall": 0.88351,
            "f1": 0.88505
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.6818181818181818,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.572623663895163,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 18,
        "unique-2": 15,
        "entropy-2": 4.106603137064474,
        "cond_entropy-2": 0.4531149709798338,
        "distinct-3": 0.9,
        "vocab_size-3": 18,
        "unique-3": 16,
        "entropy-3": 4.1219280948873624,
        "cond_entropy-3": -0.020389327891398017,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.773557262275185,
        "cond_entropy-2-nopunct": -0.026442737724814785,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.028107102122342926,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.29412,
            "recall": 0.29412,
            "fmeasure": 0.29412
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.29412,
            "fmeasure": 0.29412
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.29412,
            "fmeasure": 0.29412
        },
        "nist": 1.16195634024808,
        "bleu": 21.27988,
        "meteor": 0.19999636414068228,
        "bleurt": -1.32707,
        "nubia": {
            "semantic_relation": 2.64469,
            "contradiction": 21.1967,
            "irrelevancy": 72.08582,
            "logical_agreement": 6.71748,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.14932,
            "nubia_score": 0.29645
        },
        "bertscore": {
            "precision": 0.67243,
            "recall": 0.78403,
            "f1": 0.72396
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 72,
        "mean_pred_length": 18.0,
        "std_pred_length": 3.5355339059327378,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 22,
        "distinct-1": 0.7083333333333334,
        "vocab_size-1": 51,
        "unique-1": 39,
        "entropy-1": 5.444026911074394,
        "distinct-2": 0.9558823529411765,
        "vocab_size-2": 65,
        "unique-2": 62,
        "entropy-2": 5.999227547132698,
        "cond_entropy-2": 0.5537828766681796,
        "distinct-3": 0.984375,
        "vocab_size-3": 63,
        "unique-3": 62,
        "entropy-3": 5.96875,
        "cond_entropy-3": -0.024962841250339395,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 4.242640687119285,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.765625,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.456954882778696,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.806890595608517,
        "cond_entropy-2-nopunct": 0.3694720539779095,
        "distinct-3-nopunct": 0.9821428571428571,
        "vocab_size-3-nopunct": 55,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.7716406363433235,
        "cond_entropy-3-nopunct": -0.028107102122342922,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.32142857142857145
        },
        "rouge1": {
            "precision": 0.42991,
            "recall": 0.29658,
            "fmeasure": 0.32665
        },
        "rouge2": {
            "precision": 0.18436,
            "recall": 0.14941,
            "fmeasure": 0.15157
        },
        "rougeL": {
            "precision": 0.36265,
            "recall": 0.2655,
            "fmeasure": 0.28451
        },
        "rougeLsum": {
            "precision": 0.36265,
            "recall": 0.2655,
            "fmeasure": 0.28451
        },
        "nist": 0.37068864902526544,
        "bleu": 6.42928,
        "meteor": 0.13323718847393193,
        "bleurt": -0.57362,
        "nubia": {
            "semantic_relation": 2.37685,
            "contradiction": 23.31913,
            "irrelevancy": 66.69292,
            "logical_agreement": 9.98795,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.48774,
            "nubia_score": 0.18833
        },
        "bertscore": {
            "precision": 0.78459,
            "recall": 0.76135,
            "f1": 0.76834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "t5-small/totto_test",
        "N": 39,
        "total_length": 619,
        "mean_pred_length": 15.871794871794872,
        "std_pred_length": 4.3687672800992745,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5621970920840065,
        "vocab_size-1": 348,
        "unique-1": 281,
        "entropy-1": 7.500942411689854,
        "distinct-2": 0.9051724137931034,
        "vocab_size-2": 525,
        "unique-2": 482,
        "entropy-2": 8.961298766705529,
        "cond_entropy-2": 1.2700397493611737,
        "distinct-3": 0.9611829944547134,
        "vocab_size-3": 520,
        "unique-3": 499,
        "entropy-3": 9.00185077273626,
        "cond_entropy-3": 0.04522077240609714,
        "total_length-nopunct": 537,
        "mean_pred_length-nopunct": 13.76923076923077,
        "std_pred_length-nopunct": 3.675710560726013,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6368715083798883,
        "vocab_size-1-nopunct": 342,
        "unique-1-nopunct": 280,
        "entropy-1-nopunct": 7.73407311705984,
        "distinct-2-nopunct": 0.9116465863453815,
        "vocab_size-2-nopunct": 454,
        "unique-2-nopunct": 421,
        "entropy-2-nopunct": 8.75108807661155,
        "cond_entropy-2-nopunct": 1.099110494239911,
        "distinct-3-nopunct": 0.9629629629629629,
        "vocab_size-3-nopunct": 442,
        "unique-3-nopunct": 425,
        "entropy-3-nopunct": 8.768276269339829,
        "cond_entropy-3-nopunct": 0.028403095479295003,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17293233082706766,
            "2": 0.5291005291005291,
            "3": 0.6501240694789082
        },
        "rouge1": {
            "precision": 0.74752,
            "recall": 0.63826,
            "fmeasure": 0.67573
        },
        "rouge2": {
            "precision": 0.50051,
            "recall": 0.42894,
            "fmeasure": 0.45176
        },
        "rougeL": {
            "precision": 0.62869,
            "recall": 0.54215,
            "fmeasure": 0.57062
        },
        "rougeLsum": {
            "precision": 0.62869,
            "recall": 0.54215,
            "fmeasure": 0.57062
        },
        "nist": 5.023141268781203,
        "bleu": 32.91329,
        "meteor": 0.3289326602674248,
        "bleurt": 0.1612,
        "nubia": {
            "semantic_relation": 3.99407,
            "contradiction": 10.70477,
            "irrelevancy": 26.65712,
            "logical_agreement": 62.63811,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.4184,
            "nubia_score": 0.66806
        },
        "bertscore": {
            "precision": 0.91877,
            "recall": 0.89657,
            "f1": 0.90551
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.373557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.4718928978776571,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.3125,
            "recall": 0.32143,
            "fmeasure": 0.31481
        },
        "rouge2": {
            "precision": 0.13333,
            "recall": 0.12479,
            "fmeasure": 0.12487
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.25714,
            "fmeasure": 0.25185
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.25714,
            "fmeasure": 0.25185
        },
        "nist": 1.017023420843145,
        "bleu": 13.83437,
        "meteor": 0.1512064080890866,
        "bleurt": -0.51952,
        "nubia": {
            "semantic_relation": 2.70654,
            "contradiction": 15.38485,
            "irrelevancy": 77.55235,
            "logical_agreement": 7.06281,
            "grammar_ref": 4.03834,
            "grammar_hyp": 2.27248,
            "nubia_score": 0.42379
        },
        "bertscore": {
            "precision": 0.69579,
            "recall": 0.81139,
            "f1": 0.72277
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.5,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.6756756756756757,
        "vocab_size-1": 25,
        "unique-1": 18,
        "entropy-1": 4.432294243948858,
        "distinct-2": 0.9142857142857143,
        "vocab_size-2": 32,
        "unique-2": 29,
        "entropy-2": 4.957854445516393,
        "cond_entropy-2": 0.5413978656635444,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 32,
        "unique-3": 31,
        "entropy-3": 4.9837880587523955,
        "cond_entropy-3": 0.006020193322577645,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.41545813444441,
        "distinct-2-nopunct": 0.9032258064516129,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.760647923290102,
        "cond_entropy-2-nopunct": 0.35350823948530796,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.789015477886192,
        "cond_entropy-3-nopunct": 0.0072329606027659935,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.2857142857142857,
            "3": 0.5789473684210527
        },
        "rouge1": {
            "precision": 0.64855,
            "recall": 0.46474,
            "fmeasure": 0.5337
        },
        "rouge2": {
            "precision": 0.35859,
            "recall": 0.28067,
            "fmeasure": 0.31193
        },
        "rougeL": {
            "precision": 0.52609,
            "recall": 0.39717,
            "fmeasure": 0.44455
        },
        "rougeLsum": {
            "precision": 0.52609,
            "recall": 0.39717,
            "fmeasure": 0.44455
        },
        "nist": 1.76997580358577,
        "bleu": 25.61797,
        "meteor": 0.2441806983658151,
        "bleurt": -0.35764,
        "nubia": {
            "semantic_relation": 2.93697,
            "contradiction": 89.18727,
            "irrelevancy": 6.40297,
            "logical_agreement": 4.40976,
            "grammar_ref": 4.17,
            "grammar_hyp": 4.20122,
            "nubia_score": 0.30678
        },
        "bertscore": {
            "precision": 0.88209,
            "recall": 0.84057,
            "f1": 0.8603
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.07574294699860609,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.08866415466539351,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.2857142857142857,
            "3": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.26087,
            "recall": 0.19355,
            "fmeasure": 0.22222
        },
        "rouge2": {
            "precision": 0.04545,
            "recall": 0.03333,
            "fmeasure": 0.03846
        },
        "rougeL": {
            "precision": 0.10145,
            "recall": 0.16559,
            "fmeasure": 0.11785
        },
        "rougeLsum": {
            "precision": 0.10145,
            "recall": 0.16559,
            "fmeasure": 0.11785
        },
        "nist": 1.3627712037814919,
        "bleu": 2.9724,
        "meteor": 0.09718416119503934,
        "bleurt": -0.75918,
        "nubia": {
            "semantic_relation": 1.96678,
            "contradiction": 22.3446,
            "irrelevancy": 73.40732,
            "logical_agreement": 4.24807,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.92192,
            "nubia_score": 0.15127
        },
        "bertscore": {
            "precision": 0.76115,
            "recall": 0.76992,
            "f1": 0.75442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.6,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.6,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.6,
            "fmeasure": 0.6
        },
        "nist": 2.1139542422010487,
        "bleu": 19.08165,
        "meteor": 0.33999918601849244,
        "bleurt": 0.34287,
        "nubia": {
            "semantic_relation": 3.88885,
            "contradiction": 0.33965,
            "irrelevancy": 97.50395,
            "logical_agreement": 2.1564,
            "grammar_ref": 6.33221,
            "grammar_hyp": 5.99887,
            "nubia_score": 0.60882
        },
        "bertscore": {
            "precision": 0.8979,
            "recall": 0.88645,
            "f1": 0.89214
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "t5-small/totto_test",
        "N": 12,
        "total_length": 221,
        "mean_pred_length": 18.416666666666668,
        "std_pred_length": 4.424521317486095,
        "median_pred_length": 17.5,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.5158371040723982,
        "vocab_size-1": 114,
        "unique-1": 80,
        "entropy-1": 6.241177355243821,
        "distinct-2": 0.7799043062200957,
        "vocab_size-2": 163,
        "unique-2": 138,
        "entropy-2": 7.136267043868978,
        "cond_entropy-2": 0.8398093773144596,
        "distinct-3": 0.8527918781725888,
        "vocab_size-3": 168,
        "unique-3": 149,
        "entropy-3": 7.277512210416099,
        "cond_entropy-3": 0.16588021760576777,
        "total_length-nopunct": 188,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 3.324989557210001,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.574468085106383,
        "vocab_size-1-nopunct": 108,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.205050893283151,
        "distinct-2-nopunct": 0.8011363636363636,
        "vocab_size-2-nopunct": 141,
        "unique-2-nopunct": 123,
        "entropy-2-nopunct": 6.926201667319329,
        "cond_entropy-2-nopunct": 0.7587047115362481,
        "distinct-3-nopunct": 0.8719512195121951,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 129,
        "entropy-3-nopunct": 7.058043373650032,
        "cond_entropy-3-nopunct": 0.14646828813444882,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2972972972972973,
            "2": 0.6666666666666666,
            "3": 0.7194244604316546
        },
        "rouge1": {
            "precision": 0.7577,
            "recall": 0.74753,
            "fmeasure": 0.73828
        },
        "rouge2": {
            "precision": 0.5937,
            "recall": 0.59116,
            "fmeasure": 0.58184
        },
        "rougeL": {
            "precision": 0.70668,
            "recall": 0.6894,
            "fmeasure": 0.68511
        },
        "rougeLsum": {
            "precision": 0.70668,
            "recall": 0.6894,
            "fmeasure": 0.68511
        },
        "nist": 5.70337950596592,
        "bleu": 50.26901,
        "meteor": 0.38371320752408067,
        "bleurt": 0.27746,
        "nubia": {
            "semantic_relation": 3.81988,
            "contradiction": 22.69936,
            "irrelevancy": 39.21497,
            "logical_agreement": 38.08567,
            "grammar_ref": 4.07585,
            "grammar_hyp": 3.97953,
            "nubia_score": 0.63797
        },
        "bertscore": {
            "precision": 0.92727,
            "recall": 0.93465,
            "f1": 0.9299
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "t5-small/totto_test",
        "N": 29,
        "total_length": 447,
        "mean_pred_length": 15.413793103448276,
        "std_pred_length": 5.561674526920891,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.5883668903803132,
        "vocab_size-1": 263,
        "unique-1": 220,
        "entropy-1": 7.196002079431519,
        "distinct-2": 0.916267942583732,
        "vocab_size-2": 383,
        "unique-2": 357,
        "entropy-2": 8.509380932314889,
        "cond_entropy-2": 1.1272971681027388,
        "distinct-3": 0.9820051413881749,
        "vocab_size-3": 382,
        "unique-3": 375,
        "entropy-3": 8.567636627762631,
        "cond_entropy-3": 0.06530291342500978,
        "total_length-nopunct": 377,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.242640687119285,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6843501326259946,
        "vocab_size-1-nopunct": 258,
        "unique-1-nopunct": 219,
        "entropy-1-nopunct": 7.443725111854903,
        "distinct-2-nopunct": 0.9367816091954023,
        "vocab_size-2-nopunct": 326,
        "unique-2-nopunct": 311,
        "entropy-2-nopunct": 8.28560186509542,
        "cond_entropy-2-nopunct": 0.88808201715571,
        "distinct-3-nopunct": 0.9968652037617555,
        "vocab_size-3-nopunct": 318,
        "unique-3-nopunct": 317,
        "entropy-3-nopunct": 8.311143021288444,
        "cond_entropy-3-nopunct": 0.03671014456869148,
        "msttr-100": 0.7375,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1553398058252427,
            "2": 0.3488372093023256,
            "3": 0.7086092715231788
        },
        "rouge1": {
            "precision": 0.7364,
            "recall": 0.65801,
            "fmeasure": 0.68251
        },
        "rouge2": {
            "precision": 0.4692,
            "recall": 0.41251,
            "fmeasure": 0.43058
        },
        "rougeL": {
            "precision": 0.63035,
            "recall": 0.55299,
            "fmeasure": 0.57829
        },
        "rougeLsum": {
            "precision": 0.63035,
            "recall": 0.55299,
            "fmeasure": 0.57829
        },
        "nist": 5.584654996549835,
        "bleu": 30.8613,
        "meteor": 0.33816092049246094,
        "bleurt": 0.18082,
        "nubia": {
            "semantic_relation": 3.98098,
            "contradiction": 13.22435,
            "irrelevancy": 28.52341,
            "logical_agreement": 58.25224,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.69372,
            "nubia_score": 0.64237
        },
        "bertscore": {
            "precision": 0.91795,
            "recall": 0.91031,
            "f1": 0.91305
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "t5-small/totto_test",
        "N": 47,
        "total_length": 699,
        "mean_pred_length": 14.872340425531915,
        "std_pred_length": 3.8845959908039385,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5350500715307582,
        "vocab_size-1": 374,
        "unique-1": 300,
        "entropy-1": 7.516196735275689,
        "distinct-2": 0.8696319018404908,
        "vocab_size-2": 567,
        "unique-2": 509,
        "entropy-2": 9.033815098199604,
        "cond_entropy-2": 1.3125297386752326,
        "distinct-3": 0.943801652892562,
        "vocab_size-3": 571,
        "unique-3": 539,
        "entropy-3": 9.125899142072136,
        "cond_entropy-3": 0.09353214491355547,
        "total_length-nopunct": 609,
        "mean_pred_length-nopunct": 12.957446808510639,
        "std_pred_length-nopunct": 3.5427927846905987,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6009852216748769,
        "vocab_size-1-nopunct": 366,
        "unique-1-nopunct": 297,
        "entropy-1-nopunct": 7.695804155697129,
        "distinct-2-nopunct": 0.8807829181494662,
        "vocab_size-2-nopunct": 495,
        "unique-2-nopunct": 451,
        "entropy-2-nopunct": 8.83851215202917,
        "cond_entropy-2-nopunct": 1.2432604581442273,
        "distinct-3-nopunct": 0.9533980582524272,
        "vocab_size-3-nopunct": 491,
        "unique-3-nopunct": 467,
        "entropy-3-nopunct": 8.915224738575445,
        "cond_entropy-3-nopunct": 0.08979616111636445,
        "msttr-100": 0.70833,
        "msttr-100_nopunct": 0.76167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1592920353982301,
            "2": 0.40588235294117647,
            "3": 0.7125
        },
        "rouge1": {
            "precision": 0.75153,
            "recall": 0.65173,
            "fmeasure": 0.69187
        },
        "rouge2": {
            "precision": 0.49419,
            "recall": 0.42827,
            "fmeasure": 0.45459
        },
        "rougeL": {
            "precision": 0.65296,
            "recall": 0.57047,
            "fmeasure": 0.60347
        },
        "rougeLsum": {
            "precision": 0.65296,
            "recall": 0.57047,
            "fmeasure": 0.60347
        },
        "nist": 5.810034168836824,
        "bleu": 38.65994,
        "meteor": 0.34449319134325423,
        "bleurt": 0.1966,
        "nubia": {
            "semantic_relation": 4.16691,
            "contradiction": 11.54902,
            "irrelevancy": 29.79749,
            "logical_agreement": 58.65349,
            "grammar_ref": 4.69178,
            "grammar_hyp": 4.95769,
            "nubia_score": 0.67645
        },
        "bertscore": {
            "precision": 0.92542,
            "recall": 0.91003,
            "f1": 0.91708
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "t5-small/totto_test",
        "N": 20,
        "total_length": 316,
        "mean_pred_length": 15.8,
        "std_pred_length": 3.9949968710876362,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6012658227848101,
        "vocab_size-1": 190,
        "unique-1": 157,
        "entropy-1": 6.829772268585919,
        "distinct-2": 0.9256756756756757,
        "vocab_size-2": 274,
        "unique-2": 262,
        "entropy-2": 8.00916886388856,
        "cond_entropy-2": 1.0254152424846583,
        "distinct-3": 0.9782608695652174,
        "vocab_size-3": 270,
        "unique-3": 265,
        "entropy-3": 8.062311096263045,
        "cond_entropy-3": 0.060409225254222515,
        "total_length-nopunct": 280,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.03732584763727,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6607142857142857,
        "vocab_size-1-nopunct": 185,
        "unique-1-nopunct": 157,
        "entropy-1-nopunct": 6.90889559010139,
        "distinct-2-nopunct": 0.9307692307692308,
        "vocab_size-2-nopunct": 242,
        "unique-2-nopunct": 234,
        "entropy-2-nopunct": 7.825120841816361,
        "cond_entropy-2-nopunct": 0.9879670249253996,
        "distinct-3-nopunct": 0.9875,
        "vocab_size-3-nopunct": 237,
        "unique-3-nopunct": 235,
        "entropy-3-nopunct": 7.878745231016214,
        "cond_entropy-3-nopunct": 0.056853615961474355,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.4918032786885246,
            "3": 0.6596858638743456
        },
        "rouge1": {
            "precision": 0.66658,
            "recall": 0.69009,
            "fmeasure": 0.66362
        },
        "rouge2": {
            "precision": 0.44957,
            "recall": 0.45791,
            "fmeasure": 0.4438
        },
        "rougeL": {
            "precision": 0.57656,
            "recall": 0.60446,
            "fmeasure": 0.57704
        },
        "rougeLsum": {
            "precision": 0.57656,
            "recall": 0.60446,
            "fmeasure": 0.57704
        },
        "nist": 5.22423690417367,
        "bleu": 36.8583,
        "meteor": 0.3613739602688137,
        "bleurt": 0.16536,
        "nubia": {
            "semantic_relation": 3.92524,
            "contradiction": 10.01101,
            "irrelevancy": 34.98057,
            "logical_agreement": 55.00842,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.45629,
            "nubia_score": 0.67351
        },
        "bertscore": {
            "precision": 0.90177,
            "recall": 0.90727,
            "f1": 0.9036
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "t5-small/totto_test",
        "N": 36,
        "total_length": 604,
        "mean_pred_length": 16.77777777777778,
        "std_pred_length": 4.7848784444743275,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5678807947019867,
        "vocab_size-1": 343,
        "unique-1": 287,
        "entropy-1": 7.470542267959763,
        "distinct-2": 0.9401408450704225,
        "vocab_size-2": 534,
        "unique-2": 511,
        "entropy-2": 9.00491496720448,
        "cond_entropy-2": 1.373092862007468,
        "distinct-3": 0.9943609022556391,
        "vocab_size-3": 529,
        "unique-3": 526,
        "entropy-3": 9.044004240012573,
        "cond_entropy-3": 0.044030992699081936,
        "total_length-nopunct": 526,
        "mean_pred_length-nopunct": 14.61111111111111,
        "std_pred_length-nopunct": 4.131705175145123,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6387832699619772,
        "vocab_size-1-nopunct": 336,
        "unique-1-nopunct": 285,
        "entropy-1-nopunct": 7.630074072245191,
        "distinct-2-nopunct": 0.9489795918367347,
        "vocab_size-2-nopunct": 465,
        "unique-2-nopunct": 450,
        "entropy-2-nopunct": 8.807026153279477,
        "cond_entropy-2-nopunct": 1.241909725551662,
        "distinct-3-nopunct": 0.9977973568281938,
        "vocab_size-3-nopunct": 453,
        "unique-3-nopunct": 452,
        "entropy-3-nopunct": 8.822143200947293,
        "cond_entropy-3-nopunct": 0.02539463420095923,
        "msttr-100": 0.70833,
        "msttr-100_nopunct": 0.764,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2564102564102564,
            "2": 0.41911764705882354,
            "3": 0.7035175879396985
        },
        "rouge1": {
            "precision": 0.73336,
            "recall": 0.6417,
            "fmeasure": 0.67203
        },
        "rouge2": {
            "precision": 0.47183,
            "recall": 0.42121,
            "fmeasure": 0.43622
        },
        "rougeL": {
            "precision": 0.61343,
            "recall": 0.53919,
            "fmeasure": 0.5632
        },
        "rougeLsum": {
            "precision": 0.61343,
            "recall": 0.53919,
            "fmeasure": 0.5632
        },
        "nist": 5.755504247384189,
        "bleu": 35.09034,
        "meteor": 0.3308717346307046,
        "bleurt": 0.12355,
        "nubia": {
            "semantic_relation": 3.9748,
            "contradiction": 19.80975,
            "irrelevancy": 29.93206,
            "logical_agreement": 50.25819,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.97623,
            "nubia_score": 0.63762
        },
        "bertscore": {
            "precision": 0.91313,
            "recall": 0.90438,
            "f1": 0.90793
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 82,
        "mean_pred_length": 20.5,
        "std_pred_length": 3.840572873934304,
        "median_pred_length": 20.0,
        "min_pred_length": 16,
        "max_pred_length": 26,
        "distinct-1": 0.6707317073170732,
        "vocab_size-1": 55,
        "unique-1": 46,
        "entropy-1": 5.292881652071663,
        "distinct-2": 0.8846153846153846,
        "vocab_size-2": 69,
        "unique-2": 64,
        "entropy-2": 6.003350936810973,
        "cond_entropy-2": 0.6186310365856217,
        "distinct-3": 0.972972972972973,
        "vocab_size-3": 72,
        "unique-3": 70,
        "entropy-3": 6.155399311574901,
        "cond_entropy-3": 0.11324033595589027,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 1.8027756377319946,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8620689655172413,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.547636167541365,
        "distinct-2-nopunct": 0.9814814814814815,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.71785046512643,
        "cond_entropy-2-nopunct": 0.15616576629515577,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.07103131238874388,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4772727272727273,
            "3": 0.2982456140350877
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.30611,
            "fmeasure": 0.40801
        },
        "rouge2": {
            "precision": 0.44122,
            "recall": 0.21778,
            "fmeasure": 0.29015
        },
        "rougeL": {
            "precision": 0.51781,
            "recall": 0.27125,
            "fmeasure": 0.35524
        },
        "rougeLsum": {
            "precision": 0.51781,
            "recall": 0.27125,
            "fmeasure": 0.35524
        },
        "nist": 1.1811295542570717,
        "bleu": 29.03435,
        "meteor": 0.2134354800897913,
        "bleurt": -0.629,
        "nubia": {
            "semantic_relation": 2.73541,
            "contradiction": 11.16968,
            "irrelevancy": 30.58854,
            "logical_agreement": 58.24178,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.85922,
            "nubia_score": 0.28026
        },
        "bertscore": {
            "precision": 0.86285,
            "recall": 0.80196,
            "f1": 0.82969
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5714285714285714,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.35,
            "recall": 0.4375,
            "fmeasure": 0.38889
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.2,
            "fmeasure": 0.17647
        },
        "rougeL": {
            "precision": 0.35,
            "recall": 0.4375,
            "fmeasure": 0.38889
        },
        "rougeLsum": {
            "precision": 0.35,
            "recall": 0.4375,
            "fmeasure": 0.38889
        },
        "nist": 1.9983190476596027,
        "bleu": 9.84611,
        "meteor": 0.1543313884266698,
        "bleurt": -0.6384,
        "nubia": {
            "semantic_relation": 2.52,
            "contradiction": 0.5534,
            "irrelevancy": 95.47263,
            "logical_agreement": 3.97397,
            "grammar_ref": 3.92881,
            "grammar_hyp": 2.56534,
            "nubia_score": 0.46613
        },
        "bertscore": {
            "precision": 0.72795,
            "recall": 0.79892,
            "f1": 0.76179
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "t5-small/totto_test",
        "N": 40,
        "total_length": 609,
        "mean_pred_length": 15.225,
        "std_pred_length": 4.3674220084622,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.43842364532019706,
        "vocab_size-1": 267,
        "unique-1": 218,
        "entropy-1": 6.780736956950551,
        "distinct-2": 0.7469244288224957,
        "vocab_size-2": 425,
        "unique-2": 388,
        "entropy-2": 8.28388707669062,
        "cond_entropy-2": 1.3520922980871644,
        "distinct-3": 0.8468809073724007,
        "vocab_size-3": 448,
        "unique-3": 428,
        "entropy-3": 8.536854493716476,
        "cond_entropy-3": 0.30586160062232726,
        "total_length-nopunct": 524,
        "mean_pred_length-nopunct": 13.1,
        "std_pred_length-nopunct": 3.645545226711637,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.49809160305343514,
        "vocab_size-1-nopunct": 261,
        "unique-1-nopunct": 217,
        "entropy-1-nopunct": 6.919514128253562,
        "distinct-2-nopunct": 0.7479338842975206,
        "vocab_size-2-nopunct": 362,
        "unique-2-nopunct": 332,
        "entropy-2-nopunct": 8.042872817547144,
        "cond_entropy-2-nopunct": 1.2585253125274871,
        "distinct-3-nopunct": 0.8490990990990991,
        "vocab_size-3-nopunct": 377,
        "unique-3-nopunct": 360,
        "entropy-3-nopunct": 8.298564323959386,
        "cond_entropy-3-nopunct": 0.3278528054868536,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.668,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.3384615384615385,
            "3": 0.7375886524822695
        },
        "rouge1": {
            "precision": 0.75769,
            "recall": 0.7225,
            "fmeasure": 0.72963
        },
        "rouge2": {
            "precision": 0.56653,
            "recall": 0.52465,
            "fmeasure": 0.53801
        },
        "rougeL": {
            "precision": 0.66827,
            "recall": 0.62973,
            "fmeasure": 0.64035
        },
        "rougeLsum": {
            "precision": 0.66827,
            "recall": 0.62973,
            "fmeasure": 0.64035
        },
        "nist": 6.511661769952295,
        "bleu": 49.26424,
        "meteor": 0.38060718890244916,
        "bleurt": 0.24276,
        "nubia": {
            "semantic_relation": 4.03179,
            "contradiction": 7.81912,
            "irrelevancy": 36.7865,
            "logical_agreement": 55.39438,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.41164,
            "nubia_score": 0.68997
        },
        "bertscore": {
            "precision": 0.9218,
            "recall": 0.91789,
            "f1": 0.91867
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 1.0,
        "median_pred_length": 17.0,
        "min_pred_length": 16,
        "max_pred_length": 18,
        "distinct-1": 0.6764705882352942,
        "vocab_size-1": 23,
        "unique-1": 19,
        "entropy-1": 4.12408379706906,
        "distinct-2": 0.9375,
        "vocab_size-2": 30,
        "unique-2": 29,
        "entropy-2": 4.851409765557392,
        "cond_entropy-2": 0.7875371587496607,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": 0.06538684568063419,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.363713275750188,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.2493097618368752,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.0,
            "3": 0.16666666666666666
        },
        "rouge1": {
            "precision": 0.23681,
            "recall": 0.32161,
            "fmeasure": 0.27195
        },
        "rouge2": {
            "precision": 0.05794,
            "recall": 0.08333,
            "fmeasure": 0.06817
        },
        "rougeL": {
            "precision": 0.23681,
            "recall": 0.32161,
            "fmeasure": 0.27195
        },
        "rougeLsum": {
            "precision": 0.23681,
            "recall": 0.32161,
            "fmeasure": 0.27195
        },
        "nist": 0.8907121327983613,
        "bleu": 3.0098,
        "meteor": 0.13430141265879736,
        "bleurt": -0.35122,
        "nubia": {
            "semantic_relation": 2.77065,
            "contradiction": 17.04862,
            "irrelevancy": 78.50404,
            "logical_agreement": 4.44734,
            "grammar_ref": 5.41182,
            "grammar_hyp": 3.66677,
            "nubia_score": 0.43186
        },
        "bertscore": {
            "precision": 0.74409,
            "recall": 0.82927,
            "f1": 0.77502
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 53,
        "mean_pred_length": 26.5,
        "std_pred_length": 0.5,
        "median_pred_length": 26.5,
        "min_pred_length": 26,
        "max_pred_length": 27,
        "distinct-1": 0.5094339622641509,
        "vocab_size-1": 27,
        "unique-1": 15,
        "entropy-1": 4.2879504486858275,
        "distinct-2": 0.7647058823529411,
        "vocab_size-2": 39,
        "unique-2": 29,
        "entropy-2": 5.172233675219989,
        "cond_entropy-2": 0.8900670992995237,
        "distinct-3": 0.8571428571428571,
        "vocab_size-3": 42,
        "unique-3": 35,
        "entropy-3": 5.328995558400923,
        "cond_entropy-3": 0.12442353282954517,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6190476190476191,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.4812540297670855,
        "distinct-2-nopunct": 0.85,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 5.021928094887363,
        "cond_entropy-2-nopunct": 0.5216031722528333,
        "distinct-3-nopunct": 0.9210526315789473,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.090032776601483,
        "cond_entropy-3-nopunct": 0.031262576450960075,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.34722,
            "recall": 0.3873,
            "fmeasure": 0.34348
        },
        "rouge2": {
            "precision": 0.18329,
            "recall": 0.1835,
            "fmeasure": 0.17347
        },
        "rougeL": {
            "precision": 0.31944,
            "recall": 0.36587,
            "fmeasure": 0.31944
        },
        "rougeLsum": {
            "precision": 0.31944,
            "recall": 0.36587,
            "fmeasure": 0.31944
        },
        "nist": 1.6607319823153164,
        "bleu": 8.57136,
        "meteor": 0.1804953820174247,
        "bleurt": -0.40797,
        "nubia": {
            "semantic_relation": 3.28182,
            "contradiction": 5.34204,
            "irrelevancy": 64.76796,
            "logical_agreement": 29.89,
            "grammar_ref": 5.71002,
            "grammar_hyp": 4.21147,
            "nubia_score": 0.38352
        },
        "bertscore": {
            "precision": 0.75181,
            "recall": 0.82403,
            "f1": 0.77276
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.251629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.28642554229237843,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.35714285714285715
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.36266,
            "fmeasure": 0.4806
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.2493,
            "fmeasure": 0.33214
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.28913,
            "fmeasure": 0.38362
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.28913,
            "fmeasure": 0.38362
        },
        "nist": 0.658097229751274,
        "bleu": 24.88305,
        "meteor": 0.24364837792760677,
        "bleurt": -0.81976,
        "nubia": {
            "semantic_relation": 2.13418,
            "contradiction": 32.23334,
            "irrelevancy": 46.09277,
            "logical_agreement": 21.67389,
            "grammar_ref": 4.14314,
            "grammar_hyp": 4.04078,
            "nubia_score": 0.13404
        },
        "bertscore": {
            "precision": 0.91915,
            "recall": 0.82601,
            "f1": 0.8701
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "t5-small/totto_test",
        "N": 31,
        "total_length": 547,
        "mean_pred_length": 17.64516129032258,
        "std_pred_length": 5.1528156230310795,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.5648994515539305,
        "vocab_size-1": 309,
        "unique-1": 239,
        "entropy-1": 7.4890163844030955,
        "distinct-2": 0.8875968992248062,
        "vocab_size-2": 458,
        "unique-2": 417,
        "entropy-2": 8.751511618856657,
        "cond_entropy-2": 1.122903756184935,
        "distinct-3": 0.9649484536082474,
        "vocab_size-3": 468,
        "unique-3": 453,
        "entropy-3": 8.848624906137799,
        "cond_entropy-3": 0.10013642590545635,
        "total_length-nopunct": 474,
        "mean_pred_length-nopunct": 15.290322580645162,
        "std_pred_length-nopunct": 4.76000507174504,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6392405063291139,
        "vocab_size-1-nopunct": 303,
        "unique-1-nopunct": 238,
        "entropy-1-nopunct": 7.701701429129101,
        "distinct-2-nopunct": 0.90744920993228,
        "vocab_size-2-nopunct": 402,
        "unique-2-nopunct": 376,
        "entropy-2-nopunct": 8.56880737283491,
        "cond_entropy-2-nopunct": 0.9075753154738244,
        "distinct-3-nopunct": 0.9781553398058253,
        "vocab_size-3-nopunct": 403,
        "unique-3-nopunct": 395,
        "entropy-3-nopunct": 8.640978955575994,
        "cond_entropy-3-nopunct": 0.0777736664464846,
        "msttr-100": 0.724,
        "msttr-100_nopunct": 0.7875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24299065420560748,
            "2": 0.3670886075949367,
            "3": 0.696969696969697
        },
        "rouge1": {
            "precision": 0.79151,
            "recall": 0.68682,
            "fmeasure": 0.72672
        },
        "rouge2": {
            "precision": 0.55738,
            "recall": 0.49361,
            "fmeasure": 0.51637
        },
        "rougeL": {
            "precision": 0.68059,
            "recall": 0.5858,
            "fmeasure": 0.61992
        },
        "rougeLsum": {
            "precision": 0.68059,
            "recall": 0.5858,
            "fmeasure": 0.61992
        },
        "nist": 6.227654150907004,
        "bleu": 43.16545,
        "meteor": 0.36066259767933695,
        "bleurt": 0.17745,
        "nubia": {
            "semantic_relation": 4.10196,
            "contradiction": 9.95629,
            "irrelevancy": 24.1173,
            "logical_agreement": 65.92641,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.8189,
            "nubia_score": 0.67567
        },
        "bertscore": {
            "precision": 0.93604,
            "recall": 0.91368,
            "f1": 0.92343
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "t5-small/totto_test",
        "N": 79,
        "total_length": 1210,
        "mean_pred_length": 15.316455696202532,
        "std_pred_length": 4.902968111121067,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.5049586776859504,
        "vocab_size-1": 611,
        "unique-1": 494,
        "entropy-1": 8.038589682582764,
        "distinct-2": 0.8567639257294429,
        "vocab_size-2": 969,
        "unique-2": 880,
        "entropy-2": 9.768148112456599,
        "cond_entropy-2": 1.4905554408681572,
        "distinct-3": 0.9401140684410646,
        "vocab_size-3": 989,
        "unique-3": 936,
        "entropy-3": 9.910107416094288,
        "cond_entropy-3": 0.13714865253661065,
        "total_length-nopunct": 1060,
        "mean_pred_length-nopunct": 13.417721518987342,
        "std_pred_length-nopunct": 4.637785359023462,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5707547169811321,
        "vocab_size-1-nopunct": 605,
        "unique-1-nopunct": 493,
        "entropy-1-nopunct": 8.288921346392154,
        "distinct-2-nopunct": 0.8654434250764526,
        "vocab_size-2-nopunct": 849,
        "unique-2-nopunct": 780,
        "entropy-2-nopunct": 9.576226735139988,
        "cond_entropy-2-nopunct": 1.3660705588880782,
        "distinct-3-nopunct": 0.9423503325942351,
        "vocab_size-3-nopunct": 850,
        "unique-3-nopunct": 808,
        "entropy-3-nopunct": 9.691141300634186,
        "cond_entropy-3-nopunct": 0.1315484481933648,
        "msttr-100": 0.74167,
        "msttr-100_nopunct": 0.784,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.31189710610932475,
            "2": 0.4486301369863014,
            "3": 0.7009222661396575
        },
        "rouge1": {
            "precision": 0.72762,
            "recall": 0.66645,
            "fmeasure": 0.678
        },
        "rouge2": {
            "precision": 0.4928,
            "recall": 0.45131,
            "fmeasure": 0.45759
        },
        "rougeL": {
            "precision": 0.61602,
            "recall": 0.57109,
            "fmeasure": 0.57698
        },
        "rougeLsum": {
            "precision": 0.61602,
            "recall": 0.57109,
            "fmeasure": 0.57698
        },
        "nist": 6.8687412480835635,
        "bleu": 41.04874,
        "meteor": 0.36108811328732804,
        "bleurt": 0.07645,
        "nubia": {
            "semantic_relation": 3.97265,
            "contradiction": 10.75956,
            "irrelevancy": 38.68427,
            "logical_agreement": 50.55617,
            "grammar_ref": 4.80224,
            "grammar_hyp": 5.01585,
            "nubia_score": 0.62072
        },
        "bertscore": {
            "precision": 0.91816,
            "recall": 0.90899,
            "f1": 0.91171
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.17647058823529413
        },
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.2973,
            "fmeasure": 0.44
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.25,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.27027,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.27027,
            "fmeasure": 0.4
        },
        "nist": 0.15785079295354848,
        "bleu": 23.70635,
        "meteor": 0.1875948498749217,
        "bleurt": -0.53563,
        "nubia": {
            "semantic_relation": 2.6063,
            "contradiction": 0.66029,
            "irrelevancy": 33.53154,
            "logical_agreement": 65.80817,
            "grammar_ref": 4.39709,
            "grammar_hyp": 4.60448,
            "nubia_score": 0.19093
        },
        "bertscore": {
            "precision": 0.92502,
            "recall": 0.73953,
            "f1": 0.82194
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 44,
        "mean_pred_length": 11.0,
        "std_pred_length": 3.082207001484488,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 16,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 4.896820539042672,
        "distinct-2": 1.0,
        "vocab_size-2": 40,
        "unique-2": 40,
        "entropy-2": 5.3219280948873635,
        "cond_entropy-2": 0.2813686638041515,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 8.75,
        "std_pred_length-nopunct": 2.165063509461097,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.786425874087821,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.21201006763545704,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.19930880822340663,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.0,
            "3": 0.7666666666666667
        },
        "rouge1": {
            "precision": 0.77546,
            "recall": 0.71414,
            "fmeasure": 0.7392
        },
        "rouge2": {
            "precision": 0.58103,
            "recall": 0.52898,
            "fmeasure": 0.55127
        },
        "rougeL": {
            "precision": 0.69097,
            "recall": 0.63451,
            "fmeasure": 0.65802
        },
        "rougeLsum": {
            "precision": 0.69097,
            "recall": 0.63451,
            "fmeasure": 0.65802
        },
        "nist": 3.86631872427068,
        "bleu": 38.45803,
        "meteor": 0.36448837384644434,
        "bleurt": 0.37179,
        "nubia": {
            "semantic_relation": 4.43935,
            "contradiction": 1.00546,
            "irrelevancy": 17.93578,
            "logical_agreement": 81.05876,
            "grammar_ref": 6.02061,
            "grammar_hyp": 6.33051,
            "nubia_score": 0.72244
        },
        "bertscore": {
            "precision": 0.93878,
            "recall": 0.94273,
            "f1": 0.94059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "t5-small/totto_test",
        "N": 36,
        "total_length": 552,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 3.704351795148811,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.5670289855072463,
        "vocab_size-1": 313,
        "unique-1": 254,
        "entropy-1": 7.38810422521265,
        "distinct-2": 0.9186046511627907,
        "vocab_size-2": 474,
        "unique-2": 446,
        "entropy-2": 8.81284638725151,
        "cond_entropy-2": 1.2152172781180102,
        "distinct-3": 0.9791666666666666,
        "vocab_size-3": 470,
        "unique-3": 460,
        "entropy-3": 8.865223928941885,
        "cond_entropy-3": 0.05683944013651545,
        "total_length-nopunct": 479,
        "mean_pred_length-nopunct": 13.305555555555555,
        "std_pred_length-nopunct": 3.438502940108646,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6388308977035491,
        "vocab_size-1-nopunct": 306,
        "unique-1-nopunct": 252,
        "entropy-1-nopunct": 7.576582788815888,
        "distinct-2-nopunct": 0.9187358916478555,
        "vocab_size-2-nopunct": 407,
        "unique-2-nopunct": 384,
        "entropy-2-nopunct": 8.588883790418615,
        "cond_entropy-2-nopunct": 1.0816146595080531,
        "distinct-3-nopunct": 0.9803439803439803,
        "vocab_size-3-nopunct": 399,
        "unique-3-nopunct": 391,
        "entropy-3-nopunct": 8.6295729449542,
        "cond_entropy-3-nopunct": 0.05612416075898506,
        "msttr-100": 0.714,
        "msttr-100_nopunct": 0.7675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1728395061728395,
            "2": 0.5254237288135594,
            "3": 0.7107692307692308
        },
        "rouge1": {
            "precision": 0.70483,
            "recall": 0.71543,
            "fmeasure": 0.69673
        },
        "rouge2": {
            "precision": 0.4829,
            "recall": 0.49957,
            "fmeasure": 0.4814
        },
        "rougeL": {
            "precision": 0.60708,
            "recall": 0.62905,
            "fmeasure": 0.60642
        },
        "rougeLsum": {
            "precision": 0.60708,
            "recall": 0.62905,
            "fmeasure": 0.60642
        },
        "nist": 6.353834527884994,
        "bleu": 43.29993,
        "meteor": 0.3846784411150429,
        "bleurt": 0.17968,
        "nubia": {
            "semantic_relation": 4.1048,
            "contradiction": 6.30626,
            "irrelevancy": 45.01145,
            "logical_agreement": 48.68229,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.52651,
            "nubia_score": 0.71037
        },
        "bertscore": {
            "precision": 0.90992,
            "recall": 0.9213,
            "f1": 0.91389
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.939470994001286,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.40509942232494883,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.807763576417195,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.20971762763487742,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.52941,
            "recall": 0.37922,
            "fmeasure": 0.43971
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.20741,
            "fmeasure": 0.24103
        },
        "rougeL": {
            "precision": 0.43137,
            "recall": 0.31039,
            "fmeasure": 0.35917
        },
        "rougeLsum": {
            "precision": 0.43137,
            "recall": 0.31039,
            "fmeasure": 0.35917
        },
        "nist": 2.016134947185322,
        "bleu": 12.10164,
        "meteor": 0.1920930041493904,
        "bleurt": -0.9849,
        "nubia": {
            "semantic_relation": 2.9137,
            "contradiction": 3.22994,
            "irrelevancy": 92.23192,
            "logical_agreement": 4.53814,
            "grammar_ref": 4.75948,
            "grammar_hyp": 6.06664,
            "nubia_score": 0.21443
        },
        "bertscore": {
            "precision": 0.85838,
            "recall": 0.81367,
            "f1": 0.83115
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 25,
        "unique-1": 20,
        "entropy-1": 4.573557262275186,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.16231556531425703,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.66518,
            "recall": 0.671,
            "fmeasure": 0.6573
        },
        "rouge2": {
            "precision": 0.43077,
            "recall": 0.45,
            "fmeasure": 0.4323
        },
        "rougeL": {
            "precision": 0.62946,
            "recall": 0.62554,
            "fmeasure": 0.6173
        },
        "rougeLsum": {
            "precision": 0.62946,
            "recall": 0.62554,
            "fmeasure": 0.6173
        },
        "nist": 2.8860623418164146,
        "bleu": 30.40935,
        "meteor": 0.30045852886599284,
        "bleurt": 0.2343,
        "nubia": {
            "semantic_relation": 3.99922,
            "contradiction": 0.15036,
            "irrelevancy": 75.48597,
            "logical_agreement": 24.36368,
            "grammar_ref": 5.14789,
            "grammar_hyp": 4.45672,
            "nubia_score": 0.71267
        },
        "bertscore": {
            "precision": 0.8841,
            "recall": 0.8758,
            "f1": 0.8792
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "t5-small/totto_test",
        "N": 80,
        "total_length": 1203,
        "mean_pred_length": 15.0375,
        "std_pred_length": 4.589236728476752,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5236907730673317,
        "vocab_size-1": 630,
        "unique-1": 526,
        "entropy-1": 8.100675085804966,
        "distinct-2": 0.8993766696349065,
        "vocab_size-2": 1010,
        "unique-2": 938,
        "entropy-2": 9.881244358519318,
        "cond_entropy-2": 1.5450384635094063,
        "distinct-3": 0.9779482262703739,
        "vocab_size-3": 1020,
        "unique-3": 997,
        "entropy-3": 9.982419895060492,
        "cond_entropy-3": 0.10083234699800969,
        "total_length-nopunct": 1047,
        "mean_pred_length-nopunct": 13.0875,
        "std_pred_length-nopunct": 4.050289341516232,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5940783190066857,
        "vocab_size-1-nopunct": 622,
        "unique-1-nopunct": 522,
        "entropy-1-nopunct": 8.389300431755562,
        "distinct-2-nopunct": 0.9131334022750776,
        "vocab_size-2-nopunct": 883,
        "unique-2-nopunct": 835,
        "entropy-2-nopunct": 9.689226653000604,
        "cond_entropy-2-nopunct": 1.3821252149824887,
        "distinct-3-nopunct": 0.9842164599774521,
        "vocab_size-3-nopunct": 873,
        "unique-3-nopunct": 859,
        "entropy-3-nopunct": 9.76122321425604,
        "cond_entropy-3-nopunct": 0.08919118822047072,
        "msttr-100": 0.7425,
        "msttr-100_nopunct": 0.794,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3220338983050847,
            "2": 0.3615023474178404,
            "3": 0.6670366259711432
        },
        "rouge1": {
            "precision": 0.7307,
            "recall": 0.64875,
            "fmeasure": 0.67225
        },
        "rouge2": {
            "precision": 0.48059,
            "recall": 0.42303,
            "fmeasure": 0.43796
        },
        "rougeL": {
            "precision": 0.6254,
            "recall": 0.56036,
            "fmeasure": 0.57751
        },
        "rougeLsum": {
            "precision": 0.6254,
            "recall": 0.56036,
            "fmeasure": 0.57751
        },
        "nist": 6.328956370686163,
        "bleu": 37.33338,
        "meteor": 0.34345883949158634,
        "bleurt": 0.11622,
        "nubia": {
            "semantic_relation": 3.99717,
            "contradiction": 9.96365,
            "irrelevancy": 32.1438,
            "logical_agreement": 57.89255,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.90517,
            "nubia_score": 0.6472
        },
        "bertscore": {
            "precision": 0.91562,
            "recall": 0.90103,
            "f1": 0.9065
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7908,
        "mean_pred_length": 22.027855153203344,
        "std_pred_length": 9.490608383489896,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 65,
        "distinct-1": 0.3727870510875063,
        "vocab_size-1": 2948,
        "unique-1": 2165,
        "entropy-1": 9.267613072593328,
        "distinct-2": 0.8460723274605908,
        "vocab_size-2": 6387,
        "unique-2": 5919,
        "entropy-2": 12.356298301298754,
        "cond_entropy-2": 2.8542561498352046,
        "distinct-3": 0.9783031988873435,
        "vocab_size-3": 7034,
        "unique-3": 6921,
        "entropy-3": 12.761920875848766,
        "cond_entropy-3": 0.4164883183838953,
        "total_length-nopunct": 7031,
        "mean_pred_length-nopunct": 19.584958217270195,
        "std_pred_length-nopunct": 8.300276663236986,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.41786374626653394,
        "vocab_size-1-nopunct": 2938,
        "unique-1-nopunct": 2164,
        "entropy-1-nopunct": 9.63222029991525,
        "distinct-2-nopunct": 0.8645083932853717,
        "vocab_size-2-nopunct": 5768,
        "unique-2-nopunct": 5397,
        "entropy-2-nopunct": 12.24085468289175,
        "cond_entropy-2-nopunct": 2.7339668896335265,
        "distinct-3-nopunct": 0.9846348804055124,
        "vocab_size-3-nopunct": 6216,
        "unique-3-nopunct": 6138,
        "entropy-3-nopunct": 12.59034502459716,
        "cond_entropy-3-nopunct": 0.37048746695522455,
        "msttr-100": 0.72557,
        "msttr-100_nopunct": 0.77014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03270856302829842,
            "2": 0.1967654986522911,
            "3": 0.44457831325301206,
            "4": 0.6559633027522935,
            "5": 0.787556904400607,
            "6": 0.8873239436619719,
            "7": 0.9371584699453552,
            "8": 0.9746682750301568,
            "9": 0.9746031746031746,
            "10": 0.9914728682170543
        },
        "rouge1": {
            "precision": 0.9154,
            "recall": 0.93108,
            "fmeasure": 0.91973
        },
        "rouge2": {
            "precision": 0.833,
            "recall": 0.85502,
            "fmeasure": 0.83944
        },
        "rougeL": {
            "precision": 0.90244,
            "recall": 0.92191,
            "fmeasure": 0.90847
        },
        "rougeLsum": {
            "precision": 0.90244,
            "recall": 0.92191,
            "fmeasure": 0.90847
        },
        "nist": 13.981447987231807,
        "bleu": 92.40348,
        "meteor": 0.5796075519083013,
        "bleurt": 0.36848,
        "nubia": {
            "semantic_relation": 4.44981,
            "contradiction": 1.88822,
            "irrelevancy": 32.77875,
            "logical_agreement": 65.33302,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.30296,
            "nubia_score": 0.79041
        },
        "bertscore": {
            "precision": 0.98009,
            "recall": 0.98402,
            "f1": 0.98029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.0,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.8125,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.028107102122342922,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.7068905956085185,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.029992126993435272,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.60526,
            "recall": 0.59381,
            "fmeasure": 0.59684
        },
        "rouge2": {
            "precision": 0.40067,
            "recall": 0.38462,
            "fmeasure": 0.39084
        },
        "rougeL": {
            "precision": 0.55482,
            "recall": 0.54609,
            "fmeasure": 0.54784
        },
        "rougeLsum": {
            "precision": 0.55482,
            "recall": 0.54609,
            "fmeasure": 0.54784
        },
        "nist": 3.1413857521692776,
        "bleu": 30.64041,
        "meteor": 0.282776370819446,
        "bleurt": 0.07551,
        "nubia": {
            "semantic_relation": 4.01934,
            "contradiction": 0.20675,
            "irrelevancy": 50.06506,
            "logical_agreement": 49.7282,
            "grammar_ref": 4.99819,
            "grammar_hyp": 5.15192,
            "nubia_score": 0.6807
        },
        "bertscore": {
            "precision": 0.85243,
            "recall": 0.86464,
            "f1": 0.85827
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.0,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.6785714285714286,
        "vocab_size-1": 19,
        "unique-1": 11,
        "entropy-1": 4.137537511266052,
        "distinct-2": 0.8461538461538461,
        "vocab_size-2": 22,
        "unique-2": 18,
        "entropy-2": 4.392747410448783,
        "cond_entropy-2": 0.22981123847439044,
        "distinct-3": 0.875,
        "vocab_size-3": 21,
        "unique-3": 18,
        "entropy-3": 4.334962500721156,
        "cond_entropy-3": -0.03214388408660255,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.056020968057881,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.251629167387823,
        "cond_entropy-2-nopunct": 0.2493097618368753,
        "distinct-3-nopunct": 0.8636363636363636,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.186704345910023,
        "cond_entropy-3-nopunct": -0.03462179117476821,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.2727272727272727
        },
        "rouge1": {
            "precision": 0.44848,
            "recall": 0.2386,
            "fmeasure": 0.31111
        },
        "rouge2": {
            "precision": 0.19286,
            "recall": 0.09674,
            "fmeasure": 0.12874
        },
        "rougeL": {
            "precision": 0.3697,
            "recall": 0.19561,
            "fmeasure": 0.25556
        },
        "rougeLsum": {
            "precision": 0.3697,
            "recall": 0.19561,
            "fmeasure": 0.25556
        },
        "nist": 0.2827796236705406,
        "bleu": 5.86257,
        "meteor": 0.12472059425449415,
        "bleurt": -0.714,
        "nubia": {
            "semantic_relation": 2.66617,
            "contradiction": 29.06576,
            "irrelevancy": 66.71459,
            "logical_agreement": 4.21966,
            "grammar_ref": 3.96887,
            "grammar_hyp": 4.36808,
            "nubia_score": 0.19967
        },
        "bertscore": {
            "precision": 0.8199,
            "recall": 0.72919,
            "f1": 0.77141
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "t5-small/totto_test",
        "N": 43,
        "total_length": 671,
        "mean_pred_length": 15.604651162790697,
        "std_pred_length": 4.0470462090081805,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5216095380029806,
        "vocab_size-1": 350,
        "unique-1": 281,
        "entropy-1": 7.377335077180702,
        "distinct-2": 0.8869426751592356,
        "vocab_size-2": 557,
        "unique-2": 514,
        "entropy-2": 9.004967533546216,
        "cond_entropy-2": 1.4000100615700932,
        "distinct-3": 0.976068376068376,
        "vocab_size-3": 571,
        "unique-3": 557,
        "entropy-3": 9.14442956660747,
        "cond_entropy-3": 0.14607763264965948,
        "total_length-nopunct": 596,
        "mean_pred_length-nopunct": 13.86046511627907,
        "std_pred_length-nopunct": 4.106610639743868,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5788590604026845,
        "vocab_size-1-nopunct": 345,
        "unique-1-nopunct": 280,
        "entropy-1-nopunct": 7.543236480380919,
        "distinct-2-nopunct": 0.8860759493670886,
        "vocab_size-2-nopunct": 490,
        "unique-2-nopunct": 455,
        "entropy-2-nopunct": 8.811131657147897,
        "cond_entropy-2-nopunct": 1.345858196073902,
        "distinct-3-nopunct": 0.9803921568627451,
        "vocab_size-3-nopunct": 500,
        "unique-3-nopunct": 490,
        "entropy-3-nopunct": 8.955137750584237,
        "cond_entropy-3-nopunct": 0.1524672896364131,
        "msttr-100": 0.70167,
        "msttr-100_nopunct": 0.746,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24806201550387597,
            "2": 0.5603448275862069,
            "3": 0.7620087336244541
        },
        "rouge1": {
            "precision": 0.79428,
            "recall": 0.73736,
            "fmeasure": 0.7535
        },
        "rouge2": {
            "precision": 0.54891,
            "recall": 0.50841,
            "fmeasure": 0.51944
        },
        "rougeL": {
            "precision": 0.68901,
            "recall": 0.63656,
            "fmeasure": 0.65253
        },
        "rougeLsum": {
            "precision": 0.68901,
            "recall": 0.63656,
            "fmeasure": 0.65253
        },
        "nist": 6.796423667486157,
        "bleu": 42.52847,
        "meteor": 0.39434159692996923,
        "bleurt": 0.30572,
        "nubia": {
            "semantic_relation": 4.27845,
            "contradiction": 6.62551,
            "irrelevancy": 27.52339,
            "logical_agreement": 65.8511,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.71504,
            "nubia_score": 0.73889
        },
        "bertscore": {
            "precision": 0.93406,
            "recall": 0.92367,
            "f1": 0.92731
        }
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "t5-small/totto_test",
        "N": 79,
        "total_length": 1186,
        "mean_pred_length": 15.012658227848101,
        "std_pred_length": 3.619544942676159,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.45952782462057334,
        "vocab_size-1": 545,
        "unique-1": 421,
        "entropy-1": 7.799614020713012,
        "distinct-2": 0.8310749774164409,
        "vocab_size-2": 920,
        "unique-2": 839,
        "entropy-2": 9.633170584269985,
        "cond_entropy-2": 1.633822888685944,
        "distinct-3": 0.943579766536965,
        "vocab_size-3": 970,
        "unique-3": 936,
        "entropy-3": 9.86999888965834,
        "cond_entropy-3": 0.2486058903846155,
        "total_length-nopunct": 1036,
        "mean_pred_length-nopunct": 13.113924050632912,
        "std_pred_length-nopunct": 3.456739305638058,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5193050193050193,
        "vocab_size-1-nopunct": 538,
        "unique-1-nopunct": 421,
        "entropy-1-nopunct": 8.06378257473178,
        "distinct-2-nopunct": 0.8401253918495298,
        "vocab_size-2-nopunct": 804,
        "unique-2-nopunct": 747,
        "entropy-2-nopunct": 9.427953617926812,
        "cond_entropy-2-nopunct": 1.44356999338616,
        "distinct-3-nopunct": 0.9510250569476082,
        "vocab_size-3-nopunct": 835,
        "unique-3-nopunct": 810,
        "entropy-3-nopunct": 9.65916639150132,
        "cond_entropy-3-nopunct": 0.25872686256467076,
        "msttr-100": 0.70909,
        "msttr-100_nopunct": 0.768,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1590909090909091,
            "2": 0.36893203883495146,
            "3": 0.7475728155339806
        },
        "rouge1": {
            "precision": 0.83062,
            "recall": 0.73792,
            "fmeasure": 0.7734
        },
        "rouge2": {
            "precision": 0.60422,
            "recall": 0.53683,
            "fmeasure": 0.56219
        },
        "rougeL": {
            "precision": 0.69786,
            "recall": 0.62011,
            "fmeasure": 0.64992
        },
        "rougeLsum": {
            "precision": 0.69786,
            "recall": 0.62011,
            "fmeasure": 0.64992
        },
        "nist": 6.915309337014412,
        "bleu": 43.8356,
        "meteor": 0.3831955681239604,
        "bleurt": 0.34696,
        "nubia": {
            "semantic_relation": 4.30068,
            "contradiction": 9.82814,
            "irrelevancy": 22.13933,
            "logical_agreement": 68.03253,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.97707,
            "nubia_score": 0.72191
        },
        "bertscore": {
            "precision": 0.94218,
            "recall": 0.92685,
            "f1": 0.93368
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666
        },
        "rouge1": {
            "precision": 0.2,
            "recall": 0.13333,
            "fmeasure": 0.16
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.07143,
            "fmeasure": 0.08696
        },
        "rougeL": {
            "precision": 0.2,
            "recall": 0.13333,
            "fmeasure": 0.16
        },
        "rougeLsum": {
            "precision": 0.2,
            "recall": 0.13333,
            "fmeasure": 0.16
        },
        "nist": 0.4728176046727473,
        "bleu": 5.0971,
        "meteor": 0.08747263697277605,
        "bleurt": -0.67698,
        "nubia": {
            "semantic_relation": 2.01785,
            "contradiction": 1.77885,
            "irrelevancy": 90.6883,
            "logical_agreement": 7.53285,
            "grammar_ref": 5.48676,
            "grammar_hyp": 5.07538,
            "nubia_score": 0.14205
        },
        "bertscore": {
            "precision": 0.74579,
            "recall": 0.6847,
            "f1": 0.71394
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "t5-small/totto_test",
        "N": 25,
        "total_length": 390,
        "mean_pred_length": 15.6,
        "std_pred_length": 4.857983120596447,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5948717948717949,
        "vocab_size-1": 232,
        "unique-1": 188,
        "entropy-1": 7.2059160482648075,
        "distinct-2": 0.9232876712328767,
        "vocab_size-2": 337,
        "unique-2": 316,
        "entropy-2": 8.341164537311252,
        "cond_entropy-2": 0.962150984485557,
        "distinct-3": 0.9823529411764705,
        "vocab_size-3": 334,
        "unique-3": 328,
        "entropy-3": 8.37409681849062,
        "cond_entropy-3": 0.0395931720952943,
        "total_length-nopunct": 347,
        "mean_pred_length-nopunct": 13.88,
        "std_pred_length-nopunct": 4.29250509609482,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6512968299711815,
        "vocab_size-1-nopunct": 226,
        "unique-1-nopunct": 187,
        "entropy-1-nopunct": 7.301335350213506,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 299,
        "unique-2-nopunct": 283,
        "entropy-2-nopunct": 8.168604261634874,
        "cond_entropy-2-nopunct": 0.9106455559532902,
        "distinct-3-nopunct": 0.9865319865319865,
        "vocab_size-3-nopunct": 293,
        "unique-3-nopunct": 289,
        "entropy-3-nopunct": 8.187383093864767,
        "cond_entropy-3-nopunct": 0.02176836223176546,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2608695652173913,
            "2": 0.4057971014492754,
            "3": 0.7420494699646644
        },
        "rouge1": {
            "precision": 0.74991,
            "recall": 0.69401,
            "fmeasure": 0.71131
        },
        "rouge2": {
            "precision": 0.51604,
            "recall": 0.48482,
            "fmeasure": 0.49269
        },
        "rougeL": {
            "precision": 0.6397,
            "recall": 0.60172,
            "fmeasure": 0.61164
        },
        "rougeLsum": {
            "precision": 0.6397,
            "recall": 0.60172,
            "fmeasure": 0.61164
        },
        "nist": 6.1370106558749,
        "bleu": 40.29836,
        "meteor": 0.37139821582222754,
        "bleurt": 0.08289,
        "nubia": {
            "semantic_relation": 3.87204,
            "contradiction": 17.91082,
            "irrelevancy": 27.12355,
            "logical_agreement": 54.96564,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.91254,
            "nubia_score": 0.63866
        },
        "bertscore": {
            "precision": 0.91848,
            "recall": 0.906,
            "f1": 0.91088
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7908,
        "mean_pred_length": 22.027855153203344,
        "std_pred_length": 9.490608383489896,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 65,
        "distinct-1": 0.3727870510875063,
        "vocab_size-1": 2948,
        "unique-1": 2165,
        "entropy-1": 9.267613072593328,
        "distinct-2": 0.8460723274605908,
        "vocab_size-2": 6387,
        "unique-2": 5919,
        "entropy-2": 12.356298301298754,
        "cond_entropy-2": 2.8542561498352046,
        "distinct-3": 0.9783031988873435,
        "vocab_size-3": 7034,
        "unique-3": 6921,
        "entropy-3": 12.761920875848766,
        "cond_entropy-3": 0.4164883183838953,
        "total_length-nopunct": 7031,
        "mean_pred_length-nopunct": 19.584958217270195,
        "std_pred_length-nopunct": 8.300276663236986,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.41786374626653394,
        "vocab_size-1-nopunct": 2938,
        "unique-1-nopunct": 2164,
        "entropy-1-nopunct": 9.63222029991525,
        "distinct-2-nopunct": 0.8645083932853717,
        "vocab_size-2-nopunct": 5768,
        "unique-2-nopunct": 5397,
        "entropy-2-nopunct": 12.24085468289175,
        "cond_entropy-2-nopunct": 2.7339668896335265,
        "distinct-3-nopunct": 0.9846348804055124,
        "vocab_size-3-nopunct": 6216,
        "unique-3-nopunct": 6138,
        "entropy-3-nopunct": 12.59034502459716,
        "cond_entropy-3-nopunct": 0.37048746695522455,
        "msttr-100": 0.72557,
        "msttr-100_nopunct": 0.77014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03270856302829842,
            "2": 0.1967654986522911,
            "3": 0.44457831325301206,
            "4": 0.6559633027522935,
            "5": 0.787556904400607,
            "6": 0.8873239436619719,
            "7": 0.9371584699453552,
            "8": 0.9746682750301568,
            "9": 0.9746031746031746,
            "10": 0.9914728682170543
        },
        "rouge1": {
            "precision": 0.9154,
            "recall": 0.93108,
            "fmeasure": 0.91973
        },
        "rouge2": {
            "precision": 0.833,
            "recall": 0.85502,
            "fmeasure": 0.83944
        },
        "rougeL": {
            "precision": 0.90244,
            "recall": 0.92191,
            "fmeasure": 0.90847
        },
        "rougeLsum": {
            "precision": 0.90244,
            "recall": 0.92191,
            "fmeasure": 0.90847
        },
        "nist": 13.981447987231807,
        "bleu": 92.40348,
        "meteor": 0.5796075519083013,
        "bleurt": 0.36848,
        "nubia": {
            "semantic_relation": 4.44981,
            "contradiction": 1.88822,
            "irrelevancy": 32.77875,
            "logical_agreement": 65.33302,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.30296,
            "nubia_score": 0.79041
        },
        "bertscore": {
            "precision": 0.98009,
            "recall": 0.98402,
            "f1": 0.98029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "t5-small/totto_test",
        "N": 11,
        "total_length": 149,
        "mean_pred_length": 13.545454545454545,
        "std_pred_length": 4.163993632945013,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.7046979865771812,
        "vocab_size-1": 105,
        "unique-1": 92,
        "entropy-1": 6.30746249531565,
        "distinct-2": 0.9710144927536232,
        "vocab_size-2": 134,
        "unique-2": 132,
        "entropy-2": 7.036060688662225,
        "cond_entropy-2": 0.525518617053839,
        "distinct-3": 1.0,
        "vocab_size-3": 127,
        "unique-3": 127,
        "entropy-3": 6.988684686772147,
        "cond_entropy-3": -0.04109961252568839,
        "total_length-nopunct": 132,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.765875486765087,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7803030303030303,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.421055672862279,
        "distinct-2-nopunct": 0.9669421487603306,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 115,
        "entropy-2-nopunct": 6.836218609175429,
        "cond_entropy-2-nopunct": 0.47183006781278636,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 110,
        "unique-3-nopunct": 110,
        "entropy-3-nopunct": 6.781359713524669,
        "cond_entropy-3-nopunct": -0.046594432840843886,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19444444444444445,
            "2": 0.22727272727272727,
            "3": 0.7301587301587301
        },
        "rouge1": {
            "precision": 0.84971,
            "recall": 0.71313,
            "fmeasure": 0.76588
        },
        "rouge2": {
            "precision": 0.62121,
            "recall": 0.53617,
            "fmeasure": 0.56881
        },
        "rougeL": {
            "precision": 0.73725,
            "recall": 0.6275,
            "fmeasure": 0.67005
        },
        "rougeLsum": {
            "precision": 0.73725,
            "recall": 0.6275,
            "fmeasure": 0.67005
        },
        "nist": 5.039445632606079,
        "bleu": 46.28666,
        "meteor": 0.4116125841522156,
        "bleurt": 0.21553,
        "nubia": {
            "semantic_relation": 4.10854,
            "contradiction": 10.33607,
            "irrelevancy": 27.215,
            "logical_agreement": 62.44893,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.68471,
            "nubia_score": 0.67377
        },
        "bertscore": {
            "precision": 0.93881,
            "recall": 0.92138,
            "f1": 0.92935
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "t5-small/totto_test",
        "N": 71,
        "total_length": 904,
        "mean_pred_length": 12.732394366197184,
        "std_pred_length": 3.516391181746828,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.4303097345132743,
        "vocab_size-1": 389,
        "unique-1": 307,
        "entropy-1": 7.145218755754165,
        "distinct-2": 0.7851140456182473,
        "vocab_size-2": 654,
        "unique-2": 579,
        "entropy-2": 9.05536459498637,
        "cond_entropy-2": 1.6652917659003632,
        "distinct-3": 0.9028871391076115,
        "vocab_size-3": 688,
        "unique-3": 644,
        "entropy-3": 9.331973988125238,
        "cond_entropy-3": 0.28168764328580415,
        "total_length-nopunct": 813,
        "mean_pred_length-nopunct": 11.450704225352112,
        "std_pred_length-nopunct": 3.1299945209616187,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.4735547355473555,
        "vocab_size-1-nopunct": 385,
        "unique-1-nopunct": 307,
        "entropy-1-nopunct": 7.27942911578767,
        "distinct-2-nopunct": 0.7911051212938005,
        "vocab_size-2-nopunct": 587,
        "unique-2-nopunct": 519,
        "entropy-2-nopunct": 8.913674815331708,
        "cond_entropy-2-nopunct": 1.7923343511073517,
        "distinct-3-nopunct": 0.9001490312965723,
        "vocab_size-3-nopunct": 604,
        "unique-3-nopunct": 564,
        "entropy-3-nopunct": 9.140690430989752,
        "cond_entropy-3-nopunct": 0.2868272994903382,
        "msttr-100": 0.64444,
        "msttr-100_nopunct": 0.6775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3016759776536313,
            "2": 0.6263157894736842,
            "3": 0.8072289156626506
        },
        "rouge1": {
            "precision": 0.71701,
            "recall": 0.77891,
            "fmeasure": 0.7305
        },
        "rouge2": {
            "precision": 0.52771,
            "recall": 0.58644,
            "fmeasure": 0.54277
        },
        "rougeL": {
            "precision": 0.68565,
            "recall": 0.75093,
            "fmeasure": 0.70124
        },
        "rougeLsum": {
            "precision": 0.68565,
            "recall": 0.75093,
            "fmeasure": 0.70124
        },
        "nist": 6.737099090104487,
        "bleu": 49.23958,
        "meteor": 0.41675472137706465,
        "bleurt": 0.37383,
        "nubia": {
            "semantic_relation": 4.12715,
            "contradiction": 10.85869,
            "irrelevancy": 52.11088,
            "logical_agreement": 37.03043,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.10283,
            "nubia_score": 0.69809
        },
        "bertscore": {
            "precision": 0.93211,
            "recall": 0.94711,
            "f1": 0.93783
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "t5-small/totto_test",
        "N": 62,
        "total_length": 979,
        "mean_pred_length": 15.790322580645162,
        "std_pred_length": 4.381548911479097,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.48008171603677224,
        "vocab_size-1": 470,
        "unique-1": 355,
        "entropy-1": 7.83410863195827,
        "distinct-2": 0.8320610687022901,
        "vocab_size-2": 763,
        "unique-2": 683,
        "entropy-2": 9.403102547644522,
        "cond_entropy-2": 1.3765410306871813,
        "distinct-3": 0.92046783625731,
        "vocab_size-3": 787,
        "unique-3": 749,
        "entropy-3": 9.546827630841403,
        "cond_entropy-3": 0.14038536255542777,
        "total_length-nopunct": 853,
        "mean_pred_length-nopunct": 13.758064516129032,
        "std_pred_length-nopunct": 3.879996191679906,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5392731535756154,
        "vocab_size-1-nopunct": 460,
        "unique-1-nopunct": 351,
        "entropy-1-nopunct": 8.03486106282809,
        "distinct-2-nopunct": 0.843236409608091,
        "vocab_size-2-nopunct": 667,
        "unique-2-nopunct": 606,
        "entropy-2-nopunct": 9.21139291066842,
        "cond_entropy-2-nopunct": 1.2330195250276665,
        "distinct-3-nopunct": 0.9327846364883402,
        "vocab_size-3-nopunct": 680,
        "unique-3-nopunct": 652,
        "entropy-3-nopunct": 9.350236235432819,
        "cond_entropy-3-nopunct": 0.1327586792510732,
        "msttr-100": 0.72889,
        "msttr-100_nopunct": 0.7775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16279069767441862,
            "2": 0.3446327683615819,
            "3": 0.7580174927113703
        },
        "rouge1": {
            "precision": 0.75217,
            "recall": 0.72118,
            "fmeasure": 0.72695
        },
        "rouge2": {
            "precision": 0.54173,
            "recall": 0.51616,
            "fmeasure": 0.52146
        },
        "rougeL": {
            "precision": 0.66249,
            "recall": 0.63563,
            "fmeasure": 0.64068
        },
        "rougeLsum": {
            "precision": 0.66249,
            "recall": 0.63563,
            "fmeasure": 0.64068
        },
        "nist": 6.661543811270436,
        "bleu": 43.70315,
        "meteor": 0.37897053500158123,
        "bleurt": 0.23841,
        "nubia": {
            "semantic_relation": 4.19413,
            "contradiction": 10.74427,
            "irrelevancy": 32.49661,
            "logical_agreement": 56.75912,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.49375,
            "nubia_score": 0.72825
        },
        "bertscore": {
            "precision": 0.92485,
            "recall": 0.92027,
            "f1": 0.92093
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "t5-small/totto_test",
        "N": 77,
        "total_length": 1224,
        "mean_pred_length": 15.896103896103897,
        "std_pred_length": 4.456381432252527,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.49019607843137253,
        "vocab_size-1": 600,
        "unique-1": 477,
        "entropy-1": 7.974153824678956,
        "distinct-2": 0.8587619877942458,
        "vocab_size-2": 985,
        "unique-2": 900,
        "entropy-2": 9.770312687278016,
        "cond_entropy-2": 1.5865703982821513,
        "distinct-3": 0.9364485981308411,
        "vocab_size-3": 1002,
        "unique-3": 959,
        "entropy-3": 9.909119695814669,
        "cond_entropy-3": 0.14300108938825862,
        "total_length-nopunct": 1083,
        "mean_pred_length-nopunct": 14.064935064935066,
        "std_pred_length-nopunct": 4.307461548961689,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.543859649122807,
        "vocab_size-1-nopunct": 589,
        "unique-1-nopunct": 472,
        "entropy-1-nopunct": 8.1545110516248,
        "distinct-2-nopunct": 0.8618290258449304,
        "vocab_size-2-nopunct": 867,
        "unique-2-nopunct": 796,
        "entropy-2-nopunct": 9.582768201511863,
        "cond_entropy-2-nopunct": 1.5052877463815382,
        "distinct-3-nopunct": 0.9418729817007535,
        "vocab_size-3-nopunct": 875,
        "unique-3-nopunct": 839,
        "entropy-3-nopunct": 9.72184543977543,
        "cond_entropy-3-nopunct": 0.15304566505906614,
        "msttr-100": 0.72833,
        "msttr-100_nopunct": 0.766,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26848249027237353,
            "2": 0.437984496124031,
            "3": 0.7477243172951885
        },
        "rouge1": {
            "precision": 0.74058,
            "recall": 0.69771,
            "fmeasure": 0.70865
        },
        "rouge2": {
            "precision": 0.50279,
            "recall": 0.47218,
            "fmeasure": 0.47997
        },
        "rougeL": {
            "precision": 0.64192,
            "recall": 0.61029,
            "fmeasure": 0.61653
        },
        "rougeLsum": {
            "precision": 0.64192,
            "recall": 0.61029,
            "fmeasure": 0.61653
        },
        "nist": 7.068726887514748,
        "bleu": 44.45911,
        "meteor": 0.372529598254422,
        "bleurt": 0.15968,
        "nubia": {
            "semantic_relation": 4.03666,
            "contradiction": 12.212,
            "irrelevancy": 30.0277,
            "logical_agreement": 57.7603,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.83538,
            "nubia_score": 0.65872
        },
        "bertscore": {
            "precision": 0.92197,
            "recall": 0.91625,
            "f1": 0.91778
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.46153846153846156
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.53846,
            "fmeasure": 0.63636
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.41667,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.53846,
            "fmeasure": 0.63636
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.53846,
            "fmeasure": 0.63636
        },
        "nist": 0.7704668715773526,
        "bleu": 16.94794,
        "meteor": 0.3166560302188066,
        "bleurt": 0.03192,
        "nubia": {
            "semantic_relation": 3.72162,
            "contradiction": 1.81455,
            "irrelevancy": 0.97072,
            "logical_agreement": 97.21473,
            "grammar_ref": 3.82301,
            "grammar_hyp": 4.26942,
            "nubia_score": 0.61151
        },
        "bertscore": {
            "precision": 0.96744,
            "recall": 0.85957,
            "f1": 0.91032
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.807763576417195,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.20971762763487742,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.589898095464287,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.24009914803219054,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.68333,
            "fmeasure": 0.5763
        },
        "rouge2": {
            "precision": 0.17857,
            "recall": 0.24747,
            "fmeasure": 0.20696
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.36667,
            "fmeasure": 0.30815
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.36667,
            "fmeasure": 0.30815
        },
        "nist": 2.285272059247739,
        "bleu": 18.00283,
        "meteor": 0.36112155354185915,
        "bleurt": -0.00894,
        "nubia": {
            "semantic_relation": 4.23605,
            "contradiction": 2.25645,
            "irrelevancy": 47.38289,
            "logical_agreement": 50.36065,
            "grammar_ref": 5.93899,
            "grammar_hyp": 4.83344,
            "nubia_score": 0.72626
        },
        "bertscore": {
            "precision": 0.85115,
            "recall": 0.88093,
            "f1": 0.86102
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 108,
        "mean_pred_length": 15.428571428571429,
        "std_pred_length": 6.758214955722783,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.6111111111111112,
        "vocab_size-1": 66,
        "unique-1": 49,
        "entropy-1": 5.629350674603176,
        "distinct-2": 0.8811881188118812,
        "vocab_size-2": 89,
        "unique-2": 80,
        "entropy-2": 6.384848705777158,
        "cond_entropy-2": 0.6955692116056538,
        "distinct-3": 0.9361702127659575,
        "vocab_size-3": 88,
        "unique-3": 82,
        "entropy-3": 6.426929277209538,
        "cond_entropy-3": 0.06243737397304287,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 13.714285714285714,
        "std_pred_length-nopunct": 5.993193418115152,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.65625,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.58143441293327,
        "distinct-2-nopunct": 0.8764044943820225,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.187984661590714,
        "cond_entropy-2-nopunct": 0.6854794241014273,
        "distinct-3-nopunct": 0.9390243902439024,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.235600785105892,
        "cond_entropy-3-nopunct": 0.0721800428521348,
        "msttr-100": 0.62,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5294117647058824,
            "2": 0.3103448275862069,
            "3": 0.6610169491525424
        },
        "rouge1": {
            "precision": 0.66659,
            "recall": 0.65945,
            "fmeasure": 0.63683
        },
        "rouge2": {
            "precision": 0.42926,
            "recall": 0.42885,
            "fmeasure": 0.41042
        },
        "rougeL": {
            "precision": 0.56861,
            "recall": 0.5793,
            "fmeasure": 0.55219
        },
        "rougeLsum": {
            "precision": 0.56861,
            "recall": 0.5793,
            "fmeasure": 0.55219
        },
        "nist": 4.257614934198727,
        "bleu": 30.47132,
        "meteor": 0.3072352381209719,
        "bleurt": 0.1622,
        "nubia": {
            "semantic_relation": 3.93954,
            "contradiction": 8.3524,
            "irrelevancy": 48.24882,
            "logical_agreement": 43.39878,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.38335,
            "nubia_score": 0.6497
        },
        "bertscore": {
            "precision": 0.90559,
            "recall": 0.90343,
            "f1": 0.90373
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 7.874007874011811,
        "median_pred_length": 9.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 30,
        "unique-1": 22,
        "entropy-1": 4.804507667524723,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 34,
        "unique-2": 32,
        "entropy-2": 5.058813890331199,
        "cond_entropy-2": 0.238825213195716,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 32,
        "unique-3": 31,
        "entropy-3": 4.9837880587523955,
        "cond_entropy-3": -0.06492482147779848,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 7.408703590297622,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.707714802597437,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.875,
        "cond_entropy-2-nopunct": 0.175557217497642,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.789015477886192,
        "cond_entropy-3-nopunct": -0.07305348763104855,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.18181818181818182,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.74457,
            "recall": 0.63122,
            "fmeasure": 0.67799
        },
        "rouge2": {
            "precision": 0.46378,
            "recall": 0.40653,
            "fmeasure": 0.4296
        },
        "rougeL": {
            "precision": 0.71558,
            "recall": 0.60741,
            "fmeasure": 0.65185
        },
        "rougeLsum": {
            "precision": 0.71558,
            "recall": 0.60741,
            "fmeasure": 0.65185
        },
        "nist": 2.1400097796781776,
        "bleu": 21.42443,
        "meteor": 0.30947426855558224,
        "bleurt": 0.17846,
        "nubia": {
            "semantic_relation": 3.66559,
            "contradiction": 35.23227,
            "irrelevancy": 28.43868,
            "logical_agreement": 36.32905,
            "grammar_ref": 5.04645,
            "grammar_hyp": 5.35657,
            "nubia_score": 0.50496
        },
        "bertscore": {
            "precision": 0.93095,
            "recall": 0.91586,
            "f1": 0.92319
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "t5-small/totto_test",
        "N": 105,
        "total_length": 1609,
        "mean_pred_length": 15.323809523809524,
        "std_pred_length": 4.799792134577016,
        "median_pred_length": 16.0,
        "min_pred_length": 4,
        "max_pred_length": 27,
        "distinct-1": 0.4126786824114357,
        "vocab_size-1": 664,
        "unique-1": 517,
        "entropy-1": 7.893173301903802,
        "distinct-2": 0.7646276595744681,
        "vocab_size-2": 1150,
        "unique-2": 1008,
        "entropy-2": 9.87291738098134,
        "cond_entropy-2": 1.7676712019718184,
        "distinct-3": 0.8777698355968548,
        "vocab_size-3": 1228,
        "unique-3": 1136,
        "entropy-3": 10.147919797961029,
        "cond_entropy-3": 0.29207427478672976,
        "total_length-nopunct": 1390,
        "mean_pred_length-nopunct": 13.238095238095237,
        "std_pred_length-nopunct": 4.428315404785779,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4712230215827338,
        "vocab_size-1-nopunct": 655,
        "unique-1-nopunct": 514,
        "entropy-1-nopunct": 8.133770221093979,
        "distinct-2-nopunct": 0.7813229571984436,
        "vocab_size-2-nopunct": 1004,
        "unique-2-nopunct": 890,
        "entropy-2-nopunct": 9.692421735879487,
        "cond_entropy-2-nopunct": 1.676442098438973,
        "distinct-3-nopunct": 0.8923728813559322,
        "vocab_size-3-nopunct": 1053,
        "unique-3-nopunct": 984,
        "entropy-3-nopunct": 9.940106414658795,
        "cond_entropy-3-nopunct": 0.2718717641436527,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.73231,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2947976878612717,
            "2": 0.4086687306501548,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.61766,
            "recall": 0.61436,
            "fmeasure": 0.59866
        },
        "rouge2": {
            "precision": 0.39582,
            "recall": 0.38994,
            "fmeasure": 0.38311
        },
        "rougeL": {
            "precision": 0.52575,
            "recall": 0.52658,
            "fmeasure": 0.51057
        },
        "rougeLsum": {
            "precision": 0.52575,
            "recall": 0.52658,
            "fmeasure": 0.51057
        },
        "nist": 6.306956316030043,
        "bleu": 36.5613,
        "meteor": 0.3312540902565679,
        "bleurt": 0.01398,
        "nubia": {
            "semantic_relation": 3.51373,
            "contradiction": 13.61145,
            "irrelevancy": 40.70596,
            "logical_agreement": 45.68259,
            "grammar_ref": 4.94529,
            "grammar_hyp": 4.74284,
            "nubia_score": 0.57313
        },
        "bertscore": {
            "precision": 0.88553,
            "recall": 0.89187,
            "f1": 0.88721
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "t5-small/totto_test",
        "N": 23,
        "total_length": 364,
        "mean_pred_length": 15.826086956521738,
        "std_pred_length": 4.0287248377775216,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.5796703296703297,
        "vocab_size-1": 211,
        "unique-1": 169,
        "entropy-1": 7.033460898526952,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 310,
        "unique-2": 284,
        "entropy-2": 8.217865795586754,
        "cond_entropy-2": 0.9944548903046925,
        "distinct-3": 0.9779874213836478,
        "vocab_size-3": 311,
        "unique-3": 304,
        "entropy-3": 8.268857798051664,
        "cond_entropy-3": 0.052572282556294606,
        "total_length-nopunct": 321,
        "mean_pred_length-nopunct": 13.956521739130435,
        "std_pred_length-nopunct": 4.005195114061402,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6417445482866043,
        "vocab_size-1-nopunct": 206,
        "unique-1-nopunct": 168,
        "entropy-1-nopunct": 7.139775433658207,
        "distinct-2-nopunct": 0.9060402684563759,
        "vocab_size-2-nopunct": 270,
        "unique-2-nopunct": 247,
        "entropy-2-nopunct": 8.01529305904548,
        "cond_entropy-2-nopunct": 0.8836863063314352,
        "distinct-3-nopunct": 0.9818181818181818,
        "vocab_size-3-nopunct": 270,
        "unique-3-nopunct": 265,
        "entropy-3-nopunct": 8.06692417204839,
        "cond_entropy-3-nopunct": 0.050500697048636564,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.78667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24675324675324675,
            "2": 0.4782608695652174,
            "3": 0.793859649122807
        },
        "rouge1": {
            "precision": 0.77006,
            "recall": 0.71399,
            "fmeasure": 0.732
        },
        "rouge2": {
            "precision": 0.55277,
            "recall": 0.51894,
            "fmeasure": 0.52953
        },
        "rougeL": {
            "precision": 0.66781,
            "recall": 0.61528,
            "fmeasure": 0.63255
        },
        "rougeLsum": {
            "precision": 0.66781,
            "recall": 0.61528,
            "fmeasure": 0.63255
        },
        "nist": 6.297553587983478,
        "bleu": 46.4266,
        "meteor": 0.4052746485116606,
        "bleurt": 0.17717,
        "nubia": {
            "semantic_relation": 4.27323,
            "contradiction": 3.8793,
            "irrelevancy": 30.56669,
            "logical_agreement": 65.55401,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.82532,
            "nubia_score": 0.75345
        },
        "bertscore": {
            "precision": 0.92743,
            "recall": 0.92399,
            "f1": 0.92435
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7908,
        "mean_pred_length": 22.027855153203344,
        "std_pred_length": 9.490608383489896,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 65,
        "distinct-1": 0.3727870510875063,
        "vocab_size-1": 2948,
        "unique-1": 2165,
        "entropy-1": 9.267613072593328,
        "distinct-2": 0.8460723274605908,
        "vocab_size-2": 6387,
        "unique-2": 5919,
        "entropy-2": 12.356298301298754,
        "cond_entropy-2": 2.8542561498352046,
        "distinct-3": 0.9783031988873435,
        "vocab_size-3": 7034,
        "unique-3": 6921,
        "entropy-3": 12.761920875848766,
        "cond_entropy-3": 0.4164883183838953,
        "total_length-nopunct": 7031,
        "mean_pred_length-nopunct": 19.584958217270195,
        "std_pred_length-nopunct": 8.300276663236986,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.41786374626653394,
        "vocab_size-1-nopunct": 2938,
        "unique-1-nopunct": 2164,
        "entropy-1-nopunct": 9.63222029991525,
        "distinct-2-nopunct": 0.8645083932853717,
        "vocab_size-2-nopunct": 5768,
        "unique-2-nopunct": 5397,
        "entropy-2-nopunct": 12.24085468289175,
        "cond_entropy-2-nopunct": 2.7339668896335265,
        "distinct-3-nopunct": 0.9846348804055124,
        "vocab_size-3-nopunct": 6216,
        "unique-3-nopunct": 6138,
        "entropy-3-nopunct": 12.59034502459716,
        "cond_entropy-3-nopunct": 0.37048746695522455,
        "msttr-100": 0.72557,
        "msttr-100_nopunct": 0.77014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03270856302829842,
            "2": 0.1967654986522911,
            "3": 0.44457831325301206,
            "4": 0.6559633027522935,
            "5": 0.787556904400607,
            "6": 0.8873239436619719,
            "7": 0.9371584699453552,
            "8": 0.9746682750301568,
            "9": 0.9746031746031746,
            "10": 0.9914728682170543
        },
        "rouge1": {
            "precision": 0.9154,
            "recall": 0.93108,
            "fmeasure": 0.91973
        },
        "rouge2": {
            "precision": 0.833,
            "recall": 0.85502,
            "fmeasure": 0.83944
        },
        "rougeL": {
            "precision": 0.90244,
            "recall": 0.92191,
            "fmeasure": 0.90847
        },
        "rougeLsum": {
            "precision": 0.90244,
            "recall": 0.92191,
            "fmeasure": 0.90847
        },
        "nist": 13.981447987231807,
        "bleu": 92.40348,
        "meteor": 0.5796075519083013,
        "bleurt": 0.36848,
        "nubia": {
            "semantic_relation": 4.44981,
            "contradiction": 1.88822,
            "irrelevancy": 32.77875,
            "logical_agreement": 65.33302,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.30296,
            "nubia_score": 0.79041
        },
        "bertscore": {
            "precision": 0.98009,
            "recall": 0.98402,
            "f1": 0.98029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "t5-small/totto_test",
        "N": 23,
        "total_length": 362,
        "mean_pred_length": 15.73913043478261,
        "std_pred_length": 4.172554126612201,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.6049723756906077,
        "vocab_size-1": 219,
        "unique-1": 179,
        "entropy-1": 7.0692135024733105,
        "distinct-2": 0.9351032448377581,
        "vocab_size-2": 317,
        "unique-2": 300,
        "entropy-2": 8.262767827424028,
        "cond_entropy-2": 1.0231061108941344,
        "distinct-3": 0.9841772151898734,
        "vocab_size-3": 311,
        "unique-3": 306,
        "entropy-3": 8.272135178556875,
        "cond_entropy-3": 0.019729989175222378,
        "total_length-nopunct": 312,
        "mean_pred_length-nopunct": 13.565217391304348,
        "std_pred_length-nopunct": 3.8654105688509337,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6762820512820513,
        "vocab_size-1-nopunct": 211,
        "unique-1-nopunct": 175,
        "entropy-1-nopunct": 7.219835526713138,
        "distinct-2-nopunct": 0.9480968858131488,
        "vocab_size-2-nopunct": 274,
        "unique-2-nopunct": 262,
        "entropy-2-nopunct": 8.061586971420509,
        "cond_entropy-2-nopunct": 0.8934406430156616,
        "distinct-3-nopunct": 0.9887218045112782,
        "vocab_size-3-nopunct": 263,
        "unique-3-nopunct": 260,
        "entropy-3-nopunct": 8.032726044523798,
        "cond_entropy-3-nopunct": -0.022820361653009685,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.74667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30952380952380953,
            "2": 0.3493975903614458,
            "3": 0.654320987654321
        },
        "rouge1": {
            "precision": 0.73602,
            "recall": 0.64382,
            "fmeasure": 0.67354
        },
        "rouge2": {
            "precision": 0.47981,
            "recall": 0.41303,
            "fmeasure": 0.43417
        },
        "rougeL": {
            "precision": 0.62056,
            "recall": 0.54224,
            "fmeasure": 0.56762
        },
        "rougeLsum": {
            "precision": 0.62056,
            "recall": 0.54224,
            "fmeasure": 0.56762
        },
        "nist": 5.702347862491709,
        "bleu": 37.97689,
        "meteor": 0.32732094032661935,
        "bleurt": 0.08186,
        "nubia": {
            "semantic_relation": 3.95843,
            "contradiction": 12.84751,
            "irrelevancy": 30.9421,
            "logical_agreement": 56.21039,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.57244,
            "nubia_score": 0.64252
        },
        "bertscore": {
            "precision": 0.91798,
            "recall": 0.8963,
            "f1": 0.90465
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "t5-small/totto_test",
        "N": 51,
        "total_length": 784,
        "mean_pred_length": 15.372549019607844,
        "std_pred_length": 3.7883246041516303,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5471938775510204,
        "vocab_size-1": 429,
        "unique-1": 357,
        "entropy-1": 7.654214416992979,
        "distinct-2": 0.9154160982264665,
        "vocab_size-2": 671,
        "unique-2": 629,
        "entropy-2": 9.299541732677755,
        "cond_entropy-2": 1.4654076604811788,
        "distinct-3": 0.9897360703812317,
        "vocab_size-3": 675,
        "unique-3": 668,
        "entropy-3": 9.3931000697866,
        "cond_entropy-3": 0.09680997909221246,
        "total_length-nopunct": 678,
        "mean_pred_length-nopunct": 13.294117647058824,
        "std_pred_length-nopunct": 3.3507044483040667,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6253687315634219,
        "vocab_size-1-nopunct": 424,
        "unique-1-nopunct": 356,
        "entropy-1-nopunct": 7.917549301004757,
        "distinct-2-nopunct": 0.9218500797448166,
        "vocab_size-2-nopunct": 578,
        "unique-2-nopunct": 548,
        "entropy-2-nopunct": 9.079988803540427,
        "cond_entropy-2-nopunct": 1.2523523369412266,
        "distinct-3-nopunct": 0.9947916666666666,
        "vocab_size-3-nopunct": 573,
        "unique-3-nopunct": 570,
        "entropy-3-nopunct": 9.159508334775708,
        "cond_entropy-3-nopunct": 0.08980092654218366,
        "msttr-100": 0.72571,
        "msttr-100_nopunct": 0.79833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21354166666666666,
            "2": 0.4492753623188406,
            "3": 0.7160940325497287
        },
        "rouge1": {
            "precision": 0.77158,
            "recall": 0.71586,
            "fmeasure": 0.72859
        },
        "rouge2": {
            "precision": 0.53029,
            "recall": 0.49732,
            "fmeasure": 0.50437
        },
        "rougeL": {
            "precision": 0.65856,
            "recall": 0.61701,
            "fmeasure": 0.62568
        },
        "rougeLsum": {
            "precision": 0.65856,
            "recall": 0.61701,
            "fmeasure": 0.62568
        },
        "nist": 6.5528469706605375,
        "bleu": 44.23778,
        "meteor": 0.3656832600794696,
        "bleurt": 0.21461,
        "nubia": {
            "semantic_relation": 4.11346,
            "contradiction": 7.23327,
            "irrelevancy": 34.7639,
            "logical_agreement": 58.00283,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.87519,
            "nubia_score": 0.6696
        },
        "bertscore": {
            "precision": 0.93172,
            "recall": 0.92471,
            "f1": 0.92633
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "t5-small/totto_test",
        "N": 52,
        "total_length": 705,
        "mean_pred_length": 13.557692307692308,
        "std_pred_length": 4.258084896082806,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.4553191489361702,
        "vocab_size-1": 321,
        "unique-1": 262,
        "entropy-1": 7.001989981446855,
        "distinct-2": 0.781010719754977,
        "vocab_size-2": 510,
        "unique-2": 459,
        "entropy-2": 8.661259521359879,
        "cond_entropy-2": 1.4729497301136394,
        "distinct-3": 0.8851913477537438,
        "vocab_size-3": 532,
        "unique-3": 499,
        "entropy-3": 8.92054025419671,
        "cond_entropy-3": 0.28625553795378955,
        "total_length-nopunct": 627,
        "mean_pred_length-nopunct": 12.057692307692308,
        "std_pred_length-nopunct": 3.835128427989289,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5055821371610846,
        "vocab_size-1-nopunct": 317,
        "unique-1-nopunct": 262,
        "entropy-1-nopunct": 7.106469245435025,
        "distinct-2-nopunct": 0.782608695652174,
        "vocab_size-2-nopunct": 450,
        "unique-2-nopunct": 404,
        "entropy-2-nopunct": 8.479682130668822,
        "cond_entropy-2-nopunct": 1.5010292315672606,
        "distinct-3-nopunct": 0.8852772466539197,
        "vocab_size-3-nopunct": 463,
        "unique-3-nopunct": 433,
        "entropy-3-nopunct": 8.724141581985663,
        "cond_entropy-3-nopunct": 0.30024780750739954,
        "msttr-100": 0.62143,
        "msttr-100_nopunct": 0.655,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2894736842105263,
            "2": 0.4486486486486487,
            "3": 0.7866323907455013
        },
        "rouge1": {
            "precision": 0.70919,
            "recall": 0.71846,
            "fmeasure": 0.69493
        },
        "rouge2": {
            "precision": 0.49436,
            "recall": 0.47812,
            "fmeasure": 0.47537
        },
        "rougeL": {
            "precision": 0.6624,
            "recall": 0.66577,
            "fmeasure": 0.64748
        },
        "rougeLsum": {
            "precision": 0.6624,
            "recall": 0.66577,
            "fmeasure": 0.64748
        },
        "nist": 6.591332028399303,
        "bleu": 45.26095,
        "meteor": 0.37940211622876546,
        "bleurt": 0.24178,
        "nubia": {
            "semantic_relation": 3.96296,
            "contradiction": 13.21383,
            "irrelevancy": 33.9422,
            "logical_agreement": 52.84397,
            "grammar_ref": 5.15177,
            "grammar_hyp": 5.09131,
            "nubia_score": 0.65954
        },
        "bertscore": {
            "precision": 0.92075,
            "recall": 0.91962,
            "f1": 0.91765
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "t5-small/totto_test",
        "N": 17,
        "total_length": 228,
        "mean_pred_length": 13.411764705882353,
        "std_pred_length": 2.8913425241045903,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 133,
        "unique-1": 106,
        "entropy-1": 6.326414619744928,
        "distinct-2": 0.8672985781990521,
        "vocab_size-2": 183,
        "unique-2": 166,
        "entropy-2": 7.390414650741249,
        "cond_entropy-2": 0.9076337882048946,
        "distinct-3": 0.9226804123711341,
        "vocab_size-3": 179,
        "unique-3": 167,
        "entropy-3": 7.433600148854678,
        "cond_entropy-3": 0.07216300917234968,
        "total_length-nopunct": 198,
        "mean_pred_length-nopunct": 11.647058823529411,
        "std_pred_length-nopunct": 2.495670992423109,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6515151515151515,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 106,
        "entropy-1-nopunct": 6.402996603975637,
        "distinct-2-nopunct": 0.861878453038674,
        "vocab_size-2-nopunct": 156,
        "unique-2-nopunct": 141,
        "entropy-2-nopunct": 7.151671577643099,
        "cond_entropy-2-nopunct": 0.8472833729700617,
        "distinct-3-nopunct": 0.926829268292683,
        "vocab_size-3-nopunct": 152,
        "unique-3-nopunct": 142,
        "entropy-3-nopunct": 7.202004596055136,
        "cond_entropy-3-nopunct": 0.07422913585394506,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.43859649122807015,
            "3": 0.6395348837209303
        },
        "rouge1": {
            "precision": 0.76767,
            "recall": 0.62796,
            "fmeasure": 0.66811
        },
        "rouge2": {
            "precision": 0.42833,
            "recall": 0.37004,
            "fmeasure": 0.37884
        },
        "rougeL": {
            "precision": 0.58954,
            "recall": 0.49645,
            "fmeasure": 0.51915
        },
        "rougeLsum": {
            "precision": 0.58954,
            "recall": 0.49645,
            "fmeasure": 0.51915
        },
        "nist": 4.436110188503445,
        "bleu": 30.3168,
        "meteor": 0.31364801076484783,
        "bleurt": 0.04271,
        "nubia": {
            "semantic_relation": 3.86854,
            "contradiction": 14.42122,
            "irrelevancy": 26.95826,
            "logical_agreement": 58.62051,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.96839,
            "nubia_score": 0.58594
        },
        "bertscore": {
            "precision": 0.92591,
            "recall": 0.89674,
            "f1": 0.90982
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "t5-small/totto_test",
        "N": 19,
        "total_length": 268,
        "mean_pred_length": 14.105263157894736,
        "std_pred_length": 4.266080869296725,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.6007462686567164,
        "vocab_size-1": 161,
        "unique-1": 125,
        "entropy-1": 6.764561339447962,
        "distinct-2": 0.9076305220883534,
        "vocab_size-2": 226,
        "unique-2": 210,
        "entropy-2": 7.742071560556074,
        "cond_entropy-2": 0.7937437988909433,
        "distinct-3": 0.9782608695652174,
        "vocab_size-3": 225,
        "unique-3": 220,
        "entropy-3": 7.802011790074799,
        "cond_entropy-3": 0.06924752107842637,
        "total_length-nopunct": 239,
        "mean_pred_length-nopunct": 12.578947368421053,
        "std_pred_length-nopunct": 4.3324453952119315,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6527196652719666,
        "vocab_size-1-nopunct": 156,
        "unique-1-nopunct": 124,
        "entropy-1-nopunct": 6.8205187732920525,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 198,
        "unique-2-nopunct": 183,
        "entropy-2-nopunct": 7.543793065767872,
        "cond_entropy-2-nopunct": 0.7847588954717069,
        "distinct-3-nopunct": 0.9751243781094527,
        "vocab_size-3-nopunct": 196,
        "unique-3-nopunct": 191,
        "entropy-3-nopunct": 7.601300447397846,
        "cond_entropy-3-nopunct": 0.07498880604476824,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15584415584415584,
            "2": 0.19607843137254902,
            "3": 0.5948275862068966
        },
        "rouge1": {
            "precision": 0.72305,
            "recall": 0.56007,
            "fmeasure": 0.61578
        },
        "rouge2": {
            "precision": 0.50149,
            "recall": 0.38767,
            "fmeasure": 0.4289
        },
        "rougeL": {
            "precision": 0.64431,
            "recall": 0.50015,
            "fmeasure": 0.55008
        },
        "rougeLsum": {
            "precision": 0.64431,
            "recall": 0.50015,
            "fmeasure": 0.55008
        },
        "nist": 3.8614125333543363,
        "bleu": 33.13339,
        "meteor": 0.30966774078866466,
        "bleurt": -0.01515,
        "nubia": {
            "semantic_relation": 3.77496,
            "contradiction": 2.3636,
            "irrelevancy": 37.75796,
            "logical_agreement": 59.87844,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.85403,
            "nubia_score": 0.5474
        },
        "bertscore": {
            "precision": 0.90709,
            "recall": 0.87599,
            "f1": 0.88906
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "t5-small/totto_test",
        "N": 35,
        "total_length": 508,
        "mean_pred_length": 14.514285714285714,
        "std_pred_length": 5.499981447093012,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.547244094488189,
        "vocab_size-1": 278,
        "unique-1": 217,
        "entropy-1": 7.278022629808857,
        "distinct-2": 0.8942917547568711,
        "vocab_size-2": 423,
        "unique-2": 391,
        "entropy-2": 8.627685591061837,
        "cond_entropy-2": 1.1865545133251572,
        "distinct-3": 0.9748858447488584,
        "vocab_size-3": 427,
        "unique-3": 417,
        "entropy-3": 8.722835261651039,
        "cond_entropy-3": 0.11120076049726832,
        "total_length-nopunct": 444,
        "mean_pred_length-nopunct": 12.685714285714285,
        "std_pred_length-nopunct": 5.455123036828663,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6126126126126126,
        "vocab_size-1-nopunct": 272,
        "unique-1-nopunct": 216,
        "entropy-1-nopunct": 7.417013949574458,
        "distinct-2-nopunct": 0.8997555012224939,
        "vocab_size-2-nopunct": 368,
        "unique-2-nopunct": 344,
        "entropy-2-nopunct": 8.423428395985443,
        "cond_entropy-2-nopunct": 1.092684017519861,
        "distinct-3-nopunct": 0.9786096256684492,
        "vocab_size-3-nopunct": 366,
        "unique-3-nopunct": 359,
        "entropy-3-nopunct": 8.502095295443302,
        "cond_entropy-3-nopunct": 0.08847592965053584,
        "msttr-100": 0.714,
        "msttr-100_nopunct": 0.7425,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1702127659574468,
            "2": 0.40707964601769914,
            "3": 0.6322418136020151
        },
        "rouge1": {
            "precision": 0.77569,
            "recall": 0.64224,
            "fmeasure": 0.68866
        },
        "rouge2": {
            "precision": 0.47806,
            "recall": 0.40576,
            "fmeasure": 0.42793
        },
        "rougeL": {
            "precision": 0.67212,
            "recall": 0.56477,
            "fmeasure": 0.60159
        },
        "rougeLsum": {
            "precision": 0.67212,
            "recall": 0.56477,
            "fmeasure": 0.60159
        },
        "nist": 4.934050820700355,
        "bleu": 32.33723,
        "meteor": 0.30707960361563746,
        "bleurt": 0.06716,
        "nubia": {
            "semantic_relation": 3.81004,
            "contradiction": 8.82835,
            "irrelevancy": 33.05051,
            "logical_agreement": 58.12114,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.9093,
            "nubia_score": 0.59154
        },
        "bertscore": {
            "precision": 0.91988,
            "recall": 0.89128,
            "f1": 0.90336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.58974,
            "recall": 0.71818,
            "fmeasure": 0.64734
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.48148,
            "fmeasure": 0.43001
        },
        "rougeL": {
            "precision": 0.58974,
            "recall": 0.71818,
            "fmeasure": 0.64734
        },
        "rougeLsum": {
            "precision": 0.58974,
            "recall": 0.71818,
            "fmeasure": 0.64734
        },
        "nist": 2.1279098100202685,
        "bleu": 22.71871,
        "meteor": 0.3951686358072344,
        "bleurt": 0.17654,
        "nubia": {
            "semantic_relation": 3.88144,
            "contradiction": 0.5302,
            "irrelevancy": 89.95724,
            "logical_agreement": 9.51257,
            "grammar_ref": 5.00001,
            "grammar_hyp": 4.5907,
            "nubia_score": 0.59017
        },
        "bertscore": {
            "precision": 0.89942,
            "recall": 0.9298,
            "f1": 0.91436
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "t5-small/totto_test",
        "N": 48,
        "total_length": 731,
        "mean_pred_length": 15.229166666666666,
        "std_pred_length": 4.779468168344907,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.5389876880984952,
        "vocab_size-1": 394,
        "unique-1": 324,
        "entropy-1": 7.634776804584359,
        "distinct-2": 0.9004392386530015,
        "vocab_size-2": 615,
        "unique-2": 575,
        "entropy-2": 9.159140917680784,
        "cond_entropy-2": 1.3555221359859,
        "distinct-3": 0.9811023622047244,
        "vocab_size-3": 623,
        "unique-3": 611,
        "entropy-3": 9.272817506068913,
        "cond_entropy-3": 0.1161363574072617,
        "total_length-nopunct": 647,
        "mean_pred_length-nopunct": 13.479166666666666,
        "std_pred_length-nopunct": 4.591611841777956,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.598145285935085,
        "vocab_size-1-nopunct": 387,
        "unique-1-nopunct": 322,
        "entropy-1-nopunct": 7.798133378558543,
        "distinct-2-nopunct": 0.9065108514190318,
        "vocab_size-2-nopunct": 543,
        "unique-2-nopunct": 512,
        "entropy-2-nopunct": 8.977674766311972,
        "cond_entropy-2-nopunct": 1.253366756170953,
        "distinct-3-nopunct": 0.9818511796733213,
        "vocab_size-3-nopunct": 541,
        "unique-3-nopunct": 531,
        "entropy-3-nopunct": 9.069610867917747,
        "cond_entropy-3-nopunct": 0.1081600516438794,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.76667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22807017543859648,
            "2": 0.5256410256410257,
            "3": 0.6505791505791506
        },
        "rouge1": {
            "precision": 0.75596,
            "recall": 0.64683,
            "fmeasure": 0.68789
        },
        "rouge2": {
            "precision": 0.49169,
            "recall": 0.42695,
            "fmeasure": 0.44953
        },
        "rougeL": {
            "precision": 0.62069,
            "recall": 0.54554,
            "fmeasure": 0.57175
        },
        "rougeLsum": {
            "precision": 0.62069,
            "recall": 0.54554,
            "fmeasure": 0.57175
        },
        "nist": 5.639866241021957,
        "bleu": 33.81486,
        "meteor": 0.32328669638657526,
        "bleurt": 0.0297,
        "nubia": {
            "semantic_relation": 3.89622,
            "contradiction": 15.69892,
            "irrelevancy": 33.73382,
            "logical_agreement": 50.56726,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.69854,
            "nubia_score": 0.63579
        },
        "bertscore": {
            "precision": 0.91619,
            "recall": 0.89435,
            "f1": 0.90171
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337128,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.45,
            "fmeasure": 0.51429
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.31579,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.45,
            "fmeasure": 0.51429
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.45,
            "fmeasure": 0.51429
        },
        "nist": 2.4802218813600216,
        "bleu": 24.2812,
        "meteor": 0.21575524364960633,
        "bleurt": -0.37596,
        "nubia": {
            "semantic_relation": 3.46683,
            "contradiction": 0.57032,
            "irrelevancy": 55.66455,
            "logical_agreement": 43.76513,
            "grammar_ref": 4.8547,
            "grammar_hyp": 4.3014,
            "nubia_score": 0.50858
        },
        "bertscore": {
            "precision": 0.89521,
            "recall": 0.85365,
            "f1": 0.87188
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7908,
        "mean_pred_length": 22.027855153203344,
        "std_pred_length": 9.490608383489896,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 65,
        "distinct-1": 0.3727870510875063,
        "vocab_size-1": 2948,
        "unique-1": 2165,
        "entropy-1": 9.267613072593328,
        "distinct-2": 0.8460723274605908,
        "vocab_size-2": 6387,
        "unique-2": 5919,
        "entropy-2": 12.356298301298754,
        "cond_entropy-2": 2.8542561498352046,
        "distinct-3": 0.9783031988873435,
        "vocab_size-3": 7034,
        "unique-3": 6921,
        "entropy-3": 12.761920875848766,
        "cond_entropy-3": 0.4164883183838953,
        "total_length-nopunct": 7031,
        "mean_pred_length-nopunct": 19.584958217270195,
        "std_pred_length-nopunct": 8.300276663236986,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.41786374626653394,
        "vocab_size-1-nopunct": 2938,
        "unique-1-nopunct": 2164,
        "entropy-1-nopunct": 9.63222029991525,
        "distinct-2-nopunct": 0.8645083932853717,
        "vocab_size-2-nopunct": 5768,
        "unique-2-nopunct": 5397,
        "entropy-2-nopunct": 12.24085468289175,
        "cond_entropy-2-nopunct": 2.7339668896335265,
        "distinct-3-nopunct": 0.9846348804055124,
        "vocab_size-3-nopunct": 6216,
        "unique-3-nopunct": 6138,
        "entropy-3-nopunct": 12.59034502459716,
        "cond_entropy-3-nopunct": 0.37048746695522455,
        "msttr-100": 0.72557,
        "msttr-100_nopunct": 0.77014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03270856302829842,
            "2": 0.1967654986522911,
            "3": 0.44457831325301206,
            "4": 0.6559633027522935,
            "5": 0.787556904400607,
            "6": 0.8873239436619719,
            "7": 0.9371584699453552,
            "8": 0.9746682750301568,
            "9": 0.9746031746031746,
            "10": 0.9914728682170543
        },
        "rouge1": {
            "precision": 0.9154,
            "recall": 0.93108,
            "fmeasure": 0.91973
        },
        "rouge2": {
            "precision": 0.833,
            "recall": 0.85502,
            "fmeasure": 0.83944
        },
        "rougeL": {
            "precision": 0.90244,
            "recall": 0.92191,
            "fmeasure": 0.90847
        },
        "rougeLsum": {
            "precision": 0.90244,
            "recall": 0.92191,
            "fmeasure": 0.90847
        },
        "nist": 13.981447987231807,
        "bleu": 92.40348,
        "meteor": 0.5796075519083013,
        "bleurt": 0.36848,
        "nubia": {
            "semantic_relation": 4.44981,
            "contradiction": 1.88822,
            "irrelevancy": 32.77875,
            "logical_agreement": 65.33302,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.30296,
            "nubia_score": 0.79041
        },
        "bertscore": {
            "precision": 0.98009,
            "recall": 0.98402,
            "f1": 0.98029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "t5-small/totto_test",
        "N": 36,
        "total_length": 544,
        "mean_pred_length": 15.11111111111111,
        "std_pred_length": 3.8642073916176,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.5220588235294118,
        "vocab_size-1": 284,
        "unique-1": 230,
        "entropy-1": 7.219151132260385,
        "distinct-2": 0.8188976377952756,
        "vocab_size-2": 416,
        "unique-2": 377,
        "entropy-2": 8.479907638657615,
        "cond_entropy-2": 1.0541640254276956,
        "distinct-3": 0.902542372881356,
        "vocab_size-3": 426,
        "unique-3": 401,
        "entropy-3": 8.634637434900073,
        "cond_entropy-3": 0.1525082830126775,
        "total_length-nopunct": 482,
        "mean_pred_length-nopunct": 13.38888888888889,
        "std_pred_length-nopunct": 3.1559272081608403,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5726141078838174,
        "vocab_size-1-nopunct": 276,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.306262542395192,
        "distinct-2-nopunct": 0.820627802690583,
        "vocab_size-2-nopunct": 366,
        "unique-2-nopunct": 335,
        "entropy-2-nopunct": 8.284993593943621,
        "cond_entropy-2-nopunct": 1.0586502479674036,
        "distinct-3-nopunct": 0.9048780487804878,
        "vocab_size-3-nopunct": 371,
        "unique-3-nopunct": 350,
        "entropy-3-nopunct": 8.434836776276716,
        "cond_entropy-3-nopunct": 0.15915474212089087,
        "msttr-100": 0.706,
        "msttr-100_nopunct": 0.7525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24752475247524752,
            "2": 0.4603174603174603,
            "3": 0.7214076246334311
        },
        "rouge1": {
            "precision": 0.72792,
            "recall": 0.70656,
            "fmeasure": 0.70223
        },
        "rouge2": {
            "precision": 0.49384,
            "recall": 0.47803,
            "fmeasure": 0.47432
        },
        "rougeL": {
            "precision": 0.63365,
            "recall": 0.60859,
            "fmeasure": 0.60795
        },
        "rougeLsum": {
            "precision": 0.63365,
            "recall": 0.60859,
            "fmeasure": 0.60795
        },
        "nist": 6.012501885778946,
        "bleu": 40.09033,
        "meteor": 0.35790096090123685,
        "bleurt": 0.22177,
        "nubia": {
            "semantic_relation": 3.99542,
            "contradiction": 22.14865,
            "irrelevancy": 28.59793,
            "logical_agreement": 49.25342,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.56888,
            "nubia_score": 0.66495
        },
        "bertscore": {
            "precision": 0.92654,
            "recall": 0.91574,
            "f1": 0.91965
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "t5-small/totto_test",
        "N": 36,
        "total_length": 572,
        "mean_pred_length": 15.88888888888889,
        "std_pred_length": 4.6534203536382055,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5594405594405595,
        "vocab_size-1": 320,
        "unique-1": 268,
        "entropy-1": 7.3203825241268365,
        "distinct-2": 0.9253731343283582,
        "vocab_size-2": 496,
        "unique-2": 472,
        "entropy-2": 8.86017430455794,
        "cond_entropy-2": 1.3824441030619226,
        "distinct-3": 0.98,
        "vocab_size-3": 490,
        "unique-3": 480,
        "entropy-3": 8.925784284662019,
        "cond_entropy-3": 0.07326592688752243,
        "total_length-nopunct": 497,
        "mean_pred_length-nopunct": 13.805555555555555,
        "std_pred_length-nopunct": 4.254536431494456,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6297786720321932,
        "vocab_size-1-nopunct": 313,
        "unique-1-nopunct": 267,
        "entropy-1-nopunct": 7.4524063195898504,
        "distinct-2-nopunct": 0.9349240780911063,
        "vocab_size-2-nopunct": 431,
        "unique-2-nopunct": 416,
        "entropy-2-nopunct": 8.654229249886727,
        "cond_entropy-2-nopunct": 1.2704347935996354,
        "distinct-3-nopunct": 0.9905882352941177,
        "vocab_size-3-nopunct": 421,
        "unique-3-nopunct": 417,
        "entropy-3-nopunct": 8.712495501613363,
        "cond_entropy-3-nopunct": 0.07002665845493006,
        "msttr-100": 0.706,
        "msttr-100_nopunct": 0.7525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.29213483146067415,
            "3": 0.6876513317191283
        },
        "rouge1": {
            "precision": 0.74898,
            "recall": 0.66162,
            "fmeasure": 0.69371
        },
        "rouge2": {
            "precision": 0.49993,
            "recall": 0.43721,
            "fmeasure": 0.45884
        },
        "rougeL": {
            "precision": 0.66243,
            "recall": 0.58439,
            "fmeasure": 0.61267
        },
        "rougeLsum": {
            "precision": 0.66243,
            "recall": 0.58439,
            "fmeasure": 0.61267
        },
        "nist": 5.674483658002744,
        "bleu": 38.09782,
        "meteor": 0.3290983135290614,
        "bleurt": 0.14529,
        "nubia": {
            "semantic_relation": 4.06132,
            "contradiction": 3.04605,
            "irrelevancy": 33.59417,
            "logical_agreement": 63.35978,
            "grammar_ref": 4.82696,
            "grammar_hyp": 5.02393,
            "nubia_score": 0.66335
        },
        "bertscore": {
            "precision": 0.91717,
            "recall": 0.90213,
            "f1": 0.90868
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 87,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.685557397915997,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.6781609195402298,
        "vocab_size-1": 59,
        "unique-1": 45,
        "entropy-1": 5.628071622405264,
        "distinct-2": 0.9135802469135802,
        "vocab_size-2": 74,
        "unique-2": 69,
        "entropy-2": 6.148371299127493,
        "cond_entropy-2": 0.38918185247944276,
        "distinct-3": 0.9733333333333334,
        "vocab_size-3": 73,
        "unique-3": 71,
        "entropy-3": 6.175485357162557,
        "cond_entropy-3": -0.02096614569323108,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.671948072511782,
        "distinct-2-nopunct": 0.9428571428571428,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 6.004213195485494,
        "cond_entropy-2-nopunct": 0.3137078250226724,
        "distinct-3-nopunct": 0.96875,
        "vocab_size-3-nopunct": 62,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.9375,
        "cond_entropy-3-nopunct": -0.05498789972366222,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.46153846153846156,
            "3": 0.5862068965517241
        },
        "rouge1": {
            "precision": 0.66431,
            "recall": 0.55864,
            "fmeasure": 0.59778
        },
        "rouge2": {
            "precision": 0.42633,
            "recall": 0.34248,
            "fmeasure": 0.37321
        },
        "rougeL": {
            "precision": 0.51803,
            "recall": 0.42711,
            "fmeasure": 0.46163
        },
        "rougeLsum": {
            "precision": 0.51803,
            "recall": 0.42711,
            "fmeasure": 0.46163
        },
        "nist": 4.197062157037749,
        "bleu": 33.70534,
        "meteor": 0.3018104859638441,
        "bleurt": -0.02612,
        "nubia": {
            "semantic_relation": 3.34522,
            "contradiction": 22.48951,
            "irrelevancy": 53.65256,
            "logical_agreement": 23.85793,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.29602,
            "nubia_score": 0.44987
        },
        "bertscore": {
            "precision": 0.88969,
            "recall": 0.86408,
            "f1": 0.8765
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "t5-small/totto_test",
        "N": 17,
        "total_length": 255,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.029304421069108,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.5686274509803921,
        "vocab_size-1": 145,
        "unique-1": 110,
        "entropy-1": 6.542541130743591,
        "distinct-2": 0.907563025210084,
        "vocab_size-2": 216,
        "unique-2": 198,
        "entropy-2": 7.6951968599284575,
        "cond_entropy-2": 1.0059223269572375,
        "distinct-3": 0.9638009049773756,
        "vocab_size-3": 213,
        "unique-3": 205,
        "entropy-3": 7.7155043693461645,
        "cond_entropy-3": 0.03566296352388132,
        "total_length-nopunct": 224,
        "mean_pred_length-nopunct": 13.176470588235293,
        "std_pred_length-nopunct": 4.032738000235908,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6205357142857143,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 106,
        "entropy-1-nopunct": 6.608295863501273,
        "distinct-2-nopunct": 0.8985507246376812,
        "vocab_size-2-nopunct": 186,
        "unique-2-nopunct": 169,
        "entropy-2-nopunct": 7.473632971971155,
        "cond_entropy-2-nopunct": 0.912675473178753,
        "distinct-3-nopunct": 0.9631578947368421,
        "vocab_size-3-nopunct": 183,
        "unique-3-nopunct": 176,
        "entropy-3-nopunct": 7.496171397804642,
        "cond_entropy-3-nopunct": 0.031683256117553786,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.705,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.2653061224489796,
            "3": 0.7043010752688172
        },
        "rouge1": {
            "precision": 0.72429,
            "recall": 0.68929,
            "fmeasure": 0.69643
        },
        "rouge2": {
            "precision": 0.53363,
            "recall": 0.51073,
            "fmeasure": 0.51374
        },
        "rougeL": {
            "precision": 0.63019,
            "recall": 0.5954,
            "fmeasure": 0.60335
        },
        "rougeLsum": {
            "precision": 0.63019,
            "recall": 0.5954,
            "fmeasure": 0.60335
        },
        "nist": 5.469239111455277,
        "bleu": 43.70842,
        "meteor": 0.3559730514826589,
        "bleurt": 0.20694,
        "nubia": {
            "semantic_relation": 4.05722,
            "contradiction": 11.90401,
            "irrelevancy": 29.7174,
            "logical_agreement": 58.37859,
            "grammar_ref": 4.21928,
            "grammar_hyp": 4.0937,
            "nubia_score": 0.71699
        },
        "bertscore": {
            "precision": 0.91636,
            "recall": 0.91202,
            "f1": 0.91067
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "t5-small/totto_test",
        "N": 41,
        "total_length": 619,
        "mean_pred_length": 15.097560975609756,
        "std_pred_length": 4.321273965546083,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.43295638126009695,
        "vocab_size-1": 268,
        "unique-1": 209,
        "entropy-1": 6.949075565162179,
        "distinct-2": 0.7664359861591695,
        "vocab_size-2": 443,
        "unique-2": 394,
        "entropy-2": 8.45830521599385,
        "cond_entropy-2": 1.3528606037756266,
        "distinct-3": 0.8528864059590316,
        "vocab_size-3": 458,
        "unique-3": 426,
        "entropy-3": 8.640630256187855,
        "cond_entropy-3": 0.21188121174421873,
        "total_length-nopunct": 535,
        "mean_pred_length-nopunct": 13.048780487804878,
        "std_pred_length-nopunct": 4.017954943428827,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.4897196261682243,
        "vocab_size-1-nopunct": 262,
        "unique-1-nopunct": 208,
        "entropy-1-nopunct": 7.05660669852405,
        "distinct-2-nopunct": 0.7854251012145749,
        "vocab_size-2-nopunct": 388,
        "unique-2-nopunct": 351,
        "entropy-2-nopunct": 8.279037975988487,
        "cond_entropy-2-nopunct": 1.334859880700365,
        "distinct-3-nopunct": 0.8609271523178808,
        "vocab_size-3-nopunct": 390,
        "unique-3-nopunct": 364,
        "entropy-3-nopunct": 8.42339719202835,
        "cond_entropy-3-nopunct": 0.19610866301423252,
        "msttr-100": 0.63667,
        "msttr-100_nopunct": 0.664,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.512396694214876,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.65253,
            "recall": 0.70505,
            "fmeasure": 0.66583
        },
        "rouge2": {
            "precision": 0.40436,
            "recall": 0.4412,
            "fmeasure": 0.41351
        },
        "rougeL": {
            "precision": 0.53328,
            "recall": 0.58243,
            "fmeasure": 0.54645
        },
        "rougeLsum": {
            "precision": 0.53328,
            "recall": 0.58243,
            "fmeasure": 0.54645
        },
        "nist": 5.33697318724775,
        "bleu": 31.31279,
        "meteor": 0.3707457502803093,
        "bleurt": 0.20675,
        "nubia": {
            "semantic_relation": 3.89986,
            "contradiction": 8.03413,
            "irrelevancy": 54.58632,
            "logical_agreement": 37.37954,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.39662,
            "nubia_score": 0.66995
        },
        "bertscore": {
            "precision": 0.90252,
            "recall": 0.92031,
            "f1": 0.90952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "t5-small/totto_test",
        "N": 10,
        "total_length": 144,
        "mean_pred_length": 14.4,
        "std_pred_length": 4.054626986542659,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.625,
        "vocab_size-1": 90,
        "unique-1": 73,
        "entropy-1": 5.9187185131639675,
        "distinct-2": 0.9328358208955224,
        "vocab_size-2": 125,
        "unique-2": 118,
        "entropy-2": 6.916835459114496,
        "cond_entropy-2": 0.843585482770755,
        "distinct-3": 0.9758064516129032,
        "vocab_size-3": 121,
        "unique-3": 118,
        "entropy-3": 6.905809213612667,
        "cond_entropy-3": 0.0010103457355544678,
        "total_length-nopunct": 123,
        "mean_pred_length-nopunct": 12.3,
        "std_pred_length-nopunct": 3.7429934544425802,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6991869918699187,
        "vocab_size-1-nopunct": 86,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 5.940051343479015,
        "distinct-2-nopunct": 0.9380530973451328,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 101,
        "entropy-2-nopunct": 6.678586042061223,
        "cond_entropy-2-nopunct": 0.8095491376848537,
        "distinct-3-nopunct": 0.9902912621359223,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 101,
        "entropy-3-nopunct": 6.667083051455081,
        "cond_entropy-3-nopunct": -0.007464842998959581,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14814814814814814,
            "2": 0.4117647058823529,
            "3": 0.8018867924528302
        },
        "rouge1": {
            "precision": 0.79505,
            "recall": 0.72975,
            "fmeasure": 0.75063
        },
        "rouge2": {
            "precision": 0.49292,
            "recall": 0.47851,
            "fmeasure": 0.47386
        },
        "rougeL": {
            "precision": 0.68953,
            "recall": 0.65206,
            "fmeasure": 0.65864
        },
        "rougeLsum": {
            "precision": 0.68953,
            "recall": 0.65206,
            "fmeasure": 0.65864
        },
        "nist": 5.624171209642026,
        "bleu": 43.78552,
        "meteor": 0.40503232309890363,
        "bleurt": 0.35451,
        "nubia": {
            "semantic_relation": 4.67294,
            "contradiction": 1.43219,
            "irrelevancy": 20.14083,
            "logical_agreement": 78.42698,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.23881,
            "nubia_score": 0.8321
        },
        "bertscore": {
            "precision": 0.93271,
            "recall": 0.93025,
            "f1": 0.93077
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "t5-small/totto_test",
        "N": 42,
        "total_length": 659,
        "mean_pred_length": 15.69047619047619,
        "std_pred_length": 4.886756131374713,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5402124430955993,
        "vocab_size-1": 356,
        "unique-1": 279,
        "entropy-1": 7.537273308773089,
        "distinct-2": 0.880064829821718,
        "vocab_size-2": 543,
        "unique-2": 493,
        "entropy-2": 8.973487329295901,
        "cond_entropy-2": 1.212034324809495,
        "distinct-3": 0.951304347826087,
        "vocab_size-3": 547,
        "unique-3": 522,
        "entropy-3": 9.06608829799423,
        "cond_entropy-3": 0.1072389733834363,
        "total_length-nopunct": 581,
        "mean_pred_length-nopunct": 13.833333333333334,
        "std_pred_length-nopunct": 4.428891437490805,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6024096385542169,
        "vocab_size-1-nopunct": 350,
        "unique-1-nopunct": 279,
        "entropy-1-nopunct": 7.743809524652257,
        "distinct-2-nopunct": 0.8812615955473099,
        "vocab_size-2-nopunct": 475,
        "unique-2-nopunct": 433,
        "entropy-2-nopunct": 8.7756262422417,
        "cond_entropy-2-nopunct": 1.119934992735998,
        "distinct-3-nopunct": 0.9617706237424547,
        "vocab_size-3-nopunct": 478,
        "unique-3-nopunct": 460,
        "entropy-3-nopunct": 8.879124400712893,
        "cond_entropy-3-nopunct": 0.11665236221650326,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.778,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29310344827586204,
            "2": 0.42452830188679247,
            "3": 0.7775280898876404
        },
        "rouge1": {
            "precision": 0.76408,
            "recall": 0.74357,
            "fmeasure": 0.74396
        },
        "rouge2": {
            "precision": 0.52746,
            "recall": 0.51636,
            "fmeasure": 0.51403
        },
        "rougeL": {
            "precision": 0.66228,
            "recall": 0.64989,
            "fmeasure": 0.64768
        },
        "rougeLsum": {
            "precision": 0.66228,
            "recall": 0.64989,
            "fmeasure": 0.64768
        },
        "nist": 6.985881908566908,
        "bleu": 45.75757,
        "meteor": 0.40052757205653544,
        "bleurt": 0.28536,
        "nubia": {
            "semantic_relation": 4.23178,
            "contradiction": 4.86156,
            "irrelevancy": 33.78524,
            "logical_agreement": 61.3532,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.71356,
            "nubia_score": 0.72938
        },
        "bertscore": {
            "precision": 0.93479,
            "recall": 0.93353,
            "f1": 0.93241
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "t5-small/totto_test",
        "N": 78,
        "total_length": 1198,
        "mean_pred_length": 15.35897435897436,
        "std_pred_length": 4.819762625749665,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.48414023372287146,
        "vocab_size-1": 580,
        "unique-1": 433,
        "entropy-1": 8.040576657381319,
        "distinct-2": 0.8455357142857143,
        "vocab_size-2": 947,
        "unique-2": 849,
        "entropy-2": 9.708836694423866,
        "cond_entropy-2": 1.44959577531442,
        "distinct-3": 0.944337811900192,
        "vocab_size-3": 984,
        "unique-3": 937,
        "entropy-3": 9.898404575319873,
        "cond_entropy-3": 0.2010721594318339,
        "total_length-nopunct": 1053,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.1098692973166,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.540360873694207,
        "vocab_size-1-nopunct": 569,
        "unique-1-nopunct": 431,
        "entropy-1-nopunct": 8.226287488319395,
        "distinct-2-nopunct": 0.8441025641025641,
        "vocab_size-2-nopunct": 823,
        "unique-2-nopunct": 741,
        "entropy-2-nopunct": 9.493735107388746,
        "cond_entropy-2-nopunct": 1.3503840125749673,
        "distinct-3-nopunct": 0.947603121516165,
        "vocab_size-3-nopunct": 850,
        "unique-3-nopunct": 813,
        "entropy-3-nopunct": 9.687110251944157,
        "cond_entropy-3-nopunct": 0.21585392111628707,
        "msttr-100": 0.73273,
        "msttr-100_nopunct": 0.779,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2317596566523605,
            "2": 0.46382978723404256,
            "3": 0.7128953771289538
        },
        "rouge1": {
            "precision": 0.75117,
            "recall": 0.68722,
            "fmeasure": 0.70504
        },
        "rouge2": {
            "precision": 0.53461,
            "recall": 0.48179,
            "fmeasure": 0.49674
        },
        "rougeL": {
            "precision": 0.67721,
            "recall": 0.61905,
            "fmeasure": 0.63457
        },
        "rougeLsum": {
            "precision": 0.67721,
            "recall": 0.61905,
            "fmeasure": 0.63457
        },
        "nist": 6.738402352559605,
        "bleu": 43.70899,
        "meteor": 0.3760079859854648,
        "bleurt": 0.24291,
        "nubia": {
            "semantic_relation": 4.14955,
            "contradiction": 7.28061,
            "irrelevancy": 34.62753,
            "logical_agreement": 58.09186,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.73458,
            "nubia_score": 0.69835
        },
        "bertscore": {
            "precision": 0.92498,
            "recall": 0.91849,
            "f1": 0.92045
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "t5-small/totto_test",
        "N": 114,
        "total_length": 1750,
        "mean_pred_length": 15.350877192982455,
        "std_pred_length": 4.601644359300253,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.4725714285714286,
        "vocab_size-1": 827,
        "unique-1": 663,
        "entropy-1": 8.24786962842178,
        "distinct-2": 0.8612469437652812,
        "vocab_size-2": 1409,
        "unique-2": 1302,
        "entropy-2": 10.284576834134922,
        "cond_entropy-2": 1.8057726134507683,
        "distinct-3": 0.9651773981603153,
        "vocab_size-3": 1469,
        "unique-3": 1433,
        "entropy-3": 10.490081314644115,
        "cond_entropy-3": 0.21339727298963831,
        "total_length-nopunct": 1542,
        "mean_pred_length-nopunct": 13.526315789473685,
        "std_pred_length-nopunct": 4.375390762129667,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5311284046692607,
        "vocab_size-1-nopunct": 819,
        "unique-1-nopunct": 662,
        "entropy-1-nopunct": 8.499391480159685,
        "distinct-2-nopunct": 0.8718487394957983,
        "vocab_size-2-nopunct": 1245,
        "unique-2-nopunct": 1164,
        "entropy-2-nopunct": 10.105561354890234,
        "cond_entropy-2-nopunct": 1.7123911371909977,
        "distinct-3-nopunct": 0.969558599695586,
        "vocab_size-3-nopunct": 1274,
        "unique-3-nopunct": 1246,
        "entropy-3-nopunct": 10.288182513124873,
        "cond_entropy-3-nopunct": 0.20747728886005265,
        "msttr-100": 0.73294,
        "msttr-100_nopunct": 0.778,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21890547263681592,
            "2": 0.4263959390862944,
            "3": 0.7155399473222125
        },
        "rouge1": {
            "precision": 0.72959,
            "recall": 0.65578,
            "fmeasure": 0.67902
        },
        "rouge2": {
            "precision": 0.46988,
            "recall": 0.42608,
            "fmeasure": 0.43921
        },
        "rougeL": {
            "precision": 0.6088,
            "recall": 0.55409,
            "fmeasure": 0.5709
        },
        "rougeLsum": {
            "precision": 0.6088,
            "recall": 0.55409,
            "fmeasure": 0.5709
        },
        "nist": 6.8745387198227865,
        "bleu": 36.93534,
        "meteor": 0.3451405368338924,
        "bleurt": 0.10808,
        "nubia": {
            "semantic_relation": 3.96793,
            "contradiction": 10.96882,
            "irrelevancy": 36.22383,
            "logical_agreement": 52.80735,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.81238,
            "nubia_score": 0.64625
        },
        "bertscore": {
            "precision": 0.91231,
            "recall": 0.90682,
            "f1": 0.90813
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "t5-small/totto_test",
        "N": 122,
        "total_length": 1863,
        "mean_pred_length": 15.270491803278688,
        "std_pred_length": 4.882281254693631,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.46537842190016104,
        "vocab_size-1": 867,
        "unique-1": 696,
        "entropy-1": 8.281792566894346,
        "distinct-2": 0.8276852383687536,
        "vocab_size-2": 1441,
        "unique-2": 1299,
        "entropy-2": 10.287184817100378,
        "cond_entropy-2": 1.7771768144189934,
        "distinct-3": 0.9462631253860407,
        "vocab_size-3": 1532,
        "unique-3": 1472,
        "entropy-3": 10.535152318200673,
        "cond_entropy-3": 0.24354242379473018,
        "total_length-nopunct": 1631,
        "mean_pred_length-nopunct": 13.368852459016393,
        "std_pred_length-nopunct": 4.385521670507849,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5254445125689761,
        "vocab_size-1-nopunct": 857,
        "unique-1-nopunct": 694,
        "entropy-1-nopunct": 8.565851869874232,
        "distinct-2-nopunct": 0.8449304174950298,
        "vocab_size-2-nopunct": 1275,
        "unique-2-nopunct": 1174,
        "entropy-2-nopunct": 10.111198299997634,
        "cond_entropy-2-nopunct": 1.637281026333556,
        "distinct-3-nopunct": 0.9552992069214131,
        "vocab_size-3-nopunct": 1325,
        "unique-3-nopunct": 1284,
        "entropy-3-nopunct": 10.33065377568038,
        "cond_entropy-3-nopunct": 0.23950911698502195,
        "msttr-100": 0.72222,
        "msttr-100_nopunct": 0.7675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20898876404494382,
            "2": 0.3649851632047478,
            "3": 0.6980014803849001
        },
        "rouge1": {
            "precision": 0.73754,
            "recall": 0.66913,
            "fmeasure": 0.69086
        },
        "rouge2": {
            "precision": 0.48631,
            "recall": 0.43212,
            "fmeasure": 0.45006
        },
        "rougeL": {
            "precision": 0.64136,
            "recall": 0.57842,
            "fmeasure": 0.5984
        },
        "rougeLsum": {
            "precision": 0.64136,
            "recall": 0.57842,
            "fmeasure": 0.5984
        },
        "nist": 6.883767512080453,
        "bleu": 38.96544,
        "meteor": 0.34563072981027465,
        "bleurt": 0.1251,
        "nubia": {
            "semantic_relation": 4.01203,
            "contradiction": 9.04647,
            "irrelevancy": 30.37294,
            "logical_agreement": 60.58059,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.73966,
            "nubia_score": 0.66385
        },
        "bertscore": {
            "precision": 0.91537,
            "recall": 0.90326,
            "f1": 0.90709
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 52,
        "mean_pred_length": 13.0,
        "std_pred_length": 5.244044240850758,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.75,
        "vocab_size-1": 39,
        "unique-1": 33,
        "entropy-1": 5.063527882011021,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.4270769467824168,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.12553088208385924,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 4.06201920231798,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8409090909090909,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.078638720860853,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.2563686638041515,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.2727272727272727,
            "3": 0.5111111111111111
        },
        "rouge1": {
            "precision": 0.66396,
            "recall": 0.61296,
            "fmeasure": 0.62509
        },
        "rouge2": {
            "precision": 0.45842,
            "recall": 0.42852,
            "fmeasure": 0.43718
        },
        "rougeL": {
            "precision": 0.6336,
            "recall": 0.57728,
            "fmeasure": 0.59505
        },
        "rougeLsum": {
            "precision": 0.6336,
            "recall": 0.57728,
            "fmeasure": 0.59505
        },
        "nist": 2.660734129854744,
        "bleu": 24.59492,
        "meteor": 0.26609024140939636,
        "bleurt": 0.1301,
        "nubia": {
            "semantic_relation": 3.76117,
            "contradiction": 0.22631,
            "irrelevancy": 49.80954,
            "logical_agreement": 49.96416,
            "grammar_ref": 4.43427,
            "grammar_hyp": 4.63013,
            "nubia_score": 0.59902
        },
        "bertscore": {
            "precision": 0.89796,
            "recall": 0.87861,
            "f1": 0.88732
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 73,
        "mean_pred_length": 14.6,
        "std_pred_length": 3.0724582991474434,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.7534246575342466,
        "vocab_size-1": 55,
        "unique-1": 45,
        "entropy-1": 5.570382354100934,
        "distinct-2": 1.0,
        "vocab_size-2": 68,
        "unique-2": 68,
        "entropy-2": 6.087462841250345,
        "cond_entropy-2": 0.42604370250744245,
        "distinct-3": 1.0,
        "vocab_size-3": 63,
        "unique-3": 63,
        "entropy-3": 5.97727992349992,
        "cond_entropy-3": -0.11018291775042297,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.8973665961010275,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.54672992103457,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.7813597135246555,
        "cond_entropy-2-nopunct": 0.2673716719968103,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.6388888888888888
        },
        "rouge1": {
            "precision": 0.84051,
            "recall": 0.63857,
            "fmeasure": 0.71817
        },
        "rouge2": {
            "precision": 0.5392,
            "recall": 0.40354,
            "fmeasure": 0.45664
        },
        "rougeL": {
            "precision": 0.67974,
            "recall": 0.50319,
            "fmeasure": 0.57341
        },
        "rougeLsum": {
            "precision": 0.67974,
            "recall": 0.50319,
            "fmeasure": 0.57341
        },
        "nist": 3.224386331398533,
        "bleu": 28.39596,
        "meteor": 0.3281272465564665,
        "bleurt": 0.06128,
        "nubia": {
            "semantic_relation": 4.18723,
            "contradiction": 0.46016,
            "irrelevancy": 41.32534,
            "logical_agreement": 58.21449,
            "grammar_ref": 4.6156,
            "grammar_hyp": 5.26964,
            "nubia_score": 0.6686
        },
        "bertscore": {
            "precision": 0.91593,
            "recall": 0.89016,
            "f1": 0.90191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "t5-small/totto_test",
        "N": 81,
        "total_length": 1324,
        "mean_pred_length": 16.34567901234568,
        "std_pred_length": 4.841080620685765,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 37,
        "distinct-1": 0.47658610271903323,
        "vocab_size-1": 631,
        "unique-1": 500,
        "entropy-1": 8.05130576526411,
        "distinct-2": 0.8407079646017699,
        "vocab_size-2": 1045,
        "unique-2": 927,
        "entropy-2": 9.870971328360847,
        "cond_entropy-2": 1.6316262116849163,
        "distinct-3": 0.9259896729776248,
        "vocab_size-3": 1076,
        "unique-3": 1010,
        "entropy-3": 10.018957689894812,
        "cond_entropy-3": 0.15100975987017587,
        "total_length-nopunct": 1144,
        "mean_pred_length-nopunct": 14.123456790123457,
        "std_pred_length-nopunct": 4.137699951677044,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5437062937062938,
        "vocab_size-1-nopunct": 622,
        "unique-1-nopunct": 497,
        "entropy-1-nopunct": 8.327355460215927,
        "distinct-2-nopunct": 0.8570084666039511,
        "vocab_size-2-nopunct": 911,
        "unique-2-nopunct": 819,
        "entropy-2-nopunct": 9.681832783599038,
        "cond_entropy-2-nopunct": 1.4284621728230948,
        "distinct-3-nopunct": 0.9389002036659878,
        "vocab_size-3-nopunct": 922,
        "unique-3-nopunct": 873,
        "entropy-3-nopunct": 9.80842444087328,
        "cond_entropy-3-nopunct": 0.13878067553395637,
        "msttr-100": 0.73769,
        "msttr-100_nopunct": 0.77364,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21160409556313994,
            "2": 0.44573643410852715,
            "3": 0.7540983606557377
        },
        "rouge1": {
            "precision": 0.75077,
            "recall": 0.71081,
            "fmeasure": 0.71901
        },
        "rouge2": {
            "precision": 0.54177,
            "recall": 0.51201,
            "fmeasure": 0.51651
        },
        "rougeL": {
            "precision": 0.6483,
            "recall": 0.61801,
            "fmeasure": 0.62152
        },
        "rougeLsum": {
            "precision": 0.6483,
            "recall": 0.61801,
            "fmeasure": 0.62152
        },
        "nist": 7.2349166570963,
        "bleu": 46.23502,
        "meteor": 0.37960243626047735,
        "bleurt": 0.14648,
        "nubia": {
            "semantic_relation": 4.04201,
            "contradiction": 8.53586,
            "irrelevancy": 34.8954,
            "logical_agreement": 56.56874,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.60859,
            "nubia_score": 0.68117
        },
        "bertscore": {
            "precision": 0.92217,
            "recall": 0.91712,
            "f1": 0.91755
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "t5-small/totto_test",
        "N": 31,
        "total_length": 531,
        "mean_pred_length": 17.129032258064516,
        "std_pred_length": 5.197654157492099,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5743879472693032,
        "vocab_size-1": 305,
        "unique-1": 236,
        "entropy-1": 7.5272958570720565,
        "distinct-2": 0.912,
        "vocab_size-2": 456,
        "unique-2": 415,
        "entropy-2": 8.785254959649043,
        "cond_entropy-2": 1.115650291169994,
        "distinct-3": 0.9530916844349681,
        "vocab_size-3": 447,
        "unique-3": 425,
        "entropy-3": 8.779627481385319,
        "cond_entropy-3": 0.004172967525976989,
        "total_length-nopunct": 467,
        "mean_pred_length-nopunct": 15.064516129032258,
        "std_pred_length-nopunct": 4.689972032869139,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6445396145610278,
        "vocab_size-1-nopunct": 301,
        "unique-1-nopunct": 236,
        "entropy-1-nopunct": 7.710677999547647,
        "distinct-2-nopunct": 0.9174311926605505,
        "vocab_size-2-nopunct": 400,
        "unique-2-nopunct": 367,
        "entropy-2-nopunct": 8.597852530037219,
        "cond_entropy-2-nopunct": 0.9388139179716541,
        "distinct-3-nopunct": 0.9530864197530864,
        "vocab_size-3-nopunct": 386,
        "unique-3-nopunct": 367,
        "entropy-3-nopunct": 8.567950937278116,
        "cond_entropy-3-nopunct": -0.019332986248172663,
        "msttr-100": 0.782,
        "msttr-100_nopunct": 0.83,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2702702702702703,
            "2": 0.3253012048192771,
            "3": 0.7306666666666667
        },
        "rouge1": {
            "precision": 0.73317,
            "recall": 0.68855,
            "fmeasure": 0.70099
        },
        "rouge2": {
            "precision": 0.46916,
            "recall": 0.43284,
            "fmeasure": 0.44537
        },
        "rougeL": {
            "precision": 0.61573,
            "recall": 0.57671,
            "fmeasure": 0.58887
        },
        "rougeLsum": {
            "precision": 0.61573,
            "recall": 0.57671,
            "fmeasure": 0.58887
        },
        "nist": 6.199478453863232,
        "bleu": 39.09691,
        "meteor": 0.3592653398147062,
        "bleurt": 0.21085,
        "nubia": {
            "semantic_relation": 4.04864,
            "contradiction": 22.03907,
            "irrelevancy": 27.73332,
            "logical_agreement": 50.22762,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.8497,
            "nubia_score": 0.67042
        },
        "bertscore": {
            "precision": 0.91885,
            "recall": 0.91114,
            "f1": 0.91367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.76,
        "vocab_size-1": 19,
        "unique-1": 15,
        "entropy-1": 4.083856189774723,
        "distinct-2": 0.875,
        "vocab_size-2": 21,
        "unique-2": 18,
        "entropy-2": 4.334962500721157,
        "cond_entropy-2": 0.2744396442797651,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 22,
        "unique-3": 21,
        "entropy-3": 4.436605434317882,
        "cond_entropy-3": 0.1125124988141176,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.914866303883101,
        "distinct-2-nopunct": 0.8636363636363636,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.186704345910023,
        "cond_entropy-2-nopunct": 0.2540514807621026,
        "distinct-3-nopunct": 0.9523809523809523,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.297079327540665,
        "cond_entropy-3-nopunct": 0.07574294699860612,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.46377,
            "recall": 0.73214,
            "fmeasure": 0.56734
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.44103,
            "fmeasure": 0.33668
        },
        "rougeL": {
            "precision": 0.43478,
            "recall": 0.68452,
            "fmeasure": 0.5313
        },
        "rougeLsum": {
            "precision": 0.43478,
            "recall": 0.68452,
            "fmeasure": 0.5313
        },
        "nist": 2.0717595007788487,
        "bleu": 20.87037,
        "meteor": 0.33946067351840387,
        "bleurt": 0.09407,
        "nubia": {
            "semantic_relation": 3.15332,
            "contradiction": 0.123,
            "irrelevancy": 99.74367,
            "logical_agreement": 0.13334,
            "grammar_ref": 3.66146,
            "grammar_hyp": 3.22469,
            "nubia_score": 0.57974
        },
        "bertscore": {
            "precision": 0.87217,
            "recall": 0.92415,
            "f1": 0.89741
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "t5-small/totto_test",
        "N": 18,
        "total_length": 252,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.281744192888376,
        "median_pred_length": 12.5,
        "min_pred_length": 6,
        "max_pred_length": 22,
        "distinct-1": 0.6111111111111112,
        "vocab_size-1": 154,
        "unique-1": 120,
        "entropy-1": 6.699821207978975,
        "distinct-2": 0.9145299145299145,
        "vocab_size-2": 214,
        "unique-2": 201,
        "entropy-2": 7.660273867195656,
        "cond_entropy-2": 0.8113343919938376,
        "distinct-3": 0.9768518518518519,
        "vocab_size-3": 211,
        "unique-3": 206,
        "entropy-3": 7.708591205867166,
        "cond_entropy-3": 0.06582490970381497,
        "total_length-nopunct": 226,
        "mean_pred_length-nopunct": 12.555555555555555,
        "std_pred_length-nopunct": 4.462463472894045,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6637168141592921,
        "vocab_size-1-nopunct": 150,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.7785977834169815,
        "distinct-2-nopunct": 0.9086538461538461,
        "vocab_size-2-nopunct": 189,
        "unique-2-nopunct": 177,
        "entropy-2-nopunct": 7.473702893820252,
        "cond_entropy-2-nopunct": 0.7315403806943024,
        "distinct-3-nopunct": 0.9789473684210527,
        "vocab_size-3-nopunct": 186,
        "unique-3-nopunct": 182,
        "entropy-3-nopunct": 7.527750345173064,
        "cond_entropy-3-nopunct": 0.05665955838990328,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.755,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20408163265306123,
            "2": 0.44642857142857145,
            "3": 0.711764705882353
        },
        "rouge1": {
            "precision": 0.72631,
            "recall": 0.6576,
            "fmeasure": 0.68219
        },
        "rouge2": {
            "precision": 0.42751,
            "recall": 0.37802,
            "fmeasure": 0.39539
        },
        "rougeL": {
            "precision": 0.59371,
            "recall": 0.5351,
            "fmeasure": 0.55669
        },
        "rougeLsum": {
            "precision": 0.59371,
            "recall": 0.5351,
            "fmeasure": 0.55669
        },
        "nist": 5.488892585790222,
        "bleu": 34.84484,
        "meteor": 0.34228782051721285,
        "bleurt": 0.21918,
        "nubia": {
            "semantic_relation": 4.10088,
            "contradiction": 9.32797,
            "irrelevancy": 33.47603,
            "logical_agreement": 57.196,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.79415,
            "nubia_score": 0.69416
        },
        "bertscore": {
            "precision": 0.9222,
            "recall": 0.90789,
            "f1": 0.9136
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "t5-small/totto_test",
        "N": 10,
        "total_length": 175,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.296225070746145,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.4857142857142857,
        "vocab_size-1": 85,
        "unique-1": 55,
        "entropy-1": 5.917532203969754,
        "distinct-2": 0.696969696969697,
        "vocab_size-2": 115,
        "unique-2": 86,
        "entropy-2": 6.638207271897823,
        "cond_entropy-2": 0.6343225017335473,
        "distinct-3": 0.7612903225806451,
        "vocab_size-3": 118,
        "unique-3": 93,
        "entropy-3": 6.727611179411969,
        "cond_entropy-3": 0.11057261347205902,
        "total_length-nopunct": 159,
        "mean_pred_length-nopunct": 15.9,
        "std_pred_length-nopunct": 5.146843692983109,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5220125786163522,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.926758371158876,
        "distinct-2-nopunct": 0.6845637583892618,
        "vocab_size-2-nopunct": 102,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.453135195043259,
        "cond_entropy-2-nopunct": 0.5617881214718318,
        "distinct-3-nopunct": 0.7482014388489209,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.536066612229604,
        "cond_entropy-3-nopunct": 0.12365323915892674,
        "msttr-100": 0.61,
        "msttr-100_nopunct": 0.63,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4576271186440678,
            "2": 0.23076923076923078,
            "3": 0.5784313725490197
        },
        "rouge1": {
            "precision": 0.57007,
            "recall": 0.58668,
            "fmeasure": 0.56278
        },
        "rouge2": {
            "precision": 0.35229,
            "recall": 0.3747,
            "fmeasure": 0.35009
        },
        "rougeL": {
            "precision": 0.46276,
            "recall": 0.49127,
            "fmeasure": 0.46072
        },
        "rougeLsum": {
            "precision": 0.46276,
            "recall": 0.49127,
            "fmeasure": 0.46072
        },
        "nist": 4.185150434904263,
        "bleu": 25.40325,
        "meteor": 0.2877237243594009,
        "bleurt": -0.07642,
        "nubia": {
            "semantic_relation": 3.56065,
            "contradiction": 6.12463,
            "irrelevancy": 70.60282,
            "logical_agreement": 23.27255,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.37771,
            "nubia_score": 0.55601
        },
        "bertscore": {
            "precision": 0.88092,
            "recall": 0.87585,
            "f1": 0.87522
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "t5-small/totto_test",
        "N": 49,
        "total_length": 792,
        "mean_pred_length": 16.163265306122447,
        "std_pred_length": 4.756722155466571,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5391414141414141,
        "vocab_size-1": 427,
        "unique-1": 350,
        "entropy-1": 7.659987242733661,
        "distinct-2": 0.9057873485868102,
        "vocab_size-2": 673,
        "unique-2": 629,
        "entropy-2": 9.284033933803284,
        "cond_entropy-2": 1.4428930677863774,
        "distinct-3": 0.9769452449567724,
        "vocab_size-3": 678,
        "unique-3": 662,
        "entropy-3": 9.392682342491732,
        "cond_entropy-3": 0.11021052796107536,
        "total_length-nopunct": 675,
        "mean_pred_length-nopunct": 13.775510204081632,
        "std_pred_length-nopunct": 4.06711704604409,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6192592592592593,
        "vocab_size-1-nopunct": 418,
        "unique-1-nopunct": 349,
        "entropy-1-nopunct": 7.8706703210379105,
        "distinct-2-nopunct": 0.9185303514376997,
        "vocab_size-2-nopunct": 575,
        "unique-2-nopunct": 546,
        "entropy-2-nopunct": 9.055823505430867,
        "cond_entropy-2-nopunct": 1.264686015577897,
        "distinct-3-nopunct": 0.9844020797227037,
        "vocab_size-3-nopunct": 568,
        "unique-3-nopunct": 559,
        "entropy-3-nopunct": 9.141231668090757,
        "cond_entropy-3-nopunct": 0.09780615856751163,
        "msttr-100": 0.69429,
        "msttr-100_nopunct": 0.755,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26288659793814434,
            "2": 0.3583815028901734,
            "3": 0.7248576850094877
        },
        "rouge1": {
            "precision": 0.76846,
            "recall": 0.66286,
            "fmeasure": 0.70151
        },
        "rouge2": {
            "precision": 0.51484,
            "recall": 0.44135,
            "fmeasure": 0.46749
        },
        "rougeL": {
            "precision": 0.659,
            "recall": 0.56824,
            "fmeasure": 0.60133
        },
        "rougeLsum": {
            "precision": 0.659,
            "recall": 0.56824,
            "fmeasure": 0.60133
        },
        "nist": 6.526775818401208,
        "bleu": 42.19644,
        "meteor": 0.3608823058892242,
        "bleurt": 0.18983,
        "nubia": {
            "semantic_relation": 4.15379,
            "contradiction": 7.87008,
            "irrelevancy": 29.6674,
            "logical_agreement": 62.46252,
            "grammar_ref": 4.75318,
            "grammar_hyp": 5.06416,
            "nubia_score": 0.67232
        },
        "bertscore": {
            "precision": 0.93386,
            "recall": 0.90987,
            "f1": 0.92004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "t5-small/totto_test",
        "N": 18,
        "total_length": 269,
        "mean_pred_length": 14.944444444444445,
        "std_pred_length": 4.624478615923724,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 23,
        "distinct-1": 0.6245353159851301,
        "vocab_size-1": 168,
        "unique-1": 139,
        "entropy-1": 6.843708864080369,
        "distinct-2": 0.900398406374502,
        "vocab_size-2": 226,
        "unique-2": 209,
        "entropy-2": 7.7429217293083195,
        "cond_entropy-2": 0.8039141120961335,
        "distinct-3": 0.9527896995708155,
        "vocab_size-3": 222,
        "unique-3": 215,
        "entropy-3": 7.756806101698722,
        "cond_entropy-3": 0.018670607770462273,
        "total_length-nopunct": 243,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.763868642652151,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 162,
        "unique-1-nopunct": 137,
        "entropy-1-nopunct": 6.845690729643632,
        "distinct-2-nopunct": 0.8933333333333333,
        "vocab_size-2-nopunct": 201,
        "unique-2-nopunct": 185,
        "entropy-2-nopunct": 7.567629733504756,
        "cond_entropy-2-nopunct": 0.7764024124383812,
        "distinct-3-nopunct": 0.9468599033816425,
        "vocab_size-3-nopunct": 196,
        "unique-3-nopunct": 189,
        "entropy-3-nopunct": 7.572619566153144,
        "cond_entropy-3-nopunct": 0.021563389357651924,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2815533980582524,
            "2": 0.36363636363636365,
            "3": 0.6275510204081632
        },
        "rouge1": {
            "precision": 0.72047,
            "recall": 0.61171,
            "fmeasure": 0.6384
        },
        "rouge2": {
            "precision": 0.44905,
            "recall": 0.39319,
            "fmeasure": 0.40155
        },
        "rougeL": {
            "precision": 0.61007,
            "recall": 0.52929,
            "fmeasure": 0.54746
        },
        "rougeLsum": {
            "precision": 0.61007,
            "recall": 0.52929,
            "fmeasure": 0.54746
        },
        "nist": 5.059612152671837,
        "bleu": 35.32581,
        "meteor": 0.3194849987567239,
        "bleurt": -0.06183,
        "nubia": {
            "semantic_relation": 3.76918,
            "contradiction": 16.5844,
            "irrelevancy": 36.88101,
            "logical_agreement": 46.53459,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.91888,
            "nubia_score": 0.55027
        },
        "bertscore": {
            "precision": 0.90563,
            "recall": 0.88926,
            "f1": 0.89611
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "t5-small/totto_test",
        "N": 46,
        "total_length": 690,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.921116875704927,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5434782608695652,
        "vocab_size-1": 375,
        "unique-1": 300,
        "entropy-1": 7.587917293512777,
        "distinct-2": 0.9021739130434783,
        "vocab_size-2": 581,
        "unique-2": 543,
        "entropy-2": 9.090939646058711,
        "cond_entropy-2": 1.271359476859858,
        "distinct-3": 0.9782608695652174,
        "vocab_size-3": 585,
        "unique-3": 572,
        "entropy-3": 9.18052341332839,
        "cond_entropy-3": 0.0879766647189131,
        "total_length-nopunct": 596,
        "mean_pred_length-nopunct": 12.956521739130435,
        "std_pred_length-nopunct": 4.373619144763345,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6174496644295302,
        "vocab_size-1-nopunct": 368,
        "unique-1-nopunct": 298,
        "entropy-1-nopunct": 7.843244211408358,
        "distinct-2-nopunct": 0.9127272727272727,
        "vocab_size-2-nopunct": 502,
        "unique-2-nopunct": 472,
        "entropy-2-nopunct": 8.894389893885434,
        "cond_entropy-2-nopunct": 1.1154646810531779,
        "distinct-3-nopunct": 0.9821428571428571,
        "vocab_size-3-nopunct": 495,
        "unique-3-nopunct": 486,
        "entropy-3-nopunct": 8.941565637785562,
        "cond_entropy-3-nopunct": 0.0622735694323018,
        "msttr-100": 0.71167,
        "msttr-100_nopunct": 0.772,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17272727272727273,
            "2": 0.34306569343065696,
            "3": 0.6541501976284585
        },
        "rouge1": {
            "precision": 0.72307,
            "recall": 0.64278,
            "fmeasure": 0.66833
        },
        "rouge2": {
            "precision": 0.4882,
            "recall": 0.44254,
            "fmeasure": 0.45414
        },
        "rougeL": {
            "precision": 0.64664,
            "recall": 0.57938,
            "fmeasure": 0.59934
        },
        "rougeLsum": {
            "precision": 0.64664,
            "recall": 0.57938,
            "fmeasure": 0.59934
        },
        "nist": 5.56604643359403,
        "bleu": 35.56481,
        "meteor": 0.3355306736893097,
        "bleurt": 0.17214,
        "nubia": {
            "semantic_relation": 4.05082,
            "contradiction": 9.66686,
            "irrelevancy": 31.79758,
            "logical_agreement": 58.53555,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.76206,
            "nubia_score": 0.66658
        },
        "bertscore": {
            "precision": 0.91314,
            "recall": 0.8978,
            "f1": 0.90417
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "t5-small/totto_test",
        "N": 162,
        "total_length": 2329,
        "mean_pred_length": 14.376543209876543,
        "std_pred_length": 4.163354879549805,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.3340489480463718,
        "vocab_size-1": 778,
        "unique-1": 561,
        "entropy-1": 7.859519049344963,
        "distinct-2": 0.6972773419473927,
        "vocab_size-2": 1511,
        "unique-2": 1274,
        "entropy-2": 10.111813297615388,
        "cond_entropy-2": 1.9690623813585686,
        "distinct-3": 0.858354114713217,
        "vocab_size-3": 1721,
        "unique-3": 1592,
        "entropy-3": 10.552685843539738,
        "cond_entropy-3": 0.442540862355554,
        "total_length-nopunct": 2000,
        "mean_pred_length-nopunct": 12.345679012345679,
        "std_pred_length-nopunct": 3.65878106203827,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.3855,
        "vocab_size-1-nopunct": 771,
        "unique-1-nopunct": 560,
        "entropy-1-nopunct": 8.220571069667834,
        "distinct-2-nopunct": 0.733949945593036,
        "vocab_size-2-nopunct": 1349,
        "unique-2-nopunct": 1168,
        "entropy-2-nopunct": 9.984785164491639,
        "cond_entropy-2-nopunct": 1.8651023250233776,
        "distinct-3-nopunct": 0.8794749403341289,
        "vocab_size-3-nopunct": 1474,
        "unique-3-nopunct": 1382,
        "entropy-3-nopunct": 10.3553396976257,
        "cond_entropy-3-nopunct": 0.4046655124861971,
        "msttr-100": 0.68304,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1819571865443425,
            "2": 0.3393665158371041,
            "3": 0.7171010807374444
        },
        "rouge1": {
            "precision": 0.70975,
            "recall": 0.68448,
            "fmeasure": 0.68133
        },
        "rouge2": {
            "precision": 0.45229,
            "recall": 0.43401,
            "fmeasure": 0.43171
        },
        "rougeL": {
            "precision": 0.59099,
            "recall": 0.57038,
            "fmeasure": 0.56663
        },
        "rougeLsum": {
            "precision": 0.59099,
            "recall": 0.57038,
            "fmeasure": 0.56663
        },
        "nist": 7.1493935437974026,
        "bleu": 39.50706,
        "meteor": 0.3640984628752212,
        "bleurt": 0.20202,
        "nubia": {
            "semantic_relation": 4.004,
            "contradiction": 26.02051,
            "irrelevancy": 29.39728,
            "logical_agreement": 44.58221,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.47789,
            "nubia_score": 0.67614
        },
        "bertscore": {
            "precision": 0.91289,
            "recall": 0.91262,
            "f1": 0.91064
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 59,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 20.0,
        "min_pred_length": 18,
        "max_pred_length": 21,
        "distinct-1": 0.7627118644067796,
        "vocab_size-1": 45,
        "unique-1": 36,
        "entropy-1": 5.327475464579406,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 54,
        "unique-2": 52,
        "entropy-2": 5.735926350629038,
        "cond_entropy-2": 0.3846205780915388,
        "distinct-3": 1.0,
        "vocab_size-3": 53,
        "unique-3": 53,
        "entropy-3": 5.727920454563195,
        "cond_entropy-3": -0.003962769381197352,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8113207547169812,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.2985829545223755,
        "distinct-2-nopunct": 0.98,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.603856189774728,
        "cond_entropy-2-nopunct": 0.3110334852547947,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.04671414660772557,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.65,
            "2": 0.36363636363636365,
            "3": 0.59375
        },
        "rouge1": {
            "precision": 0.63019,
            "recall": 0.59433,
            "fmeasure": 0.60192
        },
        "rouge2": {
            "precision": 0.33987,
            "recall": 0.35221,
            "fmeasure": 0.33918
        },
        "rougeL": {
            "precision": 0.41411,
            "recall": 0.44379,
            "fmeasure": 0.41385
        },
        "rougeLsum": {
            "precision": 0.41411,
            "recall": 0.44379,
            "fmeasure": 0.41385
        },
        "nist": 4.045173345559795,
        "bleu": 25.51341,
        "meteor": 0.29076293442671797,
        "bleurt": -0.14306,
        "nubia": {
            "semantic_relation": 3.78795,
            "contradiction": 2.77248,
            "irrelevancy": 73.62256,
            "logical_agreement": 23.60496,
            "grammar_ref": 4.07664,
            "grammar_hyp": 3.44173,
            "nubia_score": 0.60699
        },
        "bertscore": {
            "precision": 0.89157,
            "recall": 0.89352,
            "f1": 0.88696
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "t5-small/totto_test",
        "N": 55,
        "total_length": 847,
        "mean_pred_length": 15.4,
        "std_pred_length": 4.845241339331163,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5478158205430933,
        "vocab_size-1": 464,
        "unique-1": 379,
        "entropy-1": 7.858248347389201,
        "distinct-2": 0.9040404040404041,
        "vocab_size-2": 716,
        "unique-2": 666,
        "entropy-2": 9.404824360030116,
        "cond_entropy-2": 1.3285687039634497,
        "distinct-3": 0.9701492537313433,
        "vocab_size-3": 715,
        "unique-3": 698,
        "entropy-3": 9.460697963083074,
        "cond_entropy-3": 0.05486211973901916,
        "total_length-nopunct": 723,
        "mean_pred_length-nopunct": 13.145454545454545,
        "std_pred_length-nopunct": 4.1050664121222065,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6307053941908713,
        "vocab_size-1-nopunct": 456,
        "unique-1-nopunct": 377,
        "entropy-1-nopunct": 8.123284150110369,
        "distinct-2-nopunct": 0.9236526946107785,
        "vocab_size-2-nopunct": 617,
        "unique-2-nopunct": 585,
        "entropy-2-nopunct": 9.201720928024015,
        "cond_entropy-2-nopunct": 1.1523719544003148,
        "distinct-3-nopunct": 0.9820554649265906,
        "vocab_size-3-nopunct": 602,
        "unique-3-nopunct": 594,
        "entropy-3-nopunct": 9.22015980120058,
        "cond_entropy-3-nopunct": 0.030550002938469253,
        "msttr-100": 0.74375,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23039215686274508,
            "2": 0.3333333333333333,
            "3": 0.7230483271375465
        },
        "rouge1": {
            "precision": 0.71792,
            "recall": 0.67147,
            "fmeasure": 0.68301
        },
        "rouge2": {
            "precision": 0.48052,
            "recall": 0.44327,
            "fmeasure": 0.45318
        },
        "rougeL": {
            "precision": 0.62795,
            "recall": 0.58766,
            "fmeasure": 0.59625
        },
        "rougeLsum": {
            "precision": 0.62795,
            "recall": 0.58766,
            "fmeasure": 0.59625
        },
        "nist": 6.47973890162206,
        "bleu": 40.71934,
        "meteor": 0.36448048467975136,
        "bleurt": 0.11501,
        "nubia": {
            "semantic_relation": 4.05586,
            "contradiction": 8.51338,
            "irrelevancy": 33.90622,
            "logical_agreement": 57.5804,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.93425,
            "nubia_score": 0.67389
        },
        "bertscore": {
            "precision": 0.91226,
            "recall": 0.90863,
            "f1": 0.90859
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "t5-small/totto_test",
        "N": 22,
        "total_length": 313,
        "mean_pred_length": 14.227272727272727,
        "std_pred_length": 4.177121868875508,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.5878594249201278,
        "vocab_size-1": 184,
        "unique-1": 150,
        "entropy-1": 6.759953394093999,
        "distinct-2": 0.9243986254295533,
        "vocab_size-2": 269,
        "unique-2": 253,
        "entropy-2": 8.008864068169887,
        "cond_entropy-2": 1.0441779389696728,
        "distinct-3": 0.9851301115241635,
        "vocab_size-3": 265,
        "unique-3": 261,
        "entropy-3": 8.041722585604923,
        "cond_entropy-3": 0.03238360310140199,
        "total_length-nopunct": 272,
        "mean_pred_length-nopunct": 12.363636363636363,
        "std_pred_length-nopunct": 3.6249821886139793,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6507352941176471,
        "vocab_size-1-nopunct": 177,
        "unique-1-nopunct": 148,
        "entropy-1-nopunct": 6.830320323210169,
        "distinct-2-nopunct": 0.932,
        "vocab_size-2-nopunct": 233,
        "unique-2-nopunct": 222,
        "entropy-2-nopunct": 7.800907160866605,
        "cond_entropy-2-nopunct": 1.0572153792439651,
        "distinct-3-nopunct": 0.9912280701754386,
        "vocab_size-3-nopunct": 226,
        "unique-3-nopunct": 224,
        "entropy-3-nopunct": 7.8153461545156535,
        "cond_entropy-3-nopunct": 0.02157625998017066,
        "msttr-100": 0.67333,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29333333333333333,
            "2": 0.45454545454545453,
            "3": 0.7119565217391305
        },
        "rouge1": {
            "precision": 0.69722,
            "recall": 0.70669,
            "fmeasure": 0.68735
        },
        "rouge2": {
            "precision": 0.4711,
            "recall": 0.46785,
            "fmeasure": 0.45818
        },
        "rougeL": {
            "precision": 0.61228,
            "recall": 0.60533,
            "fmeasure": 0.59349
        },
        "rougeLsum": {
            "precision": 0.61228,
            "recall": 0.60533,
            "fmeasure": 0.59349
        },
        "nist": 5.813843254418954,
        "bleu": 44.57986,
        "meteor": 0.37104792729891767,
        "bleurt": 0.13225,
        "nubia": {
            "semantic_relation": 4.09814,
            "contradiction": 7.38603,
            "irrelevancy": 29.60759,
            "logical_agreement": 63.00637,
            "grammar_ref": 5.03776,
            "grammar_hyp": 4.97465,
            "nubia_score": 0.69896
        },
        "bertscore": {
            "precision": 0.90815,
            "recall": 0.9057,
            "f1": 0.90552
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 70,
        "mean_pred_length": 14.0,
        "std_pred_length": 5.656854249492381,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.7571428571428571,
        "vocab_size-1": 53,
        "unique-1": 43,
        "entropy-1": 5.5540735525665355,
        "distinct-2": 0.9692307692307692,
        "vocab_size-2": 63,
        "unique-2": 61,
        "entropy-2": 5.960829351489997,
        "cond_entropy-2": 0.32792575772180177,
        "distinct-3": 0.9833333333333333,
        "vocab_size-3": 59,
        "unique-3": 58,
        "entropy-3": 5.873557262275184,
        "cond_entropy-3": -0.08214388408660253,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 11.8,
        "std_pred_length-nopunct": 4.578209256903839,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8135593220338984,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.471377583150135,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.680813428089393,
        "cond_entropy-2-nopunct": 0.24751598069959752,
        "distinct-3-nopunct": 0.9795918367346939,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.5738935175845965,
        "cond_entropy-3-nopunct": -0.09936133151764791,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09523809523809523,
            "2": 0.4,
            "3": 0.6956521739130435
        },
        "rouge1": {
            "precision": 0.74892,
            "recall": 0.73707,
            "fmeasure": 0.72415
        },
        "rouge2": {
            "precision": 0.52123,
            "recall": 0.52605,
            "fmeasure": 0.50992
        },
        "rougeL": {
            "precision": 0.67266,
            "recall": 0.72325,
            "fmeasure": 0.68865
        },
        "rougeLsum": {
            "precision": 0.67266,
            "recall": 0.72325,
            "fmeasure": 0.68865
        },
        "nist": 4.084353063784947,
        "bleu": 45.34675,
        "meteor": 0.33782047439280166,
        "bleurt": 0.30162,
        "nubia": {
            "semantic_relation": 4.05053,
            "contradiction": 3.5862,
            "irrelevancy": 30.5875,
            "logical_agreement": 65.8263,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.90959,
            "nubia_score": 0.67684
        },
        "bertscore": {
            "precision": 0.92724,
            "recall": 0.935,
            "f1": 0.92854
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "t5-small/totto_test",
        "N": 21,
        "total_length": 285,
        "mean_pred_length": 13.571428571428571,
        "std_pred_length": 4.634974994245266,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6035087719298246,
        "vocab_size-1": 172,
        "unique-1": 137,
        "entropy-1": 6.8499161634116,
        "distinct-2": 0.9242424242424242,
        "vocab_size-2": 244,
        "unique-2": 235,
        "entropy-2": 7.846141481374988,
        "cond_entropy-2": 0.7943022804748388,
        "distinct-3": 0.9794238683127572,
        "vocab_size-3": 238,
        "unique-3": 236,
        "entropy-3": 7.868805752682152,
        "cond_entropy-3": -0.0079790829182541,
        "total_length-nopunct": 245,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 4.003966287538649,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6816326530612244,
        "vocab_size-1-nopunct": 167,
        "unique-1-nopunct": 137,
        "entropy-1-nopunct": 6.978400567694389,
        "distinct-2-nopunct": 0.9330357142857143,
        "vocab_size-2-nopunct": 209,
        "unique-2-nopunct": 202,
        "entropy-2-nopunct": 7.634457350837925,
        "cond_entropy-2-nopunct": 0.6717413560142819,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 203,
        "unique-3-nopunct": 203,
        "entropy-3-nopunct": 7.665335917185182,
        "cond_entropy-3-nopunct": -0.013351933548468508,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2318840579710145,
            "2": 0.2830188679245283,
            "3": 0.7712765957446809
        },
        "rouge1": {
            "precision": 0.75492,
            "recall": 0.71447,
            "fmeasure": 0.72658
        },
        "rouge2": {
            "precision": 0.50157,
            "recall": 0.47624,
            "fmeasure": 0.48397
        },
        "rougeL": {
            "precision": 0.65181,
            "recall": 0.61201,
            "fmeasure": 0.62499
        },
        "rougeLsum": {
            "precision": 0.65181,
            "recall": 0.61201,
            "fmeasure": 0.62499
        },
        "nist": 5.541847823724266,
        "bleu": 36.89131,
        "meteor": 0.3532928475757814,
        "bleurt": 0.18191,
        "nubia": {
            "semantic_relation": 4.11877,
            "contradiction": 7.13928,
            "irrelevancy": 41.9591,
            "logical_agreement": 50.90163,
            "grammar_ref": 4.80447,
            "grammar_hyp": 4.94026,
            "nubia_score": 0.69352
        },
        "bertscore": {
            "precision": 0.92296,
            "recall": 0.91294,
            "f1": 0.91706
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "t5-small/totto_test",
        "N": 47,
        "total_length": 792,
        "mean_pred_length": 16.851063829787233,
        "std_pred_length": 4.307236480889892,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5290404040404041,
        "vocab_size-1": 419,
        "unique-1": 327,
        "entropy-1": 7.691269641864369,
        "distinct-2": 0.8832214765100671,
        "vocab_size-2": 658,
        "unique-2": 599,
        "entropy-2": 9.254030194057044,
        "cond_entropy-2": 1.3969660313416703,
        "distinct-3": 0.9527220630372493,
        "vocab_size-3": 665,
        "unique-3": 634,
        "entropy-3": 9.349662022771192,
        "cond_entropy-3": 0.1052088586264765,
        "total_length-nopunct": 703,
        "mean_pred_length-nopunct": 14.957446808510639,
        "std_pred_length-nopunct": 3.9677285790434174,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5889046941678521,
        "vocab_size-1-nopunct": 414,
        "unique-1-nopunct": 327,
        "entropy-1-nopunct": 7.8753779841095755,
        "distinct-2-nopunct": 0.8887195121951219,
        "vocab_size-2-nopunct": 583,
        "unique-2-nopunct": 534,
        "entropy-2-nopunct": 9.080875242596173,
        "cond_entropy-2-nopunct": 1.2527379326097903,
        "distinct-3-nopunct": 0.9573070607553367,
        "vocab_size-3-nopunct": 583,
        "unique-3-nopunct": 557,
        "entropy-3-nopunct": 9.164912539417099,
        "cond_entropy-3-nopunct": 0.08832545838445494,
        "msttr-100": 0.72143,
        "msttr-100_nopunct": 0.76571,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.265625,
            "2": 0.3643410852713178,
            "3": 0.7236363636363636
        },
        "rouge1": {
            "precision": 0.73126,
            "recall": 0.69367,
            "fmeasure": 0.7016
        },
        "rouge2": {
            "precision": 0.52521,
            "recall": 0.49425,
            "fmeasure": 0.50129
        },
        "rougeL": {
            "precision": 0.64363,
            "recall": 0.61277,
            "fmeasure": 0.61821
        },
        "rougeLsum": {
            "precision": 0.64363,
            "recall": 0.61277,
            "fmeasure": 0.61821
        },
        "nist": 6.540228324605479,
        "bleu": 45.32093,
        "meteor": 0.38247906095168716,
        "bleurt": 0.17668,
        "nubia": {
            "semantic_relation": 4.09005,
            "contradiction": 9.05124,
            "irrelevancy": 31.3947,
            "logical_agreement": 59.55406,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.40554,
            "nubia_score": 0.69845
        },
        "bertscore": {
            "precision": 0.91999,
            "recall": 0.9105,
            "f1": 0.91346
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 8.5,
        "median_pred_length": 18.5,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.7297297297297297,
        "vocab_size-1": 27,
        "unique-1": 20,
        "entropy-1": 4.607705730318401,
        "distinct-2": 0.9142857142857143,
        "vocab_size-2": 32,
        "unique-2": 29,
        "entropy-2": 4.957854445516392,
        "cond_entropy-2": 0.3559628657871713,
        "distinct-3": 0.9393939393939394,
        "vocab_size-3": 31,
        "unique-3": 29,
        "entropy-3": 4.923181998146335,
        "cond_entropy-3": -0.024282836980452655,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8214285714285714,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.423251796980338,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.2682727769359289,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.7407407407407407
        },
        "rouge1": {
            "precision": 0.86257,
            "recall": 0.68791,
            "fmeasure": 0.76275
        },
        "rouge2": {
            "precision": 0.65741,
            "recall": 0.50864,
            "fmeasure": 0.57156
        },
        "rougeL": {
            "precision": 0.82749,
            "recall": 0.70358,
            "fmeasure": 0.75789
        },
        "rougeLsum": {
            "precision": 0.82749,
            "recall": 0.70358,
            "fmeasure": 0.75789
        },
        "nist": 3.639246943292931,
        "bleu": 65.84422,
        "meteor": 0.37588320353823884,
        "bleurt": 0.24452,
        "nubia": {
            "semantic_relation": 4.08378,
            "contradiction": 0.77564,
            "irrelevancy": 1.37537,
            "logical_agreement": 97.849,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.82091,
            "nubia_score": 0.6747
        },
        "bertscore": {
            "precision": 0.96139,
            "recall": 0.89952,
            "f1": 0.92791
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "t5-small/totto_test",
        "N": 28,
        "total_length": 427,
        "mean_pred_length": 15.25,
        "std_pred_length": 4.041083659472684,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6088992974238876,
        "vocab_size-1": 260,
        "unique-1": 219,
        "entropy-1": 7.264904651599901,
        "distinct-2": 0.9323308270676691,
        "vocab_size-2": 372,
        "unique-2": 355,
        "entropy-2": 8.47289932235473,
        "cond_entropy-2": 1.048113287384618,
        "distinct-3": 0.9892183288409704,
        "vocab_size-3": 367,
        "unique-3": 363,
        "entropy-3": 8.513712034302674,
        "cond_entropy-3": 0.05344256959836863,
        "total_length-nopunct": 377,
        "mean_pred_length-nopunct": 13.464285714285714,
        "std_pred_length-nopunct": 3.6886132010470787,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6790450928381963,
        "vocab_size-1-nopunct": 256,
        "unique-1-nopunct": 217,
        "entropy-1-nopunct": 7.473771432390342,
        "distinct-2-nopunct": 0.9340974212034384,
        "vocab_size-2-nopunct": 326,
        "unique-2-nopunct": 312,
        "entropy-2-nopunct": 8.280848233570708,
        "cond_entropy-2-nopunct": 0.8780946159765028,
        "distinct-3-nopunct": 0.9875389408099688,
        "vocab_size-3-nopunct": 317,
        "unique-3-nopunct": 313,
        "entropy-3-nopunct": 8.301507368742193,
        "cond_entropy-3-nopunct": 0.03515938375066814,
        "msttr-100": 0.755,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1282051282051282,
            "2": 0.4666666666666667,
            "3": 0.6081871345029239
        },
        "rouge1": {
            "precision": 0.72592,
            "recall": 0.59771,
            "fmeasure": 0.64219
        },
        "rouge2": {
            "precision": 0.4847,
            "recall": 0.39707,
            "fmeasure": 0.42752
        },
        "rougeL": {
            "precision": 0.6212,
            "recall": 0.51607,
            "fmeasure": 0.55156
        },
        "rougeLsum": {
            "precision": 0.6212,
            "recall": 0.51607,
            "fmeasure": 0.55156
        },
        "nist": 4.932730710812976,
        "bleu": 34.51011,
        "meteor": 0.331948943693004,
        "bleurt": 0.07781,
        "nubia": {
            "semantic_relation": 3.86617,
            "contradiction": 4.45436,
            "irrelevancy": 35.86098,
            "logical_agreement": 59.68466,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.67971,
            "nubia_score": 0.62816
        },
        "bertscore": {
            "precision": 0.90483,
            "recall": 0.88409,
            "f1": 0.89166
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "t5-small/totto_test",
        "N": 11,
        "total_length": 158,
        "mean_pred_length": 14.363636363636363,
        "std_pred_length": 3.6499745272517696,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.6139240506329114,
        "vocab_size-1": 97,
        "unique-1": 78,
        "entropy-1": 6.0455517555662555,
        "distinct-2": 0.9115646258503401,
        "vocab_size-2": 134,
        "unique-2": 123,
        "entropy-2": 7.009196154360164,
        "cond_entropy-2": 0.8637205478125578,
        "distinct-3": 0.9779411764705882,
        "vocab_size-3": 133,
        "unique-3": 130,
        "entropy-3": 7.043345194191504,
        "cond_entropy-3": 0.04955520229632819,
        "total_length-nopunct": 141,
        "mean_pred_length-nopunct": 12.818181818181818,
        "std_pred_length-nopunct": 3.5628941713209863,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6595744680851063,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.028478903142768,
        "distinct-2-nopunct": 0.9076923076923077,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 108,
        "entropy-2-nopunct": 6.822367813028456,
        "cond_entropy-2-nopunct": 0.8725181171304115,
        "distinct-3-nopunct": 0.9747899159663865,
        "vocab_size-3-nopunct": 116,
        "unique-3-nopunct": 113,
        "entropy-3-nopunct": 6.844397595240715,
        "cond_entropy-3-nopunct": 0.03211381582570766,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24074074074074073,
            "2": 0.41935483870967744,
            "3": 0.7282608695652174
        },
        "rouge1": {
            "precision": 0.67922,
            "recall": 0.68375,
            "fmeasure": 0.66756
        },
        "rouge2": {
            "precision": 0.45602,
            "recall": 0.47388,
            "fmeasure": 0.45398
        },
        "rougeL": {
            "precision": 0.57711,
            "recall": 0.61111,
            "fmeasure": 0.58425
        },
        "rougeLsum": {
            "precision": 0.57711,
            "recall": 0.61111,
            "fmeasure": 0.58425
        },
        "nist": 5.424983056487964,
        "bleu": 45.19188,
        "meteor": 0.37815618335848494,
        "bleurt": 0.04282,
        "nubia": {
            "semantic_relation": 3.7844,
            "contradiction": 18.77763,
            "irrelevancy": 41.78779,
            "logical_agreement": 39.43458,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.49735,
            "nubia_score": 0.61631
        },
        "bertscore": {
            "precision": 0.91779,
            "recall": 0.91653,
            "f1": 0.91504
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "t5-small/totto_test",
        "N": 37,
        "total_length": 583,
        "mean_pred_length": 15.756756756756756,
        "std_pred_length": 4.395362454109432,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5660377358490566,
        "vocab_size-1": 330,
        "unique-1": 265,
        "entropy-1": 7.493883959619738,
        "distinct-2": 0.8937728937728938,
        "vocab_size-2": 488,
        "unique-2": 459,
        "entropy-2": 8.811762309413341,
        "cond_entropy-2": 1.1407494066679822,
        "distinct-3": 0.9646365422396856,
        "vocab_size-3": 491,
        "unique-3": 478,
        "entropy-3": 8.91145330481414,
        "cond_entropy-3": 0.10881068354137345,
        "total_length-nopunct": 518,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.337143162360543,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6254826254826255,
        "vocab_size-1-nopunct": 324,
        "unique-1-nopunct": 263,
        "entropy-1-nopunct": 7.661614046528913,
        "distinct-2-nopunct": 0.8835758835758836,
        "vocab_size-2-nopunct": 425,
        "unique-2-nopunct": 397,
        "entropy-2-nopunct": 8.600811398738017,
        "cond_entropy-2-nopunct": 1.015107602318731,
        "distinct-3-nopunct": 0.9617117117117117,
        "vocab_size-3-nopunct": 427,
        "unique-3-nopunct": 415,
        "entropy-3-nopunct": 8.707130083687595,
        "cond_entropy-3-nopunct": 0.12757098753104482,
        "msttr-100": 0.724,
        "msttr-100_nopunct": 0.788,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3014705882352941,
            "2": 0.336734693877551,
            "3": 0.6714975845410628
        },
        "rouge1": {
            "precision": 0.72671,
            "recall": 0.67136,
            "fmeasure": 0.67981
        },
        "rouge2": {
            "precision": 0.51098,
            "recall": 0.46936,
            "fmeasure": 0.47383
        },
        "rougeL": {
            "precision": 0.60822,
            "recall": 0.56626,
            "fmeasure": 0.57032
        },
        "rougeLsum": {
            "precision": 0.60822,
            "recall": 0.56626,
            "fmeasure": 0.57032
        },
        "nist": 6.045637293572067,
        "bleu": 37.99281,
        "meteor": 0.3501872749093019,
        "bleurt": -0.00363,
        "nubia": {
            "semantic_relation": 3.8504,
            "contradiction": 8.25491,
            "irrelevancy": 39.66943,
            "logical_agreement": 52.07566,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.75343,
            "nubia_score": 0.62212
        },
        "bertscore": {
            "precision": 0.90702,
            "recall": 0.89793,
            "f1": 0.90099
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "t5-small/totto_test",
        "N": 36,
        "total_length": 573,
        "mean_pred_length": 15.916666666666666,
        "std_pred_length": 3.817903729651769,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 23,
        "distinct-1": 0.4118673647469459,
        "vocab_size-1": 236,
        "unique-1": 186,
        "entropy-1": 6.772108617353542,
        "distinct-2": 0.7113594040968343,
        "vocab_size-2": 382,
        "unique-2": 323,
        "entropy-2": 8.25693713025997,
        "cond_entropy-2": 1.3725553232103043,
        "distinct-3": 0.8403193612774451,
        "vocab_size-3": 421,
        "unique-3": 381,
        "entropy-3": 8.562150320295437,
        "cond_entropy-3": 0.338090223600364,
        "total_length-nopunct": 489,
        "mean_pred_length-nopunct": 13.583333333333334,
        "std_pred_length-nopunct": 3.4186985827943355,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.4703476482617587,
        "vocab_size-1-nopunct": 230,
        "unique-1-nopunct": 185,
        "entropy-1-nopunct": 6.845448236678755,
        "distinct-2-nopunct": 0.7373068432671082,
        "vocab_size-2-nopunct": 334,
        "unique-2-nopunct": 287,
        "entropy-2-nopunct": 8.104980106899232,
        "cond_entropy-2-nopunct": 1.365529822733508,
        "distinct-3-nopunct": 0.8489208633093526,
        "vocab_size-3-nopunct": 354,
        "unique-3-nopunct": 323,
        "entropy-3-nopunct": 8.324038758111511,
        "cond_entropy-3-nopunct": 0.2491306145178774,
        "msttr-100": 0.622,
        "msttr-100_nopunct": 0.655,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30701754385964913,
            "2": 0.46226415094339623,
            "3": 0.6979472140762464
        },
        "rouge1": {
            "precision": 0.70754,
            "recall": 0.68576,
            "fmeasure": 0.68879
        },
        "rouge2": {
            "precision": 0.47,
            "recall": 0.45539,
            "fmeasure": 0.45707
        },
        "rougeL": {
            "precision": 0.60998,
            "recall": 0.5887,
            "fmeasure": 0.59215
        },
        "rougeLsum": {
            "precision": 0.60998,
            "recall": 0.5887,
            "fmeasure": 0.59215
        },
        "nist": 6.093174550842521,
        "bleu": 41.65489,
        "meteor": 0.3606995799919293,
        "bleurt": 0.26571,
        "nubia": {
            "semantic_relation": 3.93196,
            "contradiction": 7.69122,
            "irrelevancy": 32.51062,
            "logical_agreement": 59.79816,
            "grammar_ref": 3.9304,
            "grammar_hyp": 4.02158,
            "nubia_score": 0.70019
        },
        "bertscore": {
            "precision": 0.91862,
            "recall": 0.91792,
            "f1": 0.91683
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 110,
        "mean_pred_length": 15.714285714285714,
        "std_pred_length": 5.364280958719597,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.6181818181818182,
        "vocab_size-1": 68,
        "unique-1": 48,
        "entropy-1": 5.773996077611256,
        "distinct-2": 0.8640776699029126,
        "vocab_size-2": 89,
        "unique-2": 76,
        "entropy-2": 6.407326862113682,
        "cond_entropy-2": 0.5307075645061515,
        "distinct-3": 0.9166666666666666,
        "vocab_size-3": 88,
        "unique-3": 80,
        "entropy-3": 6.418295834054494,
        "cond_entropy-3": 0.03132538501880715,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 13.142857142857142,
        "std_pred_length-nopunct": 4.703450752329808,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6847826086956522,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.752976597474616,
        "distinct-2-nopunct": 0.8705882352941177,
        "vocab_size-2-nopunct": 74,
        "unique-2-nopunct": 64,
        "entropy-2-nopunct": 6.141686377288724,
        "cond_entropy-2-nopunct": 0.4099937211006477,
        "distinct-3-nopunct": 0.9358974358974359,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.157197090657125,
        "cond_entropy-3-nopunct": 0.02671496864971941,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1724137931034483,
            "2": 0.6521739130434783,
            "3": 0.5263157894736842
        },
        "rouge1": {
            "precision": 0.61608,
            "recall": 0.61752,
            "fmeasure": 0.60837
        },
        "rouge2": {
            "precision": 0.34384,
            "recall": 0.37533,
            "fmeasure": 0.35113
        },
        "rougeL": {
            "precision": 0.49841,
            "recall": 0.51398,
            "fmeasure": 0.49783
        },
        "rougeLsum": {
            "precision": 0.49841,
            "recall": 0.51398,
            "fmeasure": 0.49783
        },
        "nist": 3.954529495134781,
        "bleu": 29.02183,
        "meteor": 0.2820422091911295,
        "bleurt": 0.06126,
        "nubia": {
            "semantic_relation": 3.61759,
            "contradiction": 16.34016,
            "irrelevancy": 52.19532,
            "logical_agreement": 31.46453,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.32657,
            "nubia_score": 0.60327
        },
        "bertscore": {
            "precision": 0.89846,
            "recall": 0.90033,
            "f1": 0.89143
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "t5-small/totto_test",
        "N": 20,
        "total_length": 303,
        "mean_pred_length": 15.15,
        "std_pred_length": 5.1310330343898585,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.6204620462046204,
        "vocab_size-1": 188,
        "unique-1": 149,
        "entropy-1": 6.988634844857578,
        "distinct-2": 0.9222614840989399,
        "vocab_size-2": 261,
        "unique-2": 246,
        "entropy-2": 7.970509082000963,
        "cond_entropy-2": 0.8249976098326255,
        "distinct-3": 0.9543726235741445,
        "vocab_size-3": 251,
        "unique-3": 242,
        "entropy-3": 7.939053352385519,
        "cond_entropy-3": -0.01821244742302526,
        "total_length-nopunct": 265,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 4.459540335056967,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.690566037735849,
        "vocab_size-1-nopunct": 183,
        "unique-1-nopunct": 149,
        "entropy-1-nopunct": 7.102591948095665,
        "distinct-2-nopunct": 0.9224489795918367,
        "vocab_size-2-nopunct": 226,
        "unique-2-nopunct": 213,
        "entropy-2-nopunct": 7.763048857316962,
        "cond_entropy-2-nopunct": 0.72145744810735,
        "distinct-3-nopunct": 0.9511111111111111,
        "vocab_size-3-nopunct": 214,
        "unique-3-nopunct": 206,
        "entropy-3-nopunct": 7.705938246743706,
        "cond_entropy-3-nopunct": -0.04612491442335356,
        "msttr-100": 0.74333,
        "msttr-100_nopunct": 0.785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13725490196078433,
            "2": 0.42592592592592593,
            "3": 0.7955555555555556
        },
        "rouge1": {
            "precision": 0.80494,
            "recall": 0.74638,
            "fmeasure": 0.76456
        },
        "rouge2": {
            "precision": 0.6234,
            "recall": 0.59368,
            "fmeasure": 0.60183
        },
        "rougeL": {
            "precision": 0.68874,
            "recall": 0.64027,
            "fmeasure": 0.65388
        },
        "rougeLsum": {
            "precision": 0.68874,
            "recall": 0.64027,
            "fmeasure": 0.65388
        },
        "nist": 5.781467835644025,
        "bleu": 51.10127,
        "meteor": 0.41047699205744503,
        "bleurt": 0.32453,
        "nubia": {
            "semantic_relation": 4.2675,
            "contradiction": 3.09816,
            "irrelevancy": 29.23576,
            "logical_agreement": 67.66608,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.76666,
            "nubia_score": 0.74611
        },
        "bertscore": {
            "precision": 0.94042,
            "recall": 0.93236,
            "f1": 0.93586
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "t5-small/totto_test",
        "N": 31,
        "total_length": 496,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.614143753790638,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.6209677419354839,
        "vocab_size-1": 308,
        "unique-1": 261,
        "entropy-1": 7.575409531000291,
        "distinct-2": 0.9139784946236559,
        "vocab_size-2": 425,
        "unique-2": 400,
        "entropy-2": 8.656529023245296,
        "cond_entropy-2": 0.9007223204272163,
        "distinct-3": 0.9723502304147466,
        "vocab_size-3": 422,
        "unique-3": 412,
        "entropy-3": 8.70164339834305,
        "cond_entropy-3": 0.059725652437021354,
        "total_length-nopunct": 430,
        "mean_pred_length-nopunct": 13.870967741935484,
        "std_pred_length-nopunct": 3.4616976581409844,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 301,
        "unique-1-nopunct": 258,
        "entropy-1-nopunct": 7.763590570600244,
        "distinct-2-nopunct": 0.9273182957393483,
        "vocab_size-2-nopunct": 370,
        "unique-2-nopunct": 352,
        "entropy-2-nopunct": 8.467013318481056,
        "cond_entropy-2-nopunct": 0.7544321354678947,
        "distinct-3-nopunct": 0.9864130434782609,
        "vocab_size-3-nopunct": 363,
        "unique-3-nopunct": 358,
        "entropy-3-nopunct": 8.496388043013608,
        "cond_entropy-3-nopunct": 0.036943250753260576,
        "msttr-100": 0.7625,
        "msttr-100_nopunct": 0.8225,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22123893805309736,
            "2": 0.3469387755102041,
            "3": 0.7575757575757576
        },
        "rouge1": {
            "precision": 0.8065,
            "recall": 0.73747,
            "fmeasure": 0.75817
        },
        "rouge2": {
            "precision": 0.60057,
            "recall": 0.542,
            "fmeasure": 0.56161
        },
        "rougeL": {
            "precision": 0.70125,
            "recall": 0.64732,
            "fmeasure": 0.66389
        },
        "rougeLsum": {
            "precision": 0.70125,
            "recall": 0.64732,
            "fmeasure": 0.66389
        },
        "nist": 6.558684794049748,
        "bleu": 51.36373,
        "meteor": 0.40594596157379775,
        "bleurt": 0.31525,
        "nubia": {
            "semantic_relation": 4.22623,
            "contradiction": 12.24577,
            "irrelevancy": 16.76733,
            "logical_agreement": 70.9869,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.9232,
            "nubia_score": 0.71913
        },
        "bertscore": {
            "precision": 0.93901,
            "recall": 0.92643,
            "f1": 0.93193
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "t5-small/totto_test",
        "N": 17,
        "total_length": 272,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.698296959205805,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5808823529411765,
        "vocab_size-1": 158,
        "unique-1": 124,
        "entropy-1": 6.657952130483821,
        "distinct-2": 0.9176470588235294,
        "vocab_size-2": 234,
        "unique-2": 219,
        "entropy-2": 7.802119907413168,
        "cond_entropy-2": 1.0498940670449852,
        "distinct-3": 0.9621848739495799,
        "vocab_size-3": 229,
        "unique-3": 222,
        "entropy-3": 7.812843918751993,
        "cond_entropy-3": 0.016051616383232645,
        "total_length-nopunct": 222,
        "mean_pred_length-nopunct": 13.058823529411764,
        "std_pred_length-nopunct": 3.7175353668999906,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6891891891891891,
        "vocab_size-1-nopunct": 153,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.846063007944887,
        "distinct-2-nopunct": 0.9609756097560975,
        "vocab_size-2-nopunct": 197,
        "unique-2-nopunct": 189,
        "entropy-2-nopunct": 7.601431319017627,
        "cond_entropy-2-nopunct": 0.8096219627453752,
        "distinct-3-nopunct": 0.9893617021276596,
        "vocab_size-3-nopunct": 186,
        "unique-3-nopunct": 184,
        "entropy-3-nopunct": 7.5333122559329775,
        "cond_entropy-3-nopunct": -0.07701890740227695,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.020833333333333332,
            "2": 0.25,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.80473,
            "recall": 0.71479,
            "fmeasure": 0.74889
        },
        "rouge2": {
            "precision": 0.56833,
            "recall": 0.48752,
            "fmeasure": 0.51806
        },
        "rougeL": {
            "precision": 0.72155,
            "recall": 0.63322,
            "fmeasure": 0.66663
        },
        "rougeLsum": {
            "precision": 0.72155,
            "recall": 0.63322,
            "fmeasure": 0.66663
        },
        "nist": 5.3293984190977115,
        "bleu": 45.68219,
        "meteor": 0.3892579516738655,
        "bleurt": 0.29965,
        "nubia": {
            "semantic_relation": 4.1908,
            "contradiction": 11.98372,
            "irrelevancy": 14.65184,
            "logical_agreement": 73.36444,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.75925,
            "nubia_score": 0.68938
        },
        "bertscore": {
            "precision": 0.93542,
            "recall": 0.91622,
            "f1": 0.92495
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 136,
        "mean_pred_length": 17.0,
        "std_pred_length": 6.837397165588672,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.6397058823529411,
        "vocab_size-1": 87,
        "unique-1": 68,
        "entropy-1": 6.027499768320772,
        "distinct-2": 0.9296875,
        "vocab_size-2": 119,
        "unique-2": 110,
        "entropy-2": 6.859375,
        "cond_entropy-2": 0.7567577869791363,
        "distinct-3": 0.9583333333333334,
        "vocab_size-3": 115,
        "unique-3": 110,
        "entropy-3": 6.823557262275198,
        "cond_entropy-3": -0.03477607105814813,
        "total_length-nopunct": 117,
        "mean_pred_length-nopunct": 14.625,
        "std_pred_length-nopunct": 5.829611908180509,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7094017094017094,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.033695357088263,
        "distinct-2-nopunct": 0.9357798165137615,
        "vocab_size-2-nopunct": 102,
        "unique-2-nopunct": 95,
        "entropy-2-nopunct": 6.63974395780444,
        "cond_entropy-2-nopunct": 0.6582812144772903,
        "distinct-3-nopunct": 0.9603960396039604,
        "vocab_size-3-nopunct": 97,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.579003561959703,
        "cond_entropy-3-nopunct": -0.060467891530082016,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.5641025641025641,
            "3": 0.5747126436781609
        },
        "rouge1": {
            "precision": 0.77447,
            "recall": 0.62522,
            "fmeasure": 0.67031
        },
        "rouge2": {
            "precision": 0.51676,
            "recall": 0.40641,
            "fmeasure": 0.43884
        },
        "rougeL": {
            "precision": 0.66342,
            "recall": 0.53494,
            "fmeasure": 0.57537
        },
        "rougeLsum": {
            "precision": 0.66342,
            "recall": 0.53494,
            "fmeasure": 0.57537
        },
        "nist": 3.8321767477798,
        "bleu": 22.68729,
        "meteor": 0.30388072631384166,
        "bleurt": -0.02833,
        "nubia": {
            "semantic_relation": 3.69761,
            "contradiction": 13.19467,
            "irrelevancy": 24.26259,
            "logical_agreement": 62.54274,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.84663,
            "nubia_score": 0.51941
        },
        "bertscore": {
            "precision": 0.9153,
            "recall": 0.88644,
            "f1": 0.89965
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 82,
        "mean_pred_length": 11.714285714285714,
        "std_pred_length": 4.025429372458677,
        "median_pred_length": 12.0,
        "min_pred_length": 4,
        "max_pred_length": 16,
        "distinct-1": 0.7560975609756098,
        "vocab_size-1": 62,
        "unique-1": 50,
        "entropy-1": 5.759752614268647,
        "distinct-2": 0.9733333333333334,
        "vocab_size-2": 73,
        "unique-2": 71,
        "entropy-2": 6.175485357162557,
        "cond_entropy-2": 0.25139701926882313,
        "distinct-3": 0.9852941176470589,
        "vocab_size-3": 67,
        "unique-3": 66,
        "entropy-3": 6.058051076544463,
        "cond_entropy-3": -0.11194408453965912,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 3.5456210417116734,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8285714285714286,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.747070338342635,
        "distinct-2-nopunct": 0.9841269841269841,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.945533891753889,
        "cond_entropy-2-nopunct": 0.2250586129384972,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 56,
        "entropy-3-nopunct": 5.807354922057609,
        "cond_entropy-3-nopunct": -0.13421071572802676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1794871794871795,
            "2": 0.2777777777777778,
            "3": 0.6190476190476191
        },
        "rouge1": {
            "precision": 0.65064,
            "recall": 0.58118,
            "fmeasure": 0.59892
        },
        "rouge2": {
            "precision": 0.40363,
            "recall": 0.39328,
            "fmeasure": 0.39528
        },
        "rougeL": {
            "precision": 0.59643,
            "recall": 0.52721,
            "fmeasure": 0.54516
        },
        "rougeLsum": {
            "precision": 0.59643,
            "recall": 0.52721,
            "fmeasure": 0.54516
        },
        "nist": 4.160250724207038,
        "bleu": 32.68973,
        "meteor": 0.31987989028065816,
        "bleurt": -0.01939,
        "nubia": {
            "semantic_relation": 3.95623,
            "contradiction": 20.79836,
            "irrelevancy": 28.78618,
            "logical_agreement": 50.41547,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.37751,
            "nubia_score": 0.66846
        },
        "bertscore": {
            "precision": 0.91214,
            "recall": 0.90157,
            "f1": 0.90544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "t5-small/totto_test",
        "N": 15,
        "total_length": 240,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.718756898449704,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6208333333333333,
        "vocab_size-1": 149,
        "unique-1": 117,
        "entropy-1": 6.69029332845237,
        "distinct-2": 0.9422222222222222,
        "vocab_size-2": 212,
        "unique-2": 202,
        "entropy-2": 7.68598169120738,
        "cond_entropy-2": 0.8785525694127114,
        "distinct-3": 0.9857142857142858,
        "vocab_size-3": 207,
        "unique-3": 204,
        "entropy-3": 7.6856740890946815,
        "cond_entropy-3": 0.004059028840339964,
        "total_length-nopunct": 219,
        "mean_pred_length-nopunct": 14.6,
        "std_pred_length-nopunct": 5.043808085167396,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6712328767123288,
        "vocab_size-1-nopunct": 147,
        "unique-1-nopunct": 117,
        "entropy-1-nopunct": 6.768236972405527,
        "distinct-2-nopunct": 0.9362745098039216,
        "vocab_size-2-nopunct": 191,
        "unique-2-nopunct": 181,
        "entropy-2-nopunct": 7.531470011078539,
        "cond_entropy-2-nopunct": 0.8196707289044511,
        "distinct-3-nopunct": 0.9841269841269841,
        "vocab_size-3-nopunct": 186,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.53049639247505,
        "cond_entropy-3-nopunct": 0.004922307128748937,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.2692307692307692,
            "3": 0.765625
        },
        "rouge1": {
            "precision": 0.83111,
            "recall": 0.72745,
            "fmeasure": 0.76604
        },
        "rouge2": {
            "precision": 0.60623,
            "recall": 0.54245,
            "fmeasure": 0.5654
        },
        "rougeL": {
            "precision": 0.75383,
            "recall": 0.6637,
            "fmeasure": 0.69678
        },
        "rougeLsum": {
            "precision": 0.75383,
            "recall": 0.6637,
            "fmeasure": 0.69678
        },
        "nist": 5.636133961241957,
        "bleu": 48.02242,
        "meteor": 0.404294599858195,
        "bleurt": 0.29502,
        "nubia": {
            "semantic_relation": 4.19566,
            "contradiction": 18.59777,
            "irrelevancy": 27.4248,
            "logical_agreement": 53.97743,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.57724,
            "nubia_score": 0.69626
        },
        "bertscore": {
            "precision": 0.94335,
            "recall": 0.92851,
            "f1": 0.93416
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "t5-small/totto_test",
        "N": 24,
        "total_length": 333,
        "mean_pred_length": 13.875,
        "std_pred_length": 3.515590277606308,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.6066066066066066,
        "vocab_size-1": 202,
        "unique-1": 166,
        "entropy-1": 6.94796085289024,
        "distinct-2": 0.9449838187702265,
        "vocab_size-2": 292,
        "unique-2": 279,
        "entropy-2": 8.148485681626044,
        "cond_entropy-2": 0.9605658116885727,
        "distinct-3": 1.0,
        "vocab_size-3": 285,
        "unique-3": 285,
        "entropy-3": 8.15481810905212,
        "cond_entropy-3": 0.016688414481062973,
        "total_length-nopunct": 292,
        "mean_pred_length-nopunct": 12.166666666666666,
        "std_pred_length-nopunct": 3.287180487219337,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.678082191780822,
        "vocab_size-1-nopunct": 198,
        "unique-1-nopunct": 166,
        "entropy-1-nopunct": 7.109971345441114,
        "distinct-2-nopunct": 0.9365671641791045,
        "vocab_size-2-nopunct": 251,
        "unique-2-nopunct": 238,
        "entropy-2-nopunct": 7.92429814568162,
        "cond_entropy-2-nopunct": 0.871368294652712,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 244,
        "unique-3-nopunct": 244,
        "entropy-3-nopunct": 7.930737337562843,
        "cond_entropy-3-nopunct": 0.012189130711671272,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10638297872340426,
            "2": 0.32558139534883723,
            "3": 0.7172995780590717
        },
        "rouge1": {
            "precision": 0.73799,
            "recall": 0.6817,
            "fmeasure": 0.69088
        },
        "rouge2": {
            "precision": 0.4924,
            "recall": 0.45071,
            "fmeasure": 0.45957
        },
        "rougeL": {
            "precision": 0.66041,
            "recall": 0.59987,
            "fmeasure": 0.6131
        },
        "rougeLsum": {
            "precision": 0.66041,
            "recall": 0.59987,
            "fmeasure": 0.6131
        },
        "nist": 5.15125159008088,
        "bleu": 35.54711,
        "meteor": 0.35004136948843184,
        "bleurt": 0.13432,
        "nubia": {
            "semantic_relation": 3.99047,
            "contradiction": 16.8296,
            "irrelevancy": 26.38168,
            "logical_agreement": 56.78872,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.91545,
            "nubia_score": 0.6414
        },
        "bertscore": {
            "precision": 0.91889,
            "recall": 0.91083,
            "f1": 0.91311
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 97,
        "mean_pred_length": 16.166666666666668,
        "std_pred_length": 2.9107081994288304,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7628865979381443,
        "vocab_size-1": 74,
        "unique-1": 63,
        "entropy-1": 5.987705852648435,
        "distinct-2": 1.0,
        "vocab_size-2": 91,
        "unique-2": 91,
        "entropy-2": 6.507794640198703,
        "cond_entropy-2": 0.43287561681175873,
        "distinct-3": 1.0,
        "vocab_size-3": 85,
        "unique-3": 85,
        "entropy-3": 6.409390936137707,
        "cond_entropy-3": -0.09840370406099458,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8536585365853658,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 6.012860998441375,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.247927513443591,
        "cond_entropy-2-nopunct": 0.2622789628582702,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.129283016944973,
        "cond_entropy-3-nopunct": -0.11864449649861916,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.7505,
            "recall": 0.74838,
            "fmeasure": 0.73513
        },
        "rouge2": {
            "precision": 0.48133,
            "recall": 0.46111,
            "fmeasure": 0.46631
        },
        "rougeL": {
            "precision": 0.61548,
            "recall": 0.61807,
            "fmeasure": 0.60584
        },
        "rougeLsum": {
            "precision": 0.61548,
            "recall": 0.61807,
            "fmeasure": 0.60584
        },
        "nist": 4.751792349797042,
        "bleu": 42.73581,
        "meteor": 0.39706937432554723,
        "bleurt": 0.18993,
        "nubia": {
            "semantic_relation": 4.00073,
            "contradiction": 17.27832,
            "irrelevancy": 22.71529,
            "logical_agreement": 60.00639,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.64766,
            "nubia_score": 0.6729
        },
        "bertscore": {
            "precision": 0.93265,
            "recall": 0.93437,
            "f1": 0.93077
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "t5-small/totto_test",
        "N": 11,
        "total_length": 136,
        "mean_pred_length": 12.363636363636363,
        "std_pred_length": 2.1436047495548354,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.5955882352941176,
        "vocab_size-1": 81,
        "unique-1": 59,
        "entropy-1": 5.8866383649915734,
        "distinct-2": 0.808,
        "vocab_size-2": 101,
        "unique-2": 85,
        "entropy-2": 6.522711660780062,
        "cond_entropy-2": 0.4373158672591649,
        "distinct-3": 0.8859649122807017,
        "vocab_size-3": 101,
        "unique-3": 92,
        "entropy-3": 6.578332557948491,
        "cond_entropy-3": 0.06328579947283264,
        "total_length-nopunct": 121,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.174229226018436,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.900198931768968,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.314231731840537,
        "cond_entropy-2-nopunct": 0.44162718515447374,
        "distinct-3-nopunct": 0.8787878787878788,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.356431872517458,
        "cond_entropy-3-nopunct": 0.051982795192909215,
        "msttr-100": 0.61,
        "msttr-100_nopunct": 0.64,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.2413793103448276,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.65561,
            "recall": 0.62444,
            "fmeasure": 0.62924
        },
        "rouge2": {
            "precision": 0.40374,
            "recall": 0.37989,
            "fmeasure": 0.38379
        },
        "rougeL": {
            "precision": 0.60132,
            "recall": 0.57375,
            "fmeasure": 0.57712
        },
        "rougeLsum": {
            "precision": 0.60132,
            "recall": 0.57375,
            "fmeasure": 0.57712
        },
        "nist": 4.75720545133668,
        "bleu": 35.95296,
        "meteor": 0.3503154265783575,
        "bleurt": 0.1543,
        "nubia": {
            "semantic_relation": 3.98687,
            "contradiction": 3.50037,
            "irrelevancy": 69.37907,
            "logical_agreement": 27.12056,
            "grammar_ref": 5.00152,
            "grammar_hyp": 5.07096,
            "nubia_score": 0.6303
        },
        "bertscore": {
            "precision": 0.89953,
            "recall": 0.89532,
            "f1": 0.89559
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "t5-small/totto_test",
        "N": 76,
        "total_length": 1196,
        "mean_pred_length": 15.736842105263158,
        "std_pred_length": 4.57501343412647,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5083612040133779,
        "vocab_size-1": 608,
        "unique-1": 492,
        "entropy-1": 7.993895704761124,
        "distinct-2": 0.88125,
        "vocab_size-2": 987,
        "unique-2": 916,
        "entropy-2": 9.79262546243773,
        "cond_entropy-2": 1.610622374139827,
        "distinct-3": 0.975095785440613,
        "vocab_size-3": 1018,
        "unique-3": 996,
        "entropy-3": 9.974735713998902,
        "cond_entropy-3": 0.18769558359179325,
        "total_length-nopunct": 1032,
        "mean_pred_length-nopunct": 13.578947368421053,
        "std_pred_length-nopunct": 4.049896548044344,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5823643410852714,
        "vocab_size-1-nopunct": 601,
        "unique-1-nopunct": 491,
        "entropy-1-nopunct": 8.281279159096663,
        "distinct-2-nopunct": 0.8985355648535565,
        "vocab_size-2-nopunct": 859,
        "unique-2-nopunct": 812,
        "entropy-2-nopunct": 9.597220823551169,
        "cond_entropy-2-nopunct": 1.3977935543059845,
        "distinct-3-nopunct": 0.9784090909090909,
        "vocab_size-3-nopunct": 861,
        "unique-3-nopunct": 844,
        "entropy-3-nopunct": 9.736462241928768,
        "cond_entropy-3-nopunct": 0.1571450169251982,
        "msttr-100": 0.73091,
        "msttr-100_nopunct": 0.789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2709030100334448,
            "2": 0.47560975609756095,
            "3": 0.6689750692520776
        },
        "rouge1": {
            "precision": 0.69102,
            "recall": 0.65212,
            "fmeasure": 0.65472
        },
        "rouge2": {
            "precision": 0.41499,
            "recall": 0.39502,
            "fmeasure": 0.39411
        },
        "rougeL": {
            "precision": 0.58581,
            "recall": 0.56751,
            "fmeasure": 0.5614
        },
        "rougeLsum": {
            "precision": 0.58581,
            "recall": 0.56751,
            "fmeasure": 0.5614
        },
        "nist": 6.585649516695082,
        "bleu": 36.28176,
        "meteor": 0.32938638213392724,
        "bleurt": 0.08104,
        "nubia": {
            "semantic_relation": 3.89905,
            "contradiction": 13.20641,
            "irrelevancy": 36.78547,
            "logical_agreement": 50.00812,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.76735,
            "nubia_score": 0.62892
        },
        "bertscore": {
            "precision": 0.90441,
            "recall": 0.90369,
            "f1": 0.90249
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 21,
        "unique-1": 16,
        "entropy-1": 4.315824333525707,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.34341647163363254,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.106603137064474,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.22961067210860203,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5882352941176471
        },
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.57895,
            "fmeasure": 0.55
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.22222,
            "fmeasure": 0.21053
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.42105,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.42105,
            "fmeasure": 0.4
        },
        "nist": 2.0041248842847628,
        "bleu": 10.75467,
        "meteor": 0.2633543164868703,
        "bleurt": -0.22416,
        "nubia": {
            "semantic_relation": 3.39482,
            "contradiction": 1.72417,
            "irrelevancy": 85.48101,
            "logical_agreement": 12.79483,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.72764,
            "nubia_score": 0.49177
        },
        "bertscore": {
            "precision": 0.8341,
            "recall": 0.85718,
            "f1": 0.8449
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.2,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.6,
            "fmeasure": 0.63889
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.32143,
            "fmeasure": 0.34091
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "nist": 1.6476388007204534,
        "bleu": 22.08959,
        "meteor": 0.3387350864807313,
        "bleurt": 0.27507,
        "nubia": {
            "semantic_relation": 4.03669,
            "contradiction": 0.06382,
            "irrelevancy": 34.0709,
            "logical_agreement": 65.86528,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.46374,
            "nubia_score": 0.65321
        },
        "bertscore": {
            "precision": 0.92614,
            "recall": 0.93439,
            "f1": 0.93025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "t5-small/totto_test",
        "N": 50,
        "total_length": 744,
        "mean_pred_length": 14.88,
        "std_pred_length": 4.334235803460629,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.553763440860215,
        "vocab_size-1": 412,
        "unique-1": 340,
        "entropy-1": 7.6404890639925185,
        "distinct-2": 0.9106628242074928,
        "vocab_size-2": 632,
        "unique-2": 594,
        "entropy-2": 9.205604109175045,
        "cond_entropy-2": 1.345080942692187,
        "distinct-3": 0.9798136645962733,
        "vocab_size-3": 631,
        "unique-3": 619,
        "entropy-3": 9.28937202174478,
        "cond_entropy-3": 0.08543627385763275,
        "total_length-nopunct": 655,
        "mean_pred_length-nopunct": 13.1,
        "std_pred_length-nopunct": 3.9,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6213740458015267,
        "vocab_size-1-nopunct": 407,
        "unique-1-nopunct": 339,
        "entropy-1-nopunct": 7.878855257663507,
        "distinct-2-nopunct": 0.9206611570247933,
        "vocab_size-2-nopunct": 557,
        "unique-2-nopunct": 531,
        "entropy-2-nopunct": 9.022076424860344,
        "cond_entropy-2-nopunct": 1.2089437034018942,
        "distinct-3-nopunct": 0.9891891891891892,
        "vocab_size-3-nopunct": 549,
        "unique-3-nopunct": 543,
        "entropy-3-nopunct": 9.094722339615828,
        "cond_entropy-3-nopunct": 0.08694455505291805,
        "msttr-100": 0.71429,
        "msttr-100_nopunct": 0.77333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21333333333333335,
            "2": 0.5031446540880503,
            "3": 0.6824817518248175
        },
        "rouge1": {
            "precision": 0.77926,
            "recall": 0.67517,
            "fmeasure": 0.7113
        },
        "rouge2": {
            "precision": 0.53327,
            "recall": 0.46497,
            "fmeasure": 0.48749
        },
        "rougeL": {
            "precision": 0.67771,
            "recall": 0.59596,
            "fmeasure": 0.62347
        },
        "rougeLsum": {
            "precision": 0.67771,
            "recall": 0.59596,
            "fmeasure": 0.62347
        },
        "nist": 6.0944940087618305,
        "bleu": 38.74276,
        "meteor": 0.34631824444455633,
        "bleurt": 0.15291,
        "nubia": {
            "semantic_relation": 4.05148,
            "contradiction": 10.01898,
            "irrelevancy": 29.63077,
            "logical_agreement": 60.35025,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.98795,
            "nubia_score": 0.65278
        },
        "bertscore": {
            "precision": 0.92671,
            "recall": 0.90521,
            "f1": 0.91455
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "t5-small/totto_test",
        "N": 10,
        "total_length": 158,
        "mean_pred_length": 15.8,
        "std_pred_length": 3.1240998703626617,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.6329113924050633,
        "vocab_size-1": 100,
        "unique-1": 75,
        "entropy-1": 6.250151708747227,
        "distinct-2": 0.8716216216216216,
        "vocab_size-2": 129,
        "unique-2": 110,
        "entropy-2": 6.952696608872192,
        "cond_entropy-2": 0.5652816385468038,
        "distinct-3": 0.9130434782608695,
        "vocab_size-3": 126,
        "unique-3": 114,
        "entropy-3": 6.934611413299906,
        "cond_entropy-3": -0.021218763923244316,
        "total_length-nopunct": 137,
        "mean_pred_length-nopunct": 13.7,
        "std_pred_length-nopunct": 2.8301943396169813,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6934306569343066,
        "vocab_size-1-nopunct": 95,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.245297427937325,
        "distinct-2-nopunct": 0.8818897637795275,
        "vocab_size-2-nopunct": 112,
        "unique-2-nopunct": 97,
        "entropy-2-nopunct": 6.752464214331209,
        "cond_entropy-2-nopunct": 0.5585632159232701,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 108,
        "unique-3-nopunct": 99,
        "entropy-3-nopunct": 6.7165185657372355,
        "cond_entropy-3-nopunct": -0.03284988171867604,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3225806451612903,
            "2": 0.225,
            "3": 0.6306306306306306
        },
        "rouge1": {
            "precision": 0.69505,
            "recall": 0.66855,
            "fmeasure": 0.66836
        },
        "rouge2": {
            "precision": 0.44396,
            "recall": 0.42872,
            "fmeasure": 0.42832
        },
        "rougeL": {
            "precision": 0.53833,
            "recall": 0.51934,
            "fmeasure": 0.52021
        },
        "rougeLsum": {
            "precision": 0.53833,
            "recall": 0.51934,
            "fmeasure": 0.52021
        },
        "nist": 4.171877643852976,
        "bleu": 31.31881,
        "meteor": 0.31289105230052217,
        "bleurt": -0.03784,
        "nubia": {
            "semantic_relation": 3.8381,
            "contradiction": 11.53238,
            "irrelevancy": 48.82768,
            "logical_agreement": 39.63994,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.84738,
            "nubia_score": 0.56392
        },
        "bertscore": {
            "precision": 0.8972,
            "recall": 0.89587,
            "f1": 0.89402
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "t5-small/totto_test",
        "N": 11,
        "total_length": 171,
        "mean_pred_length": 15.545454545454545,
        "std_pred_length": 5.773979821163788,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.6842105263157895,
        "vocab_size-1": 117,
        "unique-1": 98,
        "entropy-1": 6.446970066884399,
        "distinct-2": 0.95625,
        "vocab_size-2": 153,
        "unique-2": 147,
        "entropy-2": 7.229710047998846,
        "cond_entropy-2": 0.6332736732497101,
        "distinct-3": 0.9865771812080537,
        "vocab_size-3": 147,
        "unique-3": 145,
        "entropy-3": 7.192322882878277,
        "cond_entropy-3": -0.04400194018249285,
        "total_length-nopunct": 149,
        "mean_pred_length-nopunct": 13.545454545454545,
        "std_pred_length-nopunct": 5.176233034722458,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7583892617449665,
        "vocab_size-1-nopunct": 113,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.551800562138246,
        "distinct-2-nopunct": 0.9637681159420289,
        "vocab_size-2-nopunct": 133,
        "unique-2-nopunct": 129,
        "entropy-2-nopunct": 7.0305904893711855,
        "cond_entropy-2-nopunct": 0.5102467934761583,
        "distinct-3-nopunct": 0.9921259842519685,
        "vocab_size-3-nopunct": 126,
        "unique-3-nopunct": 125,
        "entropy-3-nopunct": 6.972936655276084,
        "cond_entropy-3-nopunct": -0.06665167943778695,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23255813953488372,
            "2": 0.3157894736842105,
            "3": 0.6764705882352942
        },
        "rouge1": {
            "precision": 0.76097,
            "recall": 0.65324,
            "fmeasure": 0.69041
        },
        "rouge2": {
            "precision": 0.50666,
            "recall": 0.42577,
            "fmeasure": 0.45487
        },
        "rougeL": {
            "precision": 0.63468,
            "recall": 0.52887,
            "fmeasure": 0.56345
        },
        "rougeLsum": {
            "precision": 0.63468,
            "recall": 0.52887,
            "fmeasure": 0.56345
        },
        "nist": 5.3923901974936,
        "bleu": 36.06149,
        "meteor": 0.3690907304362025,
        "bleurt": 0.09662,
        "nubia": {
            "semantic_relation": 4.11545,
            "contradiction": 23.901,
            "irrelevancy": 32.32449,
            "logical_agreement": 43.77451,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.8162,
            "nubia_score": 0.67939
        },
        "bertscore": {
            "precision": 0.90218,
            "recall": 0.89873,
            "f1": 0.89906
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "t5-small/totto_test",
        "N": 17,
        "total_length": 267,
        "mean_pred_length": 15.705882352941176,
        "std_pred_length": 4.534374668376886,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.5655430711610487,
        "vocab_size-1": 151,
        "unique-1": 117,
        "entropy-1": 6.579227170291105,
        "distinct-2": 0.888,
        "vocab_size-2": 222,
        "unique-2": 200,
        "entropy-2": 7.716326172755698,
        "cond_entropy-2": 1.0034254425030094,
        "distinct-3": 0.9613733905579399,
        "vocab_size-3": 224,
        "unique-3": 215,
        "entropy-3": 7.786932925770196,
        "cond_entropy-3": 0.07164017748833165,
        "total_length-nopunct": 234,
        "mean_pred_length-nopunct": 13.764705882352942,
        "std_pred_length-nopunct": 3.9337067052471735,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6367521367521367,
        "vocab_size-1-nopunct": 149,
        "unique-1-nopunct": 117,
        "entropy-1-nopunct": 6.75117604294768,
        "distinct-2-nopunct": 0.8940092165898618,
        "vocab_size-2-nopunct": 194,
        "unique-2-nopunct": 177,
        "entropy-2-nopunct": 7.520240043612232,
        "cond_entropy-2-nopunct": 0.8025723877642715,
        "distinct-3-nopunct": 0.97,
        "vocab_size-3-nopunct": 194,
        "unique-3-nopunct": 188,
        "entropy-3-nopunct": 7.583856189774741,
        "cond_entropy-3-nopunct": 0.06412759721324675,
        "msttr-100": 0.655,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4098360655737705,
            "3": 0.6708074534161491
        },
        "rouge1": {
            "precision": 0.65233,
            "recall": 0.64392,
            "fmeasure": 0.63949
        },
        "rouge2": {
            "precision": 0.38302,
            "recall": 0.37373,
            "fmeasure": 0.3746
        },
        "rougeL": {
            "precision": 0.54618,
            "recall": 0.53813,
            "fmeasure": 0.5362
        },
        "rougeLsum": {
            "precision": 0.54618,
            "recall": 0.53813,
            "fmeasure": 0.5362
        },
        "nist": 5.307461926477351,
        "bleu": 32.24733,
        "meteor": 0.32836822648337194,
        "bleurt": 0.13745,
        "nubia": {
            "semantic_relation": 4.00164,
            "contradiction": 2.1501,
            "irrelevancy": 41.05922,
            "logical_agreement": 56.79068,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.31881,
            "nubia_score": 0.70787
        },
        "bertscore": {
            "precision": 0.89731,
            "recall": 0.90478,
            "f1": 0.89867
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "t5-small/totto_test",
        "N": 11,
        "total_length": 154,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.9772077916777016,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.6558441558441559,
        "vocab_size-1": 101,
        "unique-1": 80,
        "entropy-1": 6.231344255588413,
        "distinct-2": 0.972027972027972,
        "vocab_size-2": 139,
        "unique-2": 135,
        "entropy-2": 7.10392728083434,
        "cond_entropy-2": 0.7199297678144497,
        "distinct-3": 0.9924242424242424,
        "vocab_size-3": 131,
        "unique-3": 130,
        "entropy-3": 7.029242604206928,
        "cond_entropy-3": -0.07002267196539042,
        "total_length-nopunct": 136,
        "mean_pred_length-nopunct": 12.363636363636363,
        "std_pred_length-nopunct": 3.6249821886139793,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7132352941176471,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 78,
        "entropy-1-nopunct": 6.27327860630033,
        "distinct-2-nopunct": 0.968,
        "vocab_size-2-nopunct": 121,
        "unique-2-nopunct": 117,
        "entropy-2-nopunct": 6.901784284662096,
        "cond_entropy-2-nopunct": 0.7001538910373528,
        "distinct-3-nopunct": 0.9912280701754386,
        "vocab_size-3-nopunct": 113,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.815346154515631,
        "cond_entropy-3-nopunct": -0.0802626915499769,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15151515151515152,
            "2": 0.21428571428571427,
            "3": 0.6377952755905512
        },
        "rouge1": {
            "precision": 0.70343,
            "recall": 0.65195,
            "fmeasure": 0.65848
        },
        "rouge2": {
            "precision": 0.40277,
            "recall": 0.38096,
            "fmeasure": 0.3813
        },
        "rougeL": {
            "precision": 0.59616,
            "recall": 0.56445,
            "fmeasure": 0.56578
        },
        "rougeLsum": {
            "precision": 0.59616,
            "recall": 0.56445,
            "fmeasure": 0.56578
        },
        "nist": 3.7511628432537356,
        "bleu": 29.92643,
        "meteor": 0.32830498044959133,
        "bleurt": 0.09289,
        "nubia": {
            "semantic_relation": 3.83721,
            "contradiction": 19.07081,
            "irrelevancy": 39.49809,
            "logical_agreement": 41.43111,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.7285,
            "nubia_score": 0.58014
        },
        "bertscore": {
            "precision": 0.91508,
            "recall": 0.91172,
            "f1": 0.91174
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "t5-small/totto_test",
        "N": 75,
        "total_length": 1173,
        "mean_pred_length": 15.64,
        "std_pred_length": 4.420075414137939,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.48678601875532823,
        "vocab_size-1": 571,
        "unique-1": 447,
        "entropy-1": 7.917143753456241,
        "distinct-2": 0.8287795992714025,
        "vocab_size-2": 910,
        "unique-2": 803,
        "entropy-2": 9.63763214014028,
        "cond_entropy-2": 1.5102575917253556,
        "distinct-3": 0.9305962854349951,
        "vocab_size-3": 952,
        "unique-3": 894,
        "entropy-3": 9.8487524898478,
        "cond_entropy-3": 0.22689972645642367,
        "total_length-nopunct": 1021,
        "mean_pred_length-nopunct": 13.613333333333333,
        "std_pred_length-nopunct": 3.6291168194050862,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5514201762977473,
        "vocab_size-1-nopunct": 563,
        "unique-1-nopunct": 446,
        "entropy-1-nopunct": 8.16162310853429,
        "distinct-2-nopunct": 0.8329809725158562,
        "vocab_size-2-nopunct": 788,
        "unique-2-nopunct": 700,
        "entropy-2-nopunct": 9.423447173683009,
        "cond_entropy-2-nopunct": 1.3606767052586701,
        "distinct-3-nopunct": 0.9357060849598163,
        "vocab_size-3-nopunct": 815,
        "unique-3-nopunct": 769,
        "entropy-3-nopunct": 9.628148512487561,
        "cond_entropy-3-nopunct": 0.2277595793021464,
        "msttr-100": 0.71636,
        "msttr-100_nopunct": 0.783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2339622641509434,
            "2": 0.4027777777777778,
            "3": 0.729936305732484
        },
        "rouge1": {
            "precision": 0.73573,
            "recall": 0.68856,
            "fmeasure": 0.70202
        },
        "rouge2": {
            "precision": 0.53461,
            "recall": 0.49297,
            "fmeasure": 0.50627
        },
        "rougeL": {
            "precision": 0.65301,
            "recall": 0.60833,
            "fmeasure": 0.62194
        },
        "rougeLsum": {
            "precision": 0.65301,
            "recall": 0.60833,
            "fmeasure": 0.62194
        },
        "nist": 6.9963698399349346,
        "bleu": 45.76528,
        "meteor": 0.36847499351303803,
        "bleurt": 0.14475,
        "nubia": {
            "semantic_relation": 4.01609,
            "contradiction": 12.62886,
            "irrelevancy": 34.37768,
            "logical_agreement": 52.99346,
            "grammar_ref": 4.90125,
            "grammar_hyp": 5.10271,
            "nubia_score": 0.63664
        },
        "bertscore": {
            "precision": 0.91863,
            "recall": 0.91334,
            "f1": 0.91451
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "t5-small/totto_test",
        "N": 17,
        "total_length": 260,
        "mean_pred_length": 15.294117647058824,
        "std_pred_length": 5.266595126023386,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.6192307692307693,
        "vocab_size-1": 161,
        "unique-1": 129,
        "entropy-1": 6.799100661321453,
        "distinct-2": 0.897119341563786,
        "vocab_size-2": 218,
        "unique-2": 195,
        "entropy-2": 7.71283812087191,
        "cond_entropy-2": 0.7652091063385048,
        "distinct-3": 0.9557522123893806,
        "vocab_size-3": 216,
        "unique-3": 206,
        "entropy-3": 7.731683387193975,
        "cond_entropy-3": 0.02594068449226959,
        "total_length-nopunct": 221,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.563280553698699,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 156,
        "unique-1-nopunct": 128,
        "entropy-1-nopunct": 6.92497319053302,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 187,
        "unique-2-nopunct": 172,
        "entropy-2-nopunct": 7.498357817440482,
        "cond_entropy-2-nopunct": 0.645295407645649,
        "distinct-3-nopunct": 0.9679144385026738,
        "vocab_size-3-nopunct": 181,
        "unique-3-nopunct": 175,
        "entropy-3-nopunct": 7.482723336892962,
        "cond_entropy-3-nopunct": 0.00018983986441354988,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.805,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1702127659574468,
            "2": 0.21052631578947367,
            "3": 0.728110599078341
        },
        "rouge1": {
            "precision": 0.80075,
            "recall": 0.70132,
            "fmeasure": 0.73552
        },
        "rouge2": {
            "precision": 0.63024,
            "recall": 0.54493,
            "fmeasure": 0.57456
        },
        "rougeL": {
            "precision": 0.69923,
            "recall": 0.61432,
            "fmeasure": 0.64262
        },
        "rougeLsum": {
            "precision": 0.69923,
            "recall": 0.61432,
            "fmeasure": 0.64262
        },
        "nist": 5.4961862549054725,
        "bleu": 54.43409,
        "meteor": 0.4152652157100728,
        "bleurt": 0.28541,
        "nubia": {
            "semantic_relation": 4.16291,
            "contradiction": 10.58757,
            "irrelevancy": 12.58096,
            "logical_agreement": 76.83147,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.54356,
            "nubia_score": 0.71638
        },
        "bertscore": {
            "precision": 0.9425,
            "recall": 0.92299,
            "f1": 0.93066
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "t5-small/totto_test",
        "N": 13,
        "total_length": 206,
        "mean_pred_length": 15.846153846153847,
        "std_pred_length": 3.3706003538779457,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.6407766990291263,
        "vocab_size-1": 132,
        "unique-1": 113,
        "entropy-1": 6.547431062051375,
        "distinct-2": 0.9378238341968912,
        "vocab_size-2": 181,
        "unique-2": 173,
        "entropy-2": 7.447379317060807,
        "cond_entropy-2": 0.7274207250140114,
        "distinct-3": 0.9888888888888889,
        "vocab_size-3": 178,
        "unique-3": 176,
        "entropy-3": 7.469630874107438,
        "cond_entropy-3": 0.032729392394927705,
        "total_length-nopunct": 181,
        "mean_pred_length-nopunct": 13.923076923076923,
        "std_pred_length-nopunct": 3.074999398662567,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7016574585635359,
        "vocab_size-1-nopunct": 127,
        "unique-1-nopunct": 110,
        "entropy-1-nopunct": 6.626844403832662,
        "distinct-2-nopunct": 0.9345238095238095,
        "vocab_size-2-nopunct": 157,
        "unique-2-nopunct": 150,
        "entropy-2-nopunct": 7.237555518016884,
        "cond_entropy-2-nopunct": 0.6782648003880828,
        "distinct-3-nopunct": 0.9870967741935484,
        "vocab_size-3-nopunct": 153,
        "unique-3-nopunct": 151,
        "entropy-3-nopunct": 7.250317953661353,
        "cond_entropy-3-nopunct": 0.025742466366444925,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2962962962962963,
            "2": 0.09090909090909091,
            "3": 0.8881578947368421
        },
        "rouge1": {
            "precision": 0.82008,
            "recall": 0.83378,
            "fmeasure": 0.81815
        },
        "rouge2": {
            "precision": 0.61462,
            "recall": 0.64936,
            "fmeasure": 0.62064
        },
        "rougeL": {
            "precision": 0.7311,
            "recall": 0.73901,
            "fmeasure": 0.72735
        },
        "rougeLsum": {
            "precision": 0.7311,
            "recall": 0.73901,
            "fmeasure": 0.72735
        },
        "nist": 6.225532184617329,
        "bleu": 54.8034,
        "meteor": 0.465953429941662,
        "bleurt": 0.55118,
        "nubia": {
            "semantic_relation": 4.55187,
            "contradiction": 0.32362,
            "irrelevancy": 30.98381,
            "logical_agreement": 68.69257,
            "grammar_ref": 5.1809,
            "grammar_hyp": 4.99074,
            "nubia_score": 0.85055
        },
        "bertscore": {
            "precision": 0.94902,
            "recall": 0.95681,
            "f1": 0.95065
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 50,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.179449471770337,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 16,
        "distinct-1": 0.74,
        "vocab_size-1": 37,
        "unique-1": 29,
        "entropy-1": 5.028758439731456,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.37437723372062437,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.1312445332782525,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.8708286933869707,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.942275084497218,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.39174460128612265,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.2857142857142857,
            "3": 0.6756756756756757
        },
        "rouge1": {
            "precision": 0.72835,
            "recall": 0.71398,
            "fmeasure": 0.7174
        },
        "rouge2": {
            "precision": 0.47949,
            "recall": 0.48122,
            "fmeasure": 0.47809
        },
        "rougeL": {
            "precision": 0.64232,
            "recall": 0.64751,
            "fmeasure": 0.64244
        },
        "rougeLsum": {
            "precision": 0.64232,
            "recall": 0.64751,
            "fmeasure": 0.64244
        },
        "nist": 4.040967358071918,
        "bleu": 40.89973,
        "meteor": 0.3521084982921852,
        "bleurt": 0.1125,
        "nubia": {
            "semantic_relation": 3.56137,
            "contradiction": 28.09075,
            "irrelevancy": 31.71774,
            "logical_agreement": 40.19152,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.485,
            "nubia_score": 0.57489
        },
        "bertscore": {
            "precision": 0.9199,
            "recall": 0.9167,
            "f1": 0.91145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "t5-small/totto_test",
        "N": 44,
        "total_length": 694,
        "mean_pred_length": 15.772727272727273,
        "std_pred_length": 4.889058453524918,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.5302593659942363,
        "vocab_size-1": 368,
        "unique-1": 288,
        "entropy-1": 7.590588620044981,
        "distinct-2": 0.8661538461538462,
        "vocab_size-2": 563,
        "unique-2": 507,
        "entropy-2": 9.02129205712275,
        "cond_entropy-2": 1.256893795676976,
        "distinct-3": 0.9471947194719472,
        "vocab_size-3": 574,
        "unique-3": 549,
        "entropy-3": 9.128034647646537,
        "cond_entropy-3": 0.11534353018539467,
        "total_length-nopunct": 606,
        "mean_pred_length-nopunct": 13.772727272727273,
        "std_pred_length-nopunct": 4.456168535471805,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5973597359735974,
        "vocab_size-1-nopunct": 362,
        "unique-1-nopunct": 288,
        "entropy-1-nopunct": 7.771489566081323,
        "distinct-2-nopunct": 0.8807829181494662,
        "vocab_size-2-nopunct": 495,
        "unique-2-nopunct": 456,
        "entropy-2-nopunct": 8.836049379813424,
        "cond_entropy-2-nopunct": 1.138145882545781,
        "distinct-3-nopunct": 0.9575289575289575,
        "vocab_size-3-nopunct": 496,
        "unique-3-nopunct": 480,
        "entropy-3-nopunct": 8.922175951762433,
        "cond_entropy-3-nopunct": 0.10374932364400254,
        "msttr-100": 0.73333,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2376237623762376,
            "2": 0.456,
            "3": 0.7494600431965442
        },
        "rouge1": {
            "precision": 0.75196,
            "recall": 0.72568,
            "fmeasure": 0.72733
        },
        "rouge2": {
            "precision": 0.49289,
            "recall": 0.48338,
            "fmeasure": 0.47925
        },
        "rougeL": {
            "precision": 0.64765,
            "recall": 0.62769,
            "fmeasure": 0.62724
        },
        "rougeLsum": {
            "precision": 0.64765,
            "recall": 0.62769,
            "fmeasure": 0.62724
        },
        "nist": 6.368546971366065,
        "bleu": 40.24912,
        "meteor": 0.3716491382239856,
        "bleurt": 0.24504,
        "nubia": {
            "semantic_relation": 4.21753,
            "contradiction": 7.26701,
            "irrelevancy": 33.72864,
            "logical_agreement": 59.00435,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.72118,
            "nubia_score": 0.72753
        },
        "bertscore": {
            "precision": 0.91803,
            "recall": 0.91633,
            "f1": 0.91598
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 63,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.6507936507936508,
        "vocab_size-1": 41,
        "unique-1": 26,
        "entropy-1": 5.165860630186208,
        "distinct-2": 0.8166666666666667,
        "vocab_size-2": 49,
        "unique-2": 39,
        "entropy-2": 5.527642470572459,
        "cond_entropy-2": 0.3856861383852732,
        "distinct-3": 0.9122807017543859,
        "vocab_size-3": 52,
        "unique-3": 47,
        "entropy-3": 5.65745141767351,
        "cond_entropy-3": 0.14976937473452975,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6842105263157895,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 5.139736066720408,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.421554168830133,
        "cond_entropy-2-nopunct": 0.3018081362270033,
        "distinct-3-nopunct": 0.9019607843137255,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.4763469105989495,
        "cond_entropy-3-nopunct": 0.07440058490606626,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.60582,
            "recall": 0.67994,
            "fmeasure": 0.62934
        },
        "rouge2": {
            "precision": 0.41438,
            "recall": 0.46845,
            "fmeasure": 0.43126
        },
        "rougeL": {
            "precision": 0.46825,
            "recall": 0.54421,
            "fmeasure": 0.49349
        },
        "rougeLsum": {
            "precision": 0.46825,
            "recall": 0.54421,
            "fmeasure": 0.49349
        },
        "nist": 3.3789721500614602,
        "bleu": 31.00958,
        "meteor": 0.3729869284531951,
        "bleurt": -0.11182,
        "nubia": {
            "semantic_relation": 3.97261,
            "contradiction": 0.20798,
            "irrelevancy": 70.54768,
            "logical_agreement": 29.24434,
            "grammar_ref": 4.57112,
            "grammar_hyp": 3.95257,
            "nubia_score": 0.71344
        },
        "bertscore": {
            "precision": 0.85985,
            "recall": 0.91499,
            "f1": 0.88588
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "t5-small/totto_test",
        "N": 32,
        "total_length": 531,
        "mean_pred_length": 16.59375,
        "std_pred_length": 3.7654629114492684,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.5178907721280602,
        "vocab_size-1": 275,
        "unique-1": 211,
        "entropy-1": 7.262689448496289,
        "distinct-2": 0.8236472945891784,
        "vocab_size-2": 411,
        "unique-2": 355,
        "entropy-2": 8.529073035567539,
        "cond_entropy-2": 1.1510121648959923,
        "distinct-3": 0.9057815845824411,
        "vocab_size-3": 423,
        "unique-3": 385,
        "entropy-3": 8.66704367546065,
        "cond_entropy-3": 0.14038487443356767,
        "total_length-nopunct": 472,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 3.3634060117684275,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.5720338983050848,
        "vocab_size-1-nopunct": 270,
        "unique-1-nopunct": 211,
        "entropy-1-nopunct": 7.376021795399957,
        "distinct-2-nopunct": 0.8227272727272728,
        "vocab_size-2-nopunct": 362,
        "unique-2-nopunct": 313,
        "entropy-2-nopunct": 8.341080680768117,
        "cond_entropy-2-nopunct": 1.015205874463211,
        "distinct-3-nopunct": 0.9117647058823529,
        "vocab_size-3-nopunct": 372,
        "unique-3-nopunct": 340,
        "entropy-3-nopunct": 8.487352364019802,
        "cond_entropy-3-nopunct": 0.14158768582076822,
        "msttr-100": 0.706,
        "msttr-100_nopunct": 0.725,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.27710843373493976,
            "3": 0.7372448979591837
        },
        "rouge1": {
            "precision": 0.74562,
            "recall": 0.67687,
            "fmeasure": 0.69327
        },
        "rouge2": {
            "precision": 0.50521,
            "recall": 0.46384,
            "fmeasure": 0.46998
        },
        "rougeL": {
            "precision": 0.65153,
            "recall": 0.59278,
            "fmeasure": 0.60596
        },
        "rougeLsum": {
            "precision": 0.65153,
            "recall": 0.59278,
            "fmeasure": 0.60596
        },
        "nist": 5.767388426592374,
        "bleu": 36.98773,
        "meteor": 0.33927250347005794,
        "bleurt": 0.09217,
        "nubia": {
            "semantic_relation": 4.10248,
            "contradiction": 15.36602,
            "irrelevancy": 29.3805,
            "logical_agreement": 55.25348,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.49441,
            "nubia_score": 0.65851
        },
        "bertscore": {
            "precision": 0.90953,
            "recall": 0.90195,
            "f1": 0.90326
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "t5-small/totto_test",
        "N": 43,
        "total_length": 656,
        "mean_pred_length": 15.255813953488373,
        "std_pred_length": 4.620948373695971,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.5365853658536586,
        "vocab_size-1": 352,
        "unique-1": 284,
        "entropy-1": 7.506333555574081,
        "distinct-2": 0.8939641109298532,
        "vocab_size-2": 548,
        "unique-2": 504,
        "entropy-2": 9.005398397462017,
        "cond_entropy-2": 1.3235314122244808,
        "distinct-3": 0.9578947368421052,
        "vocab_size-3": 546,
        "unique-3": 527,
        "entropy-3": 9.062265674837843,
        "cond_entropy-3": 0.0532476795649565,
        "total_length-nopunct": 569,
        "mean_pred_length-nopunct": 13.232558139534884,
        "std_pred_length-nopunct": 4.0967213737404276,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6045694200351494,
        "vocab_size-1-nopunct": 344,
        "unique-1-nopunct": 281,
        "entropy-1-nopunct": 7.685635613089379,
        "distinct-2-nopunct": 0.9125475285171103,
        "vocab_size-2-nopunct": 480,
        "unique-2-nopunct": 452,
        "entropy-2-nopunct": 8.819986450326384,
        "cond_entropy-2-nopunct": 1.2018674947970904,
        "distinct-3-nopunct": 0.968944099378882,
        "vocab_size-3-nopunct": 468,
        "unique-3-nopunct": 456,
        "entropy-3-nopunct": 8.848063876760868,
        "cond_entropy-3-nopunct": 0.020057523320610737,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.776,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.33620689655172414,
            "2": 0.43609022556390975,
            "3": 0.7806603773584906
        },
        "rouge1": {
            "precision": 0.79164,
            "recall": 0.75107,
            "fmeasure": 0.7629
        },
        "rouge2": {
            "precision": 0.57789,
            "recall": 0.55023,
            "fmeasure": 0.55795
        },
        "rougeL": {
            "precision": 0.71676,
            "recall": 0.68627,
            "fmeasure": 0.69383
        },
        "rougeLsum": {
            "precision": 0.71676,
            "recall": 0.68627,
            "fmeasure": 0.69383
        },
        "nist": 6.951878457008502,
        "bleu": 48.83998,
        "meteor": 0.3997384282473779,
        "bleurt": 0.26123,
        "nubia": {
            "semantic_relation": 4.21093,
            "contradiction": 8.58021,
            "irrelevancy": 29.3371,
            "logical_agreement": 62.08269,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.54727,
            "nubia_score": 0.73604
        },
        "bertscore": {
            "precision": 0.93254,
            "recall": 0.9264,
            "f1": 0.92784
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 18,
        "unique-1": 14,
        "entropy-1": 4.095795255000933,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.16249647625006503,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.021928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.1813302398882836,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.782608695652174
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80529,
            "fmeasure": 0.85702
        },
        "rouge2": {
            "precision": 0.81481,
            "recall": 0.67254,
            "fmeasure": 0.72935
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.70159,
            "fmeasure": 0.75526
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.70159,
            "fmeasure": 0.75526
        },
        "nist": 3.937881678350364,
        "bleu": 54.48585,
        "meteor": 0.45013388550327027,
        "bleurt": 0.56966,
        "nubia": {
            "semantic_relation": 4.6451,
            "contradiction": 0.86312,
            "irrelevancy": 0.63969,
            "logical_agreement": 98.49719,
            "grammar_ref": 4.84371,
            "grammar_hyp": 5.23554,
            "nubia_score": 0.80228
        },
        "bertscore": {
            "precision": 0.96441,
            "recall": 0.93213,
            "f1": 0.94771
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "t5-small/totto_test",
        "N": 31,
        "total_length": 506,
        "mean_pred_length": 16.322580645161292,
        "std_pred_length": 4.7613165485771285,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.5553359683794467,
        "vocab_size-1": 281,
        "unique-1": 231,
        "entropy-1": 7.2061851519007645,
        "distinct-2": 0.888421052631579,
        "vocab_size-2": 422,
        "unique-2": 390,
        "entropy-2": 8.61080470957081,
        "cond_entropy-2": 1.2573728770045316,
        "distinct-3": 0.9594594594594594,
        "vocab_size-3": 426,
        "unique-3": 410,
        "entropy-3": 8.709934391115153,
        "cond_entropy-3": 0.11424307974936589,
        "total_length-nopunct": 450,
        "mean_pred_length-nopunct": 14.516129032258064,
        "std_pred_length-nopunct": 4.634171587881843,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6088888888888889,
        "vocab_size-1-nopunct": 274,
        "unique-1-nopunct": 229,
        "entropy-1-nopunct": 7.318388452995137,
        "distinct-2-nopunct": 0.8902147971360382,
        "vocab_size-2-nopunct": 373,
        "unique-2-nopunct": 348,
        "entropy-2-nopunct": 8.425687049492819,
        "cond_entropy-2-nopunct": 1.1960509828543735,
        "distinct-3-nopunct": 0.961340206185567,
        "vocab_size-3-nopunct": 373,
        "unique-3-nopunct": 360,
        "entropy-3-nopunct": 8.51870208186667,
        "cond_entropy-3-nopunct": 0.10397827569777685,
        "msttr-100": 0.692,
        "msttr-100_nopunct": 0.7425,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25316455696202533,
            "2": 0.36666666666666664,
            "3": 0.6338028169014085
        },
        "rouge1": {
            "precision": 0.68811,
            "recall": 0.6283,
            "fmeasure": 0.64247
        },
        "rouge2": {
            "precision": 0.46092,
            "recall": 0.4196,
            "fmeasure": 0.42912
        },
        "rougeL": {
            "precision": 0.59256,
            "recall": 0.5441,
            "fmeasure": 0.55542
        },
        "rougeLsum": {
            "precision": 0.59256,
            "recall": 0.5441,
            "fmeasure": 0.55542
        },
        "nist": 5.575001870989684,
        "bleu": 39.24009,
        "meteor": 0.3190400157075411,
        "bleurt": 0.03545,
        "nubia": {
            "semantic_relation": 3.80553,
            "contradiction": 12.0976,
            "irrelevancy": 36.22236,
            "logical_agreement": 51.68004,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.52625,
            "nubia_score": 0.62505
        },
        "bertscore": {
            "precision": 0.89669,
            "recall": 0.88187,
            "f1": 0.88823
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.0,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.96875,
        "vocab_size-1": 31,
        "unique-1": 30,
        "entropy-1": 4.9375,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": -0.09310940439148141,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.857980995127571,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": -0.10309349296410335,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5454545454545454,
            "3": 0.34615384615384615
        },
        "rouge1": {
            "precision": 0.56852,
            "recall": 0.44228,
            "fmeasure": 0.49014
        },
        "rouge2": {
            "precision": 0.31373,
            "recall": 0.24167,
            "fmeasure": 0.26866
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.33541,
            "fmeasure": 0.3665
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.33541,
            "fmeasure": 0.3665
        },
        "nist": 1.3386924447316106,
        "bleu": 12.09643,
        "meteor": 0.21038503632614938,
        "bleurt": -0.62064,
        "nubia": {
            "semantic_relation": 3.14916,
            "contradiction": 34.1611,
            "irrelevancy": 65.53567,
            "logical_agreement": 0.30323,
            "grammar_ref": 4.83168,
            "grammar_hyp": 5.7829,
            "nubia_score": 0.22369
        },
        "bertscore": {
            "precision": 0.8528,
            "recall": 0.83816,
            "f1": 0.84521
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "t5-small/totto_test",
        "N": 103,
        "total_length": 1734,
        "mean_pred_length": 16.83495145631068,
        "std_pred_length": 5.122001064091664,
        "median_pred_length": 17.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.44232987312572086,
        "vocab_size-1": 767,
        "unique-1": 590,
        "entropy-1": 8.140177778008091,
        "distinct-2": 0.8001226241569589,
        "vocab_size-2": 1305,
        "unique-2": 1184,
        "entropy-2": 10.040202380537798,
        "cond_entropy-2": 1.720743815161942,
        "distinct-3": 0.8965968586387435,
        "vocab_size-3": 1370,
        "unique-3": 1313,
        "entropy-3": 10.26490400345897,
        "cond_entropy-3": 0.2332333966243875,
        "total_length-nopunct": 1522,
        "mean_pred_length-nopunct": 14.776699029126213,
        "std_pred_length-nopunct": 4.890911005407336,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4980289093298292,
        "vocab_size-1-nopunct": 758,
        "unique-1-nopunct": 587,
        "entropy-1-nopunct": 8.36676846097325,
        "distinct-2-nopunct": 0.8090204369274137,
        "vocab_size-2-nopunct": 1148,
        "unique-2-nopunct": 1057,
        "entropy-2-nopunct": 9.844042905275657,
        "cond_entropy-2-nopunct": 1.5726896951701135,
        "distinct-3-nopunct": 0.8958966565349544,
        "vocab_size-3-nopunct": 1179,
        "unique-3-nopunct": 1134,
        "entropy-3-nopunct": 10.038415282517693,
        "cond_entropy-3-nopunct": 0.2300795945667392,
        "msttr-100": 0.71647,
        "msttr-100_nopunct": 0.752,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24390243902439024,
            "2": 0.48148148148148145,
            "3": 0.755338078291815
        },
        "rouge1": {
            "precision": 0.73813,
            "recall": 0.71771,
            "fmeasure": 0.71441
        },
        "rouge2": {
            "precision": 0.52019,
            "recall": 0.50227,
            "fmeasure": 0.50193
        },
        "rougeL": {
            "precision": 0.64591,
            "recall": 0.63128,
            "fmeasure": 0.62772
        },
        "rougeLsum": {
            "precision": 0.64591,
            "recall": 0.63128,
            "fmeasure": 0.62772
        },
        "nist": 7.62970491837636,
        "bleu": 47.94661,
        "meteor": 0.38720825893863026,
        "bleurt": 0.19927,
        "nubia": {
            "semantic_relation": 4.08021,
            "contradiction": 10.50272,
            "irrelevancy": 35.77606,
            "logical_agreement": 53.72121,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.59919,
            "nubia_score": 0.68583
        },
        "bertscore": {
            "precision": 0.92,
            "recall": 0.91693,
            "f1": 0.91699
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "t5-small/totto_test",
        "N": 144,
        "total_length": 2123,
        "mean_pred_length": 14.743055555555555,
        "std_pred_length": 4.609390366682902,
        "median_pred_length": 14.5,
        "min_pred_length": 4,
        "max_pred_length": 28,
        "distinct-1": 0.3655204898728215,
        "vocab_size-1": 776,
        "unique-1": 573,
        "entropy-1": 7.957909204449257,
        "distinct-2": 0.7023749368367862,
        "vocab_size-2": 1390,
        "unique-2": 1202,
        "entropy-2": 9.968443175445609,
        "cond_entropy-2": 1.7721722585780322,
        "distinct-3": 0.8381471389645777,
        "vocab_size-3": 1538,
        "unique-3": 1415,
        "entropy-3": 10.385235955885438,
        "cond_entropy-3": 0.40105687836712417,
        "total_length-nopunct": 1856,
        "mean_pred_length-nopunct": 12.88888888888889,
        "std_pred_length-nopunct": 4.118237067388165,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.41379310344827586,
        "vocab_size-1-nopunct": 768,
        "unique-1-nopunct": 571,
        "entropy-1-nopunct": 8.18717926906191,
        "distinct-2-nopunct": 0.7219626168224299,
        "vocab_size-2-nopunct": 1236,
        "unique-2-nopunct": 1090,
        "entropy-2-nopunct": 9.80697904719015,
        "cond_entropy-2-nopunct": 1.6863813590566725,
        "distinct-3-nopunct": 0.8488520408163265,
        "vocab_size-3-nopunct": 1331,
        "unique-3-nopunct": 1235,
        "entropy-3-nopunct": 10.186135639651464,
        "cond_entropy-3-nopunct": 0.40826712697472906,
        "msttr-100": 0.70095,
        "msttr-100_nopunct": 0.74611,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26848249027237353,
            "2": 0.5143487858719646,
            "3": 0.708171206225681
        },
        "rouge1": {
            "precision": 0.72009,
            "recall": 0.69496,
            "fmeasure": 0.69056
        },
        "rouge2": {
            "precision": 0.48965,
            "recall": 0.46705,
            "fmeasure": 0.46542
        },
        "rougeL": {
            "precision": 0.61112,
            "recall": 0.59466,
            "fmeasure": 0.58722
        },
        "rougeLsum": {
            "precision": 0.61112,
            "recall": 0.59466,
            "fmeasure": 0.58722
        },
        "nist": 7.252673424595572,
        "bleu": 42.69646,
        "meteor": 0.3790025846021295,
        "bleurt": 0.17216,
        "nubia": {
            "semantic_relation": 3.99852,
            "contradiction": 10.91148,
            "irrelevancy": 39.40521,
            "logical_agreement": 49.68331,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.75428,
            "nubia_score": 0.67272
        },
        "bertscore": {
            "precision": 0.91316,
            "recall": 0.91683,
            "f1": 0.91307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "t5-small/totto_test",
        "N": 20,
        "total_length": 287,
        "mean_pred_length": 14.35,
        "std_pred_length": 4.574658457196559,
        "median_pred_length": 13.5,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.6515679442508711,
        "vocab_size-1": 187,
        "unique-1": 154,
        "entropy-1": 7.024322436043859,
        "distinct-2": 0.9588014981273408,
        "vocab_size-2": 256,
        "unique-2": 247,
        "entropy-2": 7.97080829123808,
        "cond_entropy-2": 0.7296359190789027,
        "distinct-3": 0.9878542510121457,
        "vocab_size-3": 244,
        "unique-3": 241,
        "entropy-3": 7.924075733609,
        "cond_entropy-3": -0.03945420617575075,
        "total_length-nopunct": 249,
        "mean_pred_length-nopunct": 12.45,
        "std_pred_length-nopunct": 3.7212229172679243,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7188755020080321,
        "vocab_size-1-nopunct": 179,
        "unique-1-nopunct": 150,
        "entropy-1-nopunct": 7.130030214779477,
        "distinct-2-nopunct": 0.9519650655021834,
        "vocab_size-2-nopunct": 218,
        "unique-2-nopunct": 209,
        "entropy-2-nopunct": 7.734400294647166,
        "cond_entropy-2-nopunct": 0.6637562560500979,
        "distinct-3-nopunct": 0.9856459330143541,
        "vocab_size-3-nopunct": 206,
        "unique-3-nopunct": 203,
        "entropy-3-nopunct": 7.678650998109609,
        "cond_entropy-3-nopunct": -0.05528963209261657,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.825,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.3939393939393939,
            "3": 0.7475728155339806
        },
        "rouge1": {
            "precision": 0.77257,
            "recall": 0.66793,
            "fmeasure": 0.70582
        },
        "rouge2": {
            "precision": 0.55367,
            "recall": 0.46952,
            "fmeasure": 0.49806
        },
        "rougeL": {
            "precision": 0.6714,
            "recall": 0.57872,
            "fmeasure": 0.61151
        },
        "rougeLsum": {
            "precision": 0.6714,
            "recall": 0.57872,
            "fmeasure": 0.61151
        },
        "nist": 5.7122203605764215,
        "bleu": 43.48001,
        "meteor": 0.37089609156935877,
        "bleurt": 0.13431,
        "nubia": {
            "semantic_relation": 4.07262,
            "contradiction": 12.38439,
            "irrelevancy": 27.03551,
            "logical_agreement": 60.5801,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.82107,
            "nubia_score": 0.67354
        },
        "bertscore": {
            "precision": 0.92405,
            "recall": 0.90253,
            "f1": 0.9112
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 67,
        "mean_pred_length": 13.4,
        "std_pred_length": 4.223742416388575,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.835820895522388,
        "vocab_size-1": 56,
        "unique-1": 51,
        "entropy-1": 5.642738026627913,
        "distinct-2": 0.9838709677419355,
        "vocab_size-2": 61,
        "unique-2": 60,
        "entropy-2": 5.921938245870744,
        "cond_entropy-2": 0.1260891764156105,
        "distinct-3": 1.0,
        "vocab_size-3": 57,
        "unique-3": 57,
        "entropy-3": 5.832890014164737,
        "cond_entropy-3": -0.0862185769238879,
        "total_length-nopunct": 61,
        "mean_pred_length-nopunct": 12.2,
        "std_pred_length-nopunct": 3.9698866482558417,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8852459016393442,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.656067050642171,
        "distinct-2-nopunct": 0.9821428571428571,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.7716406363433235,
        "cond_entropy-2-nopunct": 0.1400977184619228,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.6724253419715005,
        "cond_entropy-3-nopunct": -0.09571389381159895,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.7755102040816326
        },
        "rouge1": {
            "precision": 0.7461,
            "recall": 0.79206,
            "fmeasure": 0.75284
        },
        "rouge2": {
            "precision": 0.52738,
            "recall": 0.58198,
            "fmeasure": 0.53997
        },
        "rougeL": {
            "precision": 0.66045,
            "recall": 0.71444,
            "fmeasure": 0.67241
        },
        "rougeLsum": {
            "precision": 0.66045,
            "recall": 0.71444,
            "fmeasure": 0.67241
        },
        "nist": 5.066545132198968,
        "bleu": 46.75741,
        "meteor": 0.39879989432909385,
        "bleurt": 0.15283,
        "nubia": {
            "semantic_relation": 4.12218,
            "contradiction": 31.35996,
            "irrelevancy": 28.01202,
            "logical_agreement": 40.62802,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.6367,
            "nubia_score": 0.65137
        },
        "bertscore": {
            "precision": 0.92006,
            "recall": 0.92964,
            "f1": 0.92305
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.375
        },
        "rouge1": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "nist": 1.1385968363511052,
        "bleu": 4.36858,
        "meteor": 0.2248648934411714,
        "bleurt": -0.59749,
        "nubia": {
            "semantic_relation": 2.68817,
            "contradiction": 0.28946,
            "irrelevancy": 99.6354,
            "logical_agreement": 0.07515,
            "grammar_ref": 3.85254,
            "grammar_hyp": 4.78306,
            "nubia_score": 0.24908
        },
        "bertscore": {
            "precision": 0.80999,
            "recall": 0.83938,
            "f1": 0.82442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 63,
        "mean_pred_length": 15.75,
        "std_pred_length": 2.8613807855648994,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.5873015873015873,
        "vocab_size-1": 37,
        "unique-1": 21,
        "entropy-1": 5.0107108284272,
        "distinct-2": 0.8813559322033898,
        "vocab_size-2": 52,
        "unique-2": 47,
        "entropy-2": 5.619765506915618,
        "cond_entropy-2": 0.5671297018342897,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": 0.15189507331928712,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 2.165063509461097,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.971735622379553,
        "distinct-2-nopunct": 0.9019607843137255,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.446743479141559,
        "cond_entropy-2-nopunct": 0.45674455015686677,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": 0.05960712678879351,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.7068965517241379
        },
        "rouge1": {
            "precision": 0.79487,
            "recall": 0.745,
            "fmeasure": 0.72906
        },
        "rouge2": {
            "precision": 0.54712,
            "recall": 0.55132,
            "fmeasure": 0.52097
        },
        "rougeL": {
            "precision": 0.71106,
            "recall": 0.70912,
            "fmeasure": 0.67794
        },
        "rougeLsum": {
            "precision": 0.71106,
            "recall": 0.70912,
            "fmeasure": 0.67794
        },
        "nist": 3.890624998022953,
        "bleu": 37.43103,
        "meteor": 0.3593148990021383,
        "bleurt": 0.28425,
        "nubia": {
            "semantic_relation": 4.377,
            "contradiction": 4.82721,
            "irrelevancy": 15.70091,
            "logical_agreement": 79.47187,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.67426,
            "nubia_score": 0.73591
        },
        "bertscore": {
            "precision": 0.9408,
            "recall": 0.92408,
            "f1": 0.92683
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "t5-small/totto_test",
        "N": 29,
        "total_length": 412,
        "mean_pred_length": 14.206896551724139,
        "std_pred_length": 4.221286863315724,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.5970873786407767,
        "vocab_size-1": 246,
        "unique-1": 209,
        "entropy-1": 7.127678674259541,
        "distinct-2": 0.9477806788511749,
        "vocab_size-2": 363,
        "unique-2": 350,
        "entropy-2": 8.451562241312898,
        "cond_entropy-2": 1.0703744455446047,
        "distinct-3": 0.9915254237288136,
        "vocab_size-3": 351,
        "unique-3": 348,
        "entropy-3": 8.450656397540596,
        "cond_entropy-3": 0.004064528763699038,
        "total_length-nopunct": 355,
        "mean_pred_length-nopunct": 12.241379310344827,
        "std_pred_length-nopunct": 3.682719875813238,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.676056338028169,
        "vocab_size-1-nopunct": 240,
        "unique-1-nopunct": 208,
        "entropy-1-nopunct": 7.337620781607453,
        "distinct-2-nopunct": 0.9447852760736196,
        "vocab_size-2-nopunct": 308,
        "unique-2-nopunct": 297,
        "entropy-2-nopunct": 8.208692925843376,
        "cond_entropy-2-nopunct": 0.9591631060436299,
        "distinct-3-nopunct": 0.9932659932659933,
        "vocab_size-3-nopunct": 295,
        "unique-3-nopunct": 293,
        "entropy-3-nopunct": 8.20085110733278,
        "cond_entropy-3-nopunct": 0.005831654968352226,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.78333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2153846153846154,
            "2": 0.2857142857142857,
            "3": 0.7671641791044777
        },
        "rouge1": {
            "precision": 0.83114,
            "recall": 0.73129,
            "fmeasure": 0.76962
        },
        "rouge2": {
            "precision": 0.60356,
            "recall": 0.55436,
            "fmeasure": 0.56651
        },
        "rougeL": {
            "precision": 0.70373,
            "recall": 0.6323,
            "fmeasure": 0.65418
        },
        "rougeLsum": {
            "precision": 0.70373,
            "recall": 0.6323,
            "fmeasure": 0.65418
        },
        "nist": 6.6864229959717045,
        "bleu": 48.88857,
        "meteor": 0.4152320880215928,
        "bleurt": 0.38881,
        "nubia": {
            "semantic_relation": 4.4111,
            "contradiction": 4.16656,
            "irrelevancy": 21.80249,
            "logical_agreement": 74.03095,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.74966,
            "nubia_score": 0.7967
        },
        "bertscore": {
            "precision": 0.94943,
            "recall": 0.93607,
            "f1": 0.94052
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 124,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.387482193696061,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.75,
        "vocab_size-1": 93,
        "unique-1": 79,
        "entropy-1": 6.275318814682155,
        "distinct-2": 0.9741379310344828,
        "vocab_size-2": 113,
        "unique-2": 111,
        "entropy-2": 6.799749206315803,
        "cond_entropy-2": 0.43754457233460686,
        "distinct-3": 1.0,
        "vocab_size-3": 108,
        "unique-3": 108,
        "entropy-3": 6.754887502163458,
        "cond_entropy-3": -0.040548238314441674,
        "total_length-nopunct": 109,
        "mean_pred_length-nopunct": 13.625,
        "std_pred_length-nopunct": 4.498263553861645,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8165137614678899,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.31846368249569,
        "distinct-2-nopunct": 0.9900990099009901,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 99,
        "entropy-2-nopunct": 6.63840950255376,
        "cond_entropy-2-nopunct": 0.3258642867734216,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 93,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.539158811108037,
        "cond_entropy-3-nopunct": -0.09754729529967726,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.83,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.4166666666666667,
            "3": 0.6447368421052632
        },
        "rouge1": {
            "precision": 0.63623,
            "recall": 0.64708,
            "fmeasure": 0.62435
        },
        "rouge2": {
            "precision": 0.43739,
            "recall": 0.431,
            "fmeasure": 0.41924
        },
        "rougeL": {
            "precision": 0.54859,
            "recall": 0.55977,
            "fmeasure": 0.54116
        },
        "rougeLsum": {
            "precision": 0.54859,
            "recall": 0.55977,
            "fmeasure": 0.54116
        },
        "nist": 4.475704198761289,
        "bleu": 35.6072,
        "meteor": 0.33872989906218,
        "bleurt": 0.05594,
        "nubia": {
            "semantic_relation": 3.88172,
            "contradiction": 3.80611,
            "irrelevancy": 54.58848,
            "logical_agreement": 41.60541,
            "grammar_ref": 4.75129,
            "grammar_hyp": 4.47913,
            "nubia_score": 0.66697
        },
        "bertscore": {
            "precision": 0.88156,
            "recall": 0.89578,
            "f1": 0.88568
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "t5-small/totto_test",
        "N": 16,
        "total_length": 264,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.568916720624267,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6212121212121212,
        "vocab_size-1": 164,
        "unique-1": 132,
        "entropy-1": 6.843718943838607,
        "distinct-2": 0.9354838709677419,
        "vocab_size-2": 232,
        "unique-2": 219,
        "entropy-2": 7.814055634974948,
        "cond_entropy-2": 0.8328682794408007,
        "distinct-3": 0.9956896551724138,
        "vocab_size-3": 231,
        "unique-3": 230,
        "entropy-3": 7.849360305472379,
        "cond_entropy-3": 0.03634885500864312,
        "total_length-nopunct": 233,
        "mean_pred_length-nopunct": 14.5625,
        "std_pred_length-nopunct": 4.182833220438032,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6824034334763949,
        "vocab_size-1-nopunct": 159,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.909718054897691,
        "distinct-2-nopunct": 0.9447004608294931,
        "vocab_size-2-nopunct": 205,
        "unique-2-nopunct": 196,
        "entropy-2-nopunct": 7.638256819992128,
        "cond_entropy-2-nopunct": 0.777785432999438,
        "distinct-3-nopunct": 0.9950248756218906,
        "vocab_size-3-nopunct": 200,
        "unique-3-nopunct": 199,
        "entropy-3-nopunct": 7.6411014424227215,
        "cond_entropy-3-nopunct": 0.012659103023819668,
        "msttr-100": 0.755,
        "msttr-100_nopunct": 0.795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.35,
            "3": 0.839572192513369
        },
        "rouge1": {
            "precision": 0.81889,
            "recall": 0.7854,
            "fmeasure": 0.79315
        },
        "rouge2": {
            "precision": 0.61057,
            "recall": 0.59876,
            "fmeasure": 0.59625
        },
        "rougeL": {
            "precision": 0.74112,
            "recall": 0.71306,
            "fmeasure": 0.71863
        },
        "rougeLsum": {
            "precision": 0.74112,
            "recall": 0.71306,
            "fmeasure": 0.71863
        },
        "nist": 6.465252893075859,
        "bleu": 54.0646,
        "meteor": 0.42100045763292626,
        "bleurt": 0.34054,
        "nubia": {
            "semantic_relation": 4.29597,
            "contradiction": 11.26853,
            "irrelevancy": 24.3624,
            "logical_agreement": 64.36907,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.6505,
            "nubia_score": 0.76718
        },
        "bertscore": {
            "precision": 0.9436,
            "recall": 0.94111,
            "f1": 0.94096
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 70,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.2895221179054435,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.6142857142857143,
        "vocab_size-1": 43,
        "unique-1": 28,
        "entropy-1": 5.188221545788863,
        "distinct-2": 0.8615384615384616,
        "vocab_size-2": 56,
        "unique-2": 49,
        "entropy-2": 5.722217428346505,
        "cond_entropy-2": 0.48330830341579994,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 56,
        "unique-3": 53,
        "entropy-3": 5.760975803905793,
        "cond_entropy-3": -0.015477217419935886,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 11.8,
        "std_pred_length-nopunct": 2.7129319932501073,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6610169491525424,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 5.098496227217932,
        "distinct-2-nopunct": 0.8703703703703703,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.481648844715997,
        "cond_entropy-2-nopunct": 0.34918681395280243,
        "distinct-3-nopunct": 0.9591836734693877,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.533077191053984,
        "cond_entropy-3-nopunct": -0.03813684172172959,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.55111,
            "recall": 0.58469,
            "fmeasure": 0.56069
        },
        "rouge2": {
            "precision": 0.42625,
            "recall": 0.47838,
            "fmeasure": 0.44585
        },
        "rougeL": {
            "precision": 0.48556,
            "recall": 0.52322,
            "fmeasure": 0.49756
        },
        "rougeLsum": {
            "precision": 0.48556,
            "recall": 0.52322,
            "fmeasure": 0.49756
        },
        "nist": 2.7849998979669017,
        "bleu": 27.29025,
        "meteor": 0.2566374774661105,
        "bleurt": -0.02676,
        "nubia": {
            "semantic_relation": 3.84206,
            "contradiction": 18.08368,
            "irrelevancy": 16.62756,
            "logical_agreement": 65.28875,
            "grammar_ref": 3.91039,
            "grammar_hyp": 3.20656,
            "nubia_score": 0.69857
        },
        "bertscore": {
            "precision": 0.86236,
            "recall": 0.85655,
            "f1": 0.85913
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "t5-small/totto_test",
        "N": 21,
        "total_length": 297,
        "mean_pred_length": 14.142857142857142,
        "std_pred_length": 3.9434782119549316,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.6464646464646465,
        "vocab_size-1": 192,
        "unique-1": 161,
        "entropy-1": 6.998693690242316,
        "distinct-2": 0.9420289855072463,
        "vocab_size-2": 260,
        "unique-2": 250,
        "entropy-2": 7.965373098066798,
        "cond_entropy-2": 0.792598983546369,
        "distinct-3": 0.996078431372549,
        "vocab_size-3": 254,
        "unique-3": 253,
        "entropy-3": 7.986510299603968,
        "cond_entropy-3": 0.021161431078049443,
        "total_length-nopunct": 262,
        "mean_pred_length-nopunct": 12.476190476190476,
        "std_pred_length-nopunct": 3.4450661424163664,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7137404580152672,
        "vocab_size-1-nopunct": 187,
        "unique-1-nopunct": 160,
        "entropy-1-nopunct": 7.102162078769251,
        "distinct-2-nopunct": 0.946058091286307,
        "vocab_size-2-nopunct": 228,
        "unique-2-nopunct": 221,
        "entropy-2-nopunct": 7.773844626668469,
        "cond_entropy-2-nopunct": 0.7209939754351469,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 220,
        "unique-3-nopunct": 220,
        "entropy-3-nopunct": 7.781359713524644,
        "cond_entropy-3-nopunct": 0.020787536405275087,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.755,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.40425531914893614,
            "3": 0.6185567010309279
        },
        "rouge1": {
            "precision": 0.66773,
            "recall": 0.59278,
            "fmeasure": 0.61486
        },
        "rouge2": {
            "precision": 0.42917,
            "recall": 0.38462,
            "fmeasure": 0.39544
        },
        "rougeL": {
            "precision": 0.58246,
            "recall": 0.51652,
            "fmeasure": 0.53502
        },
        "rougeLsum": {
            "precision": 0.58246,
            "recall": 0.51652,
            "fmeasure": 0.53502
        },
        "nist": 5.221163165132615,
        "bleu": 34.57923,
        "meteor": 0.3114218166207845,
        "bleurt": 0.00016,
        "nubia": {
            "semantic_relation": 3.54653,
            "contradiction": 14.70635,
            "irrelevancy": 37.25395,
            "logical_agreement": 48.0397,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.84019,
            "nubia_score": 0.55035
        },
        "bertscore": {
            "precision": 0.89634,
            "recall": 0.88479,
            "f1": 0.88821
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "t5-small/totto_test",
        "N": 9,
        "total_length": 135,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.4318767136623336,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 90,
        "unique-1": 78,
        "entropy-1": 5.993166865476494,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 119,
        "unique-2": 116,
        "entropy-2": 6.8224404393386004,
        "cond_entropy-2": 0.7082643562761545,
        "distinct-3": 1.0,
        "vocab_size-3": 117,
        "unique-3": 117,
        "entropy-3": 6.8703647195833835,
        "cond_entropy-3": 0.04274099270166687,
        "total_length-nopunct": 118,
        "mean_pred_length-nopunct": 13.11111111111111,
        "std_pred_length-nopunct": 2.6851213274654606,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7372881355932204,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.049655093747108,
        "distinct-2-nopunct": 0.944954128440367,
        "vocab_size-2-nopunct": 103,
        "unique-2-nopunct": 101,
        "entropy-2-nopunct": 6.607544187122539,
        "cond_entropy-2-nopunct": 0.588411722724889,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 100,
        "unique-3-nopunct": 100,
        "entropy-3-nopunct": 6.6438561897747395,
        "cond_entropy-3-nopunct": 0.05076961504106785,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.4090909090909091,
            "3": 0.746268656716418
        },
        "rouge1": {
            "precision": 0.64523,
            "recall": 0.65132,
            "fmeasure": 0.63303
        },
        "rouge2": {
            "precision": 0.37372,
            "recall": 0.37689,
            "fmeasure": 0.36797
        },
        "rougeL": {
            "precision": 0.52012,
            "recall": 0.54123,
            "fmeasure": 0.51757
        },
        "rougeLsum": {
            "precision": 0.52012,
            "recall": 0.54123,
            "fmeasure": 0.51757
        },
        "nist": 4.4847934347458205,
        "bleu": 26.04951,
        "meteor": 0.30290162482820343,
        "bleurt": 0.03659,
        "nubia": {
            "semantic_relation": 3.89538,
            "contradiction": 2.03291,
            "irrelevancy": 48.69272,
            "logical_agreement": 49.27437,
            "grammar_ref": 5.14381,
            "grammar_hyp": 4.6545,
            "nubia_score": 0.6409
        },
        "bertscore": {
            "precision": 0.8738,
            "recall": 0.89536,
            "f1": 0.88084
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "t5-small/totto_test",
        "N": 11,
        "total_length": 184,
        "mean_pred_length": 16.727272727272727,
        "std_pred_length": 5.1538319211121335,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.7065217391304348,
        "vocab_size-1": 130,
        "unique-1": 114,
        "entropy-1": 6.554753835109982,
        "distinct-2": 0.976878612716763,
        "vocab_size-2": 169,
        "unique-2": 166,
        "entropy-2": 7.3840219414970525,
        "cond_entropy-2": 0.7476637816448816,
        "distinct-3": 1.0,
        "vocab_size-3": 162,
        "unique-3": 162,
        "entropy-3": 7.339850002884606,
        "cond_entropy-3": -0.040735709306646335,
        "total_length-nopunct": 162,
        "mean_pred_length-nopunct": 14.727272727272727,
        "std_pred_length-nopunct": 4.956004789250549,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7716049382716049,
        "vocab_size-1-nopunct": 125,
        "unique-1-nopunct": 113,
        "entropy-1-nopunct": 6.588421797691557,
        "distinct-2-nopunct": 0.9735099337748344,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.180425351893514,
        "cond_entropy-2-nopunct": 0.6296244002708508,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 140,
        "unique-3-nopunct": 140,
        "entropy-3-nopunct": 7.129283016944978,
        "cond_entropy-3-nopunct": -0.04658681165037329,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.83,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.675,
            "3": 0.5462184873949579
        },
        "rouge1": {
            "precision": 0.68552,
            "recall": 0.64521,
            "fmeasure": 0.63013
        },
        "rouge2": {
            "precision": 0.42385,
            "recall": 0.40206,
            "fmeasure": 0.39296
        },
        "rougeL": {
            "precision": 0.53093,
            "recall": 0.49229,
            "fmeasure": 0.48619
        },
        "rougeLsum": {
            "precision": 0.53093,
            "recall": 0.49229,
            "fmeasure": 0.48619
        },
        "nist": 4.349006414108614,
        "bleu": 31.89175,
        "meteor": 0.31016756862738715,
        "bleurt": -0.1776,
        "nubia": {
            "semantic_relation": 3.27167,
            "contradiction": 22.97225,
            "irrelevancy": 28.95094,
            "logical_agreement": 48.0768,
            "grammar_ref": 4.70623,
            "grammar_hyp": 4.83432,
            "nubia_score": 0.47823
        },
        "bertscore": {
            "precision": 0.8917,
            "recall": 0.89186,
            "f1": 0.89013
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "t5-small/totto_test",
        "N": 16,
        "total_length": 256,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.031128874149275,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.578125,
        "vocab_size-1": 148,
        "unique-1": 111,
        "entropy-1": 6.683508691134911,
        "distinct-2": 0.8541666666666666,
        "vocab_size-2": 205,
        "unique-2": 181,
        "entropy-2": 7.576539710128788,
        "cond_entropy-2": 0.7391162369725638,
        "distinct-3": 0.90625,
        "vocab_size-3": 203,
        "unique-3": 187,
        "entropy-3": 7.603004754598566,
        "cond_entropy-3": 0.03666867914697368,
        "total_length-nopunct": 219,
        "mean_pred_length-nopunct": 13.6875,
        "std_pred_length-nopunct": 2.9094404530768454,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6575342465753424,
        "vocab_size-1-nopunct": 144,
        "unique-1-nopunct": 111,
        "entropy-1-nopunct": 6.804952315875384,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 174,
        "unique-2-nopunct": 154,
        "entropy-2-nopunct": 7.343738811199247,
        "cond_entropy-2-nopunct": 0.6053744554204759,
        "distinct-3-nopunct": 0.9037433155080213,
        "vocab_size-3-nopunct": 169,
        "unique-3-nopunct": 156,
        "entropy-3-nopunct": 7.3341969330918015,
        "cond_entropy-3-nopunct": 0.012626858233620654,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.34146341463414637,
            "3": 0.772972972972973
        },
        "rouge1": {
            "precision": 0.77226,
            "recall": 0.73571,
            "fmeasure": 0.74164
        },
        "rouge2": {
            "precision": 0.55831,
            "recall": 0.52922,
            "fmeasure": 0.53289
        },
        "rougeL": {
            "precision": 0.68162,
            "recall": 0.65206,
            "fmeasure": 0.65557
        },
        "rougeLsum": {
            "precision": 0.68162,
            "recall": 0.65206,
            "fmeasure": 0.65557
        },
        "nist": 5.900793137038239,
        "bleu": 47.45712,
        "meteor": 0.4017662167804374,
        "bleurt": 0.34631,
        "nubia": {
            "semantic_relation": 4.24754,
            "contradiction": 0.91662,
            "irrelevancy": 37.00345,
            "logical_agreement": 62.07992,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.44133,
            "nubia_score": 0.73633
        },
        "bertscore": {
            "precision": 0.9391,
            "recall": 0.93009,
            "f1": 0.93323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "t5-small/totto_test",
        "N": 15,
        "total_length": 203,
        "mean_pred_length": 13.533333333333333,
        "std_pred_length": 4.145144415122617,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6305418719211823,
        "vocab_size-1": 128,
        "unique-1": 103,
        "entropy-1": 6.507573351524061,
        "distinct-2": 0.9308510638297872,
        "vocab_size-2": 175,
        "unique-2": 165,
        "entropy-2": 7.404244902175048,
        "cond_entropy-2": 0.7548996808438591,
        "distinct-3": 0.9710982658959537,
        "vocab_size-3": 168,
        "unique-3": 164,
        "entropy-3": 7.372461247855433,
        "cond_entropy-3": -0.057793644259621045,
        "total_length-nopunct": 181,
        "mean_pred_length-nopunct": 12.066666666666666,
        "std_pred_length-nopunct": 4.31225643434566,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6906077348066298,
        "vocab_size-1-nopunct": 125,
        "unique-1-nopunct": 102,
        "entropy-1-nopunct": 6.596658451682235,
        "distinct-2-nopunct": 0.9397590361445783,
        "vocab_size-2-nopunct": 156,
        "unique-2-nopunct": 148,
        "entropy-2-nopunct": 7.2454624734895186,
        "cond_entropy-2-nopunct": 0.6766534135386573,
        "distinct-3-nopunct": 0.9801324503311258,
        "vocab_size-3-nopunct": 148,
        "unique-3-nopunct": 145,
        "entropy-3-nopunct": 7.198669639987311,
        "cond_entropy-3-nopunct": -0.06541027147771677,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1346153846153846,
            "2": 0.3181818181818182,
            "3": 0.7133757961783439
        },
        "rouge1": {
            "precision": 0.79755,
            "recall": 0.67068,
            "fmeasure": 0.71852
        },
        "rouge2": {
            "precision": 0.52665,
            "recall": 0.46249,
            "fmeasure": 0.48792
        },
        "rougeL": {
            "precision": 0.69284,
            "recall": 0.58662,
            "fmeasure": 0.62751
        },
        "rougeLsum": {
            "precision": 0.69284,
            "recall": 0.58662,
            "fmeasure": 0.62751
        },
        "nist": 4.548710412965216,
        "bleu": 39.63266,
        "meteor": 0.3588240732746155,
        "bleurt": 0.28922,
        "nubia": {
            "semantic_relation": 4.21383,
            "contradiction": 5.11229,
            "irrelevancy": 30.34006,
            "logical_agreement": 64.54765,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.86365,
            "nubia_score": 0.6875
        },
        "bertscore": {
            "precision": 0.93033,
            "recall": 0.91403,
            "f1": 0.92147
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "t5-small/totto_test",
        "N": 33,
        "total_length": 512,
        "mean_pred_length": 15.515151515151516,
        "std_pred_length": 4.0235760675029555,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.572265625,
        "vocab_size-1": 293,
        "unique-1": 253,
        "entropy-1": 7.20535010004601,
        "distinct-2": 0.9248434237995825,
        "vocab_size-2": 443,
        "unique-2": 415,
        "entropy-2": 8.725835473053204,
        "cond_entropy-2": 1.3319567732897393,
        "distinct-3": 0.9730941704035875,
        "vocab_size-3": 434,
        "unique-3": 423,
        "entropy-3": 8.745395667852721,
        "cond_entropy-3": 0.023765419684081045,
        "total_length-nopunct": 440,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 3.615343285319815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6522727272727272,
        "vocab_size-1-nopunct": 287,
        "unique-1-nopunct": 252,
        "entropy-1-nopunct": 7.375783187542527,
        "distinct-2-nopunct": 0.9336609336609336,
        "vocab_size-2-nopunct": 380,
        "unique-2-nopunct": 361,
        "entropy-2-nopunct": 8.503567508799058,
        "cond_entropy-2-nopunct": 1.2120772199306649,
        "distinct-3-nopunct": 0.9786096256684492,
        "vocab_size-3-nopunct": 366,
        "unique-3-nopunct": 359,
        "entropy-3-nopunct": 8.502095295443302,
        "cond_entropy-3-nopunct": 0.00776702913203365,
        "msttr-100": 0.708,
        "msttr-100_nopunct": 0.7575,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1625,
            "2": 0.208955223880597,
            "3": 0.7682926829268293
        },
        "rouge1": {
            "precision": 0.83798,
            "recall": 0.75808,
            "fmeasure": 0.78533
        },
        "rouge2": {
            "precision": 0.60518,
            "recall": 0.54713,
            "fmeasure": 0.56645
        },
        "rougeL": {
            "precision": 0.7285,
            "recall": 0.65549,
            "fmeasure": 0.68088
        },
        "rougeLsum": {
            "precision": 0.7285,
            "recall": 0.65549,
            "fmeasure": 0.68088
        },
        "nist": 6.714049830243365,
        "bleu": 46.4009,
        "meteor": 0.3993921776876619,
        "bleurt": 0.30727,
        "nubia": {
            "semantic_relation": 4.43865,
            "contradiction": 4.31083,
            "irrelevancy": 20.57357,
            "logical_agreement": 75.1156,
            "grammar_ref": 4.92209,
            "grammar_hyp": 5.05332,
            "nubia_score": 0.77974
        },
        "bertscore": {
            "precision": 0.94648,
            "recall": 0.92945,
            "f1": 0.93725
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "t5-small/totto_test",
        "N": 19,
        "total_length": 290,
        "mean_pred_length": 15.263157894736842,
        "std_pred_length": 4.165549249980922,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.6,
        "vocab_size-1": 174,
        "unique-1": 147,
        "entropy-1": 6.664671004941995,
        "distinct-2": 0.915129151291513,
        "vocab_size-2": 248,
        "unique-2": 236,
        "entropy-2": 7.874530360518083,
        "cond_entropy-2": 1.1122745742610176,
        "distinct-3": 0.9603174603174603,
        "vocab_size-3": 242,
        "unique-3": 235,
        "entropy-3": 7.886982750872295,
        "cond_entropy-3": 0.020169671845755053,
        "total_length-nopunct": 247,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.684962329308273,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6882591093117408,
        "vocab_size-1-nopunct": 170,
        "unique-1-nopunct": 145,
        "entropy-1-nopunct": 6.909066055399653,
        "distinct-2-nopunct": 0.9429824561403509,
        "vocab_size-2-nopunct": 215,
        "unique-2-nopunct": 205,
        "entropy-2-nopunct": 7.7067720865237055,
        "cond_entropy-2-nopunct": 0.8522007427583761,
        "distinct-3-nopunct": 0.9856459330143541,
        "vocab_size-3-nopunct": 206,
        "unique-3-nopunct": 203,
        "entropy-3-nopunct": 7.6786509981096085,
        "cond_entropy-3-nopunct": -0.0214405112601101,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.3076923076923077,
            "3": 0.6705202312138728
        },
        "rouge1": {
            "precision": 0.68293,
            "recall": 0.59138,
            "fmeasure": 0.61585
        },
        "rouge2": {
            "precision": 0.42763,
            "recall": 0.38186,
            "fmeasure": 0.39361
        },
        "rougeL": {
            "precision": 0.60017,
            "recall": 0.5333,
            "fmeasure": 0.54743
        },
        "rougeLsum": {
            "precision": 0.60017,
            "recall": 0.5333,
            "fmeasure": 0.54743
        },
        "nist": 4.404813090784301,
        "bleu": 34.00908,
        "meteor": 0.28652868765159295,
        "bleurt": -0.01447,
        "nubia": {
            "semantic_relation": 3.8625,
            "contradiction": 11.23805,
            "irrelevancy": 36.47564,
            "logical_agreement": 52.2863,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.55059,
            "nubia_score": 0.63878
        },
        "bertscore": {
            "precision": 0.88228,
            "recall": 0.86805,
            "f1": 0.86966
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 5.0,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 34,
        "unique-1": 32,
        "entropy-1": 4.984769618706745,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.1997752657765045,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.96875,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.9375,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": -0.026442737724814768,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.39473684210526316
        },
        "rouge1": {
            "precision": 0.60714,
            "recall": 0.473,
            "fmeasure": 0.50953
        },
        "rouge2": {
            "precision": 0.40385,
            "recall": 0.30647,
            "fmeasure": 0.33274
        },
        "rougeL": {
            "precision": 0.53571,
            "recall": 0.43623,
            "fmeasure": 0.46104
        },
        "rougeLsum": {
            "precision": 0.53571,
            "recall": 0.43623,
            "fmeasure": 0.46104
        },
        "nist": 1.8290571399719275,
        "bleu": 27.98278,
        "meteor": 0.2353905268719672,
        "bleurt": -0.2454,
        "nubia": {
            "semantic_relation": 3.10002,
            "contradiction": 16.47205,
            "irrelevancy": 64.35282,
            "logical_agreement": 19.17514,
            "grammar_ref": 4.45404,
            "grammar_hyp": 4.28357,
            "nubia_score": 0.37106
        },
        "bertscore": {
            "precision": 0.91537,
            "recall": 0.88216,
            "f1": 0.89743
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "t5-small/totto_test",
        "N": 23,
        "total_length": 371,
        "mean_pred_length": 16.130434782608695,
        "std_pred_length": 5.848108931255783,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.5822102425876011,
        "vocab_size-1": 216,
        "unique-1": 180,
        "entropy-1": 6.938304058000908,
        "distinct-2": 0.9137931034482759,
        "vocab_size-2": 318,
        "unique-2": 298,
        "entropy-2": 8.23628790113355,
        "cond_entropy-2": 1.1216127072654303,
        "distinct-3": 0.9784615384615385,
        "vocab_size-3": 318,
        "unique-3": 312,
        "entropy-3": 8.298896254062967,
        "cond_entropy-3": 0.07723321040164326,
        "total_length-nopunct": 317,
        "mean_pred_length-nopunct": 13.782608695652174,
        "std_pred_length-nopunct": 5.115675158289645,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6624605678233438,
        "vocab_size-1-nopunct": 210,
        "unique-1-nopunct": 178,
        "entropy-1-nopunct": 7.136359309787972,
        "distinct-2-nopunct": 0.9251700680272109,
        "vocab_size-2-nopunct": 272,
        "unique-2-nopunct": 258,
        "entropy-2-nopunct": 8.014616657909222,
        "cond_entropy-2-nopunct": 0.9577490864456818,
        "distinct-3-nopunct": 0.992619926199262,
        "vocab_size-3-nopunct": 269,
        "unique-3-nopunct": 267,
        "entropy-3-nopunct": 8.06738889375236,
        "cond_entropy-3-nopunct": 0.06847806905096374,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.76333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3972602739726027,
            "2": 0.29069767441860467,
            "3": 0.7478632478632479
        },
        "rouge1": {
            "precision": 0.76874,
            "recall": 0.69098,
            "fmeasure": 0.71284
        },
        "rouge2": {
            "precision": 0.56349,
            "recall": 0.50154,
            "fmeasure": 0.52006
        },
        "rougeL": {
            "precision": 0.67963,
            "recall": 0.62586,
            "fmeasure": 0.64017
        },
        "rougeLsum": {
            "precision": 0.67963,
            "recall": 0.62586,
            "fmeasure": 0.64017
        },
        "nist": 6.469323215220084,
        "bleu": 52.62595,
        "meteor": 0.3705415022327739,
        "bleurt": 0.2636,
        "nubia": {
            "semantic_relation": 4.14807,
            "contradiction": 3.75878,
            "irrelevancy": 28.02509,
            "logical_agreement": 68.21613,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.54169,
            "nubia_score": 0.71327
        },
        "bertscore": {
            "precision": 0.93898,
            "recall": 0.91371,
            "f1": 0.92426
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "t5-small/totto_test",
        "N": 26,
        "total_length": 398,
        "mean_pred_length": 15.307692307692308,
        "std_pred_length": 4.62243051925342,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5728643216080402,
        "vocab_size-1": 228,
        "unique-1": 190,
        "entropy-1": 7.008197645318557,
        "distinct-2": 0.8924731182795699,
        "vocab_size-2": 332,
        "unique-2": 307,
        "entropy-2": 8.274694992808062,
        "cond_entropy-2": 1.0963688901395159,
        "distinct-3": 0.9797687861271677,
        "vocab_size-3": 339,
        "unique-3": 332,
        "entropy-3": 8.394165799891038,
        "cond_entropy-3": 0.1335634639495133,
        "total_length-nopunct": 345,
        "mean_pred_length-nopunct": 13.26923076923077,
        "std_pred_length-nopunct": 4.2657643584860825,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6434782608695652,
        "vocab_size-1-nopunct": 222,
        "unique-1-nopunct": 189,
        "entropy-1-nopunct": 7.124408659349502,
        "distinct-2-nopunct": 0.9028213166144201,
        "vocab_size-2-nopunct": 288,
        "unique-2-nopunct": 271,
        "entropy-2-nopunct": 8.067802416569192,
        "cond_entropy-2-nopunct": 1.0286672797840228,
        "distinct-3-nopunct": 0.9761092150170648,
        "vocab_size-3-nopunct": 286,
        "unique-3-nopunct": 279,
        "entropy-3-nopunct": 8.146975284456426,
        "cond_entropy-3-nopunct": 0.10132257821860748,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21176470588235294,
            "2": 0.48507462686567165,
            "3": 0.6614173228346457
        },
        "rouge1": {
            "precision": 0.74643,
            "recall": 0.63932,
            "fmeasure": 0.67595
        },
        "rouge2": {
            "precision": 0.49582,
            "recall": 0.42389,
            "fmeasure": 0.44752
        },
        "rougeL": {
            "precision": 0.6091,
            "recall": 0.52746,
            "fmeasure": 0.55404
        },
        "rougeLsum": {
            "precision": 0.6091,
            "recall": 0.52746,
            "fmeasure": 0.55404
        },
        "nist": 5.358571787588618,
        "bleu": 37.14945,
        "meteor": 0.35063812637053193,
        "bleurt": 0.09398,
        "nubia": {
            "semantic_relation": 3.93643,
            "contradiction": 15.55201,
            "irrelevancy": 31.93328,
            "logical_agreement": 52.51471,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.63081,
            "nubia_score": 0.64478
        },
        "bertscore": {
            "precision": 0.91856,
            "recall": 0.90035,
            "f1": 0.90721
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "t5-small/totto_test",
        "N": 18,
        "total_length": 231,
        "mean_pred_length": 12.833333333333334,
        "std_pred_length": 3.8188130791298667,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 22,
        "distinct-1": 0.6190476190476191,
        "vocab_size-1": 143,
        "unique-1": 119,
        "entropy-1": 6.520673407935059,
        "distinct-2": 0.9389671361502347,
        "vocab_size-2": 200,
        "unique-2": 192,
        "entropy-2": 7.586307552270774,
        "cond_entropy-2": 0.851889980492473,
        "distinct-3": 0.9897435897435898,
        "vocab_size-3": 193,
        "unique-3": 191,
        "entropy-3": 7.586817493236827,
        "cond_entropy-3": 0.003952183136269095,
        "total_length-nopunct": 198,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.559026084010437,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.702020202020202,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 6.664851301775576,
        "distinct-2-nopunct": 0.9388888888888889,
        "vocab_size-2-nopunct": 169,
        "unique-2-nopunct": 163,
        "entropy-2-nopunct": 7.338466204805012,
        "cond_entropy-2-nopunct": 0.7422876570820647,
        "distinct-3-nopunct": 0.9876543209876543,
        "vocab_size-3-nopunct": 160,
        "unique-3-nopunct": 158,
        "entropy-3-nopunct": 7.315158644859914,
        "cond_entropy-3-nopunct": -0.012437411504081779,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17307692307692307,
            "2": 0.1724137931034483,
            "3": 0.7391304347826086
        },
        "rouge1": {
            "precision": 0.78289,
            "recall": 0.69993,
            "fmeasure": 0.72366
        },
        "rouge2": {
            "precision": 0.54061,
            "recall": 0.46867,
            "fmeasure": 0.49077
        },
        "rougeL": {
            "precision": 0.71789,
            "recall": 0.61384,
            "fmeasure": 0.64882
        },
        "rougeLsum": {
            "precision": 0.71789,
            "recall": 0.61384,
            "fmeasure": 0.64882
        },
        "nist": 5.381141496137357,
        "bleu": 36.46491,
        "meteor": 0.3864676275208398,
        "bleurt": 0.2247,
        "nubia": {
            "semantic_relation": 4.2433,
            "contradiction": 7.51958,
            "irrelevancy": 26.03298,
            "logical_agreement": 66.44744,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.84699,
            "nubia_score": 0.70041
        },
        "bertscore": {
            "precision": 0.92952,
            "recall": 0.91826,
            "f1": 0.92303
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "t5-small/totto_test",
        "N": 30,
        "total_length": 505,
        "mean_pred_length": 16.833333333333332,
        "std_pred_length": 4.2823928928682955,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5603960396039604,
        "vocab_size-1": 283,
        "unique-1": 217,
        "entropy-1": 7.3804934500412465,
        "distinct-2": 0.8778947368421053,
        "vocab_size-2": 417,
        "unique-2": 377,
        "entropy-2": 8.602554065354544,
        "cond_entropy-2": 1.0427425036490938,
        "distinct-3": 0.9393258426966292,
        "vocab_size-3": 418,
        "unique-3": 396,
        "entropy-3": 8.667831329200215,
        "cond_entropy-3": 0.07578712707238665,
        "total_length-nopunct": 444,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 4.1182520563948,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6193693693693694,
        "vocab_size-1-nopunct": 275,
        "unique-1-nopunct": 214,
        "entropy-1-nopunct": 7.496047359118838,
        "distinct-2-nopunct": 0.8695652173913043,
        "vocab_size-2-nopunct": 360,
        "unique-2-nopunct": 324,
        "entropy-2-nopunct": 8.380965029998743,
        "cond_entropy-2-nopunct": 0.9471909322699716,
        "distinct-3-nopunct": 0.9322916666666666,
        "vocab_size-3-nopunct": 358,
        "unique-3-nopunct": 337,
        "entropy-3-nopunct": 8.43971656970347,
        "cond_entropy-3-nopunct": 0.07795898195734294,
        "msttr-100": 0.728,
        "msttr-100_nopunct": 0.785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.38317757009345793,
            "3": 0.7850746268656716
        },
        "rouge1": {
            "precision": 0.74688,
            "recall": 0.71368,
            "fmeasure": 0.7183
        },
        "rouge2": {
            "precision": 0.49965,
            "recall": 0.48947,
            "fmeasure": 0.48517
        },
        "rougeL": {
            "precision": 0.61483,
            "recall": 0.60171,
            "fmeasure": 0.59709
        },
        "rougeLsum": {
            "precision": 0.61483,
            "recall": 0.60171,
            "fmeasure": 0.59709
        },
        "nist": 6.381661257389725,
        "bleu": 43.28692,
        "meteor": 0.3955848466771278,
        "bleurt": 0.18499,
        "nubia": {
            "semantic_relation": 4.18353,
            "contradiction": 10.00192,
            "irrelevancy": 41.39757,
            "logical_agreement": 48.6005,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.77403,
            "nubia_score": 0.70738
        },
        "bertscore": {
            "precision": 0.92308,
            "recall": 0.91777,
            "f1": 0.9174
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.892407118592879,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.13149514642033722,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.12928301694496638,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.839700558686835,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.08765939298884753,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.14285714285714285,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.8839,
            "recall": 0.80352,
            "fmeasure": 0.83373
        },
        "rouge2": {
            "precision": 0.74158,
            "recall": 0.65944,
            "fmeasure": 0.68737
        },
        "rougeL": {
            "precision": 0.81125,
            "recall": 0.71687,
            "fmeasure": 0.75089
        },
        "rougeLsum": {
            "precision": 0.81125,
            "recall": 0.71687,
            "fmeasure": 0.75089
        },
        "nist": 4.768680220565044,
        "bleu": 53.7662,
        "meteor": 0.4559276055673478,
        "bleurt": 0.15087,
        "nubia": {
            "semantic_relation": 4.6143,
            "contradiction": 5.92469,
            "irrelevancy": 34.97735,
            "logical_agreement": 59.09797,
            "grammar_ref": 5.80868,
            "grammar_hyp": 6.08336,
            "nubia_score": 0.7651
        },
        "bertscore": {
            "precision": 0.95315,
            "recall": 0.94202,
            "f1": 0.94678
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 105,
        "mean_pred_length": 17.5,
        "std_pred_length": 2.29128784747792,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 21,
        "distinct-1": 0.6476190476190476,
        "vocab_size-1": 68,
        "unique-1": 58,
        "entropy-1": 5.613601408949004,
        "distinct-2": 0.9595959595959596,
        "vocab_size-2": 95,
        "unique-2": 91,
        "entropy-2": 6.548548539271539,
        "cond_entropy-2": 0.8449884398980309,
        "distinct-3": 0.978494623655914,
        "vocab_size-3": 91,
        "unique-3": 89,
        "entropy-3": 6.496148058419865,
        "cond_entropy-3": -0.04718705628340612,
        "total_length-nopunct": 91,
        "mean_pred_length-nopunct": 15.166666666666666,
        "std_pred_length-nopunct": 1.863389981249825,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7252747252747253,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.671994020297931,
        "distinct-2-nopunct": 0.9529411764705882,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.315273289078884,
        "cond_entropy-2-nopunct": 0.7022769595974759,
        "distinct-3-nopunct": 0.9746835443037974,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.2531478367846995,
        "cond_entropy-3-nopunct": -0.05497727656819367,
        "msttr-100": 0.65,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.4166666666666667,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.74654,
            "recall": 0.7793,
            "fmeasure": 0.74988
        },
        "rouge2": {
            "precision": 0.40455,
            "recall": 0.4366,
            "fmeasure": 0.41023
        },
        "rougeL": {
            "precision": 0.5919,
            "recall": 0.62118,
            "fmeasure": 0.59416
        },
        "rougeLsum": {
            "precision": 0.5919,
            "recall": 0.62118,
            "fmeasure": 0.59416
        },
        "nist": 4.704229533883278,
        "bleu": 24.83813,
        "meteor": 0.37329169480554125,
        "bleurt": 0.18076,
        "nubia": {
            "semantic_relation": 4.10612,
            "contradiction": 9.08867,
            "irrelevancy": 33.84667,
            "logical_agreement": 57.06466,
            "grammar_ref": 5.40206,
            "grammar_hyp": 4.60376,
            "nubia_score": 0.75749
        },
        "bertscore": {
            "precision": 0.91018,
            "recall": 0.91739,
            "f1": 0.91295
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "t5-small/totto_test",
        "N": 18,
        "total_length": 299,
        "mean_pred_length": 16.61111111111111,
        "std_pred_length": 3.6687704402442347,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.6287625418060201,
        "vocab_size-1": 188,
        "unique-1": 161,
        "entropy-1": 6.918049896462404,
        "distinct-2": 0.9359430604982206,
        "vocab_size-2": 263,
        "unique-2": 254,
        "entropy-2": 7.978645403812329,
        "cond_entropy-2": 0.9474430628318646,
        "distinct-3": 0.9809885931558935,
        "vocab_size-3": 258,
        "unique-3": 255,
        "entropy-3": 7.995155586234053,
        "cond_entropy-3": 0.027171994191111423,
        "total_length-nopunct": 266,
        "mean_pred_length-nopunct": 14.777777777777779,
        "std_pred_length-nopunct": 3.5986966090448105,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6842105263157895,
        "vocab_size-1-nopunct": 182,
        "unique-1-nopunct": 160,
        "entropy-1-nopunct": 6.963673498181727,
        "distinct-2-nopunct": 0.9274193548387096,
        "vocab_size-2-nopunct": 230,
        "unique-2-nopunct": 221,
        "entropy-2-nopunct": 7.777686481714247,
        "cond_entropy-2-nopunct": 0.8892104064024976,
        "distinct-3-nopunct": 0.9782608695652174,
        "vocab_size-3-nopunct": 225,
        "unique-3-nopunct": 222,
        "entropy-3-nopunct": 7.795447550925551,
        "cond_entropy-3-nopunct": 0.031574881890067026,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.26,
            "3": 0.6717171717171717
        },
        "rouge1": {
            "precision": 0.68398,
            "recall": 0.64618,
            "fmeasure": 0.65409
        },
        "rouge2": {
            "precision": 0.46628,
            "recall": 0.44177,
            "fmeasure": 0.44613
        },
        "rougeL": {
            "precision": 0.58301,
            "recall": 0.5558,
            "fmeasure": 0.5617
        },
        "rougeLsum": {
            "precision": 0.58301,
            "recall": 0.5558,
            "fmeasure": 0.5617
        },
        "nist": 5.586605539184469,
        "bleu": 39.19216,
        "meteor": 0.3543695451006565,
        "bleurt": 0.04532,
        "nubia": {
            "semantic_relation": 3.7674,
            "contradiction": 6.57253,
            "irrelevancy": 39.00699,
            "logical_agreement": 54.42048,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.22236,
            "nubia_score": 0.6374
        },
        "bertscore": {
            "precision": 0.89526,
            "recall": 0.89189,
            "f1": 0.8909
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "t5-small/totto_test",
        "N": 158,
        "total_length": 2427,
        "mean_pred_length": 15.360759493670885,
        "std_pred_length": 4.379495309964929,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.4145035022661722,
        "vocab_size-1": 1006,
        "unique-1": 800,
        "entropy-1": 8.362052471120158,
        "distinct-2": 0.7809607756721022,
        "vocab_size-2": 1772,
        "unique-2": 1594,
        "entropy-2": 10.47284992836477,
        "cond_entropy-2": 1.8600736005596004,
        "distinct-3": 0.891994315490289,
        "vocab_size-3": 1883,
        "unique-3": 1790,
        "entropy-3": 10.736780937295503,
        "cond_entropy-3": 0.2708359090838123,
        "total_length-nopunct": 2102,
        "mean_pred_length-nopunct": 13.30379746835443,
        "std_pred_length-nopunct": 4.007443802774863,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.47288296860133205,
        "vocab_size-1-nopunct": 994,
        "unique-1-nopunct": 797,
        "entropy-1-nopunct": 8.671164960747904,
        "distinct-2-nopunct": 0.7993827160493827,
        "vocab_size-2-nopunct": 1554,
        "unique-2-nopunct": 1415,
        "entropy-2-nopunct": 10.295918191140537,
        "cond_entropy-2-nopunct": 1.7240780943380807,
        "distinct-3-nopunct": 0.896976483762598,
        "vocab_size-3-nopunct": 1602,
        "unique-3-nopunct": 1530,
        "entropy-3-nopunct": 10.507544653175717,
        "cond_entropy-3-nopunct": 0.24771648592868473,
        "msttr-100": 0.72625,
        "msttr-100_nopunct": 0.77619,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24734982332155478,
            "2": 0.45849802371541504,
            "3": 0.7119599248591109
        },
        "rouge1": {
            "precision": 0.73711,
            "recall": 0.67949,
            "fmeasure": 0.6929
        },
        "rouge2": {
            "precision": 0.48428,
            "recall": 0.44593,
            "fmeasure": 0.45399
        },
        "rougeL": {
            "precision": 0.62306,
            "recall": 0.58175,
            "fmeasure": 0.58899
        },
        "rougeLsum": {
            "precision": 0.62306,
            "recall": 0.58175,
            "fmeasure": 0.58899
        },
        "nist": 7.398682182543726,
        "bleu": 40.2785,
        "meteor": 0.3642650961241888,
        "bleurt": 0.16577,
        "nubia": {
            "semantic_relation": 4.07766,
            "contradiction": 8.14539,
            "irrelevancy": 34.69665,
            "logical_agreement": 57.15796,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.71164,
            "nubia_score": 0.68828
        },
        "bertscore": {
            "precision": 0.91931,
            "recall": 0.91088,
            "f1": 0.91316
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "t5-small/totto_test",
        "N": 12,
        "total_length": 156,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.69041575982343,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 22,
        "distinct-1": 0.6282051282051282,
        "vocab_size-1": 98,
        "unique-1": 81,
        "entropy-1": 6.062324136602545,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 136,
        "unique-2": 129,
        "entropy-2": 7.05357161601064,
        "cond_entropy-2": 0.7944237778696337,
        "distinct-3": 0.9772727272727273,
        "vocab_size-3": 129,
        "unique-3": 126,
        "entropy-3": 6.998939573903899,
        "cond_entropy-3": -0.05920597676443885,
        "total_length-nopunct": 136,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 4.384315479321969,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6838235294117647,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 78,
        "entropy-1-nopunct": 6.086205559269269,
        "distinct-2-nopunct": 0.9435483870967742,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.835205282143607,
        "cond_entropy-2-nopunct": 0.8136375243563834,
        "distinct-3-nopunct": 0.9821428571428571,
        "vocab_size-3-nopunct": 110,
        "unique-3-nopunct": 108,
        "entropy-3-nopunct": 6.771640636343307,
        "cond_entropy-3-nopunct": -0.06867274991709747,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13793103448275862,
            "2": 0.42857142857142855,
            "3": 0.6822429906542056
        },
        "rouge1": {
            "precision": 0.76204,
            "recall": 0.65094,
            "fmeasure": 0.69155
        },
        "rouge2": {
            "precision": 0.45244,
            "recall": 0.37215,
            "fmeasure": 0.39863
        },
        "rougeL": {
            "precision": 0.64393,
            "recall": 0.54959,
            "fmeasure": 0.5835
        },
        "rougeLsum": {
            "precision": 0.64393,
            "recall": 0.54959,
            "fmeasure": 0.5835
        },
        "nist": 4.431243061139666,
        "bleu": 31.84063,
        "meteor": 0.36020224945586027,
        "bleurt": 0.02488,
        "nubia": {
            "semantic_relation": 4.1827,
            "contradiction": 8.34324,
            "irrelevancy": 21.15932,
            "logical_agreement": 70.49744,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.64906,
            "nubia_score": 0.65224
        },
        "bertscore": {
            "precision": 0.91761,
            "recall": 0.90665,
            "f1": 0.91006
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "t5-small/totto_test",
        "N": 17,
        "total_length": 304,
        "mean_pred_length": 17.88235294117647,
        "std_pred_length": 3.848335819716736,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.5625,
        "vocab_size-1": 171,
        "unique-1": 131,
        "entropy-1": 6.809874361603118,
        "distinct-2": 0.867595818815331,
        "vocab_size-2": 249,
        "unique-2": 222,
        "entropy-2": 7.8677493917796815,
        "cond_entropy-2": 0.9538469279901151,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 252,
        "unique-3": 237,
        "entropy-3": 7.935094624804583,
        "cond_entropy-3": 0.08235144818497235,
        "total_length-nopunct": 267,
        "mean_pred_length-nopunct": 15.705882352941176,
        "std_pred_length-nopunct": 3.9072286836272037,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6217228464419475,
        "vocab_size-1-nopunct": 166,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.885594600930077,
        "distinct-2-nopunct": 0.856,
        "vocab_size-2-nopunct": 214,
        "unique-2-nopunct": 188,
        "entropy-2-nopunct": 7.643666984610176,
        "cond_entropy-2-nopunct": 0.8339792741715706,
        "distinct-3-nopunct": 0.9313304721030042,
        "vocab_size-3-nopunct": 217,
        "unique-3-nopunct": 203,
        "entropy-3-nopunct": 7.72036736781171,
        "cond_entropy-3-nopunct": 0.09591065831259579,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18,
            "2": 0.5714285714285714,
            "3": 0.7122641509433962
        },
        "rouge1": {
            "precision": 0.70268,
            "recall": 0.70875,
            "fmeasure": 0.68862
        },
        "rouge2": {
            "precision": 0.43754,
            "recall": 0.45355,
            "fmeasure": 0.43183
        },
        "rougeL": {
            "precision": 0.56802,
            "recall": 0.57512,
            "fmeasure": 0.55497
        },
        "rougeLsum": {
            "precision": 0.56802,
            "recall": 0.57512,
            "fmeasure": 0.55497
        },
        "nist": 5.551819941389113,
        "bleu": 37.93597,
        "meteor": 0.35451951565934225,
        "bleurt": -0.02725,
        "nubia": {
            "semantic_relation": 3.72657,
            "contradiction": 25.53315,
            "irrelevancy": 47.34044,
            "logical_agreement": 27.12641,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.40839,
            "nubia_score": 0.5818
        },
        "bertscore": {
            "precision": 0.88988,
            "recall": 0.90479,
            "f1": 0.89397
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "t5-small/totto_test",
        "N": 10,
        "total_length": 140,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.753945729601885,
        "median_pred_length": 13.5,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.65,
        "vocab_size-1": 91,
        "unique-1": 73,
        "entropy-1": 6.106906703037056,
        "distinct-2": 0.9384615384615385,
        "vocab_size-2": 122,
        "unique-2": 115,
        "entropy-2": 6.8934840630118135,
        "cond_entropy-2": 0.6380730378678285,
        "distinct-3": 0.9833333333333333,
        "vocab_size-3": 118,
        "unique-3": 116,
        "entropy-3": 6.8735572622752015,
        "cond_entropy-3": -0.017519821568573662,
        "total_length-nopunct": 126,
        "mean_pred_length-nopunct": 12.6,
        "std_pred_length-nopunct": 5.0635955604688645,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6984126984126984,
        "vocab_size-1-nopunct": 88,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.131221519260814,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 108,
        "unique-2-nopunct": 101,
        "entropy-2-nopunct": 6.713542309764079,
        "cond_entropy-2-nopunct": 0.6293947908687265,
        "distinct-3-nopunct": 0.9811320754716981,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.69018460550658,
        "cond_entropy-3-nopunct": -0.01916537544962317,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.25806451612903225,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.73713,
            "recall": 0.65637,
            "fmeasure": 0.6727
        },
        "rouge2": {
            "precision": 0.50643,
            "recall": 0.44924,
            "fmeasure": 0.46031
        },
        "rougeL": {
            "precision": 0.70783,
            "recall": 0.62821,
            "fmeasure": 0.64579
        },
        "rougeLsum": {
            "precision": 0.70783,
            "recall": 0.62821,
            "fmeasure": 0.64579
        },
        "nist": 4.571334222680426,
        "bleu": 36.21051,
        "meteor": 0.350592305063236,
        "bleurt": 0.07882,
        "nubia": {
            "semantic_relation": 3.85812,
            "contradiction": 12.96953,
            "irrelevancy": 35.68965,
            "logical_agreement": 51.34082,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.71985,
            "nubia_score": 0.54934
        },
        "bertscore": {
            "precision": 0.90852,
            "recall": 0.8935,
            "f1": 0.89986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "t5-small/totto_test",
        "N": 11,
        "total_length": 172,
        "mean_pred_length": 15.636363636363637,
        "std_pred_length": 4.995866059648758,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.6976744186046512,
        "vocab_size-1": 120,
        "unique-1": 104,
        "entropy-1": 6.480275600746468,
        "distinct-2": 0.937888198757764,
        "vocab_size-2": 151,
        "unique-2": 143,
        "entropy-2": 7.1973157911312065,
        "cond_entropy-2": 0.6129156915777104,
        "distinct-3": 0.9666666666666667,
        "vocab_size-3": 145,
        "unique-3": 140,
        "entropy-3": 7.162152023829198,
        "cond_entropy-3": -0.035932770928031016,
        "total_length-nopunct": 155,
        "mean_pred_length-nopunct": 14.090909090909092,
        "std_pred_length-nopunct": 5.195357113538017,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.7483870967741936,
        "vocab_size-1-nopunct": 116,
        "unique-1-nopunct": 102,
        "entropy-1-nopunct": 6.508004082526112,
        "distinct-2-nopunct": 0.9305555555555556,
        "vocab_size-2-nopunct": 134,
        "unique-2-nopunct": 126,
        "entropy-2-nopunct": 7.0205515639122815,
        "cond_entropy-2-nopunct": 0.5243143983866253,
        "distinct-3-nopunct": 0.9624060150375939,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 6.980094465576386,
        "cond_entropy-3-nopunct": -0.04001991553807163,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.3157894736842105,
            "3": 0.6785714285714286
        },
        "rouge1": {
            "precision": 0.70659,
            "recall": 0.67874,
            "fmeasure": 0.68101
        },
        "rouge2": {
            "precision": 0.46278,
            "recall": 0.44519,
            "fmeasure": 0.44581
        },
        "rougeL": {
            "precision": 0.62417,
            "recall": 0.59346,
            "fmeasure": 0.59927
        },
        "rougeLsum": {
            "precision": 0.62417,
            "recall": 0.59346,
            "fmeasure": 0.59927
        },
        "nist": 4.77703381937672,
        "bleu": 39.16961,
        "meteor": 0.3604662784011669,
        "bleurt": 0.06621,
        "nubia": {
            "semantic_relation": 3.78779,
            "contradiction": 34.99246,
            "irrelevancy": 25.01023,
            "logical_agreement": 39.99731,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.52534,
            "nubia_score": 0.62331
        },
        "bertscore": {
            "precision": 0.90171,
            "recall": 0.89099,
            "f1": 0.89565
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "t5-small/totto_test",
        "N": 42,
        "total_length": 694,
        "mean_pred_length": 16.523809523809526,
        "std_pred_length": 4.181809219066695,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.5302593659942363,
        "vocab_size-1": 368,
        "unique-1": 287,
        "entropy-1": 7.61198536554088,
        "distinct-2": 0.8941717791411042,
        "vocab_size-2": 583,
        "unique-2": 535,
        "entropy-2": 9.098292245465402,
        "cond_entropy-2": 1.3216393383938763,
        "distinct-3": 0.9639344262295082,
        "vocab_size-3": 588,
        "unique-3": 568,
        "entropy-3": 9.178059243918607,
        "cond_entropy-3": 0.09373143807296973,
        "total_length-nopunct": 615,
        "mean_pred_length-nopunct": 14.642857142857142,
        "std_pred_length-nopunct": 3.9207714776038447,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5902439024390244,
        "vocab_size-1-nopunct": 363,
        "unique-1-nopunct": 286,
        "entropy-1-nopunct": 7.803313316449142,
        "distinct-2-nopunct": 0.8865619546247818,
        "vocab_size-2-nopunct": 508,
        "unique-2-nopunct": 464,
        "entropy-2-nopunct": 8.891389212674632,
        "cond_entropy-2-nopunct": 1.1622539380400554,
        "distinct-3-nopunct": 0.96045197740113,
        "vocab_size-3-nopunct": 510,
        "unique-3-nopunct": 491,
        "entropy-3-nopunct": 8.970628738178362,
        "cond_entropy-3-nopunct": 0.09502500361187592,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.74667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12173913043478261,
            "2": 0.44086021505376344,
            "3": 0.7541322314049587
        },
        "rouge1": {
            "precision": 0.74069,
            "recall": 0.74324,
            "fmeasure": 0.73057
        },
        "rouge2": {
            "precision": 0.53787,
            "recall": 0.53382,
            "fmeasure": 0.52719
        },
        "rougeL": {
            "precision": 0.65167,
            "recall": 0.6512,
            "fmeasure": 0.64061
        },
        "rougeLsum": {
            "precision": 0.65167,
            "recall": 0.6512,
            "fmeasure": 0.64061
        },
        "nist": 6.5660929340386645,
        "bleu": 46.28183,
        "meteor": 0.39582986942371406,
        "bleurt": 0.26211,
        "nubia": {
            "semantic_relation": 4.26397,
            "contradiction": 12.47246,
            "irrelevancy": 29.72026,
            "logical_agreement": 57.80728,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.60012,
            "nubia_score": 0.72474
        },
        "bertscore": {
            "precision": 0.9263,
            "recall": 0.92733,
            "f1": 0.92584
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "t5-small/totto_test",
        "N": 80,
        "total_length": 1308,
        "mean_pred_length": 16.35,
        "std_pred_length": 4.558234307272937,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.44724770642201833,
        "vocab_size-1": 585,
        "unique-1": 468,
        "entropy-1": 7.814106929012453,
        "distinct-2": 0.7809446254071661,
        "vocab_size-2": 959,
        "unique-2": 873,
        "entropy-2": 9.554345235623956,
        "cond_entropy-2": 1.59318271862254,
        "distinct-3": 0.882404181184669,
        "vocab_size-3": 1013,
        "unique-3": 962,
        "entropy-3": 9.815584330766692,
        "cond_entropy-3": 0.28343986493235723,
        "total_length-nopunct": 1163,
        "mean_pred_length-nopunct": 14.5375,
        "std_pred_length-nopunct": 4.268910136088601,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.49699054170249357,
        "vocab_size-1-nopunct": 578,
        "unique-1-nopunct": 466,
        "entropy-1-nopunct": 8.005080401320297,
        "distinct-2-nopunct": 0.7737765466297323,
        "vocab_size-2-nopunct": 838,
        "unique-2-nopunct": 766,
        "entropy-2-nopunct": 9.333142141843796,
        "cond_entropy-2-nopunct": 1.4269201413473123,
        "distinct-3-nopunct": 0.8733798604187437,
        "vocab_size-3-nopunct": 876,
        "unique-3-nopunct": 830,
        "entropy-3-nopunct": 9.58983400663497,
        "cond_entropy-3-nopunct": 0.2913631342878603,
        "msttr-100": 0.70154,
        "msttr-100_nopunct": 0.73182,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2994350282485876,
            "2": 0.45614035087719296,
            "3": 0.6571798188874515
        },
        "rouge1": {
            "precision": 0.68814,
            "recall": 0.62749,
            "fmeasure": 0.64105
        },
        "rouge2": {
            "precision": 0.43388,
            "recall": 0.39473,
            "fmeasure": 0.40237
        },
        "rougeL": {
            "precision": 0.57294,
            "recall": 0.53591,
            "fmeasure": 0.53891
        },
        "rougeLsum": {
            "precision": 0.57294,
            "recall": 0.53591,
            "fmeasure": 0.53891
        },
        "nist": 6.2705829711363785,
        "bleu": 32.79617,
        "meteor": 0.31221485060054643,
        "bleurt": -0.01258,
        "nubia": {
            "semantic_relation": 3.76499,
            "contradiction": 12.62555,
            "irrelevancy": 39.49481,
            "logical_agreement": 47.87964,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.59495,
            "nubia_score": 0.58262
        },
        "bertscore": {
            "precision": 0.89521,
            "recall": 0.8878,
            "f1": 0.8893
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "t5-small/totto_test",
        "N": 10,
        "total_length": 168,
        "mean_pred_length": 16.8,
        "std_pred_length": 4.4,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6904761904761905,
        "vocab_size-1": 116,
        "unique-1": 99,
        "entropy-1": 6.447680811355539,
        "distinct-2": 0.9810126582278481,
        "vocab_size-2": 155,
        "unique-2": 153,
        "entropy-2": 7.26102829563178,
        "cond_entropy-2": 0.6628859979810486,
        "distinct-3": 1.0,
        "vocab_size-3": 148,
        "unique-3": 148,
        "entropy-3": 7.209453365628947,
        "cond_entropy-3": -0.048686250776778205,
        "total_length-nopunct": 150,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.358898943540674,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7533333333333333,
        "vocab_size-1-nopunct": 113,
        "unique-1-nopunct": 98,
        "entropy-1-nopunct": 6.523297455057018,
        "distinct-2-nopunct": 0.9785714285714285,
        "vocab_size-2-nopunct": 137,
        "unique-2-nopunct": 135,
        "entropy-2-nopunct": 7.081033820500953,
        "cond_entropy-2-nopunct": 0.6081307394038291,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 130,
        "unique-3-nopunct": 130,
        "entropy-3-nopunct": 7.022367813028455,
        "cond_entropy-3-nopunct": -0.05495453082294705,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.631578947368421,
            "3": 0.6831683168316832
        },
        "rouge1": {
            "precision": 0.70741,
            "recall": 0.6839,
            "fmeasure": 0.67685
        },
        "rouge2": {
            "precision": 0.4557,
            "recall": 0.45036,
            "fmeasure": 0.44527
        },
        "rougeL": {
            "precision": 0.56102,
            "recall": 0.53983,
            "fmeasure": 0.53729
        },
        "rougeLsum": {
            "precision": 0.56102,
            "recall": 0.53983,
            "fmeasure": 0.53729
        },
        "nist": 5.330601169091522,
        "bleu": 43.25411,
        "meteor": 0.36386425171528053,
        "bleurt": 0.15751,
        "nubia": {
            "semantic_relation": 4.16085,
            "contradiction": 15.96173,
            "irrelevancy": 22.959,
            "logical_agreement": 61.07927,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.61017,
            "nubia_score": 0.728
        },
        "bertscore": {
            "precision": 0.9102,
            "recall": 0.90107,
            "f1": 0.9041
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7720,
        "mean_pred_length": 21.5041782729805,
        "std_pred_length": 9.340322585225518,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37176165803108807,
        "vocab_size-1": 2870,
        "unique-1": 2100,
        "entropy-1": 9.235158439326643,
        "distinct-2": 0.847167504415161,
        "vocab_size-2": 6236,
        "unique-2": 5774,
        "entropy-2": 12.327123665919075,
        "cond_entropy-2": 2.8572508020756424,
        "distinct-3": 0.9802913453299057,
        "vocab_size-3": 6864,
        "unique-3": 6757,
        "entropy-3": 12.729865603577442,
        "cond_entropy-3": 0.41443290245541875,
        "total_length-nopunct": 6952,
        "mean_pred_length-nopunct": 19.364902506963787,
        "std_pred_length-nopunct": 8.474966868997573,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.411536248561565,
        "vocab_size-1-nopunct": 2861,
        "unique-1-nopunct": 2098,
        "entropy-1-nopunct": 9.594839877948008,
        "distinct-2-nopunct": 0.8651600182011224,
        "vocab_size-2-nopunct": 5704,
        "unique-2-nopunct": 5328,
        "entropy-2-nopunct": 12.234578669854612,
        "cond_entropy-2-nopunct": 2.760495991752104,
        "distinct-3-nopunct": 0.9847609881296118,
        "vocab_size-3-nopunct": 6139,
        "unique-3-nopunct": 6062,
        "entropy-3-nopunct": 12.572833099233705,
        "cond_entropy-3-nopunct": 0.35825618548419247,
        "msttr-100": 0.72571,
        "msttr-100_nopunct": 0.76884,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.012521222410865875,
            "2": 0.19029374201787994,
            "3": 0.6061269146608315,
            "4": 0.8573692551505546,
            "5": 0.9293873312564901,
            "6": 0.9468599033816425,
            "7": 0.9618174875906834
        },
        "rouge1": {
            "precision": 0.94971,
            "recall": 0.93391,
            "fmeasure": 0.93572
        },
        "rouge2": {
            "precision": 0.90141,
            "recall": 0.88358,
            "fmeasure": 0.88555
        },
        "rougeL": {
            "precision": 0.94542,
            "recall": 0.93022,
            "fmeasure": 0.93163
        },
        "rougeLsum": {
            "precision": 0.94542,
            "recall": 0.93022,
            "fmeasure": 0.93163
        },
        "nist": 13.407293846084126,
        "bleu": 92.10852,
        "meteor": 0.6216178784743646,
        "bleurt": 0.4048,
        "nubia": {
            "semantic_relation": 4.53451,
            "contradiction": 1.84618,
            "irrelevancy": 14.26933,
            "logical_agreement": 83.88449,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.72492,
            "nubia_score": 0.80242
        },
        "bertscore": {
            "precision": 0.97898,
            "recall": 0.98008,
            "f1": 0.97819
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "t5-small/totto_test",
        "N": 14,
        "total_length": 189,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.101393491415884,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 20,
        "distinct-1": 0.6084656084656085,
        "vocab_size-1": 115,
        "unique-1": 90,
        "entropy-1": 6.3492505092774305,
        "distinct-2": 0.9142857142857143,
        "vocab_size-2": 160,
        "unique-2": 149,
        "entropy-2": 7.254842380537453,
        "cond_entropy-2": 0.6980428306909271,
        "distinct-3": 0.9751552795031055,
        "vocab_size-3": 157,
        "unique-3": 153,
        "entropy-3": 7.281227437120814,
        "cond_entropy-3": 0.03103823818663758,
        "total_length-nopunct": 166,
        "mean_pred_length-nopunct": 11.857142857142858,
        "std_pred_length-nopunct": 3.9974481656094922,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6626506024096386,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.4085169734480285,
        "distinct-2-nopunct": 0.9144736842105263,
        "vocab_size-2-nopunct": 139,
        "unique-2-nopunct": 130,
        "entropy-2-nopunct": 7.048160882018567,
        "cond_entropy-2-nopunct": 0.6957709770612357,
        "distinct-3-nopunct": 0.9782608695652174,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.065046195908602,
        "cond_entropy-3-nopunct": 0.015412363454875405,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16393442622950818,
            "2": 0.3142857142857143,
            "3": 0.610062893081761
        },
        "rouge1": {
            "precision": 0.73689,
            "recall": 0.61519,
            "fmeasure": 0.65547
        },
        "rouge2": {
            "precision": 0.45195,
            "recall": 0.37594,
            "fmeasure": 0.39763
        },
        "rougeL": {
            "precision": 0.60966,
            "recall": 0.51279,
            "fmeasure": 0.54472
        },
        "rougeLsum": {
            "precision": 0.60966,
            "recall": 0.51279,
            "fmeasure": 0.54472
        },
        "nist": 3.898286601399472,
        "bleu": 29.12858,
        "meteor": 0.31540034373382336,
        "bleurt": 0.09686,
        "nubia": {
            "semantic_relation": 3.99161,
            "contradiction": 5.68518,
            "irrelevancy": 47.04631,
            "logical_agreement": 47.26851,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.74488,
            "nubia_score": 0.65681
        },
        "bertscore": {
            "precision": 0.92007,
            "recall": 0.89136,
            "f1": 0.90372
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "t5-small/totto_test",
        "N": 16,
        "total_length": 204,
        "mean_pred_length": 12.75,
        "std_pred_length": 3.25,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.6127450980392157,
        "vocab_size-1": 125,
        "unique-1": 102,
        "entropy-1": 6.3491835809210935,
        "distinct-2": 0.925531914893617,
        "vocab_size-2": 174,
        "unique-2": 163,
        "entropy-2": 7.39099902453849,
        "cond_entropy-2": 0.8140062317918805,
        "distinct-3": 0.9593023255813954,
        "vocab_size-3": 165,
        "unique-3": 158,
        "entropy-3": 7.344869405864857,
        "cond_entropy-3": -0.03091196033505417,
        "total_length-nopunct": 174,
        "mean_pred_length-nopunct": 10.875,
        "std_pred_length-nopunct": 2.9553976043842223,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6896551724137931,
        "vocab_size-1-nopunct": 120,
        "unique-1-nopunct": 99,
        "entropy-1-nopunct": 6.478072395565543,
        "distinct-2-nopunct": 0.9240506329113924,
        "vocab_size-2-nopunct": 146,
        "unique-2-nopunct": 137,
        "entropy-2-nopunct": 7.1344460171507675,
        "cond_entropy-2-nopunct": 0.7414238595885543,
        "distinct-3-nopunct": 0.9647887323943662,
        "vocab_size-3-nopunct": 137,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.0793245842934205,
        "cond_entropy-3-nopunct": -0.036041463164227516,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12195121951219512,
            "2": 0.30434782608695654,
            "3": 0.7195121951219512
        },
        "rouge1": {
            "precision": 0.80524,
            "recall": 0.71289,
            "fmeasure": 0.74895
        },
        "rouge2": {
            "precision": 0.54608,
            "recall": 0.49078,
            "fmeasure": 0.51101
        },
        "rougeL": {
            "precision": 0.6983,
            "recall": 0.62367,
            "fmeasure": 0.6528
        },
        "rougeLsum": {
            "precision": 0.6983,
            "recall": 0.62367,
            "fmeasure": 0.6528
        },
        "nist": 5.605259407354559,
        "bleu": 40.38926,
        "meteor": 0.3816002820714654,
        "bleurt": 0.37032,
        "nubia": {
            "semantic_relation": 4.49319,
            "contradiction": 1.11699,
            "irrelevancy": 26.39341,
            "logical_agreement": 72.4896,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.63869,
            "nubia_score": 0.80958
        },
        "bertscore": {
            "precision": 0.93148,
            "recall": 0.91993,
            "f1": 0.92526
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "t5-small/totto_test",
        "N": 19,
        "total_length": 329,
        "mean_pred_length": 17.31578947368421,
        "std_pred_length": 5.351366097883176,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5683890577507599,
        "vocab_size-1": 187,
        "unique-1": 151,
        "entropy-1": 6.841238435291528,
        "distinct-2": 0.8709677419354839,
        "vocab_size-2": 270,
        "unique-2": 241,
        "entropy-2": 7.977185584425638,
        "cond_entropy-2": 0.9822723756378219,
        "distinct-3": 0.9415807560137457,
        "vocab_size-3": 274,
        "unique-3": 258,
        "entropy-3": 8.065442739808066,
        "cond_entropy-3": 0.07768997357469966,
        "total_length-nopunct": 285,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.436689140148968,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6421052631578947,
        "vocab_size-1-nopunct": 183,
        "unique-1-nopunct": 151,
        "entropy-1-nopunct": 6.947680827041059,
        "distinct-2-nopunct": 0.8872180451127819,
        "vocab_size-2-nopunct": 236,
        "unique-2-nopunct": 216,
        "entropy-2-nopunct": 7.784920980761039,
        "cond_entropy-2-nopunct": 0.8733818088452161,
        "distinct-3-nopunct": 0.9433198380566802,
        "vocab_size-3-nopunct": 233,
        "unique-3-nopunct": 219,
        "entropy-3-nopunct": 7.8350069076980695,
        "cond_entropy-3-nopunct": 0.051632405228144496,
        "msttr-100": 0.69667,
        "msttr-100_nopunct": 0.765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.32786885245901637,
            "2": 0.4745762711864407,
            "3": 0.6763285024154589
        },
        "rouge1": {
            "precision": 0.71147,
            "recall": 0.6879,
            "fmeasure": 0.68296
        },
        "rouge2": {
            "precision": 0.45216,
            "recall": 0.43195,
            "fmeasure": 0.42746
        },
        "rougeL": {
            "precision": 0.62978,
            "recall": 0.6163,
            "fmeasure": 0.60735
        },
        "rougeLsum": {
            "precision": 0.62978,
            "recall": 0.6163,
            "fmeasure": 0.60735
        },
        "nist": 5.566390598323791,
        "bleu": 37.3535,
        "meteor": 0.3587535973139696,
        "bleurt": 0.12909,
        "nubia": {
            "semantic_relation": 3.94723,
            "contradiction": 8.53443,
            "irrelevancy": 46.45354,
            "logical_agreement": 45.01203,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.46197,
            "nubia_score": 0.64998
        },
        "bertscore": {
            "precision": 0.91275,
            "recall": 0.90755,
            "f1": 0.90761
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.875,
            "fmeasure": 0.875
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.57143,
            "fmeasure": 0.57143
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "nist": 3.7101343934554425,
        "bleu": 57.21248,
        "meteor": 0.4375894542257545,
        "bleurt": 0.03832,
        "nubia": {
            "semantic_relation": 4.81345,
            "contradiction": 3.80706,
            "irrelevancy": 1.91544,
            "logical_agreement": 94.2775,
            "grammar_ref": 4.0172,
            "grammar_hyp": 4.86318,
            "nubia_score": 0.80788
        },
        "bertscore": {
            "precision": 0.90532,
            "recall": 0.91018,
            "f1": 0.90269
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "t5-small/totto_test",
        "N": 18,
        "total_length": 316,
        "mean_pred_length": 17.555555555555557,
        "std_pred_length": 5.599823630379624,
        "median_pred_length": 18.5,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5854430379746836,
        "vocab_size-1": 185,
        "unique-1": 152,
        "entropy-1": 6.860040338473549,
        "distinct-2": 0.9161073825503355,
        "vocab_size-2": 273,
        "unique-2": 258,
        "entropy-2": 8.018248040660362,
        "cond_entropy-2": 1.0577857428471615,
        "distinct-3": 0.975,
        "vocab_size-3": 273,
        "unique-3": 268,
        "entropy-3": 8.073890963358098,
        "cond_entropy-3": 0.06498781068494906,
        "total_length-nopunct": 278,
        "mean_pred_length-nopunct": 15.444444444444445,
        "std_pred_length-nopunct": 5.123174170399334,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6330935251798561,
        "vocab_size-1-nopunct": 176,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 6.876842118704196,
        "distinct-2-nopunct": 0.9153846153846154,
        "vocab_size-2-nopunct": 238,
        "unique-2-nopunct": 226,
        "entropy-2-nopunct": 7.815158955409503,
        "cond_entropy-2-nopunct": 1.0089236873681504,
        "distinct-3-nopunct": 0.9710743801652892,
        "vocab_size-3-nopunct": 235,
        "unique-3-nopunct": 230,
        "entropy-3-nopunct": 7.854773257917873,
        "cond_entropy-3-nopunct": 0.05089430018250468,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3088235294117647,
            "2": 0.5352112676056338,
            "3": 0.6612903225806451
        },
        "rouge1": {
            "precision": 0.68134,
            "recall": 0.66788,
            "fmeasure": 0.6635
        },
        "rouge2": {
            "precision": 0.43733,
            "recall": 0.43837,
            "fmeasure": 0.43032
        },
        "rougeL": {
            "precision": 0.57066,
            "recall": 0.57992,
            "fmeasure": 0.56538
        },
        "rougeLsum": {
            "precision": 0.57066,
            "recall": 0.57992,
            "fmeasure": 0.56538
        },
        "nist": 5.568365048010284,
        "bleu": 30.65866,
        "meteor": 0.32901197258619186,
        "bleurt": -0.01265,
        "nubia": {
            "semantic_relation": 3.76796,
            "contradiction": 14.04982,
            "irrelevancy": 45.264,
            "logical_agreement": 40.68618,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.47907,
            "nubia_score": 0.62039
        },
        "bertscore": {
            "precision": 0.90141,
            "recall": 0.90224,
            "f1": 0.90014
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "t5-small/totto_test",
        "N": 131,
        "total_length": 2028,
        "mean_pred_length": 15.48091603053435,
        "std_pred_length": 4.987543483578135,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.4442800788954635,
        "vocab_size-1": 901,
        "unique-1": 717,
        "entropy-1": 8.233416220746966,
        "distinct-2": 0.823405376910912,
        "vocab_size-2": 1562,
        "unique-2": 1414,
        "entropy-2": 10.367215378977527,
        "cond_entropy-2": 1.8986998932018073,
        "distinct-3": 0.942242355605889,
        "vocab_size-3": 1664,
        "unique-3": 1599,
        "entropy-3": 10.646988053803867,
        "cond_entropy-3": 0.2867832663010355,
        "total_length-nopunct": 1762,
        "mean_pred_length-nopunct": 13.450381679389313,
        "std_pred_length-nopunct": 4.477618199424447,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5051078320090806,
        "vocab_size-1-nopunct": 890,
        "unique-1-nopunct": 715,
        "entropy-1-nopunct": 8.517125835642148,
        "distinct-2-nopunct": 0.8479460453709381,
        "vocab_size-2-nopunct": 1383,
        "unique-2-nopunct": 1275,
        "entropy-2-nopunct": 10.205921135824346,
        "cond_entropy-2-nopunct": 1.80379687829648,
        "distinct-3-nopunct": 0.9566666666666667,
        "vocab_size-3-nopunct": 1435,
        "unique-3-nopunct": 1389,
        "entropy-3-nopunct": 10.449619729068782,
        "cond_entropy-3-nopunct": 0.27414811514507076,
        "msttr-100": 0.7195,
        "msttr-100_nopunct": 0.76588,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26525198938992045,
            "2": 0.4639423076923077,
            "3": 0.6844319775596073
        },
        "rouge1": {
            "precision": 0.76089,
            "recall": 0.6848,
            "fmeasure": 0.7057
        },
        "rouge2": {
            "precision": 0.51967,
            "recall": 0.47112,
            "fmeasure": 0.48434
        },
        "rougeL": {
            "precision": 0.66085,
            "recall": 0.59763,
            "fmeasure": 0.61451
        },
        "rougeLsum": {
            "precision": 0.66085,
            "recall": 0.59763,
            "fmeasure": 0.61451
        },
        "nist": 7.188698041559706,
        "bleu": 40.52498,
        "meteor": 0.3550913216914938,
        "bleurt": 0.17459,
        "nubia": {
            "semantic_relation": 4.08315,
            "contradiction": 11.30215,
            "irrelevancy": 30.07245,
            "logical_agreement": 58.6254,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.67426,
            "nubia_score": 0.67872
        },
        "bertscore": {
            "precision": 0.92362,
            "recall": 0.91141,
            "f1": 0.91639
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "t5-small/totto_test",
        "N": 9,
        "total_length": 156,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 4.0276819911981905,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.6474358974358975,
        "vocab_size-1": 101,
        "unique-1": 85,
        "entropy-1": 6.117064435181137,
        "distinct-2": 0.9387755102040817,
        "vocab_size-2": 138,
        "unique-2": 131,
        "entropy-2": 7.063617923067649,
        "cond_entropy-2": 0.8366295952722355,
        "distinct-3": 0.9782608695652174,
        "vocab_size-3": 135,
        "unique-3": 132,
        "entropy-3": 7.065046195908602,
        "cond_entropy-3": 0.010301387304123383,
        "total_length-nopunct": 136,
        "mean_pred_length-nopunct": 15.11111111111111,
        "std_pred_length-nopunct": 3.6649827783268094,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.1360663055813776,
        "distinct-2-nopunct": 0.9291338582677166,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.831204371811523,
        "cond_entropy-2-nopunct": 0.7334225473551897,
        "distinct-3-nopunct": 0.9745762711864406,
        "vocab_size-3-nopunct": 115,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.831795591734713,
        "cond_entropy-3-nopunct": 0.012602430386285585,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3181818181818182,
            "2": 0.25,
            "3": 0.7043478260869566
        },
        "rouge1": {
            "precision": 0.76978,
            "recall": 0.72281,
            "fmeasure": 0.73658
        },
        "rouge2": {
            "precision": 0.51429,
            "recall": 0.48578,
            "fmeasure": 0.49263
        },
        "rougeL": {
            "precision": 0.64031,
            "recall": 0.60033,
            "fmeasure": 0.61193
        },
        "rougeLsum": {
            "precision": 0.64031,
            "recall": 0.60033,
            "fmeasure": 0.61193
        },
        "nist": 5.1080194503691265,
        "bleu": 32.76293,
        "meteor": 0.34802846026827716,
        "bleurt": 0.28551,
        "nubia": {
            "semantic_relation": 4.33423,
            "contradiction": 4.94705,
            "irrelevancy": 14.33535,
            "logical_agreement": 80.7176,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.3957,
            "nubia_score": 0.79994
        },
        "bertscore": {
            "precision": 0.92712,
            "recall": 0.92126,
            "f1": 0.9239
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "t5-small/totto_test",
        "N": 9,
        "total_length": 129,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 4.898979485566356,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6744186046511628,
        "vocab_size-1": 87,
        "unique-1": 74,
        "entropy-1": 6.0219023798978055,
        "distinct-2": 0.95,
        "vocab_size-2": 114,
        "unique-2": 110,
        "entropy-2": 6.790223928941866,
        "cond_entropy-2": 0.657608622957644,
        "distinct-3": 0.9819819819819819,
        "vocab_size-3": 109,
        "unique-3": 107,
        "entropy-3": 6.758379830314084,
        "cond_entropy-3": -0.02238463916832254,
        "total_length-nopunct": 116,
        "mean_pred_length-nopunct": 12.88888888888889,
        "std_pred_length-nopunct": 4.532461789860253,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7068965517241379,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.003725961249969,
        "distinct-2-nopunct": 0.9532710280373832,
        "vocab_size-2-nopunct": 102,
        "unique-2-nopunct": 99,
        "entropy-2-nopunct": 6.629317453690857,
        "cond_entropy-2-nopunct": 0.6732861915453472,
        "distinct-3-nopunct": 0.9897959183673469,
        "vocab_size-3-nopunct": 97,
        "unique-3-nopunct": 96,
        "entropy-3-nopunct": 6.594301680849911,
        "cond_entropy-3-nopunct": -0.024716325959408064,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27586206896551724,
            "2": 0.21428571428571427,
            "3": 0.7012987012987013
        },
        "rouge1": {
            "precision": 0.66208,
            "recall": 0.62615,
            "fmeasure": 0.63166
        },
        "rouge2": {
            "precision": 0.42414,
            "recall": 0.39124,
            "fmeasure": 0.40129
        },
        "rougeL": {
            "precision": 0.59551,
            "recall": 0.56408,
            "fmeasure": 0.56877
        },
        "rougeLsum": {
            "precision": 0.59551,
            "recall": 0.56408,
            "fmeasure": 0.56877
        },
        "nist": 4.2104017928422435,
        "bleu": 31.65631,
        "meteor": 0.30321109291310944,
        "bleurt": 0.17709,
        "nubia": {
            "semantic_relation": 3.73174,
            "contradiction": 26.06453,
            "irrelevancy": 16.62875,
            "logical_agreement": 57.30671,
            "grammar_ref": 5.16318,
            "grammar_hyp": 4.95296,
            "nubia_score": 0.58253
        },
        "bertscore": {
            "precision": 0.9112,
            "recall": 0.87525,
            "f1": 0.89115
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "t5-small/totto_test",
        "N": 10,
        "total_length": 131,
        "mean_pred_length": 13.1,
        "std_pred_length": 3.5341194094144583,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 19,
        "distinct-1": 0.6106870229007634,
        "vocab_size-1": 80,
        "unique-1": 60,
        "entropy-1": 5.95031176910026,
        "distinct-2": 0.8429752066115702,
        "vocab_size-2": 102,
        "unique-2": 91,
        "entropy-2": 6.554903732999332,
        "cond_entropy-2": 0.4195657769197117,
        "distinct-3": 0.8918918918918919,
        "vocab_size-3": 99,
        "unique-3": 93,
        "entropy-3": 6.53739492028723,
        "cond_entropy-3": 0.015280331817195602,
        "total_length-nopunct": 118,
        "mean_pred_length-nopunct": 11.8,
        "std_pred_length-nopunct": 3.370459909270544,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6610169491525424,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 6.002020990054761,
        "distinct-2-nopunct": 0.8240740740740741,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.347118057558757,
        "cond_entropy-2-nopunct": 0.417376887810213,
        "distinct-3-nopunct": 0.8775510204081632,
        "vocab_size-3-nopunct": 86,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.32359428275827,
        "cond_entropy-3-nopunct": 0.01808535219997379,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.2727272727272727,
            "3": 0.8867924528301887
        },
        "rouge1": {
            "precision": 0.8797,
            "recall": 0.88914,
            "fmeasure": 0.8746
        },
        "rouge2": {
            "precision": 0.76274,
            "recall": 0.80157,
            "fmeasure": 0.77291
        },
        "rougeL": {
            "precision": 0.8067,
            "recall": 0.81825,
            "fmeasure": 0.80448
        },
        "rougeLsum": {
            "precision": 0.8067,
            "recall": 0.81825,
            "fmeasure": 0.80448
        },
        "nist": 6.08919987348132,
        "bleu": 70.86859,
        "meteor": 0.5096409895800998,
        "bleurt": 0.57569,
        "nubia": {
            "semantic_relation": 4.52473,
            "contradiction": 0.36231,
            "irrelevancy": 29.8218,
            "logical_agreement": 69.8159,
            "grammar_ref": 5.03704,
            "grammar_hyp": 5.0101,
            "nubia_score": 0.8283
        },
        "bertscore": {
            "precision": 0.9599,
            "recall": 0.96275,
            "f1": 0.96116
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 67,
        "mean_pred_length": 13.4,
        "std_pred_length": 2.244994432064365,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.7313432835820896,
        "vocab_size-1": 49,
        "unique-1": 41,
        "entropy-1": 5.338789847872687,
        "distinct-2": 0.9516129032258065,
        "vocab_size-2": 59,
        "unique-2": 56,
        "entropy-2": 5.857422116838485,
        "cond_entropy-2": 0.390033176038196,
        "distinct-3": 1.0,
        "vocab_size-3": 57,
        "unique-3": 57,
        "entropy-3": 5.832890014164737,
        "cond_entropy-3": -0.016043138327396726,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 11.8,
        "std_pred_length-nopunct": 2.4,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7796610169491526,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.287398719213299,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.643776391052356,
        "cond_entropy-2-nopunct": 0.41149288759354835,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.0177286784564235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.2222222222222222,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.79141,
            "recall": 0.73234,
            "fmeasure": 0.74938
        },
        "rouge2": {
            "precision": 0.61815,
            "recall": 0.58008,
            "fmeasure": 0.58755
        },
        "rougeL": {
            "precision": 0.76558,
            "recall": 0.70843,
            "fmeasure": 0.72474
        },
        "rougeLsum": {
            "precision": 0.76558,
            "recall": 0.70843,
            "fmeasure": 0.72474
        },
        "nist": 5.442898278630914,
        "bleu": 60.27827,
        "meteor": 0.40374973571778106,
        "bleurt": 0.41323,
        "nubia": {
            "semantic_relation": 4.38105,
            "contradiction": 7.4816,
            "irrelevancy": 10.86793,
            "logical_agreement": 81.65047,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.8681,
            "nubia_score": 0.78415
        },
        "bertscore": {
            "precision": 0.96212,
            "recall": 0.93424,
            "f1": 0.94733
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 77,
        "mean_pred_length": 12.833333333333334,
        "std_pred_length": 3.3374973990834644,
        "median_pred_length": 13.5,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.7012987012987013,
        "vocab_size-1": 54,
        "unique-1": 41,
        "entropy-1": 5.488654761982,
        "distinct-2": 0.9014084507042254,
        "vocab_size-2": 64,
        "unique-2": 57,
        "entropy-2": 5.952564020913129,
        "cond_entropy-2": 0.31121933876142455,
        "distinct-3": 0.9230769230769231,
        "vocab_size-3": 60,
        "unique-3": 55,
        "entropy-3": 5.868521659182304,
        "cond_entropy-3": -0.06584084493776614,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.449489742783178,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7575757575757576,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.4321763624407815,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.740223928941851,
        "cond_entropy-2-nopunct": 0.35260267552617686,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.643776391052356,
        "cond_entropy-3-nopunct": -0.07792901937097596,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.8666666666666667,
            "3": 0.7575757575757576
        },
        "rouge1": {
            "precision": 0.6513,
            "recall": 0.76242,
            "fmeasure": 0.68984
        },
        "rouge2": {
            "precision": 0.37567,
            "recall": 0.42417,
            "fmeasure": 0.39064
        },
        "rougeL": {
            "precision": 0.59297,
            "recall": 0.69865,
            "fmeasure": 0.63071
        },
        "rougeLsum": {
            "precision": 0.59297,
            "recall": 0.69865,
            "fmeasure": 0.63071
        },
        "nist": 4.014097793577542,
        "bleu": 34.99654,
        "meteor": 0.363461007211564,
        "bleurt": 0.09659,
        "nubia": {
            "semantic_relation": 3.76015,
            "contradiction": 15.30897,
            "irrelevancy": 37.5911,
            "logical_agreement": 47.09993,
            "grammar_ref": 5.1808,
            "grammar_hyp": 4.59536,
            "nubia_score": 0.61321
        },
        "bertscore": {
            "precision": 0.8996,
            "recall": 0.90141,
            "f1": 0.89931
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "t5-small/totto_test",
        "N": 14,
        "total_length": 189,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.692582403567252,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.6031746031746031,
        "vocab_size-1": 114,
        "unique-1": 93,
        "entropy-1": 6.204336818359962,
        "distinct-2": 0.9485714285714286,
        "vocab_size-2": 166,
        "unique-2": 161,
        "entropy-2": 7.316869540379011,
        "cond_entropy-2": 0.9165767767233561,
        "distinct-3": 0.9937888198757764,
        "vocab_size-3": 160,
        "unique-3": 159,
        "entropy-3": 7.318494517866155,
        "cond_entropy-3": 0.000884493017238227,
        "total_length-nopunct": 167,
        "mean_pred_length-nopunct": 11.928571428571429,
        "std_pred_length-nopunct": 2.2188892238584383,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6586826347305389,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.258965276937405,
        "distinct-2-nopunct": 0.9477124183006536,
        "vocab_size-2-nopunct": 145,
        "unique-2-nopunct": 141,
        "entropy-2-nopunct": 7.11680107795847,
        "cond_entropy-2-nopunct": 0.9194333050905147,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 139,
        "unique-3-nopunct": 139,
        "entropy-3-nopunct": 7.118941072723523,
        "cond_entropy-3-nopunct": 0.0019113235871644207,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2972972972972973,
            "2": 0.4,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.72128,
            "recall": 0.72961,
            "fmeasure": 0.71442
        },
        "rouge2": {
            "precision": 0.5098,
            "recall": 0.51538,
            "fmeasure": 0.50449
        },
        "rougeL": {
            "precision": 0.65992,
            "recall": 0.6673,
            "fmeasure": 0.65405
        },
        "rougeLsum": {
            "precision": 0.65992,
            "recall": 0.6673,
            "fmeasure": 0.65405
        },
        "nist": 5.330525002401809,
        "bleu": 40.62327,
        "meteor": 0.4139526578784299,
        "bleurt": 0.29451,
        "nubia": {
            "semantic_relation": 4.20465,
            "contradiction": 6.00223,
            "irrelevancy": 32.36912,
            "logical_agreement": 61.62866,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.13345,
            "nubia_score": 0.75927
        },
        "bertscore": {
            "precision": 0.92719,
            "recall": 0.92425,
            "f1": 0.92401
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "t5-small/totto_test",
        "N": 66,
        "total_length": 993,
        "mean_pred_length": 15.045454545454545,
        "std_pred_length": 4.332512106968057,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 24,
        "distinct-1": 0.5035246727089627,
        "vocab_size-1": 500,
        "unique-1": 413,
        "entropy-1": 7.769743136649765,
        "distinct-2": 0.8522114347357066,
        "vocab_size-2": 790,
        "unique-2": 717,
        "entropy-2": 9.460014571176295,
        "cond_entropy-2": 1.506586142024269,
        "distinct-3": 0.9628339140534262,
        "vocab_size-3": 829,
        "unique-3": 805,
        "entropy-3": 9.660108437251488,
        "cond_entropy-3": 0.18498346188099504,
        "total_length-nopunct": 858,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.9504506839170395,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5710955710955711,
        "vocab_size-1-nopunct": 490,
        "unique-1-nopunct": 407,
        "entropy-1-nopunct": 8.038721974080987,
        "distinct-2-nopunct": 0.8813131313131313,
        "vocab_size-2-nopunct": 698,
        "unique-2-nopunct": 645,
        "entropy-2-nopunct": 9.313481957694174,
        "cond_entropy-2-nopunct": 1.3213336909220499,
        "distinct-3-nopunct": 0.9752066115702479,
        "vocab_size-3-nopunct": 708,
        "unique-3-nopunct": 691,
        "entropy-3-nopunct": 9.453199171188338,
        "cond_entropy-3-nopunct": 0.11728311314932295,
        "msttr-100": 0.72889,
        "msttr-100_nopunct": 0.77375,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21393034825870647,
            "2": 0.37755102040816324,
            "3": 0.6695402298850575
        },
        "rouge1": {
            "precision": 0.71638,
            "recall": 0.6491,
            "fmeasure": 0.66497
        },
        "rouge2": {
            "precision": 0.47647,
            "recall": 0.42931,
            "fmeasure": 0.4408
        },
        "rougeL": {
            "precision": 0.60947,
            "recall": 0.55665,
            "fmeasure": 0.56688
        },
        "rougeLsum": {
            "precision": 0.60947,
            "recall": 0.55665,
            "fmeasure": 0.56688
        },
        "nist": 5.774693870245922,
        "bleu": 32.83365,
        "meteor": 0.3359387890681817,
        "bleurt": 0.08879,
        "nubia": {
            "semantic_relation": 3.95538,
            "contradiction": 10.93416,
            "irrelevancy": 32.82074,
            "logical_agreement": 56.24509,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.40703,
            "nubia_score": 0.66605
        },
        "bertscore": {
            "precision": 0.89907,
            "recall": 0.89731,
            "f1": 0.89616
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 95,
        "mean_pred_length": 13.571428571428571,
        "std_pred_length": 3.6977654587270816,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.6631578947368421,
        "vocab_size-1": 63,
        "unique-1": 50,
        "entropy-1": 5.63002179238206,
        "distinct-2": 0.8977272727272727,
        "vocab_size-2": 79,
        "unique-2": 72,
        "entropy-2": 6.232158891364574,
        "cond_entropy-2": 0.4779218911110922,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 78,
        "unique-3": 75,
        "entropy-3": 6.265775928810542,
        "cond_entropy-3": 0.028566532395475727,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 12.428571428571429,
        "std_pred_length-nopunct": 3.7361990944634345,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7011494252873564,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.617949961241631,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.0969280948873585,
        "cond_entropy-2-nopunct": 0.48866506792385045,
        "distinct-3-nopunct": 0.9726027397260274,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.135030038332081,
        "cond_entropy-3-nopunct": 0.0322800256364906,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11428571428571428,
            "2": 0.5,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.7582,
            "recall": 0.73661,
            "fmeasure": 0.74211
        },
        "rouge2": {
            "precision": 0.54838,
            "recall": 0.53227,
            "fmeasure": 0.53127
        },
        "rougeL": {
            "precision": 0.70066,
            "recall": 0.65823,
            "fmeasure": 0.67098
        },
        "rougeLsum": {
            "precision": 0.70066,
            "recall": 0.65823,
            "fmeasure": 0.67098
        },
        "nist": 4.825136556797157,
        "bleu": 45.91091,
        "meteor": 0.38389157419675407,
        "bleurt": 0.07486,
        "nubia": {
            "semantic_relation": 4.02655,
            "contradiction": 14.96298,
            "irrelevancy": 36.70381,
            "logical_agreement": 48.33321,
            "grammar_ref": 5.24762,
            "grammar_hyp": 4.93368,
            "nubia_score": 0.6618
        },
        "bertscore": {
            "precision": 0.91001,
            "recall": 0.90752,
            "f1": 0.90719
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "t5-small/totto_test",
        "N": 18,
        "total_length": 304,
        "mean_pred_length": 16.88888888888889,
        "std_pred_length": 5.2163087085802236,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5921052631578947,
        "vocab_size-1": 180,
        "unique-1": 148,
        "entropy-1": 6.778564255318784,
        "distinct-2": 0.8916083916083916,
        "vocab_size-2": 255,
        "unique-2": 242,
        "entropy-2": 7.856476581767362,
        "cond_entropy-2": 0.9488574041057101,
        "distinct-3": 0.9514925373134329,
        "vocab_size-3": 255,
        "unique-3": 246,
        "entropy-3": 7.955978089695323,
        "cond_entropy-3": 0.10868473774221922,
        "total_length-nopunct": 268,
        "mean_pred_length-nopunct": 14.88888888888889,
        "std_pred_length-nopunct": 5.009866807820221,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6455223880597015,
        "vocab_size-1-nopunct": 173,
        "unique-1-nopunct": 146,
        "entropy-1-nopunct": 6.789805714642441,
        "distinct-2-nopunct": 0.876,
        "vocab_size-2-nopunct": 219,
        "unique-2-nopunct": 206,
        "entropy-2-nopunct": 7.618700684929431,
        "cond_entropy-2-nopunct": 0.9017678305370058,
        "distinct-3-nopunct": 0.9439655172413793,
        "vocab_size-3-nopunct": 219,
        "unique-3-nopunct": 210,
        "entropy-3-nopunct": 7.73078368907442,
        "cond_entropy-3-nopunct": 0.12608086964151946,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.20588235294117646,
            "3": 0.777292576419214
        },
        "rouge1": {
            "precision": 0.7951,
            "recall": 0.74343,
            "fmeasure": 0.75925
        },
        "rouge2": {
            "precision": 0.59401,
            "recall": 0.53444,
            "fmeasure": 0.55519
        },
        "rougeL": {
            "precision": 0.74056,
            "recall": 0.68419,
            "fmeasure": 0.70346
        },
        "rougeLsum": {
            "precision": 0.74056,
            "recall": 0.68419,
            "fmeasure": 0.70346
        },
        "nist": 5.955428737448912,
        "bleu": 47.52834,
        "meteor": 0.40287622443948057,
        "bleurt": 0.2855,
        "nubia": {
            "semantic_relation": 4.27996,
            "contradiction": 6.0318,
            "irrelevancy": 30.38851,
            "logical_agreement": 63.57969,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.51961,
            "nubia_score": 0.76104
        },
        "bertscore": {
            "precision": 0.93498,
            "recall": 0.93246,
            "f1": 0.9331
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "t5-small/totto_test",
        "N": 35,
        "total_length": 563,
        "mean_pred_length": 16.085714285714285,
        "std_pred_length": 3.923347175719285,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.3552397868561279,
        "vocab_size-1": 200,
        "unique-1": 156,
        "entropy-1": 6.401663245084671,
        "distinct-2": 0.6477272727272727,
        "vocab_size-2": 342,
        "unique-2": 288,
        "entropy-2": 7.950332421501918,
        "cond_entropy-2": 1.4106879993792723,
        "distinct-3": 0.7728194726166329,
        "vocab_size-3": 381,
        "unique-3": 342,
        "entropy-3": 8.271124835798881,
        "cond_entropy-3": 0.3592352325972662,
        "total_length-nopunct": 474,
        "mean_pred_length-nopunct": 13.542857142857143,
        "std_pred_length-nopunct": 3.5241441282579085,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.4092827004219409,
        "vocab_size-1-nopunct": 194,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 6.469166668188911,
        "distinct-2-nopunct": 0.6719817767653758,
        "vocab_size-2-nopunct": 295,
        "unique-2-nopunct": 255,
        "entropy-2-nopunct": 7.752835825157366,
        "cond_entropy-2-nopunct": 1.396878035501376,
        "distinct-3-nopunct": 0.7722772277227723,
        "vocab_size-3-nopunct": 312,
        "unique-3-nopunct": 282,
        "entropy-3-nopunct": 7.9809581514097525,
        "cond_entropy-3-nopunct": 0.2903217276164147,
        "msttr-100": 0.568,
        "msttr-100_nopunct": 0.6,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.5,
            "3": 0.7492795389048992
        },
        "rouge1": {
            "precision": 0.75552,
            "recall": 0.74116,
            "fmeasure": 0.73825
        },
        "rouge2": {
            "precision": 0.49933,
            "recall": 0.49447,
            "fmeasure": 0.49147
        },
        "rougeL": {
            "precision": 0.6332,
            "recall": 0.62075,
            "fmeasure": 0.61913
        },
        "rougeLsum": {
            "precision": 0.6332,
            "recall": 0.62075,
            "fmeasure": 0.61913
        },
        "nist": 6.196903005711933,
        "bleu": 45.80258,
        "meteor": 0.3909162532177829,
        "bleurt": 0.35697,
        "nubia": {
            "semantic_relation": 4.06595,
            "contradiction": 6.38844,
            "irrelevancy": 25.66107,
            "logical_agreement": 67.95049,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.01259,
            "nubia_score": 0.74809
        },
        "bertscore": {
            "precision": 0.92251,
            "recall": 0.92422,
            "f1": 0.92185
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "t5-small/totto_test",
        "N": 9,
        "total_length": 111,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 3.0550504633038935,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.6576576576576577,
        "vocab_size-1": 73,
        "unique-1": 53,
        "entropy-1": 5.893395429698361,
        "distinct-2": 0.8725490196078431,
        "vocab_size-2": 89,
        "unique-2": 77,
        "entropy-2": 6.410122523322838,
        "cond_entropy-2": 0.31652963202531703,
        "distinct-3": 0.9139784946236559,
        "vocab_size-3": 85,
        "unique-3": 77,
        "entropy-3": 6.367115800355348,
        "cond_entropy-3": -0.01762257922729805,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 10.88888888888889,
        "std_pred_length-nopunct": 3.1426968052735447,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7244897959183674,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.966914502733951,
        "distinct-2-nopunct": 0.8651685393258427,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.197588627571312,
        "cond_entropy-2-nopunct": 0.28494556385344333,
        "distinct-3-nopunct": 0.9125,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.146928094887357,
        "cond_entropy-3-nopunct": -0.03186924230199208,
        "msttr-100": 0.68,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.40540540540540543,
            "2": 0.45,
            "3": 0.7411764705882353
        },
        "rouge1": {
            "precision": 0.83845,
            "recall": 0.72991,
            "fmeasure": 0.76909
        },
        "rouge2": {
            "precision": 0.65392,
            "recall": 0.57427,
            "fmeasure": 0.60159
        },
        "rougeL": {
            "precision": 0.79211,
            "recall": 0.6924,
            "fmeasure": 0.72784
        },
        "rougeLsum": {
            "precision": 0.79211,
            "recall": 0.6924,
            "fmeasure": 0.72784
        },
        "nist": 4.824852177329158,
        "bleu": 51.30983,
        "meteor": 0.39068390268717396,
        "bleurt": 0.21705,
        "nubia": {
            "semantic_relation": 3.95585,
            "contradiction": 0.82148,
            "irrelevancy": 19.73088,
            "logical_agreement": 79.44764,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.05665,
            "nubia_score": 0.67388
        },
        "bertscore": {
            "precision": 0.95761,
            "recall": 0.91712,
            "f1": 0.936
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 107,
        "mean_pred_length": 13.375,
        "std_pred_length": 2.394655507583502,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.6822429906542056,
        "vocab_size-1": 73,
        "unique-1": 58,
        "entropy-1": 5.859014795863103,
        "distinct-2": 0.9494949494949495,
        "vocab_size-2": 94,
        "unique-2": 89,
        "entropy-2": 6.528346519069518,
        "cond_entropy-2": 0.542141148154897,
        "distinct-3": 0.978021978021978,
        "vocab_size-3": 89,
        "unique-3": 87,
        "entropy-3": 6.463838596242658,
        "cond_entropy-3": -0.05562791394684735,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 11.625,
        "std_pred_length-nopunct": 2.4462982238476156,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7526881720430108,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.9019424140237335,
        "distinct-2-nopunct": 0.9529411764705882,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.315273289078883,
        "cond_entropy-2-nopunct": 0.46153947713367127,
        "distinct-3-nopunct": 0.987012987012987,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.240812514720878,
        "cond_entropy-3-nopunct": -0.07766933050773542,
        "msttr-100": 0.7,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35294117647058826,
            "2": 0.4,
            "3": 0.7857142857142857
        },
        "rouge1": {
            "precision": 0.82738,
            "recall": 0.78406,
            "fmeasure": 0.80225
        },
        "rouge2": {
            "precision": 0.60024,
            "recall": 0.58712,
            "fmeasure": 0.59007
        },
        "rougeL": {
            "precision": 0.7189,
            "recall": 0.70317,
            "fmeasure": 0.70732
        },
        "rougeLsum": {
            "precision": 0.7189,
            "recall": 0.70317,
            "fmeasure": 0.70732
        },
        "nist": 5.634092884412238,
        "bleu": 52.28288,
        "meteor": 0.42321937023934814,
        "bleurt": 0.36155,
        "nubia": {
            "semantic_relation": 3.93942,
            "contradiction": 34.73413,
            "irrelevancy": 11.12294,
            "logical_agreement": 54.14294,
            "grammar_ref": 5.14697,
            "grammar_hyp": 4.9816,
            "nubia_score": 0.64761
        },
        "bertscore": {
            "precision": 0.93277,
            "recall": 0.93267,
            "f1": 0.93163
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "t5-small/totto_test",
        "N": 22,
        "total_length": 335,
        "mean_pred_length": 15.227272727272727,
        "std_pred_length": 4.358187886368894,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5791044776119403,
        "vocab_size-1": 194,
        "unique-1": 152,
        "entropy-1": 6.948004349877588,
        "distinct-2": 0.8722044728434505,
        "vocab_size-2": 273,
        "unique-2": 249,
        "entropy-2": 7.969499617164339,
        "cond_entropy-2": 0.8465486943875676,
        "distinct-3": 0.9621993127147767,
        "vocab_size-3": 280,
        "unique-3": 271,
        "entropy-3": 8.104085738082418,
        "cond_entropy-3": 0.1588178152647831,
        "total_length-nopunct": 298,
        "mean_pred_length-nopunct": 13.545454545454545,
        "std_pred_length-nopunct": 3.9164834960978214,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6342281879194631,
        "vocab_size-1-nopunct": 189,
        "unique-1-nopunct": 151,
        "entropy-1-nopunct": 7.0482080457130385,
        "distinct-2-nopunct": 0.8731884057971014,
        "vocab_size-2-nopunct": 241,
        "unique-2-nopunct": 221,
        "entropy-2-nopunct": 7.78400405309952,
        "cond_entropy-2-nopunct": 0.7850395053685258,
        "distinct-3-nopunct": 0.968503937007874,
        "vocab_size-3-nopunct": 246,
        "unique-3-nopunct": 239,
        "entropy-3-nopunct": 7.922720562747865,
        "cond_entropy-3-nopunct": 0.15271055051530394,
        "msttr-100": 0.69667,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11904761904761904,
            "2": 0.3333333333333333,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.80857,
            "recall": 0.81895,
            "fmeasure": 0.80631
        },
        "rouge2": {
            "precision": 0.62458,
            "recall": 0.62857,
            "fmeasure": 0.62086
        },
        "rougeL": {
            "precision": 0.70699,
            "recall": 0.7182,
            "fmeasure": 0.70521
        },
        "rougeLsum": {
            "precision": 0.70699,
            "recall": 0.7182,
            "fmeasure": 0.70521
        },
        "nist": 6.257000380903715,
        "bleu": 52.86567,
        "meteor": 0.45808645423001876,
        "bleurt": 0.45109,
        "nubia": {
            "semantic_relation": 4.41665,
            "contradiction": 2.02444,
            "irrelevancy": 30.06342,
            "logical_agreement": 67.91214,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.2509,
            "nubia_score": 0.8267
        },
        "bertscore": {
            "precision": 0.95094,
            "recall": 0.94784,
            "f1": 0.94868
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "t5-small/totto_test",
        "N": 26,
        "total_length": 372,
        "mean_pred_length": 14.307692307692308,
        "std_pred_length": 4.647325374459451,
        "median_pred_length": 12.5,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.5940860215053764,
        "vocab_size-1": 221,
        "unique-1": 187,
        "entropy-1": 6.978646517968209,
        "distinct-2": 0.9421965317919075,
        "vocab_size-2": 326,
        "unique-2": 311,
        "entropy-2": 8.306695677039912,
        "cond_entropy-2": 1.1152292012766165,
        "distinct-3": 0.990625,
        "vocab_size-3": 317,
        "unique-3": 314,
        "entropy-3": 8.303178094887327,
        "cond_entropy-3": 0.000626937583420137,
        "total_length-nopunct": 308,
        "mean_pred_length-nopunct": 11.846153846153847,
        "std_pred_length-nopunct": 3.5267364265685077,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7012987012987013,
        "vocab_size-1-nopunct": 216,
        "unique-1-nopunct": 187,
        "entropy-1-nopunct": 7.23024221339753,
        "distinct-2-nopunct": 0.9432624113475178,
        "vocab_size-2-nopunct": 266,
        "unique-2-nopunct": 255,
        "entropy-2-nopunct": 8.010953258404182,
        "cond_entropy-2-nopunct": 0.8396128269457606,
        "distinct-3-nopunct": 0.9921875,
        "vocab_size-3-nopunct": 254,
        "unique-3-nopunct": 252,
        "entropy-3-nopunct": 7.984375,
        "cond_entropy-3-nopunct": -0.027521274251257492,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.45161290322580644,
            "3": 0.6909871244635193
        },
        "rouge1": {
            "precision": 0.72035,
            "recall": 0.65585,
            "fmeasure": 0.66889
        },
        "rouge2": {
            "precision": 0.44033,
            "recall": 0.4093,
            "fmeasure": 0.41458
        },
        "rougeL": {
            "precision": 0.6396,
            "recall": 0.57967,
            "fmeasure": 0.59223
        },
        "rougeLsum": {
            "precision": 0.6396,
            "recall": 0.57967,
            "fmeasure": 0.59223
        },
        "nist": 5.391263315086494,
        "bleu": 36.6095,
        "meteor": 0.3265574106897494,
        "bleurt": 0.01977,
        "nubia": {
            "semantic_relation": 3.74361,
            "contradiction": 8.97311,
            "irrelevancy": 55.71777,
            "logical_agreement": 35.30912,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.66808,
            "nubia_score": 0.61301
        },
        "bertscore": {
            "precision": 0.90961,
            "recall": 0.89874,
            "f1": 0.90199
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "t5-small/totto_test",
        "N": 44,
        "total_length": 599,
        "mean_pred_length": 13.613636363636363,
        "std_pred_length": 3.2066401922127232,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.5342237061769616,
        "vocab_size-1": 320,
        "unique-1": 260,
        "entropy-1": 7.354626514336708,
        "distinct-2": 0.8486486486486486,
        "vocab_size-2": 471,
        "unique-2": 431,
        "entropy-2": 8.701806337964198,
        "cond_entropy-2": 1.0815209227272296,
        "distinct-3": 0.9256360078277887,
        "vocab_size-3": 473,
        "unique-3": 450,
        "entropy-3": 8.826292372263545,
        "cond_entropy-3": 0.14452449892560168,
        "total_length-nopunct": 538,
        "mean_pred_length-nopunct": 12.227272727272727,
        "std_pred_length-nopunct": 2.983771533141147,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5836431226765799,
        "vocab_size-1-nopunct": 314,
        "unique-1-nopunct": 256,
        "entropy-1-nopunct": 7.517337956047358,
        "distinct-2-nopunct": 0.8421052631578947,
        "vocab_size-2-nopunct": 416,
        "unique-2-nopunct": 382,
        "entropy-2-nopunct": 8.506933262117688,
        "cond_entropy-2-nopunct": 1.0821452975454244,
        "distinct-3-nopunct": 0.92,
        "vocab_size-3-nopunct": 414,
        "unique-3-nopunct": 393,
        "entropy-3-nopunct": 8.628618274478288,
        "cond_entropy-3-nopunct": 0.15335872270516482,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.758,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.6025641025641025,
            "3": 0.6811594202898551
        },
        "rouge1": {
            "precision": 0.78803,
            "recall": 0.69945,
            "fmeasure": 0.728
        },
        "rouge2": {
            "precision": 0.54761,
            "recall": 0.50739,
            "fmeasure": 0.51869
        },
        "rougeL": {
            "precision": 0.69325,
            "recall": 0.6276,
            "fmeasure": 0.64632
        },
        "rougeLsum": {
            "precision": 0.69325,
            "recall": 0.6276,
            "fmeasure": 0.64632
        },
        "nist": 6.495706349127014,
        "bleu": 44.72754,
        "meteor": 0.37403949421469923,
        "bleurt": 0.25786,
        "nubia": {
            "semantic_relation": 4.24552,
            "contradiction": 8.84526,
            "irrelevancy": 33.11146,
            "logical_agreement": 58.04328,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.64132,
            "nubia_score": 0.72015
        },
        "bertscore": {
            "precision": 0.93559,
            "recall": 0.91838,
            "f1": 0.92482
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "t5-small/totto_test",
        "N": 31,
        "total_length": 498,
        "mean_pred_length": 16.06451612903226,
        "std_pred_length": 4.384249550459872,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.5803212851405622,
        "vocab_size-1": 289,
        "unique-1": 225,
        "entropy-1": 7.5130170216980385,
        "distinct-2": 0.8822269807280514,
        "vocab_size-2": 412,
        "unique-2": 374,
        "entropy-2": 8.586156228970667,
        "cond_entropy-2": 0.9374747152611845,
        "distinct-3": 0.9518348623853211,
        "vocab_size-3": 415,
        "unique-3": 396,
        "entropy-3": 8.668391262840343,
        "cond_entropy-3": 0.09534236834895503,
        "total_length-nopunct": 437,
        "mean_pred_length-nopunct": 14.096774193548388,
        "std_pred_length-nopunct": 3.541048129048411,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6498855835240275,
        "vocab_size-1-nopunct": 284,
        "unique-1-nopunct": 225,
        "entropy-1-nopunct": 7.672496247336675,
        "distinct-2-nopunct": 0.9014778325123153,
        "vocab_size-2-nopunct": 366,
        "unique-2-nopunct": 339,
        "entropy-2-nopunct": 8.424512179473753,
        "cond_entropy-2-nopunct": 0.8147839798867422,
        "distinct-3-nopunct": 0.9653333333333334,
        "vocab_size-3-nopunct": 362,
        "unique-3-nopunct": 349,
        "entropy-3-nopunct": 8.481413452049905,
        "cond_entropy-3-nopunct": 0.06614270156024726,
        "msttr-100": 0.755,
        "msttr-100_nopunct": 0.8125,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2037037037037037,
            "2": 0.3,
            "3": 0.7810810810810811
        },
        "rouge1": {
            "precision": 0.78963,
            "recall": 0.75234,
            "fmeasure": 0.75776
        },
        "rouge2": {
            "precision": 0.57116,
            "recall": 0.55538,
            "fmeasure": 0.55282
        },
        "rougeL": {
            "precision": 0.64159,
            "recall": 0.62195,
            "fmeasure": 0.62008
        },
        "rougeLsum": {
            "precision": 0.64159,
            "recall": 0.62195,
            "fmeasure": 0.62008
        },
        "nist": 6.529422555709982,
        "bleu": 47.17319,
        "meteor": 0.4069928438064102,
        "bleurt": 0.28103,
        "nubia": {
            "semantic_relation": 4.10787,
            "contradiction": 6.92902,
            "irrelevancy": 29.35241,
            "logical_agreement": 63.71857,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.71291,
            "nubia_score": 0.6797
        },
        "bertscore": {
            "precision": 0.93956,
            "recall": 0.93163,
            "f1": 0.93471
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.5,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.7586206896551724,
        "vocab_size-1": 22,
        "unique-1": 17,
        "entropy-1": 4.306256857196538,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.6808134280893965,
        "cond_entropy-2": 0.34135095148034106,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.031031312388743945,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.083856189774723,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.31448837497794035,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.036006438040157185,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8421052631578947
        },
        "rouge1": {
            "precision": 0.70556,
            "recall": 0.81528,
            "fmeasure": 0.73403
        },
        "rouge2": {
            "precision": 0.45779,
            "recall": 0.52574,
            "fmeasure": 0.47324
        },
        "rougeL": {
            "precision": 0.64167,
            "recall": 0.73242,
            "fmeasure": 0.6653
        },
        "rougeLsum": {
            "precision": 0.64167,
            "recall": 0.73242,
            "fmeasure": 0.6653
        },
        "nist": 3.28397118506846,
        "bleu": 36.36227,
        "meteor": 0.4225975889532683,
        "bleurt": 0.42587,
        "nubia": {
            "semantic_relation": 4.44008,
            "contradiction": 0.19518,
            "irrelevancy": 15.51467,
            "logical_agreement": 84.29016,
            "grammar_ref": 5.56806,
            "grammar_hyp": 5.02062,
            "nubia_score": 0.81316
        },
        "bertscore": {
            "precision": 0.93591,
            "recall": 0.94572,
            "f1": 0.9406
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.84,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.293660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.12253022283538198,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819113,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "rouge1": {
            "precision": 0.63005,
            "recall": 0.58003,
            "fmeasure": 0.6014
        },
        "rouge2": {
            "precision": 0.41818,
            "recall": 0.43234,
            "fmeasure": 0.41854
        },
        "rougeL": {
            "precision": 0.6149,
            "recall": 0.59951,
            "fmeasure": 0.59972
        },
        "rougeLsum": {
            "precision": 0.6149,
            "recall": 0.59951,
            "fmeasure": 0.59972
        },
        "nist": 3.289844238965999,
        "bleu": 40.92658,
        "meteor": 0.37260530610770864,
        "bleurt": 0.33087,
        "nubia": {
            "semantic_relation": 4.24149,
            "contradiction": 2.78188,
            "irrelevancy": 13.5633,
            "logical_agreement": 83.65482,
            "grammar_ref": 5.15434,
            "grammar_hyp": 4.87038,
            "nubia_score": 0.74801
        },
        "bertscore": {
            "precision": 0.90924,
            "recall": 0.89224,
            "f1": 0.89928
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "t5-small/totto_test",
        "N": 25,
        "total_length": 379,
        "mean_pred_length": 15.16,
        "std_pred_length": 4.451336877837938,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.633245382585752,
        "vocab_size-1": 240,
        "unique-1": 210,
        "entropy-1": 7.19039049218662,
        "distinct-2": 0.9096045197740112,
        "vocab_size-2": 322,
        "unique-2": 304,
        "entropy-2": 8.240942185796165,
        "cond_entropy-2": 0.9007014866939139,
        "distinct-3": 0.9756838905775076,
        "vocab_size-3": 321,
        "unique-3": 315,
        "entropy-3": 8.308722573114203,
        "cond_entropy-3": 0.08500404721820329,
        "total_length-nopunct": 341,
        "mean_pred_length-nopunct": 13.64,
        "std_pred_length-nopunct": 4.362384668962608,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6891495601173021,
        "vocab_size-1-nopunct": 235,
        "unique-1-nopunct": 208,
        "entropy-1-nopunct": 7.293166585351577,
        "distinct-2-nopunct": 0.9177215189873418,
        "vocab_size-2-nopunct": 290,
        "unique-2-nopunct": 277,
        "entropy-2-nopunct": 8.09022396509053,
        "cond_entropy-2-nopunct": 0.8793723594598787,
        "distinct-3-nopunct": 0.9862542955326461,
        "vocab_size-3-nopunct": 287,
        "unique-3-nopunct": 284,
        "entropy-3-nopunct": 8.154789818845867,
        "cond_entropy-3-nopunct": 0.07947623030919,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17857142857142858,
            "2": 0.27906976744186046,
            "3": 0.8214285714285714
        },
        "rouge1": {
            "precision": 0.83727,
            "recall": 0.77042,
            "fmeasure": 0.79549
        },
        "rouge2": {
            "precision": 0.64506,
            "recall": 0.61238,
            "fmeasure": 0.62494
        },
        "rougeL": {
            "precision": 0.75169,
            "recall": 0.69378,
            "fmeasure": 0.71535
        },
        "rougeLsum": {
            "precision": 0.75169,
            "recall": 0.69378,
            "fmeasure": 0.71535
        },
        "nist": 6.560312853007092,
        "bleu": 55.16821,
        "meteor": 0.43342292805158883,
        "bleurt": 0.35846,
        "nubia": {
            "semantic_relation": 4.17461,
            "contradiction": 17.61091,
            "irrelevancy": 23.42576,
            "logical_agreement": 58.96333,
            "grammar_ref": 4.85173,
            "grammar_hyp": 5.07376,
            "nubia_score": 0.68517
        },
        "bertscore": {
            "precision": 0.94711,
            "recall": 0.93581,
            "f1": 0.94094
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 86,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 2.9249881291307074,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.7906976744186046,
        "vocab_size-1": 68,
        "unique-1": 57,
        "entropy-1": 5.919175911976089,
        "distinct-2": 1.0,
        "vocab_size-2": 80,
        "unique-2": 80,
        "entropy-2": 6.321928094887356,
        "cond_entropy-2": 0.32828384611572475,
        "distinct-3": 1.0,
        "vocab_size-3": 74,
        "unique-3": 74,
        "entropy-3": 6.2094533656289554,
        "cond_entropy-3": -0.11247472925841277,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 2.981423969999719,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.858326980885212,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 70,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.129283016944973,
        "cond_entropy-2-nopunct": 0.30435036742190663,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 64,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.0,
        "cond_entropy-3-nopunct": -0.1292830169449664,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.1111111111111111,
            "3": 0.6944444444444444
        },
        "rouge1": {
            "precision": 0.7716,
            "recall": 0.65055,
            "fmeasure": 0.68891
        },
        "rouge2": {
            "precision": 0.53073,
            "recall": 0.44169,
            "fmeasure": 0.46665
        },
        "rougeL": {
            "precision": 0.70062,
            "recall": 0.59407,
            "fmeasure": 0.62401
        },
        "rougeLsum": {
            "precision": 0.70062,
            "recall": 0.59407,
            "fmeasure": 0.62401
        },
        "nist": 4.302172350309559,
        "bleu": 41.17179,
        "meteor": 0.35733658500164395,
        "bleurt": -0.1113,
        "nubia": {
            "semantic_relation": 3.84826,
            "contradiction": 15.64945,
            "irrelevancy": 37.07885,
            "logical_agreement": 47.2717,
            "grammar_ref": 4.74863,
            "grammar_hyp": 5.40953,
            "nubia_score": 0.5103
        },
        "bertscore": {
            "precision": 0.92823,
            "recall": 0.91333,
            "f1": 0.92052
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 103,
        "mean_pred_length": 17.166666666666668,
        "std_pred_length": 5.927806414592913,
        "median_pred_length": 20.5,
        "min_pred_length": 7,
        "max_pred_length": 22,
        "distinct-1": 0.6893203883495146,
        "vocab_size-1": 71,
        "unique-1": 58,
        "entropy-1": 5.855840552653997,
        "distinct-2": 0.9381443298969072,
        "vocab_size-2": 91,
        "unique-2": 86,
        "entropy-2": 6.468419156597824,
        "cond_entropy-2": 0.5339633397452572,
        "distinct-3": 0.989010989010989,
        "vocab_size-3": 90,
        "unique-3": 89,
        "entropy-3": 6.485816618220681,
        "cond_entropy-3": 0.004089352980397655,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 13.833333333333334,
        "std_pred_length-nopunct": 4.810289896553937,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8072289156626506,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.9037211725666445,
        "distinct-2-nopunct": 0.974025974025974,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.205034754952522,
        "cond_entropy-2-nopunct": 0.3250526674856427,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.149747119504677,
        "cond_entropy-3-nopunct": -0.05006917468087456,
        "msttr-100": 0.69,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.19148936170212766,
            "3": 0.7903225806451613
        },
        "rouge1": {
            "precision": 0.74728,
            "recall": 0.54926,
            "fmeasure": 0.62586
        },
        "rouge2": {
            "precision": 0.45347,
            "recall": 0.34464,
            "fmeasure": 0.38857
        },
        "rougeL": {
            "precision": 0.62731,
            "recall": 0.4555,
            "fmeasure": 0.52092
        },
        "rougeLsum": {
            "precision": 0.62731,
            "recall": 0.4555,
            "fmeasure": 0.52092
        },
        "nist": 3.21802036729679,
        "bleu": 35.46841,
        "meteor": 0.31759934404679835,
        "bleurt": 0.06625,
        "nubia": {
            "semantic_relation": 3.79937,
            "contradiction": 4.94021,
            "irrelevancy": 22.97455,
            "logical_agreement": 72.08525,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.76062,
            "nubia_score": 0.60309
        },
        "bertscore": {
            "precision": 0.90941,
            "recall": 0.8702,
            "f1": 0.88744
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 73,
        "mean_pred_length": 14.6,
        "std_pred_length": 3.8781438859330635,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.7671232876712328,
        "vocab_size-1": 56,
        "unique-1": 50,
        "entropy-1": 5.551068524865084,
        "distinct-2": 1.0,
        "vocab_size-2": 68,
        "unique-2": 68,
        "entropy-2": 6.087462841250345,
        "cond_entropy-2": 0.46571461300400907,
        "distinct-3": 1.0,
        "vocab_size-3": 63,
        "unique-3": 63,
        "entropy-3": 5.97727992349992,
        "cond_entropy-3": -0.11018291775042297,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 12.6,
        "std_pred_length-nopunct": 2.939387691339814,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.610305074630653,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.85798099512757,
        "cond_entropy-2-nopunct": 0.2620703040201343,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.727920454563195,
        "cond_entropy-3-nopunct": -0.13006054056437302,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5925925925925926,
            "2": 0.125,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.66383,
            "recall": 0.59118,
            "fmeasure": 0.60573
        },
        "rouge2": {
            "precision": 0.42672,
            "recall": 0.36015,
            "fmeasure": 0.37446
        },
        "rougeL": {
            "precision": 0.53377,
            "recall": 0.46511,
            "fmeasure": 0.48147
        },
        "rougeLsum": {
            "precision": 0.53377,
            "recall": 0.46511,
            "fmeasure": 0.48147
        },
        "nist": 3.9507217376387906,
        "bleu": 44.32795,
        "meteor": 0.26128971800377077,
        "bleurt": -0.24536,
        "nubia": {
            "semantic_relation": 3.43997,
            "contradiction": 11.63747,
            "irrelevancy": 42.09742,
            "logical_agreement": 46.26511,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.56898,
            "nubia_score": 0.50433
        },
        "bertscore": {
            "precision": 0.91735,
            "recall": 0.86836,
            "f1": 0.89075
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "t5-small/totto_test",
        "N": 31,
        "total_length": 477,
        "mean_pred_length": 15.387096774193548,
        "std_pred_length": 4.534295260210101,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5660377358490566,
        "vocab_size-1": 270,
        "unique-1": 219,
        "entropy-1": 7.260324588109729,
        "distinct-2": 0.9192825112107623,
        "vocab_size-2": 410,
        "unique-2": 388,
        "entropy-2": 8.603054987459524,
        "cond_entropy-2": 1.1602139420321242,
        "distinct-3": 0.9879518072289156,
        "vocab_size-3": 410,
        "unique-3": 405,
        "entropy-3": 8.672871140692154,
        "cond_entropy-3": 0.0797756527176632,
        "total_length-nopunct": 420,
        "mean_pred_length-nopunct": 13.548387096774194,
        "std_pred_length-nopunct": 3.9744239564545647,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6333333333333333,
        "vocab_size-1-nopunct": 266,
        "unique-1-nopunct": 219,
        "entropy-1-nopunct": 7.4461532926345555,
        "distinct-2-nopunct": 0.9203084832904884,
        "vocab_size-2-nopunct": 358,
        "unique-2-nopunct": 341,
        "entropy-2-nopunct": 8.402498244838393,
        "cond_entropy-2-nopunct": 1.044547674507024,
        "distinct-3-nopunct": 0.9888268156424581,
        "vocab_size-3-nopunct": 354,
        "unique-3-nopunct": 350,
        "entropy-3-nopunct": 8.461469408549172,
        "cond_entropy-3-nopunct": 0.07080069193596208,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.7625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22666666666666666,
            "2": 0.5949367088607594,
            "3": 0.721875
        },
        "rouge1": {
            "precision": 0.74458,
            "recall": 0.72077,
            "fmeasure": 0.7248
        },
        "rouge2": {
            "precision": 0.4996,
            "recall": 0.48862,
            "fmeasure": 0.4896
        },
        "rougeL": {
            "precision": 0.62045,
            "recall": 0.60881,
            "fmeasure": 0.60755
        },
        "rougeLsum": {
            "precision": 0.62045,
            "recall": 0.60881,
            "fmeasure": 0.60755
        },
        "nist": 6.197600537369886,
        "bleu": 41.3555,
        "meteor": 0.3655743864510819,
        "bleurt": 0.20749,
        "nubia": {
            "semantic_relation": 4.06272,
            "contradiction": 12.98161,
            "irrelevancy": 36.85974,
            "logical_agreement": 50.15865,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.66527,
            "nubia_score": 0.68641
        },
        "bertscore": {
            "precision": 0.91746,
            "recall": 0.91128,
            "f1": 0.91287
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 130,
        "mean_pred_length": 16.25,
        "std_pred_length": 3.344772040064913,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.7153846153846154,
        "vocab_size-1": 93,
        "unique-1": 78,
        "entropy-1": 6.212188485855748,
        "distinct-2": 0.9590163934426229,
        "vocab_size-2": 117,
        "unique-2": 112,
        "entropy-2": 6.848770124448145,
        "cond_entropy-2": 0.5495873526279069,
        "distinct-3": 0.9824561403508771,
        "vocab_size-3": 112,
        "unique-3": 110,
        "entropy-3": 6.797802294866507,
        "cond_entropy-3": -0.053987674275337356,
        "total_length-nopunct": 119,
        "mean_pred_length-nopunct": 14.875,
        "std_pred_length-nopunct": 3.4798527267687636,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7478991596638656,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.180039191661207,
        "distinct-2-nopunct": 0.954954954954955,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 101,
        "entropy-2-nopunct": 6.7043257762600295,
        "cond_entropy-2-nopunct": 0.5615232158821674,
        "distinct-3-nopunct": 0.9805825242718447,
        "vocab_size-3-nopunct": 101,
        "unique-3-nopunct": 99,
        "entropy-3-nopunct": 6.647665575726924,
        "cond_entropy-3-nopunct": -0.05937164984649907,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23333333333333334,
            "2": 0.4791666666666667,
            "3": 0.6338028169014085
        },
        "rouge1": {
            "precision": 0.62573,
            "recall": 0.58392,
            "fmeasure": 0.58357
        },
        "rouge2": {
            "precision": 0.40058,
            "recall": 0.36457,
            "fmeasure": 0.37082
        },
        "rougeL": {
            "precision": 0.51281,
            "recall": 0.4851,
            "fmeasure": 0.48364
        },
        "rougeLsum": {
            "precision": 0.51281,
            "recall": 0.4851,
            "fmeasure": 0.48364
        },
        "nist": 3.8439623341725304,
        "bleu": 26.81722,
        "meteor": 0.2858943588714968,
        "bleurt": 0.05236,
        "nubia": {
            "semantic_relation": 3.67984,
            "contradiction": 21.18929,
            "irrelevancy": 44.86739,
            "logical_agreement": 33.94331,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.41355,
            "nubia_score": 0.59133
        },
        "bertscore": {
            "precision": 0.89937,
            "recall": 0.88445,
            "f1": 0.88879
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "t5-small/totto_test",
        "N": 73,
        "total_length": 1081,
        "mean_pred_length": 14.808219178082192,
        "std_pred_length": 4.967448931138378,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.48751156336725254,
        "vocab_size-1": 527,
        "unique-1": 411,
        "entropy-1": 7.838349168413322,
        "distinct-2": 0.8422619047619048,
        "vocab_size-2": 849,
        "unique-2": 759,
        "entropy-2": 9.563585401787279,
        "cond_entropy-2": 1.5128476067720373,
        "distinct-3": 0.9272727272727272,
        "vocab_size-3": 867,
        "unique-3": 812,
        "entropy-3": 9.709470984229668,
        "cond_entropy-3": 0.14581610391681873,
        "total_length-nopunct": 934,
        "mean_pred_length-nopunct": 12.794520547945206,
        "std_pred_length-nopunct": 4.468945829266702,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5546038543897216,
        "vocab_size-1-nopunct": 518,
        "unique-1-nopunct": 408,
        "entropy-1-nopunct": 8.084917307896022,
        "distinct-2-nopunct": 0.859465737514518,
        "vocab_size-2-nopunct": 740,
        "unique-2-nopunct": 676,
        "entropy-2-nopunct": 9.368789026820044,
        "cond_entropy-2-nopunct": 1.3632343100343454,
        "distinct-3-nopunct": 0.9416243654822335,
        "vocab_size-3-nopunct": 742,
        "unique-3-nopunct": 704,
        "entropy-3-nopunct": 9.495307780140575,
        "cond_entropy-3-nopunct": 0.14187179577637396,
        "msttr-100": 0.713,
        "msttr-100_nopunct": 0.76222,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.42168674698795183,
            "3": 0.7321212121212122
        },
        "rouge1": {
            "precision": 0.8128,
            "recall": 0.71624,
            "fmeasure": 0.75129
        },
        "rouge2": {
            "precision": 0.59139,
            "recall": 0.52416,
            "fmeasure": 0.54774
        },
        "rougeL": {
            "precision": 0.72212,
            "recall": 0.64126,
            "fmeasure": 0.6696
        },
        "rougeLsum": {
            "precision": 0.72212,
            "recall": 0.64126,
            "fmeasure": 0.6696
        },
        "nist": 6.842644395113215,
        "bleu": 47.7931,
        "meteor": 0.3866195614918244,
        "bleurt": 0.22631,
        "nubia": {
            "semantic_relation": 4.18058,
            "contradiction": 8.31651,
            "irrelevancy": 30.16914,
            "logical_agreement": 61.51435,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.72004,
            "nubia_score": 0.72614
        },
        "bertscore": {
            "precision": 0.93868,
            "recall": 0.92102,
            "f1": 0.92844
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "t5-small/totto_test",
        "N": 14,
        "total_length": 222,
        "mean_pred_length": 15.857142857142858,
        "std_pred_length": 4.718612732832498,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6036036036036037,
        "vocab_size-1": 134,
        "unique-1": 106,
        "entropy-1": 6.4243916711350035,
        "distinct-2": 0.9134615384615384,
        "vocab_size-2": 190,
        "unique-2": 179,
        "entropy-2": 7.487628840706021,
        "cond_entropy-2": 0.9165528421501489,
        "distinct-3": 0.9742268041237113,
        "vocab_size-3": 189,
        "unique-3": 184,
        "entropy-3": 7.548366450434528,
        "cond_entropy-3": 0.07094045655371806,
        "total_length-nopunct": 198,
        "mean_pred_length-nopunct": 14.142857142857142,
        "std_pred_length-nopunct": 4.580348440537542,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6515151515151515,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 103,
        "entropy-1-nopunct": 6.457439170574968,
        "distinct-2-nopunct": 0.907608695652174,
        "vocab_size-2-nopunct": 167,
        "unique-2-nopunct": 157,
        "entropy-2-nopunct": 7.2938627033043595,
        "cond_entropy-2-nopunct": 0.906107672905153,
        "distinct-3-nopunct": 0.9764705882352941,
        "vocab_size-3-nopunct": 166,
        "unique-3-nopunct": 162,
        "entropy-3-nopunct": 7.362332112608262,
        "cond_entropy-3-nopunct": 0.08150346541298548,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.4230769230769231,
            "3": 0.753968253968254
        },
        "rouge1": {
            "precision": 0.69788,
            "recall": 0.69287,
            "fmeasure": 0.68523
        },
        "rouge2": {
            "precision": 0.47502,
            "recall": 0.46564,
            "fmeasure": 0.4662
        },
        "rougeL": {
            "precision": 0.57481,
            "recall": 0.57809,
            "fmeasure": 0.56782
        },
        "rougeLsum": {
            "precision": 0.57481,
            "recall": 0.57809,
            "fmeasure": 0.56782
        },
        "nist": 5.340351358492636,
        "bleu": 40.92111,
        "meteor": 0.3659019205381929,
        "bleurt": 0.13572,
        "nubia": {
            "semantic_relation": 3.94139,
            "contradiction": 16.52458,
            "irrelevancy": 30.03024,
            "logical_agreement": 53.44517,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.47832,
            "nubia_score": 0.67668
        },
        "bertscore": {
            "precision": 0.91367,
            "recall": 0.91078,
            "f1": 0.91134
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 83,
        "mean_pred_length": 11.857142857142858,
        "std_pred_length": 2.231499907401901,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.6144578313253012,
        "vocab_size-1": 51,
        "unique-1": 38,
        "entropy-1": 5.295911342006002,
        "distinct-2": 0.868421052631579,
        "vocab_size-2": 66,
        "unique-2": 57,
        "entropy-2": 5.974836888415124,
        "cond_entropy-2": 0.5197467591852152,
        "distinct-3": 0.8985507246376812,
        "vocab_size-3": 62,
        "unique-3": 55,
        "entropy-3": 5.905625906053528,
        "cond_entropy-3": -0.0704916435905836,
        "total_length-nopunct": 72,
        "mean_pred_length-nopunct": 10.285714285714286,
        "std_pred_length-nopunct": 2.249716535431946,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.6805555555555556,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.309978515874348,
        "distinct-2-nopunct": 0.8769230769230769,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.764600312995173,
        "cond_entropy-2-nopunct": 0.5164621878742988,
        "distinct-3-nopunct": 0.9137931034482759,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.685567202024123,
        "cond_entropy-3-nopunct": -0.08240599889806384,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.38461538461538464,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.75192,
            "recall": 0.77005,
            "fmeasure": 0.755
        },
        "rouge2": {
            "precision": 0.48639,
            "recall": 0.50009,
            "fmeasure": 0.48896
        },
        "rougeL": {
            "precision": 0.6793,
            "recall": 0.70234,
            "fmeasure": 0.68499
        },
        "rougeLsum": {
            "precision": 0.6793,
            "recall": 0.70234,
            "fmeasure": 0.68499
        },
        "nist": 4.2255255221708214,
        "bleu": 33.40395,
        "meteor": 0.37099999538766165,
        "bleurt": 0.36348,
        "nubia": {
            "semantic_relation": 4.10841,
            "contradiction": 17.31623,
            "irrelevancy": 18.57424,
            "logical_agreement": 64.10953,
            "grammar_ref": 5.14386,
            "grammar_hyp": 5.03452,
            "nubia_score": 0.72882
        },
        "bertscore": {
            "precision": 0.93483,
            "recall": 0.92194,
            "f1": 0.92649
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "t5-small/totto_test",
        "N": 12,
        "total_length": 186,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.890466917040404,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.6397849462365591,
        "vocab_size-1": 119,
        "unique-1": 99,
        "entropy-1": 6.277850344773701,
        "distinct-2": 0.9482758620689655,
        "vocab_size-2": 165,
        "unique-2": 159,
        "entropy-2": 7.323662533192597,
        "cond_entropy-2": 0.9378470111789957,
        "distinct-3": 0.9814814814814815,
        "vocab_size-3": 159,
        "unique-3": 156,
        "entropy-3": 7.3028129658475684,
        "cond_entropy-3": -0.02179765962186693,
        "total_length-nopunct": 158,
        "mean_pred_length-nopunct": 13.166666666666666,
        "std_pred_length-nopunct": 3.7601713908928263,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7278481012658228,
        "vocab_size-1-nopunct": 115,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.439304916379958,
        "distinct-2-nopunct": 0.9657534246575342,
        "vocab_size-2-nopunct": 141,
        "unique-2-nopunct": 138,
        "entropy-2-nopunct": 7.107632778058102,
        "cond_entropy-2-nopunct": 0.6955976737246409,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 134,
        "unique-3-nopunct": 134,
        "entropy-3-nopunct": 7.06608919045778,
        "cond_entropy-3-nopunct": -0.04164581618343888,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.06,
            "2": 0.15384615384615385,
            "3": 0.6058823529411764
        },
        "rouge1": {
            "precision": 0.78601,
            "recall": 0.60313,
            "fmeasure": 0.67465
        },
        "rouge2": {
            "precision": 0.53532,
            "recall": 0.41983,
            "fmeasure": 0.46528
        },
        "rougeL": {
            "precision": 0.71877,
            "recall": 0.56052,
            "fmeasure": 0.62271
        },
        "rougeLsum": {
            "precision": 0.71877,
            "recall": 0.56052,
            "fmeasure": 0.62271
        },
        "nist": 3.139653956512987,
        "bleu": 27.08038,
        "meteor": 0.2895609670204625,
        "bleurt": 0.0648,
        "nubia": {
            "semantic_relation": 3.7481,
            "contradiction": 7.92228,
            "irrelevancy": 40.42787,
            "logical_agreement": 51.64985,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.42281,
            "nubia_score": 0.58789
        },
        "bertscore": {
            "precision": 0.91169,
            "recall": 0.87609,
            "f1": 0.89142
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 95,
        "mean_pred_length": 15.833333333333334,
        "std_pred_length": 2.793842435706702,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.6947368421052632,
        "vocab_size-1": 66,
        "unique-1": 52,
        "entropy-1": 5.762792087667189,
        "distinct-2": 0.9325842696629213,
        "vocab_size-2": 83,
        "unique-2": 78,
        "entropy-2": 6.33242008824547,
        "cond_entropy-2": 0.5341491368027936,
        "distinct-3": 0.9518072289156626,
        "vocab_size-3": 79,
        "unique-3": 75,
        "entropy-3": 6.278653889178256,
        "cond_entropy-3": -0.04340619838858778,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 14.166666666666666,
        "std_pred_length-nopunct": 3.2360813064912666,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7176470588235294,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.657436266009545,
        "distinct-2-nopunct": 0.9240506329113924,
        "vocab_size-2-nopunct": 73,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.14232647599782,
        "cond_entropy-2-nopunct": 0.5420006912638341,
        "distinct-3-nopunct": 0.9452054794520548,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.080235517784134,
        "cond_entropy-3-nopunct": -0.04882074406196958,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.16666666666666666,
            "3": 0.6794871794871795
        },
        "rouge1": {
            "precision": 0.81459,
            "recall": 0.69971,
            "fmeasure": 0.74659
        },
        "rouge2": {
            "precision": 0.61376,
            "recall": 0.53911,
            "fmeasure": 0.56959
        },
        "rougeL": {
            "precision": 0.67914,
            "recall": 0.59694,
            "fmeasure": 0.63076
        },
        "rougeLsum": {
            "precision": 0.67914,
            "recall": 0.59694,
            "fmeasure": 0.63076
        },
        "nist": 4.847233476337223,
        "bleu": 53.28979,
        "meteor": 0.3713253656473305,
        "bleurt": 0.01409,
        "nubia": {
            "semantic_relation": 3.75108,
            "contradiction": 2.78359,
            "irrelevancy": 42.35312,
            "logical_agreement": 54.86329,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.14068,
            "nubia_score": 0.61535
        },
        "bertscore": {
            "precision": 0.92949,
            "recall": 0.90809,
            "f1": 0.9184
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185191,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.71806,
            "fmeasure": 0.72545
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.48889,
            "fmeasure": 0.49425
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.5875,
            "fmeasure": 0.59355
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.5875,
            "fmeasure": 0.59355
        },
        "nist": 2.3601831360144674,
        "bleu": 21.87406,
        "meteor": 0.3298335520746021,
        "bleurt": 0.11524,
        "nubia": {
            "semantic_relation": 4.10034,
            "contradiction": 71.08031,
            "irrelevancy": 20.35026,
            "logical_agreement": 8.56944,
            "grammar_ref": 5.18542,
            "grammar_hyp": 5.02765,
            "nubia_score": 0.61117
        },
        "bertscore": {
            "precision": 0.88818,
            "recall": 0.93259,
            "f1": 0.90984
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "t5-small/totto_test",
        "N": 11,
        "total_length": 169,
        "mean_pred_length": 15.363636363636363,
        "std_pred_length": 6.4423700787369365,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.6627218934911243,
        "vocab_size-1": 112,
        "unique-1": 91,
        "entropy-1": 6.431514703246669,
        "distinct-2": 0.8924050632911392,
        "vocab_size-2": 141,
        "unique-2": 127,
        "entropy-2": 7.071154877910259,
        "cond_entropy-2": 0.4968789791858313,
        "distinct-3": 0.9387755102040817,
        "vocab_size-3": 138,
        "unique-3": 129,
        "entropy-3": 7.07722336524452,
        "cond_entropy-3": 0.02347586538146182,
        "total_length-nopunct": 150,
        "mean_pred_length-nopunct": 13.636363636363637,
        "std_pred_length-nopunct": 5.866278474509701,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7066666666666667,
        "vocab_size-1-nopunct": 106,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.435527234097931,
        "distinct-2-nopunct": 0.8776978417266187,
        "vocab_size-2-nopunct": 122,
        "unique-2-nopunct": 108,
        "entropy-2-nopunct": 6.85451742162882,
        "cond_entropy-2-nopunct": 0.4745744035048031,
        "distinct-3-nopunct": 0.9296875,
        "vocab_size-3-nopunct": 119,
        "unique-3-nopunct": 110,
        "entropy-3-nopunct": 6.859375,
        "cond_entropy-3-nopunct": 0.01976898588714468,
        "msttr-100": 0.81,
        "msttr-100_nopunct": 0.83,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15625,
            "2": 0.25,
            "3": 0.9349593495934959
        },
        "rouge1": {
            "precision": 0.88851,
            "recall": 0.87787,
            "fmeasure": 0.87956
        },
        "rouge2": {
            "precision": 0.76921,
            "recall": 0.7614,
            "fmeasure": 0.76128
        },
        "rougeL": {
            "precision": 0.86589,
            "recall": 0.86097,
            "fmeasure": 0.85971
        },
        "rougeLsum": {
            "precision": 0.86589,
            "recall": 0.86097,
            "fmeasure": 0.85971
        },
        "nist": 6.7936859497552495,
        "bleu": 75.5296,
        "meteor": 0.5171073174277874,
        "bleurt": 0.58733,
        "nubia": {
            "semantic_relation": 4.66242,
            "contradiction": 9.53612,
            "irrelevancy": 12.75975,
            "logical_agreement": 77.70413,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.24451,
            "nubia_score": 0.89498
        },
        "bertscore": {
            "precision": 0.97176,
            "recall": 0.96507,
            "f1": 0.96811
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 35,
        "mean_pred_length": 11.666666666666666,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.7428571428571429,
        "vocab_size-1": 26,
        "unique-1": 21,
        "entropy-1": 4.490296503327814,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.507108482323792,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.14201900487242786,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.386569246460625,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.42613173894149875,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.85198,
            "recall": 0.64915,
            "fmeasure": 0.73379
        },
        "rouge2": {
            "precision": 0.49247,
            "recall": 0.3692,
            "fmeasure": 0.42031
        },
        "rougeL": {
            "precision": 0.70595,
            "recall": 0.5418,
            "fmeasure": 0.61083
        },
        "rougeLsum": {
            "precision": 0.70595,
            "recall": 0.5418,
            "fmeasure": 0.61083
        },
        "nist": 2.5476041271467547,
        "bleu": 21.35847,
        "meteor": 0.34891999265464857,
        "bleurt": 0.20238,
        "nubia": {
            "semantic_relation": 4.37933,
            "contradiction": 1.00917,
            "irrelevancy": 38.70082,
            "logical_agreement": 60.29001,
            "grammar_ref": 5.15044,
            "grammar_hyp": 5.60269,
            "nubia_score": 0.68314
        },
        "bertscore": {
            "precision": 0.94074,
            "recall": 0.92362,
            "f1": 0.93193
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "t5-small/totto_test",
        "N": 12,
        "total_length": 167,
        "mean_pred_length": 13.916666666666666,
        "std_pred_length": 4.627064103967247,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.6287425149700598,
        "vocab_size-1": 105,
        "unique-1": 85,
        "entropy-1": 6.218916832024811,
        "distinct-2": 0.9096774193548387,
        "vocab_size-2": 141,
        "unique-2": 132,
        "entropy-2": 7.062450757024165,
        "cond_entropy-2": 0.6561655347847271,
        "distinct-3": 0.958041958041958,
        "vocab_size-3": 137,
        "unique-3": 133,
        "entropy-3": 7.065397385699186,
        "cond_entropy-3": 0.020877284472241422,
        "total_length-nopunct": 146,
        "mean_pred_length-nopunct": 12.166666666666666,
        "std_pred_length-nopunct": 4.017323597731316,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6917808219178082,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.286752836743277,
        "distinct-2-nopunct": 0.9104477611940298,
        "vocab_size-2-nopunct": 122,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.854413608542852,
        "cond_entropy-2-nopunct": 0.6217794148213578,
        "distinct-3-nopunct": 0.9672131147540983,
        "vocab_size-3-nopunct": 118,
        "unique-3-nopunct": 115,
        "entropy-3-nopunct": 6.8589759645943476,
        "cond_entropy-3-nopunct": 0.008989462469349997,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17142857142857143,
            "2": 0.41379310344827586,
            "3": 0.7355371900826446
        },
        "rouge1": {
            "precision": 0.82564,
            "recall": 0.70349,
            "fmeasure": 0.74277
        },
        "rouge2": {
            "precision": 0.59762,
            "recall": 0.4799,
            "fmeasure": 0.51796
        },
        "rougeL": {
            "precision": 0.74585,
            "recall": 0.6197,
            "fmeasure": 0.66148
        },
        "rougeLsum": {
            "precision": 0.74585,
            "recall": 0.6197,
            "fmeasure": 0.66148
        },
        "nist": 5.3578879013740535,
        "bleu": 45.64832,
        "meteor": 0.3757423502430262,
        "bleurt": 0.40936,
        "nubia": {
            "semantic_relation": 4.39067,
            "contradiction": 1.2875,
            "irrelevancy": 12.19823,
            "logical_agreement": 86.51427,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.64293,
            "nubia_score": 0.76746
        },
        "bertscore": {
            "precision": 0.95842,
            "recall": 0.92752,
            "f1": 0.94016
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 116,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.8722813232690143,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.6982758620689655,
        "vocab_size-1": 81,
        "unique-1": 69,
        "entropy-1": 5.971687892106227,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 102,
        "unique-2": 96,
        "entropy-2": 6.643776391052348,
        "cond_entropy-2": 0.5557816505180395,
        "distinct-3": 0.98,
        "vocab_size-3": 98,
        "unique-3": 96,
        "entropy-3": 6.603856189774739,
        "cond_entropy-3": -0.051031312388743935,
        "total_length-nopunct": 102,
        "mean_pred_length-nopunct": 12.75,
        "std_pred_length-nopunct": 2.9047375096555625,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7549019607843137,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 5.970965782935864,
        "distinct-2-nopunct": 0.9574468085106383,
        "vocab_size-2-nopunct": 90,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.469482468698901,
        "cond_entropy-2-nopunct": 0.5369387758937451,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 86,
        "unique-3-nopunct": 86,
        "entropy-3-nopunct": 6.426264754702099,
        "cond_entropy-3-nopunct": -0.05855665511507436,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.3142857142857143,
            "3": 0.8695652173913043
        },
        "rouge1": {
            "precision": 0.78259,
            "recall": 0.73928,
            "fmeasure": 0.75372
        },
        "rouge2": {
            "precision": 0.56399,
            "recall": 0.5257,
            "fmeasure": 0.53852
        },
        "rougeL": {
            "precision": 0.66076,
            "recall": 0.63464,
            "fmeasure": 0.64119
        },
        "rougeLsum": {
            "precision": 0.66076,
            "recall": 0.63464,
            "fmeasure": 0.64119
        },
        "nist": 5.429292398107049,
        "bleu": 43.71574,
        "meteor": 0.41160956170119406,
        "bleurt": 0.18481,
        "nubia": {
            "semantic_relation": 4.3439,
            "contradiction": 8.26286,
            "irrelevancy": 28.53478,
            "logical_agreement": 63.20236,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.74064,
            "nubia_score": 0.76439
        },
        "bertscore": {
            "precision": 0.92875,
            "recall": 0.94638,
            "f1": 0.93477
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "t5-small/totto_test",
        "N": 14,
        "total_length": 218,
        "mean_pred_length": 15.571428571428571,
        "std_pred_length": 5.447335989982177,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.6422018348623854,
        "vocab_size-1": 140,
        "unique-1": 120,
        "entropy-1": 6.540938403271024,
        "distinct-2": 0.946078431372549,
        "vocab_size-2": 193,
        "unique-2": 186,
        "entropy-2": 7.547377425283619,
        "cond_entropy-2": 0.899221841110983,
        "distinct-3": 0.9631578947368421,
        "vocab_size-3": 183,
        "unique-3": 178,
        "entropy-3": 7.488225213571344,
        "cond_entropy-3": -0.06046447048265316,
        "total_length-nopunct": 193,
        "mean_pred_length-nopunct": 13.785714285714286,
        "std_pred_length-nopunct": 5.129446801536781,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7046632124352331,
        "vocab_size-1-nopunct": 136,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 6.610943486603479,
        "distinct-2-nopunct": 0.9497206703910615,
        "vocab_size-2-nopunct": 170,
        "unique-2-nopunct": 165,
        "entropy-2-nopunct": 7.363649436457952,
        "cond_entropy-2-nopunct": 0.8071260040963876,
        "distinct-3-nopunct": 0.9636363636363636,
        "vocab_size-3-nopunct": 159,
        "unique-3-nopunct": 155,
        "entropy-3-nopunct": 7.284444789977161,
        "cond_entropy-3-nopunct": -0.08112992665480433,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2876712328767123,
            "2": 0.5230769230769231,
            "3": 0.7739130434782608
        },
        "rouge1": {
            "precision": 0.76805,
            "recall": 0.69374,
            "fmeasure": 0.71254
        },
        "rouge2": {
            "precision": 0.55245,
            "recall": 0.48716,
            "fmeasure": 0.50518
        },
        "rougeL": {
            "precision": 0.6268,
            "recall": 0.57623,
            "fmeasure": 0.5876
        },
        "rougeLsum": {
            "precision": 0.6268,
            "recall": 0.57623,
            "fmeasure": 0.5876
        },
        "nist": 5.371273307225265,
        "bleu": 41.5885,
        "meteor": 0.3574296171769326,
        "bleurt": 0.07257,
        "nubia": {
            "semantic_relation": 3.89918,
            "contradiction": 7.64398,
            "irrelevancy": 49.41206,
            "logical_agreement": 42.94396,
            "grammar_ref": 4.00042,
            "grammar_hyp": 4.25101,
            "nubia_score": 0.65991
        },
        "bertscore": {
            "precision": 0.92579,
            "recall": 0.92368,
            "f1": 0.92353
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 104,
        "mean_pred_length": 14.857142857142858,
        "std_pred_length": 4.882287854467161,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.5865384615384616,
        "vocab_size-1": 61,
        "unique-1": 44,
        "entropy-1": 5.524442001566112,
        "distinct-2": 0.8556701030927835,
        "vocab_size-2": 83,
        "unique-2": 75,
        "entropy-2": 6.254451244204383,
        "cond_entropy-2": 0.6549804695629865,
        "distinct-3": 0.9222222222222223,
        "vocab_size-3": 83,
        "unique-3": 79,
        "entropy-3": 6.305687679638959,
        "cond_entropy-3": 0.03366122638880756,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 12.714285714285714,
        "std_pred_length-nopunct": 4.266624149448022,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6292134831460674,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.410632447601557,
        "distinct-2-nopunct": 0.8658536585365854,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.022066943589712,
        "cond_entropy-2-nopunct": 0.6291870189583237,
        "distinct-3-nopunct": 0.9333333333333333,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.058753523800377,
        "cond_entropy-3-nopunct": 0.014665185906643521,
        "msttr-100": 0.61,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.47058823529411764,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.70648,
            "recall": 0.6651,
            "fmeasure": 0.67538
        },
        "rouge2": {
            "precision": 0.47266,
            "recall": 0.4605,
            "fmeasure": 0.45977
        },
        "rougeL": {
            "precision": 0.65576,
            "recall": 0.62314,
            "fmeasure": 0.63017
        },
        "rougeLsum": {
            "precision": 0.65576,
            "recall": 0.62314,
            "fmeasure": 0.63017
        },
        "nist": 3.8564138847658564,
        "bleu": 28.56327,
        "meteor": 0.36046048403273057,
        "bleurt": 0.06158,
        "nubia": {
            "semantic_relation": 3.80411,
            "contradiction": 14.02177,
            "irrelevancy": 55.59477,
            "logical_agreement": 30.38347,
            "grammar_ref": 4.06397,
            "grammar_hyp": 4.22853,
            "nubia_score": 0.65977
        },
        "bertscore": {
            "precision": 0.9072,
            "recall": 0.88548,
            "f1": 0.89533
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "t5-small/totto_test",
        "N": 18,
        "total_length": 272,
        "mean_pred_length": 15.11111111111111,
        "std_pred_length": 3.710179523792,
        "median_pred_length": 15.5,
        "min_pred_length": 7,
        "max_pred_length": 22,
        "distinct-1": 0.5514705882352942,
        "vocab_size-1": 150,
        "unique-1": 114,
        "entropy-1": 6.514725852729589,
        "distinct-2": 0.8937007874015748,
        "vocab_size-2": 227,
        "unique-2": 210,
        "entropy-2": 7.715912196555029,
        "cond_entropy-2": 1.0116059129254333,
        "distinct-3": 0.9788135593220338,
        "vocab_size-3": 231,
        "unique-3": 227,
        "entropy-3": 7.837071492149261,
        "cond_entropy-3": 0.14196397705145822,
        "total_length-nopunct": 242,
        "mean_pred_length-nopunct": 13.444444444444445,
        "std_pred_length-nopunct": 3.4354721852756236,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6115702479338843,
        "vocab_size-1-nopunct": 148,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.641920715302667,
        "distinct-2-nopunct": 0.8839285714285714,
        "vocab_size-2-nopunct": 198,
        "unique-2-nopunct": 182,
        "entropy-2-nopunct": 7.506978973329249,
        "cond_entropy-2-nopunct": 0.931196831214353,
        "distinct-3-nopunct": 0.9757281553398058,
        "vocab_size-3-nopunct": 201,
        "unique-3-nopunct": 197,
        "entropy-3-nopunct": 7.634292335425142,
        "cond_entropy-3-nopunct": 0.14385106635367673,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.4067796610169492,
            "3": 0.7018633540372671
        },
        "rouge1": {
            "precision": 0.6856,
            "recall": 0.6654,
            "fmeasure": 0.65553
        },
        "rouge2": {
            "precision": 0.41435,
            "recall": 0.41559,
            "fmeasure": 0.39908
        },
        "rougeL": {
            "precision": 0.55386,
            "recall": 0.54779,
            "fmeasure": 0.53408
        },
        "rougeLsum": {
            "precision": 0.55386,
            "recall": 0.54779,
            "fmeasure": 0.53408
        },
        "nist": 5.670776307710602,
        "bleu": 34.0843,
        "meteor": 0.3535512097942245,
        "bleurt": 0.17575,
        "nubia": {
            "semantic_relation": 4.11117,
            "contradiction": 6.14141,
            "irrelevancy": 44.35531,
            "logical_agreement": 49.50328,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.59893,
            "nubia_score": 0.70479
        },
        "bertscore": {
            "precision": 0.91196,
            "recall": 0.90497,
            "f1": 0.90548
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "t5-small/totto_test",
        "N": 79,
        "total_length": 1310,
        "mean_pred_length": 16.582278481012658,
        "std_pred_length": 4.541252810294235,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.41755725190839693,
        "vocab_size-1": 547,
        "unique-1": 415,
        "entropy-1": 7.752135313207511,
        "distinct-2": 0.7400487408610885,
        "vocab_size-2": 911,
        "unique-2": 808,
        "entropy-2": 9.435848128676392,
        "cond_entropy-2": 1.5120902733408497,
        "distinct-3": 0.8411458333333334,
        "vocab_size-3": 969,
        "unique-3": 905,
        "entropy-3": 9.674725504973038,
        "cond_entropy-3": 0.2826311797530687,
        "total_length-nopunct": 1147,
        "mean_pred_length-nopunct": 14.518987341772151,
        "std_pred_length-nopunct": 4.248188771145041,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4699215344376635,
        "vocab_size-1-nopunct": 539,
        "unique-1-nopunct": 413,
        "entropy-1-nopunct": 7.942961208558247,
        "distinct-2-nopunct": 0.7453183520599251,
        "vocab_size-2-nopunct": 796,
        "unique-2-nopunct": 708,
        "entropy-2-nopunct": 9.247568519269414,
        "cond_entropy-2-nopunct": 1.428119633172658,
        "distinct-3-nopunct": 0.8442871587462083,
        "vocab_size-3-nopunct": 835,
        "unique-3-nopunct": 781,
        "entropy-3-nopunct": 9.468171820977421,
        "cond_entropy-3-nopunct": 0.27485214203183883,
        "msttr-100": 0.70308,
        "msttr-100_nopunct": 0.74364,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20647773279352227,
            "2": 0.4166666666666667,
            "3": 0.7087599544937428
        },
        "rouge1": {
            "precision": 0.72294,
            "recall": 0.68078,
            "fmeasure": 0.68746
        },
        "rouge2": {
            "precision": 0.49793,
            "recall": 0.476,
            "fmeasure": 0.47784
        },
        "rougeL": {
            "precision": 0.61805,
            "recall": 0.59013,
            "fmeasure": 0.5924
        },
        "rougeLsum": {
            "precision": 0.61805,
            "recall": 0.59013,
            "fmeasure": 0.5924
        },
        "nist": 6.43738754670931,
        "bleu": 40.58415,
        "meteor": 0.34308726903540526,
        "bleurt": 0.16165,
        "nubia": {
            "semantic_relation": 3.98004,
            "contradiction": 13.15288,
            "irrelevancy": 32.81694,
            "logical_agreement": 54.03018,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.44411,
            "nubia_score": 0.66681
        },
        "bertscore": {
            "precision": 0.91442,
            "recall": 0.91034,
            "f1": 0.9104
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.242640687119285,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 35,
        "unique-1": 28,
        "entropy-1": 4.997082818407664,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 39,
        "unique-2": 36,
        "entropy-2": 5.249460279921618,
        "cond_entropy-2": 0.17450658845686987,
        "distinct-3": 0.9487179487179487,
        "vocab_size-3": 37,
        "unique-3": 35,
        "entropy-3": 5.182838116298145,
        "cond_entropy-3": -0.05563315263446054,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 3.858612300930075,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.825,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.93418371977919,
        "distinct-2-nopunct": 0.918918918918919,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.047291203466791,
        "cond_entropy-2-nopunct": 0.14454621680447755,
        "distinct-3-nopunct": 0.9411764705882353,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.969815782426809,
        "cond_entropy-3-nopunct": -0.06316699496684557,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6875,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.64583,
            "recall": 0.68802,
            "fmeasure": 0.65245
        },
        "rouge2": {
            "precision": 0.40218,
            "recall": 0.40926,
            "fmeasure": 0.39812
        },
        "rougeL": {
            "precision": 0.56618,
            "recall": 0.57628,
            "fmeasure": 0.56019
        },
        "rougeLsum": {
            "precision": 0.56618,
            "recall": 0.57628,
            "fmeasure": 0.56019
        },
        "nist": 3.850072290450324,
        "bleu": 39.85627,
        "meteor": 0.3881576930030903,
        "bleurt": 0.11911,
        "nubia": {
            "semantic_relation": 3.10247,
            "contradiction": 18.21651,
            "irrelevancy": 48.57262,
            "logical_agreement": 33.21087,
            "grammar_ref": 4.86076,
            "grammar_hyp": 4.1204,
            "nubia_score": 0.51138
        },
        "bertscore": {
            "precision": 0.8922,
            "recall": 0.89117,
            "f1": 0.89089
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 84,
        "mean_pred_length": 12.0,
        "std_pred_length": 3.4226138716316967,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 18,
        "distinct-1": 0.7738095238095238,
        "vocab_size-1": 65,
        "unique-1": 54,
        "entropy-1": 5.821887101815741,
        "distinct-2": 1.0,
        "vocab_size-2": 77,
        "unique-2": 77,
        "entropy-2": 6.266786540694905,
        "cond_entropy-2": 0.24154265696147112,
        "distinct-3": 1.0,
        "vocab_size-3": 70,
        "unique-3": 70,
        "entropy-3": 6.129283016944973,
        "cond_entropy-3": -0.13750352374993463,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 10.571428571428571,
        "std_pred_length-nopunct": 3.1558174334820746,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8378378378378378,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.854525493919623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.066089190457767,
        "cond_entropy-2-nopunct": 0.24864571298539592,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.906890595608517,
        "cond_entropy-3-nopunct": -0.15919859484925405,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.25,
            "3": 0.569620253164557
        },
        "rouge1": {
            "precision": 0.73951,
            "recall": 0.63895,
            "fmeasure": 0.66436
        },
        "rouge2": {
            "precision": 0.57094,
            "recall": 0.51299,
            "fmeasure": 0.52644
        },
        "rougeL": {
            "precision": 0.68925,
            "recall": 0.60491,
            "fmeasure": 0.62665
        },
        "rougeLsum": {
            "precision": 0.68925,
            "recall": 0.60491,
            "fmeasure": 0.62665
        },
        "nist": 3.6126706100298005,
        "bleu": 43.4767,
        "meteor": 0.3335695346379498,
        "bleurt": 0.03591,
        "nubia": {
            "semantic_relation": 3.8031,
            "contradiction": 4.4768,
            "irrelevancy": 29.95094,
            "logical_agreement": 65.57226,
            "grammar_ref": 4.69419,
            "grammar_hyp": 5.39245,
            "nubia_score": 0.59474
        },
        "bertscore": {
            "precision": 0.92273,
            "recall": 0.89653,
            "f1": 0.90833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 5.734883511361751,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.825,
        "vocab_size-1": 33,
        "unique-1": 27,
        "entropy-1": 4.953055907333277,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.23225195998924852,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 5.715476066494082,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8611111111111112,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.871178126382214,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.20037479979988243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444,
            "3": 0.5909090909090909
        },
        "rouge1": {
            "precision": 0.53148,
            "recall": 0.53544,
            "fmeasure": 0.53023
        },
        "rouge2": {
            "precision": 0.26203,
            "recall": 0.25139,
            "fmeasure": 0.25508
        },
        "rougeL": {
            "precision": 0.45741,
            "recall": 0.46682,
            "fmeasure": 0.45914
        },
        "rougeLsum": {
            "precision": 0.45741,
            "recall": 0.46682,
            "fmeasure": 0.45914
        },
        "nist": 2.539930519867598,
        "bleu": 17.13505,
        "meteor": 0.22428326246538605,
        "bleurt": -0.20999,
        "nubia": {
            "semantic_relation": 3.77003,
            "contradiction": 0.59186,
            "irrelevancy": 64.37959,
            "logical_agreement": 35.02855,
            "grammar_ref": 5.944,
            "grammar_hyp": 6.69706,
            "nubia_score": 0.55786
        },
        "bertscore": {
            "precision": 0.8408,
            "recall": 0.85333,
            "f1": 0.84701
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 139,
        "mean_pred_length": 17.375,
        "std_pred_length": 4.897384506039933,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.6546762589928058,
        "vocab_size-1": 91,
        "unique-1": 74,
        "entropy-1": 6.111430794399411,
        "distinct-2": 0.9465648854961832,
        "vocab_size-2": 124,
        "unique-2": 118,
        "entropy-2": 6.920790272513303,
        "cond_entropy-2": 0.6596238237436299,
        "distinct-3": 0.983739837398374,
        "vocab_size-3": 121,
        "unique-3": 119,
        "entropy-3": 6.9099941801359765,
        "cond_entropy-3": -0.019730549026149923,
        "total_length-nopunct": 113,
        "mean_pred_length-nopunct": 14.125,
        "std_pred_length-nopunct": 2.9341736485763756,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7522123893805309,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.161944091551451,
        "distinct-2-nopunct": 0.9619047619047619,
        "vocab_size-2-nopunct": 101,
        "unique-2-nopunct": 97,
        "entropy-2-nopunct": 6.638055041475637,
        "cond_entropy-2-nopunct": 0.5111672972212457,
        "distinct-3-nopunct": 0.9896907216494846,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 95,
        "entropy-3-nopunct": 6.57929428548611,
        "cond_entropy-3-nopunct": -0.05247700537590192,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08,
            "2": 0.2727272727272727,
            "3": 0.7127659574468085
        },
        "rouge1": {
            "precision": 0.70039,
            "recall": 0.63371,
            "fmeasure": 0.65425
        },
        "rouge2": {
            "precision": 0.44837,
            "recall": 0.40933,
            "fmeasure": 0.42175
        },
        "rougeL": {
            "precision": 0.59293,
            "recall": 0.53153,
            "fmeasure": 0.55271
        },
        "rougeLsum": {
            "precision": 0.59293,
            "recall": 0.53153,
            "fmeasure": 0.55271
        },
        "nist": 4.693373188500901,
        "bleu": 41.83301,
        "meteor": 0.36837355923362225,
        "bleurt": 0.03978,
        "nubia": {
            "semantic_relation": 3.61488,
            "contradiction": 33.84309,
            "irrelevancy": 16.82803,
            "logical_agreement": 49.32887,
            "grammar_ref": 5.01189,
            "grammar_hyp": 4.82226,
            "nubia_score": 0.54674
        },
        "bertscore": {
            "precision": 0.90861,
            "recall": 0.90259,
            "f1": 0.90067
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "t5-small/totto_test",
        "N": 110,
        "total_length": 1666,
        "mean_pred_length": 15.145454545454545,
        "std_pred_length": 4.684280023530081,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.4765906362545018,
        "vocab_size-1": 794,
        "unique-1": 635,
        "entropy-1": 8.230621400950069,
        "distinct-2": 0.8547557840616966,
        "vocab_size-2": 1330,
        "unique-2": 1230,
        "entropy-2": 10.176473801508124,
        "cond_entropy-2": 1.7001608607998258,
        "distinct-3": 0.9508990318118948,
        "vocab_size-3": 1375,
        "unique-3": 1329,
        "entropy-3": 10.383886423728836,
        "cond_entropy-3": 0.20570274276097947,
        "total_length-nopunct": 1468,
        "mean_pred_length-nopunct": 13.345454545454546,
        "std_pred_length-nopunct": 4.419864999247177,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.534741144414169,
        "vocab_size-1-nopunct": 785,
        "unique-1-nopunct": 633,
        "entropy-1-nopunct": 8.48151324957239,
        "distinct-2-nopunct": 0.8637702503681886,
        "vocab_size-2-nopunct": 1173,
        "unique-2-nopunct": 1096,
        "entropy-2-nopunct": 9.99254667017536,
        "cond_entropy-2-nopunct": 1.6129540368747581,
        "distinct-3-nopunct": 0.9527243589743589,
        "vocab_size-3-nopunct": 1189,
        "unique-3-nopunct": 1153,
        "entropy-3-nopunct": 10.173796279346778,
        "cond_entropy-3-nopunct": 0.20918585343842577,
        "msttr-100": 0.73125,
        "msttr-100_nopunct": 0.78071,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24867724867724866,
            "2": 0.5384615384615384,
            "3": 0.7216981132075472
        },
        "rouge1": {
            "precision": 0.73966,
            "recall": 0.68664,
            "fmeasure": 0.6978
        },
        "rouge2": {
            "precision": 0.50604,
            "recall": 0.465,
            "fmeasure": 0.47389
        },
        "rougeL": {
            "precision": 0.63305,
            "recall": 0.58529,
            "fmeasure": 0.59557
        },
        "rougeLsum": {
            "precision": 0.63305,
            "recall": 0.58529,
            "fmeasure": 0.59557
        },
        "nist": 7.282089303338362,
        "bleu": 42.97641,
        "meteor": 0.3704983367560244,
        "bleurt": 0.14512,
        "nubia": {
            "semantic_relation": 4.05853,
            "contradiction": 9.15354,
            "irrelevancy": 34.3429,
            "logical_agreement": 56.50356,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.98283,
            "nubia_score": 0.65994
        },
        "bertscore": {
            "precision": 0.91909,
            "recall": 0.91263,
            "f1": 0.91452
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "t5-small/totto_test",
        "N": 14,
        "total_length": 216,
        "mean_pred_length": 15.428571428571429,
        "std_pred_length": 6.114552731152199,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5972222222222222,
        "vocab_size-1": 129,
        "unique-1": 104,
        "entropy-1": 6.4399149440399945,
        "distinct-2": 0.9306930693069307,
        "vocab_size-2": 188,
        "unique-2": 177,
        "entropy-2": 7.505959564424225,
        "cond_entropy-2": 0.9111878727464995,
        "distinct-3": 0.9893617021276596,
        "vocab_size-3": 186,
        "unique-3": 184,
        "entropy-3": 7.5333122559329775,
        "cond_entropy-3": 0.038690600320329144,
        "total_length-nopunct": 193,
        "mean_pred_length-nopunct": 13.785714285714286,
        "std_pred_length-nopunct": 6.014014245654792,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6580310880829016,
        "vocab_size-1-nopunct": 127,
        "unique-1-nopunct": 104,
        "entropy-1-nopunct": 6.5421509477864,
        "distinct-2-nopunct": 0.9329608938547486,
        "vocab_size-2-nopunct": 167,
        "unique-2-nopunct": 158,
        "entropy-2-nopunct": 7.334347132000765,
        "cond_entropy-2-nopunct": 0.8566339509814068,
        "distinct-3-nopunct": 0.9939393939393939,
        "vocab_size-3-nopunct": 164,
        "unique-3-nopunct": 163,
        "entropy-3-nopunct": 7.354201002124596,
        "cond_entropy-3-nopunct": 0.0325360582067927,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.5909090909090909,
            "3": 0.7785714285714286
        },
        "rouge1": {
            "precision": 0.8274,
            "recall": 0.78774,
            "fmeasure": 0.79095
        },
        "rouge2": {
            "precision": 0.61698,
            "recall": 0.60015,
            "fmeasure": 0.5988
        },
        "rougeL": {
            "precision": 0.71609,
            "recall": 0.6923,
            "fmeasure": 0.69545
        },
        "rougeLsum": {
            "precision": 0.71609,
            "recall": 0.6923,
            "fmeasure": 0.69545
        },
        "nist": 6.111126888450197,
        "bleu": 54.61534,
        "meteor": 0.3953779460131371,
        "bleurt": 0.37356,
        "nubia": {
            "semantic_relation": 4.22392,
            "contradiction": 14.16219,
            "irrelevancy": 29.38303,
            "logical_agreement": 56.45478,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.74519,
            "nubia_score": 0.72916
        },
        "bertscore": {
            "precision": 0.94853,
            "recall": 0.93507,
            "f1": 0.93939
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 129,
        "mean_pred_length": 16.125,
        "std_pred_length": 3.6206870894900596,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.7054263565891473,
        "vocab_size-1": 91,
        "unique-1": 74,
        "entropy-1": 6.193993317418887,
        "distinct-2": 0.9669421487603306,
        "vocab_size-2": 117,
        "unique-2": 114,
        "entropy-2": 6.846508795107962,
        "cond_entropy-2": 0.5231633825976415,
        "distinct-3": 0.9911504424778761,
        "vocab_size-3": 112,
        "unique-3": 111,
        "entropy-3": 6.802479847370959,
        "cond_entropy-3": -0.03890650935353531,
        "total_length-nopunct": 111,
        "mean_pred_length-nopunct": 13.875,
        "std_pred_length-nopunct": 3.6550478793033614,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7837837837837838,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.24230584369116,
        "distinct-2-nopunct": 0.9611650485436893,
        "vocab_size-2-nopunct": 99,
        "unique-2-nopunct": 96,
        "entropy-2-nopunct": 6.60150161939524,
        "cond_entropy-2-nopunct": 0.40207810756108076,
        "distinct-3-nopunct": 0.9894736842105263,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.548802976752,
        "cond_entropy-3-nopunct": -0.04554083988212886,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19444444444444445,
            "2": 0.43333333333333335,
            "3": 0.7671232876712328
        },
        "rouge1": {
            "precision": 0.69069,
            "recall": 0.72108,
            "fmeasure": 0.68969
        },
        "rouge2": {
            "precision": 0.45336,
            "recall": 0.46943,
            "fmeasure": 0.44936
        },
        "rougeL": {
            "precision": 0.5605,
            "recall": 0.5795,
            "fmeasure": 0.55648
        },
        "rougeLsum": {
            "precision": 0.5605,
            "recall": 0.5795,
            "fmeasure": 0.55648
        },
        "nist": 4.932223925447654,
        "bleu": 36.72418,
        "meteor": 0.3727650664757513,
        "bleurt": 0.16707,
        "nubia": {
            "semantic_relation": 3.98801,
            "contradiction": 30.44777,
            "irrelevancy": 17.87303,
            "logical_agreement": 51.6792,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.59879,
            "nubia_score": 0.65624
        },
        "bertscore": {
            "precision": 0.89323,
            "recall": 0.91488,
            "f1": 0.90113
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 91,
        "mean_pred_length": 18.2,
        "std_pred_length": 7.277362159464101,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.6483516483516484,
        "vocab_size-1": 59,
        "unique-1": 43,
        "entropy-1": 5.576706113240452,
        "distinct-2": 0.9302325581395349,
        "vocab_size-2": 80,
        "unique-2": 74,
        "entropy-2": 6.286729870981169,
        "cond_entropy-2": 0.6507278871898802,
        "distinct-3": 0.9382716049382716,
        "vocab_size-3": 76,
        "unique-3": 71,
        "entropy-3": 6.216393212761157,
        "cond_entropy-3": -0.061723393792781994,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 16.6,
        "std_pred_length-nopunct": 6.590902821313633,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6867469879518072,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.551370419580661,
        "distinct-2-nopunct": 0.9358974358974359,
        "vocab_size-2-nopunct": 73,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.157197090657127,
        "cond_entropy-2-nopunct": 0.5945234025999423,
        "distinct-3-nopunct": 0.9452054794520548,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.080235517784137,
        "cond_entropy-3-nopunct": -0.06818039970825861,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5,
            "3": 0.746031746031746
        },
        "rouge1": {
            "precision": 0.79935,
            "recall": 0.72565,
            "fmeasure": 0.75105
        },
        "rouge2": {
            "precision": 0.58239,
            "recall": 0.51217,
            "fmeasure": 0.54018
        },
        "rougeL": {
            "precision": 0.71699,
            "recall": 0.65093,
            "fmeasure": 0.67439
        },
        "rougeLsum": {
            "precision": 0.71699,
            "recall": 0.65093,
            "fmeasure": 0.67439
        },
        "nist": 4.560686778602876,
        "bleu": 45.80236,
        "meteor": 0.3772880536054754,
        "bleurt": 0.03827,
        "nubia": {
            "semantic_relation": 3.97757,
            "contradiction": 3.66987,
            "irrelevancy": 49.53078,
            "logical_agreement": 46.79935,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.43779,
            "nubia_score": 0.65738
        },
        "bertscore": {
            "precision": 0.95031,
            "recall": 0.92854,
            "f1": 0.93732
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "t5-small/totto_test",
        "N": 23,
        "total_length": 358,
        "mean_pred_length": 15.565217391304348,
        "std_pred_length": 5.0633043597731255,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.5418994413407822,
        "vocab_size-1": 194,
        "unique-1": 153,
        "entropy-1": 6.819298020616318,
        "distinct-2": 0.8716417910447761,
        "vocab_size-2": 292,
        "unique-2": 268,
        "entropy-2": 8.055604609415937,
        "cond_entropy-2": 1.046586043351108,
        "distinct-3": 0.9551282051282052,
        "vocab_size-3": 298,
        "unique-3": 286,
        "entropy-3": 8.190819606668843,
        "cond_entropy-3": 0.12421716375722057,
        "total_length-nopunct": 317,
        "mean_pred_length-nopunct": 13.782608695652174,
        "std_pred_length-nopunct": 4.643429408634082,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5993690851735016,
        "vocab_size-1-nopunct": 190,
        "unique-1-nopunct": 152,
        "entropy-1-nopunct": 6.947922396207191,
        "distinct-2-nopunct": 0.8809523809523809,
        "vocab_size-2-nopunct": 259,
        "unique-2-nopunct": 240,
        "entropy-2-nopunct": 7.883027501537676,
        "cond_entropy-2-nopunct": 0.9753498168933139,
        "distinct-3-nopunct": 0.9630996309963099,
        "vocab_size-3-nopunct": 261,
        "unique-3-nopunct": 252,
        "entropy-3-nopunct": 8.005562740607845,
        "cond_entropy-3-nopunct": 0.10344001403280526,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.73667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25333333333333335,
            "2": 0.45901639344262296,
            "3": 0.711864406779661
        },
        "rouge1": {
            "precision": 0.72704,
            "recall": 0.70504,
            "fmeasure": 0.70244
        },
        "rouge2": {
            "precision": 0.48725,
            "recall": 0.47068,
            "fmeasure": 0.4687
        },
        "rougeL": {
            "precision": 0.63158,
            "recall": 0.60925,
            "fmeasure": 0.60777
        },
        "rougeLsum": {
            "precision": 0.63158,
            "recall": 0.60925,
            "fmeasure": 0.60777
        },
        "nist": 5.791677569256496,
        "bleu": 39.35566,
        "meteor": 0.3653920903781788,
        "bleurt": 0.16814,
        "nubia": {
            "semantic_relation": 4.18434,
            "contradiction": 8.1306,
            "irrelevancy": 29.79791,
            "logical_agreement": 62.07149,
            "grammar_ref": 4.22562,
            "grammar_hyp": 4.21593,
            "nubia_score": 0.7503
        },
        "bertscore": {
            "precision": 0.91326,
            "recall": 0.90792,
            "f1": 0.90904
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 5.0,
        "median_pred_length": 20.0,
        "min_pred_length": 15,
        "max_pred_length": 25,
        "distinct-1": 0.8,
        "vocab_size-1": 32,
        "unique-1": 26,
        "entropy-1": 4.884183719779189,
        "distinct-2": 0.9736842105263158,
        "vocab_size-2": 37,
        "unique-2": 36,
        "entropy-2": 5.19529593449622,
        "cond_entropy-2": 0.2924418528616385,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.050224734223495375,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8108108108108109,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.7902702574039004,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.072140159802107,
        "cond_entropy-2-nopunct": 0.2605385799904675,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.05458586728348292,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6551724137931034
        },
        "rouge1": {
            "precision": 0.56266,
            "recall": 0.70773,
            "fmeasure": 0.60836
        },
        "rouge2": {
            "precision": 0.30114,
            "recall": 0.37208,
            "fmeasure": 0.32185
        },
        "rougeL": {
            "precision": 0.4821,
            "recall": 0.61751,
            "fmeasure": 0.52553
        },
        "rougeLsum": {
            "precision": 0.4821,
            "recall": 0.61751,
            "fmeasure": 0.52553
        },
        "nist": 2.729543410911996,
        "bleu": 18.99099,
        "meteor": 0.3303962208485018,
        "bleurt": 0.04016,
        "nubia": {
            "semantic_relation": 3.69548,
            "contradiction": 50.32134,
            "irrelevancy": 1.78271,
            "logical_agreement": 47.89595,
            "grammar_ref": 4.49155,
            "grammar_hyp": 3.90976,
            "nubia_score": 0.71089
        },
        "bertscore": {
            "precision": 0.88197,
            "recall": 0.9144,
            "f1": 0.89762
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "t5-small/totto_test",
        "N": 18,
        "total_length": 265,
        "mean_pred_length": 14.722222222222221,
        "std_pred_length": 5.278947238855233,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.5886792452830188,
        "vocab_size-1": 156,
        "unique-1": 130,
        "entropy-1": 6.5775979235180895,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 228,
        "unique-2": 217,
        "entropy-2": 7.7545441425930965,
        "cond_entropy-2": 1.0549851432170207,
        "distinct-3": 0.9781659388646288,
        "vocab_size-3": 224,
        "unique-3": 220,
        "entropy-3": 7.792239213851692,
        "cond_entropy-3": 0.05293007388678061,
        "total_length-nopunct": 232,
        "mean_pred_length-nopunct": 12.88888888888889,
        "std_pred_length-nopunct": 4.8977192978964865,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6594827586206896,
        "vocab_size-1-nopunct": 153,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.729598249708033,
        "distinct-2-nopunct": 0.9392523364485982,
        "vocab_size-2-nopunct": 201,
        "unique-2-nopunct": 193,
        "entropy-2-nopunct": 7.590697535436207,
        "cond_entropy-2-nopunct": 0.9089220605903443,
        "distinct-3-nopunct": 0.9897959183673469,
        "vocab_size-3-nopunct": 194,
        "unique-3-nopunct": 192,
        "entropy-3-nopunct": 7.594301680849886,
        "cond_entropy-3-nopunct": 0.017450319481869512,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13636363636363635,
            "2": 0.25,
            "3": 0.7052631578947368
        },
        "rouge1": {
            "precision": 0.68784,
            "recall": 0.66775,
            "fmeasure": 0.66792
        },
        "rouge2": {
            "precision": 0.45078,
            "recall": 0.43838,
            "fmeasure": 0.43924
        },
        "rougeL": {
            "precision": 0.59963,
            "recall": 0.59683,
            "fmeasure": 0.58924
        },
        "rougeLsum": {
            "precision": 0.59963,
            "recall": 0.59683,
            "fmeasure": 0.58924
        },
        "nist": 5.303721286207982,
        "bleu": 37.8888,
        "meteor": 0.35912398113787125,
        "bleurt": 0.20095,
        "nubia": {
            "semantic_relation": 3.98272,
            "contradiction": 14.9571,
            "irrelevancy": 29.99522,
            "logical_agreement": 55.04768,
            "grammar_ref": 5.08526,
            "grammar_hyp": 4.97609,
            "nubia_score": 0.67025
        },
        "bertscore": {
            "precision": 0.90482,
            "recall": 0.89968,
            "f1": 0.90099
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "nist": 2.0052535157554314,
        "bleu": 16.51582,
        "meteor": 0.31253823342571707,
        "bleurt": 0.11529,
        "nubia": {
            "semantic_relation": 3.3707,
            "contradiction": 81.05109,
            "irrelevancy": 11.0637,
            "logical_agreement": 7.88521,
            "grammar_ref": 6.80479,
            "grammar_hyp": 6.6162,
            "nubia_score": 0.3874
        },
        "bertscore": {
            "precision": 0.87779,
            "recall": 0.87807,
            "f1": 0.87793
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.2516291673878226,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.2381054815525046,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0957952550009344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.262496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.93939,
            "fmeasure": 0.83413
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.80476,
            "fmeasure": 0.70392
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "nist": 2.306664886548115,
        "bleu": 27.09199,
        "meteor": 0.4912092865802179,
        "bleurt": 0.67831,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20045,
            "irrelevancy": 22.76085,
            "logical_agreement": 77.0387,
            "grammar_ref": 3.38649,
            "grammar_hyp": 3.17028,
            "nubia_score": 0.92133
        },
        "bertscore": {
            "precision": 0.94572,
            "recall": 0.94055,
            "f1": 0.94053
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.334962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.056287299734322734,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819113,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.60165,
            "recall": 0.90278,
            "fmeasure": 0.70222
        },
        "rouge2": {
            "precision": 0.44872,
            "recall": 0.68788,
            "fmeasure": 0.52503
        },
        "rougeL": {
            "precision": 0.52473,
            "recall": 0.81439,
            "fmeasure": 0.62
        },
        "rougeLsum": {
            "precision": 0.52473,
            "recall": 0.81439,
            "fmeasure": 0.62
        },
        "nist": 2.701650306213677,
        "bleu": 37.4489,
        "meteor": 0.46076005595009917,
        "bleurt": 0.15578,
        "nubia": {
            "semantic_relation": 3.99773,
            "contradiction": 0.66028,
            "irrelevancy": 63.69181,
            "logical_agreement": 35.64791,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.49591,
            "nubia_score": 0.70819
        },
        "bertscore": {
            "precision": 0.8745,
            "recall": 0.93747,
            "f1": 0.90429
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.851063829787234,
        "vocab_size-1": 40,
        "unique-1": 36,
        "entropy-1": 5.198101883546502,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.1775700396869323,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.10187961401921372,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8809523809523809,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.106603137064477,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.1751360781347702,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.1154772174199358,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.5238095238095238,
            "3": 0.7727272727272727
        },
        "rouge1": {
            "precision": 0.73287,
            "recall": 0.61598,
            "fmeasure": 0.65762
        },
        "rouge2": {
            "precision": 0.4531,
            "recall": 0.37558,
            "fmeasure": 0.40278
        },
        "rougeL": {
            "precision": 0.59306,
            "recall": 0.51157,
            "fmeasure": 0.54054
        },
        "rougeLsum": {
            "precision": 0.59306,
            "recall": 0.51157,
            "fmeasure": 0.54054
        },
        "nist": 4.128537708296736,
        "bleu": 35.96109,
        "meteor": 0.33617656422828934,
        "bleurt": 0.06925,
        "nubia": {
            "semantic_relation": 3.96318,
            "contradiction": 0.68088,
            "irrelevancy": 50.00244,
            "logical_agreement": 49.31668,
            "grammar_ref": 4.68806,
            "grammar_hyp": 4.96469,
            "nubia_score": 0.60957
        },
        "bertscore": {
            "precision": 0.88909,
            "recall": 0.8812,
            "f1": 0.88504
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 125,
        "mean_pred_length": 17.857142857142858,
        "std_pred_length": 2.356060357495806,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.632,
        "vocab_size-1": 79,
        "unique-1": 62,
        "entropy-1": 5.881806589272423,
        "distinct-2": 0.9322033898305084,
        "vocab_size-2": 110,
        "unique-2": 102,
        "entropy-2": 6.747049829022849,
        "cond_entropy-2": 0.7895763990528328,
        "distinct-3": 0.9459459459459459,
        "vocab_size-3": 105,
        "unique-3": 99,
        "entropy-3": 6.686307758242012,
        "cond_entropy-3": -0.0612001559847083,
        "total_length-nopunct": 111,
        "mean_pred_length-nopunct": 15.857142857142858,
        "std_pred_length-nopunct": 2.415933503612538,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6576576576576577,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.782902974684934,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 96,
        "unique-2-nopunct": 88,
        "entropy-2-nopunct": 6.546593564294945,
        "cond_entropy-2-nopunct": 0.7749761631297036,
        "distinct-3-nopunct": 0.9381443298969072,
        "vocab_size-3-nopunct": 91,
        "unique-3-nopunct": 85,
        "entropy-3-nopunct": 6.476201501980956,
        "cond_entropy-3-nopunct": -0.06959904090241804,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19230769230769232,
            "2": 0.3333333333333333,
            "3": 0.7222222222222222
        },
        "rouge1": {
            "precision": 0.71511,
            "recall": 0.72944,
            "fmeasure": 0.71826
        },
        "rouge2": {
            "precision": 0.52311,
            "recall": 0.53898,
            "fmeasure": 0.52761
        },
        "rougeL": {
            "precision": 0.62988,
            "recall": 0.65048,
            "fmeasure": 0.63648
        },
        "rougeLsum": {
            "precision": 0.62988,
            "recall": 0.65048,
            "fmeasure": 0.63648
        },
        "nist": 5.1440530492187175,
        "bleu": 40.96787,
        "meteor": 0.3720371564072152,
        "bleurt": 0.0557,
        "nubia": {
            "semantic_relation": 4.09561,
            "contradiction": 1.51187,
            "irrelevancy": 65.22338,
            "logical_agreement": 33.26474,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.69467,
            "nubia_score": 0.689
        },
        "bertscore": {
            "precision": 0.92194,
            "recall": 0.92358,
            "f1": 0.92164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 5.5,
        "median_pred_length": 15.5,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.9032258064516129,
        "vocab_size-1": 28,
        "unique-1": 25,
        "entropy-1": 4.760647923290102,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.04171571922345565,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9629629629629629,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.6808134280893965,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.031031312388743952,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.16666666666666666,
            "3": 0.5185185185185185
        },
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.42926,
            "fmeasure": 0.51676
        },
        "rouge2": {
            "precision": 0.52574,
            "recall": 0.2487,
            "fmeasure": 0.32084
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.31966,
            "fmeasure": 0.3783
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.31966,
            "fmeasure": 0.3783
        },
        "nist": 2.4053175895582855,
        "bleu": 16.76404,
        "meteor": 0.24058187804867986,
        "bleurt": -0.22809,
        "nubia": {
            "semantic_relation": 3.43919,
            "contradiction": 0.2309,
            "irrelevancy": 51.7778,
            "logical_agreement": 47.9913,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.82742,
            "nubia_score": 0.52011
        },
        "bertscore": {
            "precision": 0.89119,
            "recall": 0.87864,
            "f1": 0.88278
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7720,
        "mean_pred_length": 21.5041782729805,
        "std_pred_length": 9.340322585225518,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37176165803108807,
        "vocab_size-1": 2870,
        "unique-1": 2100,
        "entropy-1": 9.235158439326643,
        "distinct-2": 0.847167504415161,
        "vocab_size-2": 6236,
        "unique-2": 5774,
        "entropy-2": 12.327123665919075,
        "cond_entropy-2": 2.8572508020756424,
        "distinct-3": 0.9802913453299057,
        "vocab_size-3": 6864,
        "unique-3": 6757,
        "entropy-3": 12.729865603577442,
        "cond_entropy-3": 0.41443290245541875,
        "total_length-nopunct": 6952,
        "mean_pred_length-nopunct": 19.364902506963787,
        "std_pred_length-nopunct": 8.474966868997573,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.411536248561565,
        "vocab_size-1-nopunct": 2861,
        "unique-1-nopunct": 2098,
        "entropy-1-nopunct": 9.594839877948008,
        "distinct-2-nopunct": 0.8651600182011224,
        "vocab_size-2-nopunct": 5704,
        "unique-2-nopunct": 5328,
        "entropy-2-nopunct": 12.234578669854612,
        "cond_entropy-2-nopunct": 2.760495991752104,
        "distinct-3-nopunct": 0.9847609881296118,
        "vocab_size-3-nopunct": 6139,
        "unique-3-nopunct": 6062,
        "entropy-3-nopunct": 12.572833099233705,
        "cond_entropy-3-nopunct": 0.35825618548419247,
        "msttr-100": 0.72571,
        "msttr-100_nopunct": 0.76884,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.012521222410865875,
            "2": 0.19029374201787994,
            "3": 0.6061269146608315,
            "4": 0.8573692551505546,
            "5": 0.9293873312564901,
            "6": 0.9468599033816425,
            "7": 0.9618174875906834
        },
        "rouge1": {
            "precision": 0.94971,
            "recall": 0.93391,
            "fmeasure": 0.93572
        },
        "rouge2": {
            "precision": 0.90141,
            "recall": 0.88358,
            "fmeasure": 0.88555
        },
        "rougeL": {
            "precision": 0.94542,
            "recall": 0.93022,
            "fmeasure": 0.93163
        },
        "rougeLsum": {
            "precision": 0.94542,
            "recall": 0.93022,
            "fmeasure": 0.93163
        },
        "nist": 13.407293846084126,
        "bleu": 92.10852,
        "meteor": 0.6216178784743646,
        "bleurt": 0.4048,
        "nubia": {
            "semantic_relation": 4.53451,
            "contradiction": 1.84618,
            "irrelevancy": 14.26933,
            "logical_agreement": 83.88449,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.72492,
            "nubia_score": 0.80242
        },
        "bertscore": {
            "precision": 0.97898,
            "recall": 0.98008,
            "f1": 0.97819
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 5.0,
        "median_pred_length": 20.0,
        "min_pred_length": 15,
        "max_pred_length": 25,
        "distinct-1": 0.8,
        "vocab_size-1": 32,
        "unique-1": 25,
        "entropy-1": 4.903055907333276,
        "distinct-2": 0.9736842105263158,
        "vocab_size-2": 37,
        "unique-2": 36,
        "entropy-2": 5.19529593449622,
        "cond_entropy-2": 0.2879701422973671,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.022446956445717595,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8484848484848485,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.718488437474714,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.2244759814207919,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.6470588235294118
        },
        "rouge1": {
            "precision": 0.77667,
            "recall": 0.61828,
            "fmeasure": 0.68677
        },
        "rouge2": {
            "precision": 0.31944,
            "recall": 0.2642,
            "fmeasure": 0.28903
        },
        "rougeL": {
            "precision": 0.53667,
            "recall": 0.44124,
            "fmeasure": 0.48388
        },
        "rougeLsum": {
            "precision": 0.53667,
            "recall": 0.44124,
            "fmeasure": 0.48388
        },
        "nist": 3.3883691806955683,
        "bleu": 27.99939,
        "meteor": 0.32069772913655314,
        "bleurt": 0.06832,
        "nubia": {
            "semantic_relation": 3.13757,
            "contradiction": 0.19101,
            "irrelevancy": 47.44856,
            "logical_agreement": 52.36043,
            "grammar_ref": 4.82994,
            "grammar_hyp": 4.30604,
            "nubia_score": 0.4696
        },
        "bertscore": {
            "precision": 0.8772,
            "recall": 0.87707,
            "f1": 0.87672
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 126,
        "mean_pred_length": 15.75,
        "std_pred_length": 4.520785330006281,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 90,
        "unique-1": 75,
        "entropy-1": 6.211379181722003,
        "distinct-2": 0.9491525423728814,
        "vocab_size-2": 112,
        "unique-2": 107,
        "entropy-2": 6.774550782394345,
        "cond_entropy-2": 0.463980946731757,
        "distinct-3": 1.0,
        "vocab_size-3": 110,
        "unique-3": 110,
        "entropy-3": 6.781359713524669,
        "cond_entropy-3": 0.01467018690975892,
        "total_length-nopunct": 110,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 3.766629793329841,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.186959004567809,
        "distinct-2-nopunct": 0.9509803921568627,
        "vocab_size-2-nopunct": 97,
        "unique-2-nopunct": 93,
        "entropy-2-nopunct": 6.566985268420877,
        "cond_entropy-2-nopunct": 0.40388192637039844,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 94,
        "entropy-3-nopunct": 6.554588851677623,
        "cond_entropy-3-nopunct": -0.0034227934623318,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.3125,
            "3": 0.8125
        },
        "rouge1": {
            "precision": 0.82327,
            "recall": 0.76075,
            "fmeasure": 0.78298
        },
        "rouge2": {
            "precision": 0.66152,
            "recall": 0.60246,
            "fmeasure": 0.62491
        },
        "rougeL": {
            "precision": 0.73218,
            "recall": 0.67093,
            "fmeasure": 0.69483
        },
        "rougeLsum": {
            "precision": 0.73218,
            "recall": 0.67093,
            "fmeasure": 0.69483
        },
        "nist": 5.167659781993035,
        "bleu": 52.71754,
        "meteor": 0.4117749814982283,
        "bleurt": 0.33907,
        "nubia": {
            "semantic_relation": 4.13874,
            "contradiction": 8.19459,
            "irrelevancy": 14.68208,
            "logical_agreement": 77.12333,
            "grammar_ref": 4.87577,
            "grammar_hyp": 5.19534,
            "nubia_score": 0.67963
        },
        "bertscore": {
            "precision": 0.94242,
            "recall": 0.93967,
            "f1": 0.94095
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.16666666666666666
        },
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.45455,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.12857,
            "fmeasure": 0.12593
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.36364,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.36364,
            "fmeasure": 0.4
        },
        "nist": 1.3872674880270606,
        "bleu": 5.36949,
        "meteor": 0.14918414918414918,
        "bleurt": -0.15686,
        "nubia": {
            "semantic_relation": 3.08905,
            "contradiction": 0.82489,
            "irrelevancy": 95.69883,
            "logical_agreement": 3.47628,
            "grammar_ref": 4.68733,
            "grammar_hyp": 4.74904,
            "nubia_score": 0.41433
        },
        "bertscore": {
            "precision": 0.80643,
            "recall": 0.83866,
            "f1": 0.82223
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.44444,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "nist": 2.5092629064746266,
        "bleu": 26.91109,
        "meteor": 0.46600466392966616,
        "bleurt": 0.78782,
        "nubia": {
            "semantic_relation": 4.90242,
            "contradiction": 0.21474,
            "irrelevancy": 0.43396,
            "logical_agreement": 99.35131,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.62619,
            "nubia_score": 0.93524
        },
        "bertscore": {
            "precision": 0.96059,
            "recall": 0.96399,
            "f1": 0.96229
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 67,
        "mean_pred_length": 16.75,
        "std_pred_length": 3.897114317029974,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.7611940298507462,
        "vocab_size-1": 51,
        "unique-1": 38,
        "entropy-1": 5.547359526246375,
        "distinct-2": 0.9365079365079365,
        "vocab_size-2": 59,
        "unique-2": 55,
        "entropy-2": 5.850295796515793,
        "cond_entropy-2": 0.27896732036662547,
        "distinct-3": 0.9830508474576272,
        "vocab_size-3": 58,
        "unique-3": 57,
        "entropy-3": 5.848744744277091,
        "cond_entropy-3": 0.007058041116161994,
        "total_length-nopunct": 61,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 4.02336923485777,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8032786885245902,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.524919509658564,
        "distinct-2-nopunct": 0.9298245614035088,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.692539136971755,
        "cond_entropy-2-nopunct": 0.16829171171487864,
        "distinct-3-nopunct": 0.9811320754716981,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.690184605506592,
        "cond_entropy-3-nopunct": 0.00823798756826884,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.6666666666666666,
            "3": 0.9148936170212766
        },
        "rouge1": {
            "precision": 0.86787,
            "recall": 0.83374,
            "fmeasure": 0.84954
        },
        "rouge2": {
            "precision": 0.72981,
            "recall": 0.69584,
            "fmeasure": 0.71165
        },
        "rougeL": {
            "precision": 0.73908,
            "recall": 0.72063,
            "fmeasure": 0.72565
        },
        "rougeLsum": {
            "precision": 0.73908,
            "recall": 0.72063,
            "fmeasure": 0.72565
        },
        "nist": 5.491476043030301,
        "bleu": 60.00836,
        "meteor": 0.47636134570712263,
        "bleurt": 0.47023,
        "nubia": {
            "semantic_relation": 4.39842,
            "contradiction": 22.30674,
            "irrelevancy": 13.1445,
            "logical_agreement": 64.54876,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.29318,
            "nubia_score": 0.80717
        },
        "bertscore": {
            "precision": 0.967,
            "recall": 0.95888,
            "f1": 0.96291
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "t5-small/totto_test",
        "N": 11,
        "total_length": 171,
        "mean_pred_length": 15.545454545454545,
        "std_pred_length": 5.193766129849346,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6783625730994152,
        "vocab_size-1": 116,
        "unique-1": 101,
        "entropy-1": 6.362977384414141,
        "distinct-2": 0.96875,
        "vocab_size-2": 155,
        "unique-2": 151,
        "entropy-2": 7.254710047998846,
        "cond_entropy-2": 0.785947047473498,
        "distinct-3": 1.0,
        "vocab_size-3": 149,
        "unique-3": 149,
        "entropy-3": 7.21916852046217,
        "cond_entropy-3": -0.030579121390546544,
        "total_length-nopunct": 154,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.239708527632568,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7402597402597403,
        "vocab_size-1-nopunct": 114,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.436563668632002,
        "distinct-2-nopunct": 0.965034965034965,
        "vocab_size-2-nopunct": 138,
        "unique-2-nopunct": 134,
        "entropy-2-nopunct": 7.084662333266764,
        "cond_entropy-2-nopunct": 0.7119619624857617,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 132,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.044394119358443,
        "cond_entropy-3-nopunct": -0.03400079694900049,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.4,
            "3": 0.6170212765957447
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.61331,
            "fmeasure": 0.64957
        },
        "rouge2": {
            "precision": 0.47448,
            "recall": 0.40865,
            "fmeasure": 0.43543
        },
        "rougeL": {
            "precision": 0.62842,
            "recall": 0.54554,
            "fmeasure": 0.58018
        },
        "rougeLsum": {
            "precision": 0.62842,
            "recall": 0.54554,
            "fmeasure": 0.58018
        },
        "nist": 4.844720962837819,
        "bleu": 37.45475,
        "meteor": 0.32307440386438696,
        "bleurt": 0.0409,
        "nubia": {
            "semantic_relation": 3.58967,
            "contradiction": 36.05777,
            "irrelevancy": 27.51305,
            "logical_agreement": 36.42918,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.73416,
            "nubia_score": 0.5317
        },
        "bertscore": {
            "precision": 0.91344,
            "recall": 0.89406,
            "f1": 0.90243
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "t5-small/totto_test",
        "N": 64,
        "total_length": 1026,
        "mean_pred_length": 16.03125,
        "std_pred_length": 4.3909308167517285,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.49415204678362573,
        "vocab_size-1": 507,
        "unique-1": 397,
        "entropy-1": 7.767202062537726,
        "distinct-2": 0.8877338877338877,
        "vocab_size-2": 854,
        "unique-2": 787,
        "entropy-2": 9.613524214333395,
        "cond_entropy-2": 1.6609874049825295,
        "distinct-3": 0.9688195991091314,
        "vocab_size-3": 870,
        "unique-3": 848,
        "entropy-3": 9.742075226050222,
        "cond_entropy-3": 0.13706513148216268,
        "total_length-nopunct": 894,
        "mean_pred_length-nopunct": 13.96875,
        "std_pred_length-nopunct": 4.081087286189796,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5604026845637584,
        "vocab_size-1-nopunct": 501,
        "unique-1-nopunct": 396,
        "entropy-1-nopunct": 8.023861913173773,
        "distinct-2-nopunct": 0.8939759036144578,
        "vocab_size-2-nopunct": 742,
        "unique-2-nopunct": 692,
        "entropy-2-nopunct": 9.404386574557773,
        "cond_entropy-2-nopunct": 1.46959833476559,
        "distinct-3-nopunct": 0.9686684073107049,
        "vocab_size-3-nopunct": 742,
        "unique-3-nopunct": 724,
        "entropy-3-nopunct": 9.51134447878621,
        "cond_entropy-3-nopunct": 0.11716454954409171,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.76625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23931623931623933,
            "2": 0.44052863436123346,
            "3": 0.6993006993006993
        },
        "rouge1": {
            "precision": 0.73991,
            "recall": 0.67196,
            "fmeasure": 0.69522
        },
        "rouge2": {
            "precision": 0.48123,
            "recall": 0.44541,
            "fmeasure": 0.45569
        },
        "rougeL": {
            "precision": 0.62401,
            "recall": 0.5707,
            "fmeasure": 0.58855
        },
        "rougeLsum": {
            "precision": 0.62401,
            "recall": 0.5707,
            "fmeasure": 0.58855
        },
        "nist": 6.568225886751047,
        "bleu": 40.32156,
        "meteor": 0.3583785548460516,
        "bleurt": 0.14864,
        "nubia": {
            "semantic_relation": 4.04277,
            "contradiction": 10.88672,
            "irrelevancy": 37.55353,
            "logical_agreement": 51.55976,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.74158,
            "nubia_score": 0.67157
        },
        "bertscore": {
            "precision": 0.92553,
            "recall": 0.90789,
            "f1": 0.91528
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "t5-small/totto_test",
        "N": 15,
        "total_length": 201,
        "mean_pred_length": 13.4,
        "std_pred_length": 5.486954224947268,
        "median_pred_length": 14.0,
        "min_pred_length": 2,
        "max_pred_length": 24,
        "distinct-1": 0.6716417910447762,
        "vocab_size-1": 135,
        "unique-1": 108,
        "entropy-1": 6.663443012921512,
        "distinct-2": 0.9623655913978495,
        "vocab_size-2": 179,
        "unique-2": 173,
        "entropy-2": 7.459831458945877,
        "cond_entropy-2": 0.62324102755773,
        "distinct-3": 1.0,
        "vocab_size-3": 171,
        "unique-3": 171,
        "entropy-3": 7.417852514885889,
        "cond_entropy-3": -0.03502040439661583,
        "total_length-nopunct": 180,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 5.176871642217914,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7222222222222222,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 107,
        "entropy-1-nopunct": 6.694687572323618,
        "distinct-2-nopunct": 0.9575757575757575,
        "vocab_size-2-nopunct": 158,
        "unique-2-nopunct": 152,
        "entropy-2-nopunct": 7.2768986536266365,
        "cond_entropy-2-nopunct": 0.6122564319702319,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 150,
        "unique-3-nopunct": 150,
        "entropy-3-nopunct": 7.228818690495862,
        "cond_entropy-3-nopunct": -0.039137607068845226,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2765957446808511,
            "2": 0.2962962962962963,
            "3": 0.7870967741935484
        },
        "rouge1": {
            "precision": 0.80801,
            "recall": 0.7316,
            "fmeasure": 0.76003
        },
        "rouge2": {
            "precision": 0.62293,
            "recall": 0.56275,
            "fmeasure": 0.58407
        },
        "rougeL": {
            "precision": 0.74416,
            "recall": 0.67179,
            "fmeasure": 0.69864
        },
        "rougeLsum": {
            "precision": 0.74416,
            "recall": 0.67179,
            "fmeasure": 0.69864
        },
        "nist": 5.839311000806784,
        "bleu": 50.84107,
        "meteor": 0.42479681987348195,
        "bleurt": 0.19,
        "nubia": {
            "semantic_relation": 4.24496,
            "contradiction": 6.51795,
            "irrelevancy": 32.63159,
            "logical_agreement": 60.85046,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.73474,
            "nubia_score": 0.75071
        },
        "bertscore": {
            "precision": 0.94954,
            "recall": 0.94228,
            "f1": 0.94242
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 90,
        "mean_pred_length": 11.25,
        "std_pred_length": 1.920286436967152,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.6,
        "vocab_size-1": 54,
        "unique-1": 41,
        "entropy-1": 5.377366846065245,
        "distinct-2": 0.8048780487804879,
        "vocab_size-2": 66,
        "unique-2": 58,
        "entropy-2": 5.887682187386613,
        "cond_entropy-2": 0.3263627803715476,
        "distinct-3": 0.8378378378378378,
        "vocab_size-3": 62,
        "unique-3": 56,
        "entropy-3": 5.823921946534618,
        "cond_entropy-3": -0.012963503853998842,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 9.75,
        "std_pred_length-nopunct": 1.984313483298443,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.4097129557366355,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 56,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.646791052504721,
        "cond_entropy-2-nopunct": 0.3371568696967298,
        "distinct-3-nopunct": 0.8387096774193549,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.570737640857562,
        "cond_entropy-3-nopunct": -0.01379638397744615,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.648936170212766
        },
        "rouge1": {
            "precision": 0.86458,
            "recall": 0.7211,
            "fmeasure": 0.76817
        },
        "rouge2": {
            "precision": 0.68368,
            "recall": 0.61282,
            "fmeasure": 0.63596
        },
        "rougeL": {
            "precision": 0.82269,
            "recall": 0.69639,
            "fmeasure": 0.73816
        },
        "rougeLsum": {
            "precision": 0.82269,
            "recall": 0.69639,
            "fmeasure": 0.73816
        },
        "nist": 3.253992467027522,
        "bleu": 43.8361,
        "meteor": 0.35923343417129217,
        "bleurt": 0.59499,
        "nubia": {
            "semantic_relation": 4.55498,
            "contradiction": 0.23758,
            "irrelevancy": 0.72527,
            "logical_agreement": 99.03715,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.89126,
            "nubia_score": 0.83554
        },
        "bertscore": {
            "precision": 0.96495,
            "recall": 0.91986,
            "f1": 0.94074
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "t5-small/totto_test",
        "N": 25,
        "total_length": 388,
        "mean_pred_length": 15.52,
        "std_pred_length": 4.508835769907793,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5979381443298969,
        "vocab_size-1": 232,
        "unique-1": 192,
        "entropy-1": 7.1609927205742485,
        "distinct-2": 0.9393939393939394,
        "vocab_size-2": 341,
        "unique-2": 330,
        "entropy-2": 8.349626926835894,
        "cond_entropy-2": 1.061516766144395,
        "distinct-3": 0.9970414201183432,
        "vocab_size-3": 337,
        "unique-3": 336,
        "entropy-3": 8.394962276518834,
        "cond_entropy-3": 0.05674058719482719,
        "total_length-nopunct": 334,
        "mean_pred_length-nopunct": 13.36,
        "std_pred_length-nopunct": 4.203617489734288,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6796407185628742,
        "vocab_size-1-nopunct": 227,
        "unique-1-nopunct": 192,
        "entropy-1-nopunct": 7.316520857487564,
        "distinct-2-nopunct": 0.941747572815534,
        "vocab_size-2-nopunct": 291,
        "unique-2-nopunct": 282,
        "entropy-2-nopunct": 8.122679311234336,
        "cond_entropy-2-nopunct": 0.8795551717877254,
        "distinct-3-nopunct": 0.9964788732394366,
        "vocab_size-3-nopunct": 283,
        "unique-3-nopunct": 282,
        "entropy-3-nopunct": 8.142704865983577,
        "cond_entropy-3-nopunct": 0.029601586146212736,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.78333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17391304347826086,
            "2": 0.375,
            "3": 0.7096774193548387
        },
        "rouge1": {
            "precision": 0.77245,
            "recall": 0.72464,
            "fmeasure": 0.73602
        },
        "rouge2": {
            "precision": 0.56017,
            "recall": 0.52053,
            "fmeasure": 0.53
        },
        "rougeL": {
            "precision": 0.6701,
            "recall": 0.63029,
            "fmeasure": 0.63965
        },
        "rougeLsum": {
            "precision": 0.6701,
            "recall": 0.63029,
            "fmeasure": 0.63965
        },
        "nist": 6.026780006901145,
        "bleu": 45.78696,
        "meteor": 0.38771792426519486,
        "bleurt": 0.19156,
        "nubia": {
            "semantic_relation": 4.12679,
            "contradiction": 13.5185,
            "irrelevancy": 24.39164,
            "logical_agreement": 62.08986,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.85527,
            "nubia_score": 0.70082
        },
        "bertscore": {
            "precision": 0.92611,
            "recall": 0.9162,
            "f1": 0.91931
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "t5-small/totto_test",
        "N": 10,
        "total_length": 150,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.604345773288535,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.6,
        "vocab_size-1": 90,
        "unique-1": 70,
        "entropy-1": 6.037571711202133,
        "distinct-2": 0.8857142857142857,
        "vocab_size-2": 124,
        "unique-2": 111,
        "entropy-2": 6.884535427612901,
        "cond_entropy-2": 0.7916850402574213,
        "distinct-3": 0.9923076923076923,
        "vocab_size-3": 129,
        "unique-3": 128,
        "entropy-3": 7.00698319764384,
        "cond_entropy-3": 0.14127450767187555,
        "total_length-nopunct": 134,
        "mean_pred_length-nopunct": 13.4,
        "std_pred_length-nopunct": 4.737087712930805,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6492537313432836,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.058361112549885,
        "distinct-2-nopunct": 0.8870967741935484,
        "vocab_size-2-nopunct": 110,
        "unique-2-nopunct": 99,
        "entropy-2-nopunct": 6.710126451463553,
        "cond_entropy-2-nopunct": 0.7330337322933516,
        "distinct-3-nopunct": 0.9912280701754386,
        "vocab_size-3-nopunct": 113,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.81534615451563,
        "cond_entropy-3-nopunct": 0.1266293397997117,
        "msttr-100": 0.62,
        "msttr-100_nopunct": 0.65,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4583333333333333,
            "2": 0.5384615384615384,
            "3": 0.8440366972477065
        },
        "rouge1": {
            "precision": 0.84935,
            "recall": 0.79969,
            "fmeasure": 0.81464
        },
        "rouge2": {
            "precision": 0.67349,
            "recall": 0.65469,
            "fmeasure": 0.65183
        },
        "rougeL": {
            "precision": 0.71782,
            "recall": 0.69512,
            "fmeasure": 0.69487
        },
        "rougeLsum": {
            "precision": 0.71782,
            "recall": 0.69512,
            "fmeasure": 0.69487
        },
        "nist": 6.46557258829657,
        "bleu": 66.28611,
        "meteor": 0.4768135382736042,
        "bleurt": 0.47649,
        "nubia": {
            "semantic_relation": 4.16948,
            "contradiction": 6.2147,
            "irrelevancy": 21.60102,
            "logical_agreement": 72.18428,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.89005,
            "nubia_score": 0.73385
        },
        "bertscore": {
            "precision": 0.95807,
            "recall": 0.94456,
            "f1": 0.95024
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.59028,
            "fmeasure": 0.4881
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.40179,
            "fmeasure": 0.32456
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.59028,
            "fmeasure": 0.4881
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.59028,
            "fmeasure": 0.4881
        },
        "nist": 1.7502089689086942,
        "bleu": 19.33853,
        "meteor": 0.3322919387981395,
        "bleurt": 0.09569,
        "nubia": {
            "semantic_relation": 3.52233,
            "contradiction": 0.23633,
            "irrelevancy": 1.25273,
            "logical_agreement": 98.51094,
            "grammar_ref": 6.12307,
            "grammar_hyp": 4.43565,
            "nubia_score": 0.62775
        },
        "bertscore": {
            "precision": 0.83206,
            "recall": 0.86183,
            "f1": 0.84669
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.04978793508525296,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.1986532337201607,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.99035,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.2359263506290334,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.5084694114681032,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.3125,
            "recall": 0.48485,
            "fmeasure": 0.37987
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.32222,
            "fmeasure": 0.24667
        },
        "rougeL": {
            "precision": 0.3125,
            "recall": 0.48485,
            "fmeasure": 0.37987
        },
        "rougeLsum": {
            "precision": 0.3125,
            "recall": 0.48485,
            "fmeasure": 0.37987
        },
        "nist": 1.2996144982255693,
        "bleu": 12.01106,
        "meteor": 0.21650865165608624,
        "bleurt": -0.86263,
        "nubia": {
            "semantic_relation": 2.19512,
            "contradiction": 2.77441,
            "irrelevancy": 89.68263,
            "logical_agreement": 7.54295,
            "grammar_ref": 3.16175,
            "grammar_hyp": 2.0116,
            "nubia_score": 0.36392
        },
        "bertscore": {
            "precision": 0.67145,
            "recall": 0.82949,
            "f1": 0.74201
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "t5-small/totto_test",
        "N": 12,
        "total_length": 152,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 5.807083796728115,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.6578947368421053,
        "vocab_size-1": 100,
        "unique-1": 80,
        "entropy-1": 6.19080291944291,
        "distinct-2": 0.9571428571428572,
        "vocab_size-2": 134,
        "unique-2": 129,
        "entropy-2": 7.03817667764381,
        "cond_entropy-2": 0.6563088126299872,
        "distinct-3": 1.0,
        "vocab_size-3": 128,
        "unique-3": 128,
        "entropy-3": 7.0,
        "cond_entropy-3": -0.02963545833431431,
        "total_length-nopunct": 135,
        "mean_pred_length-nopunct": 11.25,
        "std_pred_length-nopunct": 5.417948566262573,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7185185185185186,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.264494202388277,
        "distinct-2-nopunct": 0.9512195121951219,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 112,
        "entropy-2-nopunct": 6.838816232963916,
        "cond_entropy-2-nopunct": 0.6291826544451855,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 111,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.794415866350121,
        "cond_entropy-3-nopunct": -0.03318974257324655,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.42857142857142855,
            "3": 0.717391304347826
        },
        "rouge1": {
            "precision": 0.71733,
            "recall": 0.69137,
            "fmeasure": 0.69504
        },
        "rouge2": {
            "precision": 0.48863,
            "recall": 0.45913,
            "fmeasure": 0.46714
        },
        "rougeL": {
            "precision": 0.62677,
            "recall": 0.5938,
            "fmeasure": 0.60252
        },
        "rougeLsum": {
            "precision": 0.62677,
            "recall": 0.5938,
            "fmeasure": 0.60252
        },
        "nist": 4.9005522156196575,
        "bleu": 33.44612,
        "meteor": 0.36346362426685697,
        "bleurt": 0.21274,
        "nubia": {
            "semantic_relation": 3.96436,
            "contradiction": 15.51647,
            "irrelevancy": 16.2082,
            "logical_agreement": 68.27534,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.44601,
            "nubia_score": 0.6815
        },
        "bertscore": {
            "precision": 0.91463,
            "recall": 0.91375,
            "f1": 0.91231
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 56,
        "mean_pred_length": 11.2,
        "std_pred_length": 4.06939798987516,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.8035714285714286,
        "vocab_size-1": 45,
        "unique-1": 37,
        "entropy-1": 5.350039913585522,
        "distinct-2": 0.9803921568627451,
        "vocab_size-2": 50,
        "unique-2": 49,
        "entropy-2": 5.63320965569699,
        "cond_entropy-2": 0.10036453756095007,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.10538512504491752,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 9.6,
        "std_pred_length-nopunct": 3.3823069050575527,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8541666666666666,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.2932958340544936,
        "distinct-2-nopunct": 0.9767441860465116,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.379753126795121,
        "cond_entropy-2-nopunct": 0.12037202142280215,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.125705662311144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.625,
            "3": 0.868421052631579
        },
        "rouge1": {
            "precision": 0.87683,
            "recall": 0.80474,
            "fmeasure": 0.83724
        },
        "rouge2": {
            "precision": 0.67119,
            "recall": 0.61452,
            "fmeasure": 0.63964
        },
        "rougeL": {
            "precision": 0.82794,
            "recall": 0.76492,
            "fmeasure": 0.79366
        },
        "rougeLsum": {
            "precision": 0.82794,
            "recall": 0.76492,
            "fmeasure": 0.79366
        },
        "nist": 4.9193464794726465,
        "bleu": 62.21995,
        "meteor": 0.47161454912069256,
        "bleurt": 0.37945,
        "nubia": {
            "semantic_relation": 4.49073,
            "contradiction": 0.71021,
            "irrelevancy": 1.92452,
            "logical_agreement": 97.36527,
            "grammar_ref": 5.12632,
            "grammar_hyp": 5.18014,
            "nubia_score": 0.84066
        },
        "bertscore": {
            "precision": 0.95512,
            "recall": 0.94401,
            "f1": 0.94943
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.9011,
            "fmeasure": 0.84729
        },
        "rouge2": {
            "precision": 0.52381,
            "recall": 0.59829,
            "fmeasure": 0.5584
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.60073,
            "fmeasure": 0.56486
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.60073,
            "fmeasure": 0.56486
        },
        "nist": 3.7910972535534957,
        "bleu": 36.6023,
        "meteor": 0.47897116126030975,
        "bleurt": 0.56433,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2069,
            "irrelevancy": 0.44767,
            "logical_agreement": 99.34544,
            "grammar_ref": 5.12321,
            "grammar_hyp": 3.95929,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.93731,
            "recall": 0.95564,
            "f1": 0.94638
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "t5-small/totto_test",
        "N": 9,
        "total_length": 146,
        "mean_pred_length": 16.22222222222222,
        "std_pred_length": 5.9400295131660705,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.6986301369863014,
        "vocab_size-1": 102,
        "unique-1": 87,
        "entropy-1": 6.2761253094535965,
        "distinct-2": 0.9635036496350365,
        "vocab_size-2": 132,
        "unique-2": 127,
        "entropy-2": 7.025039382230585,
        "cond_entropy-2": 0.6679371626927215,
        "distinct-3": 0.984375,
        "vocab_size-3": 126,
        "unique-3": 124,
        "entropy-3": 6.96875,
        "cond_entropy-3": -0.05896958296052653,
        "total_length-nopunct": 130,
        "mean_pred_length-nopunct": 14.444444444444445,
        "std_pred_length-nopunct": 5.335647646019098,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7538461538461538,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.300134617552066,
        "distinct-2-nopunct": 0.9586776859504132,
        "vocab_size-2-nopunct": 116,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.83621860917543,
        "cond_entropy-2-nopunct": 0.541809147302942,
        "distinct-3-nopunct": 0.9821428571428571,
        "vocab_size-3-nopunct": 110,
        "unique-3-nopunct": 108,
        "entropy-3-nopunct": 6.771640636343307,
        "cond_entropy-3-nopunct": -0.06686545807413326,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24528301886792453,
            "2": 0.4489795918367347,
            "3": 0.647887323943662
        },
        "rouge1": {
            "precision": 0.59934,
            "recall": 0.55788,
            "fmeasure": 0.56082
        },
        "rouge2": {
            "precision": 0.35698,
            "recall": 0.33154,
            "fmeasure": 0.33184
        },
        "rougeL": {
            "precision": 0.52593,
            "recall": 0.4886,
            "fmeasure": 0.49091
        },
        "rougeLsum": {
            "precision": 0.52593,
            "recall": 0.4886,
            "fmeasure": 0.49091
        },
        "nist": 4.354793145585839,
        "bleu": 29.39252,
        "meteor": 0.29291135816428326,
        "bleurt": -0.25432,
        "nubia": {
            "semantic_relation": 3.46187,
            "contradiction": 1.95272,
            "irrelevancy": 52.1168,
            "logical_agreement": 45.93048,
            "grammar_ref": 4.84583,
            "grammar_hyp": 5.10299,
            "nubia_score": 0.50173
        },
        "bertscore": {
            "precision": 0.87754,
            "recall": 0.85819,
            "f1": 0.86359
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.70955,
            "fmeasure": 0.71572
        },
        "rouge2": {
            "precision": 0.41176,
            "recall": 0.40414,
            "fmeasure": 0.40784
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.49123,
            "fmeasure": 0.4955
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.49123,
            "fmeasure": 0.4955
        },
        "nist": 2.395635046080723,
        "bleu": 9.04261,
        "meteor": 0.29845373685859217,
        "bleurt": 0.16911,
        "nubia": {
            "semantic_relation": 3.93363,
            "contradiction": 1.04621,
            "irrelevancy": 12.33617,
            "logical_agreement": 86.61762,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.9978,
            "nubia_score": 0.59154
        },
        "bertscore": {
            "precision": 0.87477,
            "recall": 0.86785,
            "f1": 0.87061
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 1.5,
        "median_pred_length": 16.5,
        "min_pred_length": 15,
        "max_pred_length": 18,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.571374711042188,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.3488228514941255,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8387096774193549,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.515175649921172,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.37308263213506987,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.6666666666666666,
            "3": 0.8947368421052632
        },
        "rouge1": {
            "precision": 0.8254,
            "recall": 0.88426,
            "fmeasure": 0.85106
        },
        "rouge2": {
            "precision": 0.71667,
            "recall": 0.73943,
            "fmeasure": 0.72659
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.87165,
            "fmeasure": 0.85061
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.87165,
            "fmeasure": 0.85061
        },
        "nist": 5.165111910619636,
        "bleu": 63.3077,
        "meteor": 0.5261251448224723,
        "bleurt": 0.65749,
        "nubia": {
            "semantic_relation": 4.77045,
            "contradiction": 0.3228,
            "irrelevancy": 26.47539,
            "logical_agreement": 73.20182,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.64753,
            "nubia_score": 0.94379
        },
        "bertscore": {
            "precision": 0.96045,
            "recall": 0.97066,
            "f1": 0.9655
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "t5-small/totto_test",
        "N": 20,
        "total_length": 311,
        "mean_pred_length": 15.55,
        "std_pred_length": 5.352335938634645,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5627009646302251,
        "vocab_size-1": 175,
        "unique-1": 134,
        "entropy-1": 6.805460793806945,
        "distinct-2": 0.9106529209621993,
        "vocab_size-2": 265,
        "unique-2": 247,
        "entropy-2": 7.982059019854492,
        "cond_entropy-2": 1.0097890912838692,
        "distinct-3": 0.988929889298893,
        "vocab_size-3": 268,
        "unique-3": 265,
        "entropy-3": 8.060008819951623,
        "cond_entropy-3": 0.07446760991663516,
        "total_length-nopunct": 274,
        "mean_pred_length-nopunct": 13.7,
        "std_pred_length-nopunct": 5.01098792654702,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6240875912408759,
        "vocab_size-1-nopunct": 171,
        "unique-1-nopunct": 134,
        "entropy-1-nopunct": 6.9272006560538335,
        "distinct-2-nopunct": 0.9133858267716536,
        "vocab_size-2-nopunct": 232,
        "unique-2-nopunct": 218,
        "entropy-2-nopunct": 7.787820316659321,
        "cond_entropy-2-nopunct": 0.9167090446082099,
        "distinct-3-nopunct": 0.9957264957264957,
        "vocab_size-3-nopunct": 233,
        "unique-3-nopunct": 232,
        "entropy-3-nopunct": 7.861817711036382,
        "cond_entropy-3-nopunct": 0.07834477643796456,
        "msttr-100": 0.71667,
        "msttr-100_nopunct": 0.755,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17567567567567569,
            "2": 0.5230769230769231,
            "3": 0.8473684210526315
        },
        "rouge1": {
            "precision": 0.80691,
            "recall": 0.7773,
            "fmeasure": 0.78366
        },
        "rouge2": {
            "precision": 0.61944,
            "recall": 0.59615,
            "fmeasure": 0.59967
        },
        "rougeL": {
            "precision": 0.67232,
            "recall": 0.64016,
            "fmeasure": 0.64841
        },
        "rougeLsum": {
            "precision": 0.67232,
            "recall": 0.64016,
            "fmeasure": 0.64841
        },
        "nist": 6.535216846672646,
        "bleu": 54.94528,
        "meteor": 0.4316722347016945,
        "bleurt": 0.28061,
        "nubia": {
            "semantic_relation": 4.12853,
            "contradiction": 11.91595,
            "irrelevancy": 20.90296,
            "logical_agreement": 67.18109,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.58084,
            "nubia_score": 0.7402
        },
        "bertscore": {
            "precision": 0.94065,
            "recall": 0.93176,
            "f1": 0.93555
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 14,
        "unique-2": 13,
        "entropy-2": 3.7735572622751845,
        "cond_entropy-2": 0.04022392894185189,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.6402239289418516,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.35294117647058826
        },
        "rouge1": {
            "precision": 0.47917,
            "recall": 0.28727,
            "fmeasure": 0.35917
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.12,
            "fmeasure": 0.15
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.23077,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.23077,
            "fmeasure": 0.28571
        },
        "nist": 0.7754952738273035,
        "bleu": 10.04488,
        "meteor": 0.1623330388698009,
        "bleurt": -0.38676,
        "nubia": {
            "semantic_relation": 2.60098,
            "contradiction": 0.63727,
            "irrelevancy": 99.07963,
            "logical_agreement": 0.2831,
            "grammar_ref": 4.71547,
            "grammar_hyp": 4.56651,
            "nubia_score": 0.19823
        },
        "bertscore": {
            "precision": 0.82894,
            "recall": 0.78203,
            "f1": 0.8048
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 5.0,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 22,
        "unique-1": 18,
        "entropy-1": 4.3248629576173565,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.2907713346559734,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.84,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.293660689688184,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.26035304898504774,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.7222222222222222
        },
        "rouge1": {
            "precision": 0.67361,
            "recall": 0.65717,
            "fmeasure": 0.61789
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.34829,
            "fmeasure": 0.34032
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.57856,
            "fmeasure": 0.5397
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.57856,
            "fmeasure": 0.5397
        },
        "nist": 2.9031041873573193,
        "bleu": 13.45555,
        "meteor": 0.3312934976144787,
        "bleurt": -0.03618,
        "nubia": {
            "semantic_relation": 3.77729,
            "contradiction": 0.42391,
            "irrelevancy": 42.23424,
            "logical_agreement": 57.34184,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.7131,
            "nubia_score": 0.54833
        },
        "bertscore": {
            "precision": 0.89947,
            "recall": 0.89973,
            "f1": 0.89372
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 120,
        "mean_pred_length": 17.142857142857142,
        "std_pred_length": 3.7579846965616874,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 25,
        "distinct-1": 0.7,
        "vocab_size-1": 84,
        "unique-1": 69,
        "entropy-1": 6.060493667147721,
        "distinct-2": 0.9734513274336283,
        "vocab_size-2": 110,
        "unique-2": 107,
        "entropy-2": 6.767081617282463,
        "cond_entropy-2": 0.5731789103048717,
        "distinct-3": 1.0,
        "vocab_size-3": 106,
        "unique-3": 106,
        "entropy-3": 6.727920454563184,
        "cond_entropy-3": -0.03565473426708267,
        "total_length-nopunct": 104,
        "mean_pred_length-nopunct": 14.857142857142858,
        "std_pred_length-nopunct": 3.481730744843983,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7788461538461539,
        "vocab_size-1-nopunct": 81,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.143553689670968,
        "distinct-2-nopunct": 0.9690721649484536,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.538057172084049,
        "cond_entropy-2-nopunct": 0.41407257725112495,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 90,
        "unique-3-nopunct": 90,
        "entropy-3-nopunct": 6.491853096329662,
        "cond_entropy-3-nopunct": -0.041393079190786546,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.6129032258064516,
            "3": 0.7160493827160493
        },
        "rouge1": {
            "precision": 0.84576,
            "recall": 0.73436,
            "fmeasure": 0.77885
        },
        "rouge2": {
            "precision": 0.57706,
            "recall": 0.49918,
            "fmeasure": 0.53092
        },
        "rougeL": {
            "precision": 0.72549,
            "recall": 0.64775,
            "fmeasure": 0.67855
        },
        "rougeLsum": {
            "precision": 0.72549,
            "recall": 0.64775,
            "fmeasure": 0.67855
        },
        "nist": 5.088850962182705,
        "bleu": 46.95582,
        "meteor": 0.3881106331459147,
        "bleurt": 0.27464,
        "nubia": {
            "semantic_relation": 4.39153,
            "contradiction": 1.70826,
            "irrelevancy": 13.14857,
            "logical_agreement": 85.14318,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.61988,
            "nubia_score": 0.78266
        },
        "bertscore": {
            "precision": 0.9439,
            "recall": 0.91981,
            "f1": 0.92993
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 43,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 4.027681991198191,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.6511627906976745,
        "vocab_size-1": 28,
        "unique-1": 21,
        "entropy-1": 4.486581685944732,
        "distinct-2": 0.925,
        "vocab_size-2": 37,
        "unique-2": 35,
        "entropy-2": 5.153055907333276,
        "cond_entropy-2": 0.6180782639912585,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": 0.0700897978270865,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 4.027681991198191,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.675,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.430640983527281,
        "distinct-2-nopunct": 0.918918918918919,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.026888838543454,
        "cond_entropy-2-nopunct": 0.641487350531851,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": 0.07668263744972706,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6470588235294118
        },
        "rouge1": {
            "precision": 0.76515,
            "recall": 0.65311,
            "fmeasure": 0.70203
        },
        "rouge2": {
            "precision": 0.49181,
            "recall": 0.40137,
            "fmeasure": 0.44049
        },
        "rougeL": {
            "precision": 0.59848,
            "recall": 0.51309,
            "fmeasure": 0.55117
        },
        "rougeLsum": {
            "precision": 0.59848,
            "recall": 0.51309,
            "fmeasure": 0.55117
        },
        "nist": 3.584943257968143,
        "bleu": 27.03768,
        "meteor": 0.3596177759334259,
        "bleurt": 0.53051,
        "nubia": {
            "semantic_relation": 4.60669,
            "contradiction": 0.43918,
            "irrelevancy": 0.52588,
            "logical_agreement": 99.03494,
            "grammar_ref": 4.67072,
            "grammar_hyp": 4.44161,
            "nubia_score": 0.89786
        },
        "bertscore": {
            "precision": 0.94379,
            "recall": 0.92544,
            "f1": 0.93425
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 66,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.5,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.6818181818181818,
        "vocab_size-1": 45,
        "unique-1": 34,
        "entropy-1": 5.2639429829292625,
        "distinct-2": 0.8870967741935484,
        "vocab_size-2": 55,
        "unique-2": 49,
        "entropy-2": 5.716214253900366,
        "cond_entropy-2": 0.3936731587703571,
        "distinct-3": 0.9310344827586207,
        "vocab_size-3": 54,
        "unique-3": 50,
        "entropy-3": 5.720049960644812,
        "cond_entropy-3": 0.0030068830538603035,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.153311931459037,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6935483870967742,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.200085221642302,
        "distinct-2-nopunct": 0.8793103448275862,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.6035863830213035,
        "cond_entropy-2-nopunct": 0.4210260640510416,
        "distinct-3-nopunct": 0.9259259259259259,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.60673935401532,
        "cond_entropy-3-nopunct": 0.0034784978167015715,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.43333333333333335,
            "2": 0.3333333333333333,
            "3": 0.675
        },
        "rouge1": {
            "precision": 0.67948,
            "recall": 0.69788,
            "fmeasure": 0.67311
        },
        "rouge2": {
            "precision": 0.45903,
            "recall": 0.4599,
            "fmeasure": 0.45054
        },
        "rougeL": {
            "precision": 0.56825,
            "recall": 0.60761,
            "fmeasure": 0.57409
        },
        "rougeLsum": {
            "precision": 0.56825,
            "recall": 0.60761,
            "fmeasure": 0.57409
        },
        "nist": 4.488421245513703,
        "bleu": 29.07044,
        "meteor": 0.34716410070670073,
        "bleurt": 0.05631,
        "nubia": {
            "semantic_relation": 4.11067,
            "contradiction": 9.08275,
            "irrelevancy": 46.21577,
            "logical_agreement": 44.70147,
            "grammar_ref": 4.84918,
            "grammar_hyp": 4.81428,
            "nubia_score": 0.67945
        },
        "bertscore": {
            "precision": 0.92376,
            "recall": 0.92196,
            "f1": 0.92099
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "t5-small/totto_test",
        "N": 29,
        "total_length": 436,
        "mean_pred_length": 15.03448275862069,
        "std_pred_length": 3.6811051434710396,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.5779816513761468,
        "vocab_size-1": 252,
        "unique-1": 197,
        "entropy-1": 7.288919076932179,
        "distinct-2": 0.9066339066339066,
        "vocab_size-2": 369,
        "unique-2": 344,
        "entropy-2": 8.448127069199995,
        "cond_entropy-2": 0.9917868428087824,
        "distinct-3": 0.9708994708994709,
        "vocab_size-3": 367,
        "unique-3": 357,
        "entropy-3": 8.502044309136009,
        "cond_entropy-3": 0.0682081910918649,
        "total_length-nopunct": 376,
        "mean_pred_length-nopunct": 12.96551724137931,
        "std_pred_length-nopunct": 2.9534638766019117,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.648936170212766,
        "vocab_size-1-nopunct": 244,
        "unique-1-nopunct": 194,
        "entropy-1-nopunct": 7.441073207622718,
        "distinct-2-nopunct": 0.9020172910662824,
        "vocab_size-2-nopunct": 313,
        "unique-2-nopunct": 291,
        "entropy-2-nopunct": 8.2050927634434,
        "cond_entropy-2-nopunct": 0.8364173329853178,
        "distinct-3-nopunct": 0.9748427672955975,
        "vocab_size-3-nopunct": 310,
        "unique-3-nopunct": 302,
        "entropy-3-nopunct": 8.262568489875562,
        "cond_entropy-3-nopunct": 0.06935394525263798,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.79333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18421052631578946,
            "2": 0.4626865671641791,
            "3": 0.7728613569321534
        },
        "rouge1": {
            "precision": 0.85744,
            "recall": 0.77088,
            "fmeasure": 0.80051
        },
        "rouge2": {
            "precision": 0.67791,
            "recall": 0.61499,
            "fmeasure": 0.63708
        },
        "rougeL": {
            "precision": 0.78808,
            "recall": 0.70067,
            "fmeasure": 0.73204
        },
        "rougeLsum": {
            "precision": 0.78808,
            "recall": 0.70067,
            "fmeasure": 0.73204
        },
        "nist": 6.499523726276477,
        "bleu": 51.87447,
        "meteor": 0.42099572981395583,
        "bleurt": 0.40314,
        "nubia": {
            "semantic_relation": 4.26249,
            "contradiction": 10.086,
            "irrelevancy": 16.3806,
            "logical_agreement": 73.5334,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.85977,
            "nubia_score": 0.73769
        },
        "bertscore": {
            "precision": 0.95182,
            "recall": 0.93629,
            "f1": 0.94323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "t5-small/totto_test",
        "N": 136,
        "total_length": 2136,
        "mean_pred_length": 15.705882352941176,
        "std_pred_length": 4.209788396000486,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.3604868913857678,
        "vocab_size-1": 770,
        "unique-1": 609,
        "entropy-1": 7.614584736577116,
        "distinct-2": 0.6785,
        "vocab_size-2": 1357,
        "unique-2": 1233,
        "entropy-2": 9.5473446949476,
        "cond_entropy-2": 1.7287115456923463,
        "distinct-3": 0.7832618025751072,
        "vocab_size-3": 1460,
        "unique-3": 1391,
        "entropy-3": 9.901396715706383,
        "cond_entropy-3": 0.44073009704562516,
        "total_length-nopunct": 1850,
        "mean_pred_length-nopunct": 13.602941176470589,
        "std_pred_length-nopunct": 3.6907663235923405,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4118918918918919,
        "vocab_size-1-nopunct": 762,
        "unique-1-nopunct": 608,
        "entropy-1-nopunct": 7.8657366112861125,
        "distinct-2-nopunct": 0.6820303383897316,
        "vocab_size-2-nopunct": 1169,
        "unique-2-nopunct": 1082,
        "entropy-2-nopunct": 9.301873491492396,
        "cond_entropy-2-nopunct": 1.6062739054076978,
        "distinct-3-nopunct": 0.7858048162230672,
        "vocab_size-3-nopunct": 1240,
        "unique-3-nopunct": 1190,
        "entropy-3-nopunct": 9.660875529128996,
        "cond_entropy-3-nopunct": 0.47358639911398737,
        "msttr-100": 0.63905,
        "msttr-100_nopunct": 0.68833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2545454545454545,
            "2": 0.4253246753246753,
            "3": 0.7466852756454989
        },
        "rouge1": {
            "precision": 0.73698,
            "recall": 0.71366,
            "fmeasure": 0.71478
        },
        "rouge2": {
            "precision": 0.5087,
            "recall": 0.4845,
            "fmeasure": 0.48962
        },
        "rougeL": {
            "precision": 0.63259,
            "recall": 0.61204,
            "fmeasure": 0.6134
        },
        "rougeLsum": {
            "precision": 0.63259,
            "recall": 0.61204,
            "fmeasure": 0.6134
        },
        "nist": 7.32968634094542,
        "bleu": 45.88461,
        "meteor": 0.37905564380138157,
        "bleurt": 0.27891,
        "nubia": {
            "semantic_relation": 4.12041,
            "contradiction": 11.72093,
            "irrelevancy": 26.77374,
            "logical_agreement": 61.50533,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.55708,
            "nubia_score": 0.70855
        },
        "bertscore": {
            "precision": 0.9213,
            "recall": 0.91961,
            "f1": 0.91897
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "t5-small/totto_test",
        "N": 11,
        "total_length": 155,
        "mean_pred_length": 14.090909090909092,
        "std_pred_length": 3.654500225862142,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.6709677419354839,
        "vocab_size-1": 104,
        "unique-1": 89,
        "entropy-1": 6.2394514831361745,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 136,
        "unique-2": 131,
        "entropy-2": 7.0430870673694805,
        "cond_entropy-2": 0.6089745747582057,
        "distinct-3": 1.0,
        "vocab_size-3": 133,
        "unique-3": 133,
        "entropy-3": 7.055282435501199,
        "cond_entropy-3": 0.022685723581361564,
        "total_length-nopunct": 137,
        "mean_pred_length-nopunct": 12.454545454545455,
        "std_pred_length-nopunct": 3.367319850445843,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7445255474452555,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.352375309833353,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 119,
        "unique-2-nopunct": 115,
        "entropy-2-nopunct": 6.848195300432541,
        "cond_entropy-2-nopunct": 0.5609170104753478,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 115,
        "unique-3-nopunct": 115,
        "entropy-3-nopunct": 6.84549005094439,
        "cond_entropy-3-nopunct": 0.009641975326983902,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.42105263157894735,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.78593,
            "recall": 0.74129,
            "fmeasure": 0.75683
        },
        "rouge2": {
            "precision": 0.58763,
            "recall": 0.56427,
            "fmeasure": 0.56939
        },
        "rougeL": {
            "precision": 0.68984,
            "recall": 0.66855,
            "fmeasure": 0.67197
        },
        "rougeLsum": {
            "precision": 0.68984,
            "recall": 0.66855,
            "fmeasure": 0.67197
        },
        "nist": 5.444599638514143,
        "bleu": 48.79855,
        "meteor": 0.4082495312173763,
        "bleurt": 0.35063,
        "nubia": {
            "semantic_relation": 4.30278,
            "contradiction": 0.96266,
            "irrelevancy": 22.24579,
            "logical_agreement": 76.79155,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.56239,
            "nubia_score": 0.76471
        },
        "bertscore": {
            "precision": 0.93329,
            "recall": 0.92839,
            "f1": 0.92966
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 93,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.681523968396046,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.7741935483870968,
        "vocab_size-1": 72,
        "unique-1": 65,
        "entropy-1": 5.916854477979785,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 84,
        "unique-2": 81,
        "entropy-2": 6.373977978607345,
        "cond_entropy-2": 0.36659689745897744,
        "distinct-3": 0.9753086419753086,
        "vocab_size-3": 79,
        "unique-3": 77,
        "entropy-3": 6.2904672868352325,
        "cond_entropy-3": -0.07840213493941187,
        "total_length-nopunct": 84,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.618802153517006,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7976190476190477,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.841547631034826,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.208479141939177,
        "cond_entropy-2-nopunct": 0.40929841796156996,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.11436944588676,
        "cond_entropy-3-nopunct": -0.08769943964215803,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.4090909090909091,
            "3": 0.8115942028985508
        },
        "rouge1": {
            "precision": 0.77577,
            "recall": 0.71162,
            "fmeasure": 0.73751
        },
        "rouge2": {
            "precision": 0.56475,
            "recall": 0.52569,
            "fmeasure": 0.54264
        },
        "rougeL": {
            "precision": 0.69893,
            "recall": 0.63098,
            "fmeasure": 0.65914
        },
        "rougeLsum": {
            "precision": 0.69893,
            "recall": 0.63098,
            "fmeasure": 0.65914
        },
        "nist": 5.165647508300875,
        "bleu": 52.79613,
        "meteor": 0.4208689494633465,
        "bleurt": 0.36478,
        "nubia": {
            "semantic_relation": 4.4178,
            "contradiction": 15.64246,
            "irrelevancy": 28.66948,
            "logical_agreement": 55.68806,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.78887,
            "nubia_score": 0.77173
        },
        "bertscore": {
            "precision": 0.94388,
            "recall": 0.92405,
            "f1": 0.9338
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.896551724137931,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.651084443403434,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.045054655184044744,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.92,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.4838561897747224,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.05361880976054911,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.1,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.61081,
            "recall": 0.63587,
            "fmeasure": 0.60917
        },
        "rouge2": {
            "precision": 0.33013,
            "recall": 0.29167,
            "fmeasure": 0.30416
        },
        "rougeL": {
            "precision": 0.47711,
            "recall": 0.46784,
            "fmeasure": 0.46263
        },
        "rougeLsum": {
            "precision": 0.47711,
            "recall": 0.46784,
            "fmeasure": 0.46263
        },
        "nist": 3.4328768366029703,
        "bleu": 40.68837,
        "meteor": 0.37642264010339443,
        "bleurt": 0.20756,
        "nubia": {
            "semantic_relation": 4.10826,
            "contradiction": 0.38455,
            "irrelevancy": 47.39647,
            "logical_agreement": 52.21899,
            "grammar_ref": 4.57807,
            "grammar_hyp": 3.80153,
            "nubia_score": 0.78244
        },
        "bertscore": {
            "precision": 0.90052,
            "recall": 0.90723,
            "f1": 0.89951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 49,
        "mean_pred_length": 12.25,
        "std_pred_length": 7.46240577829965,
        "median_pred_length": 8.5,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.6530612244897959,
        "vocab_size-1": 32,
        "unique-1": 20,
        "entropy-1": 4.823793772642484,
        "distinct-2": 0.8666666666666667,
        "vocab_size-2": 39,
        "unique-2": 33,
        "entropy-2": 5.225186429663006,
        "cond_entropy-2": 0.29391853004032126,
        "distinct-3": 0.9024390243902439,
        "vocab_size-3": 37,
        "unique-3": 33,
        "entropy-3": 5.16243005339857,
        "cond_entropy-3": -0.08552060390671311,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 10.75,
        "std_pred_length-nopunct": 7.119515432949071,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6976744186046512,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.757546440698295,
        "distinct-2-nopunct": 0.8717948717948718,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 5.028991962451991,
        "cond_entropy-2-nopunct": 0.2887499642156238,
        "distinct-3-nopunct": 0.9142857142857143,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.957854445516393,
        "cond_entropy-3-nopunct": -0.09897634477442475,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.725
        },
        "rouge1": {
            "precision": 0.80752,
            "recall": 0.70629,
            "fmeasure": 0.74554
        },
        "rouge2": {
            "precision": 0.5947,
            "recall": 0.52163,
            "fmeasure": 0.54873
        },
        "rougeL": {
            "precision": 0.72509,
            "recall": 0.62269,
            "fmeasure": 0.66251
        },
        "rougeLsum": {
            "precision": 0.72509,
            "recall": 0.62269,
            "fmeasure": 0.66251
        },
        "nist": 4.776091507382767,
        "bleu": 52.8457,
        "meteor": 0.4625752822736935,
        "bleurt": 0.45072,
        "nubia": {
            "semantic_relation": 4.70743,
            "contradiction": 0.44509,
            "irrelevancy": 0.53164,
            "logical_agreement": 99.02327,
            "grammar_ref": 4.90076,
            "grammar_hyp": 4.83833,
            "nubia_score": 0.91685
        },
        "bertscore": {
            "precision": 0.95239,
            "recall": 0.93353,
            "f1": 0.94276
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7720,
        "mean_pred_length": 21.5041782729805,
        "std_pred_length": 9.340322585225518,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37176165803108807,
        "vocab_size-1": 2870,
        "unique-1": 2100,
        "entropy-1": 9.235158439326643,
        "distinct-2": 0.847167504415161,
        "vocab_size-2": 6236,
        "unique-2": 5774,
        "entropy-2": 12.327123665919075,
        "cond_entropy-2": 2.8572508020756424,
        "distinct-3": 0.9802913453299057,
        "vocab_size-3": 6864,
        "unique-3": 6757,
        "entropy-3": 12.729865603577442,
        "cond_entropy-3": 0.41443290245541875,
        "total_length-nopunct": 6952,
        "mean_pred_length-nopunct": 19.364902506963787,
        "std_pred_length-nopunct": 8.474966868997573,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.411536248561565,
        "vocab_size-1-nopunct": 2861,
        "unique-1-nopunct": 2098,
        "entropy-1-nopunct": 9.594839877948008,
        "distinct-2-nopunct": 0.8651600182011224,
        "vocab_size-2-nopunct": 5704,
        "unique-2-nopunct": 5328,
        "entropy-2-nopunct": 12.234578669854612,
        "cond_entropy-2-nopunct": 2.760495991752104,
        "distinct-3-nopunct": 0.9847609881296118,
        "vocab_size-3-nopunct": 6139,
        "unique-3-nopunct": 6062,
        "entropy-3-nopunct": 12.572833099233705,
        "cond_entropy-3-nopunct": 0.35825618548419247,
        "msttr-100": 0.72571,
        "msttr-100_nopunct": 0.76884,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.012521222410865875,
            "2": 0.19029374201787994,
            "3": 0.6061269146608315,
            "4": 0.8573692551505546,
            "5": 0.9293873312564901,
            "6": 0.9468599033816425,
            "7": 0.9618174875906834
        },
        "rouge1": {
            "precision": 0.94971,
            "recall": 0.93391,
            "fmeasure": 0.93572
        },
        "rouge2": {
            "precision": 0.90141,
            "recall": 0.88358,
            "fmeasure": 0.88555
        },
        "rougeL": {
            "precision": 0.94542,
            "recall": 0.93022,
            "fmeasure": 0.93163
        },
        "rougeLsum": {
            "precision": 0.94542,
            "recall": 0.93022,
            "fmeasure": 0.93163
        },
        "nist": 13.407293846084126,
        "bleu": 92.10852,
        "meteor": 0.6216178784743646,
        "bleurt": 0.4048,
        "nubia": {
            "semantic_relation": 4.53451,
            "contradiction": 1.84618,
            "irrelevancy": 14.26933,
            "logical_agreement": 83.88449,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.72492,
            "nubia_score": 0.80242
        },
        "bertscore": {
            "precision": 0.97898,
            "recall": 0.98008,
            "f1": 0.97819
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 1.5,
        "median_pred_length": 18.5,
        "min_pred_length": 17,
        "max_pred_length": 20,
        "distinct-1": 0.8108108108108109,
        "vocab_size-1": 30,
        "unique-1": 24,
        "entropy-1": 4.810672622327236,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.2842550085206872,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8387096774193549,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.607264455478377,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.21998899513525957,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8125
        },
        "rouge1": {
            "precision": 0.50376,
            "recall": 0.6801,
            "fmeasure": 0.57559
        },
        "rouge2": {
            "precision": 0.24359,
            "recall": 0.37238,
            "fmeasure": 0.29372
        },
        "rougeL": {
            "precision": 0.42419,
            "recall": 0.5522,
            "fmeasure": 0.47798
        },
        "rougeLsum": {
            "precision": 0.42419,
            "recall": 0.5522,
            "fmeasure": 0.47798
        },
        "nist": 2.609452189220726,
        "bleu": 10.48319,
        "meteor": 0.37040114085724174,
        "bleurt": -0.00478,
        "nubia": {
            "semantic_relation": 4.02669,
            "contradiction": 25.44607,
            "irrelevancy": 51.9506,
            "logical_agreement": 22.60333,
            "grammar_ref": 4.76014,
            "grammar_hyp": 3.76186,
            "nubia_score": 0.71951
        },
        "bertscore": {
            "precision": 0.8685,
            "recall": 0.92896,
            "f1": 0.89278
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 41,
        "mean_pred_length": 10.25,
        "std_pred_length": 3.112474899497183,
        "median_pred_length": 9.5,
        "min_pred_length": 7,
        "max_pred_length": 15,
        "distinct-1": 0.6585365853658537,
        "vocab_size-1": 27,
        "unique-1": 19,
        "entropy-1": 4.552197126358232,
        "distinct-2": 0.8918918918918919,
        "vocab_size-2": 33,
        "unique-2": 30,
        "entropy-2": 4.9728347844894,
        "cond_entropy-2": 0.2914868341592552,
        "distinct-3": 0.9393939393939394,
        "vocab_size-3": 31,
        "unique-3": 29,
        "entropy-3": 4.923181998146335,
        "cond_entropy-3": -0.08157780681099715,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 8.75,
        "std_pred_length-nopunct": 2.680951323690902,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.471581588126282,
        "distinct-2-nopunct": 0.9032258064516129,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.7362967135428935,
        "cond_entropy-2-nopunct": 0.24732418070152468,
        "distinct-3-nopunct": 0.9629629629629629,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.6808134280893965,
        "cond_entropy-3-nopunct": -0.14060649338188233,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.42857142857142855,
            "3": 0.7096774193548387
        },
        "rouge1": {
            "precision": 0.87751,
            "recall": 0.71949,
            "fmeasure": 0.77478
        },
        "rouge2": {
            "precision": 0.71313,
            "recall": 0.59599,
            "fmeasure": 0.63538
        },
        "rougeL": {
            "precision": 0.87751,
            "recall": 0.71949,
            "fmeasure": 0.77478
        },
        "rougeLsum": {
            "precision": 0.87751,
            "recall": 0.71949,
            "fmeasure": 0.77478
        },
        "nist": 3.2757600547739574,
        "bleu": 48.29718,
        "meteor": 0.39947621248855714,
        "bleurt": 0.44579,
        "nubia": {
            "semantic_relation": 4.32238,
            "contradiction": 0.40121,
            "irrelevancy": 24.55554,
            "logical_agreement": 75.04324,
            "grammar_ref": 4.09757,
            "grammar_hyp": 4.21896,
            "nubia_score": 0.85981
        },
        "bertscore": {
            "precision": 0.96127,
            "recall": 0.94203,
            "f1": 0.9511
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 4.205650960315181,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.7818181818181819,
        "vocab_size-1": 43,
        "unique-1": 34,
        "entropy-1": 5.29490721348532,
        "distinct-2": 0.9803921568627451,
        "vocab_size-2": 50,
        "unique-2": 49,
        "entropy-2": 5.63320965569699,
        "cond_entropy-2": 0.21959283437161012,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.07528329880449633,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 4.02336923485777,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8367346938775511,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.272773364479219,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.44740865188523,
        "cond_entropy-2-nopunct": 0.16058519670698793,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.10991084780915222,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6,
            "3": 0.5272727272727272
        },
        "rouge1": {
            "precision": 0.72784,
            "recall": 0.499,
            "fmeasure": 0.58875
        },
        "rouge2": {
            "precision": 0.44876,
            "recall": 0.29717,
            "fmeasure": 0.35597
        },
        "rougeL": {
            "precision": 0.62318,
            "recall": 0.43144,
            "fmeasure": 0.50811
        },
        "rougeLsum": {
            "precision": 0.62318,
            "recall": 0.43144,
            "fmeasure": 0.50811
        },
        "nist": 2.6602882496146183,
        "bleu": 24.33851,
        "meteor": 0.2503921048278331,
        "bleurt": -0.34991,
        "nubia": {
            "semantic_relation": 3.18996,
            "contradiction": 21.57472,
            "irrelevancy": 68.63742,
            "logical_agreement": 9.78787,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.33378,
            "nubia_score": 0.44982
        },
        "bertscore": {
            "precision": 0.89147,
            "recall": 0.82539,
            "f1": 0.85513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "t5-small/totto_test",
        "N": 31,
        "total_length": 459,
        "mean_pred_length": 14.806451612903226,
        "std_pred_length": 5.031637678880471,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5424836601307189,
        "vocab_size-1": 249,
        "unique-1": 197,
        "entropy-1": 7.11172058244644,
        "distinct-2": 0.8644859813084113,
        "vocab_size-2": 370,
        "unique-2": 342,
        "entropy-2": 8.3747295723226,
        "cond_entropy-2": 1.0558821097765976,
        "distinct-3": 0.9546599496221663,
        "vocab_size-3": 379,
        "unique-3": 367,
        "entropy-3": 8.530906217261414,
        "cond_entropy-3": 0.17977578810355804,
        "total_length-nopunct": 401,
        "mean_pred_length-nopunct": 12.935483870967742,
        "std_pred_length-nopunct": 4.428175797650896,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6059850374064838,
        "vocab_size-1-nopunct": 243,
        "unique-1-nopunct": 195,
        "entropy-1-nopunct": 7.260691113762036,
        "distinct-2-nopunct": 0.8513513513513513,
        "vocab_size-2-nopunct": 315,
        "unique-2-nopunct": 290,
        "entropy-2-nopunct": 8.12337169504176,
        "cond_entropy-2-nopunct": 0.9426563731757077,
        "distinct-3-nopunct": 0.9469026548672567,
        "vocab_size-3-nopunct": 321,
        "unique-3-nopunct": 309,
        "entropy-3-nopunct": 8.285585932124649,
        "cond_entropy-3-nopunct": 0.19189960648992294,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.5154639175257731,
            "3": 0.7315436241610739
        },
        "rouge1": {
            "precision": 0.75487,
            "recall": 0.69823,
            "fmeasure": 0.70493
        },
        "rouge2": {
            "precision": 0.48324,
            "recall": 0.44396,
            "fmeasure": 0.44823
        },
        "rougeL": {
            "precision": 0.60106,
            "recall": 0.54867,
            "fmeasure": 0.55654
        },
        "rougeLsum": {
            "precision": 0.60106,
            "recall": 0.54867,
            "fmeasure": 0.55654
        },
        "nist": 5.8860217425132895,
        "bleu": 36.61615,
        "meteor": 0.3585771086897737,
        "bleurt": 0.12039,
        "nubia": {
            "semantic_relation": 4.00316,
            "contradiction": 7.39319,
            "irrelevancy": 30.68572,
            "logical_agreement": 61.9211,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.45044,
            "nubia_score": 0.6732
        },
        "bertscore": {
            "precision": 0.91085,
            "recall": 0.90536,
            "f1": 0.9057
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 106,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 3.9440531887330774,
        "median_pred_length": 18.5,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.7641509433962265,
        "vocab_size-1": 81,
        "unique-1": 72,
        "entropy-1": 6.059110520699214,
        "distinct-2": 1.0,
        "vocab_size-2": 100,
        "unique-2": 100,
        "entropy-2": 6.6438561897747395,
        "cond_entropy-2": 0.48562614007127825,
        "distinct-3": 1.0,
        "vocab_size-3": 94,
        "unique-3": 94,
        "entropy-3": 6.554588851677623,
        "cond_entropy-3": -0.08926733809708727,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 15.833333333333334,
        "std_pred_length-nopunct": 3.7601713908928263,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8315789473684211,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.109072055585502,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 89,
        "entropy-2-nopunct": 6.47573343096641,
        "cond_entropy-2-nopunct": 0.3864894800603627,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.375039431346932,
        "cond_entropy-3-nopunct": -0.10069399961947309,
        "msttr-100": 0.78,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3018867924528302,
            "2": 0.5675675675675675,
            "3": 0.5476190476190477
        },
        "rouge1": {
            "precision": 0.59581,
            "recall": 0.56759,
            "fmeasure": 0.5669
        },
        "rouge2": {
            "precision": 0.32134,
            "recall": 0.29214,
            "fmeasure": 0.29576
        },
        "rougeL": {
            "precision": 0.39001,
            "recall": 0.3681,
            "fmeasure": 0.36794
        },
        "rougeLsum": {
            "precision": 0.39001,
            "recall": 0.3681,
            "fmeasure": 0.36794
        },
        "nist": 4.252457839184895,
        "bleu": 21.84444,
        "meteor": 0.3084279191310153,
        "bleurt": -0.19732,
        "nubia": {
            "semantic_relation": 3.89031,
            "contradiction": 4.43436,
            "irrelevancy": 53.634,
            "logical_agreement": 41.93164,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.9198,
            "nubia_score": 0.59339
        },
        "bertscore": {
            "precision": 0.88272,
            "recall": 0.88727,
            "f1": 0.88392
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6153846153846154,
            "2": 1.0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.67236,
            "fmeasure": 0.68695
        },
        "rouge2": {
            "precision": 0.64444,
            "recall": 0.60948,
            "fmeasure": 0.62346
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.45014,
            "fmeasure": 0.45166
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.45014,
            "fmeasure": 0.45166
        },
        "nist": 4.617647230689446,
        "bleu": 67.78396,
        "meteor": 0.44297773537248525,
        "bleurt": -0.4264,
        "nubia": {
            "semantic_relation": 2.79024,
            "contradiction": 0.23086,
            "irrelevancy": 64.44683,
            "logical_agreement": 35.32231,
            "grammar_ref": 4.13721,
            "grammar_hyp": 3.69524,
            "nubia_score": 0.41859
        },
        "bertscore": {
            "precision": 0.94157,
            "recall": 0.89045,
            "f1": 0.91529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.0,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.8125,
        "vocab_size-1": 26,
        "unique-1": 20,
        "entropy-1": 4.625,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.24022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.52164063634332,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.62652,
            "recall": 0.5582,
            "fmeasure": 0.57983
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.30635,
            "fmeasure": 0.32978
        },
        "rougeL": {
            "precision": 0.52273,
            "recall": 0.46279,
            "fmeasure": 0.48231
        },
        "rougeLsum": {
            "precision": 0.52273,
            "recall": 0.46279,
            "fmeasure": 0.48231
        },
        "nist": 3.6660730471004888,
        "bleu": 28.64868,
        "meteor": 0.30481734105910335,
        "bleurt": -0.19516,
        "nubia": {
            "semantic_relation": 3.69938,
            "contradiction": 42.40463,
            "irrelevancy": 7.80995,
            "logical_agreement": 49.78542,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.40139,
            "nubia_score": 0.56312
        },
        "bertscore": {
            "precision": 0.90831,
            "recall": 0.8838,
            "f1": 0.89588
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 36,
        "mean_pred_length": 12.0,
        "std_pred_length": 1.632993161855452,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.6111111111111112,
        "vocab_size-1": 22,
        "unique-1": 12,
        "entropy-1": 4.294653473544341,
        "distinct-2": 0.696969696969697,
        "vocab_size-2": 23,
        "unique-2": 13,
        "entropy-2": 4.438333513297848,
        "cond_entropy-2": 0.07916267858776119,
        "distinct-3": 0.7,
        "vocab_size-3": 21,
        "unique-3": 12,
        "entropy-3": 4.306890595608518,
        "cond_entropy-3": -0.13750352374993477,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.233639952626228,
        "distinct-2-nopunct": 0.7,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 4.306890595608518,
        "cond_entropy-2-nopunct": 0.08765939298884755,
        "distinct-3-nopunct": 0.7037037037037037,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 4.162294909570876,
        "cond_entropy-3-nopunct": -0.15200309344505003,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.2,
            "3": 0.6206896551724138
        },
        "rouge1": {
            "precision": 0.68543,
            "recall": 0.66447,
            "fmeasure": 0.67133
        },
        "rouge2": {
            "precision": 0.57906,
            "recall": 0.56061,
            "fmeasure": 0.56667
        },
        "rougeL": {
            "precision": 0.67749,
            "recall": 0.65521,
            "fmeasure": 0.66278
        },
        "rougeLsum": {
            "precision": 0.67749,
            "recall": 0.65521,
            "fmeasure": 0.66278
        },
        "nist": 3.9638672656473983,
        "bleu": 57.35114,
        "meteor": 0.4119854422201138,
        "bleurt": 0.05902,
        "nubia": {
            "semantic_relation": 3.81226,
            "contradiction": 0.79408,
            "irrelevancy": 53.07951,
            "logical_agreement": 46.12642,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.95969,
            "nubia_score": 0.58879
        },
        "bertscore": {
            "precision": 0.93821,
            "recall": 0.92111,
            "f1": 0.92939
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "nist": 4.01117167855772,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.77386,
        "nubia": {
            "semantic_relation": 4.66362,
            "contradiction": 2.49017,
            "irrelevancy": 1.24853,
            "logical_agreement": 96.2613,
            "grammar_ref": 6.06085,
            "grammar_hyp": 5.70692,
            "nubia_score": 0.90186
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 4.496912521077347,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.7169811320754716,
        "vocab_size-1": 38,
        "unique-1": 27,
        "entropy-1": 5.0864110206009325,
        "distinct-2": 0.86,
        "vocab_size-2": 43,
        "unique-2": 36,
        "entropy-2": 5.363856189774728,
        "cond_entropy-2": 0.25593573521152535,
        "distinct-3": 0.8936170212765957,
        "vocab_size-3": 42,
        "unique-3": 37,
        "entropy-3": 5.341822894230831,
        "cond_entropy-3": -0.004160955118363871,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 4.9216076867444665,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 5.0038561897747265,
        "distinct-2-nopunct": 0.851063829787234,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.256716511252108,
        "cond_entropy-2-nopunct": 0.25115819381780635,
        "distinct-3-nopunct": 0.8863636363636364,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.232158891364569,
        "cond_entropy-3-nopunct": -0.026975414858522118,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.3548387096774194,
            "3": 0.44
        },
        "rouge1": {
            "precision": 0.62395,
            "recall": 0.46238,
            "fmeasure": 0.52967
        },
        "rouge2": {
            "precision": 0.39186,
            "recall": 0.27712,
            "fmeasure": 0.32349
        },
        "rougeL": {
            "precision": 0.49605,
            "recall": 0.36154,
            "fmeasure": 0.41703
        },
        "rougeLsum": {
            "precision": 0.49605,
            "recall": 0.36154,
            "fmeasure": 0.41703
        },
        "nist": 2.066857205030884,
        "bleu": 21.45152,
        "meteor": 0.18846178184387632,
        "bleurt": -0.48006,
        "nubia": {
            "semantic_relation": 2.9999,
            "contradiction": 5.38279,
            "irrelevancy": 76.94613,
            "logical_agreement": 17.67108,
            "grammar_ref": 3.62435,
            "grammar_hyp": 3.19793,
            "nubia_score": 0.55188
        },
        "bertscore": {
            "precision": 0.84567,
            "recall": 0.80338,
            "f1": 0.82307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.7,
            "fmeasure": 0.65385
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "nist": 3.7574673462380614,
        "bleu": 65.8037,
        "meteor": 0.9555555555555555,
        "bleurt": 0.34708,
        "nubia": {
            "semantic_relation": 4.11383,
            "contradiction": 0.4147,
            "irrelevancy": 35.64603,
            "logical_agreement": 63.93928,
            "grammar_ref": 4.09688,
            "grammar_hyp": 3.81746,
            "nubia_score": 0.76218
        },
        "bertscore": {
            "precision": 0.97544,
            "recall": 0.97544,
            "f1": 0.97544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 4.109609335312651,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.7307692307692307,
        "vocab_size-1": 38,
        "unique-1": 30,
        "entropy-1": 5.056020968057884,
        "distinct-2": 0.9387755102040817,
        "vocab_size-2": 46,
        "unique-2": 43,
        "entropy-2": 5.492260864523372,
        "cond_entropy-2": 0.37865558520194237,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": 0.03928689455050026,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 3.681787005729087,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7659574468085106,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.985335926099693,
        "distinct-2-nopunct": 0.9318181818181818,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.323067982273659,
        "cond_entropy-2-nopunct": 0.37654475564519296,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": 0.044461849395420534,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.46153846153846156,
            "3": 0.6333333333333333
        },
        "rouge1": {
            "precision": 0.62687,
            "recall": 0.63095,
            "fmeasure": 0.62555
        },
        "rouge2": {
            "precision": 0.33434,
            "recall": 0.34191,
            "fmeasure": 0.33621
        },
        "rougeL": {
            "precision": 0.47107,
            "recall": 0.48718,
            "fmeasure": 0.4765
        },
        "rougeLsum": {
            "precision": 0.47107,
            "recall": 0.48718,
            "fmeasure": 0.4765
        },
        "nist": 4.0670686713603414,
        "bleu": 28.86594,
        "meteor": 0.3382466726454122,
        "bleurt": 0.26106,
        "nubia": {
            "semantic_relation": 4.05519,
            "contradiction": 0.44113,
            "irrelevancy": 67.52705,
            "logical_agreement": 32.03182,
            "grammar_ref": 4.38609,
            "grammar_hyp": 4.1875,
            "nubia_score": 0.70392
        },
        "bertscore": {
            "precision": 0.89384,
            "recall": 0.90428,
            "f1": 0.89876
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.559026084010437,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 35,
        "unique-1": 29,
        "entropy-1": 5.041010577489155,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.19449216793383345,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.1154772174199358,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 3.7712361663282534,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.003055907333277,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.209453365628954,
        "cond_entropy-2-nopunct": 0.2052249329622215,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.12199052437861026,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.2,
            "3": 0.6571428571428571
        },
        "rouge1": {
            "precision": 0.74444,
            "recall": 0.62562,
            "fmeasure": 0.65927
        },
        "rouge2": {
            "precision": 0.52328,
            "recall": 0.40778,
            "fmeasure": 0.44302
        },
        "rougeL": {
            "precision": 0.70972,
            "recall": 0.58133,
            "fmeasure": 0.62039
        },
        "rougeLsum": {
            "precision": 0.70972,
            "recall": 0.58133,
            "fmeasure": 0.62039
        },
        "nist": 3.8981711197649056,
        "bleu": 31.55532,
        "meteor": 0.34513478704427336,
        "bleurt": 0.04794,
        "nubia": {
            "semantic_relation": 3.96701,
            "contradiction": 5.67775,
            "irrelevancy": 26.26727,
            "logical_agreement": 68.05499,
            "grammar_ref": 5.35172,
            "grammar_hyp": 5.20656,
            "nubia_score": 0.61235
        },
        "bertscore": {
            "precision": 0.92275,
            "recall": 0.88865,
            "f1": 0.90465
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.229871195093384,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 21,
        "unique-2": 20,
        "entropy-2": 4.368522527728205,
        "cond_entropy-2": 0.15200091267862392,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.152391277629865,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": 0.15930901853019971,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": 0.029610672108601983,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.625
        },
        "rouge1": {
            "precision": 0.25,
            "recall": 0.6125,
            "fmeasure": 0.35417
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.18254,
            "fmeasure": 0.10238
        },
        "rougeL": {
            "precision": 0.13636,
            "recall": 0.3375,
            "fmeasure": 0.19375
        },
        "rougeLsum": {
            "precision": 0.13636,
            "recall": 0.3375,
            "fmeasure": 0.19375
        },
        "nist": 1.1209107451982452,
        "bleu": 5.92833,
        "meteor": 0.27782688481069445,
        "bleurt": 0.13236,
        "nubia": {
            "semantic_relation": 4.06292,
            "contradiction": 0.14712,
            "irrelevancy": 92.92119,
            "logical_agreement": 6.93168,
            "grammar_ref": 6.57359,
            "grammar_hyp": 3.86214,
            "nubia_score": 0.36207
        },
        "bertscore": {
            "precision": 0.74629,
            "recall": 0.87009,
            "f1": 0.79938
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.67879,
            "fmeasure": 0.65657
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.42963,
            "fmeasure": 0.41404
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.48485,
            "fmeasure": 0.46898
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.48485,
            "fmeasure": 0.46898
        },
        "nist": 2.341952406276728,
        "bleu": 24.08856,
        "meteor": 0.3865247114449327,
        "bleurt": -0.3268,
        "nubia": {
            "semantic_relation": 3.7924,
            "contradiction": 89.36158,
            "irrelevancy": 2.92805,
            "logical_agreement": 7.71037,
            "grammar_ref": 5.84412,
            "grammar_hyp": 6.17573,
            "nubia_score": 0.44478
        },
        "bertscore": {
            "precision": 0.92268,
            "recall": 0.93226,
            "f1": 0.9274
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 125,
        "mean_pred_length": 15.625,
        "std_pred_length": 3.2379584617471546,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.752,
        "vocab_size-1": 94,
        "unique-1": 85,
        "entropy-1": 6.200259608888407,
        "distinct-2": 0.9829059829059829,
        "vocab_size-2": 115,
        "unique-2": 113,
        "entropy-2": 6.836176685395351,
        "cond_entropy-2": 0.5087734645940606,
        "distinct-3": 1.0,
        "vocab_size-3": 109,
        "unique-3": 109,
        "entropy-3": 6.7681843247769145,
        "cond_entropy-3": -0.06548314710005626,
        "total_length-nopunct": 110,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 2.9047375096555625,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8363636363636363,
        "vocab_size-1-nopunct": 92,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.308276986094596,
        "distinct-2-nopunct": 0.9803921568627451,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.63320965569699,
        "cond_entropy-2-nopunct": 0.362037197243971,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 94,
        "entropy-3-nopunct": 6.554588851677623,
        "cond_entropy-3-nopunct": -0.07528329880449632,
        "msttr-100": 0.79,
        "msttr-100_nopunct": 0.87,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17073170731707318,
            "2": 0.36,
            "3": 0.7971014492753623
        },
        "rouge1": {
            "precision": 0.68079,
            "recall": 0.68805,
            "fmeasure": 0.67621
        },
        "rouge2": {
            "precision": 0.38714,
            "recall": 0.3766,
            "fmeasure": 0.37885
        },
        "rougeL": {
            "precision": 0.54504,
            "recall": 0.53454,
            "fmeasure": 0.53424
        },
        "rougeLsum": {
            "precision": 0.54504,
            "recall": 0.53454,
            "fmeasure": 0.53424
        },
        "nist": 4.826904082265843,
        "bleu": 29.30242,
        "meteor": 0.323814093585282,
        "bleurt": -0.03839,
        "nubia": {
            "semantic_relation": 3.4159,
            "contradiction": 11.61285,
            "irrelevancy": 48.71808,
            "logical_agreement": 39.66908,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.70534,
            "nubia_score": 0.51345
        },
        "bertscore": {
            "precision": 0.89111,
            "recall": 0.90005,
            "f1": 0.89373
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.179449471770337,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 16,
        "distinct-1": 0.7962962962962963,
        "vocab_size-1": 43,
        "unique-1": 37,
        "entropy-1": 5.268504863154386,
        "distinct-2": 0.96,
        "vocab_size-2": 48,
        "unique-2": 46,
        "entropy-2": 5.563856189774728,
        "cond_entropy-2": 0.17426193774106402,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.03333771197858132,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.8708286933869707,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8541666666666666,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.246115365169276,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.368522527728205,
        "cond_entropy-2-nopunct": 0.15321144760910488,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.4,
            "3": 0.5535714285714286
        },
        "rouge1": {
            "precision": 0.80413,
            "recall": 0.65653,
            "fmeasure": 0.69881
        },
        "rouge2": {
            "precision": 0.64931,
            "recall": 0.5619,
            "fmeasure": 0.58365
        },
        "rougeL": {
            "precision": 0.68162,
            "recall": 0.59933,
            "fmeasure": 0.62151
        },
        "rougeLsum": {
            "precision": 0.68162,
            "recall": 0.59933,
            "fmeasure": 0.62151
        },
        "nist": 3.3539367596298404,
        "bleu": 51.03744,
        "meteor": 0.3247654769718166,
        "bleurt": 0.21588,
        "nubia": {
            "semantic_relation": 3.96997,
            "contradiction": 2.06607,
            "irrelevancy": 30.3901,
            "logical_agreement": 67.54383,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.50136,
            "nubia_score": 0.68773
        },
        "bertscore": {
            "precision": 0.92165,
            "recall": 0.85711,
            "f1": 0.88511
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "t5-small/totto_test",
        "N": 15,
        "total_length": 232,
        "mean_pred_length": 15.466666666666667,
        "std_pred_length": 4.828618389928485,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.5732758620689655,
        "vocab_size-1": 133,
        "unique-1": 101,
        "entropy-1": 6.503782300073724,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 186,
        "unique-2": 164,
        "entropy-2": 7.440010045758694,
        "cond_entropy-2": 0.803542326744735,
        "distinct-3": 0.9207920792079208,
        "vocab_size-3": 186,
        "unique-3": 172,
        "entropy-3": 7.49232150748282,
        "cond_entropy-3": 0.06628729241865408,
        "total_length-nopunct": 206,
        "mean_pred_length-nopunct": 13.733333333333333,
        "std_pred_length-nopunct": 4.567518168789504,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6262135922330098,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.552815789786737,
        "distinct-2-nopunct": 0.8638743455497382,
        "vocab_size-2-nopunct": 165,
        "unique-2-nopunct": 148,
        "entropy-2-nopunct": 7.264473657822045,
        "cond_entropy-2-nopunct": 0.7662144573558648,
        "distinct-3-nopunct": 0.9318181818181818,
        "vocab_size-3-nopunct": 164,
        "unique-3-nopunct": 154,
        "entropy-3-nopunct": 7.31448971520363,
        "cond_entropy-3-nopunct": 0.0653247366611533,
        "msttr-100": 0.655,
        "msttr-100_nopunct": 0.685,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18571428571428572,
            "2": 0.2375,
            "3": 0.6257309941520468
        },
        "rouge1": {
            "precision": 0.69284,
            "recall": 0.57065,
            "fmeasure": 0.61687
        },
        "rouge2": {
            "precision": 0.40606,
            "recall": 0.33777,
            "fmeasure": 0.36243
        },
        "rougeL": {
            "precision": 0.59024,
            "recall": 0.49568,
            "fmeasure": 0.53104
        },
        "rougeLsum": {
            "precision": 0.59024,
            "recall": 0.49568,
            "fmeasure": 0.53104
        },
        "nist": 4.437939512342775,
        "bleu": 34.3634,
        "meteor": 0.3115053216579338,
        "bleurt": -0.11546,
        "nubia": {
            "semantic_relation": 3.60027,
            "contradiction": 2.08452,
            "irrelevancy": 61.09089,
            "logical_agreement": 36.82459,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.59326,
            "nubia_score": 0.53679
        },
        "bertscore": {
            "precision": 0.88174,
            "recall": 0.87108,
            "f1": 0.8751
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "t5-small/totto_test",
        "N": 12,
        "total_length": 192,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.760952285695233,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.625,
        "vocab_size-1": 120,
        "unique-1": 88,
        "entropy-1": 6.479166329478072,
        "distinct-2": 0.9388888888888889,
        "vocab_size-2": 169,
        "unique-2": 158,
        "entropy-2": 7.369630874107439,
        "cond_entropy-2": 0.786976773523453,
        "distinct-3": 0.9880952380952381,
        "vocab_size-3": 166,
        "unique-3": 164,
        "entropy-3": 7.368507898969267,
        "cond_entropy-3": 0.007607183591942738,
        "total_length-nopunct": 172,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 4.189935029992178,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6686046511627907,
        "vocab_size-1-nopunct": 115,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.4757767113569376,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 150,
        "unique-2-nopunct": 140,
        "entropy-2-nopunct": 7.196928094887367,
        "cond_entropy-2-nopunct": 0.7736879867812898,
        "distinct-3-nopunct": 0.9864864864864865,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 144,
        "entropy-3-nopunct": 7.182426338601919,
        "cond_entropy-3-nopunct": -0.004366621150304541,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36666666666666664,
            "2": 0.3870967741935484,
            "3": 0.6793893129770993
        },
        "rouge1": {
            "precision": 0.68293,
            "recall": 0.67177,
            "fmeasure": 0.66142
        },
        "rouge2": {
            "precision": 0.50261,
            "recall": 0.50195,
            "fmeasure": 0.48947
        },
        "rougeL": {
            "precision": 0.60602,
            "recall": 0.60263,
            "fmeasure": 0.59036
        },
        "rougeLsum": {
            "precision": 0.60602,
            "recall": 0.60263,
            "fmeasure": 0.59036
        },
        "nist": 5.2398246949197524,
        "bleu": 44.19679,
        "meteor": 0.3673410411072389,
        "bleurt": 0.05068,
        "nubia": {
            "semantic_relation": 3.78814,
            "contradiction": 16.01527,
            "irrelevancy": 40.38544,
            "logical_agreement": 43.5993,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.68131,
            "nubia_score": 0.57959
        },
        "bertscore": {
            "precision": 0.91042,
            "recall": 0.91257,
            "f1": 0.9107
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.8974358974358975,
        "vocab_size-1": 35,
        "unique-1": 32,
        "entropy-1": 5.060917923934978,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 35,
        "unique-2": 34,
        "entropy-2": 5.114369445886754,
        "cond_entropy-2": -0.05992166186438031,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.06492482147779849,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9393939393939394,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.923181998146335,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.840223928941852,
        "cond_entropy-2-nopunct": -0.07083685708326806,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.07792901937097599,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.8
        },
        "rouge1": {
            "precision": 0.64722,
            "recall": 0.59947,
            "fmeasure": 0.59207
        },
        "rouge2": {
            "precision": 0.45406,
            "recall": 0.41762,
            "fmeasure": 0.41098
        },
        "rougeL": {
            "precision": 0.56944,
            "recall": 0.54905,
            "fmeasure": 0.53089
        },
        "rougeLsum": {
            "precision": 0.56944,
            "recall": 0.54905,
            "fmeasure": 0.53089
        },
        "nist": 4.037083738271257,
        "bleu": 41.24842,
        "meteor": 0.34317845737154745,
        "bleurt": -0.16529,
        "nubia": {
            "semantic_relation": 3.44157,
            "contradiction": 31.41679,
            "irrelevancy": 51.10601,
            "logical_agreement": 17.4772,
            "grammar_ref": 5.06451,
            "grammar_hyp": 4.9392,
            "nubia_score": 0.55349
        },
        "bertscore": {
            "precision": 0.90304,
            "recall": 0.91286,
            "f1": 0.90623
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.63346,
            "fmeasure": 0.72777
        },
        "rouge2": {
            "precision": 0.61905,
            "recall": 0.44444,
            "fmeasure": 0.51423
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.28571,
            "fmeasure": 0.37209
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.28571,
            "fmeasure": 0.37209
        },
        "nist": 1.4636263314821116,
        "bleu": 39.9718,
        "meteor": 0.4106546058855635,
        "bleurt": -0.37725,
        "nubia": {
            "semantic_relation": 3.76725,
            "contradiction": 86.89297,
            "irrelevancy": 12.12524,
            "logical_agreement": 0.98179,
            "grammar_ref": 3.99891,
            "grammar_hyp": 6.72743,
            "nubia_score": 0.29242
        },
        "bertscore": {
            "precision": 0.96606,
            "recall": 0.94103,
            "f1": 0.95338
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 41,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.8048780487804879,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.9001157240775095,
        "distinct-2": 0.9736842105263158,
        "vocab_size-2": 37,
        "unique-2": 36,
        "entropy-2": 5.19529593449622,
        "cond_entropy-2": 0.20616498250971246,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.06150163935576179,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8378378378378378,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.831074987250575,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.028639311838574,
        "cond_entropy-2-nopunct": 0.23095065209197801,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.06875040183120604,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7,
            "2": 0.6666666666666666,
            "3": 0.7727272727272727
        },
        "rouge1": {
            "precision": 0.73822,
            "recall": 0.81685,
            "fmeasure": 0.76296
        },
        "rouge2": {
            "precision": 0.44978,
            "recall": 0.50529,
            "fmeasure": 0.46648
        },
        "rougeL": {
            "precision": 0.50875,
            "recall": 0.62462,
            "fmeasure": 0.55231
        },
        "rougeLsum": {
            "precision": 0.50875,
            "recall": 0.62462,
            "fmeasure": 0.55231
        },
        "nist": 4.068598348217605,
        "bleu": 37.55766,
        "meteor": 0.3793504895801101,
        "bleurt": 0.30073,
        "nubia": {
            "semantic_relation": 4.24313,
            "contradiction": 1.55941,
            "irrelevancy": 31.21764,
            "logical_agreement": 67.22295,
            "grammar_ref": 5.1114,
            "grammar_hyp": 4.46383,
            "nubia_score": 0.75292
        },
        "bertscore": {
            "precision": 0.93567,
            "recall": 0.93889,
            "f1": 0.93656
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 97,
        "mean_pred_length": 16.166666666666668,
        "std_pred_length": 3.0230595245361758,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.6804123711340206,
        "vocab_size-1": 66,
        "unique-1": 51,
        "entropy-1": 5.757143708559769,
        "distinct-2": 0.9120879120879121,
        "vocab_size-2": 83,
        "unique-2": 75,
        "entropy-2": 6.331970464374528,
        "cond_entropy-2": 0.4599568634789033,
        "distinct-3": 0.9529411764705882,
        "vocab_size-3": 81,
        "unique-3": 77,
        "entropy-3": 6.315273289078882,
        "cond_entropy-3": -0.027815468766876794,
        "total_length-nopunct": 86,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 3.2489314482696545,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7209302325581395,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.711335179639726,
        "distinct-2-nopunct": 0.9125,
        "vocab_size-2-nopunct": 73,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.146928094887357,
        "cond_entropy-2-nopunct": 0.4517126333773148,
        "distinct-3-nopunct": 0.9594594594594594,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.128372284547875,
        "cond_entropy-3-nopunct": -0.04490716169084516,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.375,
            "3": 0.7361111111111112
        },
        "rouge1": {
            "precision": 0.74747,
            "recall": 0.70263,
            "fmeasure": 0.71114
        },
        "rouge2": {
            "precision": 0.55112,
            "recall": 0.5237,
            "fmeasure": 0.52492
        },
        "rougeL": {
            "precision": 0.66701,
            "recall": 0.62612,
            "fmeasure": 0.63511
        },
        "rougeLsum": {
            "precision": 0.66701,
            "recall": 0.62612,
            "fmeasure": 0.63511
        },
        "nist": 5.010360865401809,
        "bleu": 45.79969,
        "meteor": 0.3761618396698168,
        "bleurt": 0.17267,
        "nubia": {
            "semantic_relation": 4.02062,
            "contradiction": 21.39661,
            "irrelevancy": 48.78786,
            "logical_agreement": 29.81553,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.38372,
            "nubia_score": 0.6926
        },
        "bertscore": {
            "precision": 0.92428,
            "recall": 0.92242,
            "f1": 0.92281
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 71,
        "mean_pred_length": 17.75,
        "std_pred_length": 2.7726341266023544,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 20,
        "distinct-1": 0.6901408450704225,
        "vocab_size-1": 49,
        "unique-1": 36,
        "entropy-1": 5.401586338113639,
        "distinct-2": 0.9552238805970149,
        "vocab_size-2": 64,
        "unique-2": 61,
        "entropy-2": 5.976536951651798,
        "cond_entropy-2": 0.5486484586635425,
        "distinct-3": 0.9841269841269841,
        "vocab_size-3": 62,
        "unique-3": 61,
        "entropy-3": 5.945533891753889,
        "cond_entropy-3": -0.057063235211824284,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 2.947456530637899,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.315729886716714,
        "distinct-2-nopunct": 0.9803921568627451,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.63320965569699,
        "cond_entropy-2-nopunct": 0.3147840691220678,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.11783649029385802,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.5333333333333333,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.71262,
            "recall": 0.7151,
            "fmeasure": 0.7059
        },
        "rouge2": {
            "precision": 0.50093,
            "recall": 0.50996,
            "fmeasure": 0.49855
        },
        "rougeL": {
            "precision": 0.63946,
            "recall": 0.64156,
            "fmeasure": 0.63375
        },
        "rougeLsum": {
            "precision": 0.63946,
            "recall": 0.64156,
            "fmeasure": 0.63375
        },
        "nist": 5.169314479505472,
        "bleu": 51.12255,
        "meteor": 0.4121180424640995,
        "bleurt": -0.01831,
        "nubia": {
            "semantic_relation": 3.8403,
            "contradiction": 15.84754,
            "irrelevancy": 57.06585,
            "logical_agreement": 27.08661,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.5495,
            "nubia_score": 0.61782
        },
        "bertscore": {
            "precision": 0.92811,
            "recall": 0.93296,
            "f1": 0.92758
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "t5-small/totto_test",
        "N": 13,
        "total_length": 203,
        "mean_pred_length": 15.615384615384615,
        "std_pred_length": 4.197773430659154,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.6059113300492611,
        "vocab_size-1": 123,
        "unique-1": 99,
        "entropy-1": 6.389519122023311,
        "distinct-2": 0.9263157894736842,
        "vocab_size-2": 176,
        "unique-2": 168,
        "entropy-2": 7.37824312434903,
        "cond_entropy-2": 0.8526767961634498,
        "distinct-3": 0.9830508474576272,
        "vocab_size-3": 174,
        "unique-3": 171,
        "entropy-3": 7.433707244998264,
        "cond_entropy-3": 0.0695373539360419,
        "total_length-nopunct": 174,
        "mean_pred_length-nopunct": 13.384615384615385,
        "std_pred_length-nopunct": 3.5418044409911813,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6781609195402298,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.508068263087805,
        "distinct-2-nopunct": 0.9254658385093167,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 143,
        "entropy-2-nopunct": 7.1296350647197775,
        "cond_entropy-2-nopunct": 0.6659977210474536,
        "distinct-3-nopunct": 0.9864864864864865,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 144,
        "entropy-3-nopunct": 7.182426338601919,
        "cond_entropy-3-nopunct": 0.07047143316681045,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1388888888888889,
            "2": 0.058823529411764705,
            "3": 0.7908496732026143
        },
        "rouge1": {
            "precision": 0.74669,
            "recall": 0.7527,
            "fmeasure": 0.74601
        },
        "rouge2": {
            "precision": 0.5471,
            "recall": 0.55419,
            "fmeasure": 0.54797
        },
        "rougeL": {
            "precision": 0.61423,
            "recall": 0.61991,
            "fmeasure": 0.61401
        },
        "rougeLsum": {
            "precision": 0.61423,
            "recall": 0.61991,
            "fmeasure": 0.61401
        },
        "nist": 5.45598837961968,
        "bleu": 45.30732,
        "meteor": 0.4147269286448833,
        "bleurt": 0.42511,
        "nubia": {
            "semantic_relation": 4.38233,
            "contradiction": 8.49805,
            "irrelevancy": 34.12866,
            "logical_agreement": 57.37329,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.89102,
            "nubia_score": 0.77163
        },
        "bertscore": {
            "precision": 0.94019,
            "recall": 0.94093,
            "f1": 0.94037
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "t5-small/totto_test",
        "N": 898,
        "total_length": 10065,
        "mean_pred_length": 11.208240534521158,
        "std_pred_length": 3.5027922396906632,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 24,
        "distinct-1": 0.33154495777446596,
        "vocab_size-1": 3337,
        "unique-1": 2534,
        "entropy-1": 9.00523935203853,
        "distinct-2": 0.6695756517944802,
        "vocab_size-2": 6138,
        "unique-2": 5319,
        "entropy-2": 11.82576040430384,
        "cond_entropy-2": 2.2957189825981863,
        "distinct-3": 0.8202926593300278,
        "vocab_size-3": 6783,
        "unique-3": 6163,
        "entropy-3": 12.461180453448819,
        "cond_entropy-3": 0.6122472348662275,
        "total_length-nopunct": 8733,
        "mean_pred_length-nopunct": 9.724944320712694,
        "std_pred_length-nopunct": 3.099152346071486,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.3805107065155159,
        "vocab_size-1-nopunct": 3323,
        "unique-1-nopunct": 2530,
        "entropy-1-nopunct": 9.473408388138676,
        "distinct-2-nopunct": 0.6936821952776006,
        "vocab_size-2-nopunct": 5435,
        "unique-2-nopunct": 4771,
        "entropy-2-nopunct": 11.677198492283086,
        "cond_entropy-2-nopunct": 2.4020557104653806,
        "distinct-3-nopunct": 0.8309067320167219,
        "vocab_size-3-nopunct": 5764,
        "unique-3-nopunct": 5263,
        "entropy-3-nopunct": 12.244706865410585,
        "cond_entropy-3-nopunct": 0.6484223828145916,
        "msttr-100": 0.7025,
        "msttr-100_nopunct": 0.75414,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2641660015961692,
            "2": 0.51954513148543,
            "3": 0.7344183465877566
        },
        "rouge1": {
            "precision": 0.72624,
            "recall": 0.71116,
            "fmeasure": 0.70321
        },
        "rouge2": {
            "precision": 0.5277,
            "recall": 0.51647,
            "fmeasure": 0.5101
        },
        "rougeL": {
            "precision": 0.68332,
            "recall": 0.6711,
            "fmeasure": 0.66262
        },
        "rougeLsum": {
            "precision": 0.68332,
            "recall": 0.6711,
            "fmeasure": 0.66262
        },
        "nist": 8.49132354703646,
        "bleu": 46.78195,
        "meteor": 0.3936108609172009,
        "bleurt": 0.26718,
        "nubia": {
            "semantic_relation": 4.05002,
            "contradiction": 8.4781,
            "irrelevancy": 35.63768,
            "logical_agreement": 55.88422,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.07841,
            "nubia_score": 0.68911
        },
        "bertscore": {
            "precision": 0.92381,
            "recall": 0.92359,
            "f1": 0.92211
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.25
        },
        "rouge1": {
            "precision": 0.38889,
            "recall": 0.30952,
            "fmeasure": 0.34058
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.16667,
            "recall": 0.12698,
            "fmeasure": 0.14251
        },
        "rougeLsum": {
            "precision": 0.16667,
            "recall": 0.12698,
            "fmeasure": 0.14251
        },
        "nist": 1.0958217071212617,
        "bleu": 5.36949,
        "meteor": 0.11405295315682283,
        "bleurt": -0.63161,
        "nubia": {
            "semantic_relation": 3.22868,
            "contradiction": 2.51379,
            "irrelevancy": 37.69781,
            "logical_agreement": 59.78839,
            "grammar_ref": 5.77141,
            "grammar_hyp": 6.61666,
            "nubia_score": 0.30385
        },
        "bertscore": {
            "precision": 0.83787,
            "recall": 0.84454,
            "f1": 0.84119
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.14286,
            "fmeasure": 0.16667
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42857
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42857
        },
        "nist": 1.7348945401754292,
        "bleu": 12.41126,
        "meteor": 0.27192580624145596,
        "bleurt": 0.63607,
        "nubia": {
            "semantic_relation": 4.82578,
            "contradiction": 0.49509,
            "irrelevancy": 0.55922,
            "logical_agreement": 98.9457,
            "grammar_ref": 5.02153,
            "grammar_hyp": 5.19789,
            "nubia_score": 0.91859
        },
        "bertscore": {
            "precision": 0.96134,
            "recall": 0.91461,
            "f1": 0.93739
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7720,
        "mean_pred_length": 21.5041782729805,
        "std_pred_length": 9.340322585225518,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37176165803108807,
        "vocab_size-1": 2870,
        "unique-1": 2100,
        "entropy-1": 9.235158439326643,
        "distinct-2": 0.847167504415161,
        "vocab_size-2": 6236,
        "unique-2": 5774,
        "entropy-2": 12.327123665919075,
        "cond_entropy-2": 2.8572508020756424,
        "distinct-3": 0.9802913453299057,
        "vocab_size-3": 6864,
        "unique-3": 6757,
        "entropy-3": 12.729865603577442,
        "cond_entropy-3": 0.41443290245541875,
        "total_length-nopunct": 6952,
        "mean_pred_length-nopunct": 19.364902506963787,
        "std_pred_length-nopunct": 8.474966868997573,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.411536248561565,
        "vocab_size-1-nopunct": 2861,
        "unique-1-nopunct": 2098,
        "entropy-1-nopunct": 9.594839877948008,
        "distinct-2-nopunct": 0.8651600182011224,
        "vocab_size-2-nopunct": 5704,
        "unique-2-nopunct": 5328,
        "entropy-2-nopunct": 12.234578669854612,
        "cond_entropy-2-nopunct": 2.760495991752104,
        "distinct-3-nopunct": 0.9847609881296118,
        "vocab_size-3-nopunct": 6139,
        "unique-3-nopunct": 6062,
        "entropy-3-nopunct": 12.572833099233705,
        "cond_entropy-3-nopunct": 0.35825618548419247,
        "msttr-100": 0.72571,
        "msttr-100_nopunct": 0.76884,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.012521222410865875,
            "2": 0.19029374201787994,
            "3": 0.6061269146608315,
            "4": 0.8573692551505546,
            "5": 0.9293873312564901,
            "6": 0.9468599033816425,
            "7": 0.9618174875906834
        },
        "rouge1": {
            "precision": 0.94971,
            "recall": 0.93391,
            "fmeasure": 0.93572
        },
        "rouge2": {
            "precision": 0.90141,
            "recall": 0.88358,
            "fmeasure": 0.88555
        },
        "rougeL": {
            "precision": 0.94542,
            "recall": 0.93022,
            "fmeasure": 0.93163
        },
        "rougeLsum": {
            "precision": 0.94542,
            "recall": 0.93022,
            "fmeasure": 0.93163
        },
        "nist": 13.407293846084126,
        "bleu": 92.10852,
        "meteor": 0.6216178784743646,
        "bleurt": 0.4048,
        "nubia": {
            "semantic_relation": 4.53451,
            "contradiction": 1.84618,
            "irrelevancy": 14.26933,
            "logical_agreement": 83.88449,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.72492,
            "nubia_score": 0.80242
        },
        "bertscore": {
            "precision": 0.97898,
            "recall": 0.98008,
            "f1": 0.97819
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 133,
        "mean_pred_length": 19.0,
        "std_pred_length": 3.070597894314954,
        "median_pred_length": 20.0,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.6240601503759399,
        "vocab_size-1": 83,
        "unique-1": 63,
        "entropy-1": 6.013608800303258,
        "distinct-2": 0.9126984126984127,
        "vocab_size-2": 115,
        "unique-2": 104,
        "entropy-2": 6.802676748896751,
        "cond_entropy-2": 0.7238452536891926,
        "distinct-3": 0.9663865546218487,
        "vocab_size-3": 115,
        "unique-3": 111,
        "entropy-3": 6.82759087255164,
        "cond_entropy-3": 0.035184898631556424,
        "total_length-nopunct": 120,
        "mean_pred_length-nopunct": 17.142857142857142,
        "std_pred_length-nopunct": 3.313546715640915,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6583333333333333,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.978364112253845,
        "distinct-2-nopunct": 0.911504424778761,
        "vocab_size-2-nopunct": 103,
        "unique-2-nopunct": 93,
        "entropy-2-nopunct": 6.643187811972727,
        "cond_entropy-2-nopunct": 0.6840958881135243,
        "distinct-3-nopunct": 0.9622641509433962,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 98,
        "entropy-3-nopunct": 6.652448756449977,
        "cond_entropy-3-nopunct": 0.002081114789521072,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.6571428571428571,
            "3": 0.7971014492753623
        },
        "rouge1": {
            "precision": 0.70154,
            "recall": 0.69492,
            "fmeasure": 0.6844
        },
        "rouge2": {
            "precision": 0.53476,
            "recall": 0.4823,
            "fmeasure": 0.49605
        },
        "rougeL": {
            "precision": 0.62872,
            "recall": 0.63069,
            "fmeasure": 0.61678
        },
        "rougeLsum": {
            "precision": 0.62872,
            "recall": 0.63069,
            "fmeasure": 0.61678
        },
        "nist": 4.998781460277319,
        "bleu": 49.56058,
        "meteor": 0.3980972623819844,
        "bleurt": -0.01371,
        "nubia": {
            "semantic_relation": 4.10549,
            "contradiction": 17.11553,
            "irrelevancy": 32.37345,
            "logical_agreement": 50.51102,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.46458,
            "nubia_score": 0.7027
        },
        "bertscore": {
            "precision": 0.90678,
            "recall": 0.90428,
            "f1": 0.90432
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.69444,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.49091,
            "fmeasure": 0.525
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.69444,
            "fmeasure": 0.74074
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.69444,
            "fmeasure": 0.74074
        },
        "nist": 1.538908000241871,
        "bleu": 43.79519,
        "meteor": 0.3757823391575132,
        "bleurt": 0.15432,
        "nubia": {
            "semantic_relation": 3.76313,
            "contradiction": 0.3354,
            "irrelevancy": 33.93768,
            "logical_agreement": 65.72692,
            "grammar_ref": 6.47099,
            "grammar_hyp": 6.82895,
            "nubia_score": 0.61026
        },
        "bertscore": {
            "precision": 0.95219,
            "recall": 0.91486,
            "f1": 0.93316
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.5,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 21,
        "entropy-1": 4.483856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.03333771197858132,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.90456,
            "recall": 0.71832,
            "fmeasure": 0.78902
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.60027,
            "fmeasure": 0.65639
        },
        "rougeL": {
            "precision": 0.75641,
            "recall": 0.6326,
            "fmeasure": 0.68032
        },
        "rougeLsum": {
            "precision": 0.75641,
            "recall": 0.6326,
            "fmeasure": 0.68032
        },
        "nist": 3.769939907211563,
        "bleu": 56.92685,
        "meteor": 0.4066915449568284,
        "bleurt": 0.47164,
        "nubia": {
            "semantic_relation": 4.34867,
            "contradiction": 0.41316,
            "irrelevancy": 0.59089,
            "logical_agreement": 98.99596,
            "grammar_ref": 5.26806,
            "grammar_hyp": 4.87232,
            "nubia_score": 0.78925
        },
        "bertscore": {
            "precision": 0.9754,
            "recall": 0.93627,
            "f1": 0.95517
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 91,
        "mean_pred_length": 15.166666666666666,
        "std_pred_length": 4.597704741377907,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.7362637362637363,
        "vocab_size-1": 67,
        "unique-1": 57,
        "entropy-1": 5.809071465193493,
        "distinct-2": 0.9764705882352941,
        "vocab_size-2": 83,
        "unique-2": 81,
        "entropy-2": 6.3623321126082955,
        "cond_entropy-2": 0.4933150788322351,
        "distinct-3": 1.0,
        "vocab_size-3": 79,
        "unique-3": 79,
        "entropy-3": 6.303780748177105,
        "cond_entropy-3": -0.05497727656819368,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 12.166666666666666,
        "std_pred_length-nopunct": 4.2196629670573875,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.863013698630137,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.8560639016663245,
        "distinct-2-nopunct": 0.9850746268656716,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.0362384441891095,
        "cond_entropy-2-nopunct": 0.21006355660164033,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.930737337562883,
        "cond_entropy-3-nopunct": -0.10256496764898455,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.16666666666666666,
            "3": 0.44155844155844154
        },
        "rouge1": {
            "precision": 0.6634,
            "recall": 0.43358,
            "fmeasure": 0.50398
        },
        "rouge2": {
            "precision": 0.33788,
            "recall": 0.21344,
            "fmeasure": 0.2522
        },
        "rougeL": {
            "precision": 0.5671,
            "recall": 0.38415,
            "fmeasure": 0.4443
        },
        "rougeLsum": {
            "precision": 0.5671,
            "recall": 0.38415,
            "fmeasure": 0.4443
        },
        "nist": 2.6400186661513407,
        "bleu": 15.90342,
        "meteor": 0.2290504428552557,
        "bleurt": -0.12755,
        "nubia": {
            "semantic_relation": 3.55185,
            "contradiction": 17.16467,
            "irrelevancy": 33.84244,
            "logical_agreement": 48.99289,
            "grammar_ref": 4.85958,
            "grammar_hyp": 5.21093,
            "nubia_score": 0.46142
        },
        "bertscore": {
            "precision": 0.88685,
            "recall": 0.86613,
            "f1": 0.87323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.5291
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "nist": 0.9472807507835431,
        "bleu": 47.87975,
        "meteor": 0.4180407844493463,
        "bleurt": 0.78138,
        "nubia": {
            "semantic_relation": 4.92558,
            "contradiction": 0.44819,
            "irrelevancy": 0.47684,
            "logical_agreement": 99.07497,
            "grammar_ref": 3.61542,
            "grammar_hyp": 4.58816,
            "nubia_score": 0.99864
        },
        "bertscore": {
            "precision": 0.9769,
            "recall": 0.93775,
            "f1": 0.95692
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "t5-small/totto_test",
        "N": 12,
        "total_length": 178,
        "mean_pred_length": 14.833333333333334,
        "std_pred_length": 4.524623986832743,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6573033707865169,
        "vocab_size-1": 117,
        "unique-1": 103,
        "entropy-1": 6.322105996383946,
        "distinct-2": 0.9457831325301205,
        "vocab_size-2": 157,
        "unique-2": 151,
        "entropy-2": 7.252963151187328,
        "cond_entropy-2": 0.792539599173226,
        "distinct-3": 1.0,
        "vocab_size-3": 154,
        "unique-3": 154,
        "entropy-3": 7.2667865406949215,
        "cond_entropy-3": 0.023335826922589564,
        "total_length-nopunct": 155,
        "mean_pred_length-nopunct": 12.916666666666666,
        "std_pred_length-nopunct": 4.2122506520333705,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7225806451612903,
        "vocab_size-1-nopunct": 112,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.3625948737012274,
        "distinct-2-nopunct": 0.951048951048951,
        "vocab_size-2-nopunct": 136,
        "unique-2-nopunct": 132,
        "entropy-2-nopunct": 7.04613243813161,
        "cond_entropy-2-nopunct": 0.7351277174244824,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 131,
        "unique-3-nopunct": 131,
        "entropy-3-nopunct": 7.03342300153745,
        "cond_entropy-3-nopunct": -0.0022906061837604285,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.3225806451612903,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.61991,
            "recall": 0.62365,
            "fmeasure": 0.60669
        },
        "rouge2": {
            "precision": 0.43199,
            "recall": 0.44532,
            "fmeasure": 0.42735
        },
        "rougeL": {
            "precision": 0.56648,
            "recall": 0.57816,
            "fmeasure": 0.55766
        },
        "rougeLsum": {
            "precision": 0.56648,
            "recall": 0.57816,
            "fmeasure": 0.55766
        },
        "nist": 4.6125525346703915,
        "bleu": 35.12974,
        "meteor": 0.3431465756973758,
        "bleurt": 0.02591,
        "nubia": {
            "semantic_relation": 3.62766,
            "contradiction": 22.00354,
            "irrelevancy": 35.22606,
            "logical_agreement": 42.7704,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.49626,
            "nubia_score": 0.5821
        },
        "bertscore": {
            "precision": 0.89445,
            "recall": 0.90279,
            "f1": 0.89393
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 106,
        "mean_pred_length": 15.142857142857142,
        "std_pred_length": 5.026460595931194,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.7641509433962265,
        "vocab_size-1": 81,
        "unique-1": 72,
        "entropy-1": 6.032549314323819,
        "distinct-2": 0.98989898989899,
        "vocab_size-2": 98,
        "unique-2": 97,
        "entropy-2": 6.609154599877599,
        "cond_entropy-2": 0.4272730989605511,
        "distinct-3": 1.0,
        "vocab_size-3": 92,
        "unique-3": 92,
        "entropy-3": 6.523561956057027,
        "cond_entropy-3": -0.0840555335878139,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 13.428571428571429,
        "std_pred_length-nopunct": 4.271404682207444,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8191489361702128,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.030089182435006,
        "distinct-2-nopunct": 0.9885057471264368,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.419954990101597,
        "cond_entropy-2-nopunct": 0.43206693047921146,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.321928094887356,
        "cond_entropy-3-nopunct": -0.0960154009613662,
        "msttr-100": 0.78,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15151515151515152,
            "2": 0.26666666666666666,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.79351,
            "recall": 0.73305,
            "fmeasure": 0.7554
        },
        "rouge2": {
            "precision": 0.5614,
            "recall": 0.52898,
            "fmeasure": 0.54011
        },
        "rougeL": {
            "precision": 0.68341,
            "recall": 0.67227,
            "fmeasure": 0.67616
        },
        "rougeLsum": {
            "precision": 0.68341,
            "recall": 0.67227,
            "fmeasure": 0.67616
        },
        "nist": 5.335187934946055,
        "bleu": 45.54188,
        "meteor": 0.40126589777062066,
        "bleurt": 0.13082,
        "nubia": {
            "semantic_relation": 3.81942,
            "contradiction": 18.93859,
            "irrelevancy": 24.11797,
            "logical_agreement": 56.94344,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.668,
            "nubia_score": 0.63335
        },
        "bertscore": {
            "precision": 0.92465,
            "recall": 0.90688,
            "f1": 0.91264
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "t5-small/totto_test",
        "N": 111,
        "total_length": 1809,
        "mean_pred_length": 16.2972972972973,
        "std_pred_length": 4.090407575882817,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.38916528468767275,
        "vocab_size-1": 704,
        "unique-1": 581,
        "entropy-1": 7.634672069117413,
        "distinct-2": 0.7114252061248527,
        "vocab_size-2": 1208,
        "unique-2": 1104,
        "entropy-2": 9.536017339334402,
        "cond_entropy-2": 1.7125973502512908,
        "distinct-3": 0.8128544423440454,
        "vocab_size-3": 1290,
        "unique-3": 1237,
        "entropy-3": 9.835721438314248,
        "cond_entropy-3": 0.35872304853126846,
        "total_length-nopunct": 1553,
        "mean_pred_length-nopunct": 13.99099099099099,
        "std_pred_length-nopunct": 3.7235445079415315,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4468770122343851,
        "vocab_size-1-nopunct": 694,
        "unique-1-nopunct": 577,
        "entropy-1-nopunct": 7.869112779191925,
        "distinct-2-nopunct": 0.7170596393897365,
        "vocab_size-2-nopunct": 1034,
        "unique-2-nopunct": 954,
        "entropy-2-nopunct": 9.2908848689431,
        "cond_entropy-2-nopunct": 1.5647037500397951,
        "distinct-3-nopunct": 0.8159278737791135,
        "vocab_size-3-nopunct": 1086,
        "unique-3-nopunct": 1048,
        "entropy-3-nopunct": 9.583120681635716,
        "cond_entropy-3-nopunct": 0.375123141619137,
        "msttr-100": 0.645,
        "msttr-100_nopunct": 0.692,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23333333333333334,
            "2": 0.43333333333333335,
            "3": 0.7374301675977654
        },
        "rouge1": {
            "precision": 0.77019,
            "recall": 0.72416,
            "fmeasure": 0.73258
        },
        "rouge2": {
            "precision": 0.56074,
            "recall": 0.51475,
            "fmeasure": 0.52764
        },
        "rougeL": {
            "precision": 0.67998,
            "recall": 0.63393,
            "fmeasure": 0.64363
        },
        "rougeLsum": {
            "precision": 0.67998,
            "recall": 0.63393,
            "fmeasure": 0.64363
        },
        "nist": 7.25642852940368,
        "bleu": 47.77056,
        "meteor": 0.37823852920446244,
        "bleurt": 0.31993,
        "nubia": {
            "semantic_relation": 4.1817,
            "contradiction": 11.13631,
            "irrelevancy": 23.62714,
            "logical_agreement": 65.23655,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.54128,
            "nubia_score": 0.71513
        },
        "bertscore": {
            "precision": 0.93087,
            "recall": 0.92243,
            "f1": 0.92514
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 0.95,
        "vocab_size-2": 19,
        "unique-2": 18,
        "entropy-2": 4.221928094887362,
        "cond_entropy-2": 0.02961067210860201,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": 0.031262576450960075,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.142664355548846,
        "cond_entropy-2-nopunct": 0.03126257645096007,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": 0.03310859910983795,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.39804,
            "fmeasure": 0.48195
        },
        "rouge2": {
            "precision": 0.29412,
            "recall": 0.18773,
            "fmeasure": 0.22911
        },
        "rougeL": {
            "precision": 0.27778,
            "recall": 0.22046,
            "fmeasure": 0.24501
        },
        "rougeLsum": {
            "precision": 0.27778,
            "recall": 0.22046,
            "fmeasure": 0.24501
        },
        "nist": 1.7779505901080435,
        "bleu": 21.34371,
        "meteor": 0.19715773334531753,
        "bleurt": -0.4327,
        "nubia": {
            "semantic_relation": 2.64182,
            "contradiction": 0.10994,
            "irrelevancy": 99.77109,
            "logical_agreement": 0.11897,
            "grammar_ref": 3.87789,
            "grammar_hyp": 3.03277,
            "nubia_score": 0.35782
        },
        "bertscore": {
            "precision": 0.83856,
            "recall": 0.81979,
            "f1": 0.82907
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 111,
        "mean_pred_length": 13.875,
        "std_pred_length": 4.313858481684349,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6756756756756757,
        "vocab_size-1": 75,
        "unique-1": 56,
        "entropy-1": 5.939347313347924,
        "distinct-2": 0.912621359223301,
        "vocab_size-2": 94,
        "unique-2": 85,
        "entropy-2": 6.511743245629835,
        "cond_entropy-2": 0.420762039539738,
        "distinct-3": 0.9578947368421052,
        "vocab_size-3": 91,
        "unique-3": 87,
        "entropy-3": 6.485645082015158,
        "cond_entropy-3": -0.01138176095753375,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 11.875,
        "std_pred_length-nopunct": 3.0998991919093113,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7578947368421053,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 6.005543603336876,
        "distinct-2-nopunct": 0.9080459770114943,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 71,
        "entropy-2-nopunct": 6.259035449871712,
        "cond_entropy-2-nopunct": 0.29388835274119185,
        "distinct-3-nopunct": 0.9620253164556962,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.227831381088497,
        "cond_entropy-3-nopunct": -0.012580469190612863,
        "msttr-100": 0.68,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8207547169811321
        },
        "rouge1": {
            "precision": 0.94673,
            "recall": 0.83984,
            "fmeasure": 0.88148
        },
        "rouge2": {
            "precision": 0.84622,
            "recall": 0.75881,
            "fmeasure": 0.79245
        },
        "rougeL": {
            "precision": 0.88076,
            "recall": 0.78683,
            "fmeasure": 0.82349
        },
        "rougeLsum": {
            "precision": 0.88076,
            "recall": 0.78683,
            "fmeasure": 0.82349
        },
        "nist": 5.581856313555017,
        "bleu": 63.74583,
        "meteor": 0.4593963806434663,
        "bleurt": 0.57836,
        "nubia": {
            "semantic_relation": 4.30193,
            "contradiction": 8.3481,
            "irrelevancy": 0.84078,
            "logical_agreement": 90.81112,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.25375,
            "nubia_score": 0.74939
        },
        "bertscore": {
            "precision": 0.97891,
            "recall": 0.94743,
            "f1": 0.9622
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 61,
        "mean_pred_length": 15.25,
        "std_pred_length": 4.548351349665063,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.6885245901639344,
        "vocab_size-1": 42,
        "unique-1": 33,
        "entropy-1": 5.10440337106179,
        "distinct-2": 0.8421052631578947,
        "vocab_size-2": 48,
        "unique-2": 40,
        "entropy-2": 5.503856900091696,
        "cond_entropy-2": 0.3170910003633157,
        "distinct-3": 0.9056603773584906,
        "vocab_size-3": 48,
        "unique-3": 43,
        "entropy-3": 5.539241209280179,
        "cond_entropy-3": 0.06021699704305129,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 3.6996621467371855,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7090909090909091,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.010334768859808,
        "distinct-2-nopunct": 0.8235294117647058,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.304682449772213,
        "cond_entropy-2-nopunct": 0.3352123824547425,
        "distinct-3-nopunct": 0.8936170212765957,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.3418228942308295,
        "cond_entropy-3-nopunct": 0.04716111613515189,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.66273,
            "recall": 0.72575,
            "fmeasure": 0.68884
        },
        "rouge2": {
            "precision": 0.39583,
            "recall": 0.42453,
            "fmeasure": 0.40846
        },
        "rougeL": {
            "precision": 0.53011,
            "recall": 0.58692,
            "fmeasure": 0.55362
        },
        "rougeLsum": {
            "precision": 0.53011,
            "recall": 0.58692,
            "fmeasure": 0.55362
        },
        "nist": 3.9390399513567664,
        "bleu": 27.55144,
        "meteor": 0.420716302496825,
        "bleurt": 0.1736,
        "nubia": {
            "semantic_relation": 4.53009,
            "contradiction": 0.42862,
            "irrelevancy": 29.9852,
            "logical_agreement": 69.58617,
            "grammar_ref": 5.27719,
            "grammar_hyp": 4.92696,
            "nubia_score": 0.84435
        },
        "bertscore": {
            "precision": 0.90761,
            "recall": 0.93327,
            "f1": 0.91959
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 77,
        "mean_pred_length": 15.4,
        "std_pred_length": 6.499230723708768,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.8051948051948052,
        "vocab_size-1": 62,
        "unique-1": 52,
        "entropy-1": 5.821790923727495,
        "distinct-2": 0.9861111111111112,
        "vocab_size-2": 71,
        "unique-2": 70,
        "entropy-2": 6.142147223664539,
        "cond_entropy-2": 0.24014766222644454,
        "distinct-3": 1.0,
        "vocab_size-3": 67,
        "unique-3": 67,
        "entropy-3": 6.066089190457767,
        "cond_entropy-3": -0.07398506471588312,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 12.8,
        "std_pred_length-nopunct": 5.3065996645686395,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.726409765557392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 59,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.882643049361836,
        "cond_entropy-2-nopunct": 0.17941889689280613,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.7548875021634665,
        "cond_entropy-3-nopunct": -0.12775554719837257,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.25,
            "3": 0.6883116883116883
        },
        "rouge1": {
            "precision": 0.87619,
            "recall": 0.66047,
            "fmeasure": 0.74121
        },
        "rouge2": {
            "precision": 0.65833,
            "recall": 0.49547,
            "fmeasure": 0.55403
        },
        "rougeL": {
            "precision": 0.6986,
            "recall": 0.54007,
            "fmeasure": 0.59907
        },
        "rougeLsum": {
            "precision": 0.6986,
            "recall": 0.54007,
            "fmeasure": 0.59907
        },
        "nist": 2.7486315489851734,
        "bleu": 39.58533,
        "meteor": 0.3577208205379877,
        "bleurt": 0.20407,
        "nubia": {
            "semantic_relation": 4.01409,
            "contradiction": 18.32381,
            "irrelevancy": 2.5528,
            "logical_agreement": 79.12338,
            "grammar_ref": 4.65184,
            "grammar_hyp": 5.10862,
            "nubia_score": 0.65163
        },
        "bertscore": {
            "precision": 0.95017,
            "recall": 0.91813,
            "f1": 0.93367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.5,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.9310344827586207,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.720049960644813,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": -0.029019418890029347,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.96,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5638561897747225,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.03333771197858132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.2,
            "3": 0.6842105263157895
        },
        "rouge1": {
            "precision": 0.6392,
            "recall": 0.71852,
            "fmeasure": 0.67356
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.31713,
            "fmeasure": 0.30733
        },
        "rougeL": {
            "precision": 0.37216,
            "recall": 0.41412,
            "fmeasure": 0.39081
        },
        "rougeLsum": {
            "precision": 0.37216,
            "recall": 0.41412,
            "fmeasure": 0.39081
        },
        "nist": 3.8355359546845613,
        "bleu": 30.62432,
        "meteor": 0.3807864617520155,
        "bleurt": -0.06889,
        "nubia": {
            "semantic_relation": 3.82394,
            "contradiction": 1.37732,
            "irrelevancy": 62.66624,
            "logical_agreement": 35.95644,
            "grammar_ref": 4.97036,
            "grammar_hyp": 5.08658,
            "nubia_score": 0.57326
        },
        "bertscore": {
            "precision": 0.89215,
            "recall": 0.90683,
            "f1": 0.8979
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 3.112474899497183,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.7169811320754716,
        "vocab_size-1": 38,
        "unique-1": 30,
        "entropy-1": 5.027554124775201,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.547289960503035,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.12285674778553377,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 3.491060010942235,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7346938775510204,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.954209273164183,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.5741327628055837,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.13430109171159124,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5384615384615384,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.69142,
            "recall": 0.78351,
            "fmeasure": 0.73249
        },
        "rouge2": {
            "precision": 0.38682,
            "recall": 0.44504,
            "fmeasure": 0.41228
        },
        "rougeL": {
            "precision": 0.62181,
            "recall": 0.71106,
            "fmeasure": 0.66129
        },
        "rougeLsum": {
            "precision": 0.62181,
            "recall": 0.71106,
            "fmeasure": 0.66129
        },
        "nist": 4.141571131887118,
        "bleu": 40.22141,
        "meteor": 0.3725166316572911,
        "bleurt": 0.19173,
        "nubia": {
            "semantic_relation": 4.13384,
            "contradiction": 3.13929,
            "irrelevancy": 47.61546,
            "logical_agreement": 49.24525,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.24693,
            "nubia_score": 0.66515
        },
        "bertscore": {
            "precision": 0.90625,
            "recall": 0.92087,
            "f1": 0.91332
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 62,
        "mean_pred_length": 20.666666666666668,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 20.0,
        "min_pred_length": 19,
        "max_pred_length": 23,
        "distinct-1": 0.7741935483870968,
        "vocab_size-1": 48,
        "unique-1": 41,
        "entropy-1": 5.387754125245523,
        "distinct-2": 0.9830508474576272,
        "vocab_size-2": 58,
        "unique-2": 57,
        "entropy-2": 5.848744744277091,
        "cond_entropy-2": 0.4290306877553487,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": -0.03957384158995153,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7719298245614035,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.25184763734432,
        "distinct-2-nopunct": 0.9814814814814815,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.717850465126429,
        "cond_entropy-2-nopunct": 0.46893180240692284,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.6724253419715005,
        "cond_entropy-3-nopunct": -0.043246473917463196,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.70159,
            "recall": 0.74142,
            "fmeasure": 0.71264
        },
        "rouge2": {
            "precision": 0.49113,
            "recall": 0.51866,
            "fmeasure": 0.49828
        },
        "rougeL": {
            "precision": 0.60377,
            "recall": 0.64269,
            "fmeasure": 0.61518
        },
        "rougeLsum": {
            "precision": 0.60377,
            "recall": 0.64269,
            "fmeasure": 0.61518
        },
        "nist": 4.640496703152482,
        "bleu": 48.87038,
        "meteor": 0.3948824490132409,
        "bleurt": -0.06529,
        "nubia": {
            "semantic_relation": 4.04176,
            "contradiction": 1.08485,
            "irrelevancy": 79.07257,
            "logical_agreement": 19.84257,
            "grammar_ref": 4.0888,
            "grammar_hyp": 3.87421,
            "nubia_score": 0.71962
        },
        "bertscore": {
            "precision": 0.89671,
            "recall": 0.91128,
            "f1": 0.90346
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 139,
        "mean_pred_length": 17.375,
        "std_pred_length": 4.688749833377763,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.6258992805755396,
        "vocab_size-1": 87,
        "unique-1": 65,
        "entropy-1": 5.989312830140226,
        "distinct-2": 0.8702290076335878,
        "vocab_size-2": 114,
        "unique-2": 100,
        "entropy-2": 6.752851341215592,
        "cond_entropy-2": 0.7362666444053703,
        "distinct-3": 0.9186991869918699,
        "vocab_size-3": 113,
        "unique-3": 103,
        "entropy-3": 6.779912879322968,
        "cond_entropy-3": 0.037180020079541014,
        "total_length-nopunct": 126,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 4.351723796382303,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6746031746031746,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 6.013718929494839,
        "distinct-2-nopunct": 0.8728813559322034,
        "vocab_size-2-nopunct": 103,
        "unique-2-nopunct": 90,
        "entropy-2-nopunct": 6.611456608683868,
        "cond_entropy-2-nopunct": 0.6376401194605751,
        "distinct-3-nopunct": 0.9181818181818182,
        "vocab_size-3-nopunct": 101,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.617723349888304,
        "cond_entropy-3-nopunct": 0.0078075732537274505,
        "msttr-100": 0.62,
        "msttr-100_nopunct": 0.67,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.32,
            "3": 0.7157894736842105
        },
        "rouge1": {
            "precision": 0.75809,
            "recall": 0.71869,
            "fmeasure": 0.71358
        },
        "rouge2": {
            "precision": 0.52164,
            "recall": 0.50959,
            "fmeasure": 0.49507
        },
        "rougeL": {
            "precision": 0.6617,
            "recall": 0.63226,
            "fmeasure": 0.62686
        },
        "rougeLsum": {
            "precision": 0.6617,
            "recall": 0.63226,
            "fmeasure": 0.62686
        },
        "nist": 4.889196020848827,
        "bleu": 42.20617,
        "meteor": 0.3729312177542193,
        "bleurt": 0.03277,
        "nubia": {
            "semantic_relation": 3.95097,
            "contradiction": 2.64756,
            "irrelevancy": 35.56927,
            "logical_agreement": 61.78316,
            "grammar_ref": 4.94279,
            "grammar_hyp": 4.82625,
            "nubia_score": 0.61374
        },
        "bertscore": {
            "precision": 0.93446,
            "recall": 0.91504,
            "f1": 0.92322
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.247927513443583,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.07800251200127316,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.80702,
            "recall": 0.70707,
            "fmeasure": 0.75366
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.41905,
            "fmeasure": 0.44804
        },
        "rougeL": {
            "precision": 0.63158,
            "recall": 0.56277,
            "fmeasure": 0.59512
        },
        "rougeLsum": {
            "precision": 0.63158,
            "recall": 0.56277,
            "fmeasure": 0.59512
        },
        "nist": 3.681472309461716,
        "bleu": 32.39114,
        "meteor": 0.36801588252774453,
        "bleurt": 0.01815,
        "nubia": {
            "semantic_relation": 4.04255,
            "contradiction": 0.22633,
            "irrelevancy": 66.8611,
            "logical_agreement": 32.91256,
            "grammar_ref": 4.70322,
            "grammar_hyp": 5.03069,
            "nubia_score": 0.616
        },
        "bertscore": {
            "precision": 0.92502,
            "recall": 0.91008,
            "f1": 0.91749
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 1.0,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 13,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.034621791174768185,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.039126751440438104,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.25,
            "3": 0.8125
        },
        "rouge1": {
            "precision": 0.76061,
            "recall": 0.70213,
            "fmeasure": 0.72273
        },
        "rouge2": {
            "precision": 0.61852,
            "recall": 0.58162,
            "fmeasure": 0.59124
        },
        "rougeL": {
            "precision": 0.65455,
            "recall": 0.61605,
            "fmeasure": 0.62773
        },
        "rougeLsum": {
            "precision": 0.65455,
            "recall": 0.61605,
            "fmeasure": 0.62773
        },
        "nist": 4.192830868149498,
        "bleu": 46.86699,
        "meteor": 0.3780164542890513,
        "bleurt": -0.16143,
        "nubia": {
            "semantic_relation": 3.6253,
            "contradiction": 75.31898,
            "irrelevancy": 22.41591,
            "logical_agreement": 2.26512,
            "grammar_ref": 5.19402,
            "grammar_hyp": 5.89293,
            "nubia_score": 0.38776
        },
        "bertscore": {
            "precision": 0.92475,
            "recall": 0.92464,
            "f1": 0.9171
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.875
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.71717,
            "fmeasure": 0.78638
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "nist": 3.7642741174382337,
        "bleu": 81.76129,
        "meteor": 0.5064321156600579,
        "bleurt": 0.69712,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.96713,
            "irrelevancy": 0.64693,
            "logical_agreement": 98.38594,
            "grammar_ref": 4.59758,
            "grammar_hyp": 4.52299,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.97871,
            "recall": 0.94782,
            "f1": 0.96301
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 105,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.6903085094570331,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.6952380952380952,
        "vocab_size-1": 73,
        "unique-1": 61,
        "entropy-1": 5.8734771849280785,
        "distinct-2": 0.9489795918367347,
        "vocab_size-2": 93,
        "unique-2": 90,
        "entropy-2": 6.49226086452338,
        "cond_entropy-2": 0.520575550256912,
        "distinct-3": 0.989010989010989,
        "vocab_size-3": 90,
        "unique-3": 89,
        "entropy-3": 6.48581661822068,
        "cond_entropy-3": 0.0029749059735977215,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 13.285714285714286,
        "std_pred_length-nopunct": 1.1605769149479943,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7526881720430108,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.864202897848175,
        "distinct-2-nopunct": 0.9418604651162791,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.286729870981168,
        "cond_entropy-2-nopunct": 0.47746524514251976,
        "distinct-3-nopunct": 0.9873417721518988,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.278464292480902,
        "cond_entropy-3-nopunct": 0.004098271956017602,
        "msttr-100": 0.69,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.16666666666666666,
            "3": 0.8791208791208791
        },
        "rouge1": {
            "precision": 0.91748,
            "recall": 0.86844,
            "fmeasure": 0.89004
        },
        "rouge2": {
            "precision": 0.72802,
            "recall": 0.69347,
            "fmeasure": 0.70853
        },
        "rougeL": {
            "precision": 0.76435,
            "recall": 0.72794,
            "fmeasure": 0.74388
        },
        "rougeLsum": {
            "precision": 0.76435,
            "recall": 0.72794,
            "fmeasure": 0.74388
        },
        "nist": 6.222342855176405,
        "bleu": 65.66813,
        "meteor": 0.4743916301410364,
        "bleurt": 0.59107,
        "nubia": {
            "semantic_relation": 4.70563,
            "contradiction": 4.89259,
            "irrelevancy": 0.91466,
            "logical_agreement": 94.19275,
            "grammar_ref": 4.9924,
            "grammar_hyp": 5.1651,
            "nubia_score": 0.86494
        },
        "bertscore": {
            "precision": 0.98001,
            "recall": 0.97376,
            "f1": 0.9768
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 59,
        "mean_pred_length": 14.75,
        "std_pred_length": 2.0463381929681126,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.7627118644067796,
        "vocab_size-1": 45,
        "unique-1": 34,
        "entropy-1": 5.3613737696641515,
        "distinct-2": 0.9272727272727272,
        "vocab_size-2": 51,
        "unique-2": 47,
        "entropy-2": 5.635905168070111,
        "cond_entropy-2": 0.16698734602033594,
        "distinct-3": 0.9607843137254902,
        "vocab_size-3": 49,
        "unique-3": 47,
        "entropy-3": 5.59399396942248,
        "cond_entropy-3": -0.03050299900414441,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 1.6583123951777,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7962962962962963,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.3335006965678495,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.483856189774726,
        "cond_entropy-2-nopunct": 0.1840664376545254,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.43660543431788,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8478260869565217
        },
        "rouge1": {
            "precision": 0.82044,
            "recall": 0.80049,
            "fmeasure": 0.8086
        },
        "rouge2": {
            "precision": 0.67249,
            "recall": 0.65096,
            "fmeasure": 0.65973
        },
        "rougeL": {
            "precision": 0.77282,
            "recall": 0.75154,
            "fmeasure": 0.7602
        },
        "rougeLsum": {
            "precision": 0.77282,
            "recall": 0.75154,
            "fmeasure": 0.7602
        },
        "nist": 5.449225912743337,
        "bleu": 67.60992,
        "meteor": 0.44858310792246686,
        "bleurt": 0.42381,
        "nubia": {
            "semantic_relation": 4.38812,
            "contradiction": 29.95569,
            "irrelevancy": 1.48798,
            "logical_agreement": 68.55633,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.3616,
            "nubia_score": 0.82725
        },
        "bertscore": {
            "precision": 0.95714,
            "recall": 0.95122,
            "f1": 0.95308
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 1.5,
        "median_pred_length": 18.5,
        "min_pred_length": 17,
        "max_pred_length": 20,
        "distinct-1": 0.7837837837837838,
        "vocab_size-1": 29,
        "unique-1": 22,
        "entropy-1": 4.756618568273183,
        "distinct-2": 0.8857142857142857,
        "vocab_size-2": 31,
        "unique-2": 27,
        "entropy-2": 4.900711588373536,
        "cond_entropy-2": 0.14139786566354431,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 30,
        "unique-3": 27,
        "entropy-3": 4.862575937540274,
        "cond_entropy-3": -0.054585867283482935,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.532665279941248,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.483856189774723,
        "cond_entropy-2-nopunct": -0.07103131238874398,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.436605434317882,
        "cond_entropy-3-nopunct": -0.07681597284814654,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.45161290322580644
        },
        "rouge1": {
            "precision": 0.52857,
            "recall": 0.35391,
            "fmeasure": 0.41878
        },
        "rouge2": {
            "precision": 0.30495,
            "recall": 0.18844,
            "fmeasure": 0.23045
        },
        "rougeL": {
            "precision": 0.49286,
            "recall": 0.32993,
            "fmeasure": 0.38986
        },
        "rougeLsum": {
            "precision": 0.49286,
            "recall": 0.32993,
            "fmeasure": 0.38986
        },
        "nist": 2.017137216565591,
        "bleu": 18.74508,
        "meteor": 0.20165165997543755,
        "bleurt": -0.8278,
        "nubia": {
            "semantic_relation": 2.52929,
            "contradiction": 43.64469,
            "irrelevancy": 6.75587,
            "logical_agreement": 49.59943,
            "grammar_ref": 5.38335,
            "grammar_hyp": 4.98741,
            "nubia_score": 0.29478
        },
        "bertscore": {
            "precision": 0.78686,
            "recall": 0.79514,
            "f1": 0.78996
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.86364,
            "recall": 0.67949,
            "fmeasure": 0.75962
        },
        "rouge2": {
            "precision": 0.55,
            "recall": 0.42262,
            "fmeasure": 0.47727
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.32564,
            "fmeasure": 0.36218
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.32564,
            "fmeasure": 0.36218
        },
        "nist": 3.3462511803549333,
        "bleu": 43.76004,
        "meteor": 0.4001766849993164,
        "bleurt": 0.12659,
        "nubia": {
            "semantic_relation": 3.94422,
            "contradiction": 0.39049,
            "irrelevancy": 0.59122,
            "logical_agreement": 99.01829,
            "grammar_ref": 4.56931,
            "grammar_hyp": 4.35643,
            "nubia_score": 0.70805
        },
        "bertscore": {
            "precision": 0.92506,
            "recall": 0.8794,
            "f1": 0.90136
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 47,
        "mean_pred_length": 11.75,
        "std_pred_length": 2.384848003542364,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.851063829787234,
        "vocab_size-1": 40,
        "unique-1": 36,
        "entropy-1": 5.198101883546502,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.07527793795849473,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.14086253583984967,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.0615528128088303,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.183867720346298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.08600186703754797,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.16046467219324617,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24,
            "2": 0.6875,
            "3": 0.7619047619047619
        },
        "rouge1": {
            "precision": 0.75625,
            "recall": 0.80107,
            "fmeasure": 0.76753
        },
        "rouge2": {
            "precision": 0.51108,
            "recall": 0.57352,
            "fmeasure": 0.53408
        },
        "rougeL": {
            "precision": 0.68494,
            "recall": 0.74615,
            "fmeasure": 0.7061
        },
        "rougeLsum": {
            "precision": 0.68494,
            "recall": 0.74615,
            "fmeasure": 0.7061
        },
        "nist": 4.4340021654469375,
        "bleu": 38.28709,
        "meteor": 0.37060962693442995,
        "bleurt": 0.28647,
        "nubia": {
            "semantic_relation": 3.68585,
            "contradiction": 26.97817,
            "irrelevancy": 34.58699,
            "logical_agreement": 38.43484,
            "grammar_ref": 4.75156,
            "grammar_hyp": 5.30352,
            "nubia_score": 0.49528
        },
        "bertscore": {
            "precision": 0.92005,
            "recall": 0.92798,
            "f1": 0.92022
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 85,
        "mean_pred_length": 14.166666666666666,
        "std_pred_length": 3.9334745737353156,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.6588235294117647,
        "vocab_size-1": 56,
        "unique-1": 43,
        "entropy-1": 5.47398181843974,
        "distinct-2": 0.9113924050632911,
        "vocab_size-2": 72,
        "unique-2": 65,
        "entropy-2": 6.126565558303687,
        "cond_entropy-2": 0.527301204444464,
        "distinct-3": 0.958904109589041,
        "vocab_size-3": 70,
        "unique-3": 67,
        "entropy-3": 6.107632778058109,
        "cond_entropy-3": -0.03176440847516772,
        "total_length-nopunct": 75,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 3.593976442141304,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.482152023829221,
        "distinct-2-nopunct": 0.9130434782608695,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.934611413299903,
        "cond_entropy-2-nopunct": 0.4739086648330129,
        "distinct-3-nopunct": 0.9682539682539683,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 59,
        "entropy-3-nopunct": 5.913787860007857,
        "cond_entropy-3-nopunct": -0.03600643804015716,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6666666666666666,
            "3": 0.7536231884057971
        },
        "rouge1": {
            "precision": 0.82968,
            "recall": 0.73759,
            "fmeasure": 0.76858
        },
        "rouge2": {
            "precision": 0.59365,
            "recall": 0.52701,
            "fmeasure": 0.55099
        },
        "rougeL": {
            "precision": 0.66663,
            "recall": 0.62457,
            "fmeasure": 0.63615
        },
        "rougeLsum": {
            "precision": 0.66663,
            "recall": 0.62457,
            "fmeasure": 0.63615
        },
        "nist": 4.640059019894338,
        "bleu": 44.03681,
        "meteor": 0.39056910240206105,
        "bleurt": 0.27052,
        "nubia": {
            "semantic_relation": 4.31832,
            "contradiction": 19.84711,
            "irrelevancy": 22.78496,
            "logical_agreement": 57.36793,
            "grammar_ref": 4.9652,
            "grammar_hyp": 5.12224,
            "nubia_score": 0.7327
        },
        "bertscore": {
            "precision": 0.93807,
            "recall": 0.92101,
            "f1": 0.92883
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 35,
        "mean_pred_length": 11.666666666666666,
        "std_pred_length": 5.2493385826745405,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.8285714285714286,
        "vocab_size-1": 29,
        "unique-1": 24,
        "entropy-1": 4.764857659740294,
        "distinct-2": 0.96875,
        "vocab_size-2": 31,
        "unique-2": 30,
        "entropy-2": 4.9375,
        "cond_entropy-2": 0.058216983055033616,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.07305348763104855,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 5.436502143433364,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8709677419354839,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.696131794257844,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.03173004024215739,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.08349873228287957,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.8461538461538461,
            "3": 0.37037037037037035
        },
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.52267,
            "fmeasure": 0.60029
        },
        "rouge2": {
            "precision": 0.55686,
            "recall": 0.31383,
            "fmeasure": 0.37144
        },
        "rougeL": {
            "precision": 0.78704,
            "recall": 0.50245,
            "fmeasure": 0.58096
        },
        "rougeLsum": {
            "precision": 0.78704,
            "recall": 0.50245,
            "fmeasure": 0.58096
        },
        "nist": 2.452156649340553,
        "bleu": 31.4019,
        "meteor": 0.30575035437350156,
        "bleurt": -0.01807,
        "nubia": {
            "semantic_relation": 3.78403,
            "contradiction": 0.72969,
            "irrelevancy": 3.17202,
            "logical_agreement": 96.09829,
            "grammar_ref": 4.97796,
            "grammar_hyp": 5.2486,
            "nubia_score": 0.59968
        },
        "bertscore": {
            "precision": 0.90729,
            "recall": 0.84476,
            "f1": 0.87297
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 4.921607686744467,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.8157894736842105,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.83977553964551,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.2673490750535791,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.12928301694496638,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 4.4969125210773475,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.690116517593664,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.3025326628245015,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.47058823529411764,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.66856,
            "recall": 0.71362,
            "fmeasure": 0.66176
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.50535,
            "fmeasure": 0.4726
        },
        "rougeL": {
            "precision": 0.57134,
            "recall": 0.64484,
            "fmeasure": 0.5815
        },
        "rougeLsum": {
            "precision": 0.57134,
            "recall": 0.64484,
            "fmeasure": 0.5815
        },
        "nist": 3.279179924333011,
        "bleu": 30.75335,
        "meteor": 0.30199176200803557,
        "bleurt": 0.06015,
        "nubia": {
            "semantic_relation": 3.70487,
            "contradiction": 1.72892,
            "irrelevancy": 52.45134,
            "logical_agreement": 45.81973,
            "grammar_ref": 6.27104,
            "grammar_hyp": 4.99185,
            "nubia_score": 0.65828
        },
        "bertscore": {
            "precision": 0.87658,
            "recall": 0.91136,
            "f1": 0.89075
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "t5-small/totto_test",
        "N": 14,
        "total_length": 215,
        "mean_pred_length": 15.357142857142858,
        "std_pred_length": 5.135411276576769,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6511627906976745,
        "vocab_size-1": 140,
        "unique-1": 115,
        "entropy-1": 6.666827690208587,
        "distinct-2": 0.9154228855721394,
        "vocab_size-2": 184,
        "unique-2": 171,
        "entropy-2": 7.464435895137512,
        "cond_entropy-2": 0.6077382712101227,
        "distinct-3": 0.9679144385026738,
        "vocab_size-3": 181,
        "unique-3": 175,
        "entropy-3": 7.482723336892964,
        "cond_entropy-3": 0.032258677822756085,
        "total_length-nopunct": 183,
        "mean_pred_length-nopunct": 13.071428571428571,
        "std_pred_length-nopunct": 4.589806807547813,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.73224043715847,
        "vocab_size-1-nopunct": 134,
        "unique-1-nopunct": 113,
        "entropy-1-nopunct": 6.770008666672684,
        "distinct-2-nopunct": 0.9289940828402367,
        "vocab_size-2-nopunct": 157,
        "unique-2-nopunct": 148,
        "entropy-2-nopunct": 7.242566492482393,
        "cond_entropy-2-nopunct": 0.5190354228620064,
        "distinct-3-nopunct": 0.9806451612903225,
        "vocab_size-3-nopunct": 152,
        "unique-3-nopunct": 149,
        "entropy-3-nopunct": 7.237414727854903,
        "cond_entropy-3-nopunct": 0.009147469006011079,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.84,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08823529411764706,
            "2": 0.34375,
            "3": 0.8717948717948718
        },
        "rouge1": {
            "precision": 0.8149,
            "recall": 0.78193,
            "fmeasure": 0.79555
        },
        "rouge2": {
            "precision": 0.68089,
            "recall": 0.64804,
            "fmeasure": 0.6619
        },
        "rougeL": {
            "precision": 0.73129,
            "recall": 0.69978,
            "fmeasure": 0.71258
        },
        "rougeLsum": {
            "precision": 0.73129,
            "recall": 0.69978,
            "fmeasure": 0.71258
        },
        "nist": 6.1006679167025695,
        "bleu": 61.87029,
        "meteor": 0.4610855360588394,
        "bleurt": 0.41747,
        "nubia": {
            "semantic_relation": 4.24654,
            "contradiction": 4.70716,
            "irrelevancy": 25.00031,
            "logical_agreement": 70.29253,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.91293,
            "nubia_score": 0.73846
        },
        "bertscore": {
            "precision": 0.9383,
            "recall": 0.93052,
            "f1": 0.93404
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 13,
        "unique-1": 8,
        "entropy-1": 3.6143694458867563,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 15,
        "unique-2": 13,
        "entropy-2": 3.8521687236032816,
        "cond_entropy-2": 0.27047901627861526,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": 0.1625371587496606,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.4992275471326932,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.75,
        "cond_entropy-2-nopunct": 0.22503715874966057,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": 0.17355726227518528,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.625,
            "3": 0.25
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42857
        },
        "rouge2": {
            "precision": 0.11765,
            "recall": 0.08696,
            "fmeasure": 0.1
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.25,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.25,
            "fmeasure": 0.28571
        },
        "nist": 2.2172144403252005,
        "bleu": 6.25612,
        "meteor": 0.22173855123268643,
        "bleurt": -0.55606,
        "nubia": {
            "semantic_relation": 3.18344,
            "contradiction": 36.43367,
            "irrelevancy": 35.07926,
            "logical_agreement": 28.48707,
            "grammar_ref": 4.791,
            "grammar_hyp": 4.38994,
            "nubia_score": 0.43481
        },
        "bertscore": {
            "precision": 0.82627,
            "recall": 0.78374,
            "f1": 0.804
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910024,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.2186000898557489,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rougeLsum": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "nist": 4.433288378057127,
        "bleu": 78.39204,
        "meteor": 0.5347033086663171,
        "bleurt": 0.61374,
        "nubia": {
            "semantic_relation": 4.85453,
            "contradiction": 0.33848,
            "irrelevancy": 2.11318,
            "logical_agreement": 97.54834,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.31084,
            "nubia_score": 0.99053
        },
        "bertscore": {
            "precision": 0.96805,
            "recall": 0.97648,
            "f1": 0.97224
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "t5-small/totto_test",
        "N": 17,
        "total_length": 271,
        "mean_pred_length": 15.941176470588236,
        "std_pred_length": 4.207424645234745,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6162361623616236,
        "vocab_size-1": 167,
        "unique-1": 137,
        "entropy-1": 6.703662791797065,
        "distinct-2": 0.9015748031496063,
        "vocab_size-2": 229,
        "unique-2": 212,
        "entropy-2": 7.750864324738403,
        "cond_entropy-2": 0.9166869807435026,
        "distinct-3": 0.9662447257383966,
        "vocab_size-3": 229,
        "unique-3": 221,
        "entropy-3": 7.821232700375093,
        "cond_entropy-3": 0.07898840160527754,
        "total_length-nopunct": 242,
        "mean_pred_length-nopunct": 14.235294117647058,
        "std_pred_length-nopunct": 4.051570672405309,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6735537190082644,
        "vocab_size-1-nopunct": 163,
        "unique-1-nopunct": 135,
        "entropy-1-nopunct": 6.796896188411456,
        "distinct-2-nopunct": 0.9022222222222223,
        "vocab_size-2-nopunct": 203,
        "unique-2-nopunct": 189,
        "entropy-2-nopunct": 7.5719750936322585,
        "cond_entropy-2-nopunct": 0.8216943600206278,
        "distinct-3-nopunct": 0.9759615384615384,
        "vocab_size-3-nopunct": 203,
        "unique-3-nopunct": 198,
        "entropy-3-nopunct": 7.652362795064146,
        "cond_entropy-3-nopunct": 0.08091993056139471,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17777777777777778,
            "2": 0.36470588235294116,
            "3": 0.6612021857923497
        },
        "rouge1": {
            "precision": 0.72237,
            "recall": 0.65433,
            "fmeasure": 0.67492
        },
        "rouge2": {
            "precision": 0.50848,
            "recall": 0.4644,
            "fmeasure": 0.47676
        },
        "rougeL": {
            "precision": 0.64375,
            "recall": 0.58327,
            "fmeasure": 0.6003
        },
        "rougeLsum": {
            "precision": 0.64375,
            "recall": 0.58327,
            "fmeasure": 0.6003
        },
        "nist": 5.146520095852033,
        "bleu": 40.11922,
        "meteor": 0.346109298677953,
        "bleurt": 0.08763,
        "nubia": {
            "semantic_relation": 3.89953,
            "contradiction": 21.15113,
            "irrelevancy": 40.05539,
            "logical_agreement": 38.79348,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.36528,
            "nubia_score": 0.61635
        },
        "bertscore": {
            "precision": 0.92281,
            "recall": 0.90439,
            "f1": 0.91086
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 4.5,
        "median_pred_length": 9.5,
        "min_pred_length": 5,
        "max_pred_length": 14,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.04281761336971672,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.18057224564182078,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.0472389123084875,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "rouge1": {
            "precision": 0.86859,
            "recall": 0.56688,
            "fmeasure": 0.65451
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.36902,
            "fmeasure": 0.41312
        },
        "rougeL": {
            "precision": 0.84295,
            "recall": 0.55223,
            "fmeasure": 0.63457
        },
        "rougeLsum": {
            "precision": 0.84295,
            "recall": 0.55223,
            "fmeasure": 0.63457
        },
        "nist": 2.3971891011345354,
        "bleu": 41.40211,
        "meteor": 0.35300388815384265,
        "bleurt": -0.00609,
        "nubia": {
            "semantic_relation": 3.57823,
            "contradiction": 0.80888,
            "irrelevancy": 32.89553,
            "logical_agreement": 66.29559,
            "grammar_ref": 5.06568,
            "grammar_hyp": 5.82737,
            "nubia_score": 0.50354
        },
        "bertscore": {
            "precision": 0.92923,
            "recall": 0.88689,
            "f1": 0.907
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "t5-small/totto_test",
        "N": 14,
        "total_length": 231,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.2237954561133595,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.6060606060606061,
        "vocab_size-1": 140,
        "unique-1": 111,
        "entropy-1": 6.495945587452457,
        "distinct-2": 0.9078341013824884,
        "vocab_size-2": 197,
        "unique-2": 182,
        "entropy-2": 7.5553075112363635,
        "cond_entropy-2": 0.9439780451978668,
        "distinct-3": 0.9704433497536946,
        "vocab_size-3": 197,
        "unique-3": 191,
        "entropy-3": 7.606222616692571,
        "cond_entropy-3": 0.06513881036711798,
        "total_length-nopunct": 199,
        "mean_pred_length-nopunct": 14.214285714285714,
        "std_pred_length-nopunct": 2.483619807244815,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.678391959798995,
        "vocab_size-1-nopunct": 135,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.610639455433438,
        "distinct-2-nopunct": 0.9243243243243243,
        "vocab_size-2-nopunct": 171,
        "unique-2-nopunct": 162,
        "entropy-2-nopunct": 7.354328014558661,
        "cond_entropy-2-nopunct": 0.801952504048602,
        "distinct-3-nopunct": 0.9824561403508771,
        "vocab_size-3-nopunct": 168,
        "unique-3-nopunct": 165,
        "entropy-3-nopunct": 7.382764795587644,
        "cond_entropy-3-nopunct": 0.03708443157522032,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15517241379310345,
            "2": 0.4186046511627907,
            "3": 0.7518248175182481
        },
        "rouge1": {
            "precision": 0.70762,
            "recall": 0.68641,
            "fmeasure": 0.68358
        },
        "rouge2": {
            "precision": 0.42936,
            "recall": 0.42778,
            "fmeasure": 0.42243
        },
        "rougeL": {
            "precision": 0.59733,
            "recall": 0.58322,
            "fmeasure": 0.58082
        },
        "rougeLsum": {
            "precision": 0.59733,
            "recall": 0.58322,
            "fmeasure": 0.58082
        },
        "nist": 5.221197828078854,
        "bleu": 36.47099,
        "meteor": 0.37196441993000895,
        "bleurt": 0.16693,
        "nubia": {
            "semantic_relation": 3.96895,
            "contradiction": 11.72697,
            "irrelevancy": 26.88225,
            "logical_agreement": 61.39079,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.14676,
            "nubia_score": 0.69329
        },
        "bertscore": {
            "precision": 0.90867,
            "recall": 0.91186,
            "f1": 0.90915
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 13,
        "entropy-1": 4.053508854797679,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.449681520647312,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.884183719779189,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.3867829713016689,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.5882352941176471
        },
        "rouge1": {
            "precision": 0.56667,
            "recall": 0.52326,
            "fmeasure": 0.54303
        },
        "rouge2": {
            "precision": 0.19298,
            "recall": 0.1936,
            "fmeasure": 0.19292
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.29748,
            "fmeasure": 0.29815
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.29748,
            "fmeasure": 0.29815
        },
        "nist": 3.0720028895028735,
        "bleu": 7.46882,
        "meteor": 0.2670919650219064,
        "bleurt": -0.33371,
        "nubia": {
            "semantic_relation": 3.69236,
            "contradiction": 1.73274,
            "irrelevancy": 7.41533,
            "logical_agreement": 90.85193,
            "grammar_ref": 4.86737,
            "grammar_hyp": 5.41011,
            "nubia_score": 0.52912
        },
        "bertscore": {
            "precision": 0.82435,
            "recall": 0.82095,
            "f1": 0.81971
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.0,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.7666666666666667,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.3735572622751855,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.40046432644908553,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.307354922057605,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.4315463345450263,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.75,
            "3": 0.9333333333333333
        },
        "rouge1": {
            "precision": 0.67982,
            "recall": 0.93124,
            "fmeasure": 0.76802
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.54167,
            "fmeasure": 0.42443
        },
        "rougeL": {
            "precision": 0.43567,
            "recall": 0.58904,
            "fmeasure": 0.4898
        },
        "rougeLsum": {
            "precision": 0.43567,
            "recall": 0.58904,
            "fmeasure": 0.4898
        },
        "nist": 3.550820891245206,
        "bleu": 20.46826,
        "meteor": 0.4010363199669327,
        "bleurt": 0.07911,
        "nubia": {
            "semantic_relation": 4.35007,
            "contradiction": 0.97516,
            "irrelevancy": 32.95104,
            "logical_agreement": 66.07379,
            "grammar_ref": 3.96214,
            "grammar_hyp": 4.2779,
            "nubia_score": 0.65799
        },
        "bertscore": {
            "precision": 0.87811,
            "recall": 0.91451,
            "f1": 0.895
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 16,
        "unique-1": 8,
        "entropy-1": 3.91829583405449,
        "distinct-2": 0.7727272727272727,
        "vocab_size-2": 17,
        "unique-2": 12,
        "entropy-2": 4.004886164091841,
        "cond_entropy-2": 0.05628729973432271,
        "distinct-3": 0.8,
        "vocab_size-3": 16,
        "unique-3": 12,
        "entropy-3": 3.9219280948873623,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.6818181818181818,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.82306798227366,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.821928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 0.7777777777777778,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.7254805569978675,
        "cond_entropy-3-nopunct": -0.04089198233393865,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.631578947368421
        },
        "rouge1": {
            "precision": 0.71212,
            "recall": 0.69773,
            "fmeasure": 0.70406
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.46229,
            "fmeasure": 0.46391
        },
        "rougeL": {
            "precision": 0.71212,
            "recall": 0.69773,
            "fmeasure": 0.70406
        },
        "rougeLsum": {
            "precision": 0.71212,
            "recall": 0.69773,
            "fmeasure": 0.70406
        },
        "nist": 3.780841142444557,
        "bleu": 39.41028,
        "meteor": 0.44066288158839534,
        "bleurt": 0.78735,
        "nubia": {
            "semantic_relation": 4.69877,
            "contradiction": 1.87841,
            "irrelevancy": 0.83068,
            "logical_agreement": 97.29091,
            "grammar_ref": 4.16906,
            "grammar_hyp": 4.54966,
            "nubia_score": 0.82028
        },
        "bertscore": {
            "precision": 0.96483,
            "recall": 0.95094,
            "f1": 0.95778
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "t5-small/totto_test",
        "N": 13,
        "total_length": 232,
        "mean_pred_length": 17.846153846153847,
        "std_pred_length": 6.212223110636913,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.5732758620689655,
        "vocab_size-1": 133,
        "unique-1": 96,
        "entropy-1": 6.555510844021917,
        "distinct-2": 0.8493150684931506,
        "vocab_size-2": 186,
        "unique-2": 163,
        "entropy-2": 7.4214351053306125,
        "cond_entropy-2": 0.7737139435912869,
        "distinct-3": 0.9223300970873787,
        "vocab_size-3": 190,
        "unique-3": 175,
        "entropy-3": 7.527496218920289,
        "cond_entropy-3": 0.10610292380714008,
        "total_length-nopunct": 205,
        "mean_pred_length-nopunct": 15.76923076923077,
        "std_pred_length-nopunct": 4.979246871594541,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.624390243902439,
        "vocab_size-1-nopunct": 128,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.575944791435023,
        "distinct-2-nopunct": 0.859375,
        "vocab_size-2-nopunct": 165,
        "unique-2-nopunct": 147,
        "entropy-2-nopunct": 7.2483521336217445,
        "cond_entropy-2-nopunct": 0.6894341307693197,
        "distinct-3-nopunct": 0.9329608938547486,
        "vocab_size-3-nopunct": 167,
        "unique-3-nopunct": 156,
        "entropy-3-nopunct": 7.345520316358306,
        "cond_entropy-3-nopunct": 0.07270475966468544,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19718309859154928,
            "2": 0.4339622641509434,
            "3": 0.626984126984127
        },
        "rouge1": {
            "precision": 0.60139,
            "recall": 0.61034,
            "fmeasure": 0.59535
        },
        "rouge2": {
            "precision": 0.30378,
            "recall": 0.31061,
            "fmeasure": 0.30145
        },
        "rougeL": {
            "precision": 0.45413,
            "recall": 0.47483,
            "fmeasure": 0.45627
        },
        "rougeLsum": {
            "precision": 0.45413,
            "recall": 0.47483,
            "fmeasure": 0.45627
        },
        "nist": 4.621848692745928,
        "bleu": 27.24268,
        "meteor": 0.30736772219321395,
        "bleurt": -0.13614,
        "nubia": {
            "semantic_relation": 3.6194,
            "contradiction": 21.60964,
            "irrelevancy": 52.44885,
            "logical_agreement": 25.94151,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.23765,
            "nubia_score": 0.56085
        },
        "bertscore": {
            "precision": 0.87686,
            "recall": 0.86827,
            "f1": 0.87072
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 109,
        "mean_pred_length": 13.625,
        "std_pred_length": 4.270172713134681,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.7247706422018348,
        "vocab_size-1": 79,
        "unique-1": 67,
        "entropy-1": 6.031664371221929,
        "distinct-2": 0.9504950495049505,
        "vocab_size-2": 96,
        "unique-2": 92,
        "entropy-2": 6.5517274480768934,
        "cond_entropy-2": 0.3838321379840485,
        "distinct-3": 0.967741935483871,
        "vocab_size-3": 90,
        "unique-3": 87,
        "entropy-3": 6.474642682075779,
        "cond_entropy-3": -0.06792484903985525,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 3.960744879438715,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7755102040816326,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 6.044563895330245,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 81,
        "entropy-2-nopunct": 6.372354346305624,
        "cond_entropy-2-nopunct": 0.3784700908673965,
        "distinct-3-nopunct": 0.9634146341463414,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.28438127291077,
        "cond_entropy-3-nopunct": -0.0763146587583782,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.6,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.76362,
            "recall": 0.70933,
            "fmeasure": 0.7282
        },
        "rouge2": {
            "precision": 0.48134,
            "recall": 0.44144,
            "fmeasure": 0.45457
        },
        "rougeL": {
            "precision": 0.62307,
            "recall": 0.5794,
            "fmeasure": 0.59417
        },
        "rougeLsum": {
            "precision": 0.62307,
            "recall": 0.5794,
            "fmeasure": 0.59417
        },
        "nist": 5.262459170435403,
        "bleu": 46.0483,
        "meteor": 0.4072206129637945,
        "bleurt": 0.21261,
        "nubia": {
            "semantic_relation": 3.94864,
            "contradiction": 8.44845,
            "irrelevancy": 22.63373,
            "logical_agreement": 68.91781,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.15607,
            "nubia_score": 0.65762
        },
        "bertscore": {
            "precision": 0.92434,
            "recall": 0.91541,
            "f1": 0.91872
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "t5-small/totto_test",
        "N": 35,
        "total_length": 518,
        "mean_pred_length": 14.8,
        "std_pred_length": 4.314758725252532,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5540540540540541,
        "vocab_size-1": 287,
        "unique-1": 229,
        "entropy-1": 7.306190703784731,
        "distinct-2": 0.8944099378881988,
        "vocab_size-2": 432,
        "unique-2": 394,
        "entropy-2": 8.67356972575157,
        "cond_entropy-2": 1.1854580811443194,
        "distinct-3": 0.9575892857142857,
        "vocab_size-3": 429,
        "unique-3": 410,
        "entropy-3": 8.722533493486154,
        "cond_entropy-3": 0.050037066524638046,
        "total_length-nopunct": 446,
        "mean_pred_length-nopunct": 12.742857142857142,
        "std_pred_length-nopunct": 3.8272918970606518,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.625560538116592,
        "vocab_size-1-nopunct": 279,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.490727230091366,
        "distinct-2-nopunct": 0.8978102189781022,
        "vocab_size-2-nopunct": 369,
        "unique-2-nopunct": 339,
        "entropy-2-nopunct": 8.443868853906743,
        "cond_entropy-2-nopunct": 1.0322564497062519,
        "distinct-3-nopunct": 0.9627659574468085,
        "vocab_size-3-nopunct": 362,
        "unique-3-nopunct": 348,
        "entropy-3-nopunct": 8.480120766571202,
        "cond_entropy-3-nopunct": 0.047872658787161675,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2422680412371134,
            "2": 0.3153153153153153,
            "3": 0.6480446927374302
        },
        "rouge1": {
            "precision": 0.71616,
            "recall": 0.61259,
            "fmeasure": 0.64982
        },
        "rouge2": {
            "precision": 0.46603,
            "recall": 0.39824,
            "fmeasure": 0.42278
        },
        "rougeL": {
            "precision": 0.62645,
            "recall": 0.53577,
            "fmeasure": 0.56872
        },
        "rougeLsum": {
            "precision": 0.62645,
            "recall": 0.53577,
            "fmeasure": 0.56872
        },
        "nist": 5.475343844002349,
        "bleu": 36.64452,
        "meteor": 0.3166298538466963,
        "bleurt": 0.07662,
        "nubia": {
            "semantic_relation": 3.66477,
            "contradiction": 11.68127,
            "irrelevancy": 36.28066,
            "logical_agreement": 52.03807,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.66048,
            "nubia_score": 0.59566
        },
        "bertscore": {
            "precision": 0.91253,
            "recall": 0.89158,
            "f1": 0.89978
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 59,
        "mean_pred_length": 11.8,
        "std_pred_length": 2.7856776554368237,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 15,
        "distinct-1": 0.7627118644067796,
        "vocab_size-1": 45,
        "unique-1": 38,
        "entropy-1": 5.272911380700192,
        "distinct-2": 0.9814814814814815,
        "vocab_size-2": 53,
        "unique-2": 52,
        "entropy-2": 5.717850465126429,
        "cond_entropy-2": 0.2864023782942248,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.09936133151764788,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 10.4,
        "std_pred_length-nopunct": 2.6532998322843198,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8269230769230769,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.270352641668012,
        "distinct-2-nopunct": 0.9787234042553191,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.512035660188278,
        "cond_entropy-2-nopunct": 0.28743696282591324,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.11465238127982942,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.06666666666666667,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.92011,
            "recall": 0.67911,
            "fmeasure": 0.77226
        },
        "rouge2": {
            "precision": 0.76987,
            "recall": 0.54871,
            "fmeasure": 0.63123
        },
        "rougeL": {
            "precision": 0.8763,
            "recall": 0.65406,
            "fmeasure": 0.74075
        },
        "rougeLsum": {
            "precision": 0.8763,
            "recall": 0.65406,
            "fmeasure": 0.74075
        },
        "nist": 3.38828888066281,
        "bleu": 44.98158,
        "meteor": 0.41482705842076184,
        "bleurt": 0.31277,
        "nubia": {
            "semantic_relation": 4.123,
            "contradiction": 10.03364,
            "irrelevancy": 11.4627,
            "logical_agreement": 78.50365,
            "grammar_ref": 4.74509,
            "grammar_hyp": 5.01845,
            "nubia_score": 0.66358
        },
        "bertscore": {
            "precision": 0.96788,
            "recall": 0.92528,
            "f1": 0.94588
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.5,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.7567567567567568,
        "vocab_size-1": 28,
        "unique-1": 21,
        "entropy-1": 4.668912825088411,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.43411536560173103,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7575757575757576,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.498939573903908,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.45818928780261536,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9583333333333334
        },
        "rouge1": {
            "precision": 0.92121,
            "recall": 0.92121,
            "fmeasure": 0.92121
        },
        "rouge2": {
            "precision": 0.65351,
            "recall": 0.67203,
            "fmeasure": 0.66228
        },
        "rougeL": {
            "precision": 0.7053,
            "recall": 0.72955,
            "fmeasure": 0.71685
        },
        "rougeLsum": {
            "precision": 0.7053,
            "recall": 0.72955,
            "fmeasure": 0.71685
        },
        "nist": 5.129661701227847,
        "bleu": 58.02231,
        "meteor": 0.47884295481261374,
        "bleurt": 0.6198,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.57099,
            "irrelevancy": 17.58683,
            "logical_agreement": 80.84217,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.13272,
            "nubia_score": 0.96457
        },
        "bertscore": {
            "precision": 0.96716,
            "recall": 0.96942,
            "f1": 0.96828
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5333333333333333
        },
        "rouge1": {
            "precision": 0.55,
            "recall": 0.52381,
            "fmeasure": 0.53659
        },
        "rouge2": {
            "precision": 0.36842,
            "recall": 0.34444,
            "fmeasure": 0.35598
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.42208,
            "fmeasure": 0.43554
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.42208,
            "fmeasure": 0.43554
        },
        "nist": 1.9909856951699076,
        "bleu": 20.88094,
        "meteor": 0.2912539008915675,
        "bleurt": -0.39181,
        "nubia": {
            "semantic_relation": 2.77104,
            "contradiction": 93.79264,
            "irrelevancy": 5.04449,
            "logical_agreement": 1.16288,
            "grammar_ref": 3.42286,
            "grammar_hyp": 4.21589,
            "nubia_score": 0.30779
        },
        "bertscore": {
            "precision": 0.85639,
            "recall": 0.85239,
            "f1": 0.85438
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 84,
        "mean_pred_length": 16.8,
        "std_pred_length": 3.059411708155671,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.6309523809523809,
        "vocab_size-1": 53,
        "unique-1": 35,
        "entropy-1": 5.463555370028718,
        "distinct-2": 0.8354430379746836,
        "vocab_size-2": 66,
        "unique-2": 53,
        "entropy-2": 5.974666824126474,
        "cond_entropy-2": 0.4229363881396932,
        "distinct-3": 0.918918918918919,
        "vocab_size-3": 68,
        "unique-3": 62,
        "entropy-3": 6.047291203466794,
        "cond_entropy-3": 0.06783477961400909,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 15.2,
        "std_pred_length-nopunct": 2.9257477676655586,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6578947368421053,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.400475250857183,
        "distinct-2-nopunct": 0.8450704225352113,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.839887964575098,
        "cond_entropy-2-nopunct": 0.4709234364352753,
        "distinct-3-nopunct": 0.9393939393939394,
        "vocab_size-3-nopunct": 62,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.923181998146339,
        "cond_entropy-3-nopunct": 0.07646518167195332,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.2857142857142857,
            "3": 0.828125
        },
        "rouge1": {
            "precision": 0.84185,
            "recall": 0.86753,
            "fmeasure": 0.83352
        },
        "rouge2": {
            "precision": 0.67264,
            "recall": 0.66771,
            "fmeasure": 0.6608
        },
        "rougeL": {
            "precision": 0.68213,
            "recall": 0.70539,
            "fmeasure": 0.67681
        },
        "rougeLsum": {
            "precision": 0.68213,
            "recall": 0.70539,
            "fmeasure": 0.67681
        },
        "nist": 5.353948493319335,
        "bleu": 56.92903,
        "meteor": 0.44741611534856485,
        "bleurt": 0.44917,
        "nubia": {
            "semantic_relation": 4.23316,
            "contradiction": 0.19721,
            "irrelevancy": 23.51105,
            "logical_agreement": 76.29175,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.60343,
            "nubia_score": 0.83079
        },
        "bertscore": {
            "precision": 0.94303,
            "recall": 0.94202,
            "f1": 0.94117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.54545,
            "fmeasure": 0.57143
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "nist": 3.2660348391267022,
        "bleu": 58.59059,
        "meteor": 0.4719055239866094,
        "bleurt": 0.44462,
        "nubia": {
            "semantic_relation": 4.46185,
            "contradiction": 6.20929,
            "irrelevancy": 33.81651,
            "logical_agreement": 59.9742,
            "grammar_ref": 4.85143,
            "grammar_hyp": 5.4974,
            "nubia_score": 0.62052
        },
        "bertscore": {
            "precision": 0.96677,
            "recall": 0.96084,
            "f1": 0.96379
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "t5-small/totto_test",
        "N": 48,
        "total_length": 759,
        "mean_pred_length": 15.8125,
        "std_pred_length": 4.044833381405634,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.31488801054018445,
        "vocab_size-1": 239,
        "unique-1": 194,
        "entropy-1": 6.236492982663864,
        "distinct-2": 0.5654008438818565,
        "vocab_size-2": 402,
        "unique-2": 355,
        "entropy-2": 7.785996403844247,
        "cond_entropy-2": 1.4092320626895847,
        "distinct-3": 0.6666666666666666,
        "vocab_size-3": 442,
        "unique-3": 399,
        "entropy-3": 8.17006393493274,
        "cond_entropy-3": 0.460649132358364,
        "total_length-nopunct": 648,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.0345235760055207,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.3595679012345679,
        "vocab_size-1-nopunct": 233,
        "unique-1-nopunct": 194,
        "entropy-1-nopunct": 6.328779944331325,
        "distinct-2-nopunct": 0.5616666666666666,
        "vocab_size-2-nopunct": 337,
        "unique-2-nopunct": 295,
        "entropy-2-nopunct": 7.5466472347231885,
        "cond_entropy-2-nopunct": 1.3495307110567352,
        "distinct-3-nopunct": 0.6684782608695652,
        "vocab_size-3-nopunct": 369,
        "unique-3-nopunct": 333,
        "entropy-3-nopunct": 7.91964094845501,
        "cond_entropy-3-nopunct": 0.5011535504656512,
        "msttr-100": 0.50429,
        "msttr-100_nopunct": 0.52667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.28378378378378377,
            "2": 0.65,
            "3": 0.7889546351084813
        },
        "rouge1": {
            "precision": 0.77434,
            "recall": 0.77089,
            "fmeasure": 0.76115
        },
        "rouge2": {
            "precision": 0.58072,
            "recall": 0.5728,
            "fmeasure": 0.56881
        },
        "rougeL": {
            "precision": 0.69235,
            "recall": 0.68413,
            "fmeasure": 0.67803
        },
        "rougeLsum": {
            "precision": 0.69235,
            "recall": 0.68413,
            "fmeasure": 0.67803
        },
        "nist": 6.6541655515516105,
        "bleu": 56.60761,
        "meteor": 0.4136207620451743,
        "bleurt": 0.5213,
        "nubia": {
            "semantic_relation": 4.42543,
            "contradiction": 8.92653,
            "irrelevancy": 14.85506,
            "logical_agreement": 76.21841,
            "grammar_ref": 4.06325,
            "grammar_hyp": 4.00433,
            "nubia_score": 0.83761
        },
        "bertscore": {
            "precision": 0.9362,
            "recall": 0.93445,
            "f1": 0.93369
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 89,
        "mean_pred_length": 17.8,
        "std_pred_length": 4.915282290977803,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6966292134831461,
        "vocab_size-1": 62,
        "unique-1": 46,
        "entropy-1": 5.703206605099399,
        "distinct-2": 0.9047619047619048,
        "vocab_size-2": 76,
        "unique-2": 68,
        "entropy-2": 6.20184123230257,
        "cond_entropy-2": 0.4493802716000229,
        "distinct-3": 0.9620253164556962,
        "vocab_size-3": 76,
        "unique-3": 73,
        "entropy-3": 6.227831381088497,
        "cond_entropy-3": 0.0380456038793551,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 16.4,
        "std_pred_length-nopunct": 4.63033476111609,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7073170731707317,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.616638742396578,
        "distinct-2-nopunct": 0.8961038961038961,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 6.058994332902697,
        "cond_entropy-2-nopunct": 0.46449281532569364,
        "distinct-3-nopunct": 0.9583333333333334,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.086591668108983,
        "cond_entropy-3-nopunct": 0.014249571858522159,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.7428571428571429
        },
        "rouge1": {
            "precision": 0.78088,
            "recall": 0.71465,
            "fmeasure": 0.73898
        },
        "rouge2": {
            "precision": 0.60679,
            "recall": 0.52357,
            "fmeasure": 0.55413
        },
        "rougeL": {
            "precision": 0.68484,
            "recall": 0.63784,
            "fmeasure": 0.6481
        },
        "rougeLsum": {
            "precision": 0.68484,
            "recall": 0.63784,
            "fmeasure": 0.6481
        },
        "nist": 4.663208988074608,
        "bleu": 41.1014,
        "meteor": 0.3736213282974099,
        "bleurt": 0.30858,
        "nubia": {
            "semantic_relation": 4.26405,
            "contradiction": 25.86739,
            "irrelevancy": 7.06053,
            "logical_agreement": 67.07208,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.33303,
            "nubia_score": 0.76319
        },
        "bertscore": {
            "precision": 0.92584,
            "recall": 0.90717,
            "f1": 0.91479
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.9057645846554525,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.19723710464117222,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.702819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.2238830957527498,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.74332,
            "fmeasure": 0.70707
        },
        "rouge2": {
            "precision": 0.42222,
            "recall": 0.45833,
            "fmeasure": 0.43441
        },
        "rougeL": {
            "precision": 0.52083,
            "recall": 0.66132,
            "fmeasure": 0.57688
        },
        "rougeLsum": {
            "precision": 0.52083,
            "recall": 0.66132,
            "fmeasure": 0.57688
        },
        "nist": 3.59885996224681,
        "bleu": 28.25389,
        "meteor": 0.39171235788608033,
        "bleurt": 0.005,
        "nubia": {
            "semantic_relation": 4.28609,
            "contradiction": 1.36811,
            "irrelevancy": 53.27145,
            "logical_agreement": 45.36043,
            "grammar_ref": 5.72031,
            "grammar_hyp": 5.10806,
            "nubia_score": 0.73645
        },
        "bertscore": {
            "precision": 0.90448,
            "recall": 0.89756,
            "f1": 0.90033
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 138,
        "mean_pred_length": 17.25,
        "std_pred_length": 4.264680527307995,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 92,
        "unique-1": 73,
        "entropy-1": 6.21251909089596,
        "distinct-2": 0.9307692307692308,
        "vocab_size-2": 121,
        "unique-2": 114,
        "entropy-2": 6.868521659182302,
        "cond_entropy-2": 0.5918353984611909,
        "distinct-3": 0.9754098360655737,
        "vocab_size-3": 119,
        "unique-3": 116,
        "entropy-3": 6.881557009694049,
        "cond_entropy-3": 0.02312362289508728,
        "total_length-nopunct": 117,
        "mean_pred_length-nopunct": 14.625,
        "std_pred_length-nopunct": 3.119995993587171,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7435897435897436,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.215414373574069,
        "distinct-2-nopunct": 0.9541284403669725,
        "vocab_size-2-nopunct": 104,
        "unique-2-nopunct": 101,
        "entropy-2-nopunct": 6.658092581657648,
        "cond_entropy-2-nopunct": 0.4723993343961884,
        "distinct-3-nopunct": 0.9900990099009901,
        "vocab_size-3-nopunct": 100,
        "unique-3-nopunct": 99,
        "entropy-3-nopunct": 6.638409502553759,
        "cond_entropy-3-nopunct": -0.010962941035032378,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.4,
            "3": 0.7821782178217822
        },
        "rouge1": {
            "precision": 0.80048,
            "recall": 0.79019,
            "fmeasure": 0.77533
        },
        "rouge2": {
            "precision": 0.62351,
            "recall": 0.58845,
            "fmeasure": 0.58886
        },
        "rougeL": {
            "precision": 0.67546,
            "recall": 0.69232,
            "fmeasure": 0.66593
        },
        "rougeLsum": {
            "precision": 0.67546,
            "recall": 0.69232,
            "fmeasure": 0.66593
        },
        "nist": 5.284899282584301,
        "bleu": 49.13151,
        "meteor": 0.4084447164513438,
        "bleurt": 0.38479,
        "nubia": {
            "semantic_relation": 4.21604,
            "contradiction": 3.61354,
            "irrelevancy": 41.41122,
            "logical_agreement": 54.97523,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.60785,
            "nubia_score": 0.74785
        },
        "bertscore": {
            "precision": 0.93239,
            "recall": 0.92744,
            "f1": 0.92823
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 17,
        "distinct-1": 0.8775510204081632,
        "vocab_size-1": 43,
        "unique-1": 39,
        "entropy-1": 5.328995558400923,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.21319993802876086,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.09729720135491506,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9318181818181818,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.32306798227366,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.04446184939542053,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.5,
            "3": 0.6037735849056604
        },
        "rouge1": {
            "precision": 0.83115,
            "recall": 0.69472,
            "fmeasure": 0.74494
        },
        "rouge2": {
            "precision": 0.6704,
            "recall": 0.58099,
            "fmeasure": 0.61413
        },
        "rougeL": {
            "precision": 0.79411,
            "recall": 0.6747,
            "fmeasure": 0.71896
        },
        "rougeLsum": {
            "precision": 0.79411,
            "recall": 0.6747,
            "fmeasure": 0.71896
        },
        "nist": 3.1287313400336063,
        "bleu": 43.14738,
        "meteor": 0.35238470555976537,
        "bleurt": 0.31163,
        "nubia": {
            "semantic_relation": 4.46202,
            "contradiction": 1.78274,
            "irrelevancy": 31.26643,
            "logical_agreement": 66.95083,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.83926,
            "nubia_score": 0.72331
        },
        "bertscore": {
            "precision": 0.94675,
            "recall": 0.9162,
            "f1": 0.93106
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.546060565661952,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.7450980392156863,
        "vocab_size-1": 38,
        "unique-1": 31,
        "entropy-1": 5.02498318493907,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 46,
        "unique-2": 44,
        "entropy-2": 5.501629167387827,
        "cond_entropy-2": 0.44242439849825915,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.004220515502592859,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 3.6817870057290873,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.952591032002871,
        "distinct-2-nopunct": 0.9534883720930233,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.333241498888144,
        "cond_entropy-2-nopunct": 0.38362605459320676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.004336659814735813,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.8,
            "3": 0.36363636363636365
        },
        "rouge1": {
            "precision": 0.67047,
            "recall": 0.52217,
            "fmeasure": 0.57377
        },
        "rouge2": {
            "precision": 0.24444,
            "recall": 0.1908,
            "fmeasure": 0.20912
        },
        "rougeL": {
            "precision": 0.55113,
            "recall": 0.43757,
            "fmeasure": 0.47648
        },
        "rougeLsum": {
            "precision": 0.55113,
            "recall": 0.43757,
            "fmeasure": 0.47648
        },
        "nist": 2.3012104292692808,
        "bleu": 10.59756,
        "meteor": 0.20850844179542258,
        "bleurt": -0.07126,
        "nubia": {
            "semantic_relation": 3.3601,
            "contradiction": 26.58432,
            "irrelevancy": 65.48425,
            "logical_agreement": 7.93143,
            "grammar_ref": 3.79025,
            "grammar_hyp": 3.89555,
            "nubia_score": 0.45356
        },
        "bertscore": {
            "precision": 0.86823,
            "recall": 0.86596,
            "f1": 0.86655
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 3.897114317029974,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.7358490566037735,
        "vocab_size-1": 39,
        "unique-1": 30,
        "entropy-1": 5.119153237459605,
        "distinct-2": 0.8775510204081632,
        "vocab_size-2": 43,
        "unique-2": 38,
        "entropy-2": 5.354406017540444,
        "cond_entropy-2": 0.12168275698725291,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 42,
        "unique-3": 39,
        "entropy-3": 5.358519762996339,
        "cond_entropy-3": 0.02725186337365455,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.9370039370059056,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7708333333333334,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.07944869850261,
        "distinct-2-nopunct": 0.8636363636363636,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.169547811769943,
        "cond_entropy-2-nopunct": 0.10003303845263589,
        "distinct-3-nopunct": 0.925,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.171928094887363,
        "cond_entropy-3-nopunct": 0.0313686638041517,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8979591836734694
        },
        "rouge1": {
            "precision": 0.93182,
            "recall": 0.90385,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.85,
            "recall": 0.83333,
            "fmeasure": 0.84091
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.88462,
            "fmeasure": 0.89583
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.88462,
            "fmeasure": 0.89583
        },
        "nist": 5.165599592115722,
        "bleu": 74.91948,
        "meteor": 0.5323677405443321,
        "bleurt": 0.78528,
        "nubia": {
            "semantic_relation": 4.75385,
            "contradiction": 2.93035,
            "irrelevancy": 1.00244,
            "logical_agreement": 96.06721,
            "grammar_ref": 5.0449,
            "grammar_hyp": 5.06956,
            "nubia_score": 0.90003
        },
        "bertscore": {
            "precision": 0.97689,
            "recall": 0.96398,
            "f1": 0.97029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 16,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.75,
        "vocab_size-1": 12,
        "unique-1": 8,
        "entropy-1": 3.5,
        "distinct-2": 0.7857142857142857,
        "vocab_size-2": 11,
        "unique-2": 8,
        "entropy-2": 3.3787834934861767,
        "cond_entropy-2": -0.19264507794239588,
        "distinct-3": 0.8333333333333334,
        "vocab_size-3": 10,
        "unique-3": 8,
        "entropy-3": 3.2516291673878226,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.3787834934861767,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.2516291673878226,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.121928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.5625
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.60714,
            "fmeasure": 0.69048
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.39744,
            "fmeasure": 0.48246
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.53571,
            "fmeasure": 0.61905
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.53571,
            "fmeasure": 0.61905
        },
        "nist": 2.013208025713228,
        "bleu": 40.1163,
        "meteor": 0.35588556560324824,
        "bleurt": -0.09846,
        "nubia": {
            "semantic_relation": 3.85454,
            "contradiction": 1.43986,
            "irrelevancy": 17.28877,
            "logical_agreement": 81.27137,
            "grammar_ref": 4.81259,
            "grammar_hyp": 5.10501,
            "nubia_score": 0.62544
        },
        "bertscore": {
            "precision": 0.95291,
            "recall": 0.88275,
            "f1": 0.91557
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.88889,
            "fmeasure": 0.88889
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.875,
            "fmeasure": 0.875
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.88889,
            "fmeasure": 0.88889
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.88889,
            "fmeasure": 0.88889
        },
        "nist": 2.989735285398626,
        "bleu": 78.25423,
        "meteor": 0.9749999999999999,
        "bleurt": 0.93112,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.40784,
            "irrelevancy": 0.56495,
            "logical_agreement": 99.02721,
            "grammar_ref": 6.68645,
            "grammar_hyp": 6.40857,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.99266,
            "recall": 0.99266,
            "f1": 0.99266
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.7608695652173914,
        "vocab_size-1": 35,
        "unique-1": 30,
        "entropy-1": 4.917598847775984,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.4403636237326138,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.1043366598147359,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.825,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.862814895472356,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.209453365628954,
        "cond_entropy-2-nopunct": 0.383863864703757,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.12199052437861026,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 0.78125
        },
        "rouge1": {
            "precision": 0.7502,
            "recall": 0.79074,
            "fmeasure": 0.75788
        },
        "rouge2": {
            "precision": 0.5654,
            "recall": 0.60144,
            "fmeasure": 0.57275
        },
        "rougeL": {
            "precision": 0.69246,
            "recall": 0.73241,
            "fmeasure": 0.70034
        },
        "rougeLsum": {
            "precision": 0.69246,
            "recall": 0.73241,
            "fmeasure": 0.70034
        },
        "nist": 4.517799590593419,
        "bleu": 47.67116,
        "meteor": 0.4288243904498984,
        "bleurt": 0.11876,
        "nubia": {
            "semantic_relation": 3.91784,
            "contradiction": 12.31637,
            "irrelevancy": 70.88717,
            "logical_agreement": 16.79647,
            "grammar_ref": 4.26152,
            "grammar_hyp": 3.95121,
            "nubia_score": 0.68285
        },
        "bertscore": {
            "precision": 0.92109,
            "recall": 0.93881,
            "f1": 0.92558
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.0,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 21,
        "unique-1": 17,
        "entropy-1": 4.286790198827111,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.2493097618368752,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8260869565217391,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.142914673354254,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.23803582396762696,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.6190476190476191
        },
        "rouge1": {
            "precision": 0.82308,
            "recall": 0.60483,
            "fmeasure": 0.69594
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.50875,
            "fmeasure": 0.59082
        },
        "rougeL": {
            "precision": 0.82308,
            "recall": 0.60483,
            "fmeasure": 0.69594
        },
        "rougeLsum": {
            "precision": 0.82308,
            "recall": 0.60483,
            "fmeasure": 0.69594
        },
        "nist": 2.9211539713640073,
        "bleu": 53.21425,
        "meteor": 0.3847502413631662,
        "bleurt": 0.25656,
        "nubia": {
            "semantic_relation": 3.70777,
            "contradiction": 48.33235,
            "irrelevancy": 18.26211,
            "logical_agreement": 33.40554,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.93162,
            "nubia_score": 0.60814
        },
        "bertscore": {
            "precision": 0.96431,
            "recall": 0.89037,
            "f1": 0.92306
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 38,
        "unique-1": 31,
        "entropy-1": 5.110902344426085,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 44,
        "unique-2": 43,
        "entropy-2": 5.44740865188523,
        "cond_entropy-2": 0.323665873434373,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.05191662593186678,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.030633374059376,
        "distinct-2-nopunct": 0.9761904761904762,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.344698375159715,
        "cond_entropy-2-nopunct": 0.29939021935773963,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.05563315263446058,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4375,
            "3": 0.6111111111111112
        },
        "rouge1": {
            "precision": 0.74491,
            "recall": 0.607,
            "fmeasure": 0.66537
        },
        "rouge2": {
            "precision": 0.56729,
            "recall": 0.44424,
            "fmeasure": 0.49305
        },
        "rougeL": {
            "precision": 0.69491,
            "recall": 0.61971,
            "fmeasure": 0.64813
        },
        "rougeLsum": {
            "precision": 0.69491,
            "recall": 0.61971,
            "fmeasure": 0.64813
        },
        "nist": 4.196928252475877,
        "bleu": 47.12494,
        "meteor": 0.34062487676239034,
        "bleurt": -0.0132,
        "nubia": {
            "semantic_relation": 4.07864,
            "contradiction": 14.13459,
            "irrelevancy": 14.65492,
            "logical_agreement": 71.21049,
            "grammar_ref": 4.10939,
            "grammar_hyp": 3.93858,
            "nubia_score": 0.69558
        },
        "bertscore": {
            "precision": 0.92573,
            "recall": 0.90323,
            "f1": 0.90806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.18181818181818182,
            "3": 0.47619047619047616
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.37994,
            "fmeasure": 0.50678
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.17094,
            "fmeasure": 0.22956
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.14878,
            "fmeasure": 0.21688
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.14878,
            "fmeasure": 0.21688
        },
        "nist": 0.13879380550672427,
        "bleu": 7.01356,
        "meteor": 0.1999509209538126,
        "bleurt": -0.43939,
        "nubia": {
            "semantic_relation": 2.68663,
            "contradiction": 4.61879,
            "irrelevancy": 7.2477,
            "logical_agreement": 88.13351,
            "grammar_ref": 3.4256,
            "grammar_hyp": 3.31865,
            "nubia_score": 0.25106
        },
        "bertscore": {
            "precision": 0.8296,
            "recall": 0.74523,
            "f1": 0.77732
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 49,
        "mean_pred_length": 9.8,
        "std_pred_length": 2.1354156504062622,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 12,
        "distinct-1": 0.7346938775510204,
        "vocab_size-1": 36,
        "unique-1": 30,
        "entropy-1": 4.938803405773091,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 42,
        "unique-2": 41,
        "entropy-2": 5.351365993588127,
        "cond_entropy-2": 0.2255146722985315,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.05210920741188306,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 8.6,
        "std_pred_length-nopunct": 2.0591260281974,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7906976744186046,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.9260374290200755,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.1227988949656025,
        "cond_entropy-2-nopunct": 0.262580850903684,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.05944589401957252,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.375,
            "3": 0.7105263157894737
        },
        "rouge1": {
            "precision": 0.72835,
            "recall": 0.69963,
            "fmeasure": 0.71037
        },
        "rouge2": {
            "precision": 0.4781,
            "recall": 0.43322,
            "fmeasure": 0.452
        },
        "rougeL": {
            "precision": 0.72835,
            "recall": 0.69963,
            "fmeasure": 0.71037
        },
        "rougeLsum": {
            "precision": 0.72835,
            "recall": 0.69963,
            "fmeasure": 0.71037
        },
        "nist": 3.8420426685981313,
        "bleu": 36.96296,
        "meteor": 0.3926840420397834,
        "bleurt": 0.18671,
        "nubia": {
            "semantic_relation": 4.02207,
            "contradiction": 20.2232,
            "irrelevancy": 46.35651,
            "logical_agreement": 33.42029,
            "grammar_ref": 5.90284,
            "grammar_hyp": 5.16952,
            "nubia_score": 0.72015
        },
        "bertscore": {
            "precision": 0.91693,
            "recall": 0.91326,
            "f1": 0.9148
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.13652573434569687,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508588,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.35,
            "recall": 0.58333,
            "fmeasure": 0.4375
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.27273,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.41667,
            "fmeasure": 0.3125
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.41667,
            "fmeasure": 0.3125
        },
        "nist": 1.1406698865930953,
        "bleu": 7.94636,
        "meteor": 0.2904516730189926,
        "bleurt": -0.05434,
        "nubia": {
            "semantic_relation": 3.89654,
            "contradiction": 0.33844,
            "irrelevancy": 98.01995,
            "logical_agreement": 1.64161,
            "grammar_ref": 5.68739,
            "grammar_hyp": 3.45467,
            "nubia_score": 0.68151
        },
        "bertscore": {
            "precision": 0.77911,
            "recall": 0.80954,
            "f1": 0.79403
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.74411,
            "fmeasure": 0.71818
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.25,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.66667,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.66667,
            "fmeasure": 0.6
        },
        "nist": 2.657819047324848,
        "bleu": 8.99827,
        "meteor": 0.3303172033251126,
        "bleurt": 0.58116,
        "nubia": {
            "semantic_relation": 4.878,
            "contradiction": 0.21037,
            "irrelevancy": 0.55272,
            "logical_agreement": 99.23691,
            "grammar_ref": 6.26263,
            "grammar_hyp": 5.77767,
            "nubia_score": 0.95491
        },
        "bertscore": {
            "precision": 0.94128,
            "recall": 0.92026,
            "f1": 0.92987
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 63,
        "mean_pred_length": 12.6,
        "std_pred_length": 4.317406628984581,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.6349206349206349,
        "vocab_size-1": 40,
        "unique-1": 30,
        "entropy-1": 5.03887650320208,
        "distinct-2": 0.7586206896551724,
        "vocab_size-2": 44,
        "unique-2": 34,
        "entropy-2": 5.3147090122943474,
        "cond_entropy-2": 0.15656314059317294,
        "distinct-3": 0.8490566037735849,
        "vocab_size-3": 45,
        "unique-3": 38,
        "entropy-3": 5.411790501692187,
        "cond_entropy-3": 0.14833356325003227,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 11.4,
        "std_pred_length-nopunct": 3.97994974842648,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.999385189527424,
        "distinct-2-nopunct": 0.7307692307692307,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 5.094482506519421,
        "cond_entropy-2-nopunct": 0.13678047320711967,
        "distinct-3-nopunct": 0.8297872340425532,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.198101883546503,
        "cond_entropy-3-nopunct": 0.14680631443364053,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.8135593220338984
        },
        "rouge1": {
            "precision": 0.88169,
            "recall": 0.83058,
            "fmeasure": 0.84951
        },
        "rouge2": {
            "precision": 0.76294,
            "recall": 0.74337,
            "fmeasure": 0.74954
        },
        "rougeL": {
            "precision": 0.83792,
            "recall": 0.80731,
            "fmeasure": 0.81794
        },
        "rougeLsum": {
            "precision": 0.83792,
            "recall": 0.80731,
            "fmeasure": 0.81794
        },
        "nist": 4.595026199630461,
        "bleu": 59.71994,
        "meteor": 0.44867785785555775,
        "bleurt": 0.71947,
        "nubia": {
            "semantic_relation": 4.63089,
            "contradiction": 0.714,
            "irrelevancy": 0.6978,
            "logical_agreement": 98.5882,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.61323,
            "nubia_score": 0.90921
        },
        "bertscore": {
            "precision": 0.9786,
            "recall": 0.95848,
            "f1": 0.96817
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.75,
            "fmeasure": 0.81081
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.57895,
            "fmeasure": 0.62857
        },
        "rougeL": {
            "precision": 0.54902,
            "recall": 0.54167,
            "fmeasure": 0.54382
        },
        "rougeLsum": {
            "precision": 0.54902,
            "recall": 0.54167,
            "fmeasure": 0.54382
        },
        "nist": 3.731655536393195,
        "bleu": 43.75969,
        "meteor": 0.4252324522719118,
        "bleurt": 0.51374,
        "nubia": {
            "semantic_relation": 4.66466,
            "contradiction": 0.41866,
            "irrelevancy": 17.93785,
            "logical_agreement": 81.64349,
            "grammar_ref": 3.95052,
            "grammar_hyp": 3.64888,
            "nubia_score": 0.96387
        },
        "bertscore": {
            "precision": 0.94227,
            "recall": 0.93175,
            "f1": 0.92507
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 71,
        "mean_pred_length": 17.75,
        "std_pred_length": 7.013380069552769,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.704225352112676,
        "vocab_size-1": 50,
        "unique-1": 39,
        "entropy-1": 5.426027711261666,
        "distinct-2": 0.8805970149253731,
        "vocab_size-2": 59,
        "unique-2": 52,
        "entropy-2": 5.8160162426642845,
        "cond_entropy-2": 0.3137926751783246,
        "distinct-3": 0.9206349206349206,
        "vocab_size-3": 58,
        "unique-3": 53,
        "entropy-3": 5.818549764769759,
        "cond_entropy-3": 0.018411169584421308,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 6.609652033201143,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7301587301587301,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.320389796749851,
        "distinct-2-nopunct": 0.864406779661017,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.598661905257372,
        "cond_entropy-2-nopunct": 0.2959432611563235,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.599541531706475,
        "cond_entropy-3-nopunct": 0.0033509823839723025,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.16666666666666666,
            "3": 0.5277777777777778
        },
        "rouge1": {
            "precision": 0.70648,
            "recall": 0.58469,
            "fmeasure": 0.61795
        },
        "rouge2": {
            "precision": 0.52145,
            "recall": 0.45827,
            "fmeasure": 0.47475
        },
        "rougeL": {
            "precision": 0.6063,
            "recall": 0.52483,
            "fmeasure": 0.54696
        },
        "rougeLsum": {
            "precision": 0.6063,
            "recall": 0.52483,
            "fmeasure": 0.54696
        },
        "nist": 2.2337216062806298,
        "bleu": 28.13801,
        "meteor": 0.24624836523266333,
        "bleurt": 0.1221,
        "nubia": {
            "semantic_relation": 3.62671,
            "contradiction": 53.16444,
            "irrelevancy": 12.18366,
            "logical_agreement": 34.65191,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.60371,
            "nubia_score": 0.55535
        },
        "bertscore": {
            "precision": 0.91801,
            "recall": 0.8721,
            "f1": 0.8934
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.80952,
            "fmeasure": 0.87179
        },
        "rouge2": {
            "precision": 0.75758,
            "recall": 0.64103,
            "fmeasure": 0.69444
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.66667,
            "fmeasure": 0.71795
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.66667,
            "fmeasure": 0.71795
        },
        "nist": 5.437938367410022,
        "bleu": 93.65138,
        "meteor": 0.45868150025143484,
        "bleurt": 0.48642,
        "nubia": {
            "semantic_relation": 4.75946,
            "contradiction": 0.17689,
            "irrelevancy": 0.48149,
            "logical_agreement": 99.34162,
            "grammar_ref": 5.70189,
            "grammar_hyp": 4.93056,
            "nubia_score": 0.98343
        },
        "bertscore": {
            "precision": 0.9623,
            "recall": 0.95162,
            "f1": 0.95693
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 93,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.752192476461084,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 62,
        "unique-1": 48,
        "entropy-1": 5.640783810875401,
        "distinct-2": 0.9310344827586207,
        "vocab_size-2": 81,
        "unique-2": 75,
        "entropy-2": 6.3050124613659655,
        "cond_entropy-2": 0.6160135642914276,
        "distinct-3": 0.9876543209876543,
        "vocab_size-3": 80,
        "unique-3": 79,
        "entropy-3": 6.315158644859923,
        "cond_entropy-3": 0.020363297159353366,
        "total_length-nopunct": 86,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 4.4969125210773475,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6976744186046512,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.603078853312899,
        "distinct-2-nopunct": 0.925,
        "vocab_size-2-nopunct": 74,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.171928094887358,
        "cond_entropy-2-nopunct": 0.5982761529196404,
        "distinct-3-nopunct": 0.9864864864864865,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.182426338601928,
        "cond_entropy-3-nopunct": 0.02266040587672251,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.375,
            "3": 0.7708333333333334
        },
        "rouge1": {
            "precision": 0.66096,
            "recall": 0.70992,
            "fmeasure": 0.65052
        },
        "rouge2": {
            "precision": 0.4172,
            "recall": 0.45637,
            "fmeasure": 0.40772
        },
        "rougeL": {
            "precision": 0.5529,
            "recall": 0.5878,
            "fmeasure": 0.53782
        },
        "rougeLsum": {
            "precision": 0.5529,
            "recall": 0.5878,
            "fmeasure": 0.53782
        },
        "nist": 3.8300484680269165,
        "bleu": 29.95681,
        "meteor": 0.3634048915481926,
        "bleurt": -0.03258,
        "nubia": {
            "semantic_relation": 3.984,
            "contradiction": 0.83694,
            "irrelevancy": 38.31532,
            "logical_agreement": 60.84774,
            "grammar_ref": 4.25456,
            "grammar_hyp": 4.05697,
            "nubia_score": 0.70682
        },
        "bertscore": {
            "precision": 0.88335,
            "recall": 0.88661,
            "f1": 0.88267
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 78,
        "mean_pred_length": 15.6,
        "std_pred_length": 4.317406628984581,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.6410256410256411,
        "vocab_size-1": 50,
        "unique-1": 34,
        "entropy-1": 5.346693488748487,
        "distinct-2": 0.8356164383561644,
        "vocab_size-2": 61,
        "unique-2": 51,
        "entropy-2": 5.833660175318382,
        "cond_entropy-2": 0.3922256341881359,
        "distinct-3": 0.8823529411764706,
        "vocab_size-3": 60,
        "unique-3": 52,
        "entropy-3": 5.8521687236032855,
        "cond_entropy-3": 0.04469710589973404,
        "total_length-nopunct": 72,
        "mean_pred_length-nopunct": 14.4,
        "std_pred_length-nopunct": 4.6303347611160905,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.314235550408469,
        "distinct-2-nopunct": 0.8208955223880597,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.678029488965231,
        "cond_entropy-2-nopunct": 0.3978006140070542,
        "distinct-3-nopunct": 0.8709677419354839,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.69613179425784,
        "cond_entropy-3-nopunct": 0.04939744250974798,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.75,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.69671,
            "recall": 0.75327,
            "fmeasure": 0.68715
        },
        "rouge2": {
            "precision": 0.43631,
            "recall": 0.50632,
            "fmeasure": 0.44918
        },
        "rougeL": {
            "precision": 0.58446,
            "recall": 0.64053,
            "fmeasure": 0.58472
        },
        "rougeLsum": {
            "precision": 0.58446,
            "recall": 0.64053,
            "fmeasure": 0.58472
        },
        "nist": 4.404607645717697,
        "bleu": 39.34813,
        "meteor": 0.3868423033443888,
        "bleurt": 0.18955,
        "nubia": {
            "semantic_relation": 3.99543,
            "contradiction": 5.12501,
            "irrelevancy": 54.93236,
            "logical_agreement": 39.94263,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.1665,
            "nubia_score": 0.7216
        },
        "bertscore": {
            "precision": 0.9175,
            "recall": 0.91825,
            "f1": 0.91573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.884183719779189,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.3867829713016689,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.452819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.4905497624194164,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.875
        },
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.88736,
            "fmeasure": 0.78602
        },
        "rouge2": {
            "precision": 0.59375,
            "recall": 0.75962,
            "fmeasure": 0.66626
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 0.88736,
            "fmeasure": 0.78602
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 0.88736,
            "fmeasure": 0.78602
        },
        "nist": 2.681857998677189,
        "bleu": 45.80519,
        "meteor": 0.4761015269167852,
        "bleurt": 0.47099,
        "nubia": {
            "semantic_relation": 3.07467,
            "contradiction": 94.47637,
            "irrelevancy": 5.17849,
            "logical_agreement": 0.34514,
            "grammar_ref": 3.57757,
            "grammar_hyp": 2.86095,
            "nubia_score": 0.55872
        },
        "bertscore": {
            "precision": 0.93395,
            "recall": 0.98671,
            "f1": 0.95961
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 47,
        "mean_pred_length": 11.75,
        "std_pred_length": 4.14578098794425,
        "median_pred_length": 10.5,
        "min_pred_length": 8,
        "max_pred_length": 18,
        "distinct-1": 0.7446808510638298,
        "vocab_size-1": 35,
        "unique-1": 29,
        "entropy-1": 4.908535064941462,
        "distinct-2": 0.9767441860465116,
        "vocab_size-2": 42,
        "unique-2": 41,
        "entropy-2": 5.379753126795121,
        "cond_entropy-2": 0.34526957689888554,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.0895804845577984,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 10.75,
        "std_pred_length-nopunct": 4.14578098794425,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7906976744186046,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.906159452920695,
        "distinct-2-nopunct": 0.9743589743589743,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.234120167580196,
        "cond_entropy-2-nopunct": 0.38130484817554194,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.09897634477442474,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.6,
            "3": 0.84
        },
        "rouge1": {
            "precision": 0.70965,
            "recall": 0.80708,
            "fmeasure": 0.75032
        },
        "rouge2": {
            "precision": 0.52469,
            "recall": 0.59865,
            "fmeasure": 0.55457
        },
        "rougeL": {
            "precision": 0.66308,
            "recall": 0.74643,
            "fmeasure": 0.69768
        },
        "rougeLsum": {
            "precision": 0.66308,
            "recall": 0.74643,
            "fmeasure": 0.69768
        },
        "nist": 4.078590020085835,
        "bleu": 50.42079,
        "meteor": 0.5281255149923659,
        "bleurt": 0.45828,
        "nubia": {
            "semantic_relation": 4.59323,
            "contradiction": 1.29222,
            "irrelevancy": 53.82171,
            "logical_agreement": 44.88607,
            "grammar_ref": 4.98306,
            "grammar_hyp": 4.58894,
            "nubia_score": 0.86101
        },
        "bertscore": {
            "precision": 0.936,
            "recall": 0.95449,
            "f1": 0.94378
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 91,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.3094580368566735,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.6703296703296703,
        "vocab_size-1": 61,
        "unique-1": 45,
        "entropy-1": 5.657420156844261,
        "distinct-2": 0.8928571428571429,
        "vocab_size-2": 75,
        "unique-2": 67,
        "entropy-2": 6.169044952514909,
        "cond_entropy-2": 0.3978491573272512,
        "distinct-3": 0.922077922077922,
        "vocab_size-3": 71,
        "unique-3": 65,
        "entropy-3": 6.110942384850748,
        "cond_entropy-3": -0.03780507036745047,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 11.142857142857142,
        "std_pred_length-nopunct": 3.5225222874108435,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7435897435897436,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.66662449442007,
        "distinct-2-nopunct": 0.8873239436619719,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.91376278848829,
        "cond_entropy-2-nopunct": 0.27997553450619345,
        "distinct-3-nopunct": 0.921875,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.84375,
        "cond_entropy-3-nopunct": -0.05982700228337791,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2692307692307692,
            "2": 0.625,
            "3": 0.5869565217391305
        },
        "rouge1": {
            "precision": 0.58114,
            "recall": 0.55947,
            "fmeasure": 0.55457
        },
        "rouge2": {
            "precision": 0.26719,
            "recall": 0.24534,
            "fmeasure": 0.24631
        },
        "rougeL": {
            "precision": 0.46546,
            "recall": 0.45901,
            "fmeasure": 0.44747
        },
        "rougeLsum": {
            "precision": 0.46546,
            "recall": 0.45901,
            "fmeasure": 0.44747
        },
        "nist": 3.9456186850203276,
        "bleu": 24.54448,
        "meteor": 0.3033323994739522,
        "bleurt": 0.08104,
        "nubia": {
            "semantic_relation": 3.83803,
            "contradiction": 9.06895,
            "irrelevancy": 28.89542,
            "logical_agreement": 62.03563,
            "grammar_ref": 5.09695,
            "grammar_hyp": 4.79846,
            "nubia_score": 0.60624
        },
        "bertscore": {
            "precision": 0.8981,
            "recall": 0.88435,
            "f1": 0.89091
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 1.0,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 17,
        "distinct-1": 0.65625,
        "vocab_size-1": 21,
        "unique-1": 13,
        "entropy-1": 4.241729296672174,
        "distinct-2": 0.8,
        "vocab_size-2": 24,
        "unique-2": 20,
        "entropy-2": 4.456564762130954,
        "cond_entropy-2": 0.1987201790139675,
        "distinct-3": 0.8928571428571429,
        "vocab_size-3": 25,
        "unique-3": 23,
        "entropy-3": 4.5661089398374815,
        "cond_entropy-3": 0.14171030866920947,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.6785714285714286,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.0836169753972325,
        "distinct-2-nopunct": 0.7692307692307693,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.18083298720544,
        "cond_entropy-2-nopunct": 0.09192806536973061,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.303508854797679,
        "cond_entropy-3-nopunct": 0.09993632430682713,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.76429,
            "fmeasure": 0.69273
        },
        "rouge2": {
            "precision": 0.41026,
            "recall": 0.50366,
            "fmeasure": 0.44747
        },
        "rougeL": {
            "precision": 0.63095,
            "recall": 0.74524,
            "fmeasure": 0.67713
        },
        "rougeLsum": {
            "precision": 0.63095,
            "recall": 0.74524,
            "fmeasure": 0.67713
        },
        "nist": 3.1437267920254928,
        "bleu": 35.21627,
        "meteor": 0.4308284890099298,
        "bleurt": 0.50136,
        "nubia": {
            "semantic_relation": 4.81738,
            "contradiction": 0.29996,
            "irrelevancy": 17.93658,
            "logical_agreement": 81.76346,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.29106,
            "nubia_score": 0.86429
        },
        "bertscore": {
            "precision": 0.92626,
            "recall": 0.93442,
            "f1": 0.93031
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 103,
        "mean_pred_length": 14.714285714285714,
        "std_pred_length": 5.7498890849994595,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6990291262135923,
        "vocab_size-1": 72,
        "unique-1": 59,
        "entropy-1": 5.834953528490282,
        "distinct-2": 0.9270833333333334,
        "vocab_size-2": 89,
        "unique-2": 82,
        "entropy-2": 6.439129167387829,
        "cond_entropy-2": 0.4615646444855413,
        "distinct-3": 0.9325842696629213,
        "vocab_size-3": 83,
        "unique-3": 77,
        "entropy-3": 6.34090197029225,
        "cond_entropy-3": -0.08675715964239877,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 12.428571428571429,
        "std_pred_length-nopunct": 4.370588154508101,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7931034482758621,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.9095369216353175,
        "distinct-2-nopunct": 0.925,
        "vocab_size-2-nopunct": 74,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.17192809488736,
        "cond_entropy-2-nopunct": 0.2840642484957176,
        "distinct-3-nopunct": 0.9315068493150684,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 6.05283825751016,
        "cond_entropy-3-nopunct": -0.1184049058703589,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.38461538461538464,
            "2": 0.6666666666666666,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.7268,
            "recall": 0.64289,
            "fmeasure": 0.66925
        },
        "rouge2": {
            "precision": 0.45307,
            "recall": 0.39867,
            "fmeasure": 0.41566
        },
        "rougeL": {
            "precision": 0.63682,
            "recall": 0.57894,
            "fmeasure": 0.59313
        },
        "rougeLsum": {
            "precision": 0.63682,
            "recall": 0.57894,
            "fmeasure": 0.59313
        },
        "nist": 4.799654530478982,
        "bleu": 32.83925,
        "meteor": 0.3208430971280247,
        "bleurt": 0.25355,
        "nubia": {
            "semantic_relation": 4.3007,
            "contradiction": 7.63569,
            "irrelevancy": 23.8408,
            "logical_agreement": 68.52351,
            "grammar_ref": 4.57813,
            "grammar_hyp": 4.37401,
            "nubia_score": 0.74631
        },
        "bertscore": {
            "precision": 0.92749,
            "recall": 0.91558,
            "f1": 0.92123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.0,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.8125,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.040223928941851936,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9642857142857143,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.735926350629034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": -0.029992126993435266,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9629629629629629
        },
        "rouge1": {
            "precision": 0.96875,
            "recall": 0.94118,
            "fmeasure": 0.95455
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.90625,
            "fmeasure": 0.91935
        },
        "rougeL": {
            "precision": 0.96875,
            "recall": 0.94118,
            "fmeasure": 0.95455
        },
        "rougeLsum": {
            "precision": 0.96875,
            "recall": 0.94118,
            "fmeasure": 0.95455
        },
        "nist": 4.961719276477761,
        "bleu": 91.23321,
        "meteor": 0.6177006141496403,
        "bleurt": 0.84934,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30569,
            "irrelevancy": 0.54296,
            "logical_agreement": 99.15136,
            "grammar_ref": 5.04945,
            "grammar_hyp": 4.85235,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.99648,
            "recall": 0.99439,
            "f1": 0.99543
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.0,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 17,
        "distinct-1": 0.8,
        "vocab_size-1": 24,
        "unique-1": 19,
        "entropy-1": 4.481727678869737,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.28456745152635227,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8076923076923077,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.286790198827111,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.3326430951702085,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.2,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.7152,
            "recall": 0.72478,
            "fmeasure": 0.71501
        },
        "rouge2": {
            "precision": 0.41346,
            "recall": 0.42262,
            "fmeasure": 0.41459
        },
        "rougeL": {
            "precision": 0.48352,
            "recall": 0.51402,
            "fmeasure": 0.49626
        },
        "rougeLsum": {
            "precision": 0.48352,
            "recall": 0.51402,
            "fmeasure": 0.49626
        },
        "nist": 4.030369384924954,
        "bleu": 21.03595,
        "meteor": 0.3949959795884154,
        "bleurt": 0.21156,
        "nubia": {
            "semantic_relation": 4.50158,
            "contradiction": 1.44754,
            "irrelevancy": 35.46302,
            "logical_agreement": 63.08944,
            "grammar_ref": 5.35082,
            "grammar_hyp": 4.83523,
            "nubia_score": 0.87109
        },
        "bertscore": {
            "precision": 0.93569,
            "recall": 0.9401,
            "f1": 0.93766
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 5.0,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.6578947368421053,
        "vocab_size-1": 25,
        "unique-1": 15,
        "entropy-1": 4.468726448326827,
        "distinct-2": 0.8055555555555556,
        "vocab_size-2": 29,
        "unique-2": 22,
        "entropy-2": 4.781036112553421,
        "cond_entropy-2": 0.30004305673308274,
        "distinct-3": 0.8823529411764706,
        "vocab_size-3": 30,
        "unique-3": 26,
        "entropy-3": 4.852168723603279,
        "cond_entropy-3": 0.09400842804332116,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6764705882352942,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.3342381214139625,
        "distinct-2-nopunct": 0.8125,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.625,
        "cond_entropy-2-nopunct": 0.30658842357581106,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.706890595608519,
        "cond_entropy-3-nopunct": 0.07355726227518526,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.7307692307692307
        },
        "rouge1": {
            "precision": 0.71612,
            "recall": 0.77399,
            "fmeasure": 0.74363
        },
        "rouge2": {
            "precision": 0.57222,
            "recall": 0.58892,
            "fmeasure": 0.57902
        },
        "rougeL": {
            "precision": 0.63675,
            "recall": 0.66457,
            "fmeasure": 0.64903
        },
        "rougeLsum": {
            "precision": 0.63675,
            "recall": 0.66457,
            "fmeasure": 0.64903
        },
        "nist": 4.301539544766586,
        "bleu": 54.98703,
        "meteor": 0.39993112383871315,
        "bleurt": 0.39268,
        "nubia": {
            "semantic_relation": 4.24675,
            "contradiction": 5.98675,
            "irrelevancy": 2.14109,
            "logical_agreement": 91.87216,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.40392,
            "nubia_score": 0.86667
        },
        "bertscore": {
            "precision": 0.95497,
            "recall": 0.92201,
            "f1": 0.93768
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601997,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.03126257645096008,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.16666666666666666,
            "3": 0.4230769230769231
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.3526,
            "fmeasure": 0.47938
        },
        "rouge2": {
            "precision": 0.29825,
            "recall": 0.13056,
            "fmeasure": 0.1815
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.24072,
            "fmeasure": 0.33151
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.24072,
            "fmeasure": 0.33151
        },
        "nist": 0.3751380274458831,
        "bleu": 7.03416,
        "meteor": 0.17062804806321522,
        "bleurt": -0.64377,
        "nubia": {
            "semantic_relation": 3.39969,
            "contradiction": 5.47712,
            "irrelevancy": 93.15594,
            "logical_agreement": 1.36693,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.8745,
            "nubia_score": 0.26367
        },
        "bertscore": {
            "precision": 0.86933,
            "recall": 0.81338,
            "f1": 0.84042
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.83333,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.6,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.83333,
            "fmeasure": 0.71429
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.83333,
            "fmeasure": 0.71429
        },
        "nist": 1.871569948038403,
        "bleu": 35.49481,
        "meteor": 0.4964095982072904,
        "bleurt": -0.03416,
        "nubia": {
            "semantic_relation": 3.79177,
            "contradiction": 4.95623,
            "irrelevancy": 54.57702,
            "logical_agreement": 40.46676,
            "grammar_ref": 7.84225,
            "grammar_hyp": 6.86058,
            "nubia_score": 0.64873
        },
        "bertscore": {
            "precision": 0.91515,
            "recall": 0.93955,
            "f1": 0.92719
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 94,
        "mean_pred_length": 11.75,
        "std_pred_length": 3.307189138830738,
        "median_pred_length": 10.5,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.5425531914893617,
        "vocab_size-1": 51,
        "unique-1": 37,
        "entropy-1": 5.2309464645758235,
        "distinct-2": 0.7441860465116279,
        "vocab_size-2": 64,
        "unique-2": 55,
        "entropy-2": 5.7563852143016705,
        "cond_entropy-2": 0.3694985066655467,
        "distinct-3": 0.7948717948717948,
        "vocab_size-3": 62,
        "unique-3": 56,
        "entropy-3": 5.746940680400715,
        "cond_entropy-3": 0.059261059986263305,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 10.375,
        "std_pred_length-nopunct": 2.6896793489187516,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.5903614457831325,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.222418986944438,
        "distinct-2-nopunct": 0.7066666666666667,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.46069015083673,
        "cond_entropy-2-nopunct": 0.31692497003005676,
        "distinct-3-nopunct": 0.7611940298507462,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.439223518815977,
        "cond_entropy-3-nopunct": 0.055324835401247094,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.16666666666666666,
            "3": 0.8518518518518519
        },
        "rouge1": {
            "precision": 0.84236,
            "recall": 0.80507,
            "fmeasure": 0.82171
        },
        "rouge2": {
            "precision": 0.73065,
            "recall": 0.70503,
            "fmeasure": 0.71623
        },
        "rougeL": {
            "precision": 0.81562,
            "recall": 0.78124,
            "fmeasure": 0.79655
        },
        "rougeLsum": {
            "precision": 0.81562,
            "recall": 0.78124,
            "fmeasure": 0.79655
        },
        "nist": 5.319265802091247,
        "bleu": 68.19013,
        "meteor": 0.5081513784902496,
        "bleurt": 0.64803,
        "nubia": {
            "semantic_relation": 4.46411,
            "contradiction": 9.50298,
            "irrelevancy": 4.15562,
            "logical_agreement": 86.3414,
            "grammar_ref": 5.07225,
            "grammar_hyp": 4.93893,
            "nubia_score": 0.85845
        },
        "bertscore": {
            "precision": 0.96142,
            "recall": 0.95139,
            "f1": 0.95631
        }
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "t5-small/totto_test",
        "N": 300,
        "total_length": 4502,
        "mean_pred_length": 15.006666666666666,
        "std_pred_length": 4.460936623126981,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 28,
        "distinct-1": 0.38183029764549087,
        "vocab_size-1": 1719,
        "unique-1": 1347,
        "entropy-1": 8.73741343003217,
        "distinct-2": 0.7705854355069015,
        "vocab_size-2": 3238,
        "unique-2": 2886,
        "entropy-2": 11.290222173307491,
        "cond_entropy-2": 2.264780512403599,
        "distinct-3": 0.9231163505894413,
        "vocab_size-3": 3602,
        "unique-3": 3448,
        "entropy-3": 11.730136798025352,
        "cond_entropy-3": 0.43250327861620746,
        "total_length-nopunct": 3948,
        "mean_pred_length-nopunct": 13.16,
        "std_pred_length-nopunct": 4.084246156473268,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.4331306990881459,
        "vocab_size-1-nopunct": 1710,
        "unique-1-nopunct": 1346,
        "entropy-1-nopunct": 9.113451237405537,
        "distinct-2-nopunct": 0.7960526315789473,
        "vocab_size-2-nopunct": 2904,
        "unique-2-nopunct": 2638,
        "entropy-2-nopunct": 11.145716580735426,
        "cond_entropy-2-nopunct": 2.1248759701690014,
        "distinct-3-nopunct": 0.937873357228196,
        "vocab_size-3-nopunct": 3140,
        "unique-3-nopunct": 3035,
        "entropy-3-nopunct": 11.545885702028498,
        "cond_entropy-3-nopunct": 0.42013041228482595,
        "msttr-100": 0.71933,
        "msttr-100_nopunct": 0.77333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17852975495915985,
            "2": 0.3559539052496799,
            "3": 0.7545731707317073
        },
        "rouge1": {
            "precision": 0.77649,
            "recall": 0.72679,
            "fmeasure": 0.73939
        },
        "rouge2": {
            "precision": 0.53254,
            "recall": 0.49915,
            "fmeasure": 0.50718
        },
        "rougeL": {
            "precision": 0.65973,
            "recall": 0.62197,
            "fmeasure": 0.63014
        },
        "rougeLsum": {
            "precision": 0.65973,
            "recall": 0.62197,
            "fmeasure": 0.63014
        },
        "nist": 7.931714520162449,
        "bleu": 40.4149,
        "meteor": 0.3807676804943576,
        "bleurt": 0.30637,
        "nubia": {
            "semantic_relation": 4.28354,
            "contradiction": 8.91857,
            "irrelevancy": 24.89293,
            "logical_agreement": 66.1885,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.8903,
            "nubia_score": 0.74096
        },
        "bertscore": {
            "precision": 0.93248,
            "recall": 0.92551,
            "f1": 0.92788
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.75,
            "fmeasure": 0.70588
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "nist": 2.7311026318526266,
        "bleu": 58.77284,
        "meteor": 0.5459967999267895,
        "bleurt": 0.64175,
        "nubia": {
            "semantic_relation": 4.90761,
            "contradiction": 2.45107,
            "irrelevancy": 28.43244,
            "logical_agreement": 69.11649,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.48645,
            "nubia_score": 0.99014
        },
        "bertscore": {
            "precision": 0.97893,
            "recall": 0.98644,
            "f1": 0.98267
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 133,
        "mean_pred_length": 16.625,
        "std_pred_length": 2.8256636388643286,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.6917293233082706,
        "vocab_size-1": 92,
        "unique-1": 74,
        "entropy-1": 6.217687770717302,
        "distinct-2": 0.96,
        "vocab_size-2": 120,
        "unique-2": 115,
        "entropy-2": 6.885784284662096,
        "cond_entropy-2": 0.5484906968557329,
        "distinct-3": 0.9743589743589743,
        "vocab_size-3": 114,
        "unique-3": 111,
        "entropy-3": 6.819082668301336,
        "cond_entropy-3": -0.06123153089064833,
        "total_length-nopunct": 119,
        "mean_pred_length-nopunct": 14.875,
        "std_pred_length-nopunct": 2.315032397181517,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7478991596638656,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.254155318286704,
        "distinct-2-nopunct": 0.954954954954955,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 101,
        "entropy-2-nopunct": 6.704325776260029,
        "cond_entropy-2-nopunct": 0.4783263098667354,
        "distinct-3-nopunct": 0.970873786407767,
        "vocab_size-3-nopunct": 100,
        "unique-3-nopunct": 97,
        "entropy-3-nopunct": 6.628248099998768,
        "cond_entropy-3-nopunct": -0.06908038771057684,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13043478260869565,
            "2": 0.3076923076923077,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.73288,
            "recall": 0.66436,
            "fmeasure": 0.68142
        },
        "rouge2": {
            "precision": 0.45711,
            "recall": 0.42086,
            "fmeasure": 0.42754
        },
        "rougeL": {
            "precision": 0.54945,
            "recall": 0.49971,
            "fmeasure": 0.51083
        },
        "rougeLsum": {
            "precision": 0.54945,
            "recall": 0.49971,
            "fmeasure": 0.51083
        },
        "nist": 4.189522667429889,
        "bleu": 29.27646,
        "meteor": 0.3264456527849367,
        "bleurt": 0.12204,
        "nubia": {
            "semantic_relation": 3.91464,
            "contradiction": 14.66489,
            "irrelevancy": 23.15014,
            "logical_agreement": 62.18497,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.80816,
            "nubia_score": 0.61572
        },
        "bertscore": {
            "precision": 0.92136,
            "recall": 0.90049,
            "f1": 0.90966
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 4.109609335312651,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 34,
        "unique-1": 28,
        "entropy-1": 4.925118550357138,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 40,
        "unique-2": 39,
        "entropy-2": 5.308771516813203,
        "cond_entropy-2": 0.3067761787164808,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.056992912227129475,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 2.8674417556808756,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7837837837837838,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.702564514219128,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.028639311838573,
        "cond_entropy-2-nopunct": 0.3708002845085506,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.06875040183120606,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.0,
            "3": 0.7083333333333334
        },
        "rouge1": {
            "precision": 0.64379,
            "recall": 0.67647,
            "fmeasure": 0.64571
        },
        "rouge2": {
            "precision": 0.44381,
            "recall": 0.48194,
            "fmeasure": 0.45069
        },
        "rougeL": {
            "precision": 0.61601,
            "recall": 0.65686,
            "fmeasure": 0.62272
        },
        "rougeLsum": {
            "precision": 0.61601,
            "recall": 0.65686,
            "fmeasure": 0.62272
        },
        "nist": 4.315984603450454,
        "bleu": 50.60793,
        "meteor": 0.3713415814569792,
        "bleurt": 0.06826,
        "nubia": {
            "semantic_relation": 3.43507,
            "contradiction": 33.42828,
            "irrelevancy": 30.36392,
            "logical_agreement": 36.20781,
            "grammar_ref": 4.11451,
            "grammar_hyp": 4.08928,
            "nubia_score": 0.53968
        },
        "bertscore": {
            "precision": 0.91657,
            "recall": 0.92422,
            "f1": 0.91902
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.7,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.621928094887362,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 17,
        "unique-2": 15,
        "entropy-2": 4.03740119765411,
        "cond_entropy-2": 0.4523152080299074,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": 0.14421971022094907,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.5068905956085183,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.11475004073479991,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964164,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.73077,
            "fmeasure": 0.65873
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.41414,
            "fmeasure": 0.36923
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.73077,
            "fmeasure": 0.65873
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.73077,
            "fmeasure": 0.65873
        },
        "nist": 2.5057422805069214,
        "bleu": 36.71109,
        "meteor": 0.40876222815353047,
        "bleurt": -0.04065,
        "nubia": {
            "semantic_relation": 4.09515,
            "contradiction": 3.99151,
            "irrelevancy": 3.09501,
            "logical_agreement": 92.91347,
            "grammar_ref": 5.03839,
            "grammar_hyp": 4.40506,
            "nubia_score": 0.6833
        },
        "bertscore": {
            "precision": 0.90972,
            "recall": 0.8957,
            "f1": 0.90266
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.64935,
            "fmeasure": 0.68364
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "nist": 3.8107815848368243,
        "bleu": 71.38958,
        "meteor": 0.9233576642335767,
        "bleurt": 0.61973,
        "nubia": {
            "semantic_relation": 4.6448,
            "contradiction": 0.52652,
            "irrelevancy": 0.67281,
            "logical_agreement": 98.80067,
            "grammar_ref": 5.25223,
            "grammar_hyp": 5.73563,
            "nubia_score": 0.8067
        },
        "bertscore": {
            "precision": 0.98905,
            "recall": 0.98905,
            "f1": 0.98905
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.49689,
            "fmeasure": 0.49231
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.3986,
            "fmeasure": 0.39382
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.49689,
            "fmeasure": 0.49231
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.49689,
            "fmeasure": 0.49231
        },
        "nist": 1.8157443619540472,
        "bleu": 37.08164,
        "meteor": 0.33716964090221996,
        "bleurt": -0.19523,
        "nubia": {
            "semantic_relation": 3.62162,
            "contradiction": 0.09201,
            "irrelevancy": 99.77772,
            "logical_agreement": 0.13027,
            "grammar_ref": 4.57081,
            "grammar_hyp": 4.69829,
            "nubia_score": 0.49899
        },
        "bertscore": {
            "precision": 0.86501,
            "recall": 0.89427,
            "f1": 0.8794
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.3125
        },
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.49206,
            "fmeasure": 0.50855
        },
        "rouge2": {
            "precision": 0.2037,
            "recall": 0.18596,
            "fmeasure": 0.1944
        },
        "rougeL": {
            "precision": 0.29825,
            "recall": 0.27381,
            "fmeasure": 0.28547
        },
        "rougeLsum": {
            "precision": 0.29825,
            "recall": 0.27381,
            "fmeasure": 0.28547
        },
        "nist": 2.147758929321685,
        "bleu": 10.86272,
        "meteor": 0.19491605205594748,
        "bleurt": -0.4876,
        "nubia": {
            "semantic_relation": 3.3187,
            "contradiction": 0.08786,
            "irrelevancy": 99.74838,
            "logical_agreement": 0.16377,
            "grammar_ref": 4.46991,
            "grammar_hyp": 5.23427,
            "nubia_score": 0.3865
        },
        "bertscore": {
            "precision": 0.80775,
            "recall": 0.79787,
            "f1": 0.80278
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.3,
            "recall": 0.27381,
            "fmeasure": 0.28289
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.10096,
            "fmeasure": 0.10428
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.27381,
            "fmeasure": 0.28289
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.27381,
            "fmeasure": 0.28289
        },
        "nist": 1.3230577388163942,
        "bleu": 7.35256,
        "meteor": 0.24153862155091177,
        "bleurt": 0.00032,
        "nubia": {
            "semantic_relation": 2.60483,
            "contradiction": 45.00101,
            "irrelevancy": 54.22922,
            "logical_agreement": 0.76976,
            "grammar_ref": 5.58883,
            "grammar_hyp": 4.41835,
            "nubia_score": 0.24748
        },
        "bertscore": {
            "precision": 0.79938,
            "recall": 0.86334,
            "f1": 0.83013
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.22727,
            "fmeasure": 0.26862
        },
        "rouge2": {
            "precision": 0.18519,
            "recall": 0.12222,
            "fmeasure": 0.1462
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.22727,
            "fmeasure": 0.26862
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.22727,
            "fmeasure": 0.26862
        },
        "nist": 1.1877215944546626,
        "bleu": 9.3182,
        "meteor": 0.16014872254596807,
        "bleurt": -0.76655,
        "nubia": {
            "semantic_relation": 1.64137,
            "contradiction": 3.14106,
            "irrelevancy": 93.52307,
            "logical_agreement": 3.33588,
            "grammar_ref": 4.84054,
            "grammar_hyp": 5.99947,
            "nubia_score": 0.0785
        },
        "bertscore": {
            "precision": 0.78298,
            "recall": 0.76978,
            "f1": 0.77632
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.5,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.9310344827586207,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.720049960644813,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": -0.029019418890029347,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9629629629629629,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.6808134280893965,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.03103131238874396,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.83902,
            "recall": 0.88636,
            "fmeasure": 0.85831
        },
        "rouge2": {
            "precision": 0.68333,
            "recall": 0.70556,
            "fmeasure": 0.69222
        },
        "rougeL": {
            "precision": 0.77652,
            "recall": 0.81439,
            "fmeasure": 0.79195
        },
        "rougeLsum": {
            "precision": 0.77652,
            "recall": 0.81439,
            "fmeasure": 0.79195
        },
        "nist": 5.18549783958533,
        "bleu": 66.68955,
        "meteor": 0.5003329489649406,
        "bleurt": 0.40798,
        "nubia": {
            "semantic_relation": 4.88511,
            "contradiction": 0.79916,
            "irrelevancy": 50.32504,
            "logical_agreement": 48.87581,
            "grammar_ref": 5.62679,
            "grammar_hyp": 5.25816,
            "nubia_score": 0.94672
        },
        "bertscore": {
            "precision": 0.93511,
            "recall": 0.95852,
            "f1": 0.94132
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 2.5,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.7096774193548387,
        "vocab_size-1": 22,
        "unique-1": 16,
        "entropy-1": 4.284683810317086,
        "distinct-2": 0.896551724137931,
        "vocab_size-2": 26,
        "unique-2": 24,
        "entropy-2": 4.625053839880556,
        "cond_entropy-2": 0.3175777881889729,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 26,
        "unique-3": 25,
        "entropy-3": 4.680813428089397,
        "cond_entropy-3": 0.07301345156046948,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7241379310344828,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.21126073643228,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.504706483564824,
        "cond_entropy-2-nopunct": 0.3413509514803412,
        "distinct-3-nopunct": 0.96,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.5638561897747225,
        "cond_entropy-3-nopunct": 0.07916418769779478,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.43333333333333335
        },
        "rouge1": {
            "precision": 0.5125,
            "recall": 0.41601,
            "fmeasure": 0.4489
        },
        "rouge2": {
            "precision": 0.24444,
            "recall": 0.21667,
            "fmeasure": 0.22593
        },
        "rougeL": {
            "precision": 0.4625,
            "recall": 0.39013,
            "fmeasure": 0.4148
        },
        "rougeLsum": {
            "precision": 0.4625,
            "recall": 0.39013,
            "fmeasure": 0.4148
        },
        "nist": 1.9044853815118907,
        "bleu": 19.47251,
        "meteor": 0.20127555488232743,
        "bleurt": -0.25139,
        "nubia": {
            "semantic_relation": 2.82557,
            "contradiction": 2.13836,
            "irrelevancy": 40.31304,
            "logical_agreement": 57.5486,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.17134,
            "nubia_score": 0.36265
        },
        "bertscore": {
            "precision": 0.86884,
            "recall": 0.83259,
            "f1": 0.85027
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 43,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.813953488372093,
        "vocab_size-1": 35,
        "unique-1": 28,
        "entropy-1": 5.036616208140156,
        "distinct-2": 0.925,
        "vocab_size-2": 37,
        "unique-2": 34,
        "entropy-2": 5.171928094887363,
        "cond_entropy-2": 0.11453552773935088,
        "distinct-3": 0.972972972972973,
        "vocab_size-3": 36,
        "unique-3": 35,
        "entropy-3": 5.1553993115749,
        "cond_entropy-3": -0.004366621150304489,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8292682926829268,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.997676699687266,
        "distinct-2-nopunct": 0.9210526315789473,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.090032776601483,
        "cond_entropy-2-nopunct": 0.1207672851982249,
        "distinct-3-nopunct": 0.9714285714285714,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.072140159802107,
        "cond_entropy-3-nopunct": -0.004358782212904651,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.88148,
            "recall": 0.95278,
            "fmeasure": 0.91106
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.96392,
            "fmeasure": 0.88619
        },
        "rougeL": {
            "precision": 0.87407,
            "recall": 0.9542,
            "fmeasure": 0.90618
        },
        "rougeLsum": {
            "precision": 0.87407,
            "recall": 0.9542,
            "fmeasure": 0.90618
        },
        "nist": 5.160508860814183,
        "bleu": 82.77389,
        "meteor": 0.5753558987916604,
        "bleurt": 0.61365,
        "nubia": {
            "semantic_relation": 4.5475,
            "contradiction": 0.48444,
            "irrelevancy": 43.34913,
            "logical_agreement": 56.16642,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.86177,
            "nubia_score": 0.84854
        },
        "bertscore": {
            "precision": 0.97597,
            "recall": 0.98298,
            "f1": 0.97941
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "t5-small/totto_test",
        "N": 13,
        "total_length": 204,
        "mean_pred_length": 15.692307692307692,
        "std_pred_length": 3.5816759159454823,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.6176470588235294,
        "vocab_size-1": 126,
        "unique-1": 90,
        "entropy-1": 6.567259468337831,
        "distinct-2": 0.8638743455497382,
        "vocab_size-2": 165,
        "unique-2": 142,
        "entropy-2": 7.2907540243595,
        "cond_entropy-2": 0.5994809882322847,
        "distinct-3": 0.9157303370786517,
        "vocab_size-3": 163,
        "unique-3": 148,
        "entropy-3": 7.30719410512368,
        "cond_entropy-3": 0.014905094515837228,
        "total_length-nopunct": 186,
        "mean_pred_length-nopunct": 14.307692307692308,
        "std_pred_length-nopunct": 3.6243750736583835,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6559139784946236,
        "vocab_size-1-nopunct": 122,
        "unique-1-nopunct": 90,
        "entropy-1-nopunct": 6.578700730924739,
        "distinct-2-nopunct": 0.861271676300578,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 128,
        "entropy-2-nopunct": 7.141247375023065,
        "cond_entropy-2-nopunct": 0.6000377137074828,
        "distinct-3-nopunct": 0.9125,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.146928094887366,
        "cond_entropy-3-nopunct": 0.004517914139159279,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.68,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14705882352941177,
            "2": 0.5294117647058824,
            "3": 0.7073170731707317
        },
        "rouge1": {
            "precision": 0.68196,
            "recall": 0.68836,
            "fmeasure": 0.67288
        },
        "rouge2": {
            "precision": 0.46474,
            "recall": 0.46469,
            "fmeasure": 0.45579
        },
        "rougeL": {
            "precision": 0.57594,
            "recall": 0.57454,
            "fmeasure": 0.56458
        },
        "rougeLsum": {
            "precision": 0.57594,
            "recall": 0.57454,
            "fmeasure": 0.56458
        },
        "nist": 4.902845236270431,
        "bleu": 34.86323,
        "meteor": 0.36916225309987905,
        "bleurt": -0.03283,
        "nubia": {
            "semantic_relation": 4.08167,
            "contradiction": 0.46722,
            "irrelevancy": 47.91576,
            "logical_agreement": 51.61701,
            "grammar_ref": 4.86507,
            "grammar_hyp": 4.45633,
            "nubia_score": 0.73789
        },
        "bertscore": {
            "precision": 0.8883,
            "recall": 0.89358,
            "f1": 0.88983
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.82051,
            "recall": 0.82051,
            "fmeasure": 0.82051
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.67778,
            "fmeasure": 0.65657
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 0.77622,
            "fmeasure": 0.73077
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 0.77622,
            "fmeasure": 0.73077
        },
        "nist": 4.709235782687254,
        "bleu": 73.76993,
        "meteor": 0.5205559484776897,
        "bleurt": 0.42437,
        "nubia": {
            "semantic_relation": 4.80287,
            "contradiction": 0.54415,
            "irrelevancy": 18.10238,
            "logical_agreement": 81.35347,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.36386,
            "nubia_score": 0.91113
        },
        "bertscore": {
            "precision": 0.93851,
            "recall": 0.9602,
            "f1": 0.93501
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.08866415466539351,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.08866415466539351,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.4782608695652174
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.3619,
            "fmeasure": 0.46914
        },
        "rouge2": {
            "precision": 0.24074,
            "recall": 0.12745,
            "fmeasure": 0.16667
        },
        "rougeL": {
            "precision": 0.50877,
            "recall": 0.27619,
            "fmeasure": 0.35802
        },
        "rougeLsum": {
            "precision": 0.50877,
            "recall": 0.27619,
            "fmeasure": 0.35802
        },
        "nist": 0.37218086819267054,
        "bleu": 5.64054,
        "meteor": 0.2109487963712339,
        "bleurt": -0.3174,
        "nubia": {
            "semantic_relation": 3.10883,
            "contradiction": 1.04689,
            "irrelevancy": 42.17524,
            "logical_agreement": 56.77787,
            "grammar_ref": 5.19058,
            "grammar_hyp": 6.29936,
            "nubia_score": 0.22306
        },
        "bertscore": {
            "precision": 0.89883,
            "recall": 0.85011,
            "f1": 0.87379
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "t5-small/totto_test",
        "N": 10,
        "total_length": 155,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.05585995813465,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6516129032258065,
        "vocab_size-1": 101,
        "unique-1": 86,
        "entropy-1": 6.162198783452062,
        "distinct-2": 0.903448275862069,
        "vocab_size-2": 131,
        "unique-2": 121,
        "entropy-2": 6.962600296881665,
        "cond_entropy-2": 0.6804700045002227,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 130,
        "unique-3": 125,
        "entropy-3": 7.00274152297678,
        "cond_entropy-3": 0.041423358919799605,
        "total_length-nopunct": 140,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.794733192202055,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6928571428571428,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.156931971448843,
        "distinct-2-nopunct": 0.9076923076923077,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.810754159149018,
        "cond_entropy-2-nopunct": 0.6732363270088334,
        "distinct-3-nopunct": 0.9666666666666667,
        "vocab_size-3-nopunct": 116,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.840223928941868,
        "cond_entropy-3-nopunct": 0.03389622011011222,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.3611111111111111,
            "3": 0.6837606837606838
        },
        "rouge1": {
            "precision": 0.80237,
            "recall": 0.65822,
            "fmeasure": 0.71461
        },
        "rouge2": {
            "precision": 0.56162,
            "recall": 0.46856,
            "fmeasure": 0.50415
        },
        "rougeL": {
            "precision": 0.6586,
            "recall": 0.54291,
            "fmeasure": 0.58768
        },
        "rougeLsum": {
            "precision": 0.6586,
            "recall": 0.54291,
            "fmeasure": 0.58768
        },
        "nist": 4.2900669864383865,
        "bleu": 38.961,
        "meteor": 0.36052064170930004,
        "bleurt": 0.21985,
        "nubia": {
            "semantic_relation": 3.99726,
            "contradiction": 22.97491,
            "irrelevancy": 14.4185,
            "logical_agreement": 62.60658,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.48402,
            "nubia_score": 0.64225
        },
        "bertscore": {
            "precision": 0.92822,
            "recall": 0.89871,
            "f1": 0.91183
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.85185,
            "fmeasure": 0.90196
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.79545,
            "fmeasure": 0.88148
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 0.85185,
            "fmeasure": 0.90196
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 0.85185,
            "fmeasure": 0.90196
        },
        "nist": 3.658773891573415,
        "bleu": 91.31007,
        "meteor": 0.5658392913723261,
        "bleurt": 0.56509,
        "nubia": {
            "semantic_relation": 4.64338,
            "contradiction": 0.95603,
            "irrelevancy": 1.37265,
            "logical_agreement": 97.67132,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.71759,
            "nubia_score": 0.86758
        },
        "bertscore": {
            "precision": 0.97619,
            "recall": 0.95737,
            "f1": 0.96451
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.78125,
        "vocab_size-1": 25,
        "unique-1": 18,
        "entropy-1": 4.5625,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.2402239289418519,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.028107102122342964,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8214285714285714,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.450212064914747,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.16231556531425703,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.07381055075326919,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.4782608695652174
        },
        "rouge1": {
            "precision": 0.61795,
            "recall": 0.57532,
            "fmeasure": 0.59195
        },
        "rouge2": {
            "precision": 0.22619,
            "recall": 0.22906,
            "fmeasure": 0.22602
        },
        "rougeL": {
            "precision": 0.50256,
            "recall": 0.48157,
            "fmeasure": 0.48851
        },
        "rougeLsum": {
            "precision": 0.50256,
            "recall": 0.48157,
            "fmeasure": 0.48851
        },
        "nist": 3.0624099957182214,
        "bleu": 17.14319,
        "meteor": 0.3346473861862726,
        "bleurt": 0.03058,
        "nubia": {
            "semantic_relation": 4.05983,
            "contradiction": 0.21043,
            "irrelevancy": 70.16512,
            "logical_agreement": 29.62444,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.63801,
            "nubia_score": 0.67246
        },
        "bertscore": {
            "precision": 0.92462,
            "recall": 0.90274,
            "f1": 0.91231
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 64,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.9370039370059056,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.5,
        "vocab_size-1": 32,
        "unique-1": 16,
        "entropy-1": 4.695159765557392,
        "distinct-2": 0.7,
        "vocab_size-2": 42,
        "unique-2": 25,
        "entropy-2": 5.294309137239127,
        "cond_entropy-2": 0.5528053873112428,
        "distinct-3": 0.7142857142857143,
        "vocab_size-3": 40,
        "unique-3": 24,
        "entropy-3": 5.235926350629035,
        "cond_entropy-3": -0.050341253869423834,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.692582403567252,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.5185185185185185,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.467669446527787,
        "distinct-2-nopunct": 0.72,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 5.068758439731453,
        "cond_entropy-2-nopunct": 0.6640664376545256,
        "distinct-3-nopunct": 0.7391304347826086,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 5.001822825622228,
        "cond_entropy-3-nopunct": -0.06040537497502766,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7647058823529411
        },
        "rouge1": {
            "precision": 0.87535,
            "recall": 0.78557,
            "fmeasure": 0.82026
        },
        "rouge2": {
            "precision": 0.77186,
            "recall": 0.70833,
            "fmeasure": 0.73122
        },
        "rougeL": {
            "precision": 0.87535,
            "recall": 0.78557,
            "fmeasure": 0.82026
        },
        "rougeLsum": {
            "precision": 0.87535,
            "recall": 0.78557,
            "fmeasure": 0.82026
        },
        "nist": 4.426209469621478,
        "bleu": 58.75409,
        "meteor": 0.42400104137042277,
        "bleurt": 0.1743,
        "nubia": {
            "semantic_relation": 3.795,
            "contradiction": 50.28162,
            "irrelevancy": 19.04707,
            "logical_agreement": 30.67131,
            "grammar_ref": 3.98368,
            "grammar_hyp": 3.96662,
            "nubia_score": 0.6333
        },
        "bertscore": {
            "precision": 0.93623,
            "recall": 0.92737,
            "f1": 0.93162
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 2.5,
        "median_pred_length": 16.5,
        "min_pred_length": 14,
        "max_pred_length": 19,
        "distinct-1": 0.8484848484848485,
        "vocab_size-1": 28,
        "unique-1": 24,
        "entropy-1": 4.718488437474714,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 30,
        "unique-2": 29,
        "entropy-2": 4.889680181354619,
        "cond_entropy-2": 0.1922179169046629,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.651084443403434,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.04505465518404483,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.031031312388743952,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.6785714285714286
        },
        "rouge1": {
            "precision": 0.7451,
            "recall": 0.51456,
            "fmeasure": 0.60824
        },
        "rouge2": {
            "precision": 0.43182,
            "recall": 0.29224,
            "fmeasure": 0.34823
        },
        "rougeL": {
            "precision": 0.51716,
            "recall": 0.39555,
            "fmeasure": 0.4403
        },
        "rougeLsum": {
            "precision": 0.51716,
            "recall": 0.39555,
            "fmeasure": 0.4403
        },
        "nist": 2.1186547542431606,
        "bleu": 18.48649,
        "meteor": 0.3058539055114553,
        "bleurt": -0.09646,
        "nubia": {
            "semantic_relation": 3.46971,
            "contradiction": 5.11211,
            "irrelevancy": 20.14164,
            "logical_agreement": 74.74626,
            "grammar_ref": 4.42501,
            "grammar_hyp": 4.43574,
            "nubia_score": 0.46977
        },
        "bertscore": {
            "precision": 0.89244,
            "recall": 0.85881,
            "f1": 0.87436
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.546060565661952,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.7843137254901961,
        "vocab_size-1": 40,
        "unique-1": 32,
        "entropy-1": 5.187035390948686,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.3292038254163273,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.09310940439148176,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8372093023255814,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.054171731446284,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.2706633401852644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.7857142857142857
        },
        "rouge1": {
            "precision": 0.8037,
            "recall": 0.6784,
            "fmeasure": 0.71897
        },
        "rouge2": {
            "precision": 0.57843,
            "recall": 0.47457,
            "fmeasure": 0.50604
        },
        "rougeL": {
            "precision": 0.74198,
            "recall": 0.62645,
            "fmeasure": 0.66256
        },
        "rougeLsum": {
            "precision": 0.74198,
            "recall": 0.62645,
            "fmeasure": 0.66256
        },
        "nist": 4.2010954532201925,
        "bleu": 43.41311,
        "meteor": 0.3707867067950399,
        "bleurt": 0.3135,
        "nubia": {
            "semantic_relation": 3.97255,
            "contradiction": 40.27565,
            "irrelevancy": 5.33987,
            "logical_agreement": 54.38448,
            "grammar_ref": 4.44265,
            "grammar_hyp": 4.31607,
            "nubia_score": 0.6486
        },
        "bertscore": {
            "precision": 0.93852,
            "recall": 0.9069,
            "f1": 0.91836
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.76364,
            "fmeasure": 0.82105
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.58333,
            "fmeasure": 0.63072
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.76364,
            "fmeasure": 0.82105
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.76364,
            "fmeasure": 0.82105
        },
        "nist": 3.5627826266596307,
        "bleu": 78.25423,
        "meteor": 0.4800707485133138,
        "bleurt": 0.65302,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.35483,
            "irrelevancy": 0.68052,
            "logical_agreement": 97.96465,
            "grammar_ref": 5.30755,
            "grammar_hyp": 6.47712,
            "nubia_score": 0.74409
        },
        "bertscore": {
            "precision": 0.9686,
            "recall": 0.96219,
            "f1": 0.96539
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 43,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 4.714045207910316,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.7209302325581395,
        "vocab_size-1": 31,
        "unique-1": 24,
        "entropy-1": 4.768947021993018,
        "distinct-2": 0.975,
        "vocab_size-2": 39,
        "unique-2": 38,
        "entropy-2": 5.271928094887364,
        "cond_entropy-2": 0.4334077152934375,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.058420675204358556,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.96655480858378,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7435897435897436,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.682587475161557,
        "distinct-2-nopunct": 0.9722222222222222,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.114369445886754,
        "cond_entropy-2-nopunct": 0.4542387549224789,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.06492482147779848,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.5,
            "3": 0.6551724137931034
        },
        "rouge1": {
            "precision": 0.63519,
            "recall": 0.70361,
            "fmeasure": 0.65653
        },
        "rouge2": {
            "precision": 0.30551,
            "recall": 0.36006,
            "fmeasure": 0.32395
        },
        "rougeL": {
            "precision": 0.47963,
            "recall": 0.54493,
            "fmeasure": 0.50123
        },
        "rougeLsum": {
            "precision": 0.47963,
            "recall": 0.54493,
            "fmeasure": 0.50123
        },
        "nist": 3.3852739007868498,
        "bleu": 25.20727,
        "meteor": 0.31727474824584995,
        "bleurt": -0.13627,
        "nubia": {
            "semantic_relation": 3.20603,
            "contradiction": 39.98845,
            "irrelevancy": 29.10929,
            "logical_agreement": 30.90226,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.58179,
            "nubia_score": 0.48877
        },
        "bertscore": {
            "precision": 0.86319,
            "recall": 0.89058,
            "f1": 0.87315
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.8378378378378378,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.844324311457953,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.13550616686149178,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.13326653086346418,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8787878787878788,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.779094498080774,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.12099272632218087,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0625,
            "2": 0.9230769230769231,
            "3": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.7453,
            "recall": 0.85415,
            "fmeasure": 0.78056
        },
        "rouge2": {
            "precision": 0.65873,
            "recall": 0.71656,
            "fmeasure": 0.6748
        },
        "rougeL": {
            "precision": 0.7453,
            "recall": 0.85415,
            "fmeasure": 0.78056
        },
        "rougeLsum": {
            "precision": 0.7453,
            "recall": 0.85415,
            "fmeasure": 0.78056
        },
        "nist": 4.086393151083967,
        "bleu": 51.16339,
        "meteor": 0.47276715099799577,
        "bleurt": 0.48978,
        "nubia": {
            "semantic_relation": 4.55081,
            "contradiction": 0.39688,
            "irrelevancy": 33.58446,
            "logical_agreement": 66.01867,
            "grammar_ref": 5.27099,
            "grammar_hyp": 4.94256,
            "nubia_score": 0.90729
        },
        "bertscore": {
            "precision": 0.92311,
            "recall": 0.95983,
            "f1": 0.93678
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 129,
        "mean_pred_length": 16.125,
        "std_pred_length": 5.2544623892459255,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 28,
        "distinct-1": 0.5426356589147286,
        "vocab_size-1": 70,
        "unique-1": 48,
        "entropy-1": 5.701095573810569,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 99,
        "unique-2": 79,
        "entropy-2": 6.542749394263634,
        "cond_entropy-2": 0.7656319481153055,
        "distinct-3": 0.8672566371681416,
        "vocab_size-3": 98,
        "unique-3": 84,
        "entropy-3": 6.5480118163783585,
        "cond_entropy-3": -0.0035082792650396703,
        "total_length-nopunct": 111,
        "mean_pred_length-nopunct": 13.875,
        "std_pred_length-nopunct": 5.4872010169119925,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6036036036036037,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.728848920630876,
        "distinct-2-nopunct": 0.8252427184466019,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.3223279543256865,
        "cond_entropy-2-nopunct": 0.5872131168434617,
        "distinct-3-nopunct": 0.8736842105263158,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.309277845150279,
        "cond_entropy-3-nopunct": -0.01396189251370776,
        "msttr-100": 0.58,
        "msttr-100_nopunct": 0.64,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2926829268292683,
            "2": 0.6190476190476191,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.67026,
            "recall": 0.76734,
            "fmeasure": 0.70744
        },
        "rouge2": {
            "precision": 0.46109,
            "recall": 0.54601,
            "fmeasure": 0.48669
        },
        "rougeL": {
            "precision": 0.60625,
            "recall": 0.67281,
            "fmeasure": 0.62896
        },
        "rougeLsum": {
            "precision": 0.60625,
            "recall": 0.67281,
            "fmeasure": 0.62896
        },
        "nist": 4.670389806505761,
        "bleu": 43.92442,
        "meteor": 0.4279119145264363,
        "bleurt": 0.07126,
        "nubia": {
            "semantic_relation": 3.85305,
            "contradiction": 27.77062,
            "irrelevancy": 35.29113,
            "logical_agreement": 36.93825,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.86106,
            "nubia_score": 0.5954
        },
        "bertscore": {
            "precision": 0.91056,
            "recall": 0.93627,
            "f1": 0.91846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 1.5,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 12,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.070656113151928,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.10586732762079713,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.1604646721932461,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 3.9976702764876113,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.11923459263989905,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 1.0,
            "3": 0.36
        },
        "rouge1": {
            "precision": 0.75568,
            "recall": 0.62356,
            "fmeasure": 0.63953
        },
        "rouge2": {
            "precision": 0.62857,
            "recall": 0.57319,
            "fmeasure": 0.56171
        },
        "rougeL": {
            "precision": 0.71023,
            "recall": 0.60591,
            "fmeasure": 0.6141
        },
        "rougeLsum": {
            "precision": 0.71023,
            "recall": 0.60591,
            "fmeasure": 0.6141
        },
        "nist": 1.0147375076674938,
        "bleu": 23.21104,
        "meteor": 0.24572057824253843,
        "bleurt": -0.21699,
        "nubia": {
            "semantic_relation": 3.66201,
            "contradiction": 48.45402,
            "irrelevancy": 34.46596,
            "logical_agreement": 17.08001,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.71918,
            "nubia_score": 0.56152
        },
        "bertscore": {
            "precision": 0.91069,
            "recall": 0.8648,
            "f1": 0.88639
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.0990195135927845,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 39,
        "unique-1": 32,
        "entropy-1": 5.101456411015347,
        "distinct-2": 0.9375,
        "vocab_size-2": 45,
        "unique-2": 42,
        "entropy-2": 5.4599625007211605,
        "cond_entropy-2": 0.3525249812239055,
        "distinct-3": 0.9777777777777777,
        "vocab_size-3": 44,
        "unique-3": 43,
        "entropy-3": 5.447408651885229,
        "cond_entropy-3": -0.004220515502592866,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7954545454545454,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.951146891896381,
        "distinct-2-nopunct": 0.9512195121951219,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.259991029008325,
        "cond_entropy-2-nopunct": 0.34603570248323245,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.004361333279761099,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0.4782608695652174,
            "3": 0.5294117647058824
        },
        "rouge1": {
            "precision": 0.49733,
            "recall": 0.57645,
            "fmeasure": 0.52573
        },
        "rouge2": {
            "precision": 0.21338,
            "recall": 0.25288,
            "fmeasure": 0.22681
        },
        "rougeL": {
            "precision": 0.46127,
            "recall": 0.50826,
            "fmeasure": 0.47666
        },
        "rougeLsum": {
            "precision": 0.46127,
            "recall": 0.50826,
            "fmeasure": 0.47666
        },
        "nist": 3.1349769032113723,
        "bleu": 18.38713,
        "meteor": 0.26757069163684777,
        "bleurt": 0.00587,
        "nubia": {
            "semantic_relation": 4.0035,
            "contradiction": 0.25787,
            "irrelevancy": 50.32043,
            "logical_agreement": 49.4217,
            "grammar_ref": 4.61531,
            "grammar_hyp": 4.52504,
            "nubia_score": 0.69758
        },
        "bertscore": {
            "precision": 0.86503,
            "recall": 0.89271,
            "f1": 0.87738
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 73,
        "mean_pred_length": 18.25,
        "std_pred_length": 2.5860201081971503,
        "median_pred_length": 18.0,
        "min_pred_length": 15,
        "max_pred_length": 22,
        "distinct-1": 0.8082191780821918,
        "vocab_size-1": 59,
        "unique-1": 52,
        "entropy-1": 5.713730209535319,
        "distinct-2": 0.9855072463768116,
        "vocab_size-2": 68,
        "unique-2": 67,
        "entropy-2": 6.079538949531787,
        "cond_entropy-2": 0.349930151552695,
        "distinct-3": 1.0,
        "vocab_size-3": 65,
        "unique-3": 65,
        "entropy-3": 6.022367813028458,
        "cond_entropy-3": -0.055387412980483844,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 16.75,
        "std_pred_length-nopunct": 2.680951323690902,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8507462686567164,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.696613257589656,
        "distinct-2-nopunct": 0.9841269841269841,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.945533891753889,
        "cond_entropy-2-nopunct": 0.2565064076796598,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 59,
        "entropy-3-nopunct": 5.882643049361836,
        "cond_entropy-3-nopunct": -0.06073856905332944,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6428571428571429,
            "2": 0.6,
            "3": 0.6716417910447762
        },
        "rouge1": {
            "precision": 0.88564,
            "recall": 0.70965,
            "fmeasure": 0.77134
        },
        "rouge2": {
            "precision": 0.58988,
            "recall": 0.47119,
            "fmeasure": 0.5117
        },
        "rougeL": {
            "precision": 0.76261,
            "recall": 0.61637,
            "fmeasure": 0.66755
        },
        "rougeLsum": {
            "precision": 0.76261,
            "recall": 0.61637,
            "fmeasure": 0.66755
        },
        "nist": 4.372529467114177,
        "bleu": 41.05128,
        "meteor": 0.3734343723039131,
        "bleurt": 0.02682,
        "nubia": {
            "semantic_relation": 4.08703,
            "contradiction": 2.22446,
            "irrelevancy": 26.33277,
            "logical_agreement": 71.44277,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.59867,
            "nubia_score": 0.63115
        },
        "bertscore": {
            "precision": 0.94773,
            "recall": 0.9066,
            "f1": 0.92638
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 69,
        "mean_pred_length": 13.8,
        "std_pred_length": 3.370459909270543,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.7971014492753623,
        "vocab_size-1": 55,
        "unique-1": 44,
        "entropy-1": 5.669906159582653,
        "distinct-2": 0.90625,
        "vocab_size-2": 58,
        "unique-2": 52,
        "entropy-2": 5.8125,
        "cond_entropy-2": 0.10256577766443926,
        "distinct-3": 0.9152542372881356,
        "vocab_size-3": 54,
        "unique-3": 49,
        "entropy-3": 5.713151523938108,
        "cond_entropy-3": -0.08345864555341295,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 12.6,
        "std_pred_length-nopunct": 3.2,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8253968253968254,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.604108891685206,
        "distinct-2-nopunct": 0.896551724137931,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.651084443403431,
        "cond_entropy-2-nopunct": 0.061904088943637164,
        "distinct-3-nopunct": 0.9056603773584906,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.539241209280179,
        "cond_entropy-3-nopunct": -0.11119261603607111,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.64287,
            "recall": 0.71742,
            "fmeasure": 0.67159
        },
        "rouge2": {
            "precision": 0.42976,
            "recall": 0.50386,
            "fmeasure": 0.45888
        },
        "rougeL": {
            "precision": 0.55842,
            "recall": 0.64003,
            "fmeasure": 0.59138
        },
        "rougeLsum": {
            "precision": 0.55842,
            "recall": 0.64003,
            "fmeasure": 0.59138
        },
        "nist": 4.046340476260589,
        "bleu": 39.63692,
        "meteor": 0.42020902580851327,
        "bleurt": 0.25841,
        "nubia": {
            "semantic_relation": 4.18083,
            "contradiction": 18.48886,
            "irrelevancy": 34.75655,
            "logical_agreement": 46.75459,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.5071,
            "nubia_score": 0.68388
        },
        "bertscore": {
            "precision": 0.90239,
            "recall": 0.93634,
            "f1": 0.91635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.932138039759373,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.2553308213320601,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.8365916681089787,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.2704790162786153,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.87037,
            "recall": 0.77005,
            "fmeasure": 0.81429
        },
        "rouge2": {
            "precision": 0.52941,
            "recall": 0.46329,
            "fmeasure": 0.49229
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.63508,
            "fmeasure": 0.62275
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.63508,
            "fmeasure": 0.62275
        },
        "nist": 4.073200329834667,
        "bleu": 35.27296,
        "meteor": 0.3963717380598027,
        "bleurt": 0.50217,
        "nubia": {
            "semantic_relation": 4.97591,
            "contradiction": 0.11688,
            "irrelevancy": 0.71153,
            "logical_agreement": 99.17158,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.12278,
            "nubia_score": 0.9916
        },
        "bertscore": {
            "precision": 0.95621,
            "recall": 0.92773,
            "f1": 0.93315
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.34119,
            "fmeasure": 0.46358
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.2674,
            "fmeasure": 0.36918
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.29854,
            "fmeasure": 0.40564
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.29854,
            "fmeasure": 0.40564
        },
        "nist": 0.19432195860366142,
        "bleu": 17.92681,
        "meteor": 0.2526845694782849,
        "bleurt": -0.29666,
        "nubia": {
            "semantic_relation": 3.33397,
            "contradiction": 5.86135,
            "irrelevancy": 1.66517,
            "logical_agreement": 92.47349,
            "grammar_ref": 5.07625,
            "grammar_hyp": 5.6356,
            "nubia_score": 0.31744
        },
        "bertscore": {
            "precision": 0.87739,
            "recall": 0.81951,
            "f1": 0.84746
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.93333,
            "fmeasure": 0.94737
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "nist": 4.2252432046274455,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.70774,
        "nubia": {
            "semantic_relation": 4.85528,
            "contradiction": 0.45187,
            "irrelevancy": 0.4652,
            "logical_agreement": 99.08293,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.01239,
            "nubia_score": 0.98066
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 65,
        "mean_pred_length": 16.25,
        "std_pred_length": 2.48746859276655,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 20,
        "distinct-1": 0.7230769230769231,
        "vocab_size-1": 47,
        "unique-1": 33,
        "entropy-1": 5.414525120654195,
        "distinct-2": 0.8688524590163934,
        "vocab_size-2": 53,
        "unique-2": 45,
        "entropy-2": 5.668442255595667,
        "cond_entropy-2": 0.162628131162742,
        "distinct-3": 0.9122807017543859,
        "vocab_size-3": 52,
        "unique-3": 47,
        "entropy-3": 5.65745141767351,
        "cond_entropy-3": -0.027671884801653092,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7678571428571429,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.316108939837482,
        "distinct-2-nopunct": 0.8846153846153846,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.4696704873718645,
        "cond_entropy-2-nopunct": 0.15288816155131352,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.4182958340544936,
        "cond_entropy-3-nopunct": -0.03214388408660258,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.5,
            "3": 0.85
        },
        "rouge1": {
            "precision": 0.7249,
            "recall": 0.74089,
            "fmeasure": 0.72729
        },
        "rouge2": {
            "precision": 0.5253,
            "recall": 0.53107,
            "fmeasure": 0.52427
        },
        "rougeL": {
            "precision": 0.70011,
            "recall": 0.7121,
            "fmeasure": 0.70105
        },
        "rougeLsum": {
            "precision": 0.70011,
            "recall": 0.7121,
            "fmeasure": 0.70105
        },
        "nist": 5.030595078992644,
        "bleu": 59.28618,
        "meteor": 0.47594072910679597,
        "bleurt": 0.09379,
        "nubia": {
            "semantic_relation": 3.86935,
            "contradiction": 27.43706,
            "irrelevancy": 28.83434,
            "logical_agreement": 43.72859,
            "grammar_ref": 4.83501,
            "grammar_hyp": 4.06991,
            "nubia_score": 0.65054
        },
        "bertscore": {
            "precision": 0.93676,
            "recall": 0.96533,
            "f1": 0.95074
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.3764992953429935,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.91462,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 3.491060010942235,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.7169811320754716,
        "vocab_size-1": 38,
        "unique-1": 28,
        "entropy-1": 5.072167860182755,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 42,
        "unique-2": 36,
        "entropy-2": 5.313589691009831,
        "cond_entropy-2": 0.13168734873568272,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 42,
        "unique-3": 39,
        "entropy-3": 5.358519762996339,
        "cond_entropy-3": 0.07169630781809898,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 2.692582403567252,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.941933966879544,
        "distinct-2-nopunct": 0.8095238095238095,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.993391529870108,
        "cond_entropy-2-nopunct": 0.10685070481698565,
        "distinct-3-nopunct": 0.868421052631579,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.9847696187067445,
        "cond_entropy-3-nopunct": 0.03337028809017953,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8536585365853658
        },
        "rouge1": {
            "precision": 0.95906,
            "recall": 0.87795,
            "fmeasure": 0.9137
        },
        "rouge2": {
            "precision": 0.84838,
            "recall": 0.78381,
            "fmeasure": 0.81209
        },
        "rougeL": {
            "precision": 0.92398,
            "recall": 0.8399,
            "fmeasure": 0.87605
        },
        "rougeLsum": {
            "precision": 0.92398,
            "recall": 0.8399,
            "fmeasure": 0.87605
        },
        "nist": 5.213965024500052,
        "bleu": 65.58626,
        "meteor": 0.5057297014227885,
        "bleurt": 0.63808,
        "nubia": {
            "semantic_relation": 4.62251,
            "contradiction": 0.5129,
            "irrelevancy": 8.81337,
            "logical_agreement": 90.67374,
            "grammar_ref": 5.18336,
            "grammar_hyp": 5.10825,
            "nubia_score": 0.8637
        },
        "bertscore": {
            "precision": 0.96996,
            "recall": 0.96146,
            "f1": 0.9642
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "nist": 4.048415664983272,
        "bleu": 67.03421,
        "meteor": 0.5091857548700987,
        "bleurt": 0.58965,
        "nubia": {
            "semantic_relation": 4.20744,
            "contradiction": 61.82775,
            "irrelevancy": 32.46797,
            "logical_agreement": 5.70428,
            "grammar_ref": 5.3705,
            "grammar_hyp": 4.88808,
            "nubia_score": 0.61372
        },
        "bertscore": {
            "precision": 0.97259,
            "recall": 0.98308,
            "f1": 0.97766
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966057,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.10689059560851856,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.72727,
            "fmeasure": 0.59259
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.63636,
            "fmeasure": 0.51852
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.63636,
            "fmeasure": 0.51852
        },
        "nist": 2.062909597221545,
        "bleu": 28.43329,
        "meteor": 0.36092751560503006,
        "bleurt": 0.02715,
        "nubia": {
            "semantic_relation": 4.15495,
            "contradiction": 1.04293,
            "irrelevancy": 98.16391,
            "logical_agreement": 0.79316,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.38679,
            "nubia_score": 0.80594
        },
        "bertscore": {
            "precision": 0.85155,
            "recall": 0.89597,
            "f1": 0.87319
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 1.0,
            "3": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.80952,
            "recall": 0.26118,
            "fmeasure": 0.39491
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.16402,
            "fmeasure": 0.25309
        },
        "rougeL": {
            "precision": 0.7619,
            "recall": 0.24531,
            "fmeasure": 0.3711
        },
        "rougeLsum": {
            "precision": 0.7619,
            "recall": 0.24531,
            "fmeasure": 0.3711
        },
        "nist": 0.0626155820354918,
        "bleu": 9.42065,
        "meteor": 0.15301870223240222,
        "bleurt": -0.72571,
        "nubia": {
            "semantic_relation": 3.36564,
            "contradiction": 1.20746,
            "irrelevancy": 8.48876,
            "logical_agreement": 90.30378,
            "grammar_ref": 5.09304,
            "grammar_hyp": 6.45936,
            "nubia_score": 0.26909
        },
        "bertscore": {
            "precision": 0.91906,
            "recall": 0.79394,
            "f1": 0.84974
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96078,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.7381,
            "fmeasure": 0.77143
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "nist": 4.673642355475211,
        "bleu": 78.56293,
        "meteor": 0.5124329313818176,
        "bleurt": 0.6799,
        "nubia": {
            "semantic_relation": 4.7361,
            "contradiction": 0.20205,
            "irrelevancy": 0.47436,
            "logical_agreement": 99.32359,
            "grammar_ref": 4.24096,
            "grammar_hyp": 4.27871,
            "nubia_score": 0.91305
        },
        "bertscore": {
            "precision": 0.97641,
            "recall": 0.96546,
            "f1": 0.96962
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.84259,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.54762,
            "fmeasure": 0.60073
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "nist": 2.9487445430153727,
        "bleu": 51.31108,
        "meteor": 0.4561301812414779,
        "bleurt": 0.59368,
        "nubia": {
            "semantic_relation": 4.91614,
            "contradiction": 0.68707,
            "irrelevancy": 0.60509,
            "logical_agreement": 98.70784,
            "grammar_ref": 5.94246,
            "grammar_hyp": 6.87586,
            "nubia_score": 0.87589
        },
        "bertscore": {
            "precision": 0.98804,
            "recall": 0.97187,
            "f1": 0.97989
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185191,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228516,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8125
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.82353,
            "fmeasure": 0.875
        },
        "rouge2": {
            "precision": 0.92857,
            "recall": 0.8125,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.93333,
            "recall": 0.82353,
            "fmeasure": 0.875
        },
        "rougeLsum": {
            "precision": 0.93333,
            "recall": 0.82353,
            "fmeasure": 0.875
        },
        "nist": 3.8629128036351155,
        "bleu": 78.38508,
        "meteor": 0.5442666925832842,
        "bleurt": 0.42926,
        "nubia": {
            "semantic_relation": 4.08858,
            "contradiction": 8.71206,
            "irrelevancy": 3.20945,
            "logical_agreement": 88.07849,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.80718,
            "nubia_score": 0.57438
        },
        "bertscore": {
            "precision": 0.98473,
            "recall": 0.95992,
            "f1": 0.97217
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "t5-small/totto_test",
        "N": 10,
        "total_length": 154,
        "mean_pred_length": 15.4,
        "std_pred_length": 4.340506882842141,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.6558441558441559,
        "vocab_size-1": 101,
        "unique-1": 75,
        "entropy-1": 6.342237577009174,
        "distinct-2": 0.9097222222222222,
        "vocab_size-2": 131,
        "unique-2": 118,
        "entropy-2": 6.989369445886775,
        "cond_entropy-2": 0.54466999135577,
        "distinct-3": 0.9328358208955224,
        "vocab_size-3": 125,
        "unique-3": 116,
        "entropy-3": 6.931760832248824,
        "cond_entropy-3": -0.059059691581554705,
        "total_length-nopunct": 139,
        "mean_pred_length-nopunct": 13.9,
        "std_pred_length-nopunct": 4.39203825119955,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.697841726618705,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.350805101981311,
        "distinct-2-nopunct": 0.9069767441860465,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 6.82518074379533,
        "cond_entropy-2-nopunct": 0.5029133139646074,
        "distinct-3-nopunct": 0.9327731092436975,
        "vocab_size-3-nopunct": 111,
        "unique-3-nopunct": 103,
        "entropy-3-nopunct": 6.760363981795337,
        "cond_entropy-3-nopunct": -0.07439268539262162,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.34782608695652173,
            "2": 0.5185185185185185,
            "3": 0.8210526315789474
        },
        "rouge1": {
            "precision": 0.78711,
            "recall": 0.75623,
            "fmeasure": 0.76042
        },
        "rouge2": {
            "precision": 0.5469,
            "recall": 0.50451,
            "fmeasure": 0.51845
        },
        "rougeL": {
            "precision": 0.64524,
            "recall": 0.61404,
            "fmeasure": 0.61892
        },
        "rougeLsum": {
            "precision": 0.64524,
            "recall": 0.61404,
            "fmeasure": 0.61892
        },
        "nist": 5.900521691406398,
        "bleu": 50.50452,
        "meteor": 0.40129341456089745,
        "bleurt": 0.23134,
        "nubia": {
            "semantic_relation": 4.20553,
            "contradiction": 15.28648,
            "irrelevancy": 22.51306,
            "logical_agreement": 62.20046,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.234,
            "nubia_score": 0.71738
        },
        "bertscore": {
            "precision": 0.93028,
            "recall": 0.91739,
            "f1": 0.92361
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 86,
        "mean_pred_length": 17.2,
        "std_pred_length": 4.621688003316537,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.6162790697674418,
        "vocab_size-1": 53,
        "unique-1": 41,
        "entropy-1": 5.294866790212008,
        "distinct-2": 0.9012345679012346,
        "vocab_size-2": 73,
        "unique-2": 66,
        "entropy-2": 6.132999539894942,
        "cond_entropy-2": 0.7803196610356102,
        "distinct-3": 0.9605263157894737,
        "vocab_size-3": 73,
        "unique-3": 70,
        "entropy-3": 6.168980145022539,
        "cond_entropy-3": 0.04958918821900622,
        "total_length-nopunct": 71,
        "mean_pred_length-nopunct": 14.2,
        "std_pred_length-nopunct": 3.059411708155671,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.676056338028169,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.189454028414763,
        "distinct-2-nopunct": 0.8939393939393939,
        "vocab_size-2-nopunct": 59,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.820835217810529,
        "cond_entropy-2-nopunct": 0.6889791508419608,
        "distinct-3-nopunct": 0.9672131147540983,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.86516356707108,
        "cond_entropy-3-nopunct": 0.06265284938744031,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.0,
            "3": 0.5535714285714286
        },
        "rouge1": {
            "precision": 0.62059,
            "recall": 0.61639,
            "fmeasure": 0.58582
        },
        "rouge2": {
            "precision": 0.37048,
            "recall": 0.3755,
            "fmeasure": 0.35049
        },
        "rougeL": {
            "precision": 0.51547,
            "recall": 0.54962,
            "fmeasure": 0.50692
        },
        "rougeLsum": {
            "precision": 0.51547,
            "recall": 0.54962,
            "fmeasure": 0.50692
        },
        "nist": 4.166270161061627,
        "bleu": 31.01911,
        "meteor": 0.2949807419989397,
        "bleurt": -0.22311,
        "nubia": {
            "semantic_relation": 3.40708,
            "contradiction": 13.52423,
            "irrelevancy": 59.17611,
            "logical_agreement": 27.29966,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.24018,
            "nubia_score": 0.44972
        },
        "bertscore": {
            "precision": 0.89199,
            "recall": 0.88112,
            "f1": 0.8859
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.35294117647058826
        },
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.35354,
            "fmeasure": 0.48113
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.28139,
            "fmeasure": 0.38306
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.35837,
            "fmeasure": 0.4801
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.35837,
            "fmeasure": 0.4801
        },
        "nist": 0.19875592021862643,
        "bleu": 13.17961,
        "meteor": 0.19420974704408728,
        "bleurt": -0.57072,
        "nubia": {
            "semantic_relation": 3.32233,
            "contradiction": 0.22015,
            "irrelevancy": 17.41217,
            "logical_agreement": 82.36768,
            "grammar_ref": 3.0511,
            "grammar_hyp": 2.65061,
            "nubia_score": 0.63493
        },
        "bertscore": {
            "precision": 0.8878,
            "recall": 0.77098,
            "f1": 0.82338
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.8,
        "vocab_size-1": 36,
        "unique-1": 30,
        "entropy-1": 5.030633374059374,
        "distinct-2": 1.0,
        "vocab_size-2": 42,
        "unique-2": 42,
        "entropy-2": 5.3923174227787625,
        "cond_entropy-2": 0.28141670740146657,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.10691520391651191,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.825,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.921928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.209453365628954,
        "cond_entropy-2-nopunct": 0.31995770317401967,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.12199052437861026,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.38461538461538464,
            "3": 0.52
        },
        "rouge1": {
            "precision": 0.55093,
            "recall": 0.5069,
            "fmeasure": 0.52276
        },
        "rouge2": {
            "precision": 0.23889,
            "recall": 0.22589,
            "fmeasure": 0.22923
        },
        "rougeL": {
            "precision": 0.42824,
            "recall": 0.38495,
            "fmeasure": 0.40113
        },
        "rougeLsum": {
            "precision": 0.42824,
            "recall": 0.38495,
            "fmeasure": 0.40113
        },
        "nist": 2.799245838910602,
        "bleu": 7.64006,
        "meteor": 0.2513865272908831,
        "bleurt": 0.01491,
        "nubia": {
            "semantic_relation": 3.88493,
            "contradiction": 0.31265,
            "irrelevancy": 50.73795,
            "logical_agreement": 48.9494,
            "grammar_ref": 4.28129,
            "grammar_hyp": 4.40174,
            "nubia_score": 0.6655
        },
        "bertscore": {
            "precision": 0.87141,
            "recall": 0.86873,
            "f1": 0.86939
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 6.377042156569663,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 35,
        "unique-1": 30,
        "entropy-1": 5.023037065532883,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.16885114229280793,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.1154772174199358,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 5.90668171555645,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.868421052631579,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.964904158123496,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.18863800356319427,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5079365079365079
        },
        "rouge1": {
            "precision": 0.87897,
            "recall": 0.45435,
            "fmeasure": 0.58285
        },
        "rouge2": {
            "precision": 0.59722,
            "recall": 0.29488,
            "fmeasure": 0.38285
        },
        "rougeL": {
            "precision": 0.65146,
            "recall": 0.33902,
            "fmeasure": 0.43544
        },
        "rougeLsum": {
            "precision": 0.65146,
            "recall": 0.33902,
            "fmeasure": 0.43544
        },
        "nist": 0.81178315260336,
        "bleu": 17.39913,
        "meteor": 0.2531376200794584,
        "bleurt": 0.03522,
        "nubia": {
            "semantic_relation": 3.39734,
            "contradiction": 0.5973,
            "irrelevancy": 33.58213,
            "logical_agreement": 65.82058,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.97846,
            "nubia_score": 0.47619
        },
        "bertscore": {
            "precision": 0.93765,
            "recall": 0.8259,
            "f1": 0.87748
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 2.3570226039551585,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 19,
        "distinct-1": 0.75,
        "vocab_size-1": 39,
        "unique-1": 30,
        "entropy-1": 5.13294404498096,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.4194719117325545,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.09114788805819536,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7872340425531915,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.070442309078416,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.3992720283724656,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.10187961401921372,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.67219,
            "recall": 0.62991,
            "fmeasure": 0.64756
        },
        "rouge2": {
            "precision": 0.40566,
            "recall": 0.36633,
            "fmeasure": 0.38431
        },
        "rougeL": {
            "precision": 0.6475,
            "recall": 0.60763,
            "fmeasure": 0.62416
        },
        "rougeLsum": {
            "precision": 0.6475,
            "recall": 0.60763,
            "fmeasure": 0.62416
        },
        "nist": 4.128737674467138,
        "bleu": 29.67494,
        "meteor": 0.3701584385757779,
        "bleurt": 0.25947,
        "nubia": {
            "semantic_relation": 4.21416,
            "contradiction": 0.30911,
            "irrelevancy": 17.81986,
            "logical_agreement": 81.87103,
            "grammar_ref": 4.73268,
            "grammar_hyp": 4.51056,
            "nubia_score": 0.74844
        },
        "bertscore": {
            "precision": 0.93024,
            "recall": 0.90299,
            "f1": 0.91635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 19,
        "unique-1": 15,
        "entropy-1": 4.1757358691004915,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 21,
        "unique-2": 20,
        "entropy-2": 4.368522527728204,
        "cond_entropy-2": 0.20859693530755724,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.021928094887363,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.142664355548846,
        "cond_entropy-2-nopunct": 0.0838941553983285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.0224469564457176,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.42857142857142855,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.78632,
            "fmeasure": 0.63492
        },
        "rouge2": {
            "precision": 0.19298,
            "recall": 0.34722,
            "fmeasure": 0.24612
        },
        "rougeL": {
            "precision": 0.36667,
            "recall": 0.63248,
            "fmeasure": 0.46116
        },
        "rougeLsum": {
            "precision": 0.36667,
            "recall": 0.63248,
            "fmeasure": 0.46116
        },
        "nist": 2.749386876031977,
        "bleu": 24.41686,
        "meteor": 0.3591077489670912,
        "bleurt": -0.01236,
        "nubia": {
            "semantic_relation": 4.11785,
            "contradiction": 1.60924,
            "irrelevancy": 76.20549,
            "logical_agreement": 22.18527,
            "grammar_ref": 5.94843,
            "grammar_hyp": 4.42737,
            "nubia_score": 0.77026
        },
        "bertscore": {
            "precision": 0.88046,
            "recall": 0.91346,
            "f1": 0.89665
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 64,
        "mean_pred_length": 10.666666666666666,
        "std_pred_length": 3.7267799624996494,
        "median_pred_length": 8.5,
        "min_pred_length": 8,
        "max_pred_length": 18,
        "distinct-1": 0.53125,
        "vocab_size-1": 34,
        "unique-1": 23,
        "entropy-1": 4.716578664259099,
        "distinct-2": 0.7413793103448276,
        "vocab_size-2": 43,
        "unique-2": 35,
        "entropy-2": 5.24118034838934,
        "cond_entropy-2": 0.3899594946495262,
        "distinct-3": 0.8076923076923077,
        "vocab_size-3": 42,
        "unique-3": 37,
        "entropy-3": 5.243238996779223,
        "cond_entropy-3": -0.018212190489623643,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 7.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.5535714285714286,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.617547949145272,
        "distinct-2-nopunct": 0.74,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 5.023465189601649,
        "cond_entropy-2-nopunct": 0.4218970771481642,
        "distinct-3-nopunct": 0.8181818181818182,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.027169118440617,
        "cond_entropy-3-nopunct": -0.01976292345932451,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.23076923076923078,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.90327,
            "recall": 0.83876,
            "fmeasure": 0.86611
        },
        "rouge2": {
            "precision": 0.76489,
            "recall": 0.69931,
            "fmeasure": 0.72593
        },
        "rougeL": {
            "precision": 0.83383,
            "recall": 0.7808,
            "fmeasure": 0.80246
        },
        "rougeLsum": {
            "precision": 0.83383,
            "recall": 0.7808,
            "fmeasure": 0.80246
        },
        "nist": 5.082312185257378,
        "bleu": 66.02675,
        "meteor": 0.4915169785704435,
        "bleurt": 0.63283,
        "nubia": {
            "semantic_relation": 4.36629,
            "contradiction": 18.11383,
            "irrelevancy": 1.54093,
            "logical_agreement": 80.34524,
            "grammar_ref": 4.0718,
            "grammar_hyp": 4.19837,
            "nubia_score": 0.81328
        },
        "bertscore": {
            "precision": 0.97508,
            "recall": 0.97022,
            "f1": 0.97241
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.7948717948717948,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.804507667524723,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 35,
        "unique-2": 34,
        "entropy-2": 5.114369445886754,
        "cond_entropy-2": 0.21785611591339749,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.06492482147779849,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.73452166477975,
        "distinct-2-nopunct": 0.967741935483871,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.889680181354619,
        "cond_entropy-2-nopunct": 0.18931411429782607,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.07541281690069972,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.7857142857142857,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.79444,
            "recall": 0.66963,
            "fmeasure": 0.71992
        },
        "rouge2": {
            "precision": 0.50379,
            "recall": 0.41907,
            "fmeasure": 0.45259
        },
        "rougeL": {
            "precision": 0.63519,
            "recall": 0.53073,
            "fmeasure": 0.57297
        },
        "rougeLsum": {
            "precision": 0.63519,
            "recall": 0.53073,
            "fmeasure": 0.57297
        },
        "nist": 4.256738770241894,
        "bleu": 39.62503,
        "meteor": 0.37337313767320074,
        "bleurt": 0.391,
        "nubia": {
            "semantic_relation": 3.95379,
            "contradiction": 22.24997,
            "irrelevancy": 3.12849,
            "logical_agreement": 74.62154,
            "grammar_ref": 3.54742,
            "grammar_hyp": 3.31234,
            "nubia_score": 0.75334
        },
        "bertscore": {
            "precision": 0.9286,
            "recall": 0.90316,
            "f1": 0.91531
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.4142135623730951,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 15,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.9389977315718125,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.12771410208460493,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9117647058823529,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.8887896794220005,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.08463306598051874,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.058823529411764705,
            "3": 0.6388888888888888
        },
        "rouge1": {
            "precision": 0.73458,
            "recall": 0.51789,
            "fmeasure": 0.59944
        },
        "rouge2": {
            "precision": 0.38148,
            "recall": 0.26032,
            "fmeasure": 0.30362
        },
        "rougeL": {
            "precision": 0.58531,
            "recall": 0.41152,
            "fmeasure": 0.47662
        },
        "rougeLsum": {
            "precision": 0.58531,
            "recall": 0.41152,
            "fmeasure": 0.47662
        },
        "nist": 1.4567383181739553,
        "bleu": 21.61458,
        "meteor": 0.289248528699545,
        "bleurt": -0.05545,
        "nubia": {
            "semantic_relation": 3.99183,
            "contradiction": 25.02426,
            "irrelevancy": 11.99797,
            "logical_agreement": 62.97776,
            "grammar_ref": 4.60968,
            "grammar_hyp": 5.60649,
            "nubia_score": 0.49716
        },
        "bertscore": {
            "precision": 0.90755,
            "recall": 0.8526,
            "f1": 0.87878
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69841,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.50183,
            "fmeasure": 0.59816
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "nist": 2.4318521982275305,
        "bleu": 34.49084,
        "meteor": 0.40317673606169013,
        "bleurt": 0.31074,
        "nubia": {
            "semantic_relation": 4.98381,
            "contradiction": 0.68922,
            "irrelevancy": 0.65351,
            "logical_agreement": 98.65726,
            "grammar_ref": 5.37123,
            "grammar_hyp": 7.31853,
            "nubia_score": 0.67313
        },
        "bertscore": {
            "precision": 0.97536,
            "recall": 0.92792,
            "f1": 0.95105
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 57,
        "mean_pred_length": 14.25,
        "std_pred_length": 5.80409338312195,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.8596491228070176,
        "vocab_size-1": 49,
        "unique-1": 44,
        "entropy-1": 5.503856900091694,
        "distinct-2": 1.0,
        "vocab_size-2": 53,
        "unique-2": 53,
        "entropy-2": 5.727920454563195,
        "cond_entropy-2": 0.09795284609965511,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.11321061044799063,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 4.55521678957215,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.428758439731458,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5235619560570095,
        "cond_entropy-2-nopunct": 0.09176853806845059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.1312445332782525,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.7111111111111111
        },
        "rouge1": {
            "precision": 0.69722,
            "recall": 0.62539,
            "fmeasure": 0.64506
        },
        "rouge2": {
            "precision": 0.50807,
            "recall": 0.40909,
            "fmeasure": 0.45278
        },
        "rougeL": {
            "precision": 0.64722,
            "recall": 0.58191,
            "fmeasure": 0.59855
        },
        "rougeLsum": {
            "precision": 0.64722,
            "recall": 0.58191,
            "fmeasure": 0.59855
        },
        "nist": 3.7320327075101902,
        "bleu": 40.98162,
        "meteor": 0.34743885848527606,
        "bleurt": 0.02489,
        "nubia": {
            "semantic_relation": 3.65894,
            "contradiction": 12.66645,
            "irrelevancy": 35.46783,
            "logical_agreement": 51.86571,
            "grammar_ref": 4.34153,
            "grammar_hyp": 4.92283,
            "nubia_score": 0.51325
        },
        "bertscore": {
            "precision": 0.90291,
            "recall": 0.87706,
            "f1": 0.88801
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.82051,
            "recall": 0.8,
            "fmeasure": 0.80331
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.61376,
            "fmeasure": 0.62027
        },
        "rougeL": {
            "precision": 0.82051,
            "recall": 0.8,
            "fmeasure": 0.80331
        },
        "rougeLsum": {
            "precision": 0.82051,
            "recall": 0.8,
            "fmeasure": 0.80331
        },
        "nist": 4.833468941934959,
        "bleu": 58.63327,
        "meteor": 0.49502765334006454,
        "bleurt": 0.35845,
        "nubia": {
            "semantic_relation": 4.53312,
            "contradiction": 1.25441,
            "irrelevancy": 51.1636,
            "logical_agreement": 47.582,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.23026,
            "nubia_score": 0.72504
        },
        "bertscore": {
            "precision": 0.97908,
            "recall": 0.9586,
            "f1": 0.96873
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 74,
        "mean_pred_length": 18.5,
        "std_pred_length": 3.5,
        "median_pred_length": 19.5,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.7837837837837838,
        "vocab_size-1": 58,
        "unique-1": 49,
        "entropy-1": 5.67418795381224,
        "distinct-2": 0.9857142857142858,
        "vocab_size-2": 69,
        "unique-2": 68,
        "entropy-2": 6.100711588373543,
        "cond_entropy-2": 0.4285388009508287,
        "distinct-3": 1.0,
        "vocab_size-3": 66,
        "unique-3": 66,
        "entropy-3": 6.044394119358462,
        "cond_entropy-3": -0.05458586728348299,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 2.692582403567252,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.595763203079114,
        "distinct-2-nopunct": 0.9838709677419355,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.921938245870744,
        "cond_entropy-2-nopunct": 0.3551189728741764,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.061732556638613253,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12,
            "2": 0.7,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.76771,
            "recall": 0.67243,
            "fmeasure": 0.71533
        },
        "rouge2": {
            "precision": 0.49217,
            "recall": 0.49011,
            "fmeasure": 0.47616
        },
        "rougeL": {
            "precision": 0.65938,
            "recall": 0.61086,
            "fmeasure": 0.62426
        },
        "rougeLsum": {
            "precision": 0.65938,
            "recall": 0.61086,
            "fmeasure": 0.62426
        },
        "nist": 4.960312835759586,
        "bleu": 44.3419,
        "meteor": 0.4230853456235142,
        "bleurt": 0.25432,
        "nubia": {
            "semantic_relation": 4.06612,
            "contradiction": 1.82616,
            "irrelevancy": 50.67794,
            "logical_agreement": 47.49589,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.85625,
            "nubia_score": 0.60919
        },
        "bertscore": {
            "precision": 0.93218,
            "recall": 0.9368,
            "f1": 0.92692
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 56,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.9154759474226504,
        "median_pred_length": 12.5,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.6964285714285714,
        "vocab_size-1": 39,
        "unique-1": 29,
        "entropy-1": 5.052628805870279,
        "distinct-2": 0.9038461538461539,
        "vocab_size-2": 47,
        "unique-2": 43,
        "entropy-2": 5.493614958484104,
        "cond_entropy-2": 0.40760186343278526,
        "distinct-3": 0.9791666666666666,
        "vocab_size-3": 47,
        "unique-3": 46,
        "entropy-3": 5.543295834054493,
        "cond_entropy-3": 0.06691627220846971,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 11.25,
        "std_pred_length-nopunct": 2.277608394786075,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 5.002964207440786,
        "distinct-2-nopunct": 0.9512195121951219,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.259991029008325,
        "cond_entropy-2-nopunct": 0.3047232985323112,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.03999053088102579,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.69091,
            "recall": 0.70399,
            "fmeasure": 0.68799
        },
        "rouge2": {
            "precision": 0.51627,
            "recall": 0.53287,
            "fmeasure": 0.51855
        },
        "rougeL": {
            "precision": 0.58258,
            "recall": 0.64603,
            "fmeasure": 0.60853
        },
        "rougeLsum": {
            "precision": 0.58258,
            "recall": 0.64603,
            "fmeasure": 0.60853
        },
        "nist": 3.3868638669906415,
        "bleu": 34.74641,
        "meteor": 0.32897247917222106,
        "bleurt": 0.25813,
        "nubia": {
            "semantic_relation": 4.0562,
            "contradiction": 16.62432,
            "irrelevancy": 18.63362,
            "logical_agreement": 64.74207,
            "grammar_ref": 4.6519,
            "grammar_hyp": 4.59738,
            "nubia_score": 0.68807
        },
        "bertscore": {
            "precision": 0.91244,
            "recall": 0.90539,
            "f1": 0.90752
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.81212,
            "fmeasure": 0.8381
        },
        "rouge2": {
            "precision": 0.62963,
            "recall": 0.58519,
            "fmeasure": 0.60624
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.7,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.7,
            "fmeasure": 0.7
        },
        "nist": 3.0508304921677483,
        "bleu": 35.0844,
        "meteor": 0.42897263619332243,
        "bleurt": 0.61971,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21914,
            "irrelevancy": 0.45589,
            "logical_agreement": 99.32496,
            "grammar_ref": 5.07856,
            "grammar_hyp": 5.05352,
            "nubia_score": 0.99841
        },
        "bertscore": {
            "precision": 0.95262,
            "recall": 0.96332,
            "f1": 0.95771
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "t5-small/totto_test",
        "N": 123,
        "total_length": 1877,
        "mean_pred_length": 15.260162601626016,
        "std_pred_length": 4.489984153328154,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 28,
        "distinct-1": 0.3665423548215237,
        "vocab_size-1": 688,
        "unique-1": 566,
        "entropy-1": 7.43562795833407,
        "distinct-2": 0.6721778791334093,
        "vocab_size-2": 1179,
        "unique-2": 1069,
        "entropy-2": 9.366779673677648,
        "cond_entropy-2": 1.7205016265693167,
        "distinct-3": 0.7823421213979154,
        "vocab_size-3": 1276,
        "unique-3": 1217,
        "entropy-3": 9.731285724433548,
        "cond_entropy-3": 0.43059190034971206,
        "total_length-nopunct": 1635,
        "mean_pred_length-nopunct": 13.292682926829269,
        "std_pred_length-nopunct": 4.101817378922873,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.41651376146788993,
        "vocab_size-1-nopunct": 681,
        "unique-1-nopunct": 565,
        "entropy-1-nopunct": 7.65065484466268,
        "distinct-2-nopunct": 0.6812169312169312,
        "vocab_size-2-nopunct": 1030,
        "unique-2-nopunct": 946,
        "entropy-2-nopunct": 9.172619636275764,
        "cond_entropy-2-nopunct": 1.6987356330333863,
        "distinct-3-nopunct": 0.7876169906407487,
        "vocab_size-3-nopunct": 1094,
        "unique-3-nopunct": 1049,
        "entropy-3-nopunct": 9.51685518834534,
        "cond_entropy-3-nopunct": 0.4552445049070647,
        "msttr-100": 0.61444,
        "msttr-100_nopunct": 0.65438,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.303886925795053,
            "2": 0.4214046822742475,
            "3": 0.7113163972286374
        },
        "rouge1": {
            "precision": 0.74676,
            "recall": 0.72641,
            "fmeasure": 0.72404
        },
        "rouge2": {
            "precision": 0.53439,
            "recall": 0.51748,
            "fmeasure": 0.517
        },
        "rougeL": {
            "precision": 0.64627,
            "recall": 0.62842,
            "fmeasure": 0.62615
        },
        "rougeLsum": {
            "precision": 0.64627,
            "recall": 0.62842,
            "fmeasure": 0.62615
        },
        "nist": 7.196765899572763,
        "bleu": 47.17709,
        "meteor": 0.3760554401378771,
        "bleurt": 0.29845,
        "nubia": {
            "semantic_relation": 4.09878,
            "contradiction": 11.00259,
            "irrelevancy": 28.46064,
            "logical_agreement": 60.53676,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.69701,
            "nubia_score": 0.70193
        },
        "bertscore": {
            "precision": 0.9223,
            "recall": 0.91753,
            "f1": 0.91834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 3.681787005729087,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.8918918918918919,
        "vocab_size-1": 33,
        "unique-1": 30,
        "entropy-1": 4.9728347844894,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": -0.004343465555080842,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.13326653086346418,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.265986323710904,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9393939393939394,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.923181998146335,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": -0.004170190416601399,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.3333333333333333,
            "3": 0.7666666666666667
        },
        "rouge1": {
            "precision": 0.76768,
            "recall": 0.70293,
            "fmeasure": 0.72889
        },
        "rouge2": {
            "precision": 0.58466,
            "recall": 0.44537,
            "fmeasure": 0.49674
        },
        "rougeL": {
            "precision": 0.69823,
            "recall": 0.64933,
            "fmeasure": 0.66858
        },
        "rougeLsum": {
            "precision": 0.69823,
            "recall": 0.64933,
            "fmeasure": 0.66858
        },
        "nist": 3.4518289457131988,
        "bleu": 52.67406,
        "meteor": 0.3839367185725086,
        "bleurt": 0.08214,
        "nubia": {
            "semantic_relation": 3.93768,
            "contradiction": 0.25926,
            "irrelevancy": 55.44782,
            "logical_agreement": 44.29292,
            "grammar_ref": 4.66623,
            "grammar_hyp": 4.63713,
            "nubia_score": 0.69553
        },
        "bertscore": {
            "precision": 0.92732,
            "recall": 0.91147,
            "f1": 0.9065
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 17,
        "distinct-1": 0.6938775510204082,
        "vocab_size-1": 34,
        "unique-1": 24,
        "entropy-1": 4.897987079242479,
        "distinct-2": 0.9130434782608695,
        "vocab_size-2": 42,
        "unique-2": 38,
        "entropy-2": 5.349648912578749,
        "cond_entropy-2": 0.3469745292048839,
        "distinct-3": 0.9302325581395349,
        "vocab_size-3": 40,
        "unique-3": 37,
        "entropy-3": 5.286729870981167,
        "cond_entropy-3": -0.05078557344793836,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7380952380952381,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.832560875056691,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.131556065016093,
        "cond_entropy-2-nopunct": 0.3164123602969994,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.058813890331199,
        "cond_entropy-3-nopunct": -0.08769943964215805,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.2857142857142857,
            "3": 0.5945945945945946
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.63504,
            "fmeasure": 0.64824
        },
        "rouge2": {
            "precision": 0.52083,
            "recall": 0.48693,
            "fmeasure": 0.50154
        },
        "rougeL": {
            "precision": 0.65926,
            "recall": 0.62763,
            "fmeasure": 0.64083
        },
        "rougeLsum": {
            "precision": 0.65926,
            "recall": 0.62763,
            "fmeasure": 0.64083
        },
        "nist": 3.293404542114152,
        "bleu": 35.80912,
        "meteor": 0.33076442644937903,
        "bleurt": 0.01402,
        "nubia": {
            "semantic_relation": 3.60524,
            "contradiction": 1.50734,
            "irrelevancy": 14.72109,
            "logical_agreement": 83.77157,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.19916,
            "nubia_score": 0.61168
        },
        "bertscore": {
            "precision": 0.88328,
            "recall": 0.86663,
            "f1": 0.87442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.132944044980958,
        "distinct-2": 0.96,
        "vocab_size-2": 24,
        "unique-2": 23,
        "entropy-2": 4.5638561897747225,
        "cond_entropy-2": 0.4536119717201712,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": 0.024439644279765037,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.053660689688185,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.47255995686990937,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": 0.025555977074987166,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.48,
            "recall": 0.6,
            "fmeasure": 0.53333
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.21053,
            "fmeasure": 0.18605
        },
        "rougeL": {
            "precision": 0.32,
            "recall": 0.4,
            "fmeasure": 0.35556
        },
        "rougeLsum": {
            "precision": 0.32,
            "recall": 0.4,
            "fmeasure": 0.35556
        },
        "nist": 2.4673221151072484,
        "bleu": 6.64602,
        "meteor": 0.2603243930719453,
        "bleurt": -0.46764,
        "nubia": {
            "semantic_relation": 3.21258,
            "contradiction": 1.32646,
            "irrelevancy": 88.0183,
            "logical_agreement": 10.65524,
            "grammar_ref": 5.26752,
            "grammar_hyp": 3.82702,
            "nubia_score": 0.59047
        },
        "bertscore": {
            "precision": 0.80166,
            "recall": 0.84584,
            "f1": 0.82316
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.45833,
            "fmeasure": 0.56818
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.25175,
            "fmeasure": 0.31667
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.3869,
            "fmeasure": 0.47727
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.3869,
            "fmeasure": 0.47727
        },
        "nist": 1.2376331889361145,
        "bleu": 17.54847,
        "meteor": 0.26404697547181144,
        "bleurt": -0.08486,
        "nubia": {
            "semantic_relation": 3.67876,
            "contradiction": 0.71115,
            "irrelevancy": 23.90828,
            "logical_agreement": 75.38058,
            "grammar_ref": 5.74657,
            "grammar_hyp": 5.75623,
            "nubia_score": 0.56868
        },
        "bertscore": {
            "precision": 0.92904,
            "recall": 0.85055,
            "f1": 0.88806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 21,
        "entropy-1": 4.483856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.03333771197858132,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.72
        },
        "rouge1": {
            "precision": 0.91026,
            "recall": 0.75,
            "fmeasure": 0.81053
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.62939,
            "fmeasure": 0.65961
        },
        "rougeL": {
            "precision": 0.78205,
            "recall": 0.67121,
            "fmeasure": 0.71299
        },
        "rougeLsum": {
            "precision": 0.78205,
            "recall": 0.67121,
            "fmeasure": 0.71299
        },
        "nist": 3.0748081497762847,
        "bleu": 49.97758,
        "meteor": 0.3862943262274689,
        "bleurt": 0.41797,
        "nubia": {
            "semantic_relation": 4.37109,
            "contradiction": 0.27611,
            "irrelevancy": 4.98794,
            "logical_agreement": 94.73596,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.90456,
            "nubia_score": 0.76208
        },
        "bertscore": {
            "precision": 0.97035,
            "recall": 0.93052,
            "f1": 0.94955
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.91667,
            "fmeasure": 0.93333
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "nist": 4.251192788981044,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.64779,
        "nubia": {
            "semantic_relation": 4.42679,
            "contradiction": 6.87785,
            "irrelevancy": 1.70123,
            "logical_agreement": 91.42092,
            "grammar_ref": 7.10682,
            "grammar_hyp": 7.20763,
            "nubia_score": 0.72464
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 110,
        "mean_pred_length": 15.714285714285714,
        "std_pred_length": 3.4934340744678525,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 80,
        "unique-1": 66,
        "entropy-1": 6.0433845145270855,
        "distinct-2": 0.9902912621359223,
        "vocab_size-2": 102,
        "unique-2": 101,
        "entropy-2": 6.667083051455081,
        "cond_entropy-2": 0.5006082151865977,
        "distinct-3": 1.0,
        "vocab_size-3": 96,
        "unique-3": 96,
        "entropy-3": 6.5849625007211605,
        "cond_entropy-3": -0.08070469312872877,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 13.571428571428571,
        "std_pred_length-nopunct": 3.2450904833144416,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8105263157894737,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 6.129073471689608,
        "distinct-2-nopunct": 0.9886363636363636,
        "vocab_size-2-nopunct": 87,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.436704345910033,
        "cond_entropy-2-nopunct": 0.33132945327143165,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.339850002884614,
        "cond_entropy-3-nopunct": -0.09489025772798118,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.39285714285714285,
            "3": 0.7391304347826086
        },
        "rouge1": {
            "precision": 0.72969,
            "recall": 0.71393,
            "fmeasure": 0.71174
        },
        "rouge2": {
            "precision": 0.50486,
            "recall": 0.50092,
            "fmeasure": 0.49705
        },
        "rougeL": {
            "precision": 0.59146,
            "recall": 0.59143,
            "fmeasure": 0.58523
        },
        "rougeLsum": {
            "precision": 0.59146,
            "recall": 0.59143,
            "fmeasure": 0.58523
        },
        "nist": 4.542383368441592,
        "bleu": 41.33471,
        "meteor": 0.3427002005702675,
        "bleurt": 0.30183,
        "nubia": {
            "semantic_relation": 3.91586,
            "contradiction": 6.32944,
            "irrelevancy": 63.95941,
            "logical_agreement": 29.71116,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.43485,
            "nubia_score": 0.67313
        },
        "bertscore": {
            "precision": 0.9153,
            "recall": 0.91587,
            "f1": 0.9125
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.12385402685271858,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.79327,
            "fmeasure": 0.78765
        },
        "rouge2": {
            "precision": 0.51282,
            "recall": 0.52222,
            "fmeasure": 0.51619
        },
        "rougeL": {
            "precision": 0.7381,
            "recall": 0.7516,
            "fmeasure": 0.74321
        },
        "rougeLsum": {
            "precision": 0.7381,
            "recall": 0.7516,
            "fmeasure": 0.74321
        },
        "nist": 3.298331093594372,
        "bleu": 42.61083,
        "meteor": 0.4131173812693214,
        "bleurt": 0.62849,
        "nubia": {
            "semantic_relation": 4.33149,
            "contradiction": 0.19541,
            "irrelevancy": 4.27648,
            "logical_agreement": 95.52812,
            "grammar_ref": 4.55634,
            "grammar_hyp": 4.87151,
            "nubia_score": 0.71637
        },
        "bertscore": {
            "precision": 0.97094,
            "recall": 0.96339,
            "f1": 0.96715
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.67281,
            "fmeasure": 0.75742
        },
        "rouge2": {
            "precision": 0.78571,
            "recall": 0.60039,
            "fmeasure": 0.68056
        },
        "rougeL": {
            "precision": 0.86667,
            "recall": 0.67281,
            "fmeasure": 0.75742
        },
        "rougeLsum": {
            "precision": 0.86667,
            "recall": 0.67281,
            "fmeasure": 0.75742
        },
        "nist": 3.430248660880481,
        "bleu": 60.61106,
        "meteor": 0.411233960934545,
        "bleurt": -0.02314,
        "nubia": {
            "semantic_relation": 3.78393,
            "contradiction": 6.25314,
            "irrelevancy": 61.02489,
            "logical_agreement": 32.72196,
            "grammar_ref": 3.98302,
            "grammar_hyp": 4.98317,
            "nubia_score": 0.47619
        },
        "bertscore": {
            "precision": 0.95847,
            "recall": 0.9247,
            "f1": 0.939
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 11,
        "unique-1": 7,
        "entropy-1": 3.3735572622751846,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 13,
        "unique-2": 12,
        "entropy-2": 3.6644977792004623,
        "cond_entropy-2": 0.3290357550205142,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": 0.04693094992964167,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.0850551027564768,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.418295834054489,
        "cond_entropy-2-nopunct": 0.30118944924673074,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": 0.056287299734322706,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.8
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.83974,
            "fmeasure": 0.79202
        },
        "rouge2": {
            "precision": 0.61538,
            "recall": 0.69697,
            "fmeasure": 0.65333
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.83974,
            "fmeasure": 0.79202
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.83974,
            "fmeasure": 0.79202
        },
        "nist": 2.9292701720182075,
        "bleu": 56.22008,
        "meteor": 0.4768656407248471,
        "bleurt": 0.30341,
        "nubia": {
            "semantic_relation": 3.17191,
            "contradiction": 99.88113,
            "irrelevancy": 0.08265,
            "logical_agreement": 0.03621,
            "grammar_ref": 3.96979,
            "grammar_hyp": 3.52021,
            "nubia_score": 0.49974
        },
        "bertscore": {
            "precision": 0.9646,
            "recall": 0.94225,
            "f1": 0.9533
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.82143,
            "fmeasure": 0.73529
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.56566,
            "fmeasure": 0.5213
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.82143,
            "fmeasure": 0.73529
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.82143,
            "fmeasure": 0.73529
        },
        "nist": 3.1070901626504495,
        "bleu": 30.87819,
        "meteor": 0.5146997364109374,
        "bleurt": 0.55167,
        "nubia": {
            "semantic_relation": 4.39839,
            "contradiction": 0.19355,
            "irrelevancy": 58.504,
            "logical_agreement": 41.30245,
            "grammar_ref": 5.29735,
            "grammar_hyp": 4.51733,
            "nubia_score": 0.92645
        },
        "bertscore": {
            "precision": 0.94013,
            "recall": 0.97508,
            "f1": 0.95728
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.67879,
            "fmeasure": 0.80828
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.42963,
            "fmeasure": 0.52222
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.67879,
            "fmeasure": 0.80828
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.67879,
            "fmeasure": 0.80828
        },
        "nist": 1.7429940067052794,
        "bleu": 31.35601,
        "meteor": 0.3429171762502037,
        "bleurt": 0.43065,
        "nubia": {
            "semantic_relation": 4.88811,
            "contradiction": 0.86462,
            "irrelevancy": 0.61189,
            "logical_agreement": 98.5235,
            "grammar_ref": 4.055,
            "grammar_hyp": 5.26867,
            "nubia_score": 0.86686
        },
        "bertscore": {
            "precision": 0.9727,
            "recall": 0.91553,
            "f1": 0.94325
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 8.0,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 32,
        "unique-1": 27,
        "entropy-1": 4.912272579176127,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.22074436305882314,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.829966150010236,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.18612739319226895,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.76
        },
        "rouge1": {
            "precision": 0.725,
            "recall": 0.76633,
            "fmeasure": 0.7447
        },
        "rouge2": {
            "precision": 0.4525,
            "recall": 0.47718,
            "fmeasure": 0.4642
        },
        "rougeL": {
            "precision": 0.50972,
            "recall": 0.55854,
            "fmeasure": 0.53249
        },
        "rougeLsum": {
            "precision": 0.50972,
            "recall": 0.55854,
            "fmeasure": 0.53249
        },
        "nist": 4.006616942659026,
        "bleu": 26.18053,
        "meteor": 0.34916686370224137,
        "bleurt": 0.11798,
        "nubia": {
            "semantic_relation": 4.48493,
            "contradiction": 0.2032,
            "irrelevancy": 46.36529,
            "logical_agreement": 53.43151,
            "grammar_ref": 4.18803,
            "grammar_hyp": 4.04488,
            "nubia_score": 0.83353
        },
        "bertscore": {
            "precision": 0.8634,
            "recall": 0.90227,
            "f1": 0.87713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "nist": 4.090634124990776,
        "bleu": 76.11606,
        "meteor": 0.5715186082473627,
        "bleurt": 0.48581,
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        },
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.0,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 28,
        "unique-1": 24,
        "entropy-1": 4.675698135367986,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.3500371587496607,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8387096774193549,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.567099536193327,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.28309502956828325,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.56883,
            "recall": 0.47032,
            "fmeasure": 0.51458
        },
        "rouge2": {
            "precision": 0.34722,
            "recall": 0.28438,
            "fmeasure": 0.31241
        },
        "rougeL": {
            "precision": 0.51619,
            "recall": 0.42745,
            "fmeasure": 0.46733
        },
        "rougeLsum": {
            "precision": 0.51619,
            "recall": 0.42745,
            "fmeasure": 0.46733
        },
        "nist": 2.3316885423250975,
        "bleu": 20.68203,
        "meteor": 0.21323362950206912,
        "bleurt": -0.31505,
        "nubia": {
            "semantic_relation": 3.05559,
            "contradiction": 50.47615,
            "irrelevancy": 46.21813,
            "logical_agreement": 3.30571,
            "grammar_ref": 3.82725,
            "grammar_hyp": 4.64271,
            "nubia_score": 0.36008
        },
        "bertscore": {
            "precision": 0.85026,
            "recall": 0.85101,
            "f1": 0.84975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.53472,
            "fmeasure": 0.49622
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.08283,
            "fmeasure": 0.07632
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.38194,
            "fmeasure": 0.35444
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.38194,
            "fmeasure": 0.35444
        },
        "nist": 2.02003483358725,
        "bleu": 10.87866,
        "meteor": 0.23878691537242483,
        "bleurt": -0.31082,
        "nubia": {
            "semantic_relation": 3.83974,
            "contradiction": 0.92946,
            "irrelevancy": 21.16975,
            "logical_agreement": 77.90079,
            "grammar_ref": 5.53377,
            "grammar_hyp": 5.42897,
            "nubia_score": 0.60413
        },
        "bertscore": {
            "precision": 0.82675,
            "recall": 0.8412,
            "f1": 0.83317
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 80,
        "mean_pred_length": 20.0,
        "std_pred_length": 5.338539126015656,
        "median_pred_length": 19.5,
        "min_pred_length": 13,
        "max_pred_length": 28,
        "distinct-1": 0.6375,
        "vocab_size-1": 51,
        "unique-1": 37,
        "entropy-1": 5.357935401402813,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 68,
        "unique-2": 61,
        "entropy-2": 6.0274684673624925,
        "cond_entropy-2": 0.6634020485787621,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 68,
        "unique-3": 64,
        "entropy-3": 6.058813890331207,
        "cond_entropy-3": 0.04359314775099714,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 5.722761571129799,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6410256410256411,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.322332789647333,
        "distinct-2-nopunct": 0.8918918918918919,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.98303596695107,
        "cond_entropy-2-nopunct": 0.6678700640871462,
        "distinct-3-nopunct": 0.9428571428571428,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 62,
        "entropy-3-nopunct": 6.014997302659258,
        "cond_entropy-3-nopunct": 0.03061375848978054,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.2631578947368421,
            "3": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.47585,
            "recall": 0.44068,
            "fmeasure": 0.43627
        },
        "rouge2": {
            "precision": 0.25961,
            "recall": 0.23925,
            "fmeasure": 0.2366
        },
        "rougeL": {
            "precision": 0.36513,
            "recall": 0.37052,
            "fmeasure": 0.35225
        },
        "rougeLsum": {
            "precision": 0.36513,
            "recall": 0.37052,
            "fmeasure": 0.35225
        },
        "nist": 3.3186239638003676,
        "bleu": 27.44164,
        "meteor": 0.23701744151143184,
        "bleurt": -0.69853,
        "nubia": {
            "semantic_relation": 2.86525,
            "contradiction": 35.3178,
            "irrelevancy": 48.46776,
            "logical_agreement": 16.21444,
            "grammar_ref": 4.54253,
            "grammar_hyp": 4.30276,
            "nubia_score": 0.29149
        },
        "bertscore": {
            "precision": 0.8222,
            "recall": 0.7831,
            "f1": 0.802
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "t5-small/totto_test",
        "N": 6,
        "total_length": 95,
        "mean_pred_length": 15.833333333333334,
        "std_pred_length": 3.890872509976251,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.6421052631578947,
        "vocab_size-1": 61,
        "unique-1": 43,
        "entropy-1": 5.635865545665678,
        "distinct-2": 0.8539325842696629,
        "vocab_size-2": 76,
        "unique-2": 63,
        "entropy-2": 6.183598599505731,
        "cond_entropy-2": 0.4802532774530194,
        "distinct-3": 0.8795180722891566,
        "vocab_size-3": 73,
        "unique-3": 63,
        "entropy-3": 6.134075575925243,
        "cond_entropy-3": -0.05250122853513562,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 13.833333333333334,
        "std_pred_length-nopunct": 3.131382371342656,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6867469879518072,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.585765033704436,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.981072254980619,
        "cond_entropy-2-nopunct": 0.4308350964171579,
        "distinct-3-nopunct": 0.8732394366197183,
        "vocab_size-3-nopunct": 62,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.896225992744112,
        "cond_entropy-3-nopunct": -0.08887040710571219,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.55,
            "3": 0.6935483870967742
        },
        "rouge1": {
            "precision": 0.77164,
            "recall": 0.76149,
            "fmeasure": 0.75891
        },
        "rouge2": {
            "precision": 0.53928,
            "recall": 0.54373,
            "fmeasure": 0.53755
        },
        "rougeL": {
            "precision": 0.69162,
            "recall": 0.68849,
            "fmeasure": 0.68311
        },
        "rougeLsum": {
            "precision": 0.69162,
            "recall": 0.68849,
            "fmeasure": 0.68311
        },
        "nist": 4.9147636608248515,
        "bleu": 49.27092,
        "meteor": 0.40892837460469483,
        "bleurt": 0.21421,
        "nubia": {
            "semantic_relation": 4.35957,
            "contradiction": 3.29061,
            "irrelevancy": 52.84321,
            "logical_agreement": 43.86618,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.54052,
            "nubia_score": 0.75903
        },
        "bertscore": {
            "precision": 0.91659,
            "recall": 0.92908,
            "f1": 0.92272
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.1699250014423126,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.99428,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.5,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.9310344827586207,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.720049960644813,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": -0.029019418890029347,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9615384615384616,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.623516641218013,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": -0.032143884086602556,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.375,
            "3": 0.95
        },
        "rouge1": {
            "precision": 0.89583,
            "recall": 0.8401,
            "fmeasure": 0.86601
        },
        "rouge2": {
            "precision": 0.77222,
            "recall": 0.72369,
            "fmeasure": 0.74609
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.80769,
            "fmeasure": 0.81944
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.80769,
            "fmeasure": 0.81944
        },
        "nist": 4.793191126641509,
        "bleu": 72.40819,
        "meteor": 0.5101324891560334,
        "bleurt": 0.51999,
        "nubia": {
            "semantic_relation": 4.78754,
            "contradiction": 0.48293,
            "irrelevancy": 18.15488,
            "logical_agreement": 81.36219,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.97047,
            "nubia_score": 0.86434
        },
        "bertscore": {
            "precision": 0.96122,
            "recall": 0.96499,
            "f1": 0.96028
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "t5-small/totto_test",
        "N": 29,
        "total_length": 442,
        "mean_pred_length": 15.241379310344827,
        "std_pred_length": 3.390200608587712,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.3076923076923077,
        "vocab_size-1": 136,
        "unique-1": 104,
        "entropy-1": 5.621759089755826,
        "distinct-2": 0.5084745762711864,
        "vocab_size-2": 210,
        "unique-2": 180,
        "entropy-2": 6.657027305683425,
        "cond_entropy-2": 0.9863071035840557,
        "distinct-3": 0.5885416666666666,
        "vocab_size-3": 226,
        "unique-3": 201,
        "entropy-3": 6.941520151013404,
        "cond_entropy-3": 0.43281615081521635,
        "total_length-nopunct": 383,
        "mean_pred_length-nopunct": 13.206896551724139,
        "std_pred_length-nopunct": 2.708598191262825,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.3394255874673629,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 103,
        "entropy-1-nopunct": 5.572690233358234,
        "distinct-2-nopunct": 0.4858757062146893,
        "vocab_size-2-nopunct": 172,
        "unique-2-nopunct": 146,
        "entropy-2-nopunct": 6.340751702078592,
        "cond_entropy-2-nopunct": 0.9957534006939796,
        "distinct-3-nopunct": 0.5723076923076923,
        "vocab_size-3-nopunct": 186,
        "unique-3-nopunct": 163,
        "entropy-3-nopunct": 6.656999786277745,
        "cond_entropy-3-nopunct": 0.5029519660210829,
        "msttr-100": 0.455,
        "msttr-100_nopunct": 0.47,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.40350877192982454,
            "3": 0.772189349112426
        },
        "rouge1": {
            "precision": 0.83021,
            "recall": 0.78397,
            "fmeasure": 0.7936
        },
        "rouge2": {
            "precision": 0.65659,
            "recall": 0.61438,
            "fmeasure": 0.62502
        },
        "rougeL": {
            "precision": 0.77326,
            "recall": 0.72779,
            "fmeasure": 0.73851
        },
        "rougeLsum": {
            "precision": 0.77326,
            "recall": 0.72779,
            "fmeasure": 0.73851
        },
        "nist": 6.071607427279702,
        "bleu": 57.2564,
        "meteor": 0.37220572140903513,
        "bleurt": 0.43765,
        "nubia": {
            "semantic_relation": 4.19506,
            "contradiction": 13.39351,
            "irrelevancy": 12.30921,
            "logical_agreement": 74.29727,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.44599,
            "nubia_score": 0.72621
        },
        "bertscore": {
            "precision": 0.94588,
            "recall": 0.93483,
            "f1": 0.93805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "nist": 2.9898332363522426,
        "bleu": 61.0195,
        "meteor": 0.5064321156600579,
        "bleurt": 0.83294,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        },
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rouge2": {
            "precision": 0.92593,
            "recall": 0.75926,
            "fmeasure": 0.83069
        },
        "rougeL": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rougeLsum": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "nist": 2.8936441277848375,
        "bleu": 100.0,
        "meteor": 0.9652173913043478,
        "bleurt": 0.55466,
        "nubia": {
            "semantic_relation": 4.57319,
            "contradiction": 0.20028,
            "irrelevancy": 0.43256,
            "logical_agreement": 99.36716,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.18715,
            "nubia_score": 0.88792
        },
        "bertscore": {
            "precision": 0.98107,
            "recall": 0.98047,
            "f1": 0.98047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 7.0,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.73452166477975,
        "distinct-2": 0.96875,
        "vocab_size-2": 31,
        "unique-2": 30,
        "entropy-2": 4.9375,
        "cond_entropy-2": 0.16253715874966068,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.026442737724814782,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8387096774193549,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.631615665225586,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.17964675370621433,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.029019418890029344,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8076923076923077
        },
        "rouge1": {
            "precision": 0.74495,
            "recall": 0.74001,
            "fmeasure": 0.74242
        },
        "rouge2": {
            "precision": 0.4881,
            "recall": 0.48449,
            "fmeasure": 0.48625
        },
        "rougeL": {
            "precision": 0.64394,
            "recall": 0.63472,
            "fmeasure": 0.63923
        },
        "rougeLsum": {
            "precision": 0.64394,
            "recall": 0.63472,
            "fmeasure": 0.63923
        },
        "nist": 3.9828038355536215,
        "bleu": 37.08416,
        "meteor": 0.3852890526605456,
        "bleurt": 0.21076,
        "nubia": {
            "semantic_relation": 4.32429,
            "contradiction": 36.18774,
            "irrelevancy": 6.07758,
            "logical_agreement": 57.73468,
            "grammar_ref": 4.36539,
            "grammar_hyp": 4.91779,
            "nubia_score": 0.63146
        },
        "bertscore": {
            "precision": 0.90532,
            "recall": 0.89998,
            "f1": 0.90106
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 33,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 24,
        "unique-1": 16,
        "entropy-1": 4.476064195050471,
        "distinct-2": 0.8,
        "vocab_size-2": 24,
        "unique-2": 18,
        "entropy-2": 4.506890595608519,
        "cond_entropy-2": -0.07083685708326805,
        "distinct-3": 0.8148148148148148,
        "vocab_size-3": 22,
        "unique-3": 17,
        "entropy-3": 4.384517131793101,
        "cond_entropy-3": -0.07792901937097599,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.440223928941853,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.310443057719026,
        "cond_entropy-2-nopunct": -0.07792901937097599,
        "distinct-3-nopunct": 0.7916666666666666,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.16829583405449,
        "cond_entropy-3-nopunct": -0.08659166810897906,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.85185,
            "recall": 0.83333,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7451
        },
        "rougeL": {
            "precision": 0.81481,
            "recall": 0.8,
            "fmeasure": 0.80702
        },
        "rougeLsum": {
            "precision": 0.81481,
            "recall": 0.8,
            "fmeasure": 0.80702
        },
        "nist": 4.088015729955181,
        "bleu": 70.40724,
        "meteor": 0.4935212995985068,
        "bleurt": 0.6945,
        "nubia": {
            "semantic_relation": 4.61906,
            "contradiction": 0.45756,
            "irrelevancy": 7.24989,
            "logical_agreement": 92.29256,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.86083,
            "nubia_score": 0.85237
        },
        "bertscore": {
            "precision": 0.97106,
            "recall": 0.95591,
            "f1": 0.96329
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518528,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.80952,
            "recall": 0.80952,
            "fmeasure": 0.80952
        },
        "rougeLsum": {
            "precision": 0.80952,
            "recall": 0.80952,
            "fmeasure": 0.80952
        },
        "nist": 4.3644688753708625,
        "bleu": 57.34952,
        "meteor": 0.4880727997863187,
        "bleurt": 0.66005,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.53626,
            "irrelevancy": 3.49148,
            "logical_agreement": 95.97226,
            "grammar_ref": 4.18993,
            "grammar_hyp": 3.95279,
            "nubia_score": 0.99042
        },
        "bertscore": {
            "precision": 0.96953,
            "recall": 0.98034,
            "f1": 0.97491
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 42,
        "mean_pred_length": 21.0,
        "std_pred_length": 2.0,
        "median_pred_length": 21.0,
        "min_pred_length": 19,
        "max_pred_length": 23,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 4.94577248225106,
        "distinct-2": 0.975,
        "vocab_size-2": 39,
        "unique-2": 38,
        "entropy-2": 5.271928094887364,
        "cond_entropy-2": 0.34848285966268877,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.02136900249640834,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.760067015271103,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.028639311838573,
        "cond_entropy-2-nopunct": 0.29268158987165854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.0249628412503394,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0,
            "3": 0.5128205128205128
        },
        "rouge1": {
            "precision": 0.7303,
            "recall": 0.5014,
            "fmeasure": 0.59158
        },
        "rouge2": {
            "precision": 0.38492,
            "recall": 0.25444,
            "fmeasure": 0.30463
        },
        "rougeL": {
            "precision": 0.53838,
            "recall": 0.37857,
            "fmeasure": 0.44307
        },
        "rougeLsum": {
            "precision": 0.53838,
            "recall": 0.37857,
            "fmeasure": 0.44307
        },
        "nist": 3.3029861422746896,
        "bleu": 30.80752,
        "meteor": 0.2486109298637468,
        "bleurt": -0.42121,
        "nubia": {
            "semantic_relation": 3.21806,
            "contradiction": 46.05737,
            "irrelevancy": 12.70479,
            "logical_agreement": 41.23783,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.78345,
            "nubia_score": 0.43208
        },
        "bertscore": {
            "precision": 0.87122,
            "recall": 0.80393,
            "f1": 0.83623
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.084962500721156,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 18,
        "unique-2": 14,
        "entropy-2": 4.095795255000932,
        "cond_entropy-2": -0.034621791174768185,
        "distinct-3": 0.85,
        "vocab_size-3": 17,
        "unique-3": 14,
        "entropy-3": 4.021928094887363,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.004886164091841,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.9219280948873623,
        "cond_entropy-2-nopunct": -0.08750352374993502,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.8365916681089787,
        "cond_entropy-3-nopunct": -0.09644753788949419,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.6530437207411035,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.9828,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34259,
            "irrelevancy": 0.55688,
            "logical_agreement": 99.10053,
            "grammar_ref": 6.12532,
            "grammar_hyp": 6.14583,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.9057645846554525,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.19723710464117222,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.702819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.22388309575274976,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5333333333333333
        },
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.52941,
            "fmeasure": 0.54545
        },
        "rouge2": {
            "precision": 0.06667,
            "recall": 0.0625,
            "fmeasure": 0.06452
        },
        "rougeL": {
            "precision": 0.3125,
            "recall": 0.29412,
            "fmeasure": 0.30303
        },
        "rougeLsum": {
            "precision": 0.3125,
            "recall": 0.29412,
            "fmeasure": 0.30303
        },
        "nist": 1.877064753958503,
        "bleu": 6.25612,
        "meteor": 0.2384456546724936,
        "bleurt": 0.05832,
        "nubia": {
            "semantic_relation": 4.01385,
            "contradiction": 2.5559,
            "irrelevancy": 51.1627,
            "logical_agreement": 46.28141,
            "grammar_ref": 3.58521,
            "grammar_hyp": 3.37341,
            "nubia_score": 0.75818
        },
        "bertscore": {
            "precision": 0.89746,
            "recall": 0.87259,
            "f1": 0.88485
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.71667,
            "fmeasure": 0.72652
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.56085,
            "fmeasure": 0.56993
        },
        "rougeL": {
            "precision": 0.74074,
            "recall": 0.71667,
            "fmeasure": 0.72652
        },
        "rougeLsum": {
            "precision": 0.74074,
            "recall": 0.71667,
            "fmeasure": 0.72652
        },
        "nist": 3.0881882155168627,
        "bleu": 48.32698,
        "meteor": 0.36613955838904366,
        "bleurt": 0.46086,
        "nubia": {
            "semantic_relation": 3.73311,
            "contradiction": 0.5736,
            "irrelevancy": 10.55297,
            "logical_agreement": 88.87342,
            "grammar_ref": 5.68329,
            "grammar_hyp": 5.03674,
            "nubia_score": 0.63358
        },
        "bertscore": {
            "precision": 0.95104,
            "recall": 0.92369,
            "f1": 0.93424
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.6416041678685933,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.4769363694743175,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.93333,
            "fmeasure": 0.90323
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.71429,
            "fmeasure": 0.68966
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.53333,
            "fmeasure": 0.51613
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.53333,
            "fmeasure": 0.51613
        },
        "nist": 3.6643779994262076,
        "bleu": 55.64293,
        "meteor": 0.49102193871620886,
        "bleurt": 0.50338,
        "nubia": {
            "semantic_relation": 4.9347,
            "contradiction": 0.41479,
            "irrelevancy": 2.55872,
            "logical_agreement": 97.02649,
            "grammar_ref": 4.08392,
            "grammar_hyp": 3.79392,
            "nubia_score": 0.98378
        },
        "bertscore": {
            "precision": 0.95759,
            "recall": 0.96381,
            "f1": 0.96069
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 18,
        "distinct-1": 0.74,
        "vocab_size-1": 37,
        "unique-1": 31,
        "entropy-1": 4.988758439731456,
        "distinct-2": 0.9787234042553191,
        "vocab_size-2": 46,
        "unique-2": 45,
        "entropy-2": 5.512035660188278,
        "cond_entropy-2": 0.46392415126461484,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.04970268758579487,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.813953488372093,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.9611484756323305,
        "distinct-2-nopunct": 0.975,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.271928094887364,
        "cond_entropy-2-nopunct": 0.345663340185264,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.058420675204358556,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.7333333333333333,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.59273,
            "recall": 0.7636,
            "fmeasure": 0.64673
        },
        "rouge2": {
            "precision": 0.31368,
            "recall": 0.42809,
            "fmeasure": 0.34999
        },
        "rougeL": {
            "precision": 0.50368,
            "recall": 0.67782,
            "fmeasure": 0.55759
        },
        "rougeLsum": {
            "precision": 0.50368,
            "recall": 0.67782,
            "fmeasure": 0.55759
        },
        "nist": 3.583668442115503,
        "bleu": 30.52941,
        "meteor": 0.37858648135515593,
        "bleurt": 0.06131,
        "nubia": {
            "semantic_relation": 3.59661,
            "contradiction": 0.94182,
            "irrelevancy": 75.2852,
            "logical_agreement": 23.77298,
            "grammar_ref": 4.63208,
            "grammar_hyp": 3.86267,
            "nubia_score": 0.58163
        },
        "bertscore": {
            "precision": 0.83981,
            "recall": 0.90932,
            "f1": 0.86526
        }
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "t5-small/totto_test",
        "N": 300,
        "total_length": 4769,
        "mean_pred_length": 15.896666666666667,
        "std_pred_length": 4.2762119789468915,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.37009855315579787,
        "vocab_size-1": 1765,
        "unique-1": 1415,
        "entropy-1": 8.477229633553804,
        "distinct-2": 0.7256656970239427,
        "vocab_size-2": 3243,
        "unique-2": 2898,
        "entropy-2": 11.109693528898916,
        "cond_entropy-2": 2.4105904698499137,
        "distinct-3": 0.882225953466059,
        "vocab_size-3": 3678,
        "unique-3": 3484,
        "entropy-3": 11.664928816085219,
        "cond_entropy-3": 0.5736521427625686,
        "total_length-nopunct": 4194,
        "mean_pred_length-nopunct": 13.98,
        "std_pred_length-nopunct": 4.2047116429072755,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.41797806390081066,
        "vocab_size-1-nopunct": 1753,
        "unique-1-nopunct": 1411,
        "entropy-1-nopunct": 8.779592945218107,
        "distinct-2-nopunct": 0.743708269131998,
        "vocab_size-2-nopunct": 2896,
        "unique-2-nopunct": 2634,
        "entropy-2-nopunct": 10.940345314393975,
        "cond_entropy-2-nopunct": 2.3131346696852244,
        "distinct-3-nopunct": 0.8970506399554814,
        "vocab_size-3-nopunct": 3224,
        "unique-3-nopunct": 3077,
        "entropy-3-nopunct": 11.491893499135262,
        "cond_entropy-3-nopunct": 0.613498944424079,
        "msttr-100": 0.69915,
        "msttr-100_nopunct": 0.7478,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1952326901248581,
            "2": 0.3135593220338983,
            "3": 0.7434994582881906
        },
        "rouge1": {
            "precision": 0.80685,
            "recall": 0.72186,
            "fmeasure": 0.75047
        },
        "rouge2": {
            "precision": 0.55124,
            "recall": 0.49414,
            "fmeasure": 0.51293
        },
        "rougeL": {
            "precision": 0.68753,
            "recall": 0.61749,
            "fmeasure": 0.6406
        },
        "rougeLsum": {
            "precision": 0.68753,
            "recall": 0.61749,
            "fmeasure": 0.6406
        },
        "nist": 7.881754442358407,
        "bleu": 42.27092,
        "meteor": 0.3798452805547871,
        "bleurt": 0.27176,
        "nubia": {
            "semantic_relation": 4.32834,
            "contradiction": 8.03303,
            "irrelevancy": 22.24489,
            "logical_agreement": 69.72208,
            "grammar_ref": 4.91577,
            "grammar_hyp": 5.06976,
            "nubia_score": 0.7302
        },
        "bertscore": {
            "precision": 0.93674,
            "recall": 0.92374,
            "f1": 0.92893
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.95238,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.88889,
            "fmeasure": 0.85714
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.95238,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.95238,
            "fmeasure": 0.91667
        },
        "nist": 4.385134945805687,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.82005,
        "nubia": {
            "semantic_relation": 4.96652,
            "contradiction": 0.2392,
            "irrelevancy": 0.64355,
            "logical_agreement": 99.11725,
            "grammar_ref": 4.12966,
            "grammar_hyp": 3.59795,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.68182,
            "recall": 0.9375,
            "fmeasure": 0.78947
        },
        "rouge2": {
            "precision": 0.45,
            "recall": 0.64286,
            "fmeasure": 0.52941
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.6875,
            "fmeasure": 0.57895
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.6875,
            "fmeasure": 0.57895
        },
        "nist": 2.6516861753241585,
        "bleu": 24.80842,
        "meteor": 0.45379364554466606,
        "bleurt": -1.12843,
        "nubia": {
            "semantic_relation": 3.66308,
            "contradiction": 1.96103,
            "irrelevancy": 97.15066,
            "logical_agreement": 0.8883,
            "grammar_ref": 5.1072,
            "grammar_hyp": 6.11196,
            "nubia_score": 0.35991
        },
        "bertscore": {
            "precision": 0.86351,
            "recall": 0.95376,
            "f1": 0.90639
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6111111111111112
        },
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.55005,
            "fmeasure": 0.67619
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.34259,
            "fmeasure": 0.42674
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.2838,
            "fmeasure": 0.34921
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.2838,
            "fmeasure": 0.34921
        },
        "nist": 1.059659072518892,
        "bleu": 24.71209,
        "meteor": 0.2916064447813157,
        "bleurt": -0.30494,
        "nubia": {
            "semantic_relation": 3.07163,
            "contradiction": 4.65484,
            "irrelevancy": 1.02246,
            "logical_agreement": 94.3227,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.11003,
            "nubia_score": 0.51126
        },
        "bertscore": {
            "precision": 0.89684,
            "recall": 0.79045,
            "f1": 0.84029
        }
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "t5-small/totto_test",
        "N": 128,
        "total_length": 1992,
        "mean_pred_length": 15.5625,
        "std_pred_length": 4.808439845729589,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.3870481927710843,
        "vocab_size-1": 771,
        "unique-1": 605,
        "entropy-1": 7.894666808947096,
        "distinct-2": 0.7526824034334764,
        "vocab_size-2": 1403,
        "unique-2": 1245,
        "entropy-2": 10.053646259669573,
        "cond_entropy-2": 1.9457769139410237,
        "distinct-3": 0.913594470046083,
        "vocab_size-3": 1586,
        "unique-3": 1507,
        "entropy-3": 10.531344376305416,
        "cond_entropy-3": 0.4097873398780986,
        "total_length-nopunct": 1727,
        "mean_pred_length-nopunct": 13.4921875,
        "std_pred_length-nopunct": 4.331923817987079,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4406485234510712,
        "vocab_size-1-nopunct": 761,
        "unique-1-nopunct": 602,
        "entropy-1-nopunct": 8.189789953018957,
        "distinct-2-nopunct": 0.7904940587867417,
        "vocab_size-2-nopunct": 1264,
        "unique-2-nopunct": 1147,
        "entropy-2-nopunct": 9.957154204479984,
        "cond_entropy-2-nopunct": 1.768096708676367,
        "distinct-3-nopunct": 0.9326988443235894,
        "vocab_size-3-nopunct": 1372,
        "unique-3-nopunct": 1318,
        "entropy-3-nopunct": 10.352705547944392,
        "cond_entropy-3-nopunct": 0.36806615228271755,
        "msttr-100": 0.67526,
        "msttr-100_nopunct": 0.74118,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17575757575757575,
            "2": 0.29900332225913623,
            "3": 0.7461069735951252
        },
        "rouge1": {
            "precision": 0.77001,
            "recall": 0.73639,
            "fmeasure": 0.74201
        },
        "rouge2": {
            "precision": 0.52909,
            "recall": 0.51426,
            "fmeasure": 0.51353
        },
        "rougeL": {
            "precision": 0.66225,
            "recall": 0.6373,
            "fmeasure": 0.63967
        },
        "rougeLsum": {
            "precision": 0.66225,
            "recall": 0.6373,
            "fmeasure": 0.63967
        },
        "nist": 7.011328024726404,
        "bleu": 41.04322,
        "meteor": 0.3770335766483005,
        "bleurt": 0.26391,
        "nubia": {
            "semantic_relation": 4.29636,
            "contradiction": 6.68807,
            "irrelevancy": 29.54929,
            "logical_agreement": 63.76265,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.27377,
            "nubia_score": 0.76919
        },
        "bertscore": {
            "precision": 0.92458,
            "recall": 0.92173,
            "f1": 0.92148
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.6153846153846154,
        "vocab_size-1": 16,
        "unique-1": 7,
        "entropy-1": 3.9021748142117274,
        "distinct-2": 0.7916666666666666,
        "vocab_size-2": 19,
        "unique-2": 14,
        "entropy-2": 4.16829583405449,
        "cond_entropy-2": 0.2493097618368753,
        "distinct-3": 0.9545454545454546,
        "vocab_size-3": 21,
        "unique-3": 20,
        "entropy-3": 4.368522527728205,
        "cond_entropy-3": 0.2381054815525045,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.6069367321753214,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.821928094887362,
        "cond_entropy-2-nopunct": 0.30024085135823847,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.058813890331201,
        "cond_entropy-3-nopunct": 0.29244135099939467,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.64322,
            "fmeasure": 0.66837
        },
        "rouge2": {
            "precision": 0.51515,
            "recall": 0.46389,
            "fmeasure": 0.4839
        },
        "rougeL": {
            "precision": 0.69167,
            "recall": 0.63342,
            "fmeasure": 0.65602
        },
        "rougeLsum": {
            "precision": 0.69167,
            "recall": 0.63342,
            "fmeasure": 0.65602
        },
        "nist": 3.338367605182094,
        "bleu": 41.34814,
        "meteor": 0.4787982469365562,
        "bleurt": 0.49591,
        "nubia": {
            "semantic_relation": 4.96907,
            "contradiction": 0.15616,
            "irrelevancy": 0.77858,
            "logical_agreement": 99.06527,
            "grammar_ref": 4.6711,
            "grammar_hyp": 5.14455,
            "nubia_score": 0.94544
        },
        "bertscore": {
            "precision": 0.96085,
            "recall": 0.9565,
            "f1": 0.95865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.5,
        "median_pred_length": 17.5,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 30,
        "unique-1": 27,
        "entropy-1": 4.800432302535623,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.26389216315066666,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9032258064516129,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.7362967135428935,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.1367118399877132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.85833,
            "recall": 0.80833,
            "fmeasure": 0.83056
        },
        "rouge2": {
            "precision": 0.69298,
            "recall": 0.66374,
            "fmeasure": 0.67666
        },
        "rougeL": {
            "precision": 0.71667,
            "recall": 0.70797,
            "fmeasure": 0.71202
        },
        "rougeLsum": {
            "precision": 0.71667,
            "recall": 0.70797,
            "fmeasure": 0.71202
        },
        "nist": 4.467610274587632,
        "bleu": 52.77328,
        "meteor": 0.3923817050537005,
        "bleurt": 0.20612,
        "nubia": {
            "semantic_relation": 3.92868,
            "contradiction": 24.73069,
            "irrelevancy": 25.05867,
            "logical_agreement": 50.21063,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.79351,
            "nubia_score": 0.63422
        },
        "bertscore": {
            "precision": 0.93288,
            "recall": 0.93474,
            "f1": 0.9308
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 45,
        "mean_pred_length": 11.25,
        "std_pred_length": 1.7853571071357126,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 35,
        "unique-1": 29,
        "entropy-1": 4.958519762996341,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 40,
        "unique-2": 39,
        "entropy-2": 5.308771516813203,
        "cond_entropy-2": 0.2071623229225551,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.09404458493507989,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 9.75,
        "std_pred_length-nopunct": 1.299038105676658,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8205128205128205,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.875145808605837,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.072140159802107,
        "cond_entropy-2-nopunct": 0.2153093695112893,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.11057057752583334,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.36363636363636365,
            "3": 0.32432432432432434
        },
        "rouge1": {
            "precision": 0.64131,
            "recall": 0.41076,
            "fmeasure": 0.49525
        },
        "rouge2": {
            "precision": 0.39903,
            "recall": 0.26845,
            "fmeasure": 0.31985
        },
        "rougeL": {
            "precision": 0.56029,
            "recall": 0.37448,
            "fmeasure": 0.44558
        },
        "rougeLsum": {
            "precision": 0.56029,
            "recall": 0.37448,
            "fmeasure": 0.44558
        },
        "nist": 1.2541774857207746,
        "bleu": 15.89865,
        "meteor": 0.20053074551742942,
        "bleurt": -0.18612,
        "nubia": {
            "semantic_relation": 2.8625,
            "contradiction": 32.51489,
            "irrelevancy": 18.81051,
            "logical_agreement": 48.6746,
            "grammar_ref": 4.12218,
            "grammar_hyp": 4.60218,
            "nubia_score": 0.34462
        },
        "bertscore": {
            "precision": 0.8884,
            "recall": 0.83021,
            "f1": 0.85773
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 5.715476066494082,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.7592592592592593,
        "vocab_size-1": 41,
        "unique-1": 30,
        "entropy-1": 5.245447224305562,
        "distinct-2": 0.9215686274509803,
        "vocab_size-2": 47,
        "unique-2": 43,
        "entropy-2": 5.515562596873461,
        "cond_entropy-2": 0.26086676146149623,
        "distinct-3": 0.9375,
        "vocab_size-3": 45,
        "unique-3": 42,
        "entropy-3": 5.4599625007211605,
        "cond_entropy-3": -0.04579617458367275,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 5.557777333511022,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.78,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.173660689688187,
        "distinct-2-nopunct": 0.9148936170212766,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.384376085720193,
        "cond_entropy-2-nopunct": 0.2407278747609327,
        "distinct-3-nopunct": 0.9318181818181818,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.32306798227366,
        "cond_entropy-3-nopunct": -0.04970268758579487,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.07692307692307693,
            "3": 0.7804878048780488
        },
        "rouge1": {
            "precision": 0.74508,
            "recall": 0.63858,
            "fmeasure": 0.68546
        },
        "rouge2": {
            "precision": 0.54563,
            "recall": 0.45581,
            "fmeasure": 0.49501
        },
        "rougeL": {
            "precision": 0.63291,
            "recall": 0.53617,
            "fmeasure": 0.57893
        },
        "rougeLsum": {
            "precision": 0.63291,
            "recall": 0.53617,
            "fmeasure": 0.57893
        },
        "nist": 3.563722509049363,
        "bleu": 39.42935,
        "meteor": 0.3534885360533028,
        "bleurt": -0.09694,
        "nubia": {
            "semantic_relation": 3.67705,
            "contradiction": 21.88867,
            "irrelevancy": 41.26579,
            "logical_agreement": 36.84554,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.33011,
            "nubia_score": 0.55121
        },
        "bertscore": {
            "precision": 0.929,
            "recall": 0.89099,
            "f1": 0.90772
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.9375,
            "fmeasure": 0.88235
        },
        "rouge2": {
            "precision": 0.70588,
            "recall": 0.8,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.9375,
            "fmeasure": 0.88235
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.9375,
            "fmeasure": 0.88235
        },
        "nist": 3.2284321902659023,
        "bleu": 61.53267,
        "meteor": 0.5472479000182758,
        "bleurt": 0.74241,
        "nubia": {
            "semantic_relation": 4.27284,
            "contradiction": 0.9766,
            "irrelevancy": 36.5591,
            "logical_agreement": 62.4643,
            "grammar_ref": 4.67419,
            "grammar_hyp": 4.06039,
            "nubia_score": 0.7863
        },
        "bertscore": {
            "precision": 0.93546,
            "recall": 0.98183,
            "f1": 0.9559
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 67,
        "mean_pred_length": 16.75,
        "std_pred_length": 5.539629951540085,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.7164179104477612,
        "vocab_size-1": 48,
        "unique-1": 34,
        "entropy-1": 5.427956541171748,
        "distinct-2": 0.9682539682539683,
        "vocab_size-2": 61,
        "unique-2": 59,
        "entropy-2": 5.913787860007857,
        "cond_entropy-2": 0.4350002568516682,
        "distinct-3": 0.9830508474576272,
        "vocab_size-3": 58,
        "unique-3": 57,
        "entropy-3": 5.848744744277091,
        "cond_entropy-3": -0.07768772159570238,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.301162633521313,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.406890595608518,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.735926350629038,
        "cond_entropy-2-nopunct": 0.329035755020514,
        "distinct-3-nopunct": 0.9807692307692307,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.661978179679557,
        "cond_entropy-3-nopunct": -0.08768443468574297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3125,
            "2": 0.5,
            "3": 0.7894736842105263
        },
        "rouge1": {
            "precision": 0.68194,
            "recall": 0.74173,
            "fmeasure": 0.69673
        },
        "rouge2": {
            "precision": 0.40189,
            "recall": 0.45631,
            "fmeasure": 0.42333
        },
        "rougeL": {
            "precision": 0.52664,
            "recall": 0.60016,
            "fmeasure": 0.54969
        },
        "rougeLsum": {
            "precision": 0.52664,
            "recall": 0.60016,
            "fmeasure": 0.54969
        },
        "nist": 4.347109700013254,
        "bleu": 43.74599,
        "meteor": 0.3861645364385488,
        "bleurt": 0.42312,
        "nubia": {
            "semantic_relation": 4.52961,
            "contradiction": 5.51539,
            "irrelevancy": 20.14533,
            "logical_agreement": 74.33929,
            "grammar_ref": 4.54108,
            "grammar_hyp": 4.3681,
            "nubia_score": 0.76787
        },
        "bertscore": {
            "precision": 0.91629,
            "recall": 0.915,
            "f1": 0.91419
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.75,
        "vocab_size-1": 12,
        "unique-1": 9,
        "entropy-1": 3.452819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.4238830957527497,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3248629576173574,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.41269152701913925,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.44048,
            "fmeasure": 0.36594
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.14444,
            "fmeasure": 0.12063
        },
        "rougeL": {
            "precision": 0.20833,
            "recall": 0.2619,
            "fmeasure": 0.22464
        },
        "rougeLsum": {
            "precision": 0.20833,
            "recall": 0.2619,
            "fmeasure": 0.22464
        },
        "nist": 1.2671131093267114,
        "bleu": 5.65304,
        "meteor": 0.25050574940801684,
        "bleurt": -0.56473,
        "nubia": {
            "semantic_relation": 2.12963,
            "contradiction": 12.89938,
            "irrelevancy": 86.79291,
            "logical_agreement": 0.30771,
            "grammar_ref": 4.92688,
            "grammar_hyp": 3.67608,
            "nubia_score": 0.22515
        },
        "bertscore": {
            "precision": 0.71869,
            "recall": 0.77264,
            "f1": 0.71206
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.96,
        "vocab_size-1": 24,
        "unique-1": 23,
        "entropy-1": 4.5638561897747225,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.12029423371771175,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.459431618637295,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.8461538461538461,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.90833,
            "recall": 0.85732,
            "fmeasure": 0.88064
        },
        "rouge2": {
            "precision": 0.82828,
            "recall": 0.77962,
            "fmeasure": 0.80169
        },
        "rougeL": {
            "precision": 0.90833,
            "recall": 0.85732,
            "fmeasure": 0.88064
        },
        "rougeLsum": {
            "precision": 0.90833,
            "recall": 0.85732,
            "fmeasure": 0.88064
        },
        "nist": 4.435844357088381,
        "bleu": 83.11387,
        "meteor": 0.5352259138095478,
        "bleurt": 0.60994,
        "nubia": {
            "semantic_relation": 4.29202,
            "contradiction": 50.36189,
            "irrelevancy": 18.80162,
            "logical_agreement": 30.83649,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.78758,
            "nubia_score": 0.67227
        },
        "bertscore": {
            "precision": 0.99059,
            "recall": 0.99059,
            "f1": 0.99059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 17,
        "mean_pred_length": 8.5,
        "std_pred_length": 0.5,
        "median_pred_length": 8.5,
        "min_pred_length": 8,
        "max_pred_length": 9,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.18057224564182078,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.2064508774674265,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 6.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 6.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.24100809950379498,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.2895066171949847,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.9,
            "fmeasure": 0.90789
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.78148,
            "fmeasure": 0.7902
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.9,
            "fmeasure": 0.90789
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.9,
            "fmeasure": 0.90789
        },
        "nist": 4.036906337455992,
        "bleu": 86.68732,
        "meteor": 0.5608458267826603,
        "bleurt": 0.61725,
        "nubia": {
            "semantic_relation": 4.5629,
            "contradiction": 7.82066,
            "irrelevancy": 3.06896,
            "logical_agreement": 89.11038,
            "grammar_ref": 5.35128,
            "grammar_hyp": 5.64914,
            "nubia_score": 0.83485
        },
        "bertscore": {
            "precision": 0.99654,
            "recall": 0.99654,
            "f1": 0.99654
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.02999212699343527,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.62222,
            "recall": 0.46072,
            "fmeasure": 0.52838
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.31313,
            "fmeasure": 0.36111
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.42673,
            "fmeasure": 0.48113
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.42673,
            "fmeasure": 0.48113
        },
        "nist": 2.5732707745152648,
        "bleu": 25.39662,
        "meteor": 0.27575352636084893,
        "bleurt": 0.13051,
        "nubia": {
            "semantic_relation": 3.61844,
            "contradiction": 94.58765,
            "irrelevancy": 3.85374,
            "logical_agreement": 1.55861,
            "grammar_ref": 4.95426,
            "grammar_hyp": 4.14135,
            "nubia_score": 0.55472
        },
        "bertscore": {
            "precision": 0.91088,
            "recall": 0.85826,
            "f1": 0.88379
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.45455,
            "fmeasure": 0.45584
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.82143,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.82143,
            "fmeasure": 0.78333
        },
        "nist": 3.354740210181113,
        "bleu": 44.63236,
        "meteor": 0.47372197886511624,
        "bleurt": 0.41423,
        "nubia": {
            "semantic_relation": 4.70479,
            "contradiction": 0.80982,
            "irrelevancy": 0.60484,
            "logical_agreement": 98.58534,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.25415,
            "nubia_score": 0.82896
        },
        "bertscore": {
            "precision": 0.95836,
            "recall": 0.9707,
            "f1": 0.96449
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.40179,
            "fmeasure": 0.34314
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "nist": 1.1227137604546689,
        "bleu": 14.99111,
        "meteor": 0.2731132551770082,
        "bleurt": 0.34221,
        "nubia": {
            "semantic_relation": 3.78915,
            "contradiction": 2.88897,
            "irrelevancy": 55.44136,
            "logical_agreement": 41.66967,
            "grammar_ref": 4.73918,
            "grammar_hyp": 3.671,
            "nubia_score": 0.66998
        },
        "bertscore": {
            "precision": 0.82556,
            "recall": 0.86442,
            "f1": 0.84455
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 5.0,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.6578947368421053,
        "vocab_size-1": 25,
        "unique-1": 16,
        "entropy-1": 4.484255144794799,
        "distinct-2": 0.7777777777777778,
        "vocab_size-2": 28,
        "unique-2": 23,
        "entropy-2": 4.66257326515091,
        "cond_entropy-2": 0.19296658528104532,
        "distinct-3": 0.8235294117647058,
        "vocab_size-3": 28,
        "unique-3": 24,
        "entropy-3": 4.690116517593664,
        "cond_entropy-3": 0.05738747222459957,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.225619876671973,
        "distinct-2-nopunct": 0.7419354838709677,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.365013648887185,
        "cond_entropy-2-nopunct": 0.10883202978462551,
        "distinct-3-nopunct": 0.7931034482758621,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.392126684633539,
        "cond_entropy-3-nopunct": 0.013092443411121583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.2,
            "3": 0.3939393939393939
        },
        "rouge1": {
            "precision": 0.52707,
            "recall": 0.3294,
            "fmeasure": 0.39865
        },
        "rouge2": {
            "precision": 0.29657,
            "recall": 0.19966,
            "fmeasure": 0.23551
        },
        "rougeL": {
            "precision": 0.36966,
            "recall": 0.24474,
            "fmeasure": 0.29022
        },
        "rougeLsum": {
            "precision": 0.36966,
            "recall": 0.24474,
            "fmeasure": 0.29022
        },
        "nist": 1.2838215871918877,
        "bleu": 14.40743,
        "meteor": 0.18881331551155225,
        "bleurt": -0.59663,
        "nubia": {
            "semantic_relation": 3.03779,
            "contradiction": 40.71893,
            "irrelevancy": 6.28245,
            "logical_agreement": 52.99862,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.27092,
            "nubia_score": 0.43872
        },
        "bertscore": {
            "precision": 0.85237,
            "recall": 0.75144,
            "f1": 0.79548
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518528,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941851,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.18617861216337128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.64444,
            "recall": 0.67521,
            "fmeasure": 0.65873
        },
        "rouge2": {
            "precision": 0.45238,
            "recall": 0.32576,
            "fmeasure": 0.37322
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.33445,
            "fmeasure": 0.37594
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.33445,
            "fmeasure": 0.37594
        },
        "nist": 3.400559710253804,
        "bleu": 43.33208,
        "meteor": 0.29068389757220225,
        "bleurt": -0.50538,
        "nubia": {
            "semantic_relation": 3.02529,
            "contradiction": 4.03312,
            "irrelevancy": 67.1208,
            "logical_agreement": 28.84607,
            "grammar_ref": 4.61776,
            "grammar_hyp": 4.14461,
            "nubia_score": 0.41531
        },
        "bertscore": {
            "precision": 0.87686,
            "recall": 0.84336,
            "f1": 0.85978
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 21,
        "unique-1": 16,
        "entropy-1": 4.282484261342601,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.31916418769779475,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.136842188131012,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.31787309528720764,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5333333333333333,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.71678,
            "recall": 0.58193,
            "fmeasure": 0.6296
        },
        "rouge2": {
            "precision": 0.51667,
            "recall": 0.38927,
            "fmeasure": 0.434
        },
        "rougeL": {
            "precision": 0.71678,
            "recall": 0.58193,
            "fmeasure": 0.6296
        },
        "rougeLsum": {
            "precision": 0.71678,
            "recall": 0.58193,
            "fmeasure": 0.6296
        },
        "nist": 2.459631545589977,
        "bleu": 32.07543,
        "meteor": 0.33268630481547057,
        "bleurt": 0.19229,
        "nubia": {
            "semantic_relation": 3.59749,
            "contradiction": 50.17319,
            "irrelevancy": 0.68123,
            "logical_agreement": 49.14558,
            "grammar_ref": 4.13759,
            "grammar_hyp": 4.39941,
            "nubia_score": 0.51778
        },
        "bertscore": {
            "precision": 0.94522,
            "recall": 0.90426,
            "f1": 0.91993
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 6.5,
        "median_pred_length": 16.5,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.5757575757575758,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 3.6610158025583557,
        "distinct-2": 0.8064516129032258,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.320277457019029,
        "cond_entropy-2": 0.6517376748993893,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": 0.5814220797201183,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.68,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.6038561897747234,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.8797057662822882,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.37153,
            "recall": 0.41923,
            "fmeasure": 0.39192
        },
        "rouge2": {
            "precision": 0.15833,
            "recall": 0.18415,
            "fmeasure": 0.1692
        },
        "rougeL": {
            "precision": 0.31597,
            "recall": 0.35309,
            "fmeasure": 0.33173
        },
        "rougeLsum": {
            "precision": 0.31597,
            "recall": 0.35309,
            "fmeasure": 0.33173
        },
        "nist": 1.2072734733836943,
        "bleu": 4.53064,
        "meteor": 0.18153552688254695,
        "bleurt": -0.0591,
        "nubia": {
            "semantic_relation": 2.93384,
            "contradiction": 5.96858,
            "irrelevancy": 32.22259,
            "logical_agreement": 61.80883,
            "grammar_ref": 4.46901,
            "grammar_hyp": 3.36152,
            "nubia_score": 0.53141
        },
        "bertscore": {
            "precision": 0.84617,
            "recall": 0.82727,
            "f1": 0.83587
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.84175,
            "fmeasure": 0.74242
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.39167,
            "fmeasure": 0.34242
        },
        "rougeL": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "nist": 2.3648189689631285,
        "bleu": 10.88697,
        "meteor": 0.37885739133291024,
        "bleurt": -0.38963,
        "nubia": {
            "semantic_relation": 4.05623,
            "contradiction": 3.3209,
            "irrelevancy": 92.48141,
            "logical_agreement": 4.19768,
            "grammar_ref": 6.0554,
            "grammar_hyp": 5.98883,
            "nubia_score": 0.50759
        },
        "bertscore": {
            "precision": 0.87464,
            "recall": 0.91728,
            "f1": 0.89545
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "t5-small/totto_test",
        "N": 8,
        "total_length": 113,
        "mean_pred_length": 14.125,
        "std_pred_length": 2.315032397181517,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.5309734513274337,
        "vocab_size-1": 60,
        "unique-1": 39,
        "entropy-1": 5.452415765344151,
        "distinct-2": 0.8380952380952381,
        "vocab_size-2": 88,
        "unique-2": 72,
        "entropy-2": 6.383246589074083,
        "cond_entropy-2": 0.8199464720713506,
        "distinct-3": 0.9072164948453608,
        "vocab_size-3": 88,
        "unique-3": 79,
        "entropy-3": 6.4143458318778634,
        "cond_entropy-3": 0.04808884516186569,
        "total_length-nopunct": 100,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 2.449489742783178,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.58,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.454380181828818,
        "distinct-2-nopunct": 0.8260869565217391,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 6.167530570163941,
        "cond_entropy-2-nopunct": 0.7540299596547277,
        "distinct-3-nopunct": 0.8928571428571429,
        "vocab_size-3-nopunct": 75,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.178031708493046,
        "cond_entropy-3-nopunct": -0.003210158252496839,
        "msttr-100": 0.54,
        "msttr-100_nopunct": 0.58,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.43243243243243246,
            "3": 0.6438356164383562
        },
        "rouge1": {
            "precision": 0.72032,
            "recall": 0.59342,
            "fmeasure": 0.63254
        },
        "rouge2": {
            "precision": 0.42885,
            "recall": 0.36036,
            "fmeasure": 0.37843
        },
        "rougeL": {
            "precision": 0.57295,
            "recall": 0.46274,
            "fmeasure": 0.49392
        },
        "rougeLsum": {
            "precision": 0.57295,
            "recall": 0.46274,
            "fmeasure": 0.49392
        },
        "nist": 3.6213030156564656,
        "bleu": 27.45938,
        "meteor": 0.30307487870434846,
        "bleurt": -0.28079,
        "nubia": {
            "semantic_relation": 3.52326,
            "contradiction": 7.93828,
            "irrelevancy": 47.77929,
            "logical_agreement": 44.28243,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.70726,
            "nubia_score": 0.45337
        },
        "bertscore": {
            "precision": 0.86483,
            "recall": 0.85555,
            "f1": 0.85899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.6337,
            "fmeasure": 0.64957
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.40598,
            "fmeasure": 0.41111
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.60073,
            "fmeasure": 0.60779
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.60073,
            "fmeasure": 0.60779
        },
        "nist": 2.8297229108804602,
        "bleu": 35.41699,
        "meteor": 0.3289547170311567,
        "bleurt": 0.03867,
        "nubia": {
            "semantic_relation": 3.99333,
            "contradiction": 12.34712,
            "irrelevancy": 11.69265,
            "logical_agreement": 75.96023,
            "grammar_ref": 5.35534,
            "grammar_hyp": 5.90439,
            "nubia_score": 0.51861
        },
        "bertscore": {
            "precision": 0.93406,
            "recall": 0.92031,
            "f1": 0.92713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.034621791174768206,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 0.9473684210526315
        },
        "rouge1": {
            "precision": 0.84487,
            "recall": 0.90367,
            "fmeasure": 0.87187
        },
        "rouge2": {
            "precision": 0.63426,
            "recall": 0.67857,
            "fmeasure": 0.65441
        },
        "rougeL": {
            "precision": 0.76795,
            "recall": 0.82675,
            "fmeasure": 0.79495
        },
        "rougeLsum": {
            "precision": 0.76795,
            "recall": 0.82675,
            "fmeasure": 0.79495
        },
        "nist": 4.563910807120466,
        "bleu": 59.04306,
        "meteor": 0.5121077179275422,
        "bleurt": 0.56896,
        "nubia": {
            "semantic_relation": 4.63901,
            "contradiction": 0.44517,
            "irrelevancy": 33.41267,
            "logical_agreement": 66.14216,
            "grammar_ref": 5.10267,
            "grammar_hyp": 4.97163,
            "nubia_score": 0.87566
        },
        "bertscore": {
            "precision": 0.95009,
            "recall": 0.95984,
            "f1": 0.95492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 0.5,
        "median_pred_length": 10.5,
        "min_pred_length": 10,
        "max_pred_length": 11,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.14438990933517493,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.1604646721932461,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.16992500144231232,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.0,
            "3": 0.5769230769230769
        },
        "rouge1": {
            "precision": 0.85185,
            "recall": 0.56429,
            "fmeasure": 0.65404
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.45192,
            "fmeasure": 0.52402
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.55833,
            "fmeasure": 0.64504
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.55833,
            "fmeasure": 0.64504
        },
        "nist": 0.9076585857431366,
        "bleu": 37.37554,
        "meteor": 0.30627680463168216,
        "bleurt": 0.188,
        "nubia": {
            "semantic_relation": 3.91675,
            "contradiction": 0.98041,
            "irrelevancy": 1.1505,
            "logical_agreement": 97.86909,
            "grammar_ref": 4.54027,
            "grammar_hyp": 5.15266,
            "nubia_score": 0.53184
        },
        "bertscore": {
            "precision": 0.96771,
            "recall": 0.9031,
            "f1": 0.93305
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.75566,
            "fmeasure": 0.82483
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.59375,
            "fmeasure": 0.65056
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.51357,
            "fmeasure": 0.56138
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.51357,
            "fmeasure": 0.56138
        },
        "nist": 3.771611544534406,
        "bleu": 61.68673,
        "meteor": 0.5291073080791932,
        "bleurt": 0.44261,
        "nubia": {
            "semantic_relation": 4.29686,
            "contradiction": 0.2819,
            "irrelevancy": 0.49154,
            "logical_agreement": 99.22655,
            "grammar_ref": 4.29821,
            "grammar_hyp": 5.14999,
            "nubia_score": 0.70671
        },
        "bertscore": {
            "precision": 0.96802,
            "recall": 0.95686,
            "f1": 0.96241
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.11475004073479991,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.423065265165703,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.94038,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 3.5,
        "median_pred_length": 19.5,
        "min_pred_length": 16,
        "max_pred_length": 23,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 33,
        "unique-1": 27,
        "entropy-1": 4.97770991116994,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.24837547109102545,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.08017034868398329,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.843568731230678,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.21814140544378968,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.62829,
            "recall": 0.70294,
            "fmeasure": 0.66248
        },
        "rouge2": {
            "precision": 0.33889,
            "recall": 0.42081,
            "fmeasure": 0.37472
        },
        "rougeL": {
            "precision": 0.42434,
            "recall": 0.52289,
            "fmeasure": 0.4675
        },
        "rougeLsum": {
            "precision": 0.42434,
            "recall": 0.52289,
            "fmeasure": 0.4675
        },
        "nist": 3.11978697203492,
        "bleu": 13.29578,
        "meteor": 0.37907794659353167,
        "bleurt": 0.06499,
        "nubia": {
            "semantic_relation": 4.63768,
            "contradiction": 0.4523,
            "irrelevancy": 44.41663,
            "logical_agreement": 55.13106,
            "grammar_ref": 4.12394,
            "grammar_hyp": 4.23438,
            "nubia_score": 0.82549
        },
        "bertscore": {
            "precision": 0.88991,
            "recall": 0.90951,
            "f1": 0.89713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.5798,
            "fmeasure": 0.66111
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.19394,
            "fmeasure": 0.21832
        },
        "rougeL": {
            "precision": 0.62963,
            "recall": 0.41818,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.62963,
            "recall": 0.41818,
            "fmeasure": 0.5
        },
        "nist": 2.2226894223173894,
        "bleu": 19.43406,
        "meteor": 0.32476215539223885,
        "bleurt": 0.61907,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32473,
            "irrelevancy": 0.48011,
            "logical_agreement": 99.19516,
            "grammar_ref": 4.53537,
            "grammar_hyp": 4.43842,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.95513,
            "recall": 0.92542,
            "f1": 0.94004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 4.714045207910316,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.6956521739130435,
        "vocab_size-1": 32,
        "unique-1": 23,
        "entropy-1": 4.822156249394176,
        "distinct-2": 0.8372093023255814,
        "vocab_size-2": 36,
        "unique-2": 29,
        "entropy-2": 5.10068335935326,
        "cond_entropy-2": 0.24409117087227686,
        "distinct-3": 0.9,
        "vocab_size-3": 36,
        "unique-3": 32,
        "entropy-3": 5.1219280948873624,
        "cond_entropy-3": -0.004336659814735824,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.242640687119285,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6904761904761905,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.671730220243276,
        "distinct-2-nopunct": 0.8461538461538461,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.977709911169939,
        "cond_entropy-2-nopunct": 0.2694873603339817,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.003258334775643,
        "cond_entropy-3-nopunct": -0.004366106308824786,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7741935483870968
        },
        "rouge1": {
            "precision": 0.77393,
            "recall": 0.84933,
            "fmeasure": 0.79513
        },
        "rouge2": {
            "precision": 0.61667,
            "recall": 0.60707,
            "fmeasure": 0.60751
        },
        "rougeL": {
            "precision": 0.71044,
            "recall": 0.73485,
            "fmeasure": 0.71348
        },
        "rougeLsum": {
            "precision": 0.71044,
            "recall": 0.73485,
            "fmeasure": 0.71348
        },
        "nist": 3.3512909485068962,
        "bleu": 47.57265,
        "meteor": 0.43840786662073583,
        "bleurt": 0.33634,
        "nubia": {
            "semantic_relation": 4.27208,
            "contradiction": 0.68212,
            "irrelevancy": 31.57006,
            "logical_agreement": 67.74781,
            "grammar_ref": 3.77014,
            "grammar_hyp": 4.32006,
            "nubia_score": 0.65725
        },
        "bertscore": {
            "precision": 0.90187,
            "recall": 0.92152,
            "f1": 0.9111
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 5.0,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 24,
        "unique-1": 20,
        "entropy-1": 4.456564762130954,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 27,
        "unique-2": 26,
        "entropy-2": 4.735926350629034,
        "cond_entropy-2": 0.31152771946076185,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.02999212699343525,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.18083298720544,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.36409674109368645,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.03462179117476821,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.6363636363636364,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.7674,
            "fmeasure": 0.73637
        },
        "rouge2": {
            "precision": 0.59069,
            "recall": 0.58187,
            "fmeasure": 0.56572
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.71429,
            "fmeasure": 0.69642
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.71429,
            "fmeasure": 0.69642
        },
        "nist": 4.1430354917474554,
        "bleu": 51.29497,
        "meteor": 0.41112854511839897,
        "bleurt": 0.03669,
        "nubia": {
            "semantic_relation": 3.96213,
            "contradiction": 13.56338,
            "irrelevancy": 52.6133,
            "logical_agreement": 33.82332,
            "grammar_ref": 4.3679,
            "grammar_hyp": 4.23206,
            "nubia_score": 0.66285
        },
        "bertscore": {
            "precision": 0.94288,
            "recall": 0.94344,
            "f1": 0.94026
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.25,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "nist": 2.113355981086958,
        "bleu": 13.35434,
        "meteor": 0.26557509739080626,
        "bleurt": 0.14202,
        "nubia": {
            "semantic_relation": 4.01781,
            "contradiction": 0.34119,
            "irrelevancy": 96.06696,
            "logical_agreement": 3.59185,
            "grammar_ref": 3.99081,
            "grammar_hyp": 3.52262,
            "nubia_score": 0.85465
        },
        "bertscore": {
            "precision": 0.91789,
            "recall": 0.90364,
            "f1": 0.91071
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.9111111111111111,
        "vocab_size-1": 41,
        "unique-1": 39,
        "entropy-1": 5.280524762900186,
        "distinct-2": 1.0,
        "vocab_size-2": 42,
        "unique-2": 42,
        "entropy-2": 5.3923174227787625,
        "cond_entropy-2": 0.013675933643453876,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.10691520391651191,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9512195121951219,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.241579138711655,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.015504127303488054,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.11864449649861893,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9130434782608695
        },
        "rouge1": {
            "precision": 0.84444,
            "recall": 0.83303,
            "fmeasure": 0.83452
        },
        "rouge2": {
            "precision": 0.69048,
            "recall": 0.68129,
            "fmeasure": 0.68252
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.69189,
            "fmeasure": 0.69286
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.69189,
            "fmeasure": 0.69286
        },
        "nist": 4.510678373837726,
        "bleu": 56.77945,
        "meteor": 0.47972574609058444,
        "bleurt": 0.36952,
        "nubia": {
            "semantic_relation": 4.25272,
            "contradiction": 3.94152,
            "irrelevancy": 62.40302,
            "logical_agreement": 33.65547,
            "grammar_ref": 4.8308,
            "grammar_hyp": 5.1198,
            "nubia_score": 0.67789
        },
        "bertscore": {
            "precision": 0.94458,
            "recall": 0.95941,
            "f1": 0.95114
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.55556,
            "fmeasure": 0.625
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42857
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.55556,
            "fmeasure": 0.625
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.55556,
            "fmeasure": 0.625
        },
        "nist": 1.0913650456308712,
        "bleu": 32.8183,
        "meteor": 0.2538881940949526,
        "bleurt": 0.3617,
        "nubia": {
            "semantic_relation": 2.76346,
            "contradiction": 63.75985,
            "irrelevancy": 10.38447,
            "logical_agreement": 25.85568,
            "grammar_ref": 5.49813,
            "grammar_hyp": 5.04312,
            "nubia_score": 0.2528
        },
        "bertscore": {
            "precision": 0.9298,
            "recall": 0.89599,
            "f1": 0.91258
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228516,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.051189449246730745,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.63636,
            "fmeasure": 0.56
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.3,
            "fmeasure": 0.26087
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.45455,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.45455,
            "fmeasure": 0.4
        },
        "nist": 2.007248855089098,
        "bleu": 17.53482,
        "meteor": 0.2699364990882831,
        "bleurt": -0.62316,
        "nubia": {
            "semantic_relation": 3.60833,
            "contradiction": 0.8589,
            "irrelevancy": 86.72272,
            "logical_agreement": 12.41838,
            "grammar_ref": 4.59968,
            "grammar_hyp": 4.43987,
            "nubia_score": 0.53307
        },
        "bertscore": {
            "precision": 0.79994,
            "recall": 0.82256,
            "f1": 0.8039
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.9310344827586207,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.720049960644813,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.04505465518404476,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9583333333333334,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.501629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.034621791174768206,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.875,
            "3": 0.3
        },
        "rouge1": {
            "precision": 0.51389,
            "recall": 0.62281,
            "fmeasure": 0.55177
        },
        "rouge2": {
            "precision": 0.2987,
            "recall": 0.4212,
            "fmeasure": 0.34526
        },
        "rougeL": {
            "precision": 0.41389,
            "recall": 0.53893,
            "fmeasure": 0.46069
        },
        "rougeLsum": {
            "precision": 0.41389,
            "recall": 0.53893,
            "fmeasure": 0.46069
        },
        "nist": 2.201959633238657,
        "bleu": 15.09894,
        "meteor": 0.2834676813506578,
        "bleurt": 0.02703,
        "nubia": {
            "semantic_relation": 3.63987,
            "contradiction": 0.37555,
            "irrelevancy": 96.85989,
            "logical_agreement": 2.76457,
            "grammar_ref": 4.27476,
            "grammar_hyp": 4.46319,
            "nubia_score": 0.54483
        },
        "bertscore": {
            "precision": 0.85703,
            "recall": 0.89366,
            "f1": 0.87492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.6901165175936654,
        "distinct-2": 0.9375,
        "vocab_size-2": 15,
        "unique-2": 14,
        "entropy-2": 3.875,
        "cond_entropy-2": 0.20971762763487733,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": 0.040223928941851894,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.4565647621309536,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.24009914803219046,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "rouge2": {
            "precision": 0.82353,
            "recall": 0.91071,
            "fmeasure": 0.86413
        },
        "rougeL": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "rougeLsum": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "nist": 4.026196058544812,
        "bleu": 69.0167,
        "meteor": 0.6108178404694528,
        "bleurt": 0.81116,
        "nubia": {
            "semantic_relation": 4.96299,
            "contradiction": 0.14795,
            "irrelevancy": 3.49378,
            "logical_agreement": 96.35828,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.07239,
            "nubia_score": 0.98909
        },
        "bertscore": {
            "precision": 0.98423,
            "recall": 0.99714,
            "f1": 0.99064
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 7.408703590297623,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.7959183673469388,
        "vocab_size-1": 39,
        "unique-1": 32,
        "entropy-1": 5.150324384887384,
        "distinct-2": 0.9782608695652174,
        "vocab_size-2": 45,
        "unique-2": 44,
        "entropy-2": 5.480083695187445,
        "cond_entropy-2": 0.25667819889832616,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.05078557344793836,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 5.312459150169743,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.021928094887363,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.155399311574899,
        "cond_entropy-2-nopunct": 0.15779554101185753,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.06316699496684555,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.5,
            "3": 0.7083333333333334
        },
        "rouge1": {
            "precision": 0.66905,
            "recall": 0.63531,
            "fmeasure": 0.61912
        },
        "rouge2": {
            "precision": 0.43177,
            "recall": 0.42672,
            "fmeasure": 0.39654
        },
        "rougeL": {
            "precision": 0.53205,
            "recall": 0.53486,
            "fmeasure": 0.50346
        },
        "rougeLsum": {
            "precision": 0.53205,
            "recall": 0.53486,
            "fmeasure": 0.50346
        },
        "nist": 4.386376417465167,
        "bleu": 42.00986,
        "meteor": 0.3683102898223664,
        "bleurt": 0.02175,
        "nubia": {
            "semantic_relation": 3.84111,
            "contradiction": 43.96089,
            "irrelevancy": 22.95522,
            "logical_agreement": 33.08389,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.14265,
            "nubia_score": 0.68064
        },
        "bertscore": {
            "precision": 0.88163,
            "recall": 0.90036,
            "f1": 0.89007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.5909090909090909,
        "vocab_size-1": 13,
        "unique-1": 6,
        "entropy-1": 3.5503407095463877,
        "distinct-2": 0.7,
        "vocab_size-2": 14,
        "unique-2": 8,
        "entropy-2": 3.721928094887362,
        "cond_entropy-2": 0.16249647625006503,
        "distinct-3": 0.7222222222222222,
        "vocab_size-3": 13,
        "unique-3": 8,
        "entropy-3": 3.6143694458867563,
        "cond_entropy-3": -0.04089198233393864,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.6,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.4219280948873623,
        "distinct-2-nopunct": 0.6666666666666666,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 3.503258334775645,
        "cond_entropy-2-nopunct": 0.125774684332728,
        "distinct-3-nopunct": 0.6875,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 3.375,
        "cond_entropy-3-nopunct": -0.10742500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.69192,
            "recall": 0.74038,
            "fmeasure": 0.70266
        },
        "rouge2": {
            "precision": 0.39167,
            "recall": 0.42727,
            "fmeasure": 0.39916
        },
        "rougeL": {
            "precision": 0.57071,
            "recall": 0.63568,
            "fmeasure": 0.59034
        },
        "rougeLsum": {
            "precision": 0.57071,
            "recall": 0.63568,
            "fmeasure": 0.59034
        },
        "nist": 3.4845704627410363,
        "bleu": 30.44009,
        "meteor": 0.4115994198377596,
        "bleurt": 0.08872,
        "nubia": {
            "semantic_relation": 4.16955,
            "contradiction": 0.32436,
            "irrelevancy": 66.17723,
            "logical_agreement": 33.49841,
            "grammar_ref": 5.09196,
            "grammar_hyp": 4.90865,
            "nubia_score": 0.7554
        },
        "bertscore": {
            "precision": 0.91898,
            "recall": 0.93917,
            "f1": 0.9283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 61,
        "mean_pred_length": 15.25,
        "std_pred_length": 7.224091638399945,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.6557377049180327,
        "vocab_size-1": 40,
        "unique-1": 27,
        "entropy-1": 5.121162288624291,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 51,
        "unique-2": 45,
        "entropy-2": 5.622363698375264,
        "cond_entropy-2": 0.45705075525256933,
        "distinct-3": 0.9245283018867925,
        "vocab_size-3": 49,
        "unique-3": 45,
        "entropy-3": 5.576977058336782,
        "cond_entropy-3": -0.029497861488334932,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 3.3541019662496847,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7608695652173914,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 5.012479890745556,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.297079327540667,
        "cond_entropy-2-nopunct": 0.30946439539619824,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.03912675144043812,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.55,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.70699,
            "recall": 0.57682,
            "fmeasure": 0.62836
        },
        "rouge2": {
            "precision": 0.45107,
            "recall": 0.35494,
            "fmeasure": 0.39089
        },
        "rougeL": {
            "precision": 0.64821,
            "recall": 0.53291,
            "fmeasure": 0.57836
        },
        "rougeLsum": {
            "precision": 0.64821,
            "recall": 0.53291,
            "fmeasure": 0.57836
        },
        "nist": 3.414093583216457,
        "bleu": 26.63058,
        "meteor": 0.3171804351157907,
        "bleurt": -0.13376,
        "nubia": {
            "semantic_relation": 3.33177,
            "contradiction": 29.11524,
            "irrelevancy": 40.30326,
            "logical_agreement": 30.5815,
            "grammar_ref": 4.43752,
            "grammar_hyp": 4.6626,
            "nubia_score": 0.48783
        },
        "bertscore": {
            "precision": 0.90034,
            "recall": 0.88783,
            "f1": 0.89383
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.5,
        "median_pred_length": 16.5,
        "min_pred_length": 13,
        "max_pred_length": 20,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 24,
        "unique-1": 18,
        "entropy-1": 4.389556529224006,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 30,
        "unique-2": 29,
        "entropy-2": 4.889680181354619,
        "cond_entropy-2": 0.4778551095586416,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.253235913127291,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.4579514862504003,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.06845366545497372,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.1111111111111111,
            "3": 0.6470588235294118
        },
        "rouge1": {
            "precision": 0.60826,
            "recall": 0.60651,
            "fmeasure": 0.59252
        },
        "rouge2": {
            "precision": 0.40441,
            "recall": 0.35752,
            "fmeasure": 0.36767
        },
        "rougeL": {
            "precision": 0.58974,
            "recall": 0.59485,
            "fmeasure": 0.57546
        },
        "rougeLsum": {
            "precision": 0.58974,
            "recall": 0.59485,
            "fmeasure": 0.57546
        },
        "nist": 2.6695316010340004,
        "bleu": 26.75423,
        "meteor": 0.3463649768706071,
        "bleurt": -0.03636,
        "nubia": {
            "semantic_relation": 3.52427,
            "contradiction": 49.6754,
            "irrelevancy": 46.30763,
            "logical_agreement": 4.01697,
            "grammar_ref": 4.30067,
            "grammar_hyp": 3.80938,
            "nubia_score": 0.50529
        },
        "bertscore": {
            "precision": 0.89026,
            "recall": 0.90052,
            "f1": 0.89202
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.26984,
            "fmeasure": 0.32727
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "nist": 1.8094988549899862,
        "bleu": 24.59813,
        "meteor": 0.3010544205973617,
        "bleurt": 0.30353,
        "nubia": {
            "semantic_relation": 4.18837,
            "contradiction": 0.38664,
            "irrelevancy": 0.58445,
            "logical_agreement": 99.02891,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.86986,
            "nubia_score": 0.75842
        },
        "bertscore": {
            "precision": 0.97738,
            "recall": 0.94093,
            "f1": 0.95881
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.386842188131012,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.14533369456035536,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.5416666666666666
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.53846,
            "fmeasure": 0.6087
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.32,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.55,
            "recall": 0.42308,
            "fmeasure": 0.47826
        },
        "rougeLsum": {
            "precision": 0.55,
            "recall": 0.42308,
            "fmeasure": 0.47826
        },
        "nist": 2.622386020005393,
        "bleu": 28.68411,
        "meteor": 0.27983129532884876,
        "bleurt": -0.31835,
        "nubia": {
            "semantic_relation": 3.05157,
            "contradiction": 0.08098,
            "irrelevancy": 99.71447,
            "logical_agreement": 0.20455,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.71623,
            "nubia_score": 0.33505
        },
        "bertscore": {
            "precision": 0.88926,
            "recall": 0.88296,
            "f1": 0.88559
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 54,
        "mean_pred_length": 10.8,
        "std_pred_length": 2.7856776554368237,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 14,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 36,
        "unique-1": 25,
        "entropy-1": 4.947301567451677,
        "distinct-2": 0.8163265306122449,
        "vocab_size-2": 40,
        "unique-2": 33,
        "entropy-2": 5.206546578809087,
        "cond_entropy-2": 0.10472030113541325,
        "distinct-3": 0.8636363636363636,
        "vocab_size-3": 38,
        "unique-3": 32,
        "entropy-3": 5.186704345910022,
        "cond_entropy-3": 0.026539956340270728,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 9.2,
        "std_pred_length-nopunct": 2.315167380558045,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.717391304347826,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.871388043013533,
        "distinct-2-nopunct": 0.8048780487804879,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.91852761437418,
        "cond_entropy-2-nopunct": 0.12667297539033892,
        "distinct-3-nopunct": 0.8611111111111112,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.892147223664533,
        "cond_entropy-3-nopunct": 0.034595219046450965,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.6304347826086957
        },
        "rouge1": {
            "precision": 0.81667,
            "recall": 0.64872,
            "fmeasure": 0.70095
        },
        "rouge2": {
            "precision": 0.68071,
            "recall": 0.57155,
            "fmeasure": 0.6054
        },
        "rougeL": {
            "precision": 0.74444,
            "recall": 0.61819,
            "fmeasure": 0.65905
        },
        "rougeLsum": {
            "precision": 0.74444,
            "recall": 0.61819,
            "fmeasure": 0.65905
        },
        "nist": 3.7924531583708454,
        "bleu": 56.201,
        "meteor": 0.37393514953886436,
        "bleurt": 0.08903,
        "nubia": {
            "semantic_relation": 3.40264,
            "contradiction": 33.88628,
            "irrelevancy": 7.5,
            "logical_agreement": 58.61372,
            "grammar_ref": 5.02868,
            "grammar_hyp": 5.60829,
            "nubia_score": 0.51797
        },
        "bertscore": {
            "precision": 0.91002,
            "recall": 0.88672,
            "f1": 0.89711
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.03214388408660256,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.8333333333333334,
            "3": 0.3
        },
        "rouge1": {
            "precision": 0.59524,
            "recall": 0.5085,
            "fmeasure": 0.54802
        },
        "rouge2": {
            "precision": 0.28205,
            "recall": 0.25758,
            "fmeasure": 0.26724
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.37582,
            "fmeasure": 0.36394
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.37582,
            "fmeasure": 0.36394
        },
        "nist": 2.7076825409364282,
        "bleu": 23.39763,
        "meteor": 0.25830891036338943,
        "bleurt": -0.01946,
        "nubia": {
            "semantic_relation": 2.84301,
            "contradiction": 66.42877,
            "irrelevancy": 16.92233,
            "logical_agreement": 16.6489,
            "grammar_ref": 4.69116,
            "grammar_hyp": 4.3329,
            "nubia_score": 0.33952
        },
        "bertscore": {
            "precision": 0.87135,
            "recall": 0.85689,
            "f1": 0.86154
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.7,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.6219280948873616,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 17,
        "unique-2": 15,
        "entropy-2": 4.037401197654111,
        "cond_entropy-2": 0.4523152080299073,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 17,
        "unique-3": 16,
        "entropy-3": 4.058813890331201,
        "cond_entropy-3": 0.03310859910983795,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.6219280948873616,
        "distinct-2-nopunct": 0.8947368421052632,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.037401197654111,
        "cond_entropy-2-nopunct": 0.4523152080299073,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.058813890331201,
        "cond_entropy-3-nopunct": 0.03310859910983795,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.3913,
            "recall": 0.55147,
            "fmeasure": 0.45769
        },
        "rouge2": {
            "precision": 0.22727,
            "recall": 0.32639,
            "fmeasure": 0.2679
        },
        "rougeL": {
            "precision": 0.27536,
            "recall": 0.37868,
            "fmeasure": 0.3188
        },
        "rougeLsum": {
            "precision": 0.27536,
            "recall": 0.37868,
            "fmeasure": 0.3188
        },
        "nist": 1.9295984432869109,
        "bleu": 14.02578,
        "meteor": 0.26599378607022023,
        "bleurt": -0.5417,
        "nubia": {
            "semantic_relation": 2.42688,
            "contradiction": 32.85372,
            "irrelevancy": 53.59122,
            "logical_agreement": 13.55506,
            "grammar_ref": 3.5564,
            "grammar_hyp": 3.44957,
            "nubia_score": 0.33181
        },
        "bertscore": {
            "precision": 0.80882,
            "recall": 0.86144,
            "f1": 0.8343
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.4677201004745006,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2588453731729854,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.2963,
            "fmeasure": 0.42105
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.15385,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.25926,
            "fmeasure": 0.36842
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.25926,
            "fmeasure": 0.36842
        },
        "nist": 0.18367135546584373,
        "bleu": 8.32964,
        "meteor": 0.16869620918032968,
        "bleurt": -0.94,
        "nubia": {
            "semantic_relation": 2.58024,
            "contradiction": 64.31027,
            "irrelevancy": 16.19127,
            "logical_agreement": 19.49846,
            "grammar_ref": 4.95946,
            "grammar_hyp": 6.74035,
            "nubia_score": 0.11155
        },
        "bertscore": {
            "precision": 0.88963,
            "recall": 0.7762,
            "f1": 0.82905
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 1.5,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 11,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.1604646721932461,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.18057224564182078,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.18057224564182078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.058823529411764705,
            "3": 0.39285714285714285
        },
        "rouge1": {
            "precision": 0.71861,
            "recall": 0.29371,
            "fmeasure": 0.4133
        },
        "rouge2": {
            "precision": 0.18333,
            "recall": 0.07441,
            "fmeasure": 0.10447
        },
        "rougeL": {
            "precision": 0.46537,
            "recall": 0.18521,
            "fmeasure": 0.26223
        },
        "rougeLsum": {
            "precision": 0.46537,
            "recall": 0.18521,
            "fmeasure": 0.26223
        },
        "nist": 0.04099492234381029,
        "bleu": 2.24251,
        "meteor": 0.16717734175018353,
        "bleurt": -0.27867,
        "nubia": {
            "semantic_relation": 3.39702,
            "contradiction": 1.82512,
            "irrelevancy": 60.66568,
            "logical_agreement": 37.5092,
            "grammar_ref": 3.63495,
            "grammar_hyp": 4.88765,
            "nubia_score": 0.29733
        },
        "bertscore": {
            "precision": 0.84153,
            "recall": 0.77805,
            "f1": 0.80835
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.0,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 12,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.040891982333938634,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.16992500144231232,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.14285714285714285,
            "3": 0.5789473684210527
        },
        "rouge1": {
            "precision": 0.68398,
            "recall": 0.53721,
            "fmeasure": 0.59305
        },
        "rouge2": {
            "precision": 0.32222,
            "recall": 0.2131,
            "fmeasure": 0.24762
        },
        "rougeL": {
            "precision": 0.46753,
            "recall": 0.37441,
            "fmeasure": 0.40909
        },
        "rougeLsum": {
            "precision": 0.46753,
            "recall": 0.37441,
            "fmeasure": 0.40909
        },
        "nist": 1.5938388424841086,
        "bleu": 7.69249,
        "meteor": 0.2540783925323745,
        "bleurt": 0.14104,
        "nubia": {
            "semantic_relation": 3.54468,
            "contradiction": 0.65457,
            "irrelevancy": 15.34932,
            "logical_agreement": 83.99611,
            "grammar_ref": 4.70186,
            "grammar_hyp": 4.8898,
            "nubia_score": 0.51638
        },
        "bertscore": {
            "precision": 0.90461,
            "recall": 0.88021,
            "f1": 0.89137
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.21785611591339743,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.2516291673878226,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.23810548155250455,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72381,
            "fmeasure": 0.83502
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.70714,
            "fmeasure": 0.82323
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.72381,
            "fmeasure": 0.83502
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.72381,
            "fmeasure": 0.83502
        },
        "nist": 1.7809771168744533,
        "bleu": 73.88283,
        "meteor": 0.4873681160489184,
        "bleurt": 0.27082,
        "nubia": {
            "semantic_relation": 4.16014,
            "contradiction": 0.51672,
            "irrelevancy": 0.58634,
            "logical_agreement": 98.89694,
            "grammar_ref": 2.70093,
            "grammar_hyp": 2.93404,
            "nubia_score": 0.87323
        },
        "bertscore": {
            "precision": 0.99409,
            "recall": 0.9026,
            "f1": 0.94614
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 1.5,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 16,
        "distinct-1": 0.896551724137931,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.651084443403434,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.045054655184044716,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.05628729973432273,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.125,
            "3": 0.8947368421052632
        },
        "rouge1": {
            "precision": 0.77857,
            "recall": 0.81412,
            "fmeasure": 0.78571
        },
        "rouge2": {
            "precision": 0.52991,
            "recall": 0.55433,
            "fmeasure": 0.53356
        },
        "rougeL": {
            "precision": 0.63571,
            "recall": 0.68858,
            "fmeasure": 0.65344
        },
        "rougeLsum": {
            "precision": 0.63571,
            "recall": 0.68858,
            "fmeasure": 0.65344
        },
        "nist": 3.4176076529567707,
        "bleu": 34.04823,
        "meteor": 0.4427332007260423,
        "bleurt": 0.51952,
        "nubia": {
            "semantic_relation": 4.23445,
            "contradiction": 0.49605,
            "irrelevancy": 0.71131,
            "logical_agreement": 98.79264,
            "grammar_ref": 4.25678,
            "grammar_hyp": 4.00599,
            "nubia_score": 0.79108
        },
        "bertscore": {
            "precision": 0.95369,
            "recall": 0.96518,
            "f1": 0.95935
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966063,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.3684210526315789
        },
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.38384,
            "fmeasure": 0.45614
        },
        "rouge2": {
            "precision": 0.35556,
            "recall": 0.23741,
            "fmeasure": 0.2846
        },
        "rougeL": {
            "precision": 0.52083,
            "recall": 0.35606,
            "fmeasure": 0.42281
        },
        "rougeLsum": {
            "precision": 0.52083,
            "recall": 0.35606,
            "fmeasure": 0.42281
        },
        "nist": 1.507891586371933,
        "bleu": 15.15638,
        "meteor": 0.22570927987553369,
        "bleurt": -0.66664,
        "nubia": {
            "semantic_relation": 2.92575,
            "contradiction": 1.94867,
            "irrelevancy": 68.85311,
            "logical_agreement": 29.19822,
            "grammar_ref": 4.34096,
            "grammar_hyp": 5.23372,
            "nubia_score": 0.255
        },
        "bertscore": {
            "precision": 0.88794,
            "recall": 0.8287,
            "f1": 0.8573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 13,
        "unique-2": 12,
        "entropy-2": 3.6644977792004623,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": 0.04693094992964167,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.546593564294939,
        "cond_entropy-2-nopunct": -0.029992126993435245,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.03214388408660255,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4
        },
        "rouge1": {
            "precision": 0.26667,
            "recall": 0.35354,
            "fmeasure": 0.30389
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.29091,
            "fmeasure": 0.24667
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.35354,
            "fmeasure": 0.30389
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.35354,
            "fmeasure": 0.30389
        },
        "nist": 1.4346373502531466,
        "bleu": 23.96183,
        "meteor": 0.17372723584153246,
        "bleurt": -0.78594,
        "nubia": {
            "semantic_relation": 2.62939,
            "contradiction": 2.60112,
            "irrelevancy": 95.93743,
            "logical_agreement": 1.46145,
            "grammar_ref": 5.20931,
            "grammar_hyp": 4.47347,
            "nubia_score": 0.31348
        },
        "bertscore": {
            "precision": 0.71787,
            "recall": 0.76256,
            "f1": 0.73857
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 3.5,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 15,
        "entropy-1": 4.243856189774723,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.14057533149967955,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.03600643804015718,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.095795255000933,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.221928094887362,
        "cond_entropy-2-nopunct": 0.112496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.09644753788949417,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.14285714285714285,
            "3": 0.6190476190476191
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.60694,
            "fmeasure": 0.65485
        },
        "rouge2": {
            "precision": 0.41126,
            "recall": 0.34278,
            "fmeasure": 0.37106
        },
        "rougeL": {
            "precision": 0.69444,
            "recall": 0.59028,
            "fmeasure": 0.63402
        },
        "rougeLsum": {
            "precision": 0.69444,
            "recall": 0.59028,
            "fmeasure": 0.63402
        },
        "nist": 3.471763255126709,
        "bleu": 30.0492,
        "meteor": 0.4121642502108931,
        "bleurt": 0.40122,
        "nubia": {
            "semantic_relation": 4.18102,
            "contradiction": 0.72916,
            "irrelevancy": 1.43591,
            "logical_agreement": 97.83492,
            "grammar_ref": 4.56769,
            "grammar_hyp": 4.66332,
            "nubia_score": 0.74797
        },
        "bertscore": {
            "precision": 0.95933,
            "recall": 0.93375,
            "f1": 0.94618
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.6901165175936654,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.2356574713398051,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6901165175936654,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.2356574713398051,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.6470588235294118
        },
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.61111,
            "fmeasure": 0.69841
        },
        "rouge2": {
            "precision": 0.41176,
            "recall": 0.32367,
            "fmeasure": 0.36228
        },
        "rougeL": {
            "precision": 0.64815,
            "recall": 0.5,
            "fmeasure": 0.56429
        },
        "rougeLsum": {
            "precision": 0.64815,
            "recall": 0.5,
            "fmeasure": 0.56429
        },
        "nist": 3.221023317616272,
        "bleu": 30.18079,
        "meteor": 0.2732543721139816,
        "bleurt": 0.04887,
        "nubia": {
            "semantic_relation": 3.90475,
            "contradiction": 1.07091,
            "irrelevancy": 3.10189,
            "logical_agreement": 95.8272,
            "grammar_ref": 3.8277,
            "grammar_hyp": 2.92994,
            "nubia_score": 0.82141
        },
        "bertscore": {
            "precision": 0.91042,
            "recall": 0.83887,
            "f1": 0.87318
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "t5-small/totto_test",
        "N": 112,
        "total_length": 1788,
        "mean_pred_length": 15.964285714285714,
        "std_pred_length": 4.393437824570566,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.4278523489932886,
        "vocab_size-1": 765,
        "unique-1": 636,
        "entropy-1": 7.915783300840974,
        "distinct-2": 0.7804295942720764,
        "vocab_size-2": 1308,
        "unique-2": 1208,
        "entropy-2": 9.901812985393828,
        "cond_entropy-2": 1.7799293091308481,
        "distinct-3": 0.8753196930946292,
        "vocab_size-3": 1369,
        "unique-3": 1313,
        "entropy-3": 10.170720620389929,
        "cond_entropy-3": 0.3031070280469687,
        "total_length-nopunct": 1563,
        "mean_pred_length-nopunct": 13.955357142857142,
        "std_pred_length-nopunct": 3.9807312520465894,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.48304542546385154,
        "vocab_size-1-nopunct": 755,
        "unique-1-nopunct": 632,
        "entropy-1-nopunct": 8.145363258139025,
        "distinct-2-nopunct": 0.78842177808408,
        "vocab_size-2-nopunct": 1144,
        "unique-2-nopunct": 1064,
        "entropy-2-nopunct": 9.70769024489139,
        "cond_entropy-2-nopunct": 1.6937637159559833,
        "distinct-3-nopunct": 0.8812546676624347,
        "vocab_size-3-nopunct": 1180,
        "unique-3-nopunct": 1132,
        "entropy-3-nopunct": 9.974422256426559,
        "cond_entropy-3-nopunct": 0.322221904832766,
        "msttr-100": 0.68471,
        "msttr-100_nopunct": 0.73533,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2789317507418398,
            "2": 0.41346153846153844,
            "3": 0.7751531058617673
        },
        "rouge1": {
            "precision": 0.74585,
            "recall": 0.7248,
            "fmeasure": 0.72039
        },
        "rouge2": {
            "precision": 0.50789,
            "recall": 0.4803,
            "fmeasure": 0.48537
        },
        "rougeL": {
            "precision": 0.62746,
            "recall": 0.60417,
            "fmeasure": 0.60391
        },
        "rougeLsum": {
            "precision": 0.62746,
            "recall": 0.60417,
            "fmeasure": 0.60391
        },
        "nist": 7.314826485480728,
        "bleu": 43.62927,
        "meteor": 0.3790966871601681,
        "bleurt": 0.20862,
        "nubia": {
            "semantic_relation": 4.08888,
            "contradiction": 8.24763,
            "irrelevancy": 29.62608,
            "logical_agreement": 62.12629,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.72358,
            "nubia_score": 0.69726
        },
        "bertscore": {
            "precision": 0.91897,
            "recall": 0.9168,
            "f1": 0.91653
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.16666666666666666,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.46154,
            "fmeasure": 0.5291
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.27778,
            "fmeasure": 0.32018
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.46154,
            "fmeasure": 0.5291
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.46154,
            "fmeasure": 0.5291
        },
        "nist": 1.4067726424040132,
        "bleu": 15.12264,
        "meteor": 0.27447880268119035,
        "bleurt": -0.19824,
        "nubia": {
            "semantic_relation": 3.78486,
            "contradiction": 7.83358,
            "irrelevancy": 89.53096,
            "logical_agreement": 2.63546,
            "grammar_ref": 5.35395,
            "grammar_hyp": 4.65533,
            "nubia_score": 0.56511
        },
        "bertscore": {
            "precision": 0.9286,
            "recall": 0.86136,
            "f1": 0.89371
        }
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "t5-small/totto_test",
        "N": 128,
        "total_length": 1938,
        "mean_pred_length": 15.140625,
        "std_pred_length": 4.661568899992255,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.42053663570691435,
        "vocab_size-1": 815,
        "unique-1": 645,
        "entropy-1": 8.102376685586808,
        "distinct-2": 0.8121546961325967,
        "vocab_size-2": 1470,
        "unique-2": 1338,
        "entropy-2": 10.225122051669244,
        "cond_entropy-2": 1.8937631403296,
        "distinct-3": 0.9500594530321046,
        "vocab_size-3": 1598,
        "unique-3": 1546,
        "entropy-3": 10.590437207884769,
        "cond_entropy-3": 0.331579365808818,
        "total_length-nopunct": 1686,
        "mean_pred_length-nopunct": 13.171875,
        "std_pred_length-nopunct": 4.185371427289937,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.4792408066429419,
        "vocab_size-1-nopunct": 808,
        "unique-1-nopunct": 643,
        "entropy-1-nopunct": 8.407743418582731,
        "distinct-2-nopunct": 0.8363286264441592,
        "vocab_size-2-nopunct": 1303,
        "unique-2-nopunct": 1211,
        "entropy-2-nopunct": 10.069348783768753,
        "cond_entropy-2-nopunct": 1.7159378793966864,
        "distinct-3-nopunct": 0.9671328671328672,
        "vocab_size-3-nopunct": 1383,
        "unique-3-nopunct": 1352,
        "entropy-3-nopunct": 10.404709340087031,
        "cond_entropy-3-nopunct": 0.33294219109479173,
        "msttr-100": 0.68263,
        "msttr-100_nopunct": 0.73187,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17994100294985252,
            "2": 0.2897959183673469,
            "3": 0.766531713900135
        },
        "rouge1": {
            "precision": 0.79118,
            "recall": 0.73764,
            "fmeasure": 0.75348
        },
        "rouge2": {
            "precision": 0.55573,
            "recall": 0.52236,
            "fmeasure": 0.53022
        },
        "rougeL": {
            "precision": 0.6907,
            "recall": 0.64825,
            "fmeasure": 0.65948
        },
        "rougeLsum": {
            "precision": 0.6907,
            "recall": 0.64825,
            "fmeasure": 0.65948
        },
        "nist": 7.484118425235342,
        "bleu": 45.28202,
        "meteor": 0.3900191730813261,
        "bleurt": 0.31439,
        "nubia": {
            "semantic_relation": 4.37352,
            "contradiction": 8.39275,
            "irrelevancy": 21.35293,
            "logical_agreement": 70.25433,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.65699,
            "nubia_score": 0.76874
        },
        "bertscore": {
            "precision": 0.93004,
            "recall": 0.92315,
            "f1": 0.92529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.375
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.32051,
            "fmeasure": 0.43651
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.10417,
            "fmeasure": 0.14583
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.28205,
            "fmeasure": 0.38095
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.28205,
            "fmeasure": 0.38095
        },
        "nist": 0.416046228496257,
        "bleu": 10.48008,
        "meteor": 0.31889518709539827,
        "bleurt": 0.0603,
        "nubia": {
            "semantic_relation": 3.39254,
            "contradiction": 0.3586,
            "irrelevancy": 0.67477,
            "logical_agreement": 98.96663,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.78354,
            "nubia_score": 0.44363
        },
        "bertscore": {
            "precision": 0.95055,
            "recall": 0.88522,
            "f1": 0.91672
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 40,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.23606797749979,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 13,
        "distinct-1": 0.75,
        "vocab_size-1": 30,
        "unique-1": 23,
        "entropy-1": 4.753055907333276,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 32,
        "unique-2": 28,
        "entropy-2": 4.947702779220088,
        "cond_entropy-2": 0.03563267050393547,
        "distinct-3": 0.9375,
        "vocab_size-3": 30,
        "unique-3": 28,
        "entropy-3": 4.875,
        "cond_entropy-3": -0.10742500144231229,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 8.75,
        "std_pred_length-nopunct": 2.384848003542364,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.707714802597438,
        "distinct-2-nopunct": 0.9032258064516129,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.760647923290102,
        "cond_entropy-2-nopunct": 0.04281289028589151,
        "distinct-3-nopunct": 0.9259259259259259,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.606739354015322,
        "cond_entropy-3-nopunct": -0.12523473414933256,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.16666666666666666,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.84028,
            "recall": 0.70768,
            "fmeasure": 0.76187
        },
        "rouge2": {
            "precision": 0.63939,
            "recall": 0.53968,
            "fmeasure": 0.5793
        },
        "rougeL": {
            "precision": 0.80456,
            "recall": 0.68495,
            "fmeasure": 0.7341
        },
        "rougeLsum": {
            "precision": 0.80456,
            "recall": 0.68495,
            "fmeasure": 0.7341
        },
        "nist": 3.563420520797612,
        "bleu": 53.32395,
        "meteor": 0.36436519198313994,
        "bleurt": 0.40586,
        "nubia": {
            "semantic_relation": 4.4254,
            "contradiction": 11.93715,
            "irrelevancy": 32.94097,
            "logical_agreement": 55.12187,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.98919,
            "nubia_score": 0.72124
        },
        "bertscore": {
            "precision": 0.95022,
            "recall": 0.94056,
            "f1": 0.94497
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.9,
            "fmeasure": 0.73333
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.30556,
            "fmeasure": 0.30065
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.42963,
            "fmeasure": 0.41404
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.42963,
            "fmeasure": 0.41404
        },
        "nist": 2.587500460977373,
        "bleu": 19.72941,
        "meteor": 0.38723688920615973,
        "bleurt": -0.29774,
        "nubia": {
            "semantic_relation": 3.61123,
            "contradiction": 1.06153,
            "irrelevancy": 98.5977,
            "logical_agreement": 0.34077,
            "grammar_ref": 7.45181,
            "grammar_hyp": 6.77236,
            "nubia_score": 0.54194
        },
        "bertscore": {
            "precision": 0.83489,
            "recall": 0.88071,
            "f1": 0.84685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 34,
        "mean_pred_length": 11.333333333333334,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 28,
        "unique-1": 23,
        "entropy-1": 4.712319091186707,
        "distinct-2": 0.9354838709677419,
        "vocab_size-2": 29,
        "unique-2": 27,
        "entropy-2": 4.825164052322361,
        "cond_entropy-2": -0.004234272798947969,
        "distinct-3": 0.9642857142857143,
        "vocab_size-3": 27,
        "unique-3": 26,
        "entropy-3": 4.735926350629034,
        "cond_entropy-3": -0.07541281690069973,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.640223928941852,
        "distinct-2-nopunct": 0.9259259259259259,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.606739354015323,
        "cond_entropy-2-nopunct": -0.0038549452969019174,
        "distinct-3-nopunct": 0.9583333333333334,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.501629167387823,
        "cond_entropy-3-nopunct": -0.08659166810897906,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.6451612903225806
        },
        "rouge1": {
            "precision": 0.68148,
            "recall": 0.69685,
            "fmeasure": 0.6717
        },
        "rouge2": {
            "precision": 0.46759,
            "recall": 0.48501,
            "fmeasure": 0.46065
        },
        "rougeL": {
            "precision": 0.61481,
            "recall": 0.65901,
            "fmeasure": 0.62346
        },
        "rougeLsum": {
            "precision": 0.61481,
            "recall": 0.65901,
            "fmeasure": 0.62346
        },
        "nist": 2.8665525221954713,
        "bleu": 34.32702,
        "meteor": 0.319302583897779,
        "bleurt": -0.06911,
        "nubia": {
            "semantic_relation": 3.69338,
            "contradiction": 9.85147,
            "irrelevancy": 54.91606,
            "logical_agreement": 35.23247,
            "grammar_ref": 5.15251,
            "grammar_hyp": 4.64657,
            "nubia_score": 0.60187
        },
        "bertscore": {
            "precision": 0.91857,
            "recall": 0.90244,
            "f1": 0.91008
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.25,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.44444,
            "fmeasure": 0.47059
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.44444,
            "fmeasure": 0.47059
        },
        "nist": 2.2146353501023204,
        "bleu": 16.36437,
        "meteor": 0.3220085066729408,
        "bleurt": 0.13835,
        "nubia": {
            "semantic_relation": 4.28363,
            "contradiction": 0.26317,
            "irrelevancy": 94.94952,
            "logical_agreement": 4.78731,
            "grammar_ref": 4.80739,
            "grammar_hyp": 5.44913,
            "nubia_score": 0.70987
        },
        "bertscore": {
            "precision": 0.88802,
            "recall": 0.84052,
            "f1": 0.86362
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.8,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.78571,
            "fmeasure": 0.84615
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.78571,
            "fmeasure": 0.84615
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.78571,
            "fmeasure": 0.84615
        },
        "nist": 3.61969958314147,
        "bleu": 49.7428,
        "meteor": 0.45095537742281383,
        "bleurt": 0.34492,
        "nubia": {
            "semantic_relation": 4.37479,
            "contradiction": 1.34239,
            "irrelevancy": 33.7312,
            "logical_agreement": 64.92641,
            "grammar_ref": 6.35753,
            "grammar_hyp": 6.98892,
            "nubia_score": 0.65283
        },
        "bertscore": {
            "precision": 0.97577,
            "recall": 0.96025,
            "f1": 0.96207
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "nist": 2.7109047337507373,
        "bleu": 53.10725,
        "meteor": 0.5033950705050299,
        "bleurt": 0.22576,
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        },
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.61978,
            "fmeasure": 0.70735
        },
        "rouge2": {
            "precision": 0.61538,
            "recall": 0.45455,
            "fmeasure": 0.5202
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.61978,
            "fmeasure": 0.70735
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.61978,
            "fmeasure": 0.70735
        },
        "nist": 2.222123241921427,
        "bleu": 45.12847,
        "meteor": 0.37263008375938694,
        "bleurt": 0.40952,
        "nubia": {
            "semantic_relation": 3.87391,
            "contradiction": 32.69485,
            "irrelevancy": 2.71028,
            "logical_agreement": 64.59487,
            "grammar_ref": 4.20692,
            "grammar_hyp": 4.38267,
            "nubia_score": 0.57767
        },
        "bertscore": {
            "precision": 0.9802,
            "recall": 0.93154,
            "f1": 0.94887
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 34,
        "mean_pred_length": 11.333333333333334,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.5882352941176471,
        "vocab_size-1": 20,
        "unique-1": 11,
        "entropy-1": 4.124083797069061,
        "distinct-2": 0.7419354838709677,
        "vocab_size-2": 23,
        "unique-2": 17,
        "entropy-2": 4.373551149096553,
        "cond_entropy-2": 0.18931411429782613,
        "distinct-3": 0.7857142857142857,
        "vocab_size-3": 22,
        "unique-3": 16,
        "entropy-3": 4.378783493486177,
        "cond_entropy-3": -0.003984245472128352,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 9.666666666666666,
        "std_pred_length-nopunct": 0.9428090415820634,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.6206896551724138,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.9614292709896417,
        "distinct-2-nopunct": 0.7307692307692307,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 4.085055102756476,
        "cond_entropy-2-nopunct": 0.07322795378275077,
        "distinct-3-nopunct": 0.782608695652174,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 4.088779347361361,
        "cond_entropy-3-nopunct": -0.08992124034494872,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.3684210526315789
        },
        "rouge1": {
            "precision": 0.56481,
            "recall": 0.35475,
            "fmeasure": 0.41543
        },
        "rouge2": {
            "precision": 0.32197,
            "recall": 0.17253,
            "fmeasure": 0.20952
        },
        "rougeL": {
            "precision": 0.48148,
            "recall": 0.28808,
            "fmeasure": 0.34136
        },
        "rougeLsum": {
            "precision": 0.48148,
            "recall": 0.28808,
            "fmeasure": 0.34136
        },
        "nist": 0.951286423263399,
        "bleu": 8.84177,
        "meteor": 0.19139436997780473,
        "bleurt": -0.4134,
        "nubia": {
            "semantic_relation": 2.82123,
            "contradiction": 2.17582,
            "irrelevancy": 61.86049,
            "logical_agreement": 35.9637,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.55234,
            "nubia_score": 0.27657
        },
        "bertscore": {
            "precision": 0.888,
            "recall": 0.80421,
            "f1": 0.84364
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 5.0,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 17,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.084962500721156,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 20,
        "unique-2": 18,
        "entropy-2": 4.277613436819114,
        "cond_entropy-2": 0.14719639064341364,
        "distinct-3": 0.95,
        "vocab_size-3": 19,
        "unique-3": 18,
        "entropy-3": 4.221928094887362,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.9219280948873623,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.94770277922009,
        "cond_entropy-2-nopunct": 0.014663573221616898,
        "distinct-3-nopunct": 0.9375,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.875,
        "cond_entropy-3-nopunct": -0.10742500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.68333,
            "recall": 0.73016,
            "fmeasure": 0.70228
        },
        "rouge2": {
            "precision": 0.48095,
            "recall": 0.53939,
            "fmeasure": 0.50667
        },
        "rougeL": {
            "precision": 0.68333,
            "recall": 0.73016,
            "fmeasure": 0.70228
        },
        "rougeLsum": {
            "precision": 0.68333,
            "recall": 0.73016,
            "fmeasure": 0.70228
        },
        "nist": 2.5534242449798112,
        "bleu": 36.6023,
        "meteor": 0.45746702998070526,
        "bleurt": 0.37441,
        "nubia": {
            "semantic_relation": 4.64402,
            "contradiction": 1.28763,
            "irrelevancy": 31.92747,
            "logical_agreement": 66.7849,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.34626,
            "nubia_score": 0.78924
        },
        "bertscore": {
            "precision": 0.93883,
            "recall": 0.96292,
            "f1": 0.95056
        }
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "t5-small/totto_test",
        "N": 45,
        "total_length": 693,
        "mean_pred_length": 15.4,
        "std_pred_length": 4.244735301261762,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.45454545454545453,
        "vocab_size-1": 315,
        "unique-1": 242,
        "entropy-1": 7.177792206317405,
        "distinct-2": 0.7654320987654321,
        "vocab_size-2": 496,
        "unique-2": 430,
        "entropy-2": 8.625080060577098,
        "cond_entropy-2": 1.2529743470482726,
        "distinct-3": 0.8922056384742952,
        "vocab_size-3": 538,
        "unique-3": 503,
        "entropy-3": 8.93351091020914,
        "cond_entropy-3": 0.3201144846652959,
        "total_length-nopunct": 628,
        "mean_pred_length-nopunct": 13.955555555555556,
        "std_pred_length-nopunct": 4.294469598891401,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.4968152866242038,
        "vocab_size-1-nopunct": 312,
        "unique-1-nopunct": 241,
        "entropy-1-nopunct": 7.3173444072602996,
        "distinct-2-nopunct": 0.7615780445969125,
        "vocab_size-2-nopunct": 444,
        "unique-2-nopunct": 385,
        "entropy-2-nopunct": 8.447563703330392,
        "cond_entropy-2-nopunct": 1.1906419423665677,
        "distinct-3-nopunct": 0.8847583643122676,
        "vocab_size-3-nopunct": 476,
        "unique-3-nopunct": 443,
        "entropy-3-nopunct": 8.744966839587383,
        "cond_entropy-3-nopunct": 0.3422368753698998,
        "msttr-100": 0.66167,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16,
            "2": 0.484375,
            "3": 0.8157894736842105
        },
        "rouge1": {
            "precision": 0.8212,
            "recall": 0.75902,
            "fmeasure": 0.78091
        },
        "rouge2": {
            "precision": 0.61596,
            "recall": 0.56917,
            "fmeasure": 0.5846
        },
        "rougeL": {
            "precision": 0.71566,
            "recall": 0.66053,
            "fmeasure": 0.67848
        },
        "rougeLsum": {
            "precision": 0.71566,
            "recall": 0.66053,
            "fmeasure": 0.67848
        },
        "nist": 7.248901287436898,
        "bleu": 50.16835,
        "meteor": 0.4200481411630493,
        "bleurt": 0.42013,
        "nubia": {
            "semantic_relation": 4.50043,
            "contradiction": 3.89234,
            "irrelevancy": 25.78503,
            "logical_agreement": 70.32262,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.87472,
            "nubia_score": 0.8118
        },
        "bertscore": {
            "precision": 0.95094,
            "recall": 0.94134,
            "f1": 0.94556
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.56667,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "nist": 1.7990385038524417,
        "bleu": 20.16495,
        "meteor": 0.861811391223156,
        "bleurt": 0.49066,
        "nubia": {
            "semantic_relation": 4.21377,
            "contradiction": 0.17851,
            "irrelevancy": 33.78877,
            "logical_agreement": 66.03272,
            "grammar_ref": 5.27628,
            "grammar_hyp": 4.69427,
            "nubia_score": 0.81239
        },
        "bertscore": {
            "precision": 0.94225,
            "recall": 0.97743,
            "f1": 0.95951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.36538461538461536,
        "vocab_size-1": 19,
        "unique-1": 6,
        "entropy-1": 4.009797352790419,
        "distinct-2": 0.5510204081632653,
        "vocab_size-2": 27,
        "unique-2": 14,
        "entropy-2": 4.578097853921918,
        "cond_entropy-2": 0.5296503544251705,
        "distinct-3": 0.6086956521739131,
        "vocab_size-3": 28,
        "unique-3": 17,
        "entropy-3": 4.626079075293006,
        "cond_entropy-3": 0.11558635116630321,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.3829787234042553,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.9311045426606546,
        "distinct-2-nopunct": 0.5227272727272727,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 4.350477356831132,
        "cond_entropy-2-nopunct": 0.4352939033888558,
        "distinct-3-nopunct": 0.5609756097560976,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 4.350619992053589,
        "cond_entropy-3-nopunct": 0.003970386051143035,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7,
            "2": 0.3333333333333333,
            "3": 0.631578947368421
        },
        "rouge1": {
            "precision": 0.76039,
            "recall": 0.69024,
            "fmeasure": 0.69952
        },
        "rouge2": {
            "precision": 0.51678,
            "recall": 0.46677,
            "fmeasure": 0.47166
        },
        "rougeL": {
            "precision": 0.60156,
            "recall": 0.56145,
            "fmeasure": 0.56317
        },
        "rougeLsum": {
            "precision": 0.60156,
            "recall": 0.56145,
            "fmeasure": 0.56317
        },
        "nist": 4.260218754777986,
        "bleu": 39.11324,
        "meteor": 0.35874080357409716,
        "bleurt": -0.3257,
        "nubia": {
            "semantic_relation": 3.65394,
            "contradiction": 0.73481,
            "irrelevancy": 38.11026,
            "logical_agreement": 61.15493,
            "grammar_ref": 5.76985,
            "grammar_hyp": 5.36544,
            "nubia_score": 0.53425
        },
        "bertscore": {
            "precision": 0.91196,
            "recall": 0.87321,
            "f1": 0.89071
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 1.0,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 10,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.19264507794239588,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644807,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "rouge1": {
            "precision": 0.72078,
            "recall": 0.76852,
            "fmeasure": 0.72743
        },
        "rouge2": {
            "precision": 0.52222,
            "recall": 0.59061,
            "fmeasure": 0.54024
        },
        "rougeL": {
            "precision": 0.62987,
            "recall": 0.64352,
            "fmeasure": 0.62216
        },
        "rougeLsum": {
            "precision": 0.62987,
            "recall": 0.64352,
            "fmeasure": 0.62216
        },
        "nist": 2.992191822385213,
        "bleu": 41.05484,
        "meteor": 0.4635083746140032,
        "bleurt": 0.22901,
        "nubia": {
            "semantic_relation": 4.28321,
            "contradiction": 2.14178,
            "irrelevancy": 46.0605,
            "logical_agreement": 51.79773,
            "grammar_ref": 4.99735,
            "grammar_hyp": 5.71319,
            "nubia_score": 0.59071
        },
        "bertscore": {
            "precision": 0.91026,
            "recall": 0.92975,
            "f1": 0.91865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.0,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 11,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 4.021928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.07021912877717244,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.16992500144231232,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.75417,
            "recall": 0.775,
            "fmeasure": 0.7631
        },
        "rouge2": {
            "precision": 0.53439,
            "recall": 0.56296,
            "fmeasure": 0.5463
        },
        "rougeL": {
            "precision": 0.67083,
            "recall": 0.73333,
            "fmeasure": 0.69762
        },
        "rougeLsum": {
            "precision": 0.67083,
            "recall": 0.73333,
            "fmeasure": 0.69762
        },
        "nist": 3.9238460907935995,
        "bleu": 60.80526,
        "meteor": 0.4301084266040878,
        "bleurt": 0.23268,
        "nubia": {
            "semantic_relation": 4.03759,
            "contradiction": 0.28654,
            "irrelevancy": 49.67127,
            "logical_agreement": 50.04218,
            "grammar_ref": 5.47595,
            "grammar_hyp": 5.57803,
            "nubia_score": 0.69756
        },
        "bertscore": {
            "precision": 0.91314,
            "recall": 0.94054,
            "f1": 0.9264
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.334679141051595,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.28076340776035313,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.188721875540867,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.30673161811281996,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.71296,
            "fmeasure": 0.61091
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.31548,
            "fmeasure": 0.30513
        },
        "rougeL": {
            "precision": 0.41026,
            "recall": 0.5037,
            "fmeasure": 0.44589
        },
        "rougeLsum": {
            "precision": 0.41026,
            "recall": 0.5037,
            "fmeasure": 0.44589
        },
        "nist": 3.6196431860652853,
        "bleu": 19.5369,
        "meteor": 0.30693627838800625,
        "bleurt": 0.10668,
        "nubia": {
            "semantic_relation": 2.79283,
            "contradiction": 0.21534,
            "irrelevancy": 50.82752,
            "logical_agreement": 48.95714,
            "grammar_ref": 4.01628,
            "grammar_hyp": 2.74779,
            "nubia_score": 0.52228
        },
        "bertscore": {
            "precision": 0.88977,
            "recall": 0.89168,
            "f1": 0.88556
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 3.2998316455372216,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 30,
        "unique-1": 23,
        "entropy-1": 4.80700942128139,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 30,
        "unique-2": 25,
        "entropy-2": 4.843568731230679,
        "cond_entropy-2": -0.06150163935576179,
        "distinct-3": 0.875,
        "vocab_size-3": 28,
        "unique-3": 24,
        "entropy-3": 4.75,
        "cond_entropy-3": -0.06678301694496638,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 2.8674417556808756,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.734521664779751,
        "distinct-2-nopunct": 0.8387096774193549,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.631615665225586,
        "cond_entropy-2-nopunct": -0.1010084663473351,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.521640636343321,
        "cond_entropy-3-nopunct": -0.11112710261498546,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.6896551724137931
        },
        "rouge1": {
            "precision": 0.7216,
            "recall": 0.69261,
            "fmeasure": 0.69652
        },
        "rouge2": {
            "precision": 0.39701,
            "recall": 0.35467,
            "fmeasure": 0.36672
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.60554,
            "fmeasure": 0.6167
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.60554,
            "fmeasure": 0.6167
        },
        "nist": 4.0582411374215495,
        "bleu": 29.62467,
        "meteor": 0.36863482931338765,
        "bleurt": -0.06571,
        "nubia": {
            "semantic_relation": 3.85262,
            "contradiction": 5.55891,
            "irrelevancy": 68.79657,
            "logical_agreement": 25.64452,
            "grammar_ref": 5.969,
            "grammar_hyp": 5.85222,
            "nubia_score": 0.56608
        },
        "bertscore": {
            "precision": 0.93184,
            "recall": 0.92344,
            "f1": 0.92517
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.16253715874966063,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.68333,
            "recall": 0.69758,
            "fmeasure": 0.69001
        },
        "rouge2": {
            "precision": 0.40351,
            "recall": 0.45185,
            "fmeasure": 0.42554
        },
        "rougeL": {
            "precision": 0.61667,
            "recall": 0.64187,
            "fmeasure": 0.62647
        },
        "rougeLsum": {
            "precision": 0.61667,
            "recall": 0.64187,
            "fmeasure": 0.62647
        },
        "nist": 3.113129958794178,
        "bleu": 18.54541,
        "meteor": 0.3594595227826925,
        "bleurt": 0.42774,
        "nubia": {
            "semantic_relation": 4.32793,
            "contradiction": 1.03592,
            "irrelevancy": 40.67919,
            "logical_agreement": 58.28489,
            "grammar_ref": 4.42639,
            "grammar_hyp": 3.74913,
            "nubia_score": 0.85973
        },
        "bertscore": {
            "precision": 0.92232,
            "recall": 0.92776,
            "f1": 0.91894
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.5862068965517241,
        "vocab_size-1": 17,
        "unique-1": 7,
        "entropy-1": 3.978333581185264,
        "distinct-2": 0.7037037037037037,
        "vocab_size-2": 19,
        "unique-2": 11,
        "entropy-2": 4.162294909570877,
        "cond_entropy-2": 0.17504632201096829,
        "distinct-3": 0.8,
        "vocab_size-3": 20,
        "unique-3": 15,
        "entropy-3": 4.243856189774722,
        "cond_entropy-3": 0.12896868761125602,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.5925925925925926,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.884155094595805,
        "distinct-2-nopunct": 0.68,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 4.003856189774724,
        "cond_entropy-2-nopunct": 0.12596118775548726,
        "distinct-3-nopunct": 0.782608695652174,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 4.088779347361361,
        "cond_entropy-3-nopunct": 0.09709707063011433,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.47949,
            "recall": 0.56013,
            "fmeasure": 0.50855
        },
        "rouge2": {
            "precision": 0.30754,
            "recall": 0.35577,
            "fmeasure": 0.32424
        },
        "rougeL": {
            "precision": 0.47949,
            "recall": 0.56013,
            "fmeasure": 0.50855
        },
        "rougeLsum": {
            "precision": 0.47949,
            "recall": 0.56013,
            "fmeasure": 0.50855
        },
        "nist": 2.2564891871653536,
        "bleu": 20.53951,
        "meteor": 0.35531066836214587,
        "bleurt": 0.2151,
        "nubia": {
            "semantic_relation": 4.20264,
            "contradiction": 0.45127,
            "irrelevancy": 43.94623,
            "logical_agreement": 55.6025,
            "grammar_ref": 5.01983,
            "grammar_hyp": 4.94311,
            "nubia_score": 0.66529
        },
        "bertscore": {
            "precision": 0.89191,
            "recall": 0.91485,
            "f1": 0.90299
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.8841837197791884,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.3867829713016689,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.787143960698138,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.40838012700780835,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.84211,
            "recall": 0.87329,
            "fmeasure": 0.85728
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.63508,
            "fmeasure": 0.62275
        },
        "rougeL": {
            "precision": 0.78947,
            "recall": 0.81871,
            "fmeasure": 0.8037
        },
        "rougeLsum": {
            "precision": 0.78947,
            "recall": 0.81871,
            "fmeasure": 0.8037
        },
        "nist": 3.7127695998333654,
        "bleu": 50.36156,
        "meteor": 0.5338344763486319,
        "bleurt": 0.7396,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.16523,
            "irrelevancy": 0.50482,
            "logical_agreement": 99.32995,
            "grammar_ref": 3.47563,
            "grammar_hyp": 3.93388,
            "nubia_score": 0.9676
        },
        "bertscore": {
            "precision": 0.98185,
            "recall": 0.977,
            "f1": 0.97942
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "nist": 2.456435556800404,
        "bleu": 50.0,
        "meteor": 0.5277006683854432,
        "bleurt": 0.93658,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.14589,
            "irrelevancy": 0.6446,
            "logical_agreement": 98.20952,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.39193,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.98601,
            "recall": 0.99497,
            "f1": 0.99047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.44444,
            "fmeasure": 0.44071
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.09091,
            "fmeasure": 0.10526
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.25,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.25,
            "fmeasure": 0.28571
        },
        "nist": 1.2409119936655402,
        "bleu": 11.33958,
        "meteor": 0.1880197745154705,
        "bleurt": -0.37917,
        "nubia": {
            "semantic_relation": 3.4521,
            "contradiction": 0.15434,
            "irrelevancy": 99.68669,
            "logical_agreement": 0.15898,
            "grammar_ref": 5.08958,
            "grammar_hyp": 5.23502,
            "nubia_score": 0.50154
        },
        "bertscore": {
            "precision": 0.79748,
            "recall": 0.8591,
            "f1": 0.82715
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 3.9976702764876113,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.1861579047855862,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.807763576417195,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.20971762763487742,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.41785,
            "fmeasure": 0.4963
        },
        "rouge2": {
            "precision": 0.39216,
            "recall": 0.26359,
            "fmeasure": 0.31525
        },
        "rougeL": {
            "precision": 0.53704,
            "recall": 0.36752,
            "fmeasure": 0.43636
        },
        "rougeLsum": {
            "precision": 0.53704,
            "recall": 0.36752,
            "fmeasure": 0.43636
        },
        "nist": 3.0848635430839306,
        "bleu": 42.79469,
        "meteor": 0.2411415220903239,
        "bleurt": -0.3759,
        "nubia": {
            "semantic_relation": 3.30893,
            "contradiction": 30.25397,
            "irrelevancy": 40.52652,
            "logical_agreement": 29.21951,
            "grammar_ref": 4.65446,
            "grammar_hyp": 4.32298,
            "nubia_score": 0.42693
        },
        "bertscore": {
            "precision": 0.89844,
            "recall": 0.8946,
            "f1": 0.88926
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.28571,
            "recall": 0.37778,
            "fmeasure": 0.32479
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.21429,
            "recall": 0.28333,
            "fmeasure": 0.24359
        },
        "rougeLsum": {
            "precision": 0.21429,
            "recall": 0.28333,
            "fmeasure": 0.24359
        },
        "nist": 0.8756250851322958,
        "bleu": 3.45859,
        "meteor": 0.1985490013826504,
        "bleurt": -0.15568,
        "nubia": {
            "semantic_relation": 3.087,
            "contradiction": 0.19352,
            "irrelevancy": 99.63586,
            "logical_agreement": 0.17062,
            "grammar_ref": 4.40566,
            "grammar_hyp": 2.82601,
            "nubia_score": 0.59089
        },
        "bertscore": {
            "precision": 0.80033,
            "recall": 0.85014,
            "f1": 0.82449
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "nist": 1.2775418301849517,
        "bleu": 11.33958,
        "meteor": 0.31127891035349853,
        "bleurt": -0.04695,
        "nubia": {
            "semantic_relation": 3.94411,
            "contradiction": 0.52809,
            "irrelevancy": 90.87595,
            "logical_agreement": 8.59595,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.74554,
            "nubia_score": 0.60532
        },
        "bertscore": {
            "precision": 0.8573,
            "recall": 0.88842,
            "f1": 0.87258
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.0402239289418519,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.03214388408660255,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.69841,
            "fmeasure": 0.7589
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.54359,
            "fmeasure": 0.59333
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.69841,
            "fmeasure": 0.7589
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.69841,
            "fmeasure": 0.7589
        },
        "nist": 2.493523479613345,
        "bleu": 49.61578,
        "meteor": 0.49330025371510594,
        "bleurt": 0.25341,
        "nubia": {
            "semantic_relation": 3.97699,
            "contradiction": 0.36172,
            "irrelevancy": 0.59225,
            "logical_agreement": 99.04604,
            "grammar_ref": 3.68983,
            "grammar_hyp": 3.55601,
            "nubia_score": 0.73104
        },
        "bertscore": {
            "precision": 0.94572,
            "recall": 0.94175,
            "f1": 0.94373
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.418295834054489,
        "cond_entropy-2-nopunct": 0.05118944924673078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": 0.056287299734322706,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.65625,
            "fmeasure": 0.57857
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "nist": 2.8441645853579183,
        "bleu": 44.5345,
        "meteor": 0.4505163353501177,
        "bleurt": 0.30287,
        "nubia": {
            "semantic_relation": 4.19399,
            "contradiction": 0.18495,
            "irrelevancy": 94.22535,
            "logical_agreement": 5.5897,
            "grammar_ref": 5.6106,
            "grammar_hyp": 4.31806,
            "nubia_score": 0.76494
        },
        "bertscore": {
            "precision": 0.89821,
            "recall": 0.93375,
            "f1": 0.91564
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.25,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.54902,
            "recall": 0.55152,
            "fmeasure": 0.54594
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.36147,
            "fmeasure": 0.39181
        },
        "rougeL": {
            "precision": 0.4902,
            "recall": 0.48599,
            "fmeasure": 0.48333
        },
        "rougeLsum": {
            "precision": 0.4902,
            "recall": 0.48599,
            "fmeasure": 0.48333
        },
        "nist": 2.5453531899416166,
        "bleu": 40.32504,
        "meteor": 0.3020253892233447,
        "bleurt": -0.07827,
        "nubia": {
            "semantic_relation": 3.00181,
            "contradiction": 1.74031,
            "irrelevancy": 97.86896,
            "logical_agreement": 0.39074,
            "grammar_ref": 4.44297,
            "grammar_hyp": 4.34794,
            "nubia_score": 0.32658
        },
        "bertscore": {
            "precision": 0.84655,
            "recall": 0.87479,
            "f1": 0.85431
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 36,
        "unique-1": 34,
        "entropy-1": 5.112199975217029,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": -0.05992166186438028,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.449489742783178,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9696969696969697,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.9837880587523955,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": -0.07083685708326808,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.3,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.82372,
            "recall": 0.69691,
            "fmeasure": 0.7503
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.51565,
            "fmeasure": 0.54384
        },
        "rougeL": {
            "precision": 0.82372,
            "recall": 0.69691,
            "fmeasure": 0.7503
        },
        "rougeLsum": {
            "precision": 0.82372,
            "recall": 0.69691,
            "fmeasure": 0.7503
        },
        "nist": 2.320645395764646,
        "bleu": 33.59052,
        "meteor": 0.3164953301782746,
        "bleurt": 0.21503,
        "nubia": {
            "semantic_relation": 4.16284,
            "contradiction": 6.46948,
            "irrelevancy": 21.5641,
            "logical_agreement": 71.96641,
            "grammar_ref": 4.46773,
            "grammar_hyp": 4.79063,
            "nubia_score": 0.68348
        },
        "bertscore": {
            "precision": 0.93553,
            "recall": 0.92044,
            "f1": 0.92788
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.45454545454545453
        },
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.47857,
            "fmeasure": 0.54615
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.21703,
            "fmeasure": 0.25181
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.34048,
            "fmeasure": 0.38923
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.34048,
            "fmeasure": 0.38923
        },
        "nist": 3.0006339511684827,
        "bleu": 34.55764,
        "meteor": 0.37056685299787695,
        "bleurt": 0.23778,
        "nubia": {
            "semantic_relation": 4.06878,
            "contradiction": 72.51704,
            "irrelevancy": 10.46826,
            "logical_agreement": 17.0147,
            "grammar_ref": 4.95834,
            "grammar_hyp": 5.30912,
            "nubia_score": 0.55376
        },
        "bertscore": {
            "precision": 0.92493,
            "recall": 0.90004,
            "f1": 0.91232
        }
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "t5-small/totto_test",
        "N": 150,
        "total_length": 2218,
        "mean_pred_length": 14.786666666666667,
        "std_pred_length": 3.679830913989875,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.44634806131650134,
        "vocab_size-1": 990,
        "unique-1": 794,
        "entropy-1": 8.2882378869373,
        "distinct-2": 0.8027079303675049,
        "vocab_size-2": 1660,
        "unique-2": 1494,
        "entropy-2": 10.393213135544704,
        "cond_entropy-2": 1.85361181143269,
        "distinct-3": 0.9181438998957248,
        "vocab_size-3": 1761,
        "unique-3": 1680,
        "entropy-3": 10.69141877513668,
        "cond_entropy-3": 0.33093830393635065,
        "total_length-nopunct": 1955,
        "mean_pred_length-nopunct": 13.033333333333333,
        "std_pred_length-nopunct": 3.3850980619309814,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5012787723785166,
        "vocab_size-1-nopunct": 980,
        "unique-1-nopunct": 790,
        "entropy-1-nopunct": 8.571775393945623,
        "distinct-2-nopunct": 0.8127423822714681,
        "vocab_size-2-nopunct": 1467,
        "unique-2-nopunct": 1343,
        "entropy-2-nopunct": 10.201602147058336,
        "cond_entropy-2-nopunct": 1.7528366624450347,
        "distinct-3-nopunct": 0.9353474320241691,
        "vocab_size-3-nopunct": 1548,
        "unique-3-nopunct": 1494,
        "entropy-3-nopunct": 10.52039023373249,
        "cond_entropy-3-nopunct": 0.34749600222966365,
        "msttr-100": 0.71682,
        "msttr-100_nopunct": 0.75632,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18403547671840353,
            "2": 0.3783783783783784,
            "3": 0.7588774341351661
        },
        "rouge1": {
            "precision": 0.83542,
            "recall": 0.74593,
            "fmeasure": 0.77842
        },
        "rouge2": {
            "precision": 0.60004,
            "recall": 0.54337,
            "fmeasure": 0.563
        },
        "rougeL": {
            "precision": 0.71793,
            "recall": 0.64753,
            "fmeasure": 0.6722
        },
        "rougeLsum": {
            "precision": 0.71793,
            "recall": 0.64753,
            "fmeasure": 0.6722
        },
        "nist": 7.4011497135920745,
        "bleu": 44.28416,
        "meteor": 0.38980325291947715,
        "bleurt": 0.33622,
        "nubia": {
            "semantic_relation": 4.37693,
            "contradiction": 9.28775,
            "irrelevancy": 22.94641,
            "logical_agreement": 67.76585,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.29224,
            "nubia_score": 0.74384
        },
        "bertscore": {
            "precision": 0.94843,
            "recall": 0.93537,
            "f1": 0.94094
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228495,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.65132,
            "fmeasure": 0.73491
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.5037,
            "fmeasure": 0.57284
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 0.53289,
            "fmeasure": 0.60129
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 0.53289,
            "fmeasure": 0.60129
        },
        "nist": 2.905201112329386,
        "bleu": 46.27024,
        "meteor": 0.352342069114811,
        "bleurt": -0.06823,
        "nubia": {
            "semantic_relation": 4.25696,
            "contradiction": 0.51794,
            "irrelevancy": 0.53439,
            "logical_agreement": 98.94768,
            "grammar_ref": 4.542,
            "grammar_hyp": 3.7605,
            "nubia_score": 0.88265
        },
        "bertscore": {
            "precision": 0.91723,
            "recall": 0.85482,
            "f1": 0.87947
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8214285714285714,
        "vocab_size-1": 23,
        "unique-1": 19,
        "entropy-1": 4.423251796980338,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.15288816155131352,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.03214388408660258,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.84,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.293660689688185,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.17339652724591728,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.036006438040157164,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.72619,
            "recall": 0.63797,
            "fmeasure": 0.67635
        },
        "rouge2": {
            "precision": 0.60023,
            "recall": 0.51859,
            "fmeasure": 0.55475
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.56288,
            "fmeasure": 0.5984
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.56288,
            "fmeasure": 0.5984
        },
        "nist": 3.7209289356030775,
        "bleu": 56.45596,
        "meteor": 0.3708580680786463,
        "bleurt": 0.00451,
        "nubia": {
            "semantic_relation": 3.24182,
            "contradiction": 0.37037,
            "irrelevancy": 46.86924,
            "logical_agreement": 52.76039,
            "grammar_ref": 4.47266,
            "grammar_hyp": 4.13337,
            "nubia_score": 0.50394
        },
        "bertscore": {
            "precision": 0.92105,
            "recall": 0.90898,
            "f1": 0.91495
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.7381,
            "recall": 0.55417,
            "fmeasure": 0.63137
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.19832,
            "fmeasure": 0.24074
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.35,
            "fmeasure": 0.38431
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.35,
            "fmeasure": 0.38431
        },
        "nist": 2.2732056990855685,
        "bleu": 14.38264,
        "meteor": 0.26056982310922205,
        "bleurt": 0.07889,
        "nubia": {
            "semantic_relation": 3.21695,
            "contradiction": 74.20053,
            "irrelevancy": 25.19833,
            "logical_agreement": 0.60113,
            "grammar_ref": 4.75667,
            "grammar_hyp": 3.5409,
            "nubia_score": 0.48141
        },
        "bertscore": {
            "precision": 0.89863,
            "recall": 0.85066,
            "f1": 0.86474
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.4677201004745006,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2588453731729854,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.334679141051595,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.28076340776035313,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.625
        },
        "rouge1": {
            "precision": 0.60714,
            "recall": 0.56696,
            "fmeasure": 0.58571
        },
        "rouge2": {
            "precision": 0.34615,
            "recall": 0.32051,
            "fmeasure": 0.33242
        },
        "rougeL": {
            "precision": 0.53571,
            "recall": 0.49554,
            "fmeasure": 0.51429
        },
        "rougeLsum": {
            "precision": 0.53571,
            "recall": 0.49554,
            "fmeasure": 0.51429
        },
        "nist": 2.238735374646036,
        "bleu": 15.40408,
        "meteor": 0.3390961496094558,
        "bleurt": 0.27762,
        "nubia": {
            "semantic_relation": 1.90897,
            "contradiction": 70.24638,
            "irrelevancy": 13.72996,
            "logical_agreement": 16.02366,
            "grammar_ref": 3.06207,
            "grammar_hyp": 2.86402,
            "nubia_score": 0.22968
        },
        "bertscore": {
            "precision": 0.91592,
            "recall": 0.90404,
            "f1": 0.90607
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.79772,
            "fmeasure": 0.79329
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.43137,
            "fmeasure": 0.44193
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.69801,
            "fmeasure": 0.69413
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.69801,
            "fmeasure": 0.69413
        },
        "nist": 4.068509228887634,
        "bleu": 62.34181,
        "meteor": 0.4484780024350596,
        "bleurt": 0.38972,
        "nubia": {
            "semantic_relation": 3.9358,
            "contradiction": 0.54977,
            "irrelevancy": 0.62257,
            "logical_agreement": 98.82766,
            "grammar_ref": 5.3293,
            "grammar_hyp": 5.06087,
            "nubia_score": 0.67223
        },
        "bertscore": {
            "precision": 0.96579,
            "recall": 0.96879,
            "f1": 0.96729
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.60185,
            "fmeasure": 0.49206
        },
        "rouge2": {
            "precision": 0.24242,
            "recall": 0.31746,
            "fmeasure": 0.27407
        },
        "rougeL": {
            "precision": 0.30556,
            "recall": 0.39167,
            "fmeasure": 0.34242
        },
        "rougeLsum": {
            "precision": 0.30556,
            "recall": 0.39167,
            "fmeasure": 0.34242
        },
        "nist": 1.4940725447674859,
        "bleu": 13.29242,
        "meteor": 0.2546709281392665,
        "bleurt": -0.61658,
        "nubia": {
            "semantic_relation": 2.29163,
            "contradiction": 0.75144,
            "irrelevancy": 98.9313,
            "logical_agreement": 0.31726,
            "grammar_ref": 5.1757,
            "grammar_hyp": 4.56156,
            "nubia_score": 0.20754
        },
        "bertscore": {
            "precision": 0.80847,
            "recall": 0.88323,
            "f1": 0.8442
        }
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "t5-small/totto_test",
        "N": 150,
        "total_length": 2273,
        "mean_pred_length": 15.153333333333334,
        "std_pred_length": 5.08033682172966,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.42190937087549496,
        "vocab_size-1": 959,
        "unique-1": 760,
        "entropy-1": 8.212730566094002,
        "distinct-2": 0.7951012717852096,
        "vocab_size-2": 1688,
        "unique-2": 1501,
        "entropy-2": 10.406825835115649,
        "cond_entropy-2": 1.9644559092816032,
        "distinct-3": 0.9244804865686771,
        "vocab_size-3": 1824,
        "unique-3": 1731,
        "entropy-3": 10.762954610778667,
        "cond_entropy-3": 0.36447651141482795,
        "total_length-nopunct": 1996,
        "mean_pred_length-nopunct": 13.306666666666667,
        "std_pred_length-nopunct": 4.663255896426397,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.47645290581162325,
        "vocab_size-1-nopunct": 951,
        "unique-1-nopunct": 757,
        "entropy-1-nopunct": 8.489675511268745,
        "distinct-2-nopunct": 0.8055254604550379,
        "vocab_size-2-nopunct": 1487,
        "unique-2-nopunct": 1344,
        "entropy-2-nopunct": 10.213019997141187,
        "cond_entropy-2-nopunct": 1.8228775825594854,
        "distinct-3-nopunct": 0.9321933962264151,
        "vocab_size-3-nopunct": 1581,
        "unique-3-nopunct": 1512,
        "entropy-3-nopunct": 10.56018769933158,
        "cond_entropy-3-nopunct": 0.38141485606927356,
        "msttr-100": 0.71545,
        "msttr-100_nopunct": 0.77053,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1810344827586207,
            "2": 0.3972972972972973,
            "3": 0.75708257986739
        },
        "rouge1": {
            "precision": 0.77326,
            "recall": 0.71353,
            "fmeasure": 0.7301
        },
        "rouge2": {
            "precision": 0.52889,
            "recall": 0.48838,
            "fmeasure": 0.49848
        },
        "rougeL": {
            "precision": 0.64769,
            "recall": 0.60265,
            "fmeasure": 0.61347
        },
        "rougeLsum": {
            "precision": 0.64769,
            "recall": 0.60265,
            "fmeasure": 0.61347
        },
        "nist": 7.5913420840963015,
        "bleu": 42.99938,
        "meteor": 0.38340868272001716,
        "bleurt": 0.24509,
        "nubia": {
            "semantic_relation": 4.27158,
            "contradiction": 5.63516,
            "irrelevancy": 28.16463,
            "logical_agreement": 66.2002,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.79945,
            "nubia_score": 0.7378
        },
        "bertscore": {
            "precision": 0.92325,
            "recall": 0.92187,
            "f1": 0.92045
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 2.5,
        "median_pred_length": 16.5,
        "min_pred_length": 14,
        "max_pred_length": 19,
        "distinct-1": 0.7878787878787878,
        "vocab_size-1": 26,
        "unique-1": 20,
        "entropy-1": 4.597276316262592,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 30,
        "unique-2": 29,
        "entropy-2": 4.889680181354619,
        "cond_entropy-2": 0.2567340459369209,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.481727678869737,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.2845674515263523,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.02999212699343526,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.9047619047619048
        },
        "rouge1": {
            "precision": 0.73219,
            "recall": 0.89261,
            "fmeasure": 0.79202
        },
        "rouge2": {
            "precision": 0.53676,
            "recall": 0.63558,
            "fmeasure": 0.57406
        },
        "rougeL": {
            "precision": 0.59829,
            "recall": 0.70408,
            "fmeasure": 0.63938
        },
        "rougeLsum": {
            "precision": 0.59829,
            "recall": 0.70408,
            "fmeasure": 0.63938
        },
        "nist": 4.013156829696666,
        "bleu": 52.48339,
        "meteor": 0.4845935697201194,
        "bleurt": -0.08838,
        "nubia": {
            "semantic_relation": 4.21716,
            "contradiction": 0.81675,
            "irrelevancy": 40.32928,
            "logical_agreement": 58.85398,
            "grammar_ref": 5.29605,
            "grammar_hyp": 4.89241,
            "nubia_score": 0.70951
        },
        "bertscore": {
            "precision": 0.88995,
            "recall": 0.89677,
            "f1": 0.8922
        }
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "t5-small/totto_test",
        "N": 150,
        "total_length": 2413,
        "mean_pred_length": 16.086666666666666,
        "std_pred_length": 4.506198200503638,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.4202237878159967,
        "vocab_size-1": 1014,
        "unique-1": 783,
        "entropy-1": 8.262235485101117,
        "distinct-2": 0.8024745912505523,
        "vocab_size-2": 1816,
        "unique-2": 1620,
        "entropy-2": 10.547394968682111,
        "cond_entropy-2": 2.066849383689708,
        "distinct-3": 0.9394226218646474,
        "vocab_size-3": 1985,
        "unique-3": 1897,
        "entropy-3": 10.904417502505495,
        "cond_entropy-3": 0.3435096818676548,
        "total_length-nopunct": 2076,
        "mean_pred_length-nopunct": 13.84,
        "std_pred_length-nopunct": 4.038283463717391,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.48265895953757226,
        "vocab_size-1-nopunct": 1002,
        "unique-1-nopunct": 779,
        "entropy-1-nopunct": 8.599255373119375,
        "distinct-2-nopunct": 0.8359293873312564,
        "vocab_size-2-nopunct": 1610,
        "unique-2-nopunct": 1477,
        "entropy-2-nopunct": 10.395236217962552,
        "cond_entropy-2-nopunct": 1.8761172769047405,
        "distinct-3-nopunct": 0.9572072072072072,
        "vocab_size-3-nopunct": 1700,
        "unique-3-nopunct": 1645,
        "entropy-3-nopunct": 10.69668788918052,
        "cond_entropy-3-nopunct": 0.3264114842681796,
        "msttr-100": 0.7075,
        "msttr-100_nopunct": 0.7665,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1431980906921241,
            "2": 0.24028268551236748,
            "3": 0.7636949516648764
        },
        "rouge1": {
            "precision": 0.80865,
            "recall": 0.74436,
            "fmeasure": 0.76782
        },
        "rouge2": {
            "precision": 0.56691,
            "recall": 0.52066,
            "fmeasure": 0.53697
        },
        "rougeL": {
            "precision": 0.71089,
            "recall": 0.65295,
            "fmeasure": 0.67397
        },
        "rougeLsum": {
            "precision": 0.71089,
            "recall": 0.65295,
            "fmeasure": 0.67397
        },
        "nist": 7.707243857048848,
        "bleu": 44.96816,
        "meteor": 0.39404586933223956,
        "bleurt": 0.33228,
        "nubia": {
            "semantic_relation": 4.36876,
            "contradiction": 8.18918,
            "irrelevancy": 19.95471,
            "logical_agreement": 71.85611,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.73033,
            "nubia_score": 0.7629
        },
        "bertscore": {
            "precision": 0.93772,
            "recall": 0.92855,
            "f1": 0.93197
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.0,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.6764705882352942,
        "vocab_size-1": 23,
        "unique-1": 14,
        "entropy-1": 4.3815804883091625,
        "distinct-2": 0.8125,
        "vocab_size-2": 26,
        "unique-2": 20,
        "entropy-2": 4.625,
        "cond_entropy-2": 0.22503715874966063,
        "distinct-3": 0.8666666666666667,
        "vocab_size-3": 26,
        "unique-3": 22,
        "entropy-3": 4.640223928941851,
        "cond_entropy-3": 0.040223928941851894,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.240223928941852,
        "distinct-2-nopunct": 0.7857142857142857,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.378783493486178,
        "cond_entropy-2-nopunct": 0.1504643264490856,
        "distinct-3-nopunct": 0.8461538461538461,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.392747410448783,
        "cond_entropy-3-nopunct": 0.008469411468103209,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.45454545454545453,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.79266,
            "recall": 0.80631,
            "fmeasure": 0.7993
        },
        "rouge2": {
            "precision": 0.61667,
            "recall": 0.62647,
            "fmeasure": 0.62143
        },
        "rougeL": {
            "precision": 0.66108,
            "recall": 0.75758,
            "fmeasure": 0.69887
        },
        "rougeLsum": {
            "precision": 0.66108,
            "recall": 0.75758,
            "fmeasure": 0.69887
        },
        "nist": 4.260785438626554,
        "bleu": 53.22753,
        "meteor": 0.5367610654046221,
        "bleurt": 0.41391,
        "nubia": {
            "semantic_relation": 4.73414,
            "contradiction": 1.08486,
            "irrelevancy": 15.96017,
            "logical_agreement": 82.95497,
            "grammar_ref": 3.87403,
            "grammar_hyp": 4.00359,
            "nubia_score": 0.88913
        },
        "bertscore": {
            "precision": 0.96586,
            "recall": 0.96571,
            "f1": 0.96518
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 47,
        "mean_pred_length": 11.75,
        "std_pred_length": 3.344772040064913,
        "median_pred_length": 13.5,
        "min_pred_length": 6,
        "max_pred_length": 14,
        "distinct-1": 0.5957446808510638,
        "vocab_size-1": 28,
        "unique-1": 13,
        "entropy-1": 4.660971830401043,
        "distinct-2": 0.7209302325581395,
        "vocab_size-2": 31,
        "unique-2": 19,
        "entropy-2": 4.868125219818376,
        "cond_entropy-2": 0.10423404255934432,
        "distinct-3": 0.7435897435897436,
        "vocab_size-3": 29,
        "unique-3": 19,
        "entropy-3": 4.772581706041735,
        "cond_entropy-3": -0.0895804845577984,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 10.75,
        "std_pred_length-nopunct": 3.344772040064913,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.627906976744186,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.635567080283493,
        "distinct-2-nopunct": 0.717948717948718,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.721299654759684,
        "cond_entropy-2-nopunct": 0.11554772057040667,
        "distinct-3-nopunct": 0.7428571428571429,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.614997302659251,
        "cond_entropy-3-nopunct": -0.09897634477442475,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.225,
            "2": 0.37037037037037035,
            "3": 0.3793103448275862
        },
        "rouge1": {
            "precision": 0.6913,
            "recall": 0.41621,
            "fmeasure": 0.48407
        },
        "rouge2": {
            "precision": 0.39583,
            "recall": 0.22265,
            "fmeasure": 0.26653
        },
        "rougeL": {
            "precision": 0.48278,
            "recall": 0.3112,
            "fmeasure": 0.36218
        },
        "rougeLsum": {
            "precision": 0.48278,
            "recall": 0.3112,
            "fmeasure": 0.36218
        },
        "nist": 1.385074060466332,
        "bleu": 24.40209,
        "meteor": 0.21267189931189243,
        "bleurt": -0.26467,
        "nubia": {
            "semantic_relation": 3.68423,
            "contradiction": 1.92621,
            "irrelevancy": 25.26232,
            "logical_agreement": 72.81147,
            "grammar_ref": 5.44243,
            "grammar_hyp": 6.23344,
            "nubia_score": 0.47188
        },
        "bertscore": {
            "precision": 0.89705,
            "recall": 0.81731,
            "f1": 0.84736
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.58333,
            "fmeasure": 0.51852
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "nist": 2.5848040654130635,
        "bleu": 37.42032,
        "meteor": 0.4854043997759893,
        "bleurt": 0.62156,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.06983,
            "irrelevancy": 2.29714,
            "logical_agreement": 97.63303,
            "grammar_ref": 4.23153,
            "grammar_hyp": 3.7095,
            "nubia_score": 0.99841
        },
        "bertscore": {
            "precision": 0.9266,
            "recall": 0.9505,
            "f1": 0.9384
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "nist": 3.0945894140476606,
        "bleu": 62.62845,
        "meteor": 0.512675617900284,
        "bleurt": 0.79405,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37071,
            "irrelevancy": 0.70467,
            "logical_agreement": 98.92462,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.34125,
            "nubia_score": 0.98178
        },
        "bertscore": {
            "precision": 0.96634,
            "recall": 0.98092,
            "f1": 0.97358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.85784,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.52222,
            "fmeasure": 0.5276
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.67402,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.67402,
            "fmeasure": 0.68056
        },
        "nist": 3.4129576153693453,
        "bleu": 26.91657,
        "meteor": 0.3989852885537935,
        "bleurt": 0.07606,
        "nubia": {
            "semantic_relation": 3.69694,
            "contradiction": 5.96431,
            "irrelevancy": 2.1024,
            "logical_agreement": 91.93329,
            "grammar_ref": 4.86284,
            "grammar_hyp": 5.29901,
            "nubia_score": 0.51619
        },
        "bertscore": {
            "precision": 0.94455,
            "recall": 0.92038,
            "f1": 0.93231
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.0,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.450212064914748,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.323856189774722,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.22753185323880998,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.7894736842105263
        },
        "rouge1": {
            "precision": 0.81538,
            "recall": 0.84982,
            "fmeasure": 0.83018
        },
        "rouge2": {
            "precision": 0.60516,
            "recall": 0.63568,
            "fmeasure": 0.61825
        },
        "rougeL": {
            "precision": 0.77692,
            "recall": 0.81319,
            "fmeasure": 0.79267
        },
        "rougeLsum": {
            "precision": 0.77692,
            "recall": 0.81319,
            "fmeasure": 0.79267
        },
        "nist": 3.7938509766078434,
        "bleu": 47.4473,
        "meteor": 0.45415483123703027,
        "bleurt": 0.47808,
        "nubia": {
            "semantic_relation": 4.55017,
            "contradiction": 0.16622,
            "irrelevancy": 48.82839,
            "logical_agreement": 51.00539,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.38957,
            "nubia_score": 0.85736
        },
        "bertscore": {
            "precision": 0.9404,
            "recall": 0.96111,
            "f1": 0.94894
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964168,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 1.0,
            "3": 0.3888888888888889
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.48148,
            "fmeasure": 0.58605
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.20903,
            "fmeasure": 0.25674
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.30934,
            "fmeasure": 0.36228
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.30934,
            "fmeasure": 0.36228
        },
        "nist": 1.4694196506168289,
        "bleu": 9.3943,
        "meteor": 0.3010204153567416,
        "bleurt": 0.08756,
        "nubia": {
            "semantic_relation": 3.74485,
            "contradiction": 13.41521,
            "irrelevancy": 16.20091,
            "logical_agreement": 70.38388,
            "grammar_ref": 3.86337,
            "grammar_hyp": 4.91571,
            "nubia_score": 0.4724
        },
        "bertscore": {
            "precision": 0.93831,
            "recall": 0.88278,
            "f1": 0.90839
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966059,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5333333333333333
        },
        "rouge1": {
            "precision": 0.65,
            "recall": 0.59325,
            "fmeasure": 0.61973
        },
        "rouge2": {
            "precision": 0.36842,
            "recall": 0.35,
            "fmeasure": 0.35897
        },
        "rougeL": {
            "precision": 0.35,
            "recall": 0.31944,
            "fmeasure": 0.3337
        },
        "rougeLsum": {
            "precision": 0.35,
            "recall": 0.31944,
            "fmeasure": 0.3337
        },
        "nist": 2.7656598560108665,
        "bleu": 23.59645,
        "meteor": 0.336247795212403,
        "bleurt": -0.27863,
        "nubia": {
            "semantic_relation": 3.77093,
            "contradiction": 9.36918,
            "irrelevancy": 84.6598,
            "logical_agreement": 5.97102,
            "grammar_ref": 6.02354,
            "grammar_hyp": 6.15591,
            "nubia_score": 0.4937
        },
        "bertscore": {
            "precision": 0.86703,
            "recall": 0.86351,
            "f1": 0.8641
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.84,
        "vocab_size-1": 21,
        "unique-1": 17,
        "entropy-1": 4.323856189774723,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.1911063109464317,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": 0.02555597707498716,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.186704345910023,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": 0.12336199461765371,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": 0.02961067210860201,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2222222222222222,
            "3": 0.7222222222222222
        },
        "rouge1": {
            "precision": 0.73913,
            "recall": 0.67555,
            "fmeasure": 0.70263
        },
        "rouge2": {
            "precision": 0.48485,
            "recall": 0.44444,
            "fmeasure": 0.46154
        },
        "rougeL": {
            "precision": 0.56522,
            "recall": 0.52126,
            "fmeasure": 0.54033
        },
        "rougeLsum": {
            "precision": 0.56522,
            "recall": 0.52126,
            "fmeasure": 0.54033
        },
        "nist": 3.54447334645434,
        "bleu": 43.74233,
        "meteor": 0.3976506968830688,
        "bleurt": 0.12827,
        "nubia": {
            "semantic_relation": 4.28808,
            "contradiction": 23.98389,
            "irrelevancy": 30.44338,
            "logical_agreement": 45.57273,
            "grammar_ref": 3.59602,
            "grammar_hyp": 3.51436,
            "nubia_score": 0.78335
        },
        "bertscore": {
            "precision": 0.94958,
            "recall": 0.9484,
            "f1": 0.94899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.85606,
            "fmeasure": 0.82971
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.48485,
            "fmeasure": 0.46898
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.70707,
            "fmeasure": 0.68599
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.70707,
            "fmeasure": 0.68599
        },
        "nist": 2.4668767346044658,
        "bleu": 14.33511,
        "meteor": 0.42425155709994045,
        "bleurt": 0.52771,
        "nubia": {
            "semantic_relation": 4.83575,
            "contradiction": 3.55741,
            "irrelevancy": 2.88328,
            "logical_agreement": 93.5593,
            "grammar_ref": 6.27756,
            "grammar_hyp": 5.38569,
            "nubia_score": 0.9522
        },
        "bertscore": {
            "precision": 0.92887,
            "recall": 0.95663,
            "f1": 0.94255
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.79259,
            "fmeasure": 0.74127
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.60185,
            "fmeasure": 0.54581
        },
        "rougeL": {
            "precision": 0.69697,
            "recall": 0.79259,
            "fmeasure": 0.74127
        },
        "rougeLsum": {
            "precision": 0.69697,
            "recall": 0.79259,
            "fmeasure": 0.74127
        },
        "nist": 3.6507397221770597,
        "bleu": 54.91005,
        "meteor": 0.4623158007404865,
        "bleurt": 0.77475,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29724,
            "irrelevancy": 0.41998,
            "logical_agreement": 99.28278,
            "grammar_ref": 4.16465,
            "grammar_hyp": 3.71754,
            "nubia_score": 0.99015
        },
        "bertscore": {
            "precision": 0.95439,
            "recall": 0.96512,
            "f1": 0.95836
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6
        },
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.48352,
            "fmeasure": 0.60606
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.24359,
            "fmeasure": 0.31053
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.48352,
            "fmeasure": 0.60606
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.48352,
            "fmeasure": 0.60606
        },
        "nist": 0.8068784845472243,
        "bleu": 24.385,
        "meteor": 0.3281920906693159,
        "bleurt": 0.25554,
        "nubia": {
            "semantic_relation": 3.98324,
            "contradiction": 0.24641,
            "irrelevancy": 0.49048,
            "logical_agreement": 99.26311,
            "grammar_ref": 4.1674,
            "grammar_hyp": 6.15583,
            "nubia_score": 0.50852
        },
        "bertscore": {
            "precision": 0.95553,
            "recall": 0.87245,
            "f1": 0.9121
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 16,
        "unique-1": 9,
        "entropy-1": 3.8868421881310122,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 18,
        "unique-2": 14,
        "entropy-2": 4.095795255000932,
        "cond_entropy-2": 0.18150945892357126,
        "distinct-3": 0.9,
        "vocab_size-3": 18,
        "unique-3": 16,
        "entropy-3": 4.1219280948873624,
        "cond_entropy-3": 0.06249647625006499,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.6841837197791887,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.8365916681089787,
        "cond_entropy-2-nopunct": 0.16771287889736514,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.75,
        "cond_entropy-3-nopunct": -0.04492500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.70238,
            "recall": 0.72812,
            "fmeasure": 0.66733
        },
        "rouge2": {
            "precision": 0.41506,
            "recall": 0.41788,
            "fmeasure": 0.38348
        },
        "rougeL": {
            "precision": 0.64683,
            "recall": 0.69053,
            "fmeasure": 0.62277
        },
        "rougeLsum": {
            "precision": 0.64683,
            "recall": 0.69053,
            "fmeasure": 0.62277
        },
        "nist": 3.0485456157685302,
        "bleu": 23.47677,
        "meteor": 0.4191330404694759,
        "bleurt": 0.08562,
        "nubia": {
            "semantic_relation": 3.87558,
            "contradiction": 12.08955,
            "irrelevancy": 34.48055,
            "logical_agreement": 53.4299,
            "grammar_ref": 4.07172,
            "grammar_hyp": 5.16373,
            "nubia_score": 0.54334
        },
        "bertscore": {
            "precision": 0.85457,
            "recall": 0.93197,
            "f1": 0.88544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.45454545454545453,
            "2": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.34615,
            "recall": 0.32986,
            "fmeasure": 0.33229
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.22917,
            "fmeasure": 0.23519
        },
        "rougeL": {
            "precision": 0.34615,
            "recall": 0.32986,
            "fmeasure": 0.33229
        },
        "rougeLsum": {
            "precision": 0.34615,
            "recall": 0.32986,
            "fmeasure": 0.33229
        },
        "nist": 2.4773793516266975,
        "bleu": 31.61488,
        "meteor": 0.2598761232009657,
        "bleurt": -0.83128,
        "nubia": {
            "semantic_relation": 2.22173,
            "contradiction": 2.12024,
            "irrelevancy": 96.59713,
            "logical_agreement": 1.28264,
            "grammar_ref": 4.24724,
            "grammar_hyp": 4.91381,
            "nubia_score": 0.19995
        },
        "bertscore": {
            "precision": 0.83447,
            "recall": 0.85749,
            "f1": 0.84582
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 16,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.5625,
        "vocab_size-1": 9,
        "unique-1": 2,
        "entropy-1": 3.125,
        "distinct-2": 0.5714285714285714,
        "vocab_size-2": 8,
        "unique-2": 2,
        "entropy-2": 2.950212064914747,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 0.5833333333333334,
        "vocab_size-3": 7,
        "unique-3": 2,
        "entropy-3": 2.7516291673878226,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.5714285714285714,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 2.950212064914747,
        "distinct-2-nopunct": 0.5833333333333334,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 2,
        "entropy-2-nopunct": 2.7516291673878226,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 0.6,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 2.5219280948873624,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.5263157894736842
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.53693,
            "fmeasure": 0.69324
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.38333,
            "fmeasure": 0.50298
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.47443,
            "fmeasure": 0.60628
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.47443,
            "fmeasure": 0.60628
        },
        "nist": 0.8740071123203411,
        "bleu": 13.929,
        "meteor": 0.30484012701405605,
        "bleurt": -0.13453,
        "nubia": {
            "semantic_relation": 4.66282,
            "contradiction": 0.53182,
            "irrelevancy": 17.08868,
            "logical_agreement": 82.3795,
            "grammar_ref": 4.70595,
            "grammar_hyp": 7.70973,
            "nubia_score": 0.52613
        },
        "bertscore": {
            "precision": 0.93983,
            "recall": 0.85517,
            "f1": 0.89464
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 4.021928094887363,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 18,
        "unique-2": 17,
        "entropy-2": 4.142664355548846,
        "cond_entropy-2": 0.13652573434569693,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": 0.033108599109837954,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.9321380397593733,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.058813890331201,
        "cond_entropy-2-nopunct": 0.08866415466539351,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.023638630780208267,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.4697,
            "recall": 0.61905,
            "fmeasure": 0.5309
        },
        "rouge2": {
            "precision": 0.31746,
            "recall": 0.43333,
            "fmeasure": 0.36423
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.60317,
            "fmeasure": 0.5154
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.60317,
            "fmeasure": 0.5154
        },
        "nist": 2.8281769197299393,
        "bleu": 29.53505,
        "meteor": 0.2689082197032768,
        "bleurt": -0.28683,
        "nubia": {
            "semantic_relation": 3.10154,
            "contradiction": 49.73315,
            "irrelevancy": 45.32056,
            "logical_agreement": 4.94629,
            "grammar_ref": 3.44293,
            "grammar_hyp": 3.72319,
            "nubia_score": 0.4406
        },
        "bertscore": {
            "precision": 0.78797,
            "recall": 0.90558,
            "f1": 0.8347
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.2857142857142857
        },
        "rouge1": {
            "precision": 0.25641,
            "recall": 0.32576,
            "fmeasure": 0.28571
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.20513,
            "recall": 0.26515,
            "fmeasure": 0.23016
        },
        "rougeLsum": {
            "precision": 0.20513,
            "recall": 0.26515,
            "fmeasure": 0.23016
        },
        "nist": 1.1440519138669696,
        "bleu": 4.36858,
        "meteor": 0.16356877323420072,
        "bleurt": -0.57569,
        "nubia": {
            "semantic_relation": 2.37182,
            "contradiction": 0.90816,
            "irrelevancy": 94.69949,
            "logical_agreement": 4.39234,
            "grammar_ref": 5.51883,
            "grammar_hyp": 4.63127,
            "nubia_score": 0.25399
        },
        "bertscore": {
            "precision": 0.77189,
            "recall": 0.76714,
            "f1": 0.76951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "t5-small/totto_test",
        "N": 5,
        "total_length": 93,
        "mean_pred_length": 18.6,
        "std_pred_length": 6.151422599691879,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 30,
        "distinct-1": 0.6559139784946236,
        "vocab_size-1": 61,
        "unique-1": 45,
        "entropy-1": 5.660141542700998,
        "distinct-2": 0.8977272727272727,
        "vocab_size-2": 79,
        "unique-2": 70,
        "entropy-2": 6.254886164091851,
        "cond_entropy-2": 0.5906559718439368,
        "distinct-3": 0.927710843373494,
        "vocab_size-3": 77,
        "unique-3": 71,
        "entropy-3": 6.23046111809392,
        "cond_entropy-3": -0.03619941620603524,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 3.7094473981982814,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7432432432432432,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.599731534834849,
        "distinct-2-nopunct": 0.9130434782608695,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.934611413299903,
        "cond_entropy-2-nopunct": 0.3500771125805776,
        "distinct-3-nopunct": 0.921875,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.84375,
        "cond_entropy-3-nopunct": -0.1085244567781691,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5294117647058824,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.76085,
            "recall": 0.72302,
            "fmeasure": 0.71691
        },
        "rouge2": {
            "precision": 0.56095,
            "recall": 0.52369,
            "fmeasure": 0.52508
        },
        "rougeL": {
            "precision": 0.63721,
            "recall": 0.5874,
            "fmeasure": 0.59271
        },
        "rougeLsum": {
            "precision": 0.63721,
            "recall": 0.5874,
            "fmeasure": 0.59271
        },
        "nist": 3.894566200628854,
        "bleu": 40.87024,
        "meteor": 0.3533128128595491,
        "bleurt": -0.10064,
        "nubia": {
            "semantic_relation": 3.86672,
            "contradiction": 13.41584,
            "irrelevancy": 38.63955,
            "logical_agreement": 47.9446,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.93992,
            "nubia_score": 0.59749
        },
        "bertscore": {
            "precision": 0.91583,
            "recall": 0.91113,
            "f1": 0.91062
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.72222,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.48718,
            "recall": 0.57576,
            "fmeasure": 0.52778
        },
        "rougeL": {
            "precision": 0.61905,
            "recall": 0.72222,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.61905,
            "recall": 0.72222,
            "fmeasure": 0.66667
        },
        "nist": 2.6773252639090703,
        "bleu": 46.04629,
        "meteor": 0.43279677851530485,
        "bleurt": 0.03786,
        "nubia": {
            "semantic_relation": 3.82733,
            "contradiction": 0.10712,
            "irrelevancy": 99.55367,
            "logical_agreement": 0.33921,
            "grammar_ref": 5.64121,
            "grammar_hyp": 4.60274,
            "nubia_score": 0.73018
        },
        "bertscore": {
            "precision": 0.90047,
            "recall": 0.92797,
            "f1": 0.91402
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.257756064128516,
        "distinct-2": 0.96,
        "vocab_size-2": 24,
        "unique-2": 23,
        "entropy-2": 4.5638561897747225,
        "cond_entropy-2": 0.26040897177786365,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": 0.024439644279765037,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.229871195093384,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728205,
        "cond_entropy-2-nopunct": 0.07995716264584411,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": 0.02812389937955851,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5384615384615384
        },
        "rouge1": {
            "precision": 0.30435,
            "recall": 0.5,
            "fmeasure": 0.37838
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.15385,
            "fmeasure": 0.11429
        },
        "rougeL": {
            "precision": 0.28986,
            "recall": 0.43452,
            "fmeasure": 0.34742
        },
        "rougeLsum": {
            "precision": 0.28986,
            "recall": 0.43452,
            "fmeasure": 0.34742
        },
        "nist": 1.0527825752852509,
        "bleu": 3.95174,
        "meteor": 0.22233204780669688,
        "bleurt": -0.95575,
        "nubia": {
            "semantic_relation": 2.1991,
            "contradiction": 89.52659,
            "irrelevancy": 9.42768,
            "logical_agreement": 1.04574,
            "grammar_ref": 5.0526,
            "grammar_hyp": 6.60946,
            "nubia_score": 0.17757
        },
        "bertscore": {
            "precision": 0.75751,
            "recall": 0.81184,
            "f1": 0.78373
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 1.0,
        "median_pred_length": 18.0,
        "min_pred_length": 17,
        "max_pred_length": 19,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 32,
        "unique-1": 29,
        "entropy-1": 4.926733681937769,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.11621100163636432,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.08746284125033942,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9666666666666667,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.840223928941852,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": -0.028107102122342922,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.8076923076923077
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.78485,
            "fmeasure": 0.76276
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.51429,
            "fmeasure": 0.52496
        },
        "rougeL": {
            "precision": 0.60714,
            "recall": 0.60303,
            "fmeasure": 0.60276
        },
        "rougeLsum": {
            "precision": 0.60714,
            "recall": 0.60303,
            "fmeasure": 0.60276
        },
        "nist": 3.9938937487348176,
        "bleu": 57.3494,
        "meteor": 0.45739744634896373,
        "bleurt": 0.61013,
        "nubia": {
            "semantic_relation": 4.79407,
            "contradiction": 0.18174,
            "irrelevancy": 46.63794,
            "logical_agreement": 53.18032,
            "grammar_ref": 3.76682,
            "grammar_hyp": 3.67842,
            "nubia_score": 0.92521
        },
        "bertscore": {
            "precision": 0.93183,
            "recall": 0.94191,
            "f1": 0.9367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.6363636363636364,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.73215889136457,
        "distinct-2": 0.75,
        "vocab_size-2": 15,
        "unique-2": 10,
        "entropy-2": 3.821928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 0.7777777777777778,
        "vocab_size-3": 14,
        "unique-3": 10,
        "entropy-3": 3.7254805569978675,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.65,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.621928094887362,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.7254805569978675,
        "cond_entropy-2-nopunct": 0.07021912877717248,
        "distinct-3-nopunct": 0.8125,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.625,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.490498678107601,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.92254,
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "nist": 2.4156844010247407,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.6432,
        "nubia": {
            "semantic_relation": 4.6374,
            "contradiction": 0.2158,
            "irrelevancy": 0.51722,
            "logical_agreement": 99.26698,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.20485,
            "nubia_score": 0.86208
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.875
        },
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.66923,
            "fmeasure": 0.61706
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.59722,
            "fmeasure": 0.54167
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.55385,
            "fmeasure": 0.50167
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.55385,
            "fmeasure": 0.50167
        },
        "nist": 3.203180067629563,
        "bleu": 56.59119,
        "meteor": 0.4181773527712433,
        "bleurt": -0.49532,
        "nubia": {
            "semantic_relation": 2.88341,
            "contradiction": 10.49948,
            "irrelevancy": 89.03214,
            "logical_agreement": 0.46838,
            "grammar_ref": 4.19915,
            "grammar_hyp": 3.87986,
            "nubia_score": 0.36919
        },
        "bertscore": {
            "precision": 0.91903,
            "recall": 0.95073,
            "f1": 0.93461
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 1.0,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 10,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.7254805569978675,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.20507499855768768,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.19264507794239588,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.23592635062903275,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644807,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.2,
            "3": 0.2608695652173913
        },
        "rouge1": {
            "precision": 0.72487,
            "recall": 0.34264,
            "fmeasure": 0.42865
        },
        "rouge2": {
            "precision": 0.36806,
            "recall": 0.21279,
            "fmeasure": 0.25079
        },
        "rougeL": {
            "precision": 0.50794,
            "recall": 0.28251,
            "fmeasure": 0.33472
        },
        "rougeLsum": {
            "precision": 0.50794,
            "recall": 0.28251,
            "fmeasure": 0.33472
        },
        "nist": 0.13015426079428238,
        "bleu": 8.93218,
        "meteor": 0.12858311954600093,
        "bleurt": -0.48587,
        "nubia": {
            "semantic_relation": 2.77193,
            "contradiction": 0.31517,
            "irrelevancy": 82.14487,
            "logical_agreement": 17.53997,
            "grammar_ref": 4.39403,
            "grammar_hyp": 4.8054,
            "nubia_score": 0.37425
        },
        "bertscore": {
            "precision": 0.84682,
            "recall": 0.67505,
            "f1": 0.74669
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.75,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "nist": 2.659005565642719,
        "bleu": 32.64971,
        "meteor": 0.9051319272478866,
        "bleurt": 0.74939,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.4082,
            "irrelevancy": 0.76883,
            "logical_agreement": 98.82297,
            "grammar_ref": 4.6206,
            "grammar_hyp": 4.37368,
            "nubia_score": 0.96322
        },
        "bertscore": {
            "precision": 0.94619,
            "recall": 0.97387,
            "f1": 0.95983
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.25
        },
        "rouge1": {
            "precision": 0.40625,
            "recall": 0.34058,
            "fmeasure": 0.36642
        },
        "rouge2": {
            "precision": 0.23333,
            "recall": 0.19805,
            "fmeasure": 0.21156
        },
        "rougeL": {
            "precision": 0.34375,
            "recall": 0.28551,
            "fmeasure": 0.30852
        },
        "rougeLsum": {
            "precision": 0.34375,
            "recall": 0.28551,
            "fmeasure": 0.30852
        },
        "nist": 2.3989448031200795,
        "bleu": 27.09821,
        "meteor": 0.24404598750143366,
        "bleurt": -0.55466,
        "nubia": {
            "semantic_relation": 3.1743,
            "contradiction": 2.84013,
            "irrelevancy": 82.74291,
            "logical_agreement": 14.41696,
            "grammar_ref": 5.51157,
            "grammar_hyp": 6.04328,
            "nubia_score": 0.30607
        },
        "bertscore": {
            "precision": 0.8395,
            "recall": 0.84824,
            "f1": 0.83214
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 30,
        "mean_pred_length": 30.0,
        "std_pred_length": 0.0,
        "median_pred_length": 30.0,
        "min_pred_length": 30,
        "max_pred_length": 30,
        "distinct-1": 0.6333333333333333,
        "vocab_size-1": 19,
        "unique-1": 10,
        "entropy-1": 4.12323142879762,
        "distinct-2": 0.7241379310344828,
        "vocab_size-2": 21,
        "unique-2": 13,
        "entropy-2": 4.306256857196537,
        "cond_entropy-2": 0.17556539966825835,
        "distinct-3": 0.75,
        "vocab_size-3": 21,
        "unique-3": 14,
        "entropy-3": 4.307354922057605,
        "cond_entropy-3": -0.014911787355682124,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 27.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 27,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 4.060262039120378,
        "distinct-2-nopunct": 0.7307692307692307,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 4.161978179679553,
        "cond_entropy-2-nopunct": 0.0899709660608338,
        "distinct-3-nopunct": 0.76,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 4.163856189774723,
        "cond_entropy-3-nopunct": -0.01658352836636751,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.5925925925925926
        },
        "rouge1": {
            "precision": 0.76543,
            "recall": 0.63258,
            "fmeasure": 0.69266
        },
        "rouge2": {
            "precision": 0.60256,
            "recall": 0.49462,
            "fmeasure": 0.54325
        },
        "rougeL": {
            "precision": 0.62963,
            "recall": 0.52588,
            "fmeasure": 0.57307
        },
        "rougeLsum": {
            "precision": 0.62963,
            "recall": 0.52588,
            "fmeasure": 0.57307
        },
        "nist": 3.042327799340959,
        "bleu": 40.79476,
        "meteor": 0.3284849578595666,
        "bleurt": 0.03714,
        "nubia": {
            "semantic_relation": 2.95562,
            "contradiction": 95.63455,
            "irrelevancy": 0.98787,
            "logical_agreement": 3.37758,
            "grammar_ref": 3.7645,
            "grammar_hyp": 2.90759,
            "nubia_score": 0.45984
        },
        "bertscore": {
            "precision": 0.9472,
            "recall": 0.84209,
            "f1": 0.89156
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964164,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.69378,
            "fmeasure": 0.67937
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.6,
            "fmeasure": 0.48
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.81818,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.81818,
            "fmeasure": 0.66667
        },
        "nist": 2.7982431154475216,
        "bleu": 12.41952,
        "meteor": 0.35241908760868335,
        "bleurt": 0.26501,
        "nubia": {
            "semantic_relation": 4.88207,
            "contradiction": 0.42175,
            "irrelevancy": 0.47193,
            "logical_agreement": 99.10632,
            "grammar_ref": 3.90557,
            "grammar_hyp": 3.88204,
            "nubia_score": 0.86706
        },
        "bertscore": {
            "precision": 0.90748,
            "recall": 0.93854,
            "f1": 0.92036
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rouge2": {
            "precision": 0.88889,
            "recall": 0.8,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "nist": 4.548645758111165,
        "bleu": 100.0,
        "meteor": 0.5161210442123606,
        "bleurt": 0.7198,
        "nubia": {
            "semantic_relation": 4.65439,
            "contradiction": 0.55881,
            "irrelevancy": 1.76619,
            "logical_agreement": 97.675,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.54703,
            "nubia_score": 0.85279
        },
        "bertscore": {
            "precision": 0.98951,
            "recall": 0.9715,
            "f1": 0.98042
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.86111,
            "fmeasure": 0.71212
        },
        "rouge2": {
            "precision": 0.37037,
            "recall": 0.59394,
            "fmeasure": 0.44762
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.72222,
            "fmeasure": 0.59848
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.72222,
            "fmeasure": 0.59848
        },
        "nist": 3.2231086688195565,
        "bleu": 21.83418,
        "meteor": 0.42919650333815856,
        "bleurt": 0.10378,
        "nubia": {
            "semantic_relation": 4.37388,
            "contradiction": 9.95059,
            "irrelevancy": 70.10601,
            "logical_agreement": 19.94339,
            "grammar_ref": 5.75818,
            "grammar_hyp": 5.17175,
            "nubia_score": 0.73579
        },
        "bertscore": {
            "precision": 0.86422,
            "recall": 0.94535,
            "f1": 0.90005
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.9375
        },
        "rouge1": {
            "precision": 0.92105,
            "recall": 0.875,
            "fmeasure": 0.89744
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.73684,
            "fmeasure": 0.75676
        },
        "rougeL": {
            "precision": 0.92105,
            "recall": 0.875,
            "fmeasure": 0.89744
        },
        "rougeLsum": {
            "precision": 0.92105,
            "recall": 0.875,
            "fmeasure": 0.89744
        },
        "nist": 4.140728366791319,
        "bleu": 74.70143,
        "meteor": 0.5349776347145982,
        "bleurt": 0.60943,
        "nubia": {
            "semantic_relation": 4.89024,
            "contradiction": 0.23433,
            "irrelevancy": 0.50131,
            "logical_agreement": 99.26436,
            "grammar_ref": 4.55046,
            "grammar_hyp": 4.62026,
            "nubia_score": 0.92817
        },
        "bertscore": {
            "precision": 0.97682,
            "recall": 0.97908,
            "f1": 0.97794
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.45076,
            "fmeasure": 0.49755
        },
        "rouge2": {
            "precision": 0.31818,
            "recall": 0.25325,
            "fmeasure": 0.27557
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.36364,
            "fmeasure": 0.39706
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.36364,
            "fmeasure": 0.39706
        },
        "nist": 2.2987229494932637,
        "bleu": 38.50323,
        "meteor": 0.3516385862170224,
        "bleurt": -0.31468,
        "nubia": {
            "semantic_relation": 3.3196,
            "contradiction": 0.57329,
            "irrelevancy": 84.70246,
            "logical_agreement": 14.72424,
            "grammar_ref": 4.87259,
            "grammar_hyp": 4.83101,
            "nubia_score": 0.42022
        },
        "bertscore": {
            "precision": 0.88627,
            "recall": 0.88375,
            "f1": 0.885
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.8141,
            "fmeasure": 0.67241
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.47619,
            "fmeasure": 0.38721
        },
        "rougeL": {
            "precision": 0.47917,
            "recall": 0.5,
            "fmeasure": 0.47893
        },
        "rougeLsum": {
            "precision": 0.47917,
            "recall": 0.5,
            "fmeasure": 0.47893
        },
        "nist": 3.80120071263696,
        "bleu": 24.60137,
        "meteor": 0.431176672844936,
        "bleurt": 0.06146,
        "nubia": {
            "semantic_relation": 4.01034,
            "contradiction": 62.88661,
            "irrelevancy": 5.37352,
            "logical_agreement": 31.73987,
            "grammar_ref": 4.62626,
            "grammar_hyp": 3.69967,
            "nubia_score": 0.62898
        },
        "bertscore": {
            "precision": 0.92156,
            "recall": 0.94252,
            "f1": 0.93192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.026442737724814768,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.35714,
            "recall": 0.72917,
            "fmeasure": 0.47727
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.37143,
            "fmeasure": 0.21667
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.52083,
            "fmeasure": 0.33636
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.52083,
            "fmeasure": 0.33636
        },
        "nist": 1.248775664385338,
        "bleu": 13.78593,
        "meteor": 0.25,
        "bleurt": -0.81379,
        "nubia": {
            "semantic_relation": 3.02886,
            "contradiction": 3.22808,
            "irrelevancy": 96.12031,
            "logical_agreement": 0.65162,
            "grammar_ref": 7.18676,
            "grammar_hyp": 5.65478,
            "nubia_score": 0.39155
        },
        "bertscore": {
            "precision": 0.73206,
            "recall": 0.86392,
            "f1": 0.79254
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "t5-small/totto_test",
        "N": 91,
        "total_length": 1408,
        "mean_pred_length": 15.472527472527473,
        "std_pred_length": 4.651221414300727,
        "median_pred_length": 16.0,
        "min_pred_length": 4,
        "max_pred_length": 27,
        "distinct-1": 0.39985795454545453,
        "vocab_size-1": 563,
        "unique-1": 448,
        "entropy-1": 7.61276014308906,
        "distinct-2": 0.7296886864085042,
        "vocab_size-2": 961,
        "unique-2": 860,
        "entropy-2": 9.462949067800173,
        "cond_entropy-2": 1.623948215151222,
        "distinct-3": 0.8515497553017944,
        "vocab_size-3": 1044,
        "unique-3": 989,
        "entropy-3": 9.78159485497851,
        "cond_entropy-3": 0.3191618509718688,
        "total_length-nopunct": 1210,
        "mean_pred_length-nopunct": 13.296703296703297,
        "std_pred_length-nopunct": 4.093668403752219,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.46033057851239667,
        "vocab_size-1-nopunct": 557,
        "unique-1-nopunct": 447,
        "entropy-1-nopunct": 7.870431468009632,
        "distinct-2-nopunct": 0.7524575513851653,
        "vocab_size-2-nopunct": 842,
        "unique-2-nopunct": 762,
        "entropy-2-nopunct": 9.29866792373361,
        "cond_entropy-2-nopunct": 1.5053432907095374,
        "distinct-3-nopunct": 0.8657587548638133,
        "vocab_size-3-nopunct": 890,
        "unique-3-nopunct": 846,
        "entropy-3-nopunct": 9.580322623361287,
        "cond_entropy-3-nopunct": 0.3072181501520183,
        "msttr-100": 0.68786,
        "msttr-100_nopunct": 0.72667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25675675675675674,
            "2": 0.45112781954887216,
            "3": 0.7184873949579832
        },
        "rouge1": {
            "precision": 0.76183,
            "recall": 0.70175,
            "fmeasure": 0.71823
        },
        "rouge2": {
            "precision": 0.5318,
            "recall": 0.47926,
            "fmeasure": 0.49498
        },
        "rougeL": {
            "precision": 0.6677,
            "recall": 0.61345,
            "fmeasure": 0.62869
        },
        "rougeLsum": {
            "precision": 0.6677,
            "recall": 0.61345,
            "fmeasure": 0.62869
        },
        "nist": 6.921310356026368,
        "bleu": 43.9605,
        "meteor": 0.3689141448561265,
        "bleurt": 0.21062,
        "nubia": {
            "semantic_relation": 4.09977,
            "contradiction": 8.38287,
            "irrelevancy": 28.40272,
            "logical_agreement": 63.21442,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.4493,
            "nubia_score": 0.70958
        },
        "bertscore": {
            "precision": 0.92327,
            "recall": 0.91201,
            "f1": 0.9163
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4166666666666667
        },
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.46154,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.25,
            "fmeasure": 0.27273
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.46154,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.46154,
            "fmeasure": 0.5
        },
        "nist": 1.5539932675905856,
        "bleu": 8.93095,
        "meteor": 0.2843208211222033,
        "bleurt": 0.319,
        "nubia": {
            "semantic_relation": 4.24959,
            "contradiction": 0.78355,
            "irrelevancy": 96.61824,
            "logical_agreement": 2.59821,
            "grammar_ref": 3.76485,
            "grammar_hyp": 3.89732,
            "nubia_score": 0.818
        },
        "bertscore": {
            "precision": 0.90358,
            "recall": 0.88891,
            "f1": 0.89618
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 4.5,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.8275862068965517,
        "vocab_size-1": 24,
        "unique-1": 20,
        "entropy-1": 4.487122805397798,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.2211615997086175,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.363713275750188,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.24930976183687525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.3333333333333333,
            "3": 0.7058823529411765
        },
        "rouge1": {
            "precision": 0.62731,
            "recall": 0.61717,
            "fmeasure": 0.61505
        },
        "rouge2": {
            "precision": 0.27731,
            "recall": 0.30796,
            "fmeasure": 0.28876
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.54034,
            "fmeasure": 0.52758
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.54034,
            "fmeasure": 0.52758
        },
        "nist": 3.724767592486685,
        "bleu": 27.94117,
        "meteor": 0.3689360663103473,
        "bleurt": 0.46857,
        "nubia": {
            "semantic_relation": 4.14648,
            "contradiction": 39.23377,
            "irrelevancy": 6.58343,
            "logical_agreement": 54.18279,
            "grammar_ref": 4.56502,
            "grammar_hyp": 4.98194,
            "nubia_score": 0.70746
        },
        "bertscore": {
            "precision": 0.90369,
            "recall": 0.918,
            "f1": 0.91079
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 3.5,
        "median_pred_length": 10.5,
        "min_pred_length": 7,
        "max_pred_length": 14,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 14,
        "unique-1": 7,
        "entropy-1": 3.7256507561120933,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 17,
        "unique-2": 15,
        "entropy-2": 4.03740119765411,
        "cond_entropy-2": 0.2766627222437725,
        "distinct-3": 0.9411764705882353,
        "vocab_size-3": 16,
        "unique-3": 15,
        "entropy-3": 3.969815782426811,
        "cond_entropy-3": -0.0428176133697167,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.4992275471326932,
        "distinct-2-nopunct": 0.8666666666666667,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.640223928941851,
        "cond_entropy-2-nopunct": 0.08609442102484585,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.5465935642949384,
        "cond_entropy-3-nopunct": -0.12952780054434962,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.5789473684210527
        },
        "rouge1": {
            "precision": 0.79545,
            "recall": 0.59827,
            "fmeasure": 0.67164
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.39001,
            "fmeasure": 0.44024
        },
        "rougeL": {
            "precision": 0.76515,
            "recall": 0.56797,
            "fmeasure": 0.6389
        },
        "rougeLsum": {
            "precision": 0.76515,
            "recall": 0.56797,
            "fmeasure": 0.6389
        },
        "nist": 2.090899520358262,
        "bleu": 13.81294,
        "meteor": 0.29548996030610203,
        "bleurt": -0.02323,
        "nubia": {
            "semantic_relation": 3.88216,
            "contradiction": 9.96123,
            "irrelevancy": 36.5774,
            "logical_agreement": 53.46137,
            "grammar_ref": 6.00658,
            "grammar_hyp": 6.62327,
            "nubia_score": 0.53861
        },
        "bertscore": {
            "precision": 0.93512,
            "recall": 0.87287,
            "f1": 0.89847
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.75,
        "vocab_size-1": 9,
        "unique-1": 6,
        "entropy-1": 3.0849625007211556,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 9,
        "unique-2": 7,
        "entropy-2": 3.095795255000934,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 0.9,
        "vocab_size-3": 9,
        "unique-3": 8,
        "entropy-3": 3.121928094887362,
        "cond_entropy-3": 0.06249647625006499,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.913977073182752,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.9219280948873623,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.94770277922009,
        "cond_entropy-3-nopunct": 0.07021912877717243,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.60606,
            "recall": 0.58889,
            "fmeasure": 0.59627
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.52189,
            "fmeasure": 0.50961
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.56667,
            "fmeasure": 0.55487
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.56667,
            "fmeasure": 0.55487
        },
        "nist": 2.531408542555593,
        "bleu": 44.83387,
        "meteor": 0.3235935884349307,
        "bleurt": 0.10426,
        "nubia": {
            "semantic_relation": 3.89686,
            "contradiction": 0.44512,
            "irrelevancy": 0.98488,
            "logical_agreement": 98.57,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.37807,
            "nubia_score": 0.66619
        },
        "bertscore": {
            "precision": 0.94549,
            "recall": 0.87316,
            "f1": 0.90789
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.0,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.8125,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.04022392894185195,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.606739354015323,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.048968687611256,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.5666666666666667
        },
        "rouge1": {
            "precision": 0.77206,
            "recall": 0.59206,
            "fmeasure": 0.66795
        },
        "rouge2": {
            "precision": 0.50568,
            "recall": 0.35345,
            "fmeasure": 0.41333
        },
        "rougeL": {
            "precision": 0.53676,
            "recall": 0.41032,
            "fmeasure": 0.46344
        },
        "rougeLsum": {
            "precision": 0.53676,
            "recall": 0.41032,
            "fmeasure": 0.46344
        },
        "nist": 1.9609264729871976,
        "bleu": 13.66216,
        "meteor": 0.2732274166719904,
        "bleurt": -0.00188,
        "nubia": {
            "semantic_relation": 4.44354,
            "contradiction": 3.54639,
            "irrelevancy": 43.76232,
            "logical_agreement": 52.69129,
            "grammar_ref": 4.16263,
            "grammar_hyp": 4.32482,
            "nubia_score": 0.76018
        },
        "bertscore": {
            "precision": 0.92532,
            "recall": 0.88489,
            "f1": 0.90378
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.7
        },
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.52807,
            "fmeasure": 0.5543
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.39286,
            "fmeasure": 0.41216
        },
        "rougeL": {
            "precision": 0.44118,
            "recall": 0.41444,
            "fmeasure": 0.42609
        },
        "rougeLsum": {
            "precision": 0.44118,
            "recall": 0.41444,
            "fmeasure": 0.42609
        },
        "nist": 1.8947698594162619,
        "bleu": 20.06882,
        "meteor": 0.41292834530082007,
        "bleurt": -0.33276,
        "nubia": {
            "semantic_relation": 3.4,
            "contradiction": 0.28596,
            "irrelevancy": 89.18967,
            "logical_agreement": 10.52438,
            "grammar_ref": 3.66593,
            "grammar_hyp": 3.16667,
            "nubia_score": 0.60587
        },
        "bertscore": {
            "precision": 0.89229,
            "recall": 0.88091,
            "f1": 0.88656
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.02496284125033941,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.74537,
            "fmeasure": 0.61
        },
        "rouge2": {
            "precision": 0.28889,
            "recall": 0.26993,
            "fmeasure": 0.2624
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.4537,
            "fmeasure": 0.36667
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.4537,
            "fmeasure": 0.36667
        },
        "nist": 3.944482673240674,
        "bleu": 37.29661,
        "meteor": 0.36960110868892654,
        "bleurt": -0.12255,
        "nubia": {
            "semantic_relation": 4.13128,
            "contradiction": 0.11189,
            "irrelevancy": 65.07667,
            "logical_agreement": 34.81143,
            "grammar_ref": 4.62828,
            "grammar_hyp": 4.22832,
            "nubia_score": 0.74845
        },
        "bertscore": {
            "precision": 0.90166,
            "recall": 0.89658,
            "f1": 0.85849
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "t5-small/totto_test",
        "N": 4,
        "total_length": 69,
        "mean_pred_length": 17.25,
        "std_pred_length": 8.554969316134336,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.6811594202898551,
        "vocab_size-1": 47,
        "unique-1": 37,
        "entropy-1": 5.249667573751498,
        "distinct-2": 0.9076923076923077,
        "vocab_size-2": 59,
        "unique-2": 54,
        "entropy-2": 5.826138774533636,
        "cond_entropy-2": 0.5062470089683866,
        "distinct-3": 0.9672131147540983,
        "vocab_size-3": 59,
        "unique-3": 57,
        "entropy-3": 5.865163567071081,
        "cond_entropy-3": 0.05189227047153767,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 5.80409338312195,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7719298245614035,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.278334918121988,
        "distinct-2-nopunct": 0.9245283018867925,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.562733897918601,
        "cond_entropy-2-nopunct": 0.32625219459229393,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": 0.0654605630655494,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6666666666666666,
            "3": 0.8695652173913043
        },
        "rouge1": {
            "precision": 0.64525,
            "recall": 0.79137,
            "fmeasure": 0.68952
        },
        "rouge2": {
            "precision": 0.29217,
            "recall": 0.35809,
            "fmeasure": 0.31176
        },
        "rougeL": {
            "precision": 0.57844,
            "recall": 0.67501,
            "fmeasure": 0.59845
        },
        "rougeLsum": {
            "precision": 0.57844,
            "recall": 0.67501,
            "fmeasure": 0.59845
        },
        "nist": 3.9826883791956265,
        "bleu": 26.32387,
        "meteor": 0.38375848713485455,
        "bleurt": 0.26536,
        "nubia": {
            "semantic_relation": 4.13046,
            "contradiction": 1.43153,
            "irrelevancy": 28.96979,
            "logical_agreement": 69.59868,
            "grammar_ref": 4.9362,
            "grammar_hyp": 4.17092,
            "nubia_score": 0.7033
        },
        "bertscore": {
            "precision": 0.90705,
            "recall": 0.93985,
            "f1": 0.91452
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.65385,
            "recall": 0.5881,
            "fmeasure": 0.61905
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.22527,
            "fmeasure": 0.23692
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.5881,
            "fmeasure": 0.61905
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.5881,
            "fmeasure": 0.61905
        },
        "nist": 2.708910332186929,
        "bleu": 13.97899,
        "meteor": 0.33280082083577,
        "bleurt": 0.3099,
        "nubia": {
            "semantic_relation": 4.77426,
            "contradiction": 0.19061,
            "irrelevancy": 2.10572,
            "logical_agreement": 97.70367,
            "grammar_ref": 5.03823,
            "grammar_hyp": 4.40687,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.89449,
            "recall": 0.86482,
            "f1": 0.8794
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 0.5,
        "median_pred_length": 17.5,
        "min_pred_length": 17,
        "max_pred_length": 18,
        "distinct-1": 0.5142857142857142,
        "vocab_size-1": 18,
        "unique-1": 5,
        "entropy-1": 4.043568731230679,
        "distinct-2": 0.6060606060606061,
        "vocab_size-2": 20,
        "unique-2": 7,
        "entropy-2": 4.256515331479666,
        "cond_entropy-2": 0.2181414054437897,
        "distinct-3": 0.6129032258064516,
        "vocab_size-3": 19,
        "unique-3": 7,
        "entropy-3": 4.180002761999779,
        "cond_entropy-3": -0.025681679939320114,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5151515151515151,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.9534850284493626,
        "distinct-2-nopunct": 0.5806451612903226,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 4.11548663296752,
        "cond_entropy-2-nopunct": 0.23238283618971223,
        "distinct-3-nopunct": 0.5862068965517241,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 4.03039478823102,
        "cond_entropy-3-nopunct": -0.02724979801792366,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.42857142857142855,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.54191,
            "recall": 0.644,
            "fmeasure": 0.57568
        },
        "rouge2": {
            "precision": 0.39161,
            "recall": 0.46086,
            "fmeasure": 0.41258
        },
        "rougeL": {
            "precision": 0.48782,
            "recall": 0.57716,
            "fmeasure": 0.51706
        },
        "rougeLsum": {
            "precision": 0.48782,
            "recall": 0.57716,
            "fmeasure": 0.51706
        },
        "nist": 3.7821023227706236,
        "bleu": 39.04823,
        "meteor": 0.36565051783343516,
        "bleurt": -0.00017,
        "nubia": {
            "semantic_relation": 4.06167,
            "contradiction": 34.08549,
            "irrelevancy": 42.41371,
            "logical_agreement": 23.5008,
            "grammar_ref": 3.56015,
            "grammar_hyp": 3.31687,
            "nubia_score": 0.79071
        },
        "bertscore": {
            "precision": 0.88262,
            "recall": 0.92595,
            "f1": 0.90376
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.734521664779752,
        "distinct-2": 0.9375,
        "vocab_size-2": 15,
        "unique-2": 14,
        "entropy-2": 3.875,
        "cond_entropy-2": 0.10003715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.026442737724814785,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.1345227825800641,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.125,
            "3": 0.4375
        },
        "rouge1": {
            "precision": 0.64103,
            "recall": 0.43266,
            "fmeasure": 0.51551
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.1732,
            "fmeasure": 0.2046
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.26094,
            "fmeasure": 0.31029
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.26094,
            "fmeasure": 0.31029
        },
        "nist": 0.8430806952373955,
        "bleu": 7.77931,
        "meteor": 0.20309570896710138,
        "bleurt": -0.47778,
        "nubia": {
            "semantic_relation": 3.7625,
            "contradiction": 24.48526,
            "irrelevancy": 10.47915,
            "logical_agreement": 65.03559,
            "grammar_ref": 4.78465,
            "grammar_hyp": 6.32543,
            "nubia_score": 0.38647
        },
        "bertscore": {
            "precision": 0.90941,
            "recall": 0.85605,
            "f1": 0.88192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.9,
            "recall": 0.79545,
            "fmeasure": 0.84416
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.58182,
            "fmeasure": 0.62105
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.79545,
            "fmeasure": 0.84416
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.79545,
            "fmeasure": 0.84416
        },
        "nist": 4.391746226702624,
        "bleu": 62.88013,
        "meteor": 0.5016964187048004,
        "bleurt": 0.49987,
        "nubia": {
            "semantic_relation": 4.61588,
            "contradiction": 0.79065,
            "irrelevancy": 0.79241,
            "logical_agreement": 98.41693,
            "grammar_ref": 4.98843,
            "grammar_hyp": 5.20899,
            "nubia_score": 0.80411
        },
        "bertscore": {
            "precision": 0.97589,
            "recall": 0.96025,
            "f1": 0.9672
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.702819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.2238830957527498,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.589898095464287,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.24009914803219046,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.51471,
            "fmeasure": 0.58894
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.20245,
            "fmeasure": 0.23514
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.33456,
            "fmeasure": 0.38702
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.33456,
            "fmeasure": 0.38702
        },
        "nist": 1.9440723031297242,
        "bleu": 8.97505,
        "meteor": 0.2818892456171515,
        "bleurt": -0.02681,
        "nubia": {
            "semantic_relation": 3.60902,
            "contradiction": 2.69455,
            "irrelevancy": 7.8618,
            "logical_agreement": 89.44365,
            "grammar_ref": 4.95035,
            "grammar_hyp": 5.31353,
            "nubia_score": 0.48548
        },
        "bertscore": {
            "precision": 0.9248,
            "recall": 0.85423,
            "f1": 0.8794
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.59259,
            "recall": 0.47619,
            "fmeasure": 0.52479
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.25874,
            "fmeasure": 0.30576
        },
        "rougeL": {
            "precision": 0.59259,
            "recall": 0.47619,
            "fmeasure": 0.52479
        },
        "rougeLsum": {
            "precision": 0.59259,
            "recall": 0.47619,
            "fmeasure": 0.52479
        },
        "nist": 1.6585348934394,
        "bleu": 15.8271,
        "meteor": 0.27004591964226465,
        "bleurt": 0.19228,
        "nubia": {
            "semantic_relation": 3.59812,
            "contradiction": 8.1895,
            "irrelevancy": 23.07297,
            "logical_agreement": 68.73753,
            "grammar_ref": 4.72922,
            "grammar_hyp": 5.92066,
            "nubia_score": 0.39465
        },
        "bertscore": {
            "precision": 0.92893,
            "recall": 0.88062,
            "f1": 0.90125
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.403856189774722,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.10777297761309833,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": 0.025555977074987166,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.403856189774722,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.10777297761309833,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": 0.025555977074987166,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "rouge2": {
            "precision": 0.68182,
            "recall": 0.57692,
            "fmeasure": 0.625
        },
        "rougeL": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "rougeLsum": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "nist": 2.6232391060546374,
        "bleu": 42.9943,
        "meteor": 0.37636087884641,
        "bleurt": -0.08758,
        "nubia": {
            "semantic_relation": 3.38857,
            "contradiction": 7.82027,
            "irrelevancy": 21.40258,
            "logical_agreement": 70.77715,
            "grammar_ref": 4.19464,
            "grammar_hyp": 4.05161,
            "nubia_score": 0.47333
        },
        "bertscore": {
            "precision": 0.90525,
            "recall": 0.88804,
            "f1": 0.89498
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 1.0,
            "fmeasure": 0.875
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.83333,
            "fmeasure": 0.71429
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 1.0,
            "fmeasure": 0.875
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 1.0,
            "fmeasure": 0.875
        },
        "nist": 2.4,
        "bleu": 52.5382,
        "meteor": 0.527695190367949,
        "bleurt": 0.79368,
        "nubia": {
            "semantic_relation": 4.82622,
            "contradiction": 0.13834,
            "irrelevancy": 87.964,
            "logical_agreement": 11.89765,
            "grammar_ref": 5.74517,
            "grammar_hyp": 4.73817,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.94708,
            "recall": 0.99256,
            "f1": 0.96929
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.702819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.22388309575274976,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.5898980954642865,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.24009914803219054,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.64706,
            "fmeasure": 0.6875
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.375,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.52941,
            "fmeasure": 0.5625
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.52941,
            "fmeasure": 0.5625
        },
        "nist": 2.7627967178740254,
        "bleu": 21.9843,
        "meteor": 0.3587169067273053,
        "bleurt": 0.215,
        "nubia": {
            "semantic_relation": 3.98957,
            "contradiction": 0.48318,
            "irrelevancy": 3.60127,
            "logical_agreement": 95.91556,
            "grammar_ref": 4.8802,
            "grammar_hyp": 5.68971,
            "nubia_score": 0.55698
        },
        "bertscore": {
            "precision": 0.94434,
            "recall": 0.91701,
            "f1": 0.93048
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.64583,
            "recall": 0.63743,
            "fmeasure": 0.63963
        },
        "rouge2": {
            "precision": 0.31111,
            "recall": 0.27407,
            "fmeasure": 0.29091
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.52865,
            "fmeasure": 0.553
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.52865,
            "fmeasure": 0.553
        },
        "nist": 3.307403022220718,
        "bleu": 26.63255,
        "meteor": 0.31502192120553396,
        "bleurt": 0.23149,
        "nubia": {
            "semantic_relation": 4.05944,
            "contradiction": 0.22243,
            "irrelevancy": 0.53723,
            "logical_agreement": 99.24034,
            "grammar_ref": 5.46955,
            "grammar_hyp": 4.22073,
            "nubia_score": 0.83898
        },
        "bertscore": {
            "precision": 0.88032,
            "recall": 0.86548,
            "f1": 0.87106
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.47368421052631576,
        "vocab_size-1": 9,
        "unique-1": 3,
        "entropy-1": 2.9847696187067436,
        "distinct-2": 0.5294117647058824,
        "vocab_size-2": 9,
        "unique-2": 3,
        "entropy-2": 3.0286393118385755,
        "cond_entropy-2": 0.0748294454538127,
        "distinct-3": 0.6,
        "vocab_size-3": 9,
        "unique-3": 3,
        "entropy-3": 3.106890595608519,
        "cond_entropy-3": 0.08609442102484582,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.47058823529411764,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 2.793345194191516,
        "distinct-2-nopunct": 0.5333333333333333,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 2.8402239289418523,
        "cond_entropy-2-nopunct": -0.0472389123084875,
        "distinct-3-nopunct": 0.6153846153846154,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 2.931208948910323,
        "cond_entropy-3-nopunct": -0.05260472362127268,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rouge2": {
            "precision": 0.79464,
            "recall": 0.72685,
            "fmeasure": 0.75776
        },
        "rougeL": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rougeLsum": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "nist": 4.451815875634701,
        "bleu": 69.05636,
        "meteor": 0.9489775258149422,
        "bleurt": 0.78257,
        "nubia": {
            "semantic_relation": 4.99611,
            "contradiction": 0.40178,
            "irrelevancy": 0.5141,
            "logical_agreement": 99.08412,
            "grammar_ref": 4.85767,
            "grammar_hyp": 5.20195,
            "nubia_score": 0.97201
        },
        "bertscore": {
            "precision": 0.98549,
            "recall": 0.97733,
            "f1": 0.98137
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.66826,
            "fmeasure": 0.7018
        },
        "rouge2": {
            "precision": 0.47059,
            "recall": 0.42328,
            "fmeasure": 0.44511
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.4689,
            "fmeasure": 0.50811
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.4689,
            "fmeasure": 0.50811
        },
        "nist": 3.8255825864328177,
        "bleu": 31.74875,
        "meteor": 0.4390106969714567,
        "bleurt": 0.57401,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 4.67487,
            "irrelevancy": 5.37364,
            "logical_agreement": 89.95148,
            "grammar_ref": 3.4928,
            "grammar_hyp": 3.92974,
            "nubia_score": 0.95867
        },
        "bertscore": {
            "precision": 0.95384,
            "recall": 0.93577,
            "f1": 0.94472
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.6835423624332306,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.43253122228823104,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.45454545454545453,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.46551,
            "fmeasure": 0.58443
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.08838,
            "fmeasure": 0.11223
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.21159,
            "fmeasure": 0.26565
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.21159,
            "fmeasure": 0.26565
        },
        "nist": 2.4270244479576726,
        "bleu": 8.0771,
        "meteor": 0.21775368201710854,
        "bleurt": -0.79917,
        "nubia": {
            "semantic_relation": 2.51658,
            "contradiction": 26.77908,
            "irrelevancy": 29.96546,
            "logical_agreement": 43.25545,
            "grammar_ref": 3.96534,
            "grammar_hyp": 4.07278,
            "nubia_score": 0.24602
        },
        "bertscore": {
            "precision": 0.90629,
            "recall": 0.83317,
            "f1": 0.86819
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.41176,
            "fmeasure": 0.51852
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.375,
            "fmeasure": 0.48
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.41176,
            "fmeasure": 0.51852
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.41176,
            "fmeasure": 0.51852
        },
        "nist": 0.8076083232145888,
        "bleu": 26.68078,
        "meteor": 0.22905788893451226,
        "bleurt": -0.51516,
        "nubia": {
            "semantic_relation": 3.20989,
            "contradiction": 0.14667,
            "irrelevancy": 97.50456,
            "logical_agreement": 2.34876,
            "grammar_ref": 3.64996,
            "grammar_hyp": 3.81037,
            "nubia_score": 0.48508
        },
        "bertscore": {
            "precision": 0.87049,
            "recall": 0.795,
            "f1": 0.83103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.9375
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "rouge2": {
            "precision": 0.88235,
            "recall": 0.71429,
            "fmeasure": 0.78947
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "nist": 4.448844626878224,
        "bleu": 63.47496,
        "meteor": 0.4535614838983954,
        "bleurt": 0.00867,
        "nubia": {
            "semantic_relation": 4.36947,
            "contradiction": 0.21222,
            "irrelevancy": 33.35332,
            "logical_agreement": 66.43446,
            "grammar_ref": 3.23206,
            "grammar_hyp": 3.38315,
            "nubia_score": 0.8496
        },
        "bertscore": {
            "precision": 0.95797,
            "recall": 0.93445,
            "f1": 0.94607
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 10,
        "unique-1": 6,
        "entropy-1": 3.2359263506290334,
        "distinct-2": 0.7692307692307693,
        "vocab_size-2": 10,
        "unique-2": 7,
        "entropy-2": 3.238901256602631,
        "cond_entropy-2": 0.046930949929641676,
        "distinct-3": 0.8333333333333334,
        "vocab_size-3": 10,
        "unique-3": 8,
        "entropy-3": 3.2516291673878226,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.2359263506290334,
        "distinct-2-nopunct": 0.7692307692307693,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 3.238901256602631,
        "cond_entropy-2-nopunct": 0.046930949929641676,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.2516291673878226,
        "cond_entropy-3-nopunct": 0.05118944924673077,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.91228,
            "recall": 0.76416,
            "fmeasure": 0.83159
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.64685,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.91228,
            "recall": 0.76416,
            "fmeasure": 0.83159
        },
        "rougeLsum": {
            "precision": 0.91228,
            "recall": 0.76416,
            "fmeasure": 0.83159
        },
        "nist": 2.3670968993149164,
        "bleu": 52.07863,
        "meteor": 0.3853104826130613,
        "bleurt": 0.29622,
        "nubia": {
            "semantic_relation": 4.8356,
            "contradiction": 0.45487,
            "irrelevancy": 0.60011,
            "logical_agreement": 98.94501,
            "grammar_ref": 3.13705,
            "grammar_hyp": 3.73516,
            "nubia_score": 0.94055
        },
        "bertscore": {
            "precision": 0.96471,
            "recall": 0.94225,
            "f1": 0.95335
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.84295,
            "fmeasure": 0.85833
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "nist": 3.8535769082186824,
        "bleu": 76.74162,
        "meteor": 0.5426177315437225,
        "bleurt": 0.39021,
        "nubia": {
            "semantic_relation": 3.73103,
            "contradiction": 47.93643,
            "irrelevancy": 1.84919,
            "logical_agreement": 50.21438,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.4164,
            "nubia_score": 0.6985
        },
        "bertscore": {
            "precision": 0.9822,
            "recall": 0.97494,
            "f1": 0.97856
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.41026,
            "recall": 0.64286,
            "fmeasure": 0.49333
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.42424,
            "fmeasure": 0.30918
        },
        "rougeL": {
            "precision": 0.35897,
            "recall": 0.69841,
            "fmeasure": 0.47368
        },
        "rougeLsum": {
            "precision": 0.35897,
            "recall": 0.69841,
            "fmeasure": 0.47368
        },
        "nist": 1.7827443048802671,
        "bleu": 13.94285,
        "meteor": 0.302480705008112,
        "bleurt": -1.19237,
        "nubia": {
            "semantic_relation": 3.03847,
            "contradiction": 2.83729,
            "irrelevancy": 84.48927,
            "logical_agreement": 12.67343,
            "grammar_ref": 6.44614,
            "grammar_hyp": 5.39416,
            "nubia_score": 0.37528
        },
        "bertscore": {
            "precision": 0.84054,
            "recall": 0.89613,
            "f1": 0.85206
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185189,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.91667,
            "fmeasure": 0.88
        },
        "rouge2": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.91667,
            "fmeasure": 0.88
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.91667,
            "fmeasure": 0.88
        },
        "nist": 3.6461386504141604,
        "bleu": 74.4782,
        "meteor": 0.5511765807675338,
        "bleurt": 0.47035,
        "nubia": {
            "semantic_relation": 4.08704,
            "contradiction": 0.17408,
            "irrelevancy": 98.92852,
            "logical_agreement": 0.8974,
            "grammar_ref": 4.00353,
            "grammar_hyp": 4.00195,
            "nubia_score": 0.74729
        },
        "bertscore": {
            "precision": 0.96565,
            "recall": 0.97895,
            "f1": 0.96198
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 1.5,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 16,
        "distinct-1": 0.8620689655172413,
        "vocab_size-1": 25,
        "unique-1": 21,
        "entropy-1": 4.582118926162054,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 25,
        "unique-2": 23,
        "entropy-2": 4.606739354015323,
        "cond_entropy-2": -0.029019418890029344,
        "distinct-3": 0.96,
        "vocab_size-3": 24,
        "unique-3": 23,
        "entropy-3": 4.5638561897747225,
        "cond_entropy-3": -0.031031312388743952,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.03600643804015717,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5384615384615384
        },
        "rouge1": {
            "precision": 0.6958,
            "recall": 0.57265,
            "fmeasure": 0.59258
        },
        "rouge2": {
            "precision": 0.28333,
            "recall": 0.15704,
            "fmeasure": 0.19725
        },
        "rougeL": {
            "precision": 0.41259,
            "recall": 0.35613,
            "fmeasure": 0.36086
        },
        "rougeLsum": {
            "precision": 0.41259,
            "recall": 0.35613,
            "fmeasure": 0.36086
        },
        "nist": 2.3445419689305744,
        "bleu": 9.46346,
        "meteor": 0.22331846808160702,
        "bleurt": -0.24782,
        "nubia": {
            "semantic_relation": 3.56521,
            "contradiction": 1.23731,
            "irrelevancy": 48.22156,
            "logical_agreement": 50.54114,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.98343,
            "nubia_score": 0.44627
        },
        "bertscore": {
            "precision": 0.87213,
            "recall": 0.83421,
            "f1": 0.85194
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.35294,
            "fmeasure": 0.44444
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.25,
            "fmeasure": 0.32
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.35294,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.35294,
            "fmeasure": 0.44444
        },
        "nist": 0.7827723893658176,
        "bleu": 21.03828,
        "meteor": 0.2092900959565759,
        "bleurt": -0.30015,
        "nubia": {
            "semantic_relation": 3.22958,
            "contradiction": 0.25519,
            "irrelevancy": 93.27011,
            "logical_agreement": 6.4747,
            "grammar_ref": 3.28677,
            "grammar_hyp": 4.38532,
            "nubia_score": 0.36706
        },
        "bertscore": {
            "precision": 0.88245,
            "recall": 0.82871,
            "f1": 0.85474
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.7871439606981383,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.23688165146342843,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.18057224564182078,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.690116517593666,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.2697535878357437,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.0,
            "3": 0.35294117647058826
        },
        "rouge1": {
            "precision": 0.57407,
            "recall": 0.4329,
            "fmeasure": 0.49066
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.22521,
            "fmeasure": 0.25257
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.421,
            "fmeasure": 0.47616
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.421,
            "fmeasure": 0.47616
        },
        "nist": 0.779354157577945,
        "bleu": 8.15366,
        "meteor": 0.16945629085077216,
        "bleurt": 0.04937,
        "nubia": {
            "semantic_relation": 3.71098,
            "contradiction": 28.59735,
            "irrelevancy": 44.9903,
            "logical_agreement": 26.41236,
            "grammar_ref": 3.80999,
            "grammar_hyp": 5.16986,
            "nubia_score": 0.48618
        },
        "bertscore": {
            "precision": 0.88234,
            "recall": 0.8396,
            "f1": 0.85992
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.188721875540867,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.30673161811281996,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.5,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.6,
            "fmeasure": 0.46154
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.6,
            "fmeasure": 0.46154
        },
        "nist": 0.9942163464312139,
        "bleu": 13.06511,
        "meteor": 0.35602707728372085,
        "bleurt": 0.33895,
        "nubia": {
            "semantic_relation": 4.3363,
            "contradiction": 0.10349,
            "irrelevancy": 99.77726,
            "logical_agreement": 0.11925,
            "grammar_ref": 6.34893,
            "grammar_hyp": 4.91872,
            "nubia_score": 0.97367
        },
        "bertscore": {
            "precision": 0.84997,
            "recall": 0.91997,
            "f1": 0.88359
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.589898095464287,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.24009914803219046,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.188721875540867,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.3067316181128199,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.63333,
            "fmeasure": 0.7037
        },
        "rouge2": {
            "precision": 0.22727,
            "recall": 0.17857,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "nist": 2.719446985673483,
        "bleu": 14.01464,
        "meteor": 0.2889935195890205,
        "bleurt": -0.62039,
        "nubia": {
            "semantic_relation": 3.80804,
            "contradiction": 11.43835,
            "irrelevancy": 59.17958,
            "logical_agreement": 29.38207,
            "grammar_ref": 5.62728,
            "grammar_hyp": 5.13283,
            "nubia_score": 0.55798
        },
        "bertscore": {
            "precision": 0.89804,
            "recall": 0.89235,
            "f1": 0.89519
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 1.0,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.85185,
            "recall": 0.94444,
            "fmeasure": 0.88889
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94118
        },
        "nist": 3.276287077976025,
        "bleu": 58.77284,
        "meteor": 0.5054764086193895,
        "bleurt": 0.4663,
        "nubia": {
            "semantic_relation": 4.86235,
            "contradiction": 0.89405,
            "irrelevancy": 60.76008,
            "logical_agreement": 38.34587,
            "grammar_ref": 6.57473,
            "grammar_hyp": 5.18446,
            "nubia_score": 0.99266
        },
        "bertscore": {
            "precision": 0.99179,
            "recall": 0.95164,
            "f1": 0.9713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 0.5,
        "median_pred_length": 15.5,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.967741935483871,
        "vocab_size-1": 30,
        "unique-1": 29,
        "entropy-1": 4.889680181354619,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": -0.061732556638613274,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.857980995127571,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": -0.10309349296410335,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4074074074074074,
            "2": 0.47619047619047616
        },
        "rouge1": {
            "precision": 0.60938,
            "recall": 0.50468,
            "fmeasure": 0.54167
        },
        "rouge2": {
            "precision": 0.37941,
            "recall": 0.29925,
            "fmeasure": 0.32831
        },
        "rougeL": {
            "precision": 0.50347,
            "recall": 0.40114,
            "fmeasure": 0.4383
        },
        "rougeLsum": {
            "precision": 0.50347,
            "recall": 0.40114,
            "fmeasure": 0.4383
        },
        "nist": 3.4113031881482243,
        "bleu": 35.12029,
        "meteor": 0.2818498642187071,
        "bleurt": -0.09501,
        "nubia": {
            "semantic_relation": 3.55091,
            "contradiction": 1.14427,
            "irrelevancy": 62.33164,
            "logical_agreement": 36.52409,
            "grammar_ref": 4.87596,
            "grammar_hyp": 5.15623,
            "nubia_score": 0.46084
        },
        "bertscore": {
            "precision": 0.91307,
            "recall": 0.89411,
            "f1": 0.90349
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.84,
        "vocab_size-1": 21,
        "unique-1": 17,
        "entropy-1": 4.323856189774723,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.05361880976054911,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.03600643804015718,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.2626923908396215,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": 0.059231657197938034,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.03912675144043809,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.25,
            "3": 0.5652173913043478
        },
        "rouge1": {
            "precision": 0.61923,
            "recall": 0.53644,
            "fmeasure": 0.55549
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.25032,
            "fmeasure": 0.25872
        },
        "rougeL": {
            "precision": 0.58077,
            "recall": 0.48922,
            "fmeasure": 0.51317
        },
        "rougeLsum": {
            "precision": 0.58077,
            "recall": 0.48922,
            "fmeasure": 0.51317
        },
        "nist": 2.474360094201132,
        "bleu": 9.22847,
        "meteor": 0.25608004086705854,
        "bleurt": 0.11353,
        "nubia": {
            "semantic_relation": 3.88223,
            "contradiction": 54.17405,
            "irrelevancy": 5.34211,
            "logical_agreement": 40.48384,
            "grammar_ref": 4.08754,
            "grammar_hyp": 4.6928,
            "nubia_score": 0.5561
        },
        "bertscore": {
            "precision": 0.92216,
            "recall": 0.87873,
            "f1": 0.8994
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5833333333333334
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.66667,
            "fmeasure": 0.69565
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.36364,
            "fmeasure": 0.38095
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.5,
            "fmeasure": 0.52174
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.5,
            "fmeasure": 0.52174
        },
        "nist": 2.3773960073675573,
        "bleu": 23.1961,
        "meteor": 0.3760423109171667,
        "bleurt": -0.24341,
        "nubia": {
            "semantic_relation": 4.11888,
            "contradiction": 7.71257,
            "irrelevancy": 83.64083,
            "logical_agreement": 8.64659,
            "grammar_ref": 4.44512,
            "grammar_hyp": 5.15342,
            "nubia_score": 0.55584
        },
        "bertscore": {
            "precision": 0.89121,
            "recall": 0.8744,
            "f1": 0.88272
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "t5-small/totto_test",
        "N": 17,
        "total_length": 278,
        "mean_pred_length": 16.352941176470587,
        "std_pred_length": 4.702204445108551,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.579136690647482,
        "vocab_size-1": 161,
        "unique-1": 123,
        "entropy-1": 6.67283836502724,
        "distinct-2": 0.896551724137931,
        "vocab_size-2": 234,
        "unique-2": 215,
        "entropy-2": 7.781138287924004,
        "cond_entropy-2": 1.0172741295147614,
        "distinct-3": 0.9631147540983607,
        "vocab_size-3": 235,
        "unique-3": 228,
        "entropy-3": 7.84877012444809,
        "cond_entropy-3": 0.07662794737237379,
        "total_length-nopunct": 248,
        "mean_pred_length-nopunct": 14.588235294117647,
        "std_pred_length-nopunct": 4.312210072496766,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6290322580645161,
        "vocab_size-1-nopunct": 156,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.704287226829431,
        "distinct-2-nopunct": 0.9004329004329005,
        "vocab_size-2-nopunct": 208,
        "unique-2-nopunct": 193,
        "entropy-2-nopunct": 7.60756561303262,
        "cond_entropy-2-nopunct": 0.9549083702966915,
        "distinct-3-nopunct": 0.9626168224299065,
        "vocab_size-3-nopunct": 206,
        "unique-3-nopunct": 200,
        "entropy-3-nopunct": 7.657354836868405,
        "cond_entropy-3-nopunct": 0.06918697281951347,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13157894736842105,
            "2": 0.4375,
            "3": 0.6900584795321637
        },
        "rouge1": {
            "precision": 0.66681,
            "recall": 0.6038,
            "fmeasure": 0.61755
        },
        "rouge2": {
            "precision": 0.43959,
            "recall": 0.37106,
            "fmeasure": 0.39334
        },
        "rougeL": {
            "precision": 0.57604,
            "recall": 0.51837,
            "fmeasure": 0.53139
        },
        "rougeLsum": {
            "precision": 0.57604,
            "recall": 0.51837,
            "fmeasure": 0.53139
        },
        "nist": 5.051258847596816,
        "bleu": 39.83377,
        "meteor": 0.3285445194300317,
        "bleurt": 0.13189,
        "nubia": {
            "semantic_relation": 3.83322,
            "contradiction": 9.74169,
            "irrelevancy": 36.69388,
            "logical_agreement": 53.56442,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.52266,
            "nubia_score": 0.59026
        },
        "bertscore": {
            "precision": 0.89769,
            "recall": 0.88748,
            "f1": 0.89167
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9285714285714286
        },
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.87395,
            "fmeasure": 0.89862
        },
        "rouge2": {
            "precision": 0.82051,
            "recall": 0.77244,
            "fmeasure": 0.79399
        },
        "rougeL": {
            "precision": 0.92857,
            "recall": 0.87395,
            "fmeasure": 0.89862
        },
        "rougeLsum": {
            "precision": 0.92857,
            "recall": 0.87395,
            "fmeasure": 0.89862
        },
        "nist": 4.049748410536706,
        "bleu": 80.03203,
        "meteor": 0.5453172261251402,
        "bleurt": 0.68335,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30843,
            "irrelevancy": 0.40659,
            "logical_agreement": 99.28498,
            "grammar_ref": 5.90677,
            "grammar_hyp": 6.88493,
            "nubia_score": 0.82108
        },
        "bertscore": {
            "precision": 0.99654,
            "recall": 0.99654,
            "f1": 0.99654
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.28571,
            "recall": 0.19091,
            "fmeasure": 0.22876
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.10556,
            "fmeasure": 0.12917
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.19091,
            "fmeasure": 0.22876
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.19091,
            "fmeasure": 0.22876
        },
        "nist": 0.7583360936107325,
        "bleu": 8.40079,
        "meteor": 0.18287728529289485,
        "bleurt": 0.33791,
        "nubia": {
            "semantic_relation": 3.02796,
            "contradiction": 84.32738,
            "irrelevancy": 8.15461,
            "logical_agreement": 7.51801,
            "grammar_ref": 4.7527,
            "grammar_hyp": 6.79953,
            "nubia_score": 0.168
        },
        "bertscore": {
            "precision": 0.89715,
            "recall": 0.86323,
            "f1": 0.87986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "t5-small/totto_test",
        "N": 7,
        "total_length": 96,
        "mean_pred_length": 13.714285714285714,
        "std_pred_length": 3.4934340744678525,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.625,
        "vocab_size-1": 60,
        "unique-1": 44,
        "entropy-1": 5.5574083036993445,
        "distinct-2": 0.9101123595505618,
        "vocab_size-2": 81,
        "unique-2": 73,
        "entropy-2": 6.295958150067532,
        "cond_entropy-2": 0.6451015809167834,
        "distinct-3": 0.9390243902439024,
        "vocab_size-3": 77,
        "unique-3": 72,
        "entropy-3": 6.235600785105892,
        "cond_entropy-3": -0.04501069464099712,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 12.142857142857142,
        "std_pred_length-nopunct": 3.4817307448439827,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6823529411764706,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.5679110839573465,
        "distinct-2-nopunct": 0.9102564102564102,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 64,
        "entropy-2-nopunct": 6.105915039375076,
        "cond_entropy-2-nopunct": 0.6135213780492955,
        "distinct-3-nopunct": 0.9436619718309859,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 6.037071063166649,
        "cond_entropy-3-nopunct": -0.05114805710404524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.38461538461538464,
            "3": 0.5466666666666666
        },
        "rouge1": {
            "precision": 0.66291,
            "recall": 0.61083,
            "fmeasure": 0.62884
        },
        "rouge2": {
            "precision": 0.30726,
            "recall": 0.29442,
            "fmeasure": 0.29809
        },
        "rougeL": {
            "precision": 0.52035,
            "recall": 0.47474,
            "fmeasure": 0.49158
        },
        "rougeLsum": {
            "precision": 0.52035,
            "recall": 0.47474,
            "fmeasure": 0.49158
        },
        "nist": 3.236786202804964,
        "bleu": 14.54359,
        "meteor": 0.23420108742900506,
        "bleurt": 0.0628,
        "nubia": {
            "semantic_relation": 3.88717,
            "contradiction": 1.55096,
            "irrelevancy": 41.44259,
            "logical_agreement": 57.00645,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.72342,
            "nubia_score": 0.59693
        },
        "bertscore": {
            "precision": 0.87649,
            "recall": 0.86829,
            "f1": 0.86905
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.28571,
            "fmeasure": 0.35385
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.11396,
            "fmeasure": 0.14101
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.28571,
            "fmeasure": 0.35385
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.28571,
            "fmeasure": 0.35385
        },
        "nist": 0.522394142418194,
        "bleu": 16.59039,
        "meteor": 0.21567148793295737,
        "bleurt": -0.37978,
        "nubia": {
            "semantic_relation": 2.56033,
            "contradiction": 0.43691,
            "irrelevancy": 96.85255,
            "logical_agreement": 2.71054,
            "grammar_ref": 3.10421,
            "grammar_hyp": 2.47172,
            "nubia_score": 0.38529
        },
        "bertscore": {
            "precision": 0.83526,
            "recall": 0.78244,
            "f1": 0.80172
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.03600643804015717,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.03912675144043812,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.4666666666666667
        },
        "rouge1": {
            "precision": 0.36111,
            "recall": 0.41111,
            "fmeasure": 0.38384
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.11111,
            "fmeasure": 0.1
        },
        "rougeL": {
            "precision": 0.31944,
            "recall": 0.34368,
            "fmeasure": 0.32699
        },
        "rougeLsum": {
            "precision": 0.31944,
            "recall": 0.34368,
            "fmeasure": 0.32699
        },
        "nist": 1.670216000924046,
        "bleu": 6.0578,
        "meteor": 0.19299101892497114,
        "bleurt": -0.08631,
        "nubia": {
            "semantic_relation": 3.51909,
            "contradiction": 36.32477,
            "irrelevancy": 49.62065,
            "logical_agreement": 14.05459,
            "grammar_ref": 5.12311,
            "grammar_hyp": 4.90058,
            "nubia_score": 0.45948
        },
        "bertscore": {
            "precision": 0.8001,
            "recall": 0.80239,
            "f1": 0.79723
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.47222,
            "recall": 0.61111,
            "fmeasure": 0.52346
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.2381,
            "fmeasure": 0.20148
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.52778,
            "fmeasure": 0.45679
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.52778,
            "fmeasure": 0.45679
        },
        "nist": 2.03182243224112,
        "bleu": 8.00859,
        "meteor": 0.29076031411319075,
        "bleurt": -0.3841,
        "nubia": {
            "semantic_relation": 3.78223,
            "contradiction": 0.66409,
            "irrelevancy": 97.97365,
            "logical_agreement": 1.36225,
            "grammar_ref": 4.70243,
            "grammar_hyp": 4.44245,
            "nubia_score": 0.60608
        },
        "bertscore": {
            "precision": 0.83185,
            "recall": 0.92152,
            "f1": 0.87439
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.375,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "nist": 2.181303448072042,
        "bleu": 17.49165,
        "meteor": 0.35875611746824443,
        "bleurt": 0.47392,
        "nubia": {
            "semantic_relation": 4.51399,
            "contradiction": 0.2979,
            "irrelevancy": 17.35816,
            "logical_agreement": 82.34394,
            "grammar_ref": 5.69157,
            "grammar_hyp": 5.69777,
            "nubia_score": 0.77327
        },
        "bertscore": {
            "precision": 0.90603,
            "recall": 0.89212,
            "f1": 0.89902
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.023638630780208267,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.51184,
            "fmeasure": 0.5627
        },
        "rouge2": {
            "precision": 0.23333,
            "recall": 0.1886,
            "fmeasure": 0.20856
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.20395,
            "fmeasure": 0.2246
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.20395,
            "fmeasure": 0.2246
        },
        "nist": 1.5889551489679379,
        "bleu": 8.91723,
        "meteor": 0.2241574861933193,
        "bleurt": -0.26912,
        "nubia": {
            "semantic_relation": 3.87116,
            "contradiction": 1.79511,
            "irrelevancy": 58.92532,
            "logical_agreement": 39.27957,
            "grammar_ref": 4.38153,
            "grammar_hyp": 6.22357,
            "nubia_score": 0.42146
        },
        "bertscore": {
            "precision": 0.8421,
            "recall": 0.81122,
            "f1": 0.82637
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064474,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.17961067210860202,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.1000371587496606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.46153846153846156
        },
        "rouge1": {
            "precision": 0.42593,
            "recall": 0.45956,
            "fmeasure": 0.44202
        },
        "rouge2": {
            "precision": 0.11765,
            "recall": 0.13056,
            "fmeasure": 0.12374
        },
        "rougeL": {
            "precision": 0.31481,
            "recall": 0.34804,
            "fmeasure": 0.33053
        },
        "rougeLsum": {
            "precision": 0.31481,
            "recall": 0.34804,
            "fmeasure": 0.33053
        },
        "nist": 2.299977750390243,
        "bleu": 12.91803,
        "meteor": 0.24546336033833516,
        "bleurt": -0.04623,
        "nubia": {
            "semantic_relation": 3.69191,
            "contradiction": 1.00913,
            "irrelevancy": 41.29792,
            "logical_agreement": 57.69295,
            "grammar_ref": 5.85115,
            "grammar_hyp": 3.66794,
            "nubia_score": 0.81008
        },
        "bertscore": {
            "precision": 0.86077,
            "recall": 0.86614,
            "f1": 0.86345
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.07223329894392082,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.020389327891398,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.47368421052631576
        },
        "rouge1": {
            "precision": 0.51515,
            "recall": 0.47152,
            "fmeasure": 0.49194
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.20238,
            "fmeasure": 0.21164
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.34909,
            "fmeasure": 0.3559
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.34909,
            "fmeasure": 0.3559
        },
        "nist": 2.763164739166792,
        "bleu": 14.38502,
        "meteor": 0.22735656600633988,
        "bleurt": -0.37933,
        "nubia": {
            "semantic_relation": 3.41459,
            "contradiction": 1.4211,
            "irrelevancy": 97.75299,
            "logical_agreement": 0.82591,
            "grammar_ref": 4.82125,
            "grammar_hyp": 4.00128,
            "nubia_score": 0.53727
        },
        "bertscore": {
            "precision": 0.84047,
            "recall": 0.82833,
            "f1": 0.83436
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.6875,
        "vocab_size-1": 22,
        "unique-1": 14,
        "entropy-1": 4.3125,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.5402239289418519,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.028107102122342922,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.163856189774723,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.27101011410837517,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.03600643804015717,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.64103,
            "recall": 0.68774,
            "fmeasure": 0.66269
        },
        "rouge2": {
            "precision": 0.51389,
            "recall": 0.54899,
            "fmeasure": 0.53008
        },
        "rougeL": {
            "precision": 0.64103,
            "recall": 0.68774,
            "fmeasure": 0.66269
        },
        "rougeLsum": {
            "precision": 0.64103,
            "recall": 0.68774,
            "fmeasure": 0.66269
        },
        "nist": 3.1170620356142433,
        "bleu": 49.39383,
        "meteor": 0.3762850963802453,
        "bleurt": -0.40598,
        "nubia": {
            "semantic_relation": 3.5286,
            "contradiction": 14.23729,
            "irrelevancy": 68.10014,
            "logical_agreement": 17.66256,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.61724,
            "nubia_score": 0.47864
        },
        "bertscore": {
            "precision": 0.83806,
            "recall": 0.89796,
            "f1": 0.86522
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 1.5,
        "median_pred_length": 13.5,
        "min_pred_length": 12,
        "max_pred_length": 15,
        "distinct-1": 0.6296296296296297,
        "vocab_size-1": 17,
        "unique-1": 11,
        "entropy-1": 3.8524975771042005,
        "distinct-2": 0.88,
        "vocab_size-2": 22,
        "unique-2": 19,
        "entropy-2": 4.403856189774722,
        "cond_entropy-2": 0.5435498066752673,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": 0.14057533149967955,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.625,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.6531071683628116,
        "distinct-2-nopunct": 0.8636363636363636,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.186704345910023,
        "cond_entropy-2-nopunct": 0.5462675486379193,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": 0.16249647625006497,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.45454545454545453,
            "2": 0.0,
            "3": 0.058823529411764705
        },
        "rouge1": {
            "precision": 0.30952,
            "recall": 0.1266,
            "fmeasure": 0.17574
        },
        "rouge2": {
            "precision": 0.10256,
            "recall": 0.0303,
            "fmeasure": 0.04678
        },
        "rougeL": {
            "precision": 0.30952,
            "recall": 0.12439,
            "fmeasure": 0.17343
        },
        "rougeLsum": {
            "precision": 0.30952,
            "recall": 0.12439,
            "fmeasure": 0.17343
        },
        "nist": 0.03939780020567891,
        "bleu": 4.70789,
        "meteor": 0.07298094100426342,
        "bleurt": -0.98916,
        "nubia": {
            "semantic_relation": 1.14273,
            "contradiction": 7.47476,
            "irrelevancy": 92.05746,
            "logical_agreement": 0.46778,
            "grammar_ref": 3.44707,
            "grammar_hyp": 3.44326,
            "nubia_score": 0.07053
        },
        "bertscore": {
            "precision": 0.77124,
            "recall": 0.69215,
            "f1": 0.72863
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92593,
            "fmeasure": 0.95833
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.875,
            "fmeasure": 0.90476
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92593,
            "fmeasure": 0.95833
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92593,
            "fmeasure": 0.95833
        },
        "nist": 3.1597204709350555,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.78666,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.51914,
            "irrelevancy": 0.51068,
            "logical_agreement": 98.97018,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.10894,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.6818181818181818,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.572623663895163,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 18,
        "unique-2": 15,
        "entropy-2": 4.106603137064474,
        "cond_entropy-2": 0.4531149709798338,
        "distinct-3": 0.9,
        "vocab_size-3": 18,
        "unique-3": 16,
        "entropy-3": 4.1219280948873624,
        "cond_entropy-3": -0.020389327891398017,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.773557262275185,
        "cond_entropy-2-nopunct": -0.026442737724814785,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.028107102122342926,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.29412,
            "recall": 0.29412,
            "fmeasure": 0.29412
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.29412,
            "fmeasure": 0.29412
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.29412,
            "fmeasure": 0.29412
        },
        "nist": 1.16195634024808,
        "bleu": 21.27988,
        "meteor": 0.19999636414068228,
        "bleurt": -1.32707,
        "nubia": {
            "semantic_relation": 2.64469,
            "contradiction": 21.1967,
            "irrelevancy": 72.08582,
            "logical_agreement": 6.71748,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.14932,
            "nubia_score": 0.29645
        },
        "bertscore": {
            "precision": 0.67243,
            "recall": 0.78403,
            "f1": 0.72396
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "nist": 2.625,
        "bleu": 59.46036,
        "meteor": 0.9555555555555555,
        "bleurt": 0.90115,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.78492,
            "irrelevancy": 0.54406,
            "logical_agreement": 98.67101,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.3113,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.97522,
            "recall": 0.97522,
            "f1": 0.97522
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.9230769230769231
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.91296,
            "fmeasure": 0.92788
        },
        "rouge2": {
            "precision": 0.64706,
            "recall": 0.62436,
            "fmeasure": 0.63508
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.69815,
            "fmeasure": 0.70955
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.69815,
            "fmeasure": 0.70955
        },
        "nist": 3.6232815648073005,
        "bleu": 41.21421,
        "meteor": 0.45357892719895504,
        "bleurt": 0.12438,
        "nubia": {
            "semantic_relation": 4.59304,
            "contradiction": 0.68298,
            "irrelevancy": 94.58576,
            "logical_agreement": 4.73125,
            "grammar_ref": 4.59116,
            "grammar_hyp": 5.12762,
            "nubia_score": 0.73416
        },
        "bertscore": {
            "precision": 0.94819,
            "recall": 0.93219,
            "f1": 0.94012
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.375,
            "recall": 0.56349,
            "fmeasure": 0.44862
        },
        "rouge2": {
            "precision": 0.13636,
            "recall": 0.20833,
            "fmeasure": 0.16409
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.49206,
            "fmeasure": 0.39599
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.49206,
            "fmeasure": 0.39599
        },
        "nist": 1.627048478234408,
        "bleu": 9.66927,
        "meteor": 0.33752574585864054,
        "bleurt": 0.24363,
        "nubia": {
            "semantic_relation": 3.05288,
            "contradiction": 0.20045,
            "irrelevancy": 97.01994,
            "logical_agreement": 2.77961,
            "grammar_ref": 4.8549,
            "grammar_hyp": 4.19951,
            "nubia_score": 0.43683
        },
        "bertscore": {
            "precision": 0.84274,
            "recall": 0.89541,
            "f1": 0.86828
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "total_length": 1276,
        "mean_pred_length": 22.0,
        "std_pred_length": 9.579072016101307,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 46,
        "distinct-1": 0.5078369905956113,
        "vocab_size-1": 648,
        "unique-1": 516,
        "entropy-1": 8.102857232552187,
        "distinct-2": 0.9293924466338259,
        "vocab_size-2": 1132,
        "unique-2": 1082,
        "entropy-2": 10.063793209231736,
        "cond_entropy-2": 1.7874395188739653,
        "distinct-3": 0.9948275862068966,
        "vocab_size-3": 1154,
        "unique-3": 1148,
        "entropy-3": 10.169564262428569,
        "cond_entropy-3": 0.1150963136308578,
        "total_length-nopunct": 1151,
        "mean_pred_length-nopunct": 19.844827586206897,
        "std_pred_length-nopunct": 8.831373783353751,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5595134665508253,
        "vocab_size-1-nopunct": 644,
        "unique-1-nopunct": 515,
        "entropy-1-nopunct": 8.344163196576895,
        "distinct-2-nopunct": 0.9432753888380604,
        "vocab_size-2-nopunct": 1031,
        "unique-2-nopunct": 990,
        "entropy-2-nopunct": 9.954367507809,
        "cond_entropy-2-nopunct": 1.6931426391813549,
        "distinct-3-nopunct": 0.9951690821256038,
        "vocab_size-3-nopunct": 1030,
        "unique-3-nopunct": 1025,
        "entropy-3-nopunct": 10.00575321663796,
        "cond_entropy-3-nopunct": 0.058248694641582485,
        "msttr-100": 0.71917,
        "msttr-100_nopunct": 0.76364,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.010550996483001172,
            "2": 0.1619718309859155,
            "3": 0.5194805194805194,
            "4": 0.8461538461538461,
            "5": 0.9050279329608939,
            "6": 0.9354838709677419,
            "7": 0.9624413145539906
        },
        "rouge1": {
            "precision": 0.95076,
            "recall": 0.90977,
            "fmeasure": 0.92325
        },
        "rouge2": {
            "precision": 0.91188,
            "recall": 0.86418,
            "fmeasure": 0.87845
        },
        "rougeL": {
            "precision": 0.94835,
            "recall": 0.90937,
            "fmeasure": 0.92179
        },
        "rougeLsum": {
            "precision": 0.94835,
            "recall": 0.90937,
            "fmeasure": 0.92179
        },
        "nist": 11.049368937140521,
        "bleu": 92.45026,
        "meteor": 0.613232250592205,
        "bleurt": 0.37654,
        "nubia": {
            "semantic_relation": 4.45474,
            "contradiction": 2.05495,
            "irrelevancy": 11.45271,
            "logical_agreement": 86.49233,
            "grammar_ref": 4.54049,
            "grammar_hyp": 4.44616,
            "nubia_score": 0.81493
        },
        "bertscore": {
            "precision": 0.98096,
            "recall": 0.97633,
            "f1": 0.97691
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432269,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.92857,
            "fmeasure": 0.68627
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.46667,
            "fmeasure": 0.325
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.70238,
            "fmeasure": 0.51634
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.70238,
            "fmeasure": 0.51634
        },
        "nist": 2.067854147017713,
        "bleu": 17.82753,
        "meteor": 0.38512988974641926,
        "bleurt": -0.27439,
        "nubia": {
            "semantic_relation": 4.0804,
            "contradiction": 2.34576,
            "irrelevancy": 96.42153,
            "logical_agreement": 1.2327,
            "grammar_ref": 7.77345,
            "grammar_hyp": 6.82433,
            "nubia_score": 0.6902
        },
        "bertscore": {
            "precision": 0.84697,
            "recall": 0.89231,
            "f1": 0.86778
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "total_length": 534,
        "mean_pred_length": 24.272727272727273,
        "std_pred_length": 9.663341310812537,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 41,
        "distinct-1": 0.5711610486891385,
        "vocab_size-1": 305,
        "unique-1": 254,
        "entropy-1": 7.355107186211777,
        "distinct-2": 0.935546875,
        "vocab_size-2": 479,
        "unique-2": 457,
        "entropy-2": 8.844190551736684,
        "cond_entropy-2": 1.370754179568784,
        "distinct-3": 0.9938775510204082,
        "vocab_size-3": 487,
        "unique-3": 484,
        "entropy-3": 8.924393041043412,
        "cond_entropy-3": 0.07903475024913684,
        "total_length-nopunct": 484,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 8.774964387392123,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.6260330578512396,
        "vocab_size-1-nopunct": 303,
        "unique-1-nopunct": 254,
        "entropy-1-nopunct": 7.51789018633158,
        "distinct-2-nopunct": 0.9372294372294372,
        "vocab_size-2-nopunct": 433,
        "unique-2-nopunct": 415,
        "entropy-2-nopunct": 8.696393116068013,
        "cond_entropy-2-nopunct": 1.2253676096483648,
        "distinct-3-nopunct": 0.9931818181818182,
        "vocab_size-3-nopunct": 437,
        "unique-3-nopunct": 434,
        "entropy-3-nopunct": 8.767723349888337,
        "cond_entropy-3-nopunct": 0.07682530281500545,
        "msttr-100": 0.714,
        "msttr-100_nopunct": 0.7475,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.01,
            "2": 0.1694915254237288,
            "3": 0.625,
            "4": 0.9387755102040817,
            "5": 0.918918918918919,
            "6": 0.9797979797979798,
            "7": 0.9821428571428571
        },
        "rouge1": {
            "precision": 0.95875,
            "recall": 0.95122,
            "fmeasure": 0.95024
        },
        "rouge2": {
            "precision": 0.93206,
            "recall": 0.92281,
            "fmeasure": 0.92199
        },
        "rougeL": {
            "precision": 0.95785,
            "recall": 0.94978,
            "fmeasure": 0.9491
        },
        "rougeLsum": {
            "precision": 0.95785,
            "recall": 0.94978,
            "fmeasure": 0.9491
        },
        "nist": 9.919747995077053,
        "bleu": 95.38509,
        "meteor": 0.6456810729256535,
        "bleurt": 0.41714,
        "nubia": {
            "semantic_relation": 4.50961,
            "contradiction": 2.71188,
            "irrelevancy": 17.44942,
            "logical_agreement": 79.8387,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.588,
            "nubia_score": 0.80083
        },
        "bertscore": {
            "precision": 0.98287,
            "recall": 0.98249,
            "f1": 0.98116
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 16,
        "mean_pred_length": 8.0,
        "std_pred_length": 2.0,
        "median_pred_length": 8.0,
        "min_pred_length": 6,
        "max_pred_length": 10,
        "distinct-1": 0.8125,
        "vocab_size-1": 13,
        "unique-1": 10,
        "entropy-1": 3.625,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 12,
        "unique-2": 10,
        "entropy-2": 3.521640636343319,
        "cond_entropy-2": -0.19264507794239585,
        "distinct-3": 0.9166666666666666,
        "vocab_size-3": 11,
        "unique-3": 10,
        "entropy-3": 3.4182958340544896,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.521640636343319,
        "cond_entropy-2-nopunct": -0.19264507794239585,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.4182958340544896,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.42857142857142855,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.5,
            "fmeasure": 0.46487
        },
        "rouge2": {
            "precision": 0.21861,
            "recall": 0.24583,
            "fmeasure": 0.22804
        },
        "rougeL": {
            "precision": 0.40278,
            "recall": 0.44823,
            "fmeasure": 0.41946
        },
        "rougeLsum": {
            "precision": 0.40278,
            "recall": 0.44823,
            "fmeasure": 0.41946
        },
        "nist": 1.6819261883864955,
        "bleu": 5.81664,
        "meteor": 0.262682115088755,
        "bleurt": -0.23789,
        "nubia": {
            "semantic_relation": 3.82287,
            "contradiction": 13.40216,
            "irrelevancy": 48.94946,
            "logical_agreement": 37.64838,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.17075,
            "nubia_score": 0.62296
        },
        "bertscore": {
            "precision": 0.72967,
            "recall": 0.83622,
            "f1": 0.77891
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "total_length": 64,
        "mean_pred_length": 21.333333333333332,
        "std_pred_length": 8.259674462242579,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 33,
        "distinct-1": 0.84375,
        "vocab_size-1": 54,
        "unique-1": 46,
        "entropy-1": 5.663909765557392,
        "distinct-2": 0.9836065573770492,
        "vocab_size-2": 60,
        "unique-2": 59,
        "entropy-2": 5.897950452316981,
        "cond_entropy-2": 0.17262073923769725,
        "distinct-3": 1.0,
        "vocab_size-3": 58,
        "unique-3": 58,
        "entropy-3": 5.85798099512757,
        "cond_entropy-3": -0.03827358381462443,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 19.333333333333332,
        "std_pred_length-nopunct": 7.542472332656507,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.651084443403433,
        "distinct-2-nopunct": 0.9818181818181818,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.744996077161019,
        "cond_entropy-2-nopunct": 0.08701508203345133,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.700439718141095,
        "cond_entropy-3-nopunct": -0.042458456922029035,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.02564102564102564,
            "2": 0.26666666666666666,
            "3": 0.25,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.93175,
            "recall": 0.97126,
            "fmeasure": 0.95013
        },
        "rouge2": {
            "precision": 0.85841,
            "recall": 0.93676,
            "fmeasure": 0.89451
        },
        "rougeL": {
            "precision": 0.93175,
            "recall": 0.97126,
            "fmeasure": 0.95013
        },
        "rougeLsum": {
            "precision": 0.93175,
            "recall": 0.97126,
            "fmeasure": 0.95013
        },
        "nist": 7.067913390935007,
        "bleu": 94.85349,
        "meteor": 0.6443981516802815,
        "bleurt": 0.642,
        "nubia": {
            "semantic_relation": 4.75446,
            "contradiction": 1.43306,
            "irrelevancy": 22.85532,
            "logical_agreement": 75.71162,
            "grammar_ref": 4.54431,
            "grammar_hyp": 5.49212,
            "nubia_score": 0.75818
        },
        "bertscore": {
            "precision": 0.98895,
            "recall": 0.99423,
            "f1": 0.98916
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "total_length": 767,
        "mean_pred_length": 25.566666666666666,
        "std_pred_length": 11.295082509166939,
        "median_pred_length": 23.0,
        "min_pred_length": 6,
        "max_pred_length": 52,
        "distinct-1": 0.529335071707953,
        "vocab_size-1": 406,
        "unique-1": 335,
        "entropy-1": 7.673994472183233,
        "distinct-2": 0.926729986431479,
        "vocab_size-2": 683,
        "unique-2": 653,
        "entropy-2": 9.34305451070283,
        "cond_entropy-2": 1.545107202085342,
        "distinct-3": 0.9858557284299858,
        "vocab_size-3": 697,
        "unique-3": 690,
        "entropy-3": 9.434074661518592,
        "cond_entropy-3": 0.09876270944638701,
        "total_length-nopunct": 687,
        "mean_pred_length-nopunct": 22.9,
        "std_pred_length-nopunct": 10.060980734169673,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.586608442503639,
        "vocab_size-1-nopunct": 403,
        "unique-1-nopunct": 335,
        "entropy-1-nopunct": 7.874585763815206,
        "distinct-2-nopunct": 0.9452054794520548,
        "vocab_size-2-nopunct": 621,
        "unique-2-nopunct": 600,
        "entropy-2-nopunct": 9.225595883781478,
        "cond_entropy-2-nopunct": 1.4020148929138765,
        "distinct-3-nopunct": 0.9904306220095693,
        "vocab_size-3-nopunct": 621,
        "unique-3-nopunct": 616,
        "entropy-3-nopunct": 9.27197890951323,
        "cond_entropy-3-nopunct": 0.052801861929875585,
        "msttr-100": 0.71571,
        "msttr-100_nopunct": 0.755,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.006787330316742082,
            "2": 0.16049382716049382,
            "3": 0.6271186440677966,
            "4": 0.8405797101449275,
            "5": 0.9565217391304348,
            "6": 0.987012987012987,
            "7": 0.9771689497716894
        },
        "rouge1": {
            "precision": 0.93306,
            "recall": 0.93958,
            "fmeasure": 0.93145
        },
        "rouge2": {
            "precision": 0.87232,
            "recall": 0.87549,
            "fmeasure": 0.8678
        },
        "rougeL": {
            "precision": 0.93197,
            "recall": 0.9367,
            "fmeasure": 0.92913
        },
        "rougeLsum": {
            "precision": 0.93197,
            "recall": 0.9367,
            "fmeasure": 0.92913
        },
        "nist": 9.974768636134918,
        "bleu": 88.45594,
        "meteor": 0.6010723815345386,
        "bleurt": 0.27944,
        "nubia": {
            "semantic_relation": 4.45239,
            "contradiction": 0.94296,
            "irrelevancy": 15.86088,
            "logical_agreement": 83.19617,
            "grammar_ref": 4.65355,
            "grammar_hyp": 4.89065,
            "nubia_score": 0.75074
        },
        "bertscore": {
            "precision": 0.96547,
            "recall": 0.97958,
            "f1": 0.97034
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 2.0,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 19,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 30,
        "unique-1": 27,
        "entropy-1": 4.829966150010236,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.123627393192269,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.625053839880556,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.1470875256345436,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.6333333333333333
        },
        "rouge1": {
            "precision": 0.7193,
            "recall": 0.58312,
            "fmeasure": 0.63947
        },
        "rouge2": {
            "precision": 0.40488,
            "recall": 0.33824,
            "fmeasure": 0.36591
        },
        "rougeL": {
            "precision": 0.4364,
            "recall": 0.35192,
            "fmeasure": 0.38684
        },
        "rougeLsum": {
            "precision": 0.4364,
            "recall": 0.35192,
            "fmeasure": 0.38684
        },
        "nist": 3.173284506024319,
        "bleu": 22.14777,
        "meteor": 0.3537938178321542,
        "bleurt": 0.32161,
        "nubia": {
            "semantic_relation": 4.50799,
            "contradiction": 0.72236,
            "irrelevancy": 0.72797,
            "logical_agreement": 98.54967,
            "grammar_ref": 4.13564,
            "grammar_hyp": 4.32862,
            "nubia_score": 0.79292
        },
        "bertscore": {
            "precision": 0.92115,
            "recall": 0.90527,
            "f1": 0.91181
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "total_length": 212,
        "mean_pred_length": 23.555555555555557,
        "std_pred_length": 6.148371258780854,
        "median_pred_length": 22.0,
        "min_pred_length": 15,
        "max_pred_length": 37,
        "distinct-1": 0.7075471698113207,
        "vocab_size-1": 150,
        "unique-1": 130,
        "entropy-1": 6.8032669784467465,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 196,
        "unique-2": 194,
        "entropy-2": 7.558678358296496,
        "cond_entropy-2": 0.6558673220766857,
        "distinct-3": 1.0,
        "vocab_size-3": 194,
        "unique-3": 194,
        "entropy-3": 7.599912842187102,
        "cond_entropy-3": 0.04618251497310177,
        "total_length-nopunct": 196,
        "mean_pred_length-nopunct": 21.77777777777778,
        "std_pred_length-nopunct": 5.3495124965380985,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.7448979591836735,
        "vocab_size-1-nopunct": 146,
        "unique-1-nopunct": 128,
        "entropy-1-nopunct": 6.819365091822994,
        "distinct-2-nopunct": 0.9625668449197861,
        "vocab_size-2-nopunct": 180,
        "unique-2-nopunct": 178,
        "entropy-2-nopunct": 7.431111120559256,
        "cond_entropy-2-nopunct": 0.6362013242972817,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 178,
        "unique-3-nopunct": 178,
        "entropy-3-nopunct": 7.47573343096637,
        "cond_entropy-3-nopunct": 0.050476524193385774,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.02962962962962963,
            "2": 0.09090909090909091,
            "3": 0.5,
            "4": 0.85,
            "5": 1.0,
            "6": 1.0,
            "7": 0.9841269841269841
        },
        "rouge1": {
            "precision": 0.95213,
            "recall": 0.98959,
            "fmeasure": 0.97007
        },
        "rouge2": {
            "precision": 0.91348,
            "recall": 0.93925,
            "fmeasure": 0.92589
        },
        "rougeL": {
            "precision": 0.95213,
            "recall": 0.98959,
            "fmeasure": 0.97007
        },
        "rougeLsum": {
            "precision": 0.95213,
            "recall": 0.98959,
            "fmeasure": 0.97007
        },
        "nist": 8.316522514748268,
        "bleu": 89.10389,
        "meteor": 0.6456685706600745,
        "bleurt": 0.37953,
        "nubia": {
            "semantic_relation": 4.71586,
            "contradiction": 3.00284,
            "irrelevancy": 18.48924,
            "logical_agreement": 78.50792,
            "grammar_ref": 4.59683,
            "grammar_hyp": 4.83986,
            "nubia_score": 0.83106
        },
        "bertscore": {
            "precision": 0.97254,
            "recall": 0.99036,
            "f1": 0.9801
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 1.5,
        "median_pred_length": 13.5,
        "min_pred_length": 12,
        "max_pred_length": 15,
        "distinct-1": 0.9259259259259259,
        "vocab_size-1": 25,
        "unique-1": 23,
        "entropy-1": 4.606739354015322,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": -0.03103131238874395,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.96,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5638561897747225,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.03333771197858132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5263157894736842,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.68125,
            "recall": 0.62247,
            "fmeasure": 0.65021
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.47908,
            "fmeasure": 0.50457
        },
        "rougeL": {
            "precision": 0.68125,
            "recall": 0.62247,
            "fmeasure": 0.65021
        },
        "rougeLsum": {
            "precision": 0.68125,
            "recall": 0.62247,
            "fmeasure": 0.65021
        },
        "nist": 3.559014977684977,
        "bleu": 48.59598,
        "meteor": 0.35804082127943526,
        "bleurt": 0.05548,
        "nubia": {
            "semantic_relation": 4.25031,
            "contradiction": 1.19199,
            "irrelevancy": 22.44849,
            "logical_agreement": 76.35953,
            "grammar_ref": 5.11675,
            "grammar_hyp": 4.96262,
            "nubia_score": 0.70016
        },
        "bertscore": {
            "precision": 0.9051,
            "recall": 0.90429,
            "f1": 0.90467
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966057,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518523,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.9
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85568
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.85833,
            "fmeasure": 0.72741
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85568
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85568
        },
        "nist": 3.196979798573185,
        "bleu": 55.60337,
        "meteor": 0.5206924026304247,
        "bleurt": 0.40102,
        "nubia": {
            "semantic_relation": 4.17998,
            "contradiction": 0.61916,
            "irrelevancy": 93.24068,
            "logical_agreement": 6.14017,
            "grammar_ref": 4.75081,
            "grammar_hyp": 3.84954,
            "nubia_score": 0.77863
        },
        "bertscore": {
            "precision": 0.9344,
            "recall": 0.97921,
            "f1": 0.95628
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 3.5,
        "median_pred_length": 19.5,
        "min_pred_length": 16,
        "max_pred_length": 23,
        "distinct-1": 0.7435897435897436,
        "vocab_size-1": 29,
        "unique-1": 19,
        "entropy-1": 4.772581706041735,
        "distinct-2": 0.9459459459459459,
        "vocab_size-2": 35,
        "unique-2": 33,
        "entropy-2": 5.101345257520845,
        "cond_entropy-2": 0.35648357919913354,
        "distinct-3": 0.9714285714285714,
        "vocab_size-3": 34,
        "unique-3": 33,
        "entropy-3": 5.072140159802107,
        "cond_entropy-3": -0.023027491541126214,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7428571428571429,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.6149973026592495,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.923181998146335,
        "cond_entropy-2-nopunct": 0.339353526655911,
        "distinct-3-nopunct": 0.967741935483871,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.889680181354619,
        "cond_entropy-3-nopunct": -0.0256816799393201,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7714285714285715
        },
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.68456,
            "fmeasure": 0.76185
        },
        "rouge2": {
            "precision": 0.5401,
            "recall": 0.40458,
            "fmeasure": 0.4587
        },
        "rougeL": {
            "precision": 0.61667,
            "recall": 0.48749,
            "fmeasure": 0.54153
        },
        "rougeLsum": {
            "precision": 0.61667,
            "recall": 0.48749,
            "fmeasure": 0.54153
        },
        "nist": 2.8825427202898,
        "bleu": 27.21544,
        "meteor": 0.3245270263463823,
        "bleurt": 0.01873,
        "nubia": {
            "semantic_relation": 4.58933,
            "contradiction": 6.33189,
            "irrelevancy": 1.81318,
            "logical_agreement": 91.85492,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.667,
            "nubia_score": 0.78123
        },
        "bertscore": {
            "precision": 0.90295,
            "recall": 0.87468,
            "f1": 0.88677
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.61616,
            "fmeasure": 0.57727
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.275,
            "fmeasure": 0.26111
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.44949,
            "fmeasure": 0.42727
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.44949,
            "fmeasure": 0.42727
        },
        "nist": 2.6631010638672525,
        "bleu": 36.95372,
        "meteor": 0.2764769733517268,
        "bleurt": 0.08679,
        "nubia": {
            "semantic_relation": 3.34811,
            "contradiction": 98.49265,
            "irrelevancy": 0.70741,
            "logical_agreement": 0.79994,
            "grammar_ref": 5.60099,
            "grammar_hyp": 4.62473,
            "nubia_score": 0.4694
        },
        "bertscore": {
            "precision": 0.86273,
            "recall": 0.8897,
            "f1": 0.87084
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.54684,
            "fmeasure": 0.65134
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.3125,
            "fmeasure": 0.37037
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.41176,
            "fmeasure": 0.48276
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.41176,
            "fmeasure": 0.48276
        },
        "nist": 1.7905236018288486,
        "bleu": 14.99746,
        "meteor": 0.2785376776415849,
        "bleurt": -0.15838,
        "nubia": {
            "semantic_relation": 3.1872,
            "contradiction": 99.54013,
            "irrelevancy": 0.34972,
            "logical_agreement": 0.11014,
            "grammar_ref": 4.71038,
            "grammar_hyp": 5.45209,
            "nubia_score": 0.28056
        },
        "bertscore": {
            "precision": 0.90949,
            "recall": 0.87633,
            "f1": 0.8926
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.48148,
            "fmeasure": 0.48148
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "nist": 2.638831505321384,
        "bleu": 37.06866,
        "meteor": 0.44902503618506967,
        "bleurt": -0.10894,
        "nubia": {
            "semantic_relation": 4.58092,
            "contradiction": 7.04595,
            "irrelevancy": 11.07823,
            "logical_agreement": 81.87583,
            "grammar_ref": 5.6957,
            "grammar_hyp": 5.05686,
            "nubia_score": 0.73966
        },
        "bertscore": {
            "precision": 0.94558,
            "recall": 0.96722,
            "f1": 0.95628
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.68354236243323,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.43253122228823104,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.32323142879762,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.5258134337464763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.26667,
            "recall": 0.28356,
            "fmeasure": 0.27381
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.07639,
            "fmeasure": 0.0735
        },
        "rougeL": {
            "precision": 0.24444,
            "recall": 0.23379,
            "fmeasure": 0.2381
        },
        "rougeLsum": {
            "precision": 0.24444,
            "recall": 0.23379,
            "fmeasure": 0.2381
        },
        "nist": 1.1076685432222044,
        "bleu": 5.10928,
        "meteor": 0.11169995011102074,
        "bleurt": -0.81869,
        "nubia": {
            "semantic_relation": 1.00179,
            "contradiction": 62.65993,
            "irrelevancy": 35.75781,
            "logical_agreement": 1.58227,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.69895,
            "nubia_score": 0.09206
        },
        "bertscore": {
            "precision": 0.67619,
            "recall": 0.65373,
            "f1": 0.66477
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.73294,
            "fmeasure": 0.74531
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.40741,
            "fmeasure": 0.41249
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.64133,
            "fmeasure": 0.65215
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.64133,
            "fmeasure": 0.65215
        },
        "nist": 0.9976510795081363,
        "bleu": 19.98749,
        "meteor": 0.46565290508521523,
        "bleurt": 0.232,
        "nubia": {
            "semantic_relation": 4.41203,
            "contradiction": 0.59262,
            "irrelevancy": 0.69455,
            "logical_agreement": 98.71283,
            "grammar_ref": 3.44041,
            "grammar_hyp": 4.43218,
            "nubia_score": 0.7726
        },
        "bertscore": {
            "precision": 0.95334,
            "recall": 0.95833,
            "f1": 0.95583
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964168,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.84211,
            "fmeasure": 0.91429
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.73684,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.73684,
            "fmeasure": 0.8
        },
        "nist": 2.647221591589278,
        "bleu": 42.00221,
        "meteor": 0.4279864922020735,
        "bleurt": 0.5614,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.16647,
            "irrelevancy": 0.41466,
            "logical_agreement": 99.41888,
            "grammar_ref": 4.21408,
            "grammar_hyp": 4.9055,
            "nubia_score": 0.93643
        },
        "bertscore": {
            "precision": 0.96223,
            "recall": 0.94739,
            "f1": 0.95475
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.56667,
            "fmeasure": 0.62212
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.40336,
            "fmeasure": 0.44562
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.51111,
            "fmeasure": 0.5576
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.51111,
            "fmeasure": 0.5576
        },
        "nist": 2.347902497459469,
        "bleu": 39.65588,
        "meteor": 0.3433924064545907,
        "bleurt": 0.00816,
        "nubia": {
            "semantic_relation": 4.26597,
            "contradiction": 0.19738,
            "irrelevancy": 29.64589,
            "logical_agreement": 70.15673,
            "grammar_ref": 4.4151,
            "grammar_hyp": 5.34039,
            "nubia_score": 0.62207
        },
        "bertscore": {
            "precision": 0.91796,
            "recall": 0.90133,
            "f1": 0.90957
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.5833333333333334,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.751629167387823,
        "distinct-2-nopunct": 0.5909090909090909,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.6412498004554794,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 0.6,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.521928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "nist": 2.966193015531081,
        "bleu": 72.92572,
        "meteor": 0.5638904804662692,
        "bleurt": 0.47074,
        "nubia": {
            "semantic_relation": 4.41566,
            "contradiction": 0.40909,
            "irrelevancy": 93.28802,
            "logical_agreement": 6.30289,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.43146,
            "nubia_score": 0.88872
        },
        "bertscore": {
            "precision": 0.92453,
            "recall": 0.96298,
            "f1": 0.94336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 27,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.4074074074074074,
        "vocab_size-1": 11,
        "unique-1": 3,
        "entropy-1": 3.3460319459668852,
        "distinct-2": 0.5,
        "vocab_size-2": 12,
        "unique-2": 6,
        "entropy-2": 3.3962406251802895,
        "cond_entropy-2": 0.02819531114783215,
        "distinct-3": 0.5238095238095238,
        "vocab_size-3": 11,
        "unique-3": 6,
        "entropy-3": 3.260201350835077,
        "cond_entropy-3": -0.19264507794239577,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.4166666666666667,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 3.1981203125901447,
        "distinct-2-nopunct": 0.5238095238095238,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 3.260201350835077,
        "cond_entropy-2-nopunct": 0.03377813644634077,
        "distinct-3-nopunct": 0.5555555555555556,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 3.1132833342948745,
        "cond_entropy-3-nopunct": -0.222392421336448,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.60561,
            "fmeasure": 0.73219
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.52125,
            "fmeasure": 0.62799
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 0.60561,
            "fmeasure": 0.73219
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 0.60561,
            "fmeasure": 0.73219
        },
        "nist": 0.877720847030034,
        "bleu": 29.4192,
        "meteor": 0.2985933099097678,
        "bleurt": 0.48739,
        "nubia": {
            "semantic_relation": 4.49214,
            "contradiction": 0.27176,
            "irrelevancy": 0.49422,
            "logical_agreement": 99.23402,
            "grammar_ref": 4.141,
            "grammar_hyp": 6.17474,
            "nubia_score": 0.68814
        },
        "bertscore": {
            "precision": 0.96162,
            "recall": 0.90069,
            "f1": 0.92952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 59,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 4.714045207910316,
        "median_pred_length": 23.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.4915254237288136,
        "vocab_size-1": 29,
        "unique-1": 13,
        "entropy-1": 4.530971761872781,
        "distinct-2": 0.7678571428571429,
        "vocab_size-2": 43,
        "unique-2": 31,
        "entropy-2": 5.32958907380469,
        "cond_entropy-2": 0.7861195683658968,
        "distinct-3": 0.8113207547169812,
        "vocab_size-3": 43,
        "unique-3": 33,
        "entropy-3": 5.350561963997157,
        "cond_entropy-3": 0.048016240093585065,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 2.357022603955158,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5869565217391305,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.615422010169678,
        "distinct-2-nopunct": 0.7441860465116279,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.897081324419226,
        "cond_entropy-2-nopunct": 0.29850628721843087,
        "distinct-3-nopunct": 0.775,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.871928094887363,
        "cond_entropy-3-nopunct": 0.014535527739350905,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.5111111111111111
        },
        "rouge1": {
            "precision": 0.61601,
            "recall": 0.51743,
            "fmeasure": 0.56
        },
        "rouge2": {
            "precision": 0.23674,
            "recall": 0.19181,
            "fmeasure": 0.21015
        },
        "rougeL": {
            "precision": 0.38235,
            "recall": 0.3207,
            "fmeasure": 0.34704
        },
        "rougeLsum": {
            "precision": 0.38235,
            "recall": 0.3207,
            "fmeasure": 0.34704
        },
        "nist": 3.1199865737110852,
        "bleu": 9.58846,
        "meteor": 0.25240133997010394,
        "bleurt": -0.09316,
        "nubia": {
            "semantic_relation": 3.31284,
            "contradiction": 36.84325,
            "irrelevancy": 58.96585,
            "logical_agreement": 4.19091,
            "grammar_ref": 4.73012,
            "grammar_hyp": 4.40535,
            "nubia_score": 0.44754
        },
        "bertscore": {
            "precision": 0.88968,
            "recall": 0.87081,
            "f1": 0.8794
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.21785611591339743,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0957952550009344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.262496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.76923,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57071
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.64957,
            "fmeasure": 0.73504
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.64957,
            "fmeasure": 0.73504
        },
        "nist": 3.6468094959587605,
        "bleu": 48.48701,
        "meteor": 0.3983240151613566,
        "bleurt": 0.53921,
        "nubia": {
            "semantic_relation": 4.96091,
            "contradiction": 0.26575,
            "irrelevancy": 0.50296,
            "logical_agreement": 99.2313,
            "grammar_ref": 4.20051,
            "grammar_hyp": 5.03598,
            "nubia_score": 0.91551
        },
        "bertscore": {
            "precision": 0.97128,
            "recall": 0.95234,
            "f1": 0.96172
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.45455,
            "fmeasure": 0.52632
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.2,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.36364,
            "fmeasure": 0.42105
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.36364,
            "fmeasure": 0.42105
        },
        "nist": 1.3266029805022201,
        "bleu": 14.44881,
        "meteor": 0.20468712467413674,
        "bleurt": -0.34825,
        "nubia": {
            "semantic_relation": 3.20122,
            "contradiction": 0.10513,
            "irrelevancy": 99.75742,
            "logical_agreement": 0.13745,
            "grammar_ref": 4.25346,
            "grammar_hyp": 4.51152,
            "nubia_score": 0.51088
        },
        "bertscore": {
            "precision": 0.85509,
            "recall": 0.82953,
            "f1": 0.84212
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.68452,
            "fmeasure": 0.81197
        },
        "rouge2": {
            "precision": 0.88889,
            "recall": 0.58803,
            "fmeasure": 0.70707
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.68452,
            "fmeasure": 0.81197
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.68452,
            "fmeasure": 0.81197
        },
        "nist": 2.3844928740222238,
        "bleu": 59.79112,
        "meteor": 0.4603139313159562,
        "bleurt": 0.52075,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.42778,
            "irrelevancy": 0.48673,
            "logical_agreement": 99.08549,
            "grammar_ref": 4.10709,
            "grammar_hyp": 5.43598,
            "nubia_score": 0.87415
        },
        "bertscore": {
            "precision": 0.98402,
            "recall": 0.93478,
            "f1": 0.95876
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 4.021928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.24178889224043368,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.734521664779752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.2875371587496606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.63158,
            "recall": 0.8381,
            "fmeasure": 0.72014
        },
        "rouge2": {
            "precision": 0.42593,
            "recall": 0.56044,
            "fmeasure": 0.48387
        },
        "rougeL": {
            "precision": 0.54386,
            "recall": 0.7381,
            "fmeasure": 0.62626
        },
        "rougeLsum": {
            "precision": 0.54386,
            "recall": 0.7381,
            "fmeasure": 0.62626
        },
        "nist": 3.6411518392847304,
        "bleu": 29.62789,
        "meteor": 0.40537736522403855,
        "bleurt": 0.08789,
        "nubia": {
            "semantic_relation": 3.56926,
            "contradiction": 0.09765,
            "irrelevancy": 99.77052,
            "logical_agreement": 0.13183,
            "grammar_ref": 3.90604,
            "grammar_hyp": 3.07487,
            "nubia_score": 0.75963
        },
        "bertscore": {
            "precision": 0.83703,
            "recall": 0.91869,
            "f1": 0.87596
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.46154,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.25,
            "fmeasure": 0.31579
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.46154,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.46154,
            "fmeasure": 0.57143
        },
        "nist": 1.0159330244017084,
        "bleu": 13.39235,
        "meteor": 0.29856988218120256,
        "bleurt": 0.6125,
        "nubia": {
            "semantic_relation": 4.93676,
            "contradiction": 8.10139,
            "irrelevancy": 1.95092,
            "logical_agreement": 89.94769,
            "grammar_ref": 3.94537,
            "grammar_hyp": 5.30195,
            "nubia_score": 0.80508
        },
        "bertscore": {
            "precision": 0.94408,
            "recall": 0.87436,
            "f1": 0.90788
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.74802,
            "fmeasure": 0.8254
        },
        "rouge2": {
            "precision": 0.76923,
            "recall": 0.61111,
            "fmeasure": 0.67821
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.68452,
            "fmeasure": 0.74921
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.68452,
            "fmeasure": 0.74921
        },
        "nist": 3.2251551102253364,
        "bleu": 48.76485,
        "meteor": 0.4735175294844011,
        "bleurt": 0.25077,
        "nubia": {
            "semantic_relation": 4.15887,
            "contradiction": 0.71992,
            "irrelevancy": 33.85829,
            "logical_agreement": 65.42179,
            "grammar_ref": 3.89472,
            "grammar_hyp": 4.71592,
            "nubia_score": 0.64689
        },
        "bertscore": {
            "precision": 0.9538,
            "recall": 0.94652,
            "f1": 0.95014
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.6178096843744547,
        "distinct-2": 0.8,
        "vocab_size-2": 16,
        "unique-2": 13,
        "entropy-2": 3.884183719779189,
        "cond_entropy-2": 0.30509942232494885,
        "distinct-3": 0.8947368421052632,
        "vocab_size-3": 17,
        "unique-3": 15,
        "entropy-3": 4.03740119765411,
        "cond_entropy-3": 0.17625665551219521,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.4,
            "3": 0.1
        },
        "rouge1": {
            "precision": 0.64583,
            "recall": 0.33174,
            "fmeasure": 0.43732
        },
        "rouge2": {
            "precision": 0.24444,
            "recall": 0.12381,
            "fmeasure": 0.16403
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.25798,
            "fmeasure": 0.3396
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.25798,
            "fmeasure": 0.3396
        },
        "nist": 1.2443771529163639,
        "bleu": 3.91543,
        "meteor": 0.12895118266474515,
        "bleurt": -0.60187,
        "nubia": {
            "semantic_relation": 2.29419,
            "contradiction": 2.92066,
            "irrelevancy": 18.13395,
            "logical_agreement": 78.94539,
            "grammar_ref": 5.53052,
            "grammar_hyp": 4.11939,
            "nubia_score": 0.2196
        },
        "bertscore": {
            "precision": 0.83886,
            "recall": 0.77772,
            "f1": 0.80565
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.6,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.54545,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.54545,
            "fmeasure": 0.6
        },
        "nist": 3.35968659556746,
        "bleu": 35.59193,
        "meteor": 0.44259081512009457,
        "bleurt": 0.6436,
        "nubia": {
            "semantic_relation": 4.82161,
            "contradiction": 0.30325,
            "irrelevancy": 0.49839,
            "logical_agreement": 99.19836,
            "grammar_ref": 5.42176,
            "grammar_hyp": 5.1729,
            "nubia_score": 0.96024
        },
        "bertscore": {
            "precision": 0.96386,
            "recall": 0.95672,
            "f1": 0.96028
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 2.8284271247461903,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 21,
        "distinct-1": 0.6274509803921569,
        "vocab_size-1": 32,
        "unique-1": 19,
        "entropy-1": 4.82890475356652,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 40,
        "unique-2": 32,
        "entropy-2": 5.251629167387827,
        "cond_entropy-2": 0.37638429430154413,
        "distinct-3": 0.9111111111111111,
        "vocab_size-3": 41,
        "unique-3": 37,
        "entropy-3": 5.314075318551895,
        "cond_entropy-3": 0.08466837338629603,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6382978723404256,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.740447096220397,
        "distinct-2-nopunct": 0.8181818181818182,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 5.095795255000931,
        "cond_entropy-2-nopunct": 0.4108578239253507,
        "distinct-3-nopunct": 0.9024390243902439,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.16243005339857,
        "cond_entropy-3-nopunct": 0.09324233720029851,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.7222222222222222,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.779,
            "recall": 0.7975,
            "fmeasure": 0.77704
        },
        "rouge2": {
            "precision": 0.57037,
            "recall": 0.55815,
            "fmeasure": 0.55664
        },
        "rougeL": {
            "precision": 0.654,
            "recall": 0.64697,
            "fmeasure": 0.64138
        },
        "rougeLsum": {
            "precision": 0.654,
            "recall": 0.64697,
            "fmeasure": 0.64138
        },
        "nist": 4.602961377761486,
        "bleu": 48.0263,
        "meteor": 0.4086679011864398,
        "bleurt": -0.07969,
        "nubia": {
            "semantic_relation": 4.14249,
            "contradiction": 2.28355,
            "irrelevancy": 69.86375,
            "logical_agreement": 27.8527,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.33566,
            "nubia_score": 0.7099
        },
        "bertscore": {
            "precision": 0.93342,
            "recall": 0.92507,
            "f1": 0.92307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.8963,
            "fmeasure": 0.92788
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.49537,
            "fmeasure": 0.51716
        },
        "rougeL": {
            "precision": 0.85185,
            "recall": 0.79259,
            "fmeasure": 0.82066
        },
        "rougeLsum": {
            "precision": 0.85185,
            "recall": 0.79259,
            "fmeasure": 0.82066
        },
        "nist": 3.7456398254417365,
        "bleu": 55.62833,
        "meteor": 0.46736318340128513,
        "bleurt": 0.70029,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18796,
            "irrelevancy": 0.48475,
            "logical_agreement": 99.32729,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.58474,
            "nubia_score": 0.95724
        },
        "bertscore": {
            "precision": 0.97269,
            "recall": 0.95351,
            "f1": 0.963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.04281761336971672,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.18057224564182078,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.0472389123084875,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.57407,
            "fmeasure": 0.664
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.41943,
            "fmeasure": 0.49359
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.57407,
            "fmeasure": 0.664
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.57407,
            "fmeasure": 0.664
        },
        "nist": 1.9943519935627814,
        "bleu": 25.11437,
        "meteor": 0.34496839495254344,
        "bleurt": 0.39467,
        "nubia": {
            "semantic_relation": 4.34156,
            "contradiction": 1.58939,
            "irrelevancy": 4.4296,
            "logical_agreement": 93.98101,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.01237,
            "nubia_score": 0.84667
        },
        "bertscore": {
            "precision": 0.92483,
            "recall": 0.88996,
            "f1": 0.90538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.53725,
            "fmeasure": 0.67949
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.30476,
            "fmeasure": 0.38999
        },
        "rougeL": {
            "precision": 0.92593,
            "recall": 0.53725,
            "fmeasure": 0.67949
        },
        "rougeLsum": {
            "precision": 0.92593,
            "recall": 0.53725,
            "fmeasure": 0.67949
        },
        "nist": 1.5650536941879871,
        "bleu": 31.36323,
        "meteor": 0.3047832353998032,
        "bleurt": -0.23037,
        "nubia": {
            "semantic_relation": 3.78288,
            "contradiction": 1.76065,
            "irrelevancy": 11.76777,
            "logical_agreement": 86.47158,
            "grammar_ref": 4.68072,
            "grammar_hyp": 5.72581,
            "nubia_score": 0.47087
        },
        "bertscore": {
            "precision": 0.94929,
            "recall": 0.83493,
            "f1": 0.88844
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.4677201004745006,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2588453731729854,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.334679141051595,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.28076340776035313,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.72751,
            "fmeasure": 0.77977
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.42836,
            "fmeasure": 0.48184
        },
        "rougeL": {
            "precision": 0.79487,
            "recall": 0.51704,
            "fmeasure": 0.62309
        },
        "rougeLsum": {
            "precision": 0.79487,
            "recall": 0.51704,
            "fmeasure": 0.62309
        },
        "nist": 2.6480557839832715,
        "bleu": 46.82569,
        "meteor": 0.3600287039374883,
        "bleurt": -0.00821,
        "nubia": {
            "semantic_relation": 3.40876,
            "contradiction": 0.32234,
            "irrelevancy": 0.80338,
            "logical_agreement": 98.87429,
            "grammar_ref": 3.09217,
            "grammar_hyp": 2.63045,
            "nubia_score": 0.7359
        },
        "bertscore": {
            "precision": 0.9387,
            "recall": 0.89931,
            "f1": 0.91858
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.79365,
            "fmeasure": 0.76863
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "nist": 2.763324482612094,
        "bleu": 59.69492,
        "meteor": 0.902035682675735,
        "bleurt": 0.64829,
        "nubia": {
            "semantic_relation": 4.92238,
            "contradiction": 0.17593,
            "irrelevancy": 35.19794,
            "logical_agreement": 64.62613,
            "grammar_ref": 4.01433,
            "grammar_hyp": 3.71883,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.96429,
            "recall": 0.97126,
            "f1": 0.96429
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.42424,
            "recall": 0.5,
            "fmeasure": 0.45781
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.13228,
            "fmeasure": 0.11352
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.39167,
            "fmeasure": 0.35923
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.39167,
            "fmeasure": 0.35923
        },
        "nist": 1.5912281254206746,
        "bleu": 8.51659,
        "meteor": 0.26122654631064807,
        "bleurt": -0.25641,
        "nubia": {
            "semantic_relation": 3.59337,
            "contradiction": 44.65833,
            "irrelevancy": 53.1804,
            "logical_agreement": 2.16127,
            "grammar_ref": 3.90726,
            "grammar_hyp": 4.14932,
            "nubia_score": 0.47085
        },
        "bertscore": {
            "precision": 0.78258,
            "recall": 0.76731,
            "f1": 0.76748
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "nist": 3.0881978509745025,
        "bleu": 68.94026,
        "meteor": 0.81809314801268,
        "bleurt": 0.64449,
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        },
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97491
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.80952,
            "recall": 0.59091,
            "fmeasure": 0.67236
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.4,
            "fmeasure": 0.47727
        },
        "rougeL": {
            "precision": 0.80952,
            "recall": 0.59091,
            "fmeasure": 0.67236
        },
        "rougeLsum": {
            "precision": 0.80952,
            "recall": 0.59091,
            "fmeasure": 0.67236
        },
        "nist": 2.503909578931098,
        "bleu": 59.59429,
        "meteor": 0.319191237100613,
        "bleurt": -0.0361,
        "nubia": {
            "semantic_relation": 3.95287,
            "contradiction": 5.31705,
            "irrelevancy": 31.0643,
            "logical_agreement": 63.61865,
            "grammar_ref": 5.78237,
            "grammar_hyp": 5.10443,
            "nubia_score": 0.70024
        },
        "bertscore": {
            "precision": 0.9799,
            "recall": 0.87115,
            "f1": 0.92233
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.63158,
            "recall": 0.93333,
            "fmeasure": 0.75142
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.67532,
            "fmeasure": 0.53448
        },
        "rougeL": {
            "precision": 0.38596,
            "recall": 0.57778,
            "fmeasure": 0.46173
        },
        "rougeLsum": {
            "precision": 0.38596,
            "recall": 0.57778,
            "fmeasure": 0.46173
        },
        "nist": 1.9098031644888838,
        "bleu": 23.41812,
        "meteor": 0.42669152467998045,
        "bleurt": -0.44266,
        "nubia": {
            "semantic_relation": 3.76718,
            "contradiction": 0.13699,
            "irrelevancy": 96.73154,
            "logical_agreement": 3.13146,
            "grammar_ref": 4.47457,
            "grammar_hyp": 4.46662,
            "nubia_score": 0.60619
        },
        "bertscore": {
            "precision": 0.80261,
            "recall": 0.90723,
            "f1": 0.8494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601997,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.03126257645096008,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.77632,
            "fmeasure": 0.76282
        },
        "rouge2": {
            "precision": 0.5614,
            "recall": 0.58285,
            "fmeasure": 0.57183
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.77632,
            "fmeasure": 0.76282
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.77632,
            "fmeasure": 0.76282
        },
        "nist": 3.555099738276094,
        "bleu": 50.32882,
        "meteor": 0.4546337124532775,
        "bleurt": 0.63533,
        "nubia": {
            "semantic_relation": 4.76259,
            "contradiction": 0.31001,
            "irrelevancy": 4.85593,
            "logical_agreement": 94.83406,
            "grammar_ref": 4.62058,
            "grammar_hyp": 4.32926,
            "nubia_score": 0.92242
        },
        "bertscore": {
            "precision": 0.9598,
            "recall": 0.95976,
            "f1": 0.95978
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.62465,
            "fmeasure": 0.69142
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.51282,
            "fmeasure": 0.58951
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.62465,
            "fmeasure": 0.69142
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.62465,
            "fmeasure": 0.69142
        },
        "nist": 3.179158422000987,
        "bleu": 50.78432,
        "meteor": 0.3876669651197313,
        "bleurt": 0.05546,
        "nubia": {
            "semantic_relation": 3.83539,
            "contradiction": 27.20618,
            "irrelevancy": 67.00664,
            "logical_agreement": 5.78718,
            "grammar_ref": 4.48877,
            "grammar_hyp": 4.52277,
            "nubia_score": 0.58167
        },
        "bertscore": {
            "precision": 0.96075,
            "recall": 0.91274,
            "f1": 0.92047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.19394,
            "fmeasure": 0.20702
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "nist": 0.9313738634396848,
        "bleu": 8.29519,
        "meteor": 0.2331715255855191,
        "bleurt": -0.53575,
        "nubia": {
            "semantic_relation": 2.78899,
            "contradiction": 0.29727,
            "irrelevancy": 97.22608,
            "logical_agreement": 2.47665,
            "grammar_ref": 4.79209,
            "grammar_hyp": 3.90146,
            "nubia_score": 0.40056
        },
        "bertscore": {
            "precision": 0.79602,
            "recall": 0.78154,
            "f1": 0.78871
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "nist": 3.0088906840841796,
        "bleu": 58.33511,
        "meteor": 0.4630505936482093,
        "bleurt": 0.7528,
        "nubia": {
            "semantic_relation": 4.98921,
            "contradiction": 0.42473,
            "irrelevancy": 22.33974,
            "logical_agreement": 77.23553,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.79251,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.97213,
            "recall": 0.96481,
            "f1": 0.96846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.625,
            "fmeasure": 0.625
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.42857,
            "fmeasure": 0.42857
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.625,
            "fmeasure": 0.625
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.625,
            "fmeasure": 0.625
        },
        "nist": 2.1132833342948754,
        "bleu": 23.3569,
        "meteor": 0.36393879011224795,
        "bleurt": 0.68235,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.73747,
            "irrelevancy": 0.55536,
            "logical_agreement": 98.70717,
            "grammar_ref": 5.85687,
            "grammar_hyp": 6.49111,
            "nubia_score": 0.86661
        },
        "bertscore": {
            "precision": 0.91504,
            "recall": 0.90917,
            "f1": 0.91209
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.51111,
            "fmeasure": 0.63059
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.37473,
            "fmeasure": 0.4715
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.51111,
            "fmeasure": 0.63059
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.51111,
            "fmeasure": 0.63059
        },
        "nist": 0.3259150714430162,
        "bleu": 25.91627,
        "meteor": 0.3204723844763208,
        "bleurt": 0.32531,
        "nubia": {
            "semantic_relation": 3.90656,
            "contradiction": 0.18927,
            "irrelevancy": 4.71062,
            "logical_agreement": 95.10011,
            "grammar_ref": 3.74426,
            "grammar_hyp": 4.73845,
            "nubia_score": 0.61151
        },
        "bertscore": {
            "precision": 0.97311,
            "recall": 0.89803,
            "f1": 0.93407
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.90476,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "nist": 3.462425934400558,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.45919,
        "nubia": {
            "semantic_relation": 4.21715,
            "contradiction": 0.42269,
            "irrelevancy": 0.62596,
            "logical_agreement": 98.95136,
            "grammar_ref": 6.37596,
            "grammar_hyp": 6.07415,
            "nubia_score": 0.84205
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.734521664779752,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.2875371587496606,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.3068905956085185,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.61438,
            "fmeasure": 0.59452
        },
        "rouge2": {
            "precision": 0.28889,
            "recall": 0.29924,
            "fmeasure": 0.29198
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.48039,
            "fmeasure": 0.46609
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.48039,
            "fmeasure": 0.46609
        },
        "nist": 2.3004723774353115,
        "bleu": 12.39899,
        "meteor": 0.28172493439430124,
        "bleurt": -0.02564,
        "nubia": {
            "semantic_relation": 3.48557,
            "contradiction": 10.76548,
            "irrelevancy": 87.45151,
            "logical_agreement": 1.78301,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.58252,
            "nubia_score": 0.48331
        },
        "bertscore": {
            "precision": 0.90154,
            "recall": 0.87253,
            "f1": 0.88366
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "total_length": 1718,
        "mean_pred_length": 27.26984126984127,
        "std_pred_length": 8.524858792679337,
        "median_pred_length": 27.0,
        "min_pred_length": 7,
        "max_pred_length": 48,
        "distinct-1": 0.4947613504074505,
        "vocab_size-1": 850,
        "unique-1": 687,
        "entropy-1": 8.420186473343605,
        "distinct-2": 0.9262839879154079,
        "vocab_size-2": 1533,
        "unique-2": 1462,
        "entropy-2": 10.496569582371428,
        "cond_entropy-2": 1.937404268683684,
        "distinct-3": 0.9949748743718593,
        "vocab_size-3": 1584,
        "unique-3": 1578,
        "entropy-3": 10.625318087880231,
        "cond_entropy-3": 0.13399404126084896,
        "total_length-nopunct": 1558,
        "mean_pred_length-nopunct": 24.73015873015873,
        "std_pred_length-nopunct": 7.551319340640319,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5417201540436457,
        "vocab_size-1-nopunct": 844,
        "unique-1-nopunct": 684,
        "entropy-1-nopunct": 8.662093235224019,
        "distinct-2-nopunct": 0.9431438127090301,
        "vocab_size-2-nopunct": 1410,
        "unique-2-nopunct": 1355,
        "entropy-2-nopunct": 10.408389361765703,
        "cond_entropy-2-nopunct": 1.8078686254944518,
        "distinct-3-nopunct": 0.9979050279329609,
        "vocab_size-3-nopunct": 1429,
        "unique-3-nopunct": 1426,
        "entropy-3-nopunct": 10.479625833130102,
        "cond_entropy-3-nopunct": 0.07728748090419585,
        "msttr-100": 0.73882,
        "msttr-100_nopunct": 0.77733,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.011571841851494697,
            "2": 0.2422360248447205,
            "3": 0.6808510638297872,
            "4": 0.8656716417910447,
            "5": 0.9490196078431372,
            "6": 0.9546599496221663,
            "7": 0.9584905660377359
        },
        "rouge1": {
            "precision": 0.95964,
            "recall": 0.93489,
            "fmeasure": 0.94246
        },
        "rouge2": {
            "precision": 0.91705,
            "recall": 0.89544,
            "fmeasure": 0.90118
        },
        "rougeL": {
            "precision": 0.95742,
            "recall": 0.93409,
            "fmeasure": 0.94093
        },
        "rougeLsum": {
            "precision": 0.95742,
            "recall": 0.93409,
            "fmeasure": 0.94093
        },
        "nist": 11.568337578194654,
        "bleu": 94.95086,
        "meteor": 0.643161468170161,
        "bleurt": 0.42353,
        "nubia": {
            "semantic_relation": 4.55484,
            "contradiction": 1.37258,
            "irrelevancy": 15.75821,
            "logical_agreement": 82.86921,
            "grammar_ref": 4.43738,
            "grammar_hyp": 4.48057,
            "nubia_score": 0.81405
        },
        "bertscore": {
            "precision": 0.98709,
            "recall": 0.98378,
            "f1": 0.98494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.07574294699860609,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.08866415466539351,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.2857142857142857,
            "3": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.26087,
            "recall": 0.19355,
            "fmeasure": 0.22222
        },
        "rouge2": {
            "precision": 0.04545,
            "recall": 0.03333,
            "fmeasure": 0.03846
        },
        "rougeL": {
            "precision": 0.10145,
            "recall": 0.16559,
            "fmeasure": 0.11785
        },
        "rougeLsum": {
            "precision": 0.10145,
            "recall": 0.16559,
            "fmeasure": 0.11785
        },
        "nist": 1.3627712037814919,
        "bleu": 2.9724,
        "meteor": 0.09718416119503934,
        "bleurt": -0.75918,
        "nubia": {
            "semantic_relation": 1.96678,
            "contradiction": 22.3446,
            "irrelevancy": 73.40732,
            "logical_agreement": 4.24807,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.92192,
            "nubia_score": 0.15127
        },
        "bertscore": {
            "precision": 0.76115,
            "recall": 0.76992,
            "f1": 0.75442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.75,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.3453,
            "fmeasure": 0.35165
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.4375,
            "fmeasure": 0.46667
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.4375,
            "fmeasure": 0.46667
        },
        "nist": 3.2780657238930058,
        "bleu": 22.35509,
        "meteor": 0.37563665624975745,
        "bleurt": 0.27596,
        "nubia": {
            "semantic_relation": 4.39876,
            "contradiction": 0.21963,
            "irrelevancy": 33.55081,
            "logical_agreement": 66.22955,
            "grammar_ref": 4.41465,
            "grammar_hyp": 5.85929,
            "nubia_score": 0.60921
        },
        "bertscore": {
            "precision": 0.93611,
            "recall": 0.91992,
            "f1": 0.92795
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.7,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "nist": 3.1566687205209765,
        "bleu": 59.2065,
        "meteor": 0.4603105469113841,
        "bleurt": 0.46434,
        "nubia": {
            "semantic_relation": 4.26096,
            "contradiction": 0.80225,
            "irrelevancy": 0.51437,
            "logical_agreement": 98.68338,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.89549,
            "nubia_score": 0.76313
        },
        "bertscore": {
            "precision": 0.96496,
            "recall": 0.93489,
            "f1": 0.94969
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.8465578035643277,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.87565,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.69325,
            "irrelevancy": 0.54497,
            "logical_agreement": 98.76179,
            "grammar_ref": 7.00423,
            "grammar_hyp": 7.45225,
            "nubia_score": 0.93405
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.6842105263157895,
        "vocab_size-1": 13,
        "unique-1": 7,
        "entropy-1": 3.616348566075164,
        "distinct-2": 0.7647058823529411,
        "vocab_size-2": 13,
        "unique-2": 9,
        "entropy-2": 3.6168746059562227,
        "cond_entropy-2": -0.04281761336971672,
        "distinct-3": 0.8666666666666667,
        "vocab_size-3": 13,
        "unique-3": 11,
        "entropy-3": 3.640223928941851,
        "cond_entropy-3": -0.047238912308487487,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.6875,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.375,
        "distinct-2-nopunct": 0.7857142857142857,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.3787834934861767,
        "cond_entropy-2-nopunct": -0.04978793508525296,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.2516291673878226,
        "cond_entropy-3-nopunct": -0.05572575466978135,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8235294117647058
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.80808,
            "fmeasure": 0.89164
        },
        "rouge2": {
            "precision": 0.85714,
            "recall": 0.675,
            "fmeasure": 0.75294
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.80808,
            "fmeasure": 0.89164
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.80808,
            "fmeasure": 0.89164
        },
        "nist": 3.9130114797625772,
        "bleu": 72.88984,
        "meteor": 0.48512412481345385,
        "bleurt": 0.81467,
        "nubia": {
            "semantic_relation": 4.91674,
            "contradiction": 0.52652,
            "irrelevancy": 8.79427,
            "logical_agreement": 90.67921,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.70076,
            "nubia_score": 0.9921
        },
        "bertscore": {
            "precision": 0.99383,
            "recall": 0.96534,
            "f1": 0.97796
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6190476190476191
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.6689,
            "fmeasure": 0.80098
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.52364,
            "fmeasure": 0.63243
        },
        "rougeL": {
            "precision": 0.9375,
            "recall": 0.62709,
            "fmeasure": 0.75092
        },
        "rougeLsum": {
            "precision": 0.9375,
            "recall": 0.62709,
            "fmeasure": 0.75092
        },
        "nist": 1.6041549626212654,
        "bleu": 23.89033,
        "meteor": 0.3693129849176603,
        "bleurt": 0.44769,
        "nubia": {
            "semantic_relation": 4.45563,
            "contradiction": 0.18531,
            "irrelevancy": 0.43326,
            "logical_agreement": 99.38143,
            "grammar_ref": 3.26294,
            "grammar_hyp": 2.73391,
            "nubia_score": 0.95943
        },
        "bertscore": {
            "precision": 0.96156,
            "recall": 0.87546,
            "f1": 0.91617
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.47058823529411764
        },
        "rouge1": {
            "precision": 0.64444,
            "recall": 0.54684,
            "fmeasure": 0.59154
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.18382,
            "fmeasure": 0.19785
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.34641,
            "fmeasure": 0.37121
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.34641,
            "fmeasure": 0.37121
        },
        "nist": 2.062866048948979,
        "bleu": 8.48719,
        "meteor": 0.2298489848661965,
        "bleurt": -0.33174,
        "nubia": {
            "semantic_relation": 3.40027,
            "contradiction": 0.43471,
            "irrelevancy": 93.69936,
            "logical_agreement": 5.86592,
            "grammar_ref": 4.84215,
            "grammar_hyp": 4.65894,
            "nubia_score": 0.44714
        },
        "bertscore": {
            "precision": 0.86056,
            "recall": 0.85094,
            "f1": 0.85572
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.45472,
            "fmeasure": 0.5162
        },
        "rouge2": {
            "precision": 0.2381,
            "recall": 0.175,
            "fmeasure": 0.20131
        },
        "rougeL": {
            "precision": 0.31111,
            "recall": 0.23716,
            "fmeasure": 0.26852
        },
        "rougeLsum": {
            "precision": 0.31111,
            "recall": 0.23716,
            "fmeasure": 0.26852
        },
        "nist": 2.567112202619359,
        "bleu": 7.74672,
        "meteor": 0.3120674165881927,
        "bleurt": -0.08718,
        "nubia": {
            "semantic_relation": 3.96444,
            "contradiction": 4.7388,
            "irrelevancy": 13.30346,
            "logical_agreement": 81.95774,
            "grammar_ref": 5.50536,
            "grammar_hyp": 5.17773,
            "nubia_score": 0.62193
        },
        "bertscore": {
            "precision": 0.87588,
            "recall": 0.86586,
            "f1": 0.86857
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5263157894736842
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.38406,
            "fmeasure": 0.52381
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.19436,
            "fmeasure": 0.27121
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.15362,
            "fmeasure": 0.20952
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.15362,
            "fmeasure": 0.20952
        },
        "nist": 0.5673719174486793,
        "bleu": 15.85,
        "meteor": 0.23339822190284532,
        "bleurt": -0.54869,
        "nubia": {
            "semantic_relation": 3.13152,
            "contradiction": 70.17115,
            "irrelevancy": 3.11966,
            "logical_agreement": 26.70919,
            "grammar_ref": 4.294,
            "grammar_hyp": 4.86977,
            "nubia_score": 0.24643
        },
        "bertscore": {
            "precision": 0.87659,
            "recall": 0.80677,
            "f1": 0.8398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "nist": 2.4414522615933616,
        "bleu": 64.34589,
        "meteor": 0.41468405035508926,
        "bleurt": 0.75286,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.52457,
            "irrelevancy": 0.92815,
            "logical_agreement": 98.54728,
            "grammar_ref": 6.21263,
            "grammar_hyp": 6.19444,
            "nubia_score": 0.97837
        },
        "bertscore": {
            "precision": 0.98422,
            "recall": 0.98422,
            "f1": 0.98422
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.886868538598291,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.88843,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2217,
            "irrelevancy": 0.43077,
            "logical_agreement": 99.34753,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.86832,
            "nubia_score": 0.98747
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.52778,
            "fmeasure": 0.64583
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.35417,
            "fmeasure": 0.44505
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.52778,
            "fmeasure": 0.64583
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.52778,
            "fmeasure": 0.64583
        },
        "nist": 0.7523186607677644,
        "bleu": 11.09148,
        "meteor": 0.3632707060776975,
        "bleurt": 0.46665,
        "nubia": {
            "semantic_relation": 4.48995,
            "contradiction": 0.4933,
            "irrelevancy": 0.56798,
            "logical_agreement": 98.93872,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.65309,
            "nubia_score": 0.88518
        },
        "bertscore": {
            "precision": 0.95553,
            "recall": 0.90658,
            "f1": 0.93041
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.75,
            "fmeasure": 0.70588
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "nist": 3.2302161591141387,
        "bleu": 67.03421,
        "meteor": 0.5131120550911532,
        "bleurt": 0.81644,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.19134,
            "irrelevancy": 3.01467,
            "logical_agreement": 96.79398,
            "grammar_ref": 4.6877,
            "grammar_hyp": 4.25112,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.97479,
            "recall": 0.99201,
            "f1": 0.98333
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 0.5,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 19,
        "unique-1": 15,
        "entropy-1": 4.175735869100492,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 20,
        "unique-2": 19,
        "entropy-2": 4.297079327540665,
        "cond_entropy-2": 0.05923165719793805,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.03912675144043808,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.106603137064474,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.142664355548846,
        "cond_entropy-2-nopunct": 0.06613640645429873,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.04281761336971672,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.42105263157894735
        },
        "rouge1": {
            "precision": 0.45758,
            "recall": 0.45724,
            "fmeasure": 0.45669
        },
        "rouge2": {
            "precision": 0.15556,
            "recall": 0.15715,
            "fmeasure": 0.15615
        },
        "rougeL": {
            "precision": 0.45758,
            "recall": 0.45724,
            "fmeasure": 0.45669
        },
        "rougeLsum": {
            "precision": 0.45758,
            "recall": 0.45724,
            "fmeasure": 0.45669
        },
        "nist": 1.872456174975236,
        "bleu": 6.47551,
        "meteor": 0.21676151195826449,
        "bleurt": -0.14024,
        "nubia": {
            "semantic_relation": 4.16871,
            "contradiction": 1.23298,
            "irrelevancy": 53.16736,
            "logical_agreement": 45.59966,
            "grammar_ref": 6.17452,
            "grammar_hyp": 5.62625,
            "nubia_score": 0.67952
        },
        "bertscore": {
            "precision": 0.85445,
            "recall": 0.83385,
            "f1": 0.84114
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.1111111111111111,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.43355,
            "fmeasure": 0.59692
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.33946,
            "fmeasure": 0.47826
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 0.43355,
            "fmeasure": 0.59692
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 0.43355,
            "fmeasure": 0.59692
        },
        "nist": 0.18623347460781886,
        "bleu": 26.4483,
        "meteor": 0.2947486648902057,
        "bleurt": -0.59628,
        "nubia": {
            "semantic_relation": 3.24439,
            "contradiction": 29.87979,
            "irrelevancy": 1.16633,
            "logical_agreement": 68.95387,
            "grammar_ref": 5.24053,
            "grammar_hyp": 6.31523,
            "nubia_score": 0.30089
        },
        "bertscore": {
            "precision": 0.93964,
            "recall": 0.88422,
            "f1": 0.91018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.69697,
            "fmeasure": 0.71146
        },
        "rouge2": {
            "precision": 0.55,
            "recall": 0.52727,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.69697,
            "fmeasure": 0.71146
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.69697,
            "fmeasure": 0.71146
        },
        "nist": 2.342478979140894,
        "bleu": 27.37929,
        "meteor": 0.3867080524339607,
        "bleurt": 0.48733,
        "nubia": {
            "semantic_relation": 4.65516,
            "contradiction": 0.3889,
            "irrelevancy": 4.41451,
            "logical_agreement": 95.19658,
            "grammar_ref": 4.19853,
            "grammar_hyp": 4.40053,
            "nubia_score": 0.87425
        },
        "bertscore": {
            "precision": 0.89668,
            "recall": 0.90983,
            "f1": 0.9017
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.10003715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.1,
            "3": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.5614,
            "recall": 0.50794,
            "fmeasure": 0.53333
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.2,
            "fmeasure": 0.21053
        },
        "rougeL": {
            "precision": 0.35088,
            "recall": 0.31746,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.35088,
            "recall": 0.31746,
            "fmeasure": 0.33333
        },
        "nist": 2.102366969727596,
        "bleu": 6.62167,
        "meteor": 0.2933127926114874,
        "bleurt": 0.15522,
        "nubia": {
            "semantic_relation": 4.33695,
            "contradiction": 38.26363,
            "irrelevancy": 21.1229,
            "logical_agreement": 40.61347,
            "grammar_ref": 3.9898,
            "grammar_hyp": 4.9543,
            "nubia_score": 0.60011
        },
        "bertscore": {
            "precision": 0.9007,
            "recall": 0.86128,
            "f1": 0.88055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 5,
        "mean_pred_length": 5.0,
        "std_pred_length": 0.0,
        "median_pred_length": 5.0,
        "min_pred_length": 5,
        "max_pred_length": 5,
        "distinct-1": 1.0,
        "vocab_size-1": 5,
        "unique-1": 5,
        "entropy-1": 2.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 4,
        "unique-2": 4,
        "entropy-2": 2.0,
        "cond_entropy-2": -0.32192809488736235,
        "distinct-3": 1.0,
        "vocab_size-3": 3,
        "unique-3": 3,
        "entropy-3": 1.584962500721156,
        "cond_entropy-3": -0.4150374992788437,
        "total_length-nopunct": 4,
        "mean_pred_length-nopunct": 4.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 4,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 4,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 3,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 1.584962500721156,
        "cond_entropy-2-nopunct": -0.4150374992788437,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 2,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 1.0,
        "cond_entropy-3-nopunct": -0.5849625007211562,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "nist": 1.3934338964335204,
        "bleu": 28.6419,
        "meteor": 0.4307001776843669,
        "bleurt": 0.82527,
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.30154,
            "irrelevancy": 0.49604,
            "logical_agreement": 99.20242,
            "grammar_ref": 5.72796,
            "grammar_hyp": 7.07513,
            "nubia_score": 0.79132
        },
        "bertscore": {
            "precision": 0.97397,
            "recall": 0.93815,
            "f1": 0.95573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.0,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.6363636363636364,
        "vocab_size-1": 14,
        "unique-1": 7,
        "entropy-1": 3.697845823084412,
        "distinct-2": 0.75,
        "vocab_size-2": 15,
        "unique-2": 10,
        "entropy-2": 3.821928094887362,
        "cond_entropy-2": 0.10024085135823842,
        "distinct-3": 0.8333333333333334,
        "vocab_size-3": 15,
        "unique-3": 12,
        "entropy-3": 3.8365916681089787,
        "cond_entropy-3": -0.04089198233393866,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.4613201402110083,
        "distinct-2-nopunct": 0.8125,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.625,
        "cond_entropy-2-nopunct": 0.12725546744290445,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.521640636343319,
        "cond_entropy-3-nopunct": -0.04978793508525297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6521739130434783
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.72727,
            "fmeasure": 0.79798
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.4375
        },
        "rougeL": {
            "precision": 0.86364,
            "recall": 0.68182,
            "fmeasure": 0.75253
        },
        "rougeLsum": {
            "precision": 0.86364,
            "recall": 0.68182,
            "fmeasure": 0.75253
        },
        "nist": 1.752669255529416,
        "bleu": 14.85347,
        "meteor": 0.24630350789422903,
        "bleurt": 0.26952,
        "nubia": {
            "semantic_relation": 4.24866,
            "contradiction": 1.43853,
            "irrelevancy": 0.96842,
            "logical_agreement": 97.59306,
            "grammar_ref": 4.1188,
            "grammar_hyp": 4.74529,
            "nubia_score": 0.70273
        },
        "bertscore": {
            "precision": 0.95839,
            "recall": 0.87683,
            "f1": 0.91446
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.589898095464287,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.24009914803219054,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.13692518080981952,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.46429,
            "recall": 0.58547,
            "fmeasure": 0.51369
        },
        "rouge2": {
            "precision": 0.26923,
            "recall": 0.33333,
            "fmeasure": 0.29524
        },
        "rougeL": {
            "precision": 0.46429,
            "recall": 0.58547,
            "fmeasure": 0.51369
        },
        "rougeLsum": {
            "precision": 0.46429,
            "recall": 0.58547,
            "fmeasure": 0.51369
        },
        "nist": 2.3155368703474615,
        "bleu": 19.25161,
        "meteor": 0.33575706334962574,
        "bleurt": -0.18679,
        "nubia": {
            "semantic_relation": 3.6713,
            "contradiction": 0.28884,
            "irrelevancy": 83.3903,
            "logical_agreement": 16.32085,
            "grammar_ref": 4.60771,
            "grammar_hyp": 4.62535,
            "nubia_score": 0.51491
        },
        "bertscore": {
            "precision": 0.85514,
            "recall": 0.86242,
            "f1": 0.85123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.037537158749660585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.69697,
            "fmeasure": 0.54253
        },
        "rouge2": {
            "precision": 0.29412,
            "recall": 0.47727,
            "fmeasure": 0.36376
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.52273,
            "fmeasure": 0.4069
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.52273,
            "fmeasure": 0.4069
        },
        "nist": 1.6260275876122958,
        "bleu": 17.18153,
        "meteor": 0.3256838604697674,
        "bleurt": 0.10808,
        "nubia": {
            "semantic_relation": 4.34341,
            "contradiction": 0.07854,
            "irrelevancy": 98.59162,
            "logical_agreement": 1.32985,
            "grammar_ref": 5.10481,
            "grammar_hyp": 4.49675,
            "nubia_score": 0.75155
        },
        "bertscore": {
            "precision": 0.8558,
            "recall": 0.89924,
            "f1": 0.87698
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 1.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.79206,
            "fmeasure": 0.78467
        },
        "rouge2": {
            "precision": 0.40476,
            "recall": 0.41026,
            "fmeasure": 0.40741
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.56667,
            "fmeasure": 0.56092
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.56667,
            "fmeasure": 0.56092
        },
        "nist": 4.150367535985529,
        "bleu": 33.36823,
        "meteor": 0.4169278925510008,
        "bleurt": -0.0545,
        "nubia": {
            "semantic_relation": 3.77337,
            "contradiction": 0.51365,
            "irrelevancy": 71.76558,
            "logical_agreement": 27.72078,
            "grammar_ref": 4.11472,
            "grammar_hyp": 3.37207,
            "nubia_score": 0.74853
        },
        "bertscore": {
            "precision": 0.91772,
            "recall": 0.89861,
            "f1": 0.90806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.3219280948873626,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.97683,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.037503523749935014,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.72222,
            "fmeasure": 0.69281
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.27381,
            "fmeasure": 0.26111
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.60185,
            "fmeasure": 0.57734
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.60185,
            "fmeasure": 0.57734
        },
        "nist": 2.182650875192532,
        "bleu": 11.13261,
        "meteor": 0.29042090518621033,
        "bleurt": 0.14548,
        "nubia": {
            "semantic_relation": 4.65264,
            "contradiction": 0.90132,
            "irrelevancy": 33.52665,
            "logical_agreement": 65.57203,
            "grammar_ref": 5.6187,
            "grammar_hyp": 6.60807,
            "nubia_score": 0.6541
        },
        "bertscore": {
            "precision": 0.89821,
            "recall": 0.86727,
            "f1": 0.88131
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666
        },
        "rouge1": {
            "precision": 0.2,
            "recall": 0.13333,
            "fmeasure": 0.16
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.07143,
            "fmeasure": 0.08696
        },
        "rougeL": {
            "precision": 0.2,
            "recall": 0.13333,
            "fmeasure": 0.16
        },
        "rougeLsum": {
            "precision": 0.2,
            "recall": 0.13333,
            "fmeasure": 0.16
        },
        "nist": 0.4728176046727473,
        "bleu": 5.0971,
        "meteor": 0.08747263697277605,
        "bleurt": -0.67698,
        "nubia": {
            "semantic_relation": 2.01785,
            "contradiction": 1.77885,
            "irrelevancy": 90.6883,
            "logical_agreement": 7.53285,
            "grammar_ref": 5.48676,
            "grammar_hyp": 5.07538,
            "nubia_score": 0.14205
        },
        "bertscore": {
            "precision": 0.74579,
            "recall": 0.6847,
            "f1": 0.71394
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "t5-small/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.6412498004554794,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 0.6111111111111112,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.392147223664534,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.91667,
            "fmeasure": 0.95652
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.81818,
            "fmeasure": 0.85714
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.91667,
            "fmeasure": 0.95652
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.91667,
            "fmeasure": 0.95652
        },
        "nist": 3.569636662899469,
        "bleu": 76.11606,
        "meteor": 0.5398895612015752,
        "bleurt": 0.7596,
        "nubia": {
            "semantic_relation": 4.77808,
            "contradiction": 0.93501,
            "irrelevancy": 0.60596,
            "logical_agreement": 98.45902,
            "grammar_ref": 5.00662,
            "grammar_hyp": 4.79063,
            "nubia_score": 0.88767
        },
        "bertscore": {
            "precision": 0.98695,
            "recall": 0.95995,
            "f1": 0.97326
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.7619,
            "recall": 0.64815,
            "fmeasure": 0.7
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.51786,
            "fmeasure": 0.56044
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.61111,
            "fmeasure": 0.65833
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.61111,
            "fmeasure": 0.65833
        },
        "nist": 3.9298102988486567,
        "bleu": 84.08964,
        "meteor": 0.4913780175462578,
        "bleurt": 0.06602,
        "nubia": {
            "semantic_relation": 3.33504,
            "contradiction": 2.50955,
            "irrelevancy": 1.66889,
            "logical_agreement": 95.82157,
            "grammar_ref": 3.66596,
            "grammar_hyp": 5.17851,
            "nubia_score": 0.42782
        },
        "bertscore": {
            "precision": 0.94574,
            "recall": 0.95687,
            "f1": 0.95127
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "t5-small/totto_test",
        "N": 3,
        "total_length": 32,
        "mean_pred_length": 10.666666666666666,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.5625,
        "vocab_size-1": 18,
        "unique-1": 10,
        "entropy-1": 3.9681390622295662,
        "distinct-2": 0.7586206896551724,
        "vocab_size-2": 22,
        "unique-2": 16,
        "entropy-2": 4.349191770915038,
        "cond_entropy-2": 0.3238353056216045,
        "distinct-3": 0.8461538461538461,
        "vocab_size-3": 22,
        "unique-3": 18,
        "entropy-3": 4.392747410448783,
        "cond_entropy-3": 0.02533901155826875,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5925925925925926,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7821222241453065,
        "distinct-2-nopunct": 0.7916666666666666,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.136842188131012,
        "cond_entropy-2-nopunct": 0.34423541534454694,
        "distinct-3-nopunct": 0.9047619047619048,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.201841232302569,
        "cond_entropy-3-nopunct": 0.03377813644634074,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.82735,
            "recall": 0.77181,
            "fmeasure": 0.79554
        },
        "rouge2": {
            "precision": 0.69136,
            "recall": 0.65617,
            "fmeasure": 0.67098
        },
        "rougeL": {
            "precision": 0.75043,
            "recall": 0.7126,
            "fmeasure": 0.72873
        },
        "rougeLsum": {
            "precision": 0.75043,
            "recall": 0.7126,
            "fmeasure": 0.72873
        },
        "nist": 2.762766242073967,
        "bleu": 35.51814,
        "meteor": 0.3197167195340106,
        "bleurt": 0.41854,
        "nubia": {
            "semantic_relation": 4.21441,
            "contradiction": 18.42885,
            "irrelevancy": 12.14268,
            "logical_agreement": 69.42848,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.73532,
            "nubia_score": 0.6885
        },
        "bertscore": {
            "precision": 0.94047,
            "recall": 0.92259,
            "f1": 0.92959
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "total_length": 3020,
        "mean_pred_length": 18.19277108433735,
        "std_pred_length": 7.727213421463823,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.44900662251655626,
        "vocab_size-1": 1356,
        "unique-1": 1081,
        "entropy-1": 8.576112394409316,
        "distinct-2": 0.8728100911002102,
        "vocab_size-2": 2491,
        "unique-2": 2350,
        "entropy-2": 11.051053202339377,
        "cond_entropy-2": 2.2146447127351703,
        "distinct-3": 0.9769345238095238,
        "vocab_size-3": 2626,
        "unique-3": 2585,
        "entropy-3": 11.33811705653211,
        "cond_entropy-3": 0.3033700298779383,
        "total_length-nopunct": 2662,
        "mean_pred_length-nopunct": 16.03614457831325,
        "std_pred_length-nopunct": 6.682012868821574,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5067618332081142,
        "vocab_size-1-nopunct": 1349,
        "unique-1-nopunct": 1081,
        "entropy-1-nopunct": 8.90317820755513,
        "distinct-2-nopunct": 0.8834134615384616,
        "vocab_size-2-nopunct": 2205,
        "unique-2-nopunct": 2095,
        "entropy-2-nopunct": 10.879826792887403,
        "cond_entropy-2-nopunct": 2.1125273874189396,
        "distinct-3-nopunct": 0.9824034334763948,
        "vocab_size-3-nopunct": 2289,
        "unique-3-nopunct": 2259,
        "entropy-3-nopunct": 11.146936465929778,
        "cond_entropy-3-nopunct": 0.2896721765660627,
        "msttr-100": 0.71367,
        "msttr-100_nopunct": 0.75923,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.029078363725973385,
            "2": 0.17383512544802868,
            "3": 0.42704626334519574,
            "4": 0.6223175965665236,
            "5": 0.7465437788018433,
            "6": 0.8787878787878788,
            "7": 0.9225352112676056,
            "8": 0.9710610932475884,
            "9": 0.9696969696969697,
            "10": 0.9917491749174917
        },
        "rouge1": {
            "precision": 0.91712,
            "recall": 0.93055,
            "fmeasure": 0.92003
        },
        "rouge2": {
            "precision": 0.82997,
            "recall": 0.85457,
            "fmeasure": 0.83727
        },
        "rougeL": {
            "precision": 0.90284,
            "recall": 0.91935,
            "fmeasure": 0.90726
        },
        "rougeLsum": {
            "precision": 0.90284,
            "recall": 0.91935,
            "fmeasure": 0.90726
        },
        "nist": 12.622192000590765,
        "bleu": 92.18039,
        "meteor": 0.5747089397054144,
        "bleurt": 0.41485,
        "nubia": {
            "semantic_relation": 4.49246,
            "contradiction": 2.26483,
            "irrelevancy": 29.66824,
            "logical_agreement": 68.06694,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.38366,
            "nubia_score": 0.81612
        },
        "bertscore": {
            "precision": 0.98145,
            "recall": 0.98511,
            "f1": 0.98108
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.90909,
            "fmeasure": 0.90909
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "nist": 2.964645514318526,
        "bleu": 57.8357,
        "meteor": 0.6047441855848348,
        "bleurt": 0.28191,
        "nubia": {
            "semantic_relation": 4.49578,
            "contradiction": 18.9933,
            "irrelevancy": 67.98386,
            "logical_agreement": 13.02284,
            "grammar_ref": 4.85772,
            "grammar_hyp": 5.59002,
            "nubia_score": 0.57415
        },
        "bertscore": {
            "precision": 0.97662,
            "recall": 0.96725,
            "f1": 0.97191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5625,
            "fmeasure": 0.52941
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.28571,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.5625,
            "fmeasure": 0.52941
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.5625,
            "fmeasure": 0.52941
        },
        "nist": 2.5612239888752377,
        "bleu": 21.36435,
        "meteor": 0.3438239212500029,
        "bleurt": -0.22974,
        "nubia": {
            "semantic_relation": 3.62597,
            "contradiction": 2.44109,
            "irrelevancy": 94.03182,
            "logical_agreement": 3.52708,
            "grammar_ref": 5.57872,
            "grammar_hyp": 6.72231,
            "nubia_score": 0.35669
        },
        "bertscore": {
            "precision": 0.85772,
            "recall": 0.86671,
            "f1": 0.86219
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "t5-small/totto_test",
        "N": 1850,
        "total_length": 25023,
        "mean_pred_length": 13.525945945945946,
        "std_pred_length": 3.606994301211197,
        "median_pred_length": 14.0,
        "min_pred_length": 2,
        "max_pred_length": 26,
        "distinct-1": 0.25524517443951567,
        "vocab_size-1": 6387,
        "unique-1": 4773,
        "entropy-1": 9.12393293196942,
        "distinct-2": 0.58809821775342,
        "vocab_size-2": 13628,
        "unique-2": 11978,
        "entropy-2": 12.263838434052339,
        "cond_entropy-2": 2.752572983868397,
        "distinct-3": 0.7498006847066548,
        "vocab_size-3": 15988,
        "unique-3": 14848,
        "entropy-3": 13.085501913069493,
        "cond_entropy-3": 0.8966569474755979,
        "total_length-nopunct": 21891,
        "mean_pred_length-nopunct": 11.832972972972973,
        "std_pred_length-nopunct": 3.288587033202134,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.2911242062948244,
        "vocab_size-1-nopunct": 6373,
        "unique-1-nopunct": 4772,
        "entropy-1-nopunct": 9.546996736524461,
        "distinct-2-nopunct": 0.6050097300533905,
        "vocab_size-2-nopunct": 12125,
        "unique-2-nopunct": 10820,
        "entropy-2-nopunct": 12.074428576284813,
        "cond_entropy-2-nopunct": 2.7779365846196975,
        "distinct-3-nopunct": 0.7530097300863065,
        "vocab_size-3-nopunct": 13698,
        "unique-3-nopunct": 12764,
        "entropy-3-nopunct": 12.863696393472283,
        "cond_entropy-3-nopunct": 0.960519876646458,
        "msttr-100": 0.68868,
        "msttr-100_nopunct": 0.7344,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2644981412639405,
            "2": 0.4705994654448263,
            "3": 0.753641503159295
        },
        "rouge1": {
            "precision": 0.72116,
            "recall": 0.7113,
            "fmeasure": 0.70321
        },
        "rouge2": {
            "precision": 0.51332,
            "recall": 0.50241,
            "fmeasure": 0.4986
        },
        "rougeL": {
            "precision": 0.6484,
            "recall": 0.63872,
            "fmeasure": 0.63186
        },
        "rougeLsum": {
            "precision": 0.6484,
            "recall": 0.63872,
            "fmeasure": 0.63186
        },
        "nist": 9.132520174259675,
        "bleu": 47.54781,
        "meteor": 0.3857321985474973,
        "bleurt": 0.25374,
        "nubia": {
            "semantic_relation": 4.11002,
            "contradiction": 7.91208,
            "irrelevancy": 33.98914,
            "logical_agreement": 58.09878,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.69774,
            "nubia_score": 0.70584
        },
        "bertscore": {
            "precision": 0.91916,
            "recall": 0.91905,
            "f1": 0.91744
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.75556,
            "fmeasure": 0.70707
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.55556,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.75556,
            "fmeasure": 0.70707
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.75556,
            "fmeasure": 0.70707
        },
        "nist": 1.8627708715739293,
        "bleu": 39.55333,
        "meteor": 0.3362351251375338,
        "bleurt": 0.07632,
        "nubia": {
            "semantic_relation": 3.82328,
            "contradiction": 6.20516,
            "irrelevancy": 43.75143,
            "logical_agreement": 50.0434,
            "grammar_ref": 5.64952,
            "grammar_hyp": 4.38342,
            "nubia_score": 0.57387
        },
        "bertscore": {
            "precision": 0.87269,
            "recall": 0.87493,
            "f1": 0.87381
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "total_length": 1317,
        "mean_pred_length": 22.70689655172414,
        "std_pred_length": 8.72967317927107,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 45,
        "distinct-1": 0.5056947608200456,
        "vocab_size-1": 666,
        "unique-1": 536,
        "entropy-1": 8.122601284640332,
        "distinct-2": 0.9253375694996029,
        "vocab_size-2": 1165,
        "unique-2": 1120,
        "entropy-2": 10.085418802247988,
        "cond_entropy-2": 1.7906675481738372,
        "distinct-3": 0.9941715237302248,
        "vocab_size-3": 1194,
        "unique-3": 1187,
        "entropy-3": 10.21836348316607,
        "cond_entropy-3": 0.14321390522871566,
        "total_length-nopunct": 1178,
        "mean_pred_length-nopunct": 20.310344827586206,
        "std_pred_length-nopunct": 7.90723565749516,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5594227504244482,
        "vocab_size-1-nopunct": 659,
        "unique-1-nopunct": 535,
        "entropy-1-nopunct": 8.326529399485695,
        "distinct-2-nopunct": 0.9357142857142857,
        "vocab_size-2-nopunct": 1048,
        "unique-2-nopunct": 1008,
        "entropy-2-nopunct": 9.96311439171861,
        "cond_entropy-2-nopunct": 1.7238925606365272,
        "distinct-3-nopunct": 0.9934086629001884,
        "vocab_size-3-nopunct": 1055,
        "unique-3-nopunct": 1048,
        "entropy-3-nopunct": 10.039385376604294,
        "cond_entropy-3-nopunct": 0.08534610754404887,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75909,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.036170212765957444,
            "2": 0.1937984496124031,
            "3": 0.4105960264900662,
            "4": 0.5545454545454546,
            "5": 0.8222222222222222,
            "6": 0.8557692307692307,
            "7": 0.9210526315789473,
            "8": 0.9659863945578231,
            "9": 0.9803921568627451,
            "10": 0.9906103286384976
        },
        "rouge1": {
            "precision": 0.9223,
            "recall": 0.93588,
            "fmeasure": 0.92509
        },
        "rouge2": {
            "precision": 0.84949,
            "recall": 0.85858,
            "fmeasure": 0.84877
        },
        "rougeL": {
            "precision": 0.91277,
            "recall": 0.92549,
            "fmeasure": 0.91485
        },
        "rougeLsum": {
            "precision": 0.91277,
            "recall": 0.92549,
            "fmeasure": 0.91485
        },
        "nist": 11.81160477304472,
        "bleu": 93.01664,
        "meteor": 0.5647398537278113,
        "bleurt": 0.35385,
        "nubia": {
            "semantic_relation": 4.39796,
            "contradiction": 2.35381,
            "irrelevancy": 31.30141,
            "logical_agreement": 66.34478,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.25956,
            "nubia_score": 0.78051
        },
        "bertscore": {
            "precision": 0.97781,
            "recall": 0.97977,
            "f1": 0.97692
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "t5-small/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730745,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.867976246918685,
        "bleu": 100.0,
        "meteor": 1.0,
        "bleurt": 0.73788,
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "total_length": 754,
        "mean_pred_length": 23.5625,
        "std_pred_length": 9.134199130191984,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 41,
        "distinct-1": 0.5318302387267905,
        "vocab_size-1": 401,
        "unique-1": 320,
        "entropy-1": 7.651332152946935,
        "distinct-2": 0.9127423822714681,
        "vocab_size-2": 659,
        "unique-2": 620,
        "entropy-2": 9.28544865154349,
        "cond_entropy-2": 1.4877512994691737,
        "distinct-3": 0.9855072463768116,
        "vocab_size-3": 680,
        "unique-3": 671,
        "entropy-3": 9.400373004560961,
        "cond_entropy-3": 0.12323305448281241,
        "total_length-nopunct": 664,
        "mean_pred_length-nopunct": 20.75,
        "std_pred_length-nopunct": 7.806247497997997,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.5948795180722891,
        "vocab_size-1-nopunct": 395,
        "unique-1-nopunct": 319,
        "entropy-1-nopunct": 7.849807195752457,
        "distinct-2-nopunct": 0.9224683544303798,
        "vocab_size-2-nopunct": 583,
        "unique-2-nopunct": 554,
        "entropy-2-nopunct": 9.112493006104975,
        "cond_entropy-2-nopunct": 1.3238211055069808,
        "distinct-3-nopunct": 0.9866666666666667,
        "vocab_size-3-nopunct": 592,
        "unique-3-nopunct": 585,
        "entropy-3-nopunct": 9.200893877992291,
        "cond_entropy-3-nopunct": 0.0952695514644744,
        "msttr-100": 0.69714,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.028747433264887063,
            "2": 0.27102803738317754,
            "3": 0.4647887323943662,
            "4": 0.765625,
            "5": 0.8363636363636363,
            "6": 0.8970588235294118,
            "7": 0.9696969696969697,
            "8": 0.9841269841269841,
            "9": 0.9404761904761905,
            "10": 0.9919354838709677
        },
        "rouge1": {
            "precision": 0.92394,
            "recall": 0.94142,
            "fmeasure": 0.92914
        },
        "rouge2": {
            "precision": 0.83833,
            "recall": 0.86454,
            "fmeasure": 0.84742
        },
        "rougeL": {
            "precision": 0.90571,
            "recall": 0.92398,
            "fmeasure": 0.91116
        },
        "rougeLsum": {
            "precision": 0.90571,
            "recall": 0.92398,
            "fmeasure": 0.91116
        },
        "nist": 10.921081071207142,
        "bleu": 94.38485,
        "meteor": 0.5787054431273644,
        "bleurt": 0.36696,
        "nubia": {
            "semantic_relation": 4.52259,
            "contradiction": 1.74519,
            "irrelevancy": 34.96765,
            "logical_agreement": 63.28715,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.09554,
            "nubia_score": 0.81055
        },
        "bertscore": {
            "precision": 0.98056,
            "recall": 0.98484,
            "f1": 0.9817
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "total_length": 97,
        "mean_pred_length": 19.4,
        "std_pred_length": 8.616263691415206,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.7216494845360825,
        "vocab_size-1": 70,
        "unique-1": 56,
        "entropy-1": 5.854916321501668,
        "distinct-2": 0.9891304347826086,
        "vocab_size-2": 91,
        "unique-2": 90,
        "entropy-2": 6.501822825622244,
        "cond_entropy-2": 0.5469083530316744,
        "distinct-3": 1.0,
        "vocab_size-3": 87,
        "unique-3": 87,
        "entropy-3": 6.442943495848723,
        "cond_entropy-3": -0.057629954461158185,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 17.8,
        "std_pred_length-nopunct": 7.858753081755401,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7640449438202247,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.860509975885917,
        "distinct-2-nopunct": 0.9880952380952381,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 82,
        "entropy-2-nopunct": 6.368507898969236,
        "cond_entropy-2-nopunct": 0.5446183668381178,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.303780748177105,
        "cond_entropy-3-nopunct": -0.06322021890545503,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.06944444444444445,
            "2": 0.19047619047619047,
            "3": 0.375,
            "4": 0.8,
            "5": 0.5714285714285714,
            "6": 0.9230769230769231,
            "7": 1.0,
            "8": 1.0,
            "9": 0.875,
            "10": 1.0
        },
        "rouge1": {
            "precision": 0.94148,
            "recall": 0.9031,
            "fmeasure": 0.92022
        },
        "rouge2": {
            "precision": 0.87803,
            "recall": 0.84164,
            "fmeasure": 0.85769
        },
        "rougeL": {
            "precision": 0.93981,
            "recall": 0.90477,
            "fmeasure": 0.92007
        },
        "rougeLsum": {
            "precision": 0.93981,
            "recall": 0.90477,
            "fmeasure": 0.92007
        },
        "nist": 7.799229185926382,
        "bleu": 86.30421,
        "meteor": 0.620780248932557,
        "bleurt": 0.45721,
        "nubia": {
            "semantic_relation": 4.56899,
            "contradiction": 0.1696,
            "irrelevancy": 33.53606,
            "logical_agreement": 66.29434,
            "grammar_ref": 5.04038,
            "grammar_hyp": 4.90111,
            "nubia_score": 0.79767
        },
        "bertscore": {
            "precision": 0.99067,
            "recall": 0.992,
            "f1": 0.98972
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "total_length": 728,
        "mean_pred_length": 26.0,
        "std_pred_length": 11.907380664349077,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 65,
        "distinct-1": 0.554945054945055,
        "vocab_size-1": 404,
        "unique-1": 335,
        "entropy-1": 7.756583970918355,
        "distinct-2": 0.9242857142857143,
        "vocab_size-2": 647,
        "unique-2": 614,
        "entropy-2": 9.267017259018742,
        "cond_entropy-2": 1.3861624750664487,
        "distinct-3": 0.9821428571428571,
        "vocab_size-3": 660,
        "unique-3": 651,
        "entropy-3": 9.353233103572693,
        "cond_entropy-3": 0.08793820746883828,
        "total_length-nopunct": 648,
        "mean_pred_length-nopunct": 23.142857142857142,
        "std_pred_length-nopunct": 9.62405574482982,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.6141975308641975,
        "vocab_size-1-nopunct": 398,
        "unique-1-nopunct": 334,
        "entropy-1-nopunct": 7.890436329002734,
        "distinct-2-nopunct": 0.9435483870967742,
        "vocab_size-2-nopunct": 585,
        "unique-2-nopunct": 562,
        "entropy-2-nopunct": 9.138340660169062,
        "cond_entropy-2-nopunct": 1.2973635563782333,
        "distinct-3-nopunct": 0.9949324324324325,
        "vocab_size-3-nopunct": 589,
        "unique-3-nopunct": 586,
        "entropy-3-nopunct": 9.199318230493787,
        "cond_entropy-3-nopunct": 0.06411599070136818,
        "msttr-100": 0.71714,
        "msttr-100_nopunct": 0.76833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03275529865125241,
            "2": 0.18421052631578946,
            "3": 0.40789473684210525,
            "4": 0.6129032258064516,
            "5": 0.7741935483870968,
            "6": 0.8888888888888888,
            "7": 0.9506172839506173,
            "8": 1.0,
            "9": 0.9818181818181818,
            "10": 1.0
        },
        "rouge1": {
            "precision": 0.91518,
            "recall": 0.91904,
            "fmeasure": 0.91502
        },
        "rouge2": {
            "precision": 0.842,
            "recall": 0.8559,
            "fmeasure": 0.84453
        },
        "rougeL": {
            "precision": 0.90508,
            "recall": 0.91892,
            "fmeasure": 0.90857
        },
        "rougeLsum": {
            "precision": 0.90508,
            "recall": 0.91892,
            "fmeasure": 0.90857
        },
        "nist": 10.657093654179457,
        "bleu": 92.62875,
        "meteor": 0.5984371034051811,
        "bleurt": 0.28758,
        "nubia": {
            "semantic_relation": 4.44707,
            "contradiction": 1.89422,
            "irrelevancy": 30.63544,
            "logical_agreement": 67.47033,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.44746,
            "nubia_score": 0.76922
        },
        "bertscore": {
            "precision": 0.981,
            "recall": 0.98361,
            "f1": 0.98053
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "total_length": 180,
        "mean_pred_length": 25.714285714285715,
        "std_pred_length": 5.7498890849994595,
        "median_pred_length": 26.0,
        "min_pred_length": 17,
        "max_pred_length": 37,
        "distinct-1": 0.7055555555555556,
        "vocab_size-1": 127,
        "unique-1": 113,
        "entropy-1": 6.550509016350641,
        "distinct-2": 0.9595375722543352,
        "vocab_size-2": 166,
        "unique-2": 163,
        "entropy-2": 7.328474886731522,
        "cond_entropy-2": 0.6946676539638329,
        "distinct-3": 1.0,
        "vocab_size-3": 166,
        "unique-3": 166,
        "entropy-3": 7.375039431346908,
        "cond_entropy-3": 0.03899269754514164,
        "total_length-nopunct": 159,
        "mean_pred_length-nopunct": 22.714285714285715,
        "std_pred_length-nopunct": 4.130523512800274,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.7672955974842768,
        "vocab_size-1-nopunct": 122,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.555509468570055,
        "distinct-2-nopunct": 0.9605263157894737,
        "vocab_size-2-nopunct": 146,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.140266145176459,
        "cond_entropy-2-nopunct": 0.6196357187577162,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 145,
        "unique-3-nopunct": 145,
        "entropy-3-nopunct": 7.179909090014958,
        "cond_entropy-3-nopunct": 0.04484039020307509,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03529411764705882,
            "2": 0.13636363636363635,
            "3": 0.6666666666666666,
            "4": 0.9166666666666666,
            "5": 0.9375,
            "6": 1.0,
            "7": 1.0,
            "8": 0.96,
            "9": 1.0,
            "10": 0.9583333333333334
        },
        "rouge1": {
            "precision": 0.90122,
            "recall": 0.94414,
            "fmeasure": 0.91993
        },
        "rouge2": {
            "precision": 0.83439,
            "recall": 0.88632,
            "fmeasure": 0.85665
        },
        "rougeL": {
            "precision": 0.88522,
            "recall": 0.93984,
            "fmeasure": 0.91031
        },
        "rougeLsum": {
            "precision": 0.88522,
            "recall": 0.93984,
            "fmeasure": 0.91031
        },
        "nist": 8.559278050833372,
        "bleu": 90.30807,
        "meteor": 0.5900354132801044,
        "bleurt": 0.31503,
        "nubia": {
            "semantic_relation": 4.39303,
            "contradiction": 1.75963,
            "irrelevancy": 46.81759,
            "logical_agreement": 51.42278,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.3273,
            "nubia_score": 0.75265
        },
        "bertscore": {
            "precision": 0.98105,
            "recall": 0.98662,
            "f1": 0.982
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "total_length": 1812,
        "mean_pred_length": 28.761904761904763,
        "std_pred_length": 8.71909833279574,
        "median_pred_length": 27.0,
        "min_pred_length": 10,
        "max_pred_length": 48,
        "distinct-1": 0.4867549668874172,
        "vocab_size-1": 882,
        "unique-1": 714,
        "entropy-1": 8.448258810432531,
        "distinct-2": 0.9291023441966838,
        "vocab_size-2": 1625,
        "unique-2": 1556,
        "entropy-2": 10.58798243225297,
        "cond_entropy-2": 2.003032115802414,
        "distinct-3": 0.99644128113879,
        "vocab_size-3": 1680,
        "unique-3": 1675,
        "entropy-3": 10.711823644487682,
        "cond_entropy-3": 0.12612949065903292,
        "total_length-nopunct": 1631,
        "mean_pred_length-nopunct": 25.88888888888889,
        "std_pred_length-nopunct": 7.576302048736314,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5364806866952789,
        "vocab_size-1-nopunct": 875,
        "unique-1-nopunct": 712,
        "entropy-1-nopunct": 8.679140702052969,
        "distinct-2-nopunct": 0.9451530612244898,
        "vocab_size-2-nopunct": 1482,
        "unique-2-nopunct": 1429,
        "entropy-2-nopunct": 10.479721317992865,
        "cond_entropy-2-nopunct": 1.857628704381283,
        "distinct-3-nopunct": 0.998671096345515,
        "vocab_size-3-nopunct": 1503,
        "unique-3-nopunct": 1501,
        "entropy-3-nopunct": 10.55288996433821,
        "cond_entropy-3-nopunct": 0.07881932883424232,
        "msttr-100": 0.74444,
        "msttr-100_nopunct": 0.7875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03510204081632653,
            "2": 0.22131147540983606,
            "3": 0.4824561403508772,
            "4": 0.7177914110429447,
            "5": 0.7964071856287425,
            "6": 0.9032258064516129,
            "7": 0.9457831325301205,
            "8": 0.9767441860465116,
            "9": 0.9942528735632183,
            "10": 0.9907407407407407
        },
        "rouge1": {
            "precision": 0.89978,
            "recall": 0.92892,
            "fmeasure": 0.91127
        },
        "rouge2": {
            "precision": 0.81536,
            "recall": 0.84527,
            "fmeasure": 0.82685
        },
        "rougeL": {
            "precision": 0.88801,
            "recall": 0.92501,
            "fmeasure": 0.90325
        },
        "rougeLsum": {
            "precision": 0.88801,
            "recall": 0.92501,
            "fmeasure": 0.90325
        },
        "nist": 11.98155206818021,
        "bleu": 91.77847,
        "meteor": 0.5910581285657235,
        "bleurt": 0.2954,
        "nubia": {
            "semantic_relation": 4.34625,
            "contradiction": 0.68794,
            "irrelevancy": 40.5556,
            "logical_agreement": 58.75646,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.12124,
            "nubia_score": 0.73456
        },
        "bertscore": {
            "precision": 0.97703,
            "recall": 0.9839,
            "f1": 0.97955
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "t5-small/totto_test",
        "N": 2221,
        "total_length": 32293,
        "mean_pred_length": 14.539846915803691,
        "std_pred_length": 3.5947159396892543,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.26076858761960797,
        "vocab_size-1": 8421,
        "unique-1": 6120,
        "entropy-1": 9.703332414405427,
        "distinct-2": 0.6569233838786911,
        "vocab_size-2": 19755,
        "unique-2": 17251,
        "entropy-2": 13.413967314952497,
        "cond_entropy-2": 3.31945544331883,
        "distinct-3": 0.8492334207030269,
        "vocab_size-3": 23652,
        "unique-3": 22135,
        "entropy-3": 14.265042113636289,
        "cond_entropy-3": 0.8505623325389755,
        "total_length-nopunct": 28197,
        "mean_pred_length-nopunct": 12.69563259792886,
        "std_pred_length-nopunct": 3.333905314319023,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.2980813561726425,
        "vocab_size-1-nopunct": 8405,
        "unique-1-nopunct": 6120,
        "entropy-1-nopunct": 10.21570294274778,
        "distinct-2-nopunct": 0.6943332306744687,
        "vocab_size-2-nopunct": 18036,
        "unique-2-nopunct": 16079,
        "entropy-2-nopunct": 13.32629202543954,
        "cond_entropy-2-nopunct": 3.282749797179711,
        "distinct-3-nopunct": 0.8733319301199748,
        "vocab_size-3-nopunct": 20746,
        "unique-3-nopunct": 19571,
        "entropy-3-nopunct": 14.131993893932227,
        "cond_entropy-3-nopunct": 0.8697872465044046,
        "msttr-100": 0.73373,
        "msttr-100_nopunct": 0.78641,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2233744394618834,
            "2": 0.4175977653631285,
            "3": 0.7536433969053616
        },
        "rouge1": {
            "precision": 0.76705,
            "recall": 0.72048,
            "fmeasure": 0.73153
        },
        "rouge2": {
            "precision": 0.52956,
            "recall": 0.49588,
            "fmeasure": 0.50358
        },
        "rougeL": {
            "precision": 0.65808,
            "recall": 0.62033,
            "fmeasure": 0.62863
        },
        "rougeLsum": {
            "precision": 0.65808,
            "recall": 0.62033,
            "fmeasure": 0.62863
        },
        "nist": 9.826630678647007,
        "bleu": 44.71536,
        "meteor": 0.38680280793016986,
        "bleurt": 0.24084,
        "nubia": {
            "semantic_relation": 4.22147,
            "contradiction": 8.60016,
            "irrelevancy": 29.79032,
            "logical_agreement": 61.60952,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.85231,
            "nubia_score": 0.71968
        },
        "bertscore": {
            "precision": 0.92717,
            "recall": 0.9209,
            "f1": 0.92248
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "total_length": 3149,
        "mean_pred_length": 18.097701149425287,
        "std_pred_length": 7.642643175975576,
        "median_pred_length": 17.5,
        "min_pred_length": 5,
        "max_pred_length": 41,
        "distinct-1": 0.44013972689742775,
        "vocab_size-1": 1386,
        "unique-1": 1085,
        "entropy-1": 8.605288518233774,
        "distinct-2": 0.8779831932773109,
        "vocab_size-2": 2612,
        "unique-2": 2471,
        "entropy-2": 11.131419447802317,
        "cond_entropy-2": 2.267174831713182,
        "distinct-3": 0.9832202784719742,
        "vocab_size-3": 2754,
        "unique-3": 2717,
        "entropy-3": 11.415121725049891,
        "cond_entropy-3": 0.29700204284681214,
        "total_length-nopunct": 2818,
        "mean_pred_length-nopunct": 16.195402298850574,
        "std_pred_length-nopunct": 6.929595168981499,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.4893541518807665,
        "vocab_size-1-nopunct": 1379,
        "unique-1-nopunct": 1082,
        "entropy-1-nopunct": 8.928763018766952,
        "distinct-2-nopunct": 0.8869137670196672,
        "vocab_size-2-nopunct": 2345,
        "unique-2-nopunct": 2227,
        "entropy-2-nopunct": 10.986550034492733,
        "cond_entropy-2-nopunct": 2.1851321442568934,
        "distinct-3-nopunct": 0.9866396761133603,
        "vocab_size-3-nopunct": 2437,
        "unique-3-nopunct": 2410,
        "entropy-3-nopunct": 11.241542472217892,
        "cond_entropy-3-nopunct": 0.2759946465504539,
        "msttr-100": 0.71613,
        "msttr-100_nopunct": 0.7625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.01416579223504722,
            "2": 0.19141914191419143,
            "3": 0.6031746031746031,
            "4": 0.842741935483871,
            "5": 0.913312693498452,
            "6": 0.9283582089552239,
            "7": 0.9552742616033755
        },
        "rouge1": {
            "precision": 0.94768,
            "recall": 0.93492,
            "fmeasure": 0.93431
        },
        "rouge2": {
            "precision": 0.89352,
            "recall": 0.87838,
            "fmeasure": 0.87848
        },
        "rougeL": {
            "precision": 0.94073,
            "recall": 0.92841,
            "fmeasure": 0.92745
        },
        "rougeLsum": {
            "precision": 0.94073,
            "recall": 0.92841,
            "fmeasure": 0.92745
        },
        "nist": 12.075443346911596,
        "bleu": 90.6544,
        "meteor": 0.6141706184828819,
        "bleurt": 0.42471,
        "nubia": {
            "semantic_relation": 4.55788,
            "contradiction": 1.94164,
            "irrelevancy": 13.62633,
            "logical_agreement": 84.43204,
            "grammar_ref": 4.58509,
            "grammar_hyp": 4.87587,
            "nubia_score": 0.80244
        },
        "bertscore": {
            "precision": 0.97739,
            "recall": 0.97899,
            "f1": 0.97686
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "t5-small/totto_test",
        "N": 1369,
        "total_length": 23599,
        "mean_pred_length": 17.238130021913804,
        "std_pred_length": 4.1453124725582375,
        "median_pred_length": 17.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.2592482732319166,
        "vocab_size-1": 6118,
        "unique-1": 4391,
        "entropy-1": 9.512382741114623,
        "distinct-2": 0.6494826810616284,
        "vocab_size-2": 14438,
        "unique-2": 12480,
        "entropy-2": 13.008975191544124,
        "cond_entropy-2": 3.241349614786282,
        "distinct-3": 0.8396529408944922,
        "vocab_size-3": 17516,
        "unique-3": 16249,
        "entropy-3": 13.820764192584829,
        "cond_entropy-3": 0.820634423856945,
        "total_length-nopunct": 20758,
        "mean_pred_length-nopunct": 15.162892622352082,
        "std_pred_length-nopunct": 3.7364486040028204,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.2939589555833895,
        "vocab_size-1-nopunct": 6102,
        "unique-1-nopunct": 4390,
        "entropy-1-nopunct": 9.933999068394607,
        "distinct-2-nopunct": 0.682603538088607,
        "vocab_size-2-nopunct": 13235,
        "unique-2-nopunct": 11680,
        "entropy-2-nopunct": 12.91146897275091,
        "cond_entropy-2-nopunct": 3.1082764336200683,
        "distinct-3-nopunct": 0.8596559378468368,
        "vocab_size-3-nopunct": 15491,
        "unique-3-nopunct": 14513,
        "entropy-3-nopunct": 13.6774558707568,
        "cond_entropy-3-nopunct": 0.8160403695306415,
        "msttr-100": 0.72813,
        "msttr-100_nopunct": 0.77372,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2346524064171123,
            "2": 0.4094795993159052,
            "3": 0.7325363762603393
        },
        "rouge1": {
            "precision": 0.75419,
            "recall": 0.69728,
            "fmeasure": 0.71313
        },
        "rouge2": {
            "precision": 0.51163,
            "recall": 0.47302,
            "fmeasure": 0.48348
        },
        "rougeL": {
            "precision": 0.63417,
            "recall": 0.58901,
            "fmeasure": 0.60078
        },
        "rougeLsum": {
            "precision": 0.63417,
            "recall": 0.58901,
            "fmeasure": 0.60078
        },
        "nist": 9.313076600381212,
        "bleu": 43.44639,
        "meteor": 0.37512977415398024,
        "bleurt": 0.16711,
        "nubia": {
            "semantic_relation": 4.05169,
            "contradiction": 13.0792,
            "irrelevancy": 32.3338,
            "logical_agreement": 54.58701,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.53706,
            "nubia_score": 0.67944
        },
        "bertscore": {
            "precision": 0.92253,
            "recall": 0.91235,
            "f1": 0.91587
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "t5-small/totto_test",
        "N": 483,
        "total_length": 9168,
        "mean_pred_length": 18.981366459627328,
        "std_pred_length": 3.8218160669990846,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.3263525305410122,
        "vocab_size-1": 2992,
        "unique-1": 2279,
        "entropy-1": 9.12546976170228,
        "distinct-2": 0.7244674726540011,
        "vocab_size-2": 6292,
        "unique-2": 5543,
        "entropy-2": 12.087764383378481,
        "cond_entropy-2": 2.801373148462154,
        "distinct-3": 0.8991709339185564,
        "vocab_size-3": 7375,
        "unique-3": 6954,
        "entropy-3": 12.719013807695216,
        "cond_entropy-3": 0.6377234210145014,
        "total_length-nopunct": 8125,
        "mean_pred_length-nopunct": 16.821946169772257,
        "std_pred_length-nopunct": 3.697877901489986,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.3667692307692308,
        "vocab_size-1-nopunct": 2980,
        "unique-1-nopunct": 2277,
        "entropy-1-nopunct": 9.465699107388684,
        "distinct-2-nopunct": 0.7512431300706621,
        "vocab_size-2-nopunct": 5741,
        "unique-2-nopunct": 5145,
        "entropy-2-nopunct": 11.982268233280639,
        "cond_entropy-2-nopunct": 2.605943505036924,
        "distinct-3-nopunct": 0.9089258276295572,
        "vocab_size-3-nopunct": 6507,
        "unique-3-nopunct": 6180,
        "entropy-3-nopunct": 12.544938236765978,
        "cond_entropy-3-nopunct": 0.596674442743924,
        "msttr-100": 0.72747,
        "msttr-100_nopunct": 0.76728,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23502036067481094,
            "2": 0.35870967741935483,
            "3": 0.6897256275539988
        },
        "rouge1": {
            "precision": 0.74434,
            "recall": 0.65993,
            "fmeasure": 0.68814
        },
        "rouge2": {
            "precision": 0.47422,
            "recall": 0.42071,
            "fmeasure": 0.43784
        },
        "rougeL": {
            "precision": 0.59396,
            "recall": 0.52852,
            "fmeasure": 0.54928
        },
        "rougeLsum": {
            "precision": 0.59396,
            "recall": 0.52852,
            "fmeasure": 0.54928
        },
        "nist": 7.893914363119728,
        "bleu": 36.06326,
        "meteor": 0.3441181537202714,
        "bleurt": 0.04866,
        "nubia": {
            "semantic_relation": 3.90511,
            "contradiction": 17.19928,
            "irrelevancy": 32.63641,
            "logical_agreement": 50.16431,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.41453,
            "nubia_score": 0.63334
        },
        "bertscore": {
            "precision": 0.91301,
            "recall": 0.89812,
            "f1": 0.90382
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "t5-small/totto_test",
        "N": 379,
        "total_length": 7457,
        "mean_pred_length": 19.6754617414248,
        "std_pred_length": 3.801500118494139,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.34571543516159314,
        "vocab_size-1": 2578,
        "unique-1": 1895,
        "entropy-1": 9.10839375496635,
        "distinct-2": 0.75190731845154,
        "vocab_size-2": 5322,
        "unique-2": 4640,
        "entropy-2": 11.964175709504406,
        "cond_entropy-2": 2.744462114210618,
        "distinct-3": 0.9183460217942977,
        "vocab_size-3": 6152,
        "unique-3": 5808,
        "entropy-3": 12.504998239507003,
        "cond_entropy-3": 0.5434741798545191,
        "total_length-nopunct": 6511,
        "mean_pred_length-nopunct": 17.179419525065963,
        "std_pred_length-nopunct": 3.5911792671049168,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.39348794348026417,
        "vocab_size-1-nopunct": 2562,
        "unique-1-nopunct": 1895,
        "entropy-1-nopunct": 9.48389220433598,
        "distinct-2-nopunct": 0.7889758643183301,
        "vocab_size-2-nopunct": 4838,
        "unique-2-nopunct": 4332,
        "entropy-2-nopunct": 11.86870441191853,
        "cond_entropy-2-nopunct": 2.4495014712360375,
        "distinct-3-nopunct": 0.9306448809316878,
        "vocab_size-3-nopunct": 5354,
        "unique-3-nopunct": 5112,
        "entropy-3-nopunct": 12.311734980602287,
        "cond_entropy-3-nopunct": 0.464826548763181,
        "msttr-100": 0.70865,
        "msttr-100_nopunct": 0.75308,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2261904761904762,
            "2": 0.3597475455820477,
            "3": 0.6590086830680174
        },
        "rouge1": {
            "precision": 0.73761,
            "recall": 0.6164,
            "fmeasure": 0.66082
        },
        "rouge2": {
            "precision": 0.45231,
            "recall": 0.37701,
            "fmeasure": 0.40375
        },
        "rougeL": {
            "precision": 0.58216,
            "recall": 0.49183,
            "fmeasure": 0.52336
        },
        "rougeLsum": {
            "precision": 0.58216,
            "recall": 0.49183,
            "fmeasure": 0.52336
        },
        "nist": 6.785266695002293,
        "bleu": 31.31991,
        "meteor": 0.31749586851618455,
        "bleurt": 0.00575,
        "nubia": {
            "semantic_relation": 3.75994,
            "contradiction": 17.84113,
            "irrelevancy": 30.63204,
            "logical_agreement": 51.52683,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.40888,
            "nubia_score": 0.58248
        },
        "bertscore": {
            "precision": 0.91028,
            "recall": 0.88479,
            "f1": 0.89554
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "t5-small/totto_test",
        "N": 124,
        "total_length": 2503,
        "mean_pred_length": 20.18548387096774,
        "std_pred_length": 3.6397601292017794,
        "median_pred_length": 20.5,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.4434678385936876,
        "vocab_size-1": 1110,
        "unique-1": 861,
        "entropy-1": 8.520505572463692,
        "distinct-2": 0.8306010928961749,
        "vocab_size-2": 1976,
        "unique-2": 1793,
        "entropy-2": 10.709174804239721,
        "cond_entropy-2": 2.169121251458412,
        "distinct-3": 0.9623059866962306,
        "vocab_size-3": 2170,
        "unique-3": 2104,
        "entropy-3": 11.056131988431295,
        "cond_entropy-3": 0.3550024876776993,
        "total_length-nopunct": 2212,
        "mean_pred_length-nopunct": 17.838709677419356,
        "std_pred_length-nopunct": 3.738179427454203,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4977396021699819,
        "vocab_size-1-nopunct": 1101,
        "unique-1-nopunct": 860,
        "entropy-1-nopunct": 8.802487129478408,
        "distinct-2-nopunct": 0.8524904214559387,
        "vocab_size-2-nopunct": 1780,
        "unique-2-nopunct": 1640,
        "entropy-2-nopunct": 10.58449284379997,
        "cond_entropy-2-nopunct": 1.8428111249050119,
        "distinct-3-nopunct": 0.9653767820773931,
        "vocab_size-3-nopunct": 1896,
        "unique-3-nopunct": 1843,
        "entropy-3-nopunct": 10.863632923329154,
        "cond_entropy-3-nopunct": 0.29256536289696805,
        "msttr-100": 0.7088,
        "msttr-100_nopunct": 0.75409,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19668737060041408,
            "2": 0.3047404063205418,
            "3": 0.6072874493927125
        },
        "rouge1": {
            "precision": 0.69873,
            "recall": 0.55588,
            "fmeasure": 0.60416
        },
        "rouge2": {
            "precision": 0.40534,
            "recall": 0.32552,
            "fmeasure": 0.35113
        },
        "rougeL": {
            "precision": 0.54763,
            "recall": 0.43981,
            "fmeasure": 0.47515
        },
        "rougeLsum": {
            "precision": 0.54763,
            "recall": 0.43981,
            "fmeasure": 0.47515
        },
        "nist": 5.022354564347156,
        "bleu": 25.31695,
        "meteor": 0.28122832536670955,
        "bleurt": -0.1855,
        "nubia": {
            "semantic_relation": 3.48168,
            "contradiction": 18.81241,
            "irrelevancy": 35.90256,
            "logical_agreement": 45.28502,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.49857,
            "nubia_score": 0.4997
        },
        "bertscore": {
            "precision": 0.88975,
            "recall": 0.87005,
            "f1": 0.87772
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "t5-small/totto_test",
        "N": 128,
        "total_length": 2679,
        "mean_pred_length": 20.9296875,
        "std_pred_length": 4.410894881126023,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.4143337066069429,
        "vocab_size-1": 1110,
        "unique-1": 867,
        "entropy-1": 8.292618020810425,
        "distinct-2": 0.7636221089768718,
        "vocab_size-2": 1948,
        "unique-2": 1753,
        "entropy-2": 10.48003413943083,
        "cond_entropy-2": 2.1573470431242976,
        "distinct-3": 0.8815517952950888,
        "vocab_size-3": 2136,
        "unique-3": 2040,
        "entropy-3": 10.838326282916881,
        "cond_entropy-3": 0.37078529428640944,
        "total_length-nopunct": 2297,
        "mean_pred_length-nopunct": 17.9453125,
        "std_pred_length-nopunct": 4.279874037555749,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.47845015237266,
        "vocab_size-1-nopunct": 1099,
        "unique-1-nopunct": 863,
        "entropy-1-nopunct": 8.64841516086034,
        "distinct-2-nopunct": 0.7869986168741355,
        "vocab_size-2-nopunct": 1707,
        "unique-2-nopunct": 1560,
        "entropy-2-nopunct": 10.321060417110807,
        "cond_entropy-2-nopunct": 1.7332419212155177,
        "distinct-3-nopunct": 0.8961293483586478,
        "vocab_size-3-nopunct": 1829,
        "unique-3-nopunct": 1767,
        "entropy-3-nopunct": 10.628223250843634,
        "cond_entropy-3-nopunct": 0.33619652370471065,
        "msttr-100": 0.69077,
        "msttr-100_nopunct": 0.73773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2675736961451247,
            "2": 0.3313953488372093,
            "3": 0.5528344671201814
        },
        "rouge1": {
            "precision": 0.71634,
            "recall": 0.52037,
            "fmeasure": 0.58753
        },
        "rouge2": {
            "precision": 0.45145,
            "recall": 0.32063,
            "fmeasure": 0.36518
        },
        "rougeL": {
            "precision": 0.58898,
            "recall": 0.42524,
            "fmeasure": 0.48109
        },
        "rougeLsum": {
            "precision": 0.58898,
            "recall": 0.42524,
            "fmeasure": 0.48109
        },
        "nist": 4.045752203003768,
        "bleu": 27.37229,
        "meteor": 0.2704029655103789,
        "bleurt": -0.22661,
        "nubia": {
            "semantic_relation": 3.35979,
            "contradiction": 25.0286,
            "irrelevancy": 30.19439,
            "logical_agreement": 44.77701,
            "grammar_ref": 4.11595,
            "grammar_hyp": 4.30841,
            "nubia_score": 0.44594
        },
        "bertscore": {
            "precision": 0.89652,
            "recall": 0.86029,
            "f1": 0.87617
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "t5-small/totto_test",
        "N": 61,
        "total_length": 1193,
        "mean_pred_length": 19.557377049180328,
        "std_pred_length": 5.354711699281679,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.49958088851634536,
        "vocab_size-1": 596,
        "unique-1": 476,
        "entropy-1": 7.919800342906739,
        "distinct-2": 0.8321554770318021,
        "vocab_size-2": 942,
        "unique-2": 857,
        "entropy-2": 9.646891830962861,
        "cond_entropy-2": 1.692938510566169,
        "distinct-3": 0.9439775910364145,
        "vocab_size-3": 1011,
        "unique-3": 969,
        "entropy-3": 9.936924041137198,
        "cond_entropy-3": 0.3002174799259256,
        "total_length-nopunct": 1026,
        "mean_pred_length-nopunct": 16.81967213114754,
        "std_pred_length-nopunct": 4.9107049232591535,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5730994152046783,
        "vocab_size-1-nopunct": 588,
        "unique-1-nopunct": 472,
        "entropy-1-nopunct": 8.243268386159048,
        "distinct-2-nopunct": 0.8746113989637305,
        "vocab_size-2-nopunct": 844,
        "unique-2-nopunct": 786,
        "entropy-2-nopunct": 9.550082205344935,
        "cond_entropy-2-nopunct": 1.3665027336270175,
        "distinct-3-nopunct": 0.9623893805309734,
        "vocab_size-3-nopunct": 870,
        "unique-3-nopunct": 846,
        "entropy-3-nopunct": 9.73349253766218,
        "cond_entropy-3-nopunct": 0.1962836907627337,
        "msttr-100": 0.67727,
        "msttr-100_nopunct": 0.739,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1827956989247312,
            "2": 0.3212669683257919,
            "3": 0.5688935281837161
        },
        "rouge1": {
            "precision": 0.69694,
            "recall": 0.51732,
            "fmeasure": 0.5777
        },
        "rouge2": {
            "precision": 0.40909,
            "recall": 0.29783,
            "fmeasure": 0.33467
        },
        "rougeL": {
            "precision": 0.5696,
            "recall": 0.42802,
            "fmeasure": 0.47447
        },
        "rougeLsum": {
            "precision": 0.5696,
            "recall": 0.42802,
            "fmeasure": 0.47447
        },
        "nist": 4.291616262487238,
        "bleu": 27.05329,
        "meteor": 0.2708401270868958,
        "bleurt": -0.15622,
        "nubia": {
            "semantic_relation": 3.3213,
            "contradiction": 17.37391,
            "irrelevancy": 30.76002,
            "logical_agreement": 51.86608,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.52155,
            "nubia_score": 0.4445
        },
        "bertscore": {
            "precision": 0.89508,
            "recall": 0.85835,
            "f1": 0.87399
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "t5-small/totto_test",
        "N": 40,
        "total_length": 806,
        "mean_pred_length": 20.15,
        "std_pred_length": 5.410868691809107,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.5,
        "vocab_size-1": 403,
        "unique-1": 328,
        "entropy-1": 7.499963179585338,
        "distinct-2": 0.8433420365535248,
        "vocab_size-2": 646,
        "unique-2": 590,
        "entropy-2": 9.14591977561891,
        "cond_entropy-2": 1.6359526262606372,
        "distinct-3": 0.9476584022038568,
        "vocab_size-3": 688,
        "unique-3": 661,
        "entropy-3": 9.382364567930454,
        "cond_entropy-3": 0.2489398091840248,
        "total_length-nopunct": 684,
        "mean_pred_length-nopunct": 17.1,
        "std_pred_length-nopunct": 4.334743360338648,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5760233918128655,
        "vocab_size-1-nopunct": 394,
        "unique-1-nopunct": 324,
        "entropy-1-nopunct": 7.746250531383299,
        "distinct-2-nopunct": 0.8618012422360248,
        "vocab_size-2-nopunct": 555,
        "unique-2-nopunct": 515,
        "entropy-2-nopunct": 8.944516218467877,
        "cond_entropy-2-nopunct": 1.2543427992117668,
        "distinct-3-nopunct": 0.9552980132450332,
        "vocab_size-3-nopunct": 577,
        "unique-3-nopunct": 558,
        "entropy-3-nopunct": 9.132583303959322,
        "cond_entropy-3-nopunct": 0.206065535632427,
        "msttr-100": 0.69625,
        "msttr-100_nopunct": 0.75333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18493150684931506,
            "2": 0.3431952662721893,
            "3": 0.59472049689441
        },
        "rouge1": {
            "precision": 0.73958,
            "recall": 0.54762,
            "fmeasure": 0.61356
        },
        "rouge2": {
            "precision": 0.48038,
            "recall": 0.35463,
            "fmeasure": 0.39782
        },
        "rougeL": {
            "precision": 0.61361,
            "recall": 0.46038,
            "fmeasure": 0.51253
        },
        "rougeLsum": {
            "precision": 0.61361,
            "recall": 0.46038,
            "fmeasure": 0.51253
        },
        "nist": 4.315993614591063,
        "bleu": 30.83732,
        "meteor": 0.294083174101438,
        "bleurt": -0.13466,
        "nubia": {
            "semantic_relation": 3.36406,
            "contradiction": 18.85041,
            "irrelevancy": 32.02755,
            "logical_agreement": 49.12204,
            "grammar_ref": 4.29053,
            "grammar_hyp": 4.45939,
            "nubia_score": 0.4586
        },
        "bertscore": {
            "precision": 0.90564,
            "recall": 0.87455,
            "f1": 0.88813
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "t5-small/totto_test",
        "N": 20,
        "total_length": 383,
        "mean_pred_length": 19.15,
        "std_pred_length": 6.342515273927214,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.577023498694517,
        "vocab_size-1": 221,
        "unique-1": 182,
        "entropy-1": 6.86903116350232,
        "distinct-2": 0.8815426997245179,
        "vocab_size-2": 320,
        "unique-2": 290,
        "entropy-2": 8.224255645832235,
        "cond_entropy-2": 1.3851118460997178,
        "distinct-3": 0.9620991253644315,
        "vocab_size-3": 330,
        "unique-3": 317,
        "entropy-3": 8.346263016901647,
        "cond_entropy-3": 0.13247793037928854,
        "total_length-nopunct": 312,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 5.2573757712379665,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6858974358974359,
        "vocab_size-1-nopunct": 214,
        "unique-1-nopunct": 180,
        "entropy-1-nopunct": 7.21727392748735,
        "distinct-2-nopunct": 0.9075342465753424,
        "vocab_size-2-nopunct": 265,
        "unique-2-nopunct": 246,
        "entropy-2-nopunct": 7.971076945931676,
        "cond_entropy-2-nopunct": 0.7969799990104688,
        "distinct-3-nopunct": 0.9742647058823529,
        "vocab_size-3-nopunct": 265,
        "unique-3-nopunct": 258,
        "entropy-3-nopunct": 8.035992253015058,
        "cond_entropy-3-nopunct": 0.0773232198002016,
        "msttr-100": 0.68667,
        "msttr-100_nopunct": 0.76667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.34065934065934067,
            "3": 0.49096385542168675
        },
        "rouge1": {
            "precision": 0.71843,
            "recall": 0.45732,
            "fmeasure": 0.53476
        },
        "rouge2": {
            "precision": 0.44102,
            "recall": 0.26558,
            "fmeasure": 0.31818
        },
        "rougeL": {
            "precision": 0.60425,
            "recall": 0.38378,
            "fmeasure": 0.45001
        },
        "rougeLsum": {
            "precision": 0.60425,
            "recall": 0.38378,
            "fmeasure": 0.45001
        },
        "nist": 1.9633251454345095,
        "bleu": 24.80804,
        "meteor": 0.2372487040335005,
        "bleurt": -0.33843,
        "nubia": {
            "semantic_relation": 3.16683,
            "contradiction": 19.72528,
            "irrelevancy": 28.71904,
            "logical_agreement": 51.55568,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.70677,
            "nubia_score": 0.38721
        },
        "bertscore": {
            "precision": 0.88996,
            "recall": 0.85073,
            "f1": 0.86475
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "t5-small/totto_test",
        "N": 26,
        "total_length": 556,
        "mean_pred_length": 21.384615384615383,
        "std_pred_length": 4.930883234011491,
        "median_pred_length": 21.5,
        "min_pred_length": 12,
        "max_pred_length": 31,
        "distinct-1": 0.4892086330935252,
        "vocab_size-1": 272,
        "unique-1": 205,
        "entropy-1": 7.094402358812783,
        "distinct-2": 0.8452830188679246,
        "vocab_size-2": 448,
        "unique-2": 401,
        "entropy-2": 8.662069222143629,
        "cond_entropy-2": 1.5697131315818373,
        "distinct-3": 0.9345238095238095,
        "vocab_size-3": 471,
        "unique-3": 445,
        "entropy-3": 8.833897656621897,
        "cond_entropy-3": 0.18670402973479297,
        "total_length-nopunct": 473,
        "mean_pred_length-nopunct": 18.192307692307693,
        "std_pred_length-nopunct": 4.260906645748881,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5644820295983086,
        "vocab_size-1-nopunct": 267,
        "unique-1-nopunct": 204,
        "entropy-1-nopunct": 7.29450916723004,
        "distinct-2-nopunct": 0.8657718120805369,
        "vocab_size-2-nopunct": 387,
        "unique-2-nopunct": 354,
        "entropy-2-nopunct": 8.464056595079672,
        "cond_entropy-2-nopunct": 1.2266582041704979,
        "distinct-3-nopunct": 0.9406175771971497,
        "vocab_size-3-nopunct": 396,
        "unique-3-nopunct": 378,
        "entropy-3-nopunct": 8.584031143953574,
        "cond_entropy-3-nopunct": 0.132461419605484,
        "msttr-100": 0.648,
        "msttr-100_nopunct": 0.6925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15833333333333333,
            "2": 0.24369747899159663,
            "3": 0.5616740088105727
        },
        "rouge1": {
            "precision": 0.73164,
            "recall": 0.49361,
            "fmeasure": 0.57349
        },
        "rouge2": {
            "precision": 0.47168,
            "recall": 0.31751,
            "fmeasure": 0.368
        },
        "rougeL": {
            "precision": 0.60878,
            "recall": 0.41499,
            "fmeasure": 0.48063
        },
        "rougeLsum": {
            "precision": 0.60878,
            "recall": 0.41499,
            "fmeasure": 0.48063
        },
        "nist": 2.618861455756518,
        "bleu": 24.56514,
        "meteor": 0.2584852635484993,
        "bleurt": -0.23192,
        "nubia": {
            "semantic_relation": 3.19039,
            "contradiction": 13.86266,
            "irrelevancy": 35.06125,
            "logical_agreement": 51.07609,
            "grammar_ref": 4.04917,
            "grammar_hyp": 4.08718,
            "nubia_score": 0.41642
        },
        "bertscore": {
            "precision": 0.89659,
            "recall": 0.8585,
            "f1": 0.87526
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "t5-small/totto_test",
        "N": 10,
        "total_length": 206,
        "mean_pred_length": 20.6,
        "std_pred_length": 3.7735924528226414,
        "median_pred_length": 20.5,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.6262135922330098,
        "vocab_size-1": 129,
        "unique-1": 107,
        "entropy-1": 6.4072254125590336,
        "distinct-2": 0.8724489795918368,
        "vocab_size-2": 171,
        "unique-2": 154,
        "entropy-2": 7.316090838946928,
        "cond_entropy-2": 0.907281055662547,
        "distinct-3": 0.946236559139785,
        "vocab_size-3": 176,
        "unique-3": 167,
        "entropy-3": 7.427573394429747,
        "cond_entropy-3": 0.11363969285355488,
        "total_length-nopunct": 167,
        "mean_pred_length-nopunct": 16.7,
        "std_pred_length-nopunct": 3.0016662039607267,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7485029940119761,
        "vocab_size-1-nopunct": 125,
        "unique-1-nopunct": 106,
        "entropy-1-nopunct": 6.644643346350914,
        "distinct-2-nopunct": 0.9554140127388535,
        "vocab_size-2-nopunct": 150,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.200640573718608,
        "cond_entropy-2-nopunct": 0.5607536176317394,
        "distinct-3-nopunct": 0.9863945578231292,
        "vocab_size-3-nopunct": 145,
        "unique-3-nopunct": 143,
        "entropy-3-nopunct": 7.172461460482613,
        "cond_entropy-3-nopunct": -0.028588625128980347,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1506849315068493,
            "2": 0.3050847457627119,
            "3": 0.4726027397260274
        },
        "rouge1": {
            "precision": 0.63725,
            "recall": 0.42723,
            "fmeasure": 0.50399
        },
        "rouge2": {
            "precision": 0.40081,
            "recall": 0.26582,
            "fmeasure": 0.31714
        },
        "rougeL": {
            "precision": 0.54068,
            "recall": 0.37434,
            "fmeasure": 0.43608
        },
        "rougeLsum": {
            "precision": 0.54068,
            "recall": 0.37434,
            "fmeasure": 0.43608
        },
        "nist": 2.5958404573122262,
        "bleu": 28.85398,
        "meteor": 0.2307057622600961,
        "bleurt": -0.33264,
        "nubia": {
            "semantic_relation": 2.78755,
            "contradiction": 13.19631,
            "irrelevancy": 43.47903,
            "logical_agreement": 43.32466,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.64927,
            "nubia_score": 0.3454
        },
        "bertscore": {
            "precision": 0.86249,
            "recall": 0.82851,
            "f1": 0.84305
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "t5-small/totto_test",
        "N": 14,
        "total_length": 306,
        "mean_pred_length": 21.857142857142858,
        "std_pred_length": 3.814579977948197,
        "median_pred_length": 22.5,
        "min_pred_length": 14,
        "max_pred_length": 30,
        "distinct-1": 0.5849673202614379,
        "vocab_size-1": 179,
        "unique-1": 140,
        "entropy-1": 6.712024361749036,
        "distinct-2": 0.8835616438356164,
        "vocab_size-2": 258,
        "unique-2": 234,
        "entropy-2": 7.913211887876056,
        "cond_entropy-2": 1.213312016634405,
        "distinct-3": 0.9568345323741008,
        "vocab_size-3": 266,
        "unique-3": 254,
        "entropy-3": 8.03261013747167,
        "cond_entropy-3": 0.12973126180452244,
        "total_length-nopunct": 261,
        "mean_pred_length-nopunct": 18.642857142857142,
        "std_pred_length-nopunct": 3.7722131218602555,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6628352490421456,
        "vocab_size-1-nopunct": 173,
        "unique-1-nopunct": 140,
        "entropy-1-nopunct": 6.842159971276066,
        "distinct-2-nopunct": 0.8947368421052632,
        "vocab_size-2-nopunct": 221,
        "unique-2-nopunct": 204,
        "entropy-2-nopunct": 7.689193092187928,
        "cond_entropy-2-nopunct": 0.8852133612060384,
        "distinct-3-nopunct": 0.9613733905579399,
        "vocab_size-3-nopunct": 224,
        "unique-3-nopunct": 215,
        "entropy-3-nopunct": 7.786932925770195,
        "cond_entropy-3-nopunct": 0.10043699217262163,
        "msttr-100": 0.66667,
        "msttr-100_nopunct": 0.715,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.34285714285714286,
            "2": 0.2753623188405797,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.60234,
            "recall": 0.47475,
            "fmeasure": 0.51538
        },
        "rouge2": {
            "precision": 0.33945,
            "recall": 0.26495,
            "fmeasure": 0.28758
        },
        "rougeL": {
            "precision": 0.47497,
            "recall": 0.38602,
            "fmeasure": 0.4128
        },
        "rougeLsum": {
            "precision": 0.47497,
            "recall": 0.38602,
            "fmeasure": 0.4128
        },
        "nist": 3.332648463302037,
        "bleu": 22.42847,
        "meteor": 0.23688652657456094,
        "bleurt": -0.26597,
        "nubia": {
            "semantic_relation": 3.06709,
            "contradiction": 29.19004,
            "irrelevancy": 39.43764,
            "logical_agreement": 31.37232,
            "grammar_ref": 4.37064,
            "grammar_hyp": 4.18585,
            "nubia_score": 0.38406
        },
        "bertscore": {
            "precision": 0.86502,
            "recall": 0.8443,
            "f1": 0.85304
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "t5-small/totto_test",
        "N": 14,
        "total_length": 268,
        "mean_pred_length": 19.142857142857142,
        "std_pred_length": 4.997958767010258,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.5783582089552238,
        "vocab_size-1": 155,
        "unique-1": 128,
        "entropy-1": 6.4022545518848935,
        "distinct-2": 0.905511811023622,
        "vocab_size-2": 230,
        "unique-2": 213,
        "entropy-2": 7.773609133689099,
        "cond_entropy-2": 1.336079492809589,
        "distinct-3": 0.9541666666666667,
        "vocab_size-3": 229,
        "unique-3": 220,
        "entropy-3": 7.808933199757198,
        "cond_entropy-3": 0.03709946291153019,
        "total_length-nopunct": 221,
        "mean_pred_length-nopunct": 15.785714285714286,
        "std_pred_length-nopunct": 3.8578041761116504,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6787330316742082,
        "vocab_size-1-nopunct": 150,
        "unique-1-nopunct": 125,
        "entropy-1-nopunct": 6.742759289607056,
        "distinct-2-nopunct": 0.9371980676328503,
        "vocab_size-2-nopunct": 194,
        "unique-2-nopunct": 183,
        "entropy-2-nopunct": 7.560589493710282,
        "cond_entropy-2-nopunct": 0.8663666450513543,
        "distinct-3-nopunct": 0.9792746113989638,
        "vocab_size-3-nopunct": 189,
        "unique-3-nopunct": 186,
        "entropy-3-nopunct": 7.547094925857886,
        "cond_entropy-3-nopunct": -0.014217031618998916,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2619047619047619,
            "2": 0.11764705882352941,
            "3": 0.3269961977186312
        },
        "rouge1": {
            "precision": 0.49441,
            "recall": 0.31289,
            "fmeasure": 0.36847
        },
        "rouge2": {
            "precision": 0.21723,
            "recall": 0.12453,
            "fmeasure": 0.15282
        },
        "rougeL": {
            "precision": 0.35922,
            "recall": 0.22493,
            "fmeasure": 0.26542
        },
        "rougeLsum": {
            "precision": 0.35922,
            "recall": 0.22493,
            "fmeasure": 0.26542
        },
        "nist": 1.2599786309310865,
        "bleu": 9.54373,
        "meteor": 0.15081565017095339,
        "bleurt": -0.61426,
        "nubia": {
            "semantic_relation": 2.59843,
            "contradiction": 23.38526,
            "irrelevancy": 57.28822,
            "logical_agreement": 19.32652,
            "grammar_ref": 3.91022,
            "grammar_hyp": 4.06254,
            "nubia_score": 0.28099
        },
        "bertscore": {
            "precision": 0.81999,
            "recall": 0.77843,
            "f1": 0.79745
        }
    },
    "totto_test": {
        "predictions_file": "t5-small/totto_test",
        "N": 7700,
        "total_length": 117724,
        "mean_pred_length": 15.28883116883117,
        "std_pred_length": 4.617465986916114,
        "median_pred_length": 15.0,
        "min_pred_length": 2,
        "max_pred_length": 37,
        "distinct-1": 0.17807753729061193,
        "vocab_size-1": 20964,
        "unique-1": 14573,
        "entropy-1": 10.045518712105157,
        "distinct-2": 0.5406002326765069,
        "vocab_size-2": 59479,
        "unique-2": 49977,
        "entropy-2": 14.39046055875672,
        "cond_entropy-2": 4.008007656645744,
        "distinct-3": 0.7585903600328369,
        "vocab_size-3": 77622,
        "unique-3": 70523,
        "entropy-3": 15.650399916777616,
        "cond_entropy-3": 1.265974463297359,
        "total_length-nopunct": 102874,
        "mean_pred_length-nopunct": 13.36025974025974,
        "std_pred_length-nopunct": 4.17143407837129,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.20359857689989697,
        "vocab_size-1-nopunct": 20945,
        "unique-1-nopunct": 14572,
        "entropy-1-nopunct": 10.582515115905453,
        "distinct-2-nopunct": 0.5817870426797235,
        "vocab_size-2-nopunct": 55371,
        "unique-2-nopunct": 47579,
        "entropy-2-nopunct": 14.36001477062111,
        "cond_entropy-2-nopunct": 3.9567586916082162,
        "distinct-3-nopunct": 0.7821867069071953,
        "vocab_size-3-nopunct": 68421,
        "unique-3-nopunct": 62916,
        "entropy-3-nopunct": 15.517374304839352,
        "cond_entropy-3-nopunct": 1.254074809617605,
        "msttr-100": 0.72669,
        "msttr-100_nopunct": 0.7764,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.238315294499169,
            "2": 0.4231638418079096,
            "3": 0.7149674729359757
        },
        "rouge1": {
            "precision": 0.74043,
            "recall": 0.6899,
            "fmeasure": 0.70084
        },
        "rouge2": {
            "precision": 0.50718,
            "recall": 0.47237,
            "fmeasure": 0.47955
        },
        "rougeL": {
            "precision": 0.63972,
            "recall": 0.5993,
            "fmeasure": 0.60702
        },
        "rougeLsum": {
            "precision": 0.63972,
            "recall": 0.5993,
            "fmeasure": 0.60702
        },
        "nist": 9.967971439277747,
        "bleu": 41.55022,
        "meteor": 0.3626226256117732,
        "bleurt": 0.1784,
        "nubia": {
            "semantic_relation": 4.03874,
            "contradiction": 11.00054,
            "irrelevancy": 32.51838,
            "logical_agreement": 56.48108,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.70348,
            "nubia_score": 0.67488
        },
        "bertscore": {
            "precision": 0.91944,
            "recall": 0.91162,
            "f1": 0.91384
        }
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7908,
        "mean_pred_length": 22.027855153203344,
        "std_pred_length": 9.490608383489896,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 65,
        "distinct-1": 0.3727870510875063,
        "vocab_size-1": 2948,
        "unique-1": 2165,
        "entropy-1": 9.267613072593328,
        "distinct-2": 0.8460723274605908,
        "vocab_size-2": 6387,
        "unique-2": 5919,
        "entropy-2": 12.356298301298754,
        "cond_entropy-2": 2.8542561498352046,
        "distinct-3": 0.9783031988873435,
        "vocab_size-3": 7034,
        "unique-3": 6921,
        "entropy-3": 12.761920875848766,
        "cond_entropy-3": 0.4164883183838953,
        "total_length-nopunct": 7031,
        "mean_pred_length-nopunct": 19.584958217270195,
        "std_pred_length-nopunct": 8.300276663236986,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.41786374626653394,
        "vocab_size-1-nopunct": 2938,
        "unique-1-nopunct": 2164,
        "entropy-1-nopunct": 9.63222029991525,
        "distinct-2-nopunct": 0.8645083932853717,
        "vocab_size-2-nopunct": 5768,
        "unique-2-nopunct": 5397,
        "entropy-2-nopunct": 12.24085468289175,
        "cond_entropy-2-nopunct": 2.7339668896335265,
        "distinct-3-nopunct": 0.9846348804055124,
        "vocab_size-3-nopunct": 6216,
        "unique-3-nopunct": 6138,
        "entropy-3-nopunct": 12.59034502459716,
        "cond_entropy-3-nopunct": 0.37048746695522455,
        "msttr-100": 0.72557,
        "msttr-100_nopunct": 0.77014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03270856302829842,
            "2": 0.1967654986522911,
            "3": 0.44457831325301206,
            "4": 0.6559633027522935,
            "5": 0.787556904400607,
            "6": 0.8873239436619719,
            "7": 0.9371584699453552,
            "8": 0.9746682750301568,
            "9": 0.9746031746031746,
            "10": 0.9914728682170543
        },
        "rouge1": {
            "precision": 0.9154,
            "recall": 0.93108,
            "fmeasure": 0.91973
        },
        "rouge2": {
            "precision": 0.833,
            "recall": 0.85502,
            "fmeasure": 0.83944
        },
        "rougeL": {
            "precision": 0.90244,
            "recall": 0.92191,
            "fmeasure": 0.90847
        },
        "rougeLsum": {
            "precision": 0.90244,
            "recall": 0.92191,
            "fmeasure": 0.90847
        },
        "nist": 13.981447987231807,
        "bleu": 92.40348,
        "sari": 51.61936,
        "meteor": 0.5796075519083013,
        "bleurt": 0.36848,
        "nubia": {
            "semantic_relation": 4.44981,
            "contradiction": 1.88822,
            "irrelevancy": 32.77875,
            "logical_agreement": 65.33302,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.30296,
            "nubia_score": 0.79041
        },
        "bertscore": {
            "precision": 0.98009,
            "recall": 0.98402,
            "f1": 0.98029
        }
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7720,
        "mean_pred_length": 21.5041782729805,
        "std_pred_length": 9.340322585225518,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37176165803108807,
        "vocab_size-1": 2870,
        "unique-1": 2100,
        "entropy-1": 9.235158439326643,
        "distinct-2": 0.847167504415161,
        "vocab_size-2": 6236,
        "unique-2": 5774,
        "entropy-2": 12.327123665919075,
        "cond_entropy-2": 2.8572508020756424,
        "distinct-3": 0.9802913453299057,
        "vocab_size-3": 6864,
        "unique-3": 6757,
        "entropy-3": 12.729865603577442,
        "cond_entropy-3": 0.41443290245541875,
        "total_length-nopunct": 6952,
        "mean_pred_length-nopunct": 19.364902506963787,
        "std_pred_length-nopunct": 8.474966868997573,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.411536248561565,
        "vocab_size-1-nopunct": 2861,
        "unique-1-nopunct": 2098,
        "entropy-1-nopunct": 9.594839877948008,
        "distinct-2-nopunct": 0.8651600182011224,
        "vocab_size-2-nopunct": 5704,
        "unique-2-nopunct": 5328,
        "entropy-2-nopunct": 12.234578669854612,
        "cond_entropy-2-nopunct": 2.760495991752104,
        "distinct-3-nopunct": 0.9847609881296118,
        "vocab_size-3-nopunct": 6139,
        "unique-3-nopunct": 6062,
        "entropy-3-nopunct": 12.572833099233705,
        "cond_entropy-3-nopunct": 0.35825618548419247,
        "msttr-100": 0.72571,
        "msttr-100_nopunct": 0.76884,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.012521222410865875,
            "2": 0.19029374201787994,
            "3": 0.6061269146608315,
            "4": 0.8573692551505546,
            "5": 0.9293873312564901,
            "6": 0.9468599033816425,
            "7": 0.9618174875906834
        },
        "rouge1": {
            "precision": 0.94971,
            "recall": 0.93391,
            "fmeasure": 0.93572
        },
        "rouge2": {
            "precision": 0.90141,
            "recall": 0.88358,
            "fmeasure": 0.88555
        },
        "rougeL": {
            "precision": 0.94542,
            "recall": 0.93022,
            "fmeasure": 0.93163
        },
        "rougeLsum": {
            "precision": 0.94542,
            "recall": 0.93022,
            "fmeasure": 0.93163
        },
        "nist": 13.407293846084126,
        "bleu": 92.10852,
        "sari": 61.81409,
        "meteor": 0.6216178784743646,
        "bleurt": 0.4048,
        "nubia": {
            "semantic_relation": 4.53451,
            "contradiction": 1.84618,
            "irrelevancy": 14.26933,
            "logical_agreement": 83.88449,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.72492,
            "nubia_score": 0.80242
        },
        "bertscore": {
            "precision": 0.97898,
            "recall": 0.98008,
            "f1": 0.97819
        }
    },
    "wiki_auto_asset_turk_challenge_train_sample": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_challenge_train_sample",
        "N": 500
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "total_length": 6734,
        "mean_pred_length": 18.75766016713092,
        "std_pred_length": 8.695709638259885,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 64,
        "distinct-1": 0.3722898722898723,
        "vocab_size-1": 2507,
        "unique-1": 1878,
        "entropy-1": 9.054646080901083,
        "distinct-2": 0.8290196078431372,
        "vocab_size-2": 5285,
        "unique-2": 4890,
        "entropy-2": 12.005257590714193,
        "cond_entropy-2": 2.662999464463489,
        "distinct-3": 0.9554521276595744,
        "vocab_size-3": 5748,
        "unique-3": 5644,
        "entropy-3": 12.383611382450313,
        "cond_entropy-3": 0.4012369332894443,
        "total_length-nopunct": 6002,
        "mean_pred_length-nopunct": 16.71866295264624,
        "std_pred_length-nopunct": 7.769052411399909,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.41652782405864713,
        "vocab_size-1-nopunct": 2500,
        "unique-1-nopunct": 1876,
        "entropy-1-nopunct": 9.426046899558163,
        "distinct-2-nopunct": 0.8566365408470672,
        "vocab_size-2-nopunct": 4834,
        "unique-2-nopunct": 4496,
        "entropy-2-nopunct": 11.992308399326491,
        "cond_entropy-2-nopunct": 2.703952536342587,
        "distinct-3-nopunct": 0.9782361847085541,
        "vocab_size-3-nopunct": 5169,
        "unique-3-nopunct": 5088,
        "entropy-3-nopunct": 12.31724485154028,
        "cond_entropy-3-nopunct": 0.34868003392183144,
        "msttr-100": 0.71955,
        "msttr-100_nopunct": 0.76483,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "local_recall": {
            "1": 0.05565217391304348,
            "2": 0.13736263736263737,
            "3": 0.2403282532239156,
            "4": 0.34277620396600567,
            "5": 0.4116865869853918,
            "6": 0.4802955665024631,
            "7": 0.5593607305936074,
            "8": 0.6656746031746031,
            "9": 0.7827338129496403
        },
        "rouge1": {
            "precision": 0.66934,
            "recall": 0.65575,
            "fmeasure": 0.65273
        },
        "rouge2": {
            "precision": 0.43374,
            "recall": 0.43083,
            "fmeasure": 0.42291
        },
        "rougeL": {
            "precision": 0.60969,
            "recall": 0.6046,
            "fmeasure": 0.59774
        },
        "rougeLsum": {
            "precision": 0.60969,
            "recall": 0.6046,
            "fmeasure": 0.59774
        },
        "nist": 8.709710036785342,
        "bleu": 40.18077,
        "sari": 44.86435,
        "meteor": 0.3465887289999396,
        "bleurt": -0.19587,
        "nubia": {
            "semantic_relation": 3.53107,
            "contradiction": 11.80253,
            "irrelevancy": 34.93839,
            "logical_agreement": 53.25908,
            "grammar_ref": 4.57404,
            "grammar_hyp": 4.91898,
            "nubia_score": 0.51009
        },
        "bertscore": {
            "precision": 0.90187,
            "recall": 0.90777,
            "f1": 0.90072
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "total_length": 6755,
        "mean_pred_length": 18.81615598885794,
        "std_pred_length": 8.298717270961548,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 59,
        "distinct-1": 0.40503330866025167,
        "vocab_size-1": 2736,
        "unique-1": 2170,
        "entropy-1": 9.229924986788303,
        "distinct-2": 0.8447467166979362,
        "vocab_size-2": 5403,
        "unique-2": 5057,
        "entropy-2": 12.04956985959827,
        "cond_entropy-2": 2.5228472967650233,
        "distinct-3": 0.9564353155540831,
        "vocab_size-3": 5774,
        "unique-3": 5671,
        "entropy-3": 12.383385157844142,
        "cond_entropy-3": 0.35586906452284006,
        "total_length-nopunct": 6010,
        "mean_pred_length-nopunct": 16.740947075208915,
        "std_pred_length-nopunct": 7.376260211105242,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 50,
        "distinct-1-nopunct": 0.453910149750416,
        "vocab_size-1-nopunct": 2728,
        "unique-1-nopunct": 2167,
        "entropy-1-nopunct": 9.62808898262111,
        "distinct-2-nopunct": 0.8729428419748717,
        "vocab_size-2-nopunct": 4933,
        "unique-2-nopunct": 4644,
        "entropy-2-nopunct": 12.042754240571657,
        "cond_entropy-2-nopunct": 2.553088681221104,
        "distinct-3-nopunct": 0.9803476946334089,
        "vocab_size-3-nopunct": 5188,
        "unique-3-nopunct": 5111,
        "entropy-3-nopunct": 12.323530130485457,
        "cond_entropy-3-nopunct": 0.3043948728577401,
        "msttr-100": 0.73328,
        "msttr-100_nopunct": 0.7795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "local_recall": {
            "1": 0.04599033816425121,
            "2": 0.15521978021978022,
            "3": 0.2672919109026964,
            "4": 0.3909348441926346,
            "5": 0.4847277556440903,
            "6": 0.5566502463054187,
            "7": 0.6666666666666666,
            "8": 0.7400793650793651,
            "9": 0.8309352517985612
        },
        "rouge1": {
            "precision": 0.71934,
            "recall": 0.71229,
            "fmeasure": 0.7071
        },
        "rouge2": {
            "precision": 0.50943,
            "recall": 0.50987,
            "fmeasure": 0.5003
        },
        "rougeL": {
            "precision": 0.67757,
            "recall": 0.67898,
            "fmeasure": 0.66924
        },
        "rougeLsum": {
            "precision": 0.67757,
            "recall": 0.67898,
            "fmeasure": 0.66924
        },
        "nist": 9.923772270267557,
        "bleu": 51.03015,
        "sari": 46.91655,
        "meteor": 0.37247863055621766,
        "bleurt": -0.49177,
        "nubia": {
            "semantic_relation": 3.87898,
            "contradiction": 5.01888,
            "irrelevancy": 27.47308,
            "logical_agreement": 67.50804,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.65096,
            "nubia_score": 0.51681
        },
        "bertscore": {
            "precision": 0.89258,
            "recall": 0.92105,
            "f1": 0.90212
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "total_length": 6694,
        "mean_pred_length": 18.64623955431755,
        "std_pred_length": 8.053801058245057,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.45309232148192413,
        "vocab_size-1": 3033,
        "unique-1": 2528,
        "entropy-1": 9.470475015434387,
        "distinct-2": 0.8729281767955801,
        "vocab_size-2": 5530,
        "unique-2": 5268,
        "entropy-2": 12.134722090573554,
        "cond_entropy-2": 2.353726775906125,
        "distinct-3": 0.9656961178045516,
        "vocab_size-3": 5771,
        "unique-3": 5706,
        "entropy-3": 12.401417129061686,
        "cond_entropy-3": 0.28633368204841064,
        "total_length-nopunct": 5968,
        "mean_pred_length-nopunct": 16.623955431754876,
        "std_pred_length-nopunct": 7.158031891955973,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5068699731903485,
        "vocab_size-1-nopunct": 3025,
        "unique-1-nopunct": 2525,
        "entropy-1-nopunct": 9.889709526338436,
        "distinct-2-nopunct": 0.899447316812266,
        "vocab_size-2-nopunct": 5045,
        "unique-2-nopunct": 4834,
        "entropy-2-nopunct": 12.109840773672047,
        "cond_entropy-2-nopunct": 2.3517838047091617,
        "distinct-3-nopunct": 0.9870476190476191,
        "vocab_size-3-nopunct": 5182,
        "unique-3-nopunct": 5137,
        "entropy-3-nopunct": 12.326421750305611,
        "cond_entropy-3-nopunct": 0.23651026792085272,
        "msttr-100": 0.7553,
        "msttr-100_nopunct": 0.80237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "local_recall": {
            "1": 0.04154589371980676,
            "2": 0.12912087912087913,
            "3": 0.2473622508792497,
            "4": 0.358356940509915,
            "5": 0.42231075697211157,
            "6": 0.5049261083743842,
            "7": 0.5993150684931506,
            "8": 0.6458333333333334,
            "9": 0.7517985611510791
        },
        "rouge1": {
            "precision": 0.64528,
            "recall": 0.63822,
            "fmeasure": 0.63361
        },
        "rouge2": {
            "precision": 0.41154,
            "recall": 0.41235,
            "fmeasure": 0.40442
        },
        "rougeL": {
            "precision": 0.60971,
            "recall": 0.60938,
            "fmeasure": 0.60086
        },
        "rougeLsum": {
            "precision": 0.60971,
            "recall": 0.60938,
            "fmeasure": 0.60086
        },
        "nist": 8.537826875584441,
        "bleu": 39.40705,
        "sari": 45.07845,
        "meteor": 0.3177597442045791,
        "bleurt": -0.88573,
        "nubia": {
            "semantic_relation": 3.61703,
            "contradiction": 7.40649,
            "irrelevancy": 27.26867,
            "logical_agreement": 65.32484,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.40793,
            "nubia_score": 0.40711
        },
        "bertscore": {
            "precision": 0.84978,
            "recall": 0.89266,
            "f1": 0.86667
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "total_length": 6672,
        "mean_pred_length": 18.584958217270195,
        "std_pred_length": 8.16391250186374,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 59,
        "distinct-1": 0.36555755395683454,
        "vocab_size-1": 2439,
        "unique-1": 1828,
        "entropy-1": 9.030741409241555,
        "distinct-2": 0.8229051164264217,
        "vocab_size-2": 5195,
        "unique-2": 4775,
        "entropy-2": 11.975472152648257,
        "cond_entropy-2": 2.6540577364984603,
        "distinct-3": 0.9512932482364796,
        "vocab_size-3": 5664,
        "unique-3": 5542,
        "entropy-3": 12.358025805447765,
        "cond_entropy-3": 0.4052098865510158,
        "total_length-nopunct": 5952,
        "mean_pred_length-nopunct": 16.579387186629525,
        "std_pred_length-nopunct": 7.249913545768471,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 50,
        "distinct-1-nopunct": 0.40843413978494625,
        "vocab_size-1-nopunct": 2431,
        "unique-1-nopunct": 1825,
        "entropy-1-nopunct": 9.394200650369926,
        "distinct-2-nopunct": 0.8494546754872162,
        "vocab_size-2-nopunct": 4751,
        "unique-2-nopunct": 4396,
        "entropy-2-nopunct": 11.95602282872804,
        "cond_entropy-2-nopunct": 2.707057368841921,
        "distinct-3-nopunct": 0.9734428735192969,
        "vocab_size-3-nopunct": 5095,
        "unique-3-nopunct": 4997,
        "entropy-3-nopunct": 12.291309482743413,
        "cond_entropy-3-nopunct": 0.36149986891051694,
        "msttr-100": 0.71879,
        "msttr-100_nopunct": 0.76051,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "local_recall": {
            "1": 0.05178743961352657,
            "2": 0.16483516483516483,
            "3": 0.3071512309495897,
            "4": 0.4447592067988669,
            "5": 0.5365205843293492,
            "6": 0.6206896551724138,
            "7": 0.7534246575342466,
            "8": 0.8125,
            "9": 0.9115107913669065
        },
        "rouge1": {
            "precision": 0.80771,
            "recall": 0.78298,
            "fmeasure": 0.78633
        },
        "rouge2": {
            "precision": 0.63052,
            "recall": 0.61491,
            "fmeasure": 0.61246
        },
        "rougeL": {
            "precision": 0.76222,
            "recall": 0.74823,
            "fmeasure": 0.74543
        },
        "rougeLsum": {
            "precision": 0.76222,
            "recall": 0.74823,
            "fmeasure": 0.74543
        },
        "nist": 11.5557296062864,
        "bleu": 65.5482,
        "sari": 49.04093,
        "meteor": 0.4363786881968551,
        "bleurt": 0.07895,
        "nubia": {
            "semantic_relation": 4.09333,
            "contradiction": 3.28515,
            "irrelevancy": 28.60311,
            "logical_agreement": 68.11175,
            "grammar_ref": 4.57404,
            "grammar_hyp": 4.62853,
            "nubia_score": 0.67118
        },
        "bertscore": {
            "precision": 0.94359,
            "recall": 0.94683,
            "f1": 0.94136
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "total_length": 7385,
        "mean_pred_length": 20.571030640668525,
        "std_pred_length": 9.163926297026517,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3664184157075152,
        "vocab_size-1": 2706,
        "unique-1": 1987,
        "entropy-1": 9.146656866687636,
        "distinct-2": 0.8421576999715343,
        "vocab_size-2": 5917,
        "unique-2": 5498,
        "entropy-2": 12.22309005464263,
        "cond_entropy-2": 2.8255305124198435,
        "distinct-3": 0.9716514174291285,
        "vocab_size-3": 6478,
        "unique-3": 6369,
        "entropy-3": 12.620430292275028,
        "cond_entropy-3": 0.4095432341963963,
        "total_length-nopunct": 6655,
        "mean_pred_length-nopunct": 18.537604456824514,
        "std_pred_length-nopunct": 8.320067083079554,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.40510894064613073,
        "vocab_size-1-nopunct": 2696,
        "unique-1-nopunct": 1982,
        "entropy-1-nopunct": 9.481621313928345,
        "distinct-2-nopunct": 0.860705209656925,
        "vocab_size-2-nopunct": 5419,
        "unique-2-nopunct": 5068,
        "entropy-2-nopunct": 12.139102389866599,
        "cond_entropy-2-nopunct": 2.7824141278588894,
        "distinct-3-nopunct": 0.9819774296782887,
        "vocab_size-3-nopunct": 5830,
        "unique-3-nopunct": 5746,
        "entropy-3-nopunct": 12.49573768941282,
        "cond_entropy-3-nopunct": 0.3763288917628674,
        "msttr-100": 0.72055,
        "msttr-100_nopunct": 0.76394,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "local_recall": {
            "1": 0.06218166383701188,
            "2": 0.1839080459770115,
            "3": 0.350109409190372,
            "4": 0.3676703645007924,
            "5": 0.4932502596053998,
            "6": 0.6129227053140096,
            "7": 0.746086292478045
        },
        "rouge1": {
            "precision": 0.69324,
            "recall": 0.67078,
            "fmeasure": 0.67348
        },
        "rouge2": {
            "precision": 0.45922,
            "recall": 0.44994,
            "fmeasure": 0.44768
        },
        "rougeL": {
            "precision": 0.63687,
            "recall": 0.62192,
            "fmeasure": 0.62069
        },
        "rougeLsum": {
            "precision": 0.63687,
            "recall": 0.62192,
            "fmeasure": 0.62069
        },
        "nist": 8.57086024131584,
        "bleu": 41.75098,
        "sari": 45.82334,
        "meteor": 0.3573921079418023,
        "bleurt": -0.07663,
        "nubia": {
            "semantic_relation": 3.76233,
            "contradiction": 11.99808,
            "irrelevancy": 25.77848,
            "logical_agreement": 62.22343,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.79694,
            "nubia_score": 0.59464
        },
        "bertscore": {
            "precision": 0.90775,
            "recall": 0.90834,
            "f1": 0.90566
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "total_length": 7571,
        "mean_pred_length": 21.089136490250695,
        "std_pred_length": 9.598216470859668,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 66,
        "distinct-1": 0.41077796856425836,
        "vocab_size-1": 3110,
        "unique-1": 2448,
        "entropy-1": 9.441411913623192,
        "distinct-2": 0.8686910704381586,
        "vocab_size-2": 6265,
        "unique-2": 5895,
        "entropy-2": 12.365209709413813,
        "cond_entropy-2": 2.667188627674357,
        "distinct-3": 0.9804465197723625,
        "vocab_size-3": 6719,
        "unique-3": 6644,
        "entropy-3": 12.685545304857696,
        "cond_entropy-3": 0.33440319269481805,
        "total_length-nopunct": 6830,
        "mean_pred_length-nopunct": 19.025069637883007,
        "std_pred_length-nopunct": 8.644442782034227,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.4538799414348463,
        "vocab_size-1-nopunct": 3100,
        "unique-1-nopunct": 2447,
        "entropy-1-nopunct": 9.795716927496027,
        "distinct-2-nopunct": 0.8867253902024417,
        "vocab_size-2-nopunct": 5738,
        "unique-2-nopunct": 5429,
        "entropy-2-nopunct": 12.279663981453389,
        "cond_entropy-2-nopunct": 2.608309533574855,
        "distinct-3-nopunct": 0.9882198952879581,
        "vocab_size-3-nopunct": 6040,
        "unique-3-nopunct": 5983,
        "entropy-3-nopunct": 12.551308288032859,
        "cond_entropy-3-nopunct": 0.2901921446798251,
        "msttr-100": 0.74733,
        "msttr-100_nopunct": 0.78926,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "local_recall": {
            "1": 0.042444821731748725,
            "2": 0.17624521072796934,
            "3": 0.39606126914660833,
            "4": 0.5324881141045958,
            "5": 0.6438213914849429,
            "6": 0.7361111111111112,
            "7": 0.8140511645666285
        },
        "rouge1": {
            "precision": 0.76232,
            "recall": 0.75294,
            "fmeasure": 0.75011
        },
        "rouge2": {
            "precision": 0.57879,
            "recall": 0.57011,
            "fmeasure": 0.56763
        },
        "rougeL": {
            "precision": 0.7358,
            "recall": 0.72807,
            "fmeasure": 0.72426
        },
        "rougeLsum": {
            "precision": 0.7358,
            "recall": 0.72807,
            "fmeasure": 0.72426
        },
        "nist": 9.947712607280648,
        "bleu": 54.01947,
        "sari": 48.84457,
        "meteor": 0.40337738184153943,
        "bleurt": -0.41599,
        "nubia": {
            "semantic_relation": 4.15289,
            "contradiction": 5.78698,
            "irrelevancy": 16.70534,
            "logical_agreement": 77.50768,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.66304,
            "nubia_score": 0.59693
        },
        "bertscore": {
            "precision": 0.89943,
            "recall": 0.92492,
            "f1": 0.90985
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "total_length": 7539,
        "mean_pred_length": 21.0,
        "std_pred_length": 9.363593339249693,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 53,
        "distinct-1": 0.4586815227483751,
        "vocab_size-1": 3458,
        "unique-1": 2863,
        "entropy-1": 9.690415980915198,
        "distinct-2": 0.8940111420612813,
        "vocab_size-2": 6419,
        "unique-2": 6130,
        "entropy-2": 12.4469479405924,
        "cond_entropy-2": 2.4899058900520856,
        "distinct-3": 0.9868054537457851,
        "vocab_size-3": 6731,
        "unique-3": 6682,
        "entropy-3": 12.69598528869508,
        "cond_entropy-3": 0.2604672127961204,
        "total_length-nopunct": 6795,
        "mean_pred_length-nopunct": 18.92757660167131,
        "std_pred_length-nopunct": 8.48727000076345,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.5074319352465048,
        "vocab_size-1-nopunct": 3448,
        "unique-1-nopunct": 2861,
        "entropy-1-nopunct": 10.077465867664285,
        "distinct-2-nopunct": 0.9105034182722188,
        "vocab_size-2-nopunct": 5860,
        "unique-2-nopunct": 5623,
        "entropy-2-nopunct": 12.352020720816082,
        "cond_entropy-2-nopunct": 2.3898575622545826,
        "distinct-3-nopunct": 0.9932532499588613,
        "vocab_size-3-nopunct": 6036,
        "unique-3-nopunct": 6001,
        "entropy-3-nopunct": 12.554824085017069,
        "cond_entropy-3-nopunct": 0.21842278578849164,
        "msttr-100": 0.77013,
        "msttr-100_nopunct": 0.81612,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "local_recall": {
            "1": 0.03713921901528013,
            "2": 0.13537675606641125,
            "3": 0.3304157549234136,
            "4": 0.4469096671949287,
            "5": 0.5482866043613707,
            "6": 0.6527777777777778,
            "7": 0.7434135166093929
        },
        "rouge1": {
            "precision": 0.67974,
            "recall": 0.67138,
            "fmeasure": 0.66878
        },
        "rouge2": {
            "precision": 0.45837,
            "recall": 0.45474,
            "fmeasure": 0.45093
        },
        "rougeL": {
            "precision": 0.65359,
            "recall": 0.64799,
            "fmeasure": 0.64375
        },
        "rougeLsum": {
            "precision": 0.65359,
            "recall": 0.64799,
            "fmeasure": 0.64375
        },
        "nist": 8.482623752363995,
        "bleu": 40.31818,
        "sari": 46.75135,
        "meteor": 0.33624578061706845,
        "bleurt": -0.86137,
        "nubia": {
            "semantic_relation": 3.92353,
            "contradiction": 7.42996,
            "irrelevancy": 17.21082,
            "logical_agreement": 75.35922,
            "grammar_ref": 4.55265,
            "grammar_hyp": 6.42246,
            "nubia_score": 0.48323
        },
        "bertscore": {
            "precision": 0.8547,
            "recall": 0.89669,
            "f1": 0.87247
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "total_length": 7556,
        "mean_pred_length": 21.04735376044568,
        "std_pred_length": 9.526709993687374,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 65,
        "distinct-1": 0.36341979883536263,
        "vocab_size-1": 2746,
        "unique-1": 2003,
        "entropy-1": 9.221703530927172,
        "distinct-2": 0.8446574961789635,
        "vocab_size-2": 6079,
        "unique-2": 5629,
        "entropy-2": 12.28464342501091,
        "cond_entropy-2": 2.816612650812016,
        "distinct-3": 0.9729453056449254,
        "vocab_size-3": 6653,
        "unique-3": 6541,
        "entropy-3": 12.665193935252365,
        "cond_entropy-3": 0.3939890048376941,
        "total_length-nopunct": 6834,
        "mean_pred_length-nopunct": 19.036211699164344,
        "std_pred_length-nopunct": 8.631181608284201,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.4003511852502195,
        "vocab_size-1-nopunct": 2736,
        "unique-1-nopunct": 2001,
        "entropy-1-nopunct": 9.541282102438553,
        "distinct-2-nopunct": 0.8617760617760618,
        "vocab_size-2-nopunct": 5580,
        "unique-2-nopunct": 5197,
        "entropy-2-nopunct": 12.19815859505779,
        "cond_entropy-2-nopunct": 2.7819381732847144,
        "distinct-3-nopunct": 0.9816873773708306,
        "vocab_size-3-nopunct": 6004,
        "unique-3-nopunct": 5919,
        "entropy-3-nopunct": 12.536913422646398,
        "cond_entropy-3-nopunct": 0.3578203972884853,
        "msttr-100": 0.732,
        "msttr-100_nopunct": 0.76912,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "local_recall": {
            "1": 0.04753820033955857,
            "2": 0.19029374201787994,
            "3": 0.4638949671772429,
            "4": 0.6022187004754358,
            "5": 0.726895119418484,
            "6": 0.8079710144927537,
            "7": 0.900725467735777
        },
        "rouge1": {
            "precision": 0.84597,
            "recall": 0.83215,
            "fmeasure": 0.83049
        },
        "rouge2": {
            "precision": 0.70814,
            "recall": 0.69758,
            "fmeasure": 0.69423
        },
        "rougeL": {
            "precision": 0.81453,
            "recall": 0.80541,
            "fmeasure": 0.80109
        },
        "rougeLsum": {
            "precision": 0.81453,
            "recall": 0.80541,
            "fmeasure": 0.80109
        },
        "nist": 11.519521762813726,
        "bleu": 69.80254,
        "sari": 52.1268,
        "meteor": 0.4857629498910658,
        "bleurt": 0.2268,
        "nubia": {
            "semantic_relation": 4.40275,
            "contradiction": 3.59461,
            "irrelevancy": 16.62465,
            "logical_agreement": 79.78074,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.58438,
            "nubia_score": 0.77623
        },
        "bertscore": {
            "precision": 0.95311,
            "recall": 0.95321,
            "f1": 0.95106
        }
    },
    "dart_test": {
        "predictions_file": "t5-small/dart_test",
        "N": 1667
    },
    "wiki_auto_asset_turk_validation": {
        "predictions_file": "t5-small/wiki_auto_asset_turk_validation",
        "N": 2000
    },
    "common_gen_validation": {
        "predictions_file": "t5-small/common_gen_validation",
        "N": 993
    },
    "totto_validation": {
        "predictions_file": "t5-small/totto_validation",
        "N": 7700
    }
}

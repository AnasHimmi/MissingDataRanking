{
    "submission_name": "mT5_xl",
    "param_count": "-",
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 1654,
        "total_length": 39592,
        "mean_pred_length": 23.937122128174124,
        "std_pred_length": 12.899984081365142,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 106,
        "distinct-1": 0.04511012325722368,
        "vocab_size-1": 1786,
        "unique-1": 416,
        "entropy-1": 8.113138383076183,
        "distinct-2": 0.1674574305445727,
        "vocab_size-2": 6353,
        "unique-2": 2559,
        "entropy-2": 11.23836918535135,
        "cond_entropy-2": 2.9453601681327624,
        "distinct-3": 0.30509315400727594,
        "vocab_size-3": 11070,
        "unique-3": 5976,
        "entropy-3": 12.404944879834543,
        "cond_entropy-3": 1.2277054101670994,
        "total_length-nopunct": 34716,
        "mean_pred_length-nopunct": 20.98911729141475,
        "std_pred_length-nopunct": 11.487804482170809,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 95,
        "distinct-1-nopunct": 0.05110035718400737,
        "vocab_size-1-nopunct": 1774,
        "unique-1-nopunct": 415,
        "entropy-1-nopunct": 8.434117557959999,
        "distinct-2-nopunct": 0.1842296291815377,
        "vocab_size-2-nopunct": 6091,
        "unique-2-nopunct": 2685,
        "entropy-2-nopunct": 11.17096566338148,
        "cond_entropy-2-nopunct": 2.8732468603377015,
        "distinct-3-nopunct": 0.3247580234335201,
        "vocab_size-3-nopunct": 10200,
        "unique-3-nopunct": 5824,
        "entropy-3-nopunct": 12.287283935247837,
        "cond_entropy-3-nopunct": 1.1653834757781032,
        "msttr-100": 0.51876,
        "msttr-100_nopunct": 0.53297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 49.93756,
        "nist": 9.229958491611624,
        "rouge1": {
            "precision": 0.77014,
            "recall": 0.75343,
            "fmeasure": 0.7549
        },
        "rouge2": {
            "precision": 0.51778,
            "recall": 0.50582,
            "fmeasure": 0.50681
        },
        "rougeL": {
            "precision": 0.61903,
            "recall": 0.60672,
            "fmeasure": 0.60712
        },
        "rougeLsum": {
            "precision": 0.61903,
            "recall": 0.60672,
            "fmeasure": 0.60712
        },
        "local_recall": {
            "1": 0.22994147630734377,
            "2": 0.6003580454928391,
            "3": 0.8862514029180696,
            "4": 0.8181818181818182,
            "5": 0.8275862068965517
        },
        "meteor": 0.39638941535068345,
        "nubia": {
            "semantic_relation": 4.4747,
            "contradiction": 7.94469,
            "irrelevancy": 7.76292,
            "logical_agreement": 84.29238,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.56857,
            "nubia_score": 0.80305
        },
        "bleurt": 0.23536,
        "bertscore": {
            "precision": 0.92633,
            "recall": 0.9248,
            "f1": 0.92431
        }
    },
    "web_nlg_en_challenge_test_numbers": {
        "predictions_file": "mT5_xl/web_nlg_en_challenge_test_numbers",
        "N": 500,
        "total_length": 12383,
        "mean_pred_length": 24.766,
        "std_pred_length": 13.292375408481359,
        "median_pred_length": 22.5,
        "min_pred_length": 5,
        "max_pred_length": 86,
        "distinct-1": 0.12024549785996931,
        "vocab_size-1": 1489,
        "unique-1": 600,
        "entropy-1": 8.127180255064154,
        "distinct-2": 0.3898005554152992,
        "vocab_size-2": 4632,
        "unique-2": 2892,
        "entropy-2": 11.271900950589256,
        "cond_entropy-2": 2.974052145586606,
        "distinct-3": 0.6194324870420803,
        "vocab_size-3": 7051,
        "unique-3": 5407,
        "entropy-3": 12.329371137084879,
        "cond_entropy-3": 1.0991516348502521,
        "total_length-nopunct": 10895,
        "mean_pred_length-nopunct": 21.79,
        "std_pred_length-nopunct": 11.809060081141089,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.13565855897200552,
        "vocab_size-1-nopunct": 1478,
        "unique-1-nopunct": 600,
        "entropy-1-nopunct": 8.41989521237486,
        "distinct-2-nopunct": 0.4082732082732083,
        "vocab_size-2-nopunct": 4244,
        "unique-2-nopunct": 2748,
        "entropy-2-nopunct": 11.170074642563375,
        "cond_entropy-2-nopunct": 2.8672462136372285,
        "distinct-3-nopunct": 0.6328448711470439,
        "vocab_size-3-nopunct": 6262,
        "unique-3-nopunct": 4892,
        "entropy-3-nopunct": 12.164295236052066,
        "cond_entropy-3-nopunct": 1.0216129365811435,
        "msttr-100": 0.65472,
        "msttr-100_nopunct": 0.70065,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_numbers.json",
        "bleu": 43.38985,
        "nist": 8.262089605666935,
        "rouge1": {
            "precision": 0.72419,
            "recall": 0.7123,
            "fmeasure": 0.71146
        },
        "rouge2": {
            "precision": 0.46573,
            "recall": 0.45835,
            "fmeasure": 0.45713
        },
        "rougeL": {
            "precision": 0.57191,
            "recall": 0.56272,
            "fmeasure": 0.56133
        },
        "rougeLsum": {
            "precision": 0.57191,
            "recall": 0.56272,
            "fmeasure": 0.56133
        },
        "local_recall": {
            "1": 0.2197365670081539,
            "2": 0.5497076023391813,
            "3": 0.8392184979386987,
            "4": 0.7777777777777778,
            "5": 0.9090909090909091
        },
        "meteor": 0.3695380578761182,
        "nubia": {
            "semantic_relation": 4.14582,
            "contradiction": 22.21362,
            "irrelevancy": 8.25492,
            "logical_agreement": 69.53146,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.61334,
            "nubia_score": 0.69775
        },
        "bleurt": 0.12068,
        "bertscore": {
            "precision": 0.9121,
            "recall": 0.91276,
            "f1": 0.91101
        }
    },
    "schema_guided_dialog_val": {
        "predictions_file": "mT5_xl/schema_guided_dialog_val",
        "N": 10000,
        "total_length": 121130,
        "mean_pred_length": 12.113,
        "std_pred_length": 7.048221832490802,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 54,
        "distinct-1": 0.03395525468504912,
        "vocab_size-1": 4113,
        "unique-1": 1733,
        "entropy-1": 8.085734794701903,
        "distinct-2": 0.13392423288041033,
        "vocab_size-2": 14883,
        "unique-2": 7770,
        "entropy-2": 11.405295931895628,
        "cond_entropy-2": 3.043664598880709,
        "distinct-3": 0.2678281849464067,
        "vocab_size-3": 27086,
        "unique-3": 17081,
        "entropy-3": 12.868464632108942,
        "cond_entropy-3": 1.4787766448484256,
        "total_length-nopunct": 106169,
        "mean_pred_length-nopunct": 10.6169,
        "std_pred_length-nopunct": 6.454373276314286,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.0385894187568876,
        "vocab_size-1-nopunct": 4097,
        "unique-1-nopunct": 1730,
        "entropy-1-nopunct": 8.327595500758079,
        "distinct-2-nopunct": 0.14775031455042686,
        "vocab_size-2-nopunct": 14209,
        "unique-2-nopunct": 7754,
        "entropy-2-nopunct": 11.303843440914084,
        "cond_entropy-2-nopunct": 3.1176924534845414,
        "distinct-3-nopunct": 0.29053630688542853,
        "vocab_size-3-nopunct": 25039,
        "unique-3-nopunct": 16361,
        "entropy-3-nopunct": 12.763909231292905,
        "cond_entropy-3-nopunct": 1.491910856931375,
        "msttr-100": 0.69463,
        "msttr-100_nopunct": 0.72505,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_val.json",
        "bleu": 36.73813,
        "nist": 7.697350459323307,
        "rouge1": {
            "precision": 0.63924,
            "recall": 0.61709,
            "fmeasure": 0.6147
        },
        "rouge2": {
            "precision": 0.42314,
            "recall": 0.40921,
            "fmeasure": 0.40636
        },
        "rougeL": {
            "precision": 0.58004,
            "recall": 0.5601,
            "fmeasure": 0.55786
        },
        "rougeLsum": {
            "precision": 0.58004,
            "recall": 0.5601,
            "fmeasure": 0.55786
        },
        "local_recall": {
            "1": 0.6193076121735248
        },
        "meteor": 0.3496061372131486,
        "nubia": {
            "semantic_relation": 3.91975,
            "contradiction": 3.0372,
            "irrelevancy": 16.97204,
            "logical_agreement": 79.99076,
            "grammar_ref": 4.88727,
            "grammar_hyp": 4.6328,
            "nubia_score": 0.72898
        },
        "bleurt": 0.06109,
        "bertscore": {
            "precision": 0.88842,
            "recall": 0.88171,
            "f1": 0.88448
        }
    },
    "common_gen_val": {
        "predictions_file": "mT5_xl/common_gen_val",
        "N": 993,
        "total_length": 11439,
        "mean_pred_length": 11.51963746223565,
        "std_pred_length": 3.0178834325356267,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 24,
        "distinct-1": 0.14301949471107614,
        "vocab_size-1": 1636,
        "unique-1": 849,
        "entropy-1": 7.5883438204298175,
        "distinct-2": 0.5045950603101665,
        "vocab_size-2": 5271,
        "unique-2": 3924,
        "entropy-2": 11.350537216988894,
        "cond_entropy-2": 3.522768172022156,
        "distinct-3": 0.782608695652174,
        "vocab_size-3": 7398,
        "unique-3": 6481,
        "entropy-3": 12.558039613934898,
        "cond_entropy-3": 1.262172633899592,
        "total_length-nopunct": 10549,
        "mean_pred_length-nopunct": 10.623363544813696,
        "std_pred_length-nopunct": 2.846728828130047,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.15489619869181914,
        "vocab_size-1-nopunct": 1634,
        "unique-1-nopunct": 849,
        "entropy-1-nopunct": 7.76803911053069,
        "distinct-2-nopunct": 0.5044997907074089,
        "vocab_size-2-nopunct": 4821,
        "unique-2-nopunct": 3633,
        "entropy-2-nopunct": 11.175543199762222,
        "cond_entropy-2-nopunct": 3.713709578475092,
        "distinct-3-nopunct": 0.7890926077309354,
        "vocab_size-3-nopunct": 6757,
        "unique-3-nopunct": 5954,
        "entropy-3-nopunct": 12.427980626103698,
        "cond_entropy-3-nopunct": 1.3299420513592664,
        "msttr-100": 0.62184,
        "msttr-100_nopunct": 0.64648,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/common_gen_val.json",
        "bleu": 21.25149,
        "nist": 6.340809289208497,
        "rouge1": {
            "precision": 0.59983,
            "recall": 0.61536,
            "fmeasure": 0.59489
        },
        "rouge2": {
            "precision": 0.27598,
            "recall": 0.27625,
            "fmeasure": 0.2687
        },
        "rougeL": {
            "precision": 0.5082,
            "recall": 0.51703,
            "fmeasure": 0.50132
        },
        "rougeLsum": {
            "precision": 0.5082,
            "recall": 0.51703,
            "fmeasure": 0.50132
        },
        "local_recall": {
            "1": 0.10448693913260843,
            "2": 0.31835106382978723,
            "3": 0.49707602339181284,
            "4": 0.7476908118619349,
            "5": 0.7618025751072961,
            "6": 0.75,
            "7": 0.8333333333333334,
            "8": 0.2
        },
        "meteor": 0.2474247411234108,
        "nubia": {
            "semantic_relation": 2.98887,
            "contradiction": 30.64707,
            "irrelevancy": 35.66952,
            "logical_agreement": 33.68342,
            "grammar_ref": 4.64808,
            "grammar_hyp": 4.72462,
            "nubia_score": 0.40256
        },
        "bleurt": -0.52312,
        "bertscore": {
            "precision": 0.87176,
            "recall": 0.8772,
            "f1": 0.87315
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7167,
        "mean_pred_length": 19.963788300835656,
        "std_pred_length": 9.29589858462179,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.3573322171061811,
        "vocab_size-1": 2561,
        "unique-1": 1869,
        "entropy-1": 9.113280774616257,
        "distinct-2": 0.832256169212691,
        "vocab_size-2": 5666,
        "unique-2": 5238,
        "entropy-2": 12.139825987465183,
        "cond_entropy-2": 2.7671722316842198,
        "distinct-3": 0.9615444254923244,
        "vocab_size-3": 6201,
        "unique-3": 6079,
        "entropy-3": 12.526257117156364,
        "cond_entropy-3": 0.4056865141794836,
        "total_length-nopunct": 6341,
        "mean_pred_length-nopunct": 17.662952646239553,
        "std_pred_length-nopunct": 8.092814184272115,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.40198706828575936,
        "vocab_size-1-nopunct": 2549,
        "unique-1-nopunct": 1868,
        "entropy-1-nopunct": 9.453751403450571,
        "distinct-2-nopunct": 0.8567368772985624,
        "vocab_size-2-nopunct": 5125,
        "unique-2-nopunct": 4772,
        "entropy-2-nopunct": 12.061882539880092,
        "cond_entropy-2-nopunct": 2.7488311245862627,
        "distinct-3-nopunct": 0.9779477147430198,
        "vocab_size-3-nopunct": 5499,
        "unique-3-nopunct": 5403,
        "entropy-3-nopunct": 12.407352949029834,
        "cond_entropy-3-nopunct": 0.3694223002622433,
        "msttr-100": 0.7269,
        "msttr-100_nopunct": 0.76762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 67.21602,
        "nist": 11.095537431856437,
        "rouge1": {
            "precision": 0.84507,
            "recall": 0.78787,
            "fmeasure": 0.80316
        },
        "rouge2": {
            "precision": 0.7046,
            "recall": 0.65558,
            "fmeasure": 0.66725
        },
        "rougeL": {
            "precision": 0.81486,
            "recall": 0.76168,
            "fmeasure": 0.77518
        },
        "rougeLsum": {
            "precision": 0.81486,
            "recall": 0.76168,
            "fmeasure": 0.77518
        },
        "local_recall": {
            "1": 0.04647707979626486,
            "2": 0.16219667943805874,
            "3": 0.4026258205689278,
            "4": 0.5404120443740095,
            "5": 0.6355140186915887,
            "6": 0.7518115942028986,
            "7": 0.8694158075601375
        },
        "meteor": 0.45786204822397686,
        "nubia": {
            "semantic_relation": 4.28957,
            "contradiction": 4.23798,
            "irrelevancy": 17.2489,
            "logical_agreement": 78.51313,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.90086,
            "nubia_score": 0.69691
        },
        "bleurt": 0.21354,
        "bertscore": {
            "precision": 0.95341,
            "recall": 0.94332,
            "f1": 0.94609
        }
    },
    "cs_restaurants_challenge_test_scramble_parent": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 500,
        "total_length": 5553,
        "mean_pred_length": 11.106,
        "std_pred_length": 3.621983434528656,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.0965244012245633,
        "vocab_size-1": 536,
        "unique-1": 219,
        "entropy-1": 6.8980538749125575,
        "distinct-2": 0.2736987927963586,
        "vocab_size-2": 1383,
        "unique-2": 795,
        "entropy-2": 8.892908585782429,
        "cond_entropy-2": 1.7256366603588997,
        "distinct-3": 0.4210410718207775,
        "vocab_size-3": 1917,
        "unique-3": 1366,
        "entropy-3": 9.505634347319743,
        "cond_entropy-3": 0.6676239447511428,
        "total_length-nopunct": 4586,
        "mean_pred_length-nopunct": 9.172,
        "std_pred_length-nopunct": 3.2867029071700413,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.11600523331879634,
        "vocab_size-1-nopunct": 532,
        "unique-1-nopunct": 219,
        "entropy-1-nopunct": 7.224148995272072,
        "distinct-2-nopunct": 0.28952520802741066,
        "vocab_size-2-nopunct": 1183,
        "unique-2-nopunct": 688,
        "entropy-2-nopunct": 8.75619331802647,
        "cond_entropy-2-nopunct": 1.7060788805510767,
        "distinct-3-nopunct": 0.4539877300613497,
        "vocab_size-3-nopunct": 1628,
        "unique-3-nopunct": 1188,
        "entropy-3-nopunct": 9.412512008296813,
        "cond_entropy-3-nopunct": 0.7674581893208776,
        "msttr-100": 0.60655,
        "msttr-100_nopunct": 0.65578,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 17.56366,
        "nist": 3.8275987019935664,
        "rouge1": {
            "precision": 0.49721,
            "recall": 0.51996,
            "fmeasure": 0.49172
        },
        "rouge2": {
            "precision": 0.28159,
            "recall": 0.2888,
            "fmeasure": 0.27616
        },
        "rougeL": {
            "precision": 0.44595,
            "recall": 0.46796,
            "fmeasure": 0.44173
        },
        "rougeLsum": {
            "precision": 0.44595,
            "recall": 0.46796,
            "fmeasure": 0.44173
        },
        "local_recall": {
            "1": 0.46168180759375727
        },
        "meteor": 0.2340699535484374,
        "nubia": {
            "semantic_relation": 3.25358,
            "contradiction": 26.0072,
            "irrelevancy": 31.1186,
            "logical_agreement": 42.8742,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.79774,
            "nubia_score": 0.46212
        },
        "bleurt": -0.27283,
        "bertscore": {
            "precision": 0.88711,
            "recall": 0.89792,
            "f1": 0.89208
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7167,
        "mean_pred_length": 19.963788300835656,
        "std_pred_length": 9.29589858462179,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.3573322171061811,
        "vocab_size-1": 2561,
        "unique-1": 1869,
        "entropy-1": 9.113280774616257,
        "distinct-2": 0.832256169212691,
        "vocab_size-2": 5666,
        "unique-2": 5238,
        "entropy-2": 12.139825987465183,
        "cond_entropy-2": 2.7671722316842198,
        "distinct-3": 0.9615444254923244,
        "vocab_size-3": 6201,
        "unique-3": 6079,
        "entropy-3": 12.526257117156364,
        "cond_entropy-3": 0.4056865141794836,
        "total_length-nopunct": 6341,
        "mean_pred_length-nopunct": 17.662952646239553,
        "std_pred_length-nopunct": 8.092814184272115,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.40198706828575936,
        "vocab_size-1-nopunct": 2549,
        "unique-1-nopunct": 1868,
        "entropy-1-nopunct": 9.453751403450571,
        "distinct-2-nopunct": 0.8567368772985624,
        "vocab_size-2-nopunct": 5125,
        "unique-2-nopunct": 4772,
        "entropy-2-nopunct": 12.061882539880092,
        "cond_entropy-2-nopunct": 2.7488311245862627,
        "distinct-3-nopunct": 0.9779477147430198,
        "vocab_size-3-nopunct": 5499,
        "unique-3-nopunct": 5403,
        "entropy-3-nopunct": 12.407352949029834,
        "cond_entropy-3-nopunct": 0.3694223002622433,
        "msttr-100": 0.7269,
        "msttr-100_nopunct": 0.76762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 67.21602,
        "nist": 11.095537431856437,
        "rouge1": {
            "precision": 0.84507,
            "recall": 0.78787,
            "fmeasure": 0.80316
        },
        "rouge2": {
            "precision": 0.7046,
            "recall": 0.65558,
            "fmeasure": 0.66725
        },
        "rougeL": {
            "precision": 0.81486,
            "recall": 0.76168,
            "fmeasure": 0.77518
        },
        "rougeLsum": {
            "precision": 0.81486,
            "recall": 0.76168,
            "fmeasure": 0.77518
        },
        "local_recall": {
            "1": 0.04647707979626486,
            "2": 0.16219667943805874,
            "3": 0.4026258205689278,
            "4": 0.5404120443740095,
            "5": 0.6355140186915887,
            "6": 0.7518115942028986,
            "7": 0.8694158075601375
        },
        "meteor": 0.45786204822397686,
        "nubia": {
            "semantic_relation": 4.28957,
            "contradiction": 4.23798,
            "irrelevancy": 17.2489,
            "logical_agreement": 78.51313,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.90086,
            "nubia_score": 0.69691
        },
        "bleurt": 0.21354,
        "bertscore": {
            "precision": 0.95341,
            "recall": 0.94332,
            "f1": 0.94609
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 253,
        "total_length": 2196,
        "mean_pred_length": 8.679841897233201,
        "std_pred_length": 2.809545554010969,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 19,
        "distinct-1": 0.42213114754098363,
        "vocab_size-1": 927,
        "unique-1": 630,
        "entropy-1": 8.376583999604044,
        "distinct-2": 0.7575913535769428,
        "vocab_size-2": 1472,
        "unique-2": 1210,
        "entropy-2": 10.265001588972446,
        "cond_entropy-2": 1.2036489045878092,
        "distinct-3": 0.8733727810650888,
        "vocab_size-3": 1476,
        "unique-3": 1319,
        "entropy-3": 10.432258912546795,
        "cond_entropy-3": 0.14823395194905553,
        "total_length-nopunct": 1767,
        "mean_pred_length-nopunct": 6.984189723320158,
        "std_pred_length-nopunct": 2.5225753504677852,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5217883418222977,
        "vocab_size-1-nopunct": 922,
        "unique-1-nopunct": 630,
        "entropy-1-nopunct": 9.10012877890718,
        "distinct-2-nopunct": 0.7760898282694848,
        "vocab_size-2-nopunct": 1175,
        "unique-2-nopunct": 982,
        "entropy-2-nopunct": 9.957170430706336,
        "cond_entropy-2-nopunct": 0.957254090621406,
        "distinct-3-nopunct": 0.8754956383822363,
        "vocab_size-3-nopunct": 1104,
        "unique-3-nopunct": 992,
        "entropy-3-nopunct": 10.012495252274737,
        "cond_entropy-3-nopunct": 0.12977714027675716,
        "msttr-100": 0.76762,
        "msttr-100_nopunct": 0.88176,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 61.11193,
        "nist": 8.49040651642362,
        "rouge1": {
            "precision": 0.34387,
            "recall": 0.33833,
            "fmeasure": 0.33992
        },
        "rouge2": {
            "precision": 0.18857,
            "recall": 0.18709,
            "fmeasure": 0.18746
        },
        "rougeL": {
            "precision": 0.34321,
            "recall": 0.33783,
            "fmeasure": 0.33935
        },
        "rougeLsum": {
            "precision": 0.34321,
            "recall": 0.33783,
            "fmeasure": 0.33935
        },
        "local_recall": {
            "1": 0.38976109215017063,
            "2": 0.7210599721059973,
            "3": 0.8395904436860068,
            "4": 0.8571428571428571,
            "5": 0.8181818181818182,
            "6": 0.9,
            "7": 1.0
        },
        "meteor": 0.7566773441465963,
        "nubia": {
            "semantic_relation": 4.2116,
            "contradiction": 20.49333,
            "irrelevancy": 19.82754,
            "logical_agreement": 59.67913,
            "grammar_ref": 2.90527,
            "grammar_hyp": 2.88794,
            "nubia_score": 0.85032
        },
        "bleurt": 0.38974,
        "bertscore": {
            "precision": 0.96763,
            "recall": 0.96751,
            "f1": 0.96711
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 149,
        "total_length": 1788,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.005592841163310962,
        "vocab_size-1": 10,
        "unique-1": 0,
        "entropy-1": 3.188721875540867,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 11,
        "unique-2": 0,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.30673161811281985,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 10,
        "unique-3": 0,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 1192,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.006711409395973154,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": 0.1,
        "msttr-100_nopunct": 0.08,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 0.696,
        "nist": 0.4722844955395275,
        "rouge1": {
            "precision": 0.17833,
            "recall": 0.38229,
            "fmeasure": 0.23855
        },
        "rouge2": {
            "precision": 0.03975,
            "recall": 0.11333,
            "fmeasure": 0.0579
        },
        "rougeL": {
            "precision": 0.16635,
            "recall": 0.35865,
            "fmeasure": 0.22326
        },
        "rougeLsum": {
            "precision": 0.16635,
            "recall": 0.35865,
            "fmeasure": 0.22326
        },
        "local_recall": {
            "1": 0.09785522788203753
        },
        "meteor": 0.05941689963779256,
        "nubia": {
            "semantic_relation": 2.21147,
            "contradiction": 50.78054,
            "irrelevancy": 43.97333,
            "logical_agreement": 5.24613,
            "grammar_ref": 6.81129,
            "grammar_hyp": 6.2034,
            "nubia_score": 0.20101
        },
        "bleurt": -1.10101,
        "bertscore": {
            "precision": 0.79134,
            "recall": 0.85869,
            "f1": 0.82349
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 100.0,
        "nist": 4.1322265887439,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.56053,
            "contradiction": 14.31616,
            "irrelevancy": 10.10795,
            "logical_agreement": 75.57589,
            "grammar_ref": 2.53664,
            "grammar_hyp": 2.60057,
            "nubia_score": 0.9107
        },
        "bleurt": 0.54643,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 609,
        "total_length": 6503,
        "mean_pred_length": 10.67816091954023,
        "std_pred_length": 3.8153005292448845,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 24,
        "distinct-1": 0.09503306166384745,
        "vocab_size-1": 618,
        "unique-1": 216,
        "entropy-1": 6.9749099192415684,
        "distinct-2": 0.27824906684764167,
        "vocab_size-2": 1640,
        "unique-2": 851,
        "entropy-2": 9.355474340634444,
        "cond_entropy-2": 2.0089779467291633,
        "distinct-3": 0.45695364238410596,
        "vocab_size-3": 2415,
        "unique-3": 1678,
        "entropy-3": 10.260107463436743,
        "cond_entropy-3": 1.001306241644096,
        "total_length-nopunct": 5622,
        "mean_pred_length-nopunct": 9.231527093596059,
        "std_pred_length-nopunct": 3.431802075306369,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.10921380291711134,
        "vocab_size-1-nopunct": 614,
        "unique-1-nopunct": 216,
        "entropy-1-nopunct": 7.249289671841915,
        "distinct-2-nopunct": 0.2774785557550369,
        "vocab_size-2-nopunct": 1391,
        "unique-2-nopunct": 752,
        "entropy-2-nopunct": 9.090435677907971,
        "cond_entropy-2-nopunct": 2.1253017468317053,
        "distinct-3-nopunct": 0.4645776566757493,
        "vocab_size-3-nopunct": 2046,
        "unique-3-nopunct": 1467,
        "entropy-3-nopunct": 10.0109354785789,
        "cond_entropy-3-nopunct": 1.1188902042762556,
        "msttr-100": 0.59969,
        "msttr-100_nopunct": 0.63964,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 21.21623,
        "nist": 4.520618097403151,
        "rouge1": {
            "precision": 0.57451,
            "recall": 0.55207,
            "fmeasure": 0.55203
        },
        "rouge2": {
            "precision": 0.32885,
            "recall": 0.31865,
            "fmeasure": 0.3172
        },
        "rougeL": {
            "precision": 0.51221,
            "recall": 0.49263,
            "fmeasure": 0.49268
        },
        "rougeLsum": {
            "precision": 0.51221,
            "recall": 0.49263,
            "fmeasure": 0.49268
        },
        "local_recall": {
            "1": 0.5032842180010652
        },
        "meteor": 0.2552829555953498,
        "nubia": {
            "semantic_relation": 3.53028,
            "contradiction": 18.42594,
            "irrelevancy": 29.9127,
            "logical_agreement": 51.66137,
            "grammar_ref": 6.96179,
            "grammar_hyp": 7.05071,
            "nubia_score": 0.52935
        },
        "bleurt": -0.0783,
        "bertscore": {
            "precision": 0.90714,
            "recall": 0.90575,
            "f1": 0.90625
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 125,
        "total_length": 3589,
        "mean_pred_length": 28.712,
        "std_pred_length": 9.544687318084339,
        "median_pred_length": 29.0,
        "min_pred_length": 9,
        "max_pred_length": 51,
        "distinct-1": 0.12315408191696851,
        "vocab_size-1": 442,
        "unique-1": 121,
        "entropy-1": 7.077091884868348,
        "distinct-2": 0.3357390300230947,
        "vocab_size-2": 1163,
        "unique-2": 578,
        "entropy-2": 9.464792074650855,
        "cond_entropy-2": 2.277672570318842,
        "distinct-3": 0.5085354896675651,
        "vocab_size-3": 1698,
        "unique-3": 1088,
        "entropy-3": 10.233029168626349,
        "cond_entropy-3": 0.7919261881982951,
        "total_length-nopunct": 3156,
        "mean_pred_length-nopunct": 25.248,
        "std_pred_length-nopunct": 8.50285222734113,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.13783269961977188,
        "vocab_size-1-nopunct": 435,
        "unique-1-nopunct": 120,
        "entropy-1-nopunct": 7.244030631075741,
        "distinct-2-nopunct": 0.3645661497855493,
        "vocab_size-2-nopunct": 1105,
        "unique-2-nopunct": 588,
        "entropy-2-nopunct": 9.394159650770574,
        "cond_entropy-2-nopunct": 2.226173708404028,
        "distinct-3-nopunct": 0.5357880247763248,
        "vocab_size-3-nopunct": 1557,
        "unique-3-nopunct": 1053,
        "entropy-3-nopunct": 10.111831342344878,
        "cond_entropy-3-nopunct": 0.7267247441248588,
        "msttr-100": 0.49886,
        "msttr-100_nopunct": 0.51129,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 38.55594,
        "nist": 7.059940369865718,
        "rouge1": {
            "precision": 0.71444,
            "recall": 0.68198,
            "fmeasure": 0.68827
        },
        "rouge2": {
            "precision": 0.43605,
            "recall": 0.41364,
            "fmeasure": 0.41741
        },
        "rougeL": {
            "precision": 0.54077,
            "recall": 0.51782,
            "fmeasure": 0.52097
        },
        "rougeLsum": {
            "precision": 0.54077,
            "recall": 0.51782,
            "fmeasure": 0.52097
        },
        "local_recall": {
            "1": 0.21001300390117036,
            "2": 0.4893882646691635,
            "3": 0.8178571428571428
        },
        "meteor": 0.3355927306557008,
        "nubia": {
            "semantic_relation": 4.09416,
            "contradiction": 9.85185,
            "irrelevancy": 10.82676,
            "logical_agreement": 79.32139,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.36808,
            "nubia_score": 0.68819
        },
        "bleurt": 0.0692,
        "bertscore": {
            "precision": 0.90087,
            "recall": 0.89249,
            "f1": 0.89466
        }
    },
    "cs_restaurants_val": {
        "predictions_file": "mT5_xl/cs_restaurants_val",
        "N": 781,
        "total_length": 7388,
        "mean_pred_length": 9.45966709346991,
        "std_pred_length": 4.208700748336143,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 26,
        "distinct-1": 0.05928532755820249,
        "vocab_size-1": 438,
        "unique-1": 146,
        "entropy-1": 6.8141650348768765,
        "distinct-2": 0.19252308158014228,
        "vocab_size-2": 1272,
        "unique-2": 614,
        "entropy-2": 8.992034581691035,
        "cond_entropy-2": 1.8214181391226918,
        "distinct-3": 0.3372811534500515,
        "vocab_size-3": 1965,
        "unique-3": 1165,
        "entropy-3": 9.8785388447266,
        "cond_entropy-3": 0.795222958633162,
        "total_length-nopunct": 6294,
        "mean_pred_length-nopunct": 8.058898847631243,
        "std_pred_length-nopunct": 3.7374271781083848,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.06895455989831585,
        "vocab_size-1-nopunct": 434,
        "unique-1-nopunct": 146,
        "entropy-1-nopunct": 7.044031067135877,
        "distinct-2-nopunct": 0.208597859604571,
        "vocab_size-2-nopunct": 1150,
        "unique-2-nopunct": 584,
        "entropy-2-nopunct": 8.873768583650014,
        "cond_entropy-2-nopunct": 1.8707426192130479,
        "distinct-3-nopunct": 0.3702451394759087,
        "vocab_size-3-nopunct": 1752,
        "unique-3-nopunct": 1076,
        "entropy-3-nopunct": 9.79221307228704,
        "cond_entropy-3-nopunct": 0.8141259609952707,
        "msttr-100": 0.59767,
        "msttr-100_nopunct": 0.63677,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_val.json",
        "bleu": 16.99869,
        "nist": 4.010117111788224,
        "rouge1": {
            "precision": 0.56653,
            "recall": 0.50123,
            "fmeasure": 0.52072
        },
        "rouge2": {
            "precision": 0.34222,
            "recall": 0.30135,
            "fmeasure": 0.31298
        },
        "rougeL": {
            "precision": 0.51424,
            "recall": 0.45475,
            "fmeasure": 0.47265
        },
        "rougeLsum": {
            "precision": 0.51424,
            "recall": 0.45475,
            "fmeasure": 0.47265
        },
        "local_recall": {
            "1": 0.43402366863905323
        },
        "meteor": 0.22899306045938939,
        "nubia": {
            "semantic_relation": 3.31336,
            "contradiction": 26.24545,
            "irrelevancy": 24.0507,
            "logical_agreement": 49.70385,
            "grammar_ref": 6.54085,
            "grammar_hyp": 6.7924,
            "nubia_score": 0.44918
        },
        "bleurt": -0.09208,
        "bertscore": {
            "precision": 0.90984,
            "recall": 0.9,
            "f1": 0.90467
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 1510,
        "total_length": 34877,
        "mean_pred_length": 23.097350993377482,
        "std_pred_length": 12.70836115767449,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 81,
        "distinct-1": 0.0484560025231528,
        "vocab_size-1": 1690,
        "unique-1": 441,
        "entropy-1": 8.068118332871688,
        "distinct-2": 0.17265561782599576,
        "vocab_size-2": 5761,
        "unique-2": 2409,
        "entropy-2": 11.121332406592112,
        "cond_entropy-2": 2.8672934395126375,
        "distinct-3": 0.3044856703393289,
        "vocab_size-3": 9700,
        "unique-3": 5288,
        "entropy-3": 12.21326397223306,
        "cond_entropy-3": 1.1580461003603466,
        "total_length-nopunct": 30643,
        "mean_pred_length-nopunct": 20.29337748344371,
        "std_pred_length-nopunct": 11.339932191267255,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.054759651470156316,
        "vocab_size-1-nopunct": 1678,
        "unique-1-nopunct": 440,
        "entropy-1-nopunct": 8.382226853697164,
        "distinct-2-nopunct": 0.1867641506195723,
        "vocab_size-2-nopunct": 5441,
        "unique-2-nopunct": 2445,
        "entropy-2-nopunct": 11.035194323249343,
        "cond_entropy-2-nopunct": 2.7964078877693765,
        "distinct-3-nopunct": 0.321073018861094,
        "vocab_size-3-nopunct": 8869,
        "unique-3-nopunct": 5045,
        "entropy-3-nopunct": 12.084002914920225,
        "cond_entropy-3-nopunct": 1.1022877477749606,
        "msttr-100": 0.51152,
        "msttr-100_nopunct": 0.52092,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 51.98632,
        "nist": 9.338171630927551,
        "rouge1": {
            "precision": 0.77735,
            "recall": 0.76037,
            "fmeasure": 0.76216
        },
        "rouge2": {
            "precision": 0.5315,
            "recall": 0.51945,
            "fmeasure": 0.52046
        },
        "rougeL": {
            "precision": 0.63345,
            "recall": 0.62055,
            "fmeasure": 0.6213
        },
        "rougeLsum": {
            "precision": 0.63345,
            "recall": 0.62055,
            "fmeasure": 0.6213
        },
        "local_recall": {
            "1": 0.237688585254768,
            "2": 0.6150035385704176,
            "3": 0.8911010749952293,
            "4": 0.8431372549019608,
            "5": 0.7619047619047619
        },
        "meteor": 0.4033281849601201,
        "nubia": {
            "semantic_relation": 4.51271,
            "contradiction": 7.49244,
            "irrelevancy": 7.45517,
            "logical_agreement": 85.05238,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.58783,
            "nubia_score": 0.81584
        },
        "bleurt": 0.26526,
        "bertscore": {
            "precision": 0.93,
            "recall": 0.92807,
            "f1": 0.92779
        }
    },
    "cs_restaurants_test": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 842,
        "total_length": 9245,
        "mean_pred_length": 10.979809976247031,
        "std_pred_length": 3.6033530125443045,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.07203893996755002,
        "vocab_size-1": 666,
        "unique-1": 227,
        "entropy-1": 6.950309911140144,
        "distinct-2": 0.2194454361537546,
        "vocab_size-2": 1844,
        "unique-2": 939,
        "entropy-2": 9.061372188935575,
        "cond_entropy-2": 1.8328554785903206,
        "distinct-3": 0.3614601243221796,
        "vocab_size-3": 2733,
        "unique-3": 1841,
        "entropy-3": 9.765170612143955,
        "cond_entropy-3": 0.7743225907806166,
        "total_length-nopunct": 7621,
        "mean_pred_length-nopunct": 9.051068883610451,
        "std_pred_length-nopunct": 3.238868024231682,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.0868652407820496,
        "vocab_size-1-nopunct": 662,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.29303543090008,
        "distinct-2-nopunct": 0.23233515267738605,
        "vocab_size-2-nopunct": 1575,
        "unique-2-nopunct": 839,
        "entropy-2-nopunct": 8.917672462227358,
        "cond_entropy-2-nopunct": 1.8268399333055922,
        "distinct-3-nopunct": 0.39178036045140646,
        "vocab_size-3-nopunct": 2326,
        "unique-3-nopunct": 1623,
        "entropy-3-nopunct": 9.68349586140469,
        "cond_entropy-3-nopunct": 0.8963735608655233,
        "msttr-100": 0.59391,
        "msttr-100_nopunct": 0.63934,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 17.36895,
        "nist": 3.88423582682771,
        "rouge1": {
            "precision": 0.50007,
            "recall": 0.51608,
            "fmeasure": 0.49134
        },
        "rouge2": {
            "precision": 0.27876,
            "recall": 0.28201,
            "fmeasure": 0.27145
        },
        "rougeL": {
            "precision": 0.4464,
            "recall": 0.46277,
            "fmeasure": 0.43948
        },
        "rougeLsum": {
            "precision": 0.4464,
            "recall": 0.46277,
            "fmeasure": 0.43948
        },
        "local_recall": {
            "1": 0.45206428373510665
        },
        "meteor": 0.22922577880244754,
        "nubia": {
            "semantic_relation": 3.25515,
            "contradiction": 25.04482,
            "irrelevancy": 31.59959,
            "logical_agreement": 43.3556,
            "grammar_ref": 6.8707,
            "grammar_hyp": 6.83208,
            "nubia_score": 0.4607
        },
        "bleurt": -0.264,
        "bertscore": {
            "precision": 0.88742,
            "recall": 0.89771,
            "f1": 0.89214
        }
    },
    "cs_restaurants_challenge_test_scramble": {
        "predictions_file": "mT5_xl/cs_restaurants_challenge_test_scramble",
        "N": 500,
        "total_length": 5577,
        "mean_pred_length": 11.154,
        "std_pred_length": 4.123382591998952,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 28,
        "distinct-1": 0.11547426932042316,
        "vocab_size-1": 644,
        "unique-1": 282,
        "entropy-1": 7.2870379012389614,
        "distinct-2": 0.3509946818987591,
        "vocab_size-2": 1782,
        "unique-2": 1102,
        "entropy-2": 9.68622898057484,
        "cond_entropy-2": 2.096691802945063,
        "distinct-3": 0.5376884422110553,
        "vocab_size-3": 2461,
        "unique-3": 1858,
        "entropy-3": 10.46651831168079,
        "cond_entropy-3": 0.8153784259627892,
        "total_length-nopunct": 4709,
        "mean_pred_length-nopunct": 9.418,
        "std_pred_length-nopunct": 3.656128553538565,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.13590995965173072,
        "vocab_size-1-nopunct": 640,
        "unique-1-nopunct": 282,
        "entropy-1-nopunct": 7.607561708985986,
        "distinct-2-nopunct": 0.36683297695414585,
        "vocab_size-2-nopunct": 1544,
        "unique-2-nopunct": 969,
        "entropy-2-nopunct": 9.53613306313754,
        "cond_entropy-2-nopunct": 2.093569319925358,
        "distinct-3-nopunct": 0.5643030466433001,
        "vocab_size-3-nopunct": 2093,
        "unique-3-nopunct": 1601,
        "entropy-3-nopunct": 10.310156955215204,
        "cond_entropy-3-nopunct": 0.8708905335138898,
        "msttr-100": 0.64655,
        "msttr-100_nopunct": 0.69745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_challenge_test_scramble.json",
        "bleu": 16.576,
        "nist": 3.698960013130832,
        "rouge1": {
            "precision": 0.47319,
            "recall": 0.48334,
            "fmeasure": 0.46608
        },
        "rouge2": {
            "precision": 0.2674,
            "recall": 0.27155,
            "fmeasure": 0.26271
        },
        "rougeL": {
            "precision": 0.41857,
            "recall": 0.4275,
            "fmeasure": 0.41224
        },
        "rougeLsum": {
            "precision": 0.41857,
            "recall": 0.4275,
            "fmeasure": 0.41224
        },
        "local_recall": {
            "1": 0.449103191241556
        },
        "meteor": 0.22732510578008505,
        "nubia": {
            "semantic_relation": 3.10396,
            "contradiction": 24.89794,
            "irrelevancy": 30.34473,
            "logical_agreement": 44.75733,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.82047,
            "nubia_score": 0.4464
        },
        "bleurt": -0.22978,
        "bertscore": {
            "precision": 0.88871,
            "recall": 0.89607,
            "f1": 0.8921
        }
    },
    "web_nlg_ru_val": {
        "predictions_file": "mT5_xl/web_nlg_ru_val",
        "N": 790,
        "total_length": 15397,
        "mean_pred_length": 19.48987341772152,
        "std_pred_length": 9.62508714327421,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.08754952263427941,
        "vocab_size-1": 1348,
        "unique-1": 418,
        "entropy-1": 8.156205992349648,
        "distinct-2": 0.21722461833367562,
        "vocab_size-2": 3173,
        "unique-2": 1374,
        "entropy-2": 10.501731584051823,
        "cond_entropy-2": 2.1072483698416518,
        "distinct-3": 0.3222117681117464,
        "vocab_size-3": 4452,
        "unique-3": 2346,
        "entropy-3": 11.25719989085263,
        "cond_entropy-3": 0.7873690604779646,
        "total_length-nopunct": 12516,
        "mean_pred_length-nopunct": 15.843037974683543,
        "std_pred_length-nopunct": 8.222117186216357,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.10730265260466602,
        "vocab_size-1-nopunct": 1343,
        "unique-1-nopunct": 418,
        "entropy-1-nopunct": 8.762028748743106,
        "distinct-2-nopunct": 0.2488487122633464,
        "vocab_size-2-nopunct": 2918,
        "unique-2-nopunct": 1379,
        "entropy-2-nopunct": 10.48705358362587,
        "cond_entropy-2-nopunct": 1.7929932844796777,
        "distinct-3-nopunct": 0.35835771762984636,
        "vocab_size-3-nopunct": 3919,
        "unique-3-nopunct": 2191,
        "entropy-3-nopunct": 11.122160377493666,
        "cond_entropy-3-nopunct": 0.6637616007308009,
        "msttr-100": 0.45569,
        "msttr-100_nopunct": 0.50408,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_val.json",
        "bleu": 47.23924,
        "nist": 8.25049426329957,
        "rouge1": {
            "precision": 0.34633,
            "recall": 0.34206,
            "fmeasure": 0.34264
        },
        "rouge2": {
            "precision": 0.13834,
            "recall": 0.13809,
            "fmeasure": 0.13735
        },
        "rougeL": {
            "precision": 0.33228,
            "recall": 0.32775,
            "fmeasure": 0.32845
        },
        "rougeLsum": {
            "precision": 0.33228,
            "recall": 0.32775,
            "fmeasure": 0.32845
        },
        "local_recall": {
            "1": 0.25612589776087874,
            "2": 0.637747946303346,
            "3": 0.8631496474275268,
            "4": 0.8787878787878788,
            "5": 0.7692307692307693,
            "6": 1.0,
            "7": 1.0,
            "8": 0,
            "9": 1.0
        },
        "meteor": 0.6237413849749344,
        "nubia": {
            "semantic_relation": 3.98595,
            "contradiction": 20.57721,
            "irrelevancy": 21.35782,
            "logical_agreement": 58.06498,
            "grammar_ref": 2.60252,
            "grammar_hyp": 2.59293,
            "nubia_score": 0.8199
        },
        "bleurt": 0.18859,
        "bertscore": {
            "precision": 0.95365,
            "recall": 0.95249,
            "f1": 0.95226
        }
    },
    "web_nlg_ru_test": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 1102,
        "total_length": 22935,
        "mean_pred_length": 20.812159709618875,
        "std_pred_length": 11.29854386727654,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 73,
        "distinct-1": 0.1144538914323087,
        "vocab_size-1": 2625,
        "unique-1": 818,
        "entropy-1": 8.921667716977092,
        "distinct-2": 0.2986763156689415,
        "vocab_size-2": 6521,
        "unique-2": 3089,
        "entropy-2": 11.739698652449027,
        "cond_entropy-2": 2.559786531932668,
        "distinct-3": 0.4450822439824417,
        "vocab_size-3": 9227,
        "unique-3": 5405,
        "entropy-3": 12.598825916936669,
        "cond_entropy-3": 0.8807095980766831,
        "total_length-nopunct": 18867,
        "mean_pred_length-nopunct": 17.120689655172413,
        "std_pred_length-nopunct": 9.534965183411874,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.13870779668203742,
        "vocab_size-1-nopunct": 2617,
        "unique-1-nopunct": 817,
        "entropy-1-nopunct": 9.628801301421358,
        "distinct-2-nopunct": 0.33717984801576134,
        "vocab_size-2-nopunct": 5990,
        "unique-2-nopunct": 3061,
        "entropy-2-nopunct": 11.71775922539053,
        "cond_entropy-2-nopunct": 2.1657499644688567,
        "distinct-3-nopunct": 0.48472663986076936,
        "vocab_size-3-nopunct": 8077,
        "unique-3-nopunct": 5087,
        "entropy-3-nopunct": 12.433998513933455,
        "cond_entropy-3-nopunct": 0.761314960250119,
        "msttr-100": 0.7217,
        "msttr-100_nopunct": 0.8159,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 52.54859,
        "nist": 9.611812208356266,
        "rouge1": {
            "precision": 0.45138,
            "recall": 0.45157,
            "fmeasure": 0.44839
        },
        "rouge2": {
            "precision": 0.25676,
            "recall": 0.25788,
            "fmeasure": 0.25464
        },
        "rougeL": {
            "precision": 0.43305,
            "recall": 0.4337,
            "fmeasure": 0.43021
        },
        "rougeLsum": {
            "precision": 0.43305,
            "recall": 0.4337,
            "fmeasure": 0.43021
        },
        "local_recall": {
            "1": 0.2936978088644636,
            "2": 0.6665749277556076,
            "3": 0.8951296883746968,
            "4": 0.935064935064935,
            "5": 0.918918918918919,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "meteor": 0.6684995551426751,
        "nubia": {
            "semantic_relation": 4.02417,
            "contradiction": 18.86671,
            "irrelevancy": 22.02903,
            "logical_agreement": 59.10427,
            "grammar_ref": 2.65213,
            "grammar_hyp": 2.62478,
            "nubia_score": 0.83849
        },
        "bleurt": 0.20898,
        "bertscore": {
            "precision": 0.95805,
            "recall": 0.95599,
            "f1": 0.95639
        }
    },
    "web_nlg_ru_challenge_test_scramble": {
        "predictions_file": "mT5_xl/web_nlg_ru_challenge_test_scramble",
        "N": 500,
        "total_length": 10605,
        "mean_pred_length": 21.21,
        "std_pred_length": 12.248832597435563,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 73,
        "distinct-1": 0.21735030645921735,
        "vocab_size-1": 2305,
        "unique-1": 1156,
        "entropy-1": 8.972583949916425,
        "distinct-2": 0.5419099455714993,
        "vocab_size-2": 5476,
        "unique-2": 3840,
        "entropy-2": 11.818010106868153,
        "cond_entropy-2": 2.591720645947394,
        "distinct-3": 0.7486725663716814,
        "vocab_size-3": 7191,
        "unique-3": 5950,
        "entropy-3": 12.567625135920386,
        "cond_entropy-3": 0.7547839753491437,
        "total_length-nopunct": 8782,
        "mean_pred_length-nopunct": 17.564,
        "std_pred_length-nopunct": 10.306789218762553,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.26132999316784333,
        "vocab_size-1-nopunct": 2295,
        "unique-1-nopunct": 1156,
        "entropy-1-nopunct": 9.649555274456828,
        "distinct-2-nopunct": 0.5901956049263463,
        "vocab_size-2-nopunct": 4888,
        "unique-2-nopunct": 3600,
        "entropy-2-nopunct": 11.74917580215768,
        "cond_entropy-2-nopunct": 2.1676569987328893,
        "distinct-3-nopunct": 0.7765355949627345,
        "vocab_size-3-nopunct": 6043,
        "unique-3-nopunct": 5143,
        "entropy-3-nopunct": 12.340109730208534,
        "cond_entropy-3-nopunct": 0.6134315175136394,
        "msttr-100": 0.65085,
        "msttr-100_nopunct": 0.71655,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_challenge_test_scramble.json",
        "bleu": 41.70913,
        "nist": 8.07404206175996,
        "rouge1": {
            "precision": 0.42815,
            "recall": 0.43702,
            "fmeasure": 0.42862
        },
        "rouge2": {
            "precision": 0.2308,
            "recall": 0.239,
            "fmeasure": 0.2314
        },
        "rougeL": {
            "precision": 0.41016,
            "recall": 0.41825,
            "fmeasure": 0.40989
        },
        "rougeLsum": {
            "precision": 0.41016,
            "recall": 0.41825,
            "fmeasure": 0.40989
        },
        "local_recall": {
            "1": 0.27803129074315514,
            "2": 0.5984848484848485,
            "3": 0.8372781065088757,
            "4": 0.8444444444444444,
            "5": 0.8,
            "6": 1.0
        },
        "meteor": 0.5931491023833364,
        "nubia": {
            "semantic_relation": 3.90544,
            "contradiction": 21.8246,
            "irrelevancy": 23.87846,
            "logical_agreement": 54.29694,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.62763,
            "nubia_score": 0.80103
        },
        "bleurt": 0.13885,
        "bertscore": {
            "precision": 0.94739,
            "recall": 0.94712,
            "f1": 0.94638
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 494,
        "total_length": 11061,
        "mean_pred_length": 22.39068825910931,
        "std_pred_length": 9.606593253555333,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 68,
        "distinct-1": 0.16264352228550763,
        "vocab_size-1": 1799,
        "unique-1": 685,
        "entropy-1": 8.61358109368577,
        "distinct-2": 0.38326866660357717,
        "vocab_size-2": 4050,
        "unique-2": 2172,
        "entropy-2": 11.218838901778941,
        "cond_entropy-2": 2.3845435672002275,
        "distinct-3": 0.5397597537972798,
        "vocab_size-3": 5437,
        "unique-3": 3519,
        "entropy-3": 11.966383943734453,
        "cond_entropy-3": 0.7679600832963083,
        "total_length-nopunct": 9029,
        "mean_pred_length-nopunct": 18.277327935222672,
        "std_pred_length-nopunct": 7.873880110959922,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.19847159153837635,
        "vocab_size-1-nopunct": 1792,
        "unique-1-nopunct": 684,
        "entropy-1-nopunct": 9.285493028457365,
        "distinct-2-nopunct": 0.42718219097832455,
        "vocab_size-2-nopunct": 3646,
        "unique-2-nopunct": 2098,
        "entropy-2-nopunct": 11.142685820728396,
        "cond_entropy-2-nopunct": 1.928668893192016,
        "distinct-3-nopunct": 0.5813953488372093,
        "vocab_size-3-nopunct": 4675,
        "unique-3-nopunct": 3230,
        "entropy-3-nopunct": 11.774216168576505,
        "cond_entropy-3-nopunct": 0.6696242795737807,
        "msttr-100": 0.71355,
        "msttr-100_nopunct": 0.80411,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 50.05733,
        "nist": 9.049952039222973,
        "rouge1": {
            "precision": 0.40105,
            "recall": 0.40697,
            "fmeasure": 0.40067
        },
        "rouge2": {
            "precision": 0.23482,
            "recall": 0.23957,
            "fmeasure": 0.23397
        },
        "rougeL": {
            "precision": 0.37792,
            "recall": 0.38486,
            "fmeasure": 0.37789
        },
        "rougeLsum": {
            "precision": 0.37792,
            "recall": 0.38486,
            "fmeasure": 0.37789
        },
        "local_recall": {
            "1": 0.26870842572062087,
            "2": 0.6372950819672131,
            "3": 0.8913926856298485,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "meteor": 0.6467401063473774,
        "nubia": {
            "semantic_relation": 3.97033,
            "contradiction": 18.26316,
            "irrelevancy": 22.60312,
            "logical_agreement": 59.13373,
            "grammar_ref": 2.60025,
            "grammar_hyp": 2.56305,
            "nubia_score": 0.82983
        },
        "bleurt": 0.14258,
        "bertscore": {
            "precision": 0.95444,
            "recall": 0.9517,
            "f1": 0.95232
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 22,
        "total_length": 233,
        "mean_pred_length": 10.590909090909092,
        "std_pred_length": 1.2670327149787595,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 14,
        "distinct-1": 0.09871244635193133,
        "vocab_size-1": 23,
        "unique-1": 0,
        "entropy-1": 4.105641016154232,
        "distinct-2": 0.13270142180094788,
        "vocab_size-2": 28,
        "unique-2": 0,
        "entropy-2": 4.391471583992264,
        "cond_entropy-2": 0.2127523555962336,
        "distinct-3": 0.14285714285714285,
        "vocab_size-3": 27,
        "unique-3": 0,
        "entropy-3": 4.364126397846319,
        "cond_entropy-3": 0.04655743178307417,
        "total_length-nopunct": 187,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 1.0335288182638247,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.11229946524064172,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.9768708271968207,
        "distinct-2-nopunct": 0.13333333333333333,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.074445144732581,
        "cond_entropy-2-nopunct": 0.21427921089366486,
        "distinct-3-nopunct": 0.14685314685314685,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.0160452400469655,
        "cond_entropy-3-nopunct": 0.03346780870002589,
        "msttr-100": 0.21,
        "msttr-100_nopunct": 0.21,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 28.90671,
        "nist": 2.4121207261977435,
        "rouge1": {
            "precision": 0.49825,
            "recall": 0.49489,
            "fmeasure": 0.49254
        },
        "rouge2": {
            "precision": 0.34814,
            "recall": 0.33753,
            "fmeasure": 0.34028
        },
        "rougeL": {
            "precision": 0.48112,
            "recall": 0.47444,
            "fmeasure": 0.47394
        },
        "rougeLsum": {
            "precision": 0.48112,
            "recall": 0.47444,
            "fmeasure": 0.47394
        },
        "local_recall": {
            "1": 0.4228571428571429
        },
        "meteor": 0.2339889097754775,
        "nubia": {
            "semantic_relation": 2.87912,
            "contradiction": 24.94643,
            "irrelevancy": 26.0131,
            "logical_agreement": 49.04047,
            "grammar_ref": 6.09546,
            "grammar_hyp": 5.85525,
            "nubia_score": 0.39209
        },
        "bleurt": -0.05447,
        "bertscore": {
            "precision": 0.91549,
            "recall": 0.91341,
            "f1": 0.91438
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 460,
        "total_length": 11272,
        "mean_pred_length": 24.504347826086956,
        "std_pred_length": 9.435017027742962,
        "median_pred_length": 23.0,
        "min_pred_length": 7,
        "max_pred_length": 61,
        "distinct-1": 0.14646912704045423,
        "vocab_size-1": 1651,
        "unique-1": 525,
        "entropy-1": 8.519910083517201,
        "distinct-2": 0.34341472438031817,
        "vocab_size-2": 3713,
        "unique-2": 1759,
        "entropy-2": 11.064588411448405,
        "cond_entropy-2": 2.3462941429603044,
        "distinct-3": 0.4857998454404946,
        "vocab_size-3": 5029,
        "unique-3": 2922,
        "entropy-3": 11.848196933045433,
        "cond_entropy-3": 0.8055377613727276,
        "total_length-nopunct": 9233,
        "mean_pred_length-nopunct": 20.071739130434782,
        "std_pred_length-nopunct": 8.237062663550121,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 50,
        "distinct-1-nopunct": 0.17816527672479152,
        "vocab_size-1-nopunct": 1645,
        "unique-1-nopunct": 525,
        "entropy-1-nopunct": 9.179943208412318,
        "distinct-2-nopunct": 0.3907443291918386,
        "vocab_size-2-nopunct": 3428,
        "unique-2-nopunct": 1761,
        "entropy-2-nopunct": 11.084900866126437,
        "cond_entropy-2-nopunct": 1.9634725191193063,
        "distinct-3-nopunct": 0.5353061469986767,
        "vocab_size-3-nopunct": 4450,
        "unique-3-nopunct": 2824,
        "entropy-3-nopunct": 11.712616740100803,
        "cond_entropy-3-nopunct": 0.6505465243655816,
        "msttr-100": 0.60027,
        "msttr-100_nopunct": 0.6638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 49.37584,
        "nist": 8.946061341423977,
        "rouge1": {
            "precision": 0.3667,
            "recall": 0.36228,
            "fmeasure": 0.36216
        },
        "rouge2": {
            "precision": 0.16693,
            "recall": 0.1627,
            "fmeasure": 0.1632
        },
        "rougeL": {
            "precision": 0.35952,
            "recall": 0.35586,
            "fmeasure": 0.35526
        },
        "rougeLsum": {
            "precision": 0.35952,
            "recall": 0.35586,
            "fmeasure": 0.35526
        },
        "local_recall": {
            "1": 0.27983310152990265,
            "2": 0.6677787044759522,
            "3": 0.8964414234306277,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "meteor": 0.6449895793573397,
        "nubia": {
            "semantic_relation": 4.00881,
            "contradiction": 18.40439,
            "irrelevancy": 21.93064,
            "logical_agreement": 59.66497,
            "grammar_ref": 2.52111,
            "grammar_hyp": 2.49937,
            "nubia_score": 0.8408
        },
        "bleurt": 0.16254,
        "bertscore": {
            "precision": 0.95534,
            "recall": 0.95194,
            "f1": 0.95298
        }
    },
    "mlsum_de_val": {
        "predictions_file": "mT5_xl/mlsum_de_val",
        "N": 11392,
        "total_length": 330228,
        "mean_pred_length": 28.987710674157302,
        "std_pred_length": 11.55319538879056,
        "median_pred_length": 27.0,
        "min_pred_length": 5,
        "max_pred_length": 95,
        "distinct-1": 0.11495088242063059,
        "vocab_size-1": 37960,
        "unique-1": 22474,
        "entropy-1": 10.599303506991125,
        "distinct-2": 0.5251445884404522,
        "vocab_size-2": 167435,
        "unique-2": 134289,
        "entropy-2": 16.074697432330932,
        "cond_entropy-2": 5.2454516997043905,
        "distinct-3": 0.8436853540807432,
        "vocab_size-3": 259386,
        "unique-3": 237785,
        "entropy-3": 17.735276011409052,
        "cond_entropy-3": 1.638619998363113,
        "total_length-nopunct": 293276,
        "mean_pred_length-nopunct": 25.744030898876403,
        "std_pred_length-nopunct": 10.261655789314466,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.12937983333106015,
        "vocab_size-1-nopunct": 37944,
        "unique-1-nopunct": 22470,
        "entropy-1-nopunct": 11.162162890359612,
        "distinct-2-nopunct": 0.5858509173986463,
        "vocab_size-2-nopunct": 165142,
        "unique-2-nopunct": 135753,
        "entropy-2-nopunct": 16.347492953435218,
        "cond_entropy-2-nopunct": 5.276583750154618,
        "distinct-3-nopunct": 0.8802922082723333,
        "vocab_size-3-nopunct": 238112,
        "unique-3-nopunct": 222005,
        "entropy-3-nopunct": 17.688340558509843,
        "cond_entropy-3-nopunct": 1.3743627134515095,
        "msttr-100": 0.77442,
        "msttr-100_nopunct": 0.8265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_val.json",
        "bleu": 35.41436,
        "nist": 7.064071272505812,
        "rouge1": {
            "precision": 0.45508,
            "recall": 0.47782,
            "fmeasure": 0.45605
        },
        "rouge2": {
            "precision": 0.34304,
            "recall": 0.35454,
            "fmeasure": 0.34449
        },
        "rougeL": {
            "precision": 0.41591,
            "recall": 0.43377,
            "fmeasure": 0.41668
        },
        "rougeLsum": {
            "precision": 0.41591,
            "recall": 0.43377,
            "fmeasure": 0.41668
        },
        "local_recall": {
            "1": 0.48793546315620484
        },
        "meteor": 0.442077633171916,
        "nubia": {
            "semantic_relation": 2.83451,
            "contradiction": 21.91339,
            "irrelevancy": 42.32675,
            "logical_agreement": 35.75986,
            "grammar_ref": 5.04919,
            "grammar_hyp": 4.9388,
            "nubia_score": 0.41905
        },
        "bleurt": -0.2366,
        "bertscore": {
            "precision": 0.89082,
            "recall": 0.8969,
            "f1": 0.89366
        }
    },
    "mlsum_de_test": {
        "predictions_file": "mT5_xl/mlsum_de_test",
        "N": 10695,
        "total_length": 311504,
        "mean_pred_length": 29.12613370733988,
        "std_pred_length": 11.739413265074594,
        "median_pred_length": 27.0,
        "min_pred_length": 5,
        "max_pred_length": 95,
        "distinct-1": 0.11908675330011814,
        "vocab_size-1": 37096,
        "unique-1": 22065,
        "entropy-1": 10.600434436620494,
        "distinct-2": 0.5351103191726312,
        "vocab_size-2": 160966,
        "unique-2": 129717,
        "entropy-2": 16.051113650461172,
        "cond_entropy-2": 5.223492945217067,
        "distinct-3": 0.8512722584914896,
        "vocab_size-3": 246966,
        "unique-3": 227544,
        "entropy-3": 17.674817409172995,
        "cond_entropy-3": 1.6037960305376102,
        "total_length-nopunct": 276606,
        "mean_pred_length-nopunct": 25.863113604488078,
        "std_pred_length-nopunct": 10.40009169555798,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.1340571064980514,
        "vocab_size-1-nopunct": 37081,
        "unique-1-nopunct": 22063,
        "entropy-1-nopunct": 11.162335304014896,
        "distinct-2-nopunct": 0.5961543523961025,
        "vocab_size-2-nopunct": 158524,
        "unique-2-nopunct": 131071,
        "entropy-2-nopunct": 16.31782327901553,
        "cond_entropy-2-nopunct": 5.246031129177817,
        "distinct-3-nopunct": 0.8870642906400853,
        "vocab_size-3-nopunct": 226393,
        "unique-3-nopunct": 212070,
        "entropy-3-nopunct": 17.623126427762976,
        "cond_entropy-3-nopunct": 1.338333810480177,
        "msttr-100": 0.77514,
        "msttr-100_nopunct": 0.82612,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "bleu": 37.22915,
        "nist": 7.3339708449497465,
        "rouge1": {
            "precision": 0.47036,
            "recall": 0.49198,
            "fmeasure": 0.47086
        },
        "rouge2": {
            "precision": 0.36039,
            "recall": 0.37255,
            "fmeasure": 0.36199
        },
        "rougeL": {
            "precision": 0.43166,
            "recall": 0.44889,
            "fmeasure": 0.43218
        },
        "rougeLsum": {
            "precision": 0.43166,
            "recall": 0.44889,
            "fmeasure": 0.43218
        },
        "local_recall": {
            "1": 0.5026917358837407
        },
        "meteor": 0.45756839669701305,
        "nubia": {
            "semantic_relation": 2.88355,
            "contradiction": 21.85934,
            "irrelevancy": 41.12917,
            "logical_agreement": 37.01149,
            "grammar_ref": 5.03454,
            "grammar_hyp": 4.93621,
            "nubia_score": 0.43068
        },
        "bleurt": -0.21291,
        "bertscore": {
            "precision": 0.89365,
            "recall": 0.89928,
            "f1": 0.89627
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.03283,
        "nist": 2.95194765929552,
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.66369,
            "fmeasure": 0.70072
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.29402,
            "fmeasure": 0.3121
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 0.5625,
            "fmeasure": 0.62069
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 0.5625,
            "fmeasure": 0.62069
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.14285714285714285,
            "3": 0.8888888888888888
        },
        "meteor": 0.3286086117375328,
        "nubia": {
            "semantic_relation": 3.9672,
            "contradiction": 0.10482,
            "irrelevancy": 42.37033,
            "logical_agreement": 57.52485,
            "grammar_ref": 3.92881,
            "grammar_hyp": 4.53669,
            "nubia_score": 0.65459
        },
        "bleurt": 0.34258,
        "bertscore": {
            "precision": 0.91357,
            "recall": 0.88453,
            "f1": 0.89581
        }
    },
    "mlsum_de_challenge_test_covid": {
        "predictions_file": "mT5_xl/mlsum_de_challenge_test_covid",
        "N": 5058,
        "total_length": 153291,
        "mean_pred_length": 30.30664294187426,
        "std_pred_length": 8.414567251609617,
        "median_pred_length": 30.0,
        "min_pred_length": 6,
        "max_pred_length": 89,
        "distinct-1": 0.11917203227847688,
        "vocab_size-1": 18268,
        "unique-1": 11829,
        "entropy-1": 9.602540488434142,
        "distinct-2": 0.47316724346130756,
        "vocab_size-2": 70139,
        "unique-2": 59073,
        "entropy-2": 13.759227524847725,
        "cond_entropy-2": 4.0129610707924686,
        "distinct-3": 0.6879273616203946,
        "vocab_size-3": 98494,
        "unique-3": 93510,
        "entropy-3": 14.723485954054794,
        "cond_entropy-3": 0.9617457645348506,
        "total_length-nopunct": 134565,
        "mean_pred_length-nopunct": 26.604389086595493,
        "std_pred_length-nopunct": 7.360450544546739,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.1355998959610597,
        "vocab_size-1-nopunct": 18247,
        "unique-1-nopunct": 11825,
        "entropy-1-nopunct": 10.095336198550974,
        "distinct-2-nopunct": 0.5263190406696163,
        "vocab_size-2-nopunct": 68162,
        "unique-2-nopunct": 58799,
        "entropy-2-nopunct": 13.91020514066936,
        "cond_entropy-2-nopunct": 3.8968460191740126,
        "distinct-3-nopunct": 0.7137944057405041,
        "vocab_size-3-nopunct": 88831,
        "unique-3-nopunct": 85540,
        "entropy-3-nopunct": 14.641563888465688,
        "cond_entropy-3-nopunct": 0.7492103258795931,
        "msttr-100": 0.73883,
        "msttr-100_nopunct": 0.7864,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_challenge_test_covid.json",
        "bleu": 19.38604,
        "nist": 3.8423795064932036,
        "rouge1": {
            "precision": 0.27832,
            "recall": 0.37818,
            "fmeasure": 0.31208
        },
        "rouge2": {
            "precision": 0.19214,
            "recall": 0.25667,
            "fmeasure": 0.21462
        },
        "rougeL": {
            "precision": 0.25367,
            "recall": 0.34313,
            "fmeasure": 0.28419
        },
        "rougeLsum": {
            "precision": 0.25367,
            "recall": 0.34313,
            "fmeasure": 0.28419
        },
        "local_recall": {
            "1": 0.38473208592599106
        },
        "meteor": 0.3289100109573322,
        "nubia": {
            "semantic_relation": 1.9333,
            "contradiction": 25.69223,
            "irrelevancy": 57.50703,
            "logical_agreement": 16.80074,
            "grammar_ref": 5.17449,
            "grammar_hyp": 4.97049,
            "nubia_score": 0.24404
        },
        "bleurt": -0.53713,
        "bertscore": {
            "precision": 0.8586,
            "recall": 0.87748,
            "f1": 0.86772
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 16,
        "total_length": 293,
        "mean_pred_length": 18.3125,
        "std_pred_length": 4.2384954582964935,
        "median_pred_length": 18.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.2832764505119454,
        "vocab_size-1": 83,
        "unique-1": 37,
        "entropy-1": 5.592187601421012,
        "distinct-2": 0.48736462093862815,
        "vocab_size-2": 135,
        "unique-2": 83,
        "entropy-2": 6.595502785802557,
        "cond_entropy-2": 0.9225971628942484,
        "distinct-3": 0.5862068965517241,
        "vocab_size-3": 153,
        "unique-3": 103,
        "entropy-3": 6.894031210154994,
        "cond_entropy-3": 0.3212383941124131,
        "total_length-nopunct": 252,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 3.881043674065006,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.32142857142857145,
        "vocab_size-1-nopunct": 81,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.665945056892789,
        "distinct-2-nopunct": 0.5084745762711864,
        "vocab_size-2-nopunct": 120,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.461544977139174,
        "cond_entropy-2-nopunct": 0.840611170926649,
        "distinct-3-nopunct": 0.6136363636363636,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.7592323433400265,
        "cond_entropy-3-nopunct": 0.31887260964862607,
        "msttr-100": 0.47,
        "msttr-100_nopunct": 0.515,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 16.84911,
        "nist": 3.1717741610342505,
        "rouge1": {
            "precision": 0.55486,
            "recall": 0.55617,
            "fmeasure": 0.54727
        },
        "rouge2": {
            "precision": 0.31383,
            "recall": 0.32666,
            "fmeasure": 0.31436
        },
        "rougeL": {
            "precision": 0.4294,
            "recall": 0.44375,
            "fmeasure": 0.42944
        },
        "rougeLsum": {
            "precision": 0.4294,
            "recall": 0.44375,
            "fmeasure": 0.42944
        },
        "local_recall": {
            "1": 0.48582995951417
        },
        "meteor": 0.2401040258805828,
        "nubia": {
            "semantic_relation": 3.2888,
            "contradiction": 38.02792,
            "irrelevancy": 22.13877,
            "logical_agreement": 39.83331,
            "grammar_ref": 5.92126,
            "grammar_hyp": 6.07243,
            "nubia_score": 0.51399
        },
        "bleurt": -0.09045,
        "bertscore": {
            "precision": 0.91058,
            "recall": 0.91251,
            "f1": 0.91138
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 354,
        "total_length": 9669,
        "mean_pred_length": 27.3135593220339,
        "std_pred_length": 10.56566699123367,
        "median_pred_length": 26.0,
        "min_pred_length": 8,
        "max_pred_length": 73,
        "distinct-1": 0.15854793670493328,
        "vocab_size-1": 1533,
        "unique-1": 601,
        "entropy-1": 8.467794772293352,
        "distinct-2": 0.35276435856146,
        "vocab_size-2": 3286,
        "unique-2": 1737,
        "entropy-2": 10.861116846332298,
        "cond_entropy-2": 2.2205347376963522,
        "distinct-3": 0.48487891976341924,
        "vocab_size-3": 4345,
        "unique-3": 2722,
        "entropy-3": 11.547855984148164,
        "cond_entropy-3": 0.7006673784822619,
        "total_length-nopunct": 8064,
        "mean_pred_length-nopunct": 22.779661016949152,
        "std_pred_length-nopunct": 9.183750935267284,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.1892361111111111,
        "vocab_size-1-nopunct": 1526,
        "unique-1-nopunct": 601,
        "entropy-1-nopunct": 9.03415856476487,
        "distinct-2-nopunct": 0.39040207522697795,
        "vocab_size-2-nopunct": 3010,
        "unique-2-nopunct": 1685,
        "entropy-2-nopunct": 10.826519724599274,
        "cond_entropy-2-nopunct": 1.83871984808883,
        "distinct-3-nopunct": 0.5182164219684611,
        "vocab_size-3-nopunct": 3812,
        "unique-3-nopunct": 2524,
        "entropy-3-nopunct": 11.372301046322121,
        "cond_entropy-3-nopunct": 0.5658770445702357,
        "msttr-100": 0.71635,
        "msttr-100_nopunct": 0.789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 53.63675,
        "nist": 9.073001852116231,
        "rouge1": {
            "precision": 0.59972,
            "recall": 0.59601,
            "fmeasure": 0.59378
        },
        "rouge2": {
            "precision": 0.33684,
            "recall": 0.33474,
            "fmeasure": 0.33223
        },
        "rougeL": {
            "precision": 0.57542,
            "recall": 0.5716,
            "fmeasure": 0.56938
        },
        "rougeLsum": {
            "precision": 0.57542,
            "recall": 0.5716,
            "fmeasure": 0.56938
        },
        "local_recall": {
            "1": 0.30095810633101633,
            "2": 0.6856230031948882,
            "3": 0.9063162356930903,
            "4": 1.0,
            "5": 0.9545454545454546,
            "6": 1.0,
            "7": 1.0
        },
        "meteor": 0.6718955036828284,
        "nubia": {
            "semantic_relation": 3.96382,
            "contradiction": 18.55927,
            "irrelevancy": 22.83494,
            "logical_agreement": 58.60578,
            "grammar_ref": 2.54394,
            "grammar_hyp": 2.52292,
            "nubia_score": 0.84192
        },
        "bleurt": 0.17151,
        "bertscore": {
            "precision": 0.95612,
            "recall": 0.95362,
            "f1": 0.9543
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 106,
        "total_length": 2112,
        "mean_pred_length": 19.92452830188679,
        "std_pred_length": 4.590182536773142,
        "median_pred_length": 19.5,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.43892045454545453,
        "vocab_size-1": 927,
        "unique-1": 733,
        "entropy-1": 8.317120018412819,
        "distinct-2": 0.8584247258225324,
        "vocab_size-2": 1722,
        "unique-2": 1599,
        "entropy-2": 10.552858150654881,
        "cond_entropy-2": 2.025468927532917,
        "distinct-3": 0.9731578947368421,
        "vocab_size-3": 1849,
        "unique-3": 1815,
        "entropy-3": 10.825717499305128,
        "cond_entropy-3": 0.27113223571879663,
        "total_length-nopunct": 1963,
        "mean_pred_length-nopunct": 18.5188679245283,
        "std_pred_length-nopunct": 4.497863501363252,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.4696892511462048,
        "vocab_size-1-nopunct": 922,
        "unique-1-nopunct": 733,
        "entropy-1-nopunct": 8.469107545349157,
        "distinct-2-nopunct": 0.8669897684437264,
        "vocab_size-2-nopunct": 1610,
        "unique-2-nopunct": 1497,
        "entropy-2-nopunct": 10.47043895564828,
        "cond_entropy-2-nopunct": 2.088181258586854,
        "distinct-3-nopunct": 0.9800114220445459,
        "vocab_size-3-nopunct": 1716,
        "unique-3-nopunct": 1687,
        "entropy-3-nopunct": 10.730631385006804,
        "cond_entropy-3-nopunct": 0.261653486782408,
        "msttr-100": 0.74143,
        "msttr-100_nopunct": 0.76737,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 12.91978,
        "nist": 3.924652484608203,
        "rouge1": {
            "precision": 0.51181,
            "recall": 0.42996,
            "fmeasure": 0.45826
        },
        "rouge2": {
            "precision": 0.2328,
            "recall": 0.19343,
            "fmeasure": 0.207
        },
        "rougeL": {
            "precision": 0.40497,
            "recall": 0.33906,
            "fmeasure": 0.36188
        },
        "rougeLsum": {
            "precision": 0.40497,
            "recall": 0.33906,
            "fmeasure": 0.36188
        },
        "local_recall": {
            "1": 0.40875576036866357
        },
        "meteor": 0.20666073942899896,
        "nubia": {
            "semantic_relation": 3.20078,
            "contradiction": 15.8224,
            "irrelevancy": 59.30699,
            "logical_agreement": 24.87061,
            "grammar_ref": 3.66018,
            "grammar_hyp": 3.66339,
            "nubia_score": 0.48679
        },
        "bleurt": -0.21283,
        "bertscore": {
            "precision": 0.86107,
            "recall": 0.83903,
            "f1": 0.84953
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 1075,
        "total_length": 22517,
        "mean_pred_length": 20.946046511627905,
        "std_pred_length": 11.309879225299442,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 73,
        "distinct-1": 0.11480214948705422,
        "vocab_size-1": 2585,
        "unique-1": 795,
        "entropy-1": 8.91598885230589,
        "distinct-2": 0.2994123682492305,
        "vocab_size-2": 6420,
        "unique-2": 3022,
        "entropy-2": 11.729437988231417,
        "cond_entropy-2": 2.5574950570678827,
        "distinct-3": 0.44537732606667646,
        "vocab_size-3": 9071,
        "unique-3": 5284,
        "entropy-3": 12.58067825679634,
        "cond_entropy-3": 0.8750725971370915,
        "total_length-nopunct": 18527,
        "mean_pred_length-nopunct": 17.234418604651164,
        "std_pred_length-nopunct": 9.547381304748361,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.13909429481297567,
        "vocab_size-1-nopunct": 2577,
        "unique-1-nopunct": 794,
        "entropy-1-nopunct": 9.622698132939842,
        "distinct-2-nopunct": 0.337554435021774,
        "vocab_size-2-nopunct": 5891,
        "unique-2-nopunct": 2990,
        "entropy-2-nopunct": 11.704985495629298,
        "cond_entropy-2-nopunct": 2.1605854001191176,
        "distinct-3-nopunct": 0.4851315869817427,
        "vocab_size-3-nopunct": 7945,
        "unique-3-nopunct": 4986,
        "entropy-3-nopunct": 12.416630143169538,
        "cond_entropy-3-nopunct": 0.7552786429477291,
        "msttr-100": 0.72511,
        "msttr-100_nopunct": 0.81324,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 52.64755,
        "nist": 9.617659718739965,
        "rouge1": {
            "precision": 0.45448,
            "recall": 0.45458,
            "fmeasure": 0.45144
        },
        "rouge2": {
            "precision": 0.25803,
            "recall": 0.25918,
            "fmeasure": 0.25591
        },
        "rougeL": {
            "precision": 0.4366,
            "recall": 0.43698,
            "fmeasure": 0.43362
        },
        "rougeLsum": {
            "precision": 0.4366,
            "recall": 0.43698,
            "fmeasure": 0.43362
        },
        "local_recall": {
            "1": 0.2934270599318791,
            "2": 0.6688593421973408,
            "3": 0.897440794499618,
            "4": 0.935064935064935,
            "5": 0.918918918918919,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "meteor": 0.6688715812059015,
        "nubia": {
            "semantic_relation": 4.02668,
            "contradiction": 18.66026,
            "irrelevancy": 22.114,
            "logical_agreement": 59.22575,
            "grammar_ref": 2.64396,
            "grammar_hyp": 2.61637,
            "nubia_score": 0.8402
        },
        "bleurt": 0.20902,
        "bertscore": {
            "precision": 0.9581,
            "recall": 0.95616,
            "f1": 0.9565
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 4,
        "total_length": 33,
        "mean_pred_length": 8.25,
        "std_pred_length": 1.7853571071357126,
        "median_pred_length": 8.0,
        "min_pred_length": 6,
        "max_pred_length": 11,
        "distinct-1": 0.8787878787878788,
        "vocab_size-1": 29,
        "unique-1": 27,
        "entropy-1": 4.741363816328152,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": -0.11744760698950202,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.21412480535284767,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 6.75,
        "std_pred_length-nopunct": 1.920286436967152,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.754887502163471,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.23132554610645592,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.27563444261342734,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 48.46525,
        "nist": 3.450593755251722,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.15384615384615385,
            "3": 1.0
        },
        "meteor": 0.6934430904061327,
        "nubia": {
            "semantic_relation": 3.90492,
            "contradiction": 45.76113,
            "irrelevancy": 15.88723,
            "logical_agreement": 38.35164,
            "grammar_ref": 3.0388,
            "grammar_hyp": 3.03105,
            "nubia_score": 0.71806
        },
        "bleurt": 0.40305,
        "bertscore": {
            "precision": 0.95631,
            "recall": 0.96425,
            "f1": 0.95933
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 19,
        "total_length": 309,
        "mean_pred_length": 16.263157894736842,
        "std_pred_length": 9.98863620248508,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 41,
        "distinct-1": 0.4174757281553398,
        "vocab_size-1": 129,
        "unique-1": 81,
        "entropy-1": 6.2255907300442725,
        "distinct-2": 0.7,
        "vocab_size-2": 203,
        "unique-2": 161,
        "entropy-2": 7.341046608249244,
        "cond_entropy-2": 0.9379686751643961,
        "distinct-3": 0.8265682656826568,
        "vocab_size-3": 224,
        "unique-3": 193,
        "entropy-3": 7.678517757275416,
        "cond_entropy-3": 0.26425951211121457,
        "total_length-nopunct": 253,
        "mean_pred_length-nopunct": 13.31578947368421,
        "std_pred_length-nopunct": 8.435842275851718,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.4901185770750988,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.322191452141247,
        "distinct-2-nopunct": 0.7521367521367521,
        "vocab_size-2-nopunct": 176,
        "unique-2-nopunct": 145,
        "entropy-2-nopunct": 7.1905467434311525,
        "cond_entropy-2-nopunct": 0.8051592832741344,
        "distinct-3-nopunct": 0.8511627906976744,
        "vocab_size-3-nopunct": 183,
        "unique-3-nopunct": 161,
        "entropy-3-nopunct": 7.402311324116879,
        "cond_entropy-3-nopunct": 0.23928337857825852,
        "msttr-100": 0.58,
        "msttr-100_nopunct": 0.67,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 52.14796,
        "nist": 6.458115466430717,
        "rouge1": {
            "precision": 0.33431,
            "recall": 0.3561,
            "fmeasure": 0.34257
        },
        "rouge2": {
            "precision": 0.24298,
            "recall": 0.25526,
            "fmeasure": 0.24714
        },
        "rougeL": {
            "precision": 0.29616,
            "recall": 0.32623,
            "fmeasure": 0.3079
        },
        "rougeLsum": {
            "precision": 0.29616,
            "recall": 0.32623,
            "fmeasure": 0.3079
        },
        "local_recall": {
            "1": 0.2883435582822086,
            "2": 0.5729166666666666,
            "3": 0.8260869565217391
        },
        "meteor": 0.6842358815843543,
        "nubia": {
            "semantic_relation": 3.9907,
            "contradiction": 23.19586,
            "irrelevancy": 18.22916,
            "logical_agreement": 58.57498,
            "grammar_ref": 2.97301,
            "grammar_hyp": 2.96926,
            "nubia_score": 0.79744
        },
        "bleurt": 0.20094,
        "bertscore": {
            "precision": 0.96036,
            "recall": 0.9482,
            "f1": 0.95386
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 106,
        "total_length": 2142,
        "mean_pred_length": 20.20754716981132,
        "std_pred_length": 4.3734123397020355,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 38,
        "distinct-1": 0.4169000933706816,
        "vocab_size-1": 893,
        "unique-1": 673,
        "entropy-1": 8.261757170316184,
        "distinct-2": 0.8379174852652259,
        "vocab_size-2": 1706,
        "unique-2": 1543,
        "entropy-2": 10.530339227806826,
        "cond_entropy-2": 2.0642386905097334,
        "distinct-3": 0.9523316062176166,
        "vocab_size-3": 1838,
        "unique-3": 1768,
        "entropy-3": 10.805113705736217,
        "cond_entropy-3": 0.2692312388673554,
        "total_length-nopunct": 1979,
        "mean_pred_length-nopunct": 18.669811320754718,
        "std_pred_length-nopunct": 4.201800373589217,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.4477008590197069,
        "vocab_size-1-nopunct": 886,
        "unique-1-nopunct": 672,
        "entropy-1-nopunct": 8.400804279412858,
        "distinct-2-nopunct": 0.8510411105178858,
        "vocab_size-2-nopunct": 1594,
        "unique-2-nopunct": 1450,
        "entropy-2-nopunct": 10.450321707258066,
        "cond_entropy-2-nopunct": 2.128188143660278,
        "distinct-3-nopunct": 0.9620826259196378,
        "vocab_size-3-nopunct": 1700,
        "unique-3-nopunct": 1643,
        "entropy-3-nopunct": 10.705663402661115,
        "cond_entropy-3-nopunct": 0.2529992385837101,
        "msttr-100": 0.73238,
        "msttr-100_nopunct": 0.75947,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 12.80554,
        "nist": 3.73890608870511,
        "rouge1": {
            "precision": 0.46751,
            "recall": 0.40476,
            "fmeasure": 0.42672
        },
        "rouge2": {
            "precision": 0.20251,
            "recall": 0.17799,
            "fmeasure": 0.18595
        },
        "rougeL": {
            "precision": 0.37431,
            "recall": 0.32809,
            "fmeasure": 0.34384
        },
        "rougeLsum": {
            "precision": 0.37431,
            "recall": 0.32809,
            "fmeasure": 0.34384
        },
        "local_recall": {
            "1": 0.3892271662763466
        },
        "meteor": 0.19409802112881105,
        "nubia": {
            "semantic_relation": 3.07755,
            "contradiction": 16.73384,
            "irrelevancy": 61.19116,
            "logical_agreement": 22.075,
            "grammar_ref": 3.68583,
            "grammar_hyp": 3.54858,
            "nubia_score": 0.47319
        },
        "bleurt": -0.26029,
        "bertscore": {
            "precision": 0.84823,
            "recall": 0.82999,
            "f1": 0.83868
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 34,
        "total_length": 361,
        "mean_pred_length": 10.617647058823529,
        "std_pred_length": 2.9705882352941173,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 17,
        "distinct-1": 0.2631578947368421,
        "vocab_size-1": 95,
        "unique-1": 37,
        "entropy-1": 5.723911714832916,
        "distinct-2": 0.4801223241590214,
        "vocab_size-2": 157,
        "unique-2": 80,
        "entropy-2": 6.91419917636524,
        "cond_entropy-2": 0.9495300792917767,
        "distinct-3": 0.6177474402730375,
        "vocab_size-3": 181,
        "unique-3": 109,
        "entropy-3": 7.272513968681551,
        "cond_entropy-3": 0.2996748733219967,
        "total_length-nopunct": 314,
        "mean_pred_length-nopunct": 9.235294117647058,
        "std_pred_length-nopunct": 2.578860025503879,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.2961783439490446,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.8118434154099745,
        "distinct-2-nopunct": 0.5,
        "vocab_size-2-nopunct": 140,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.787493342025699,
        "cond_entropy-2-nopunct": 0.9451675654052042,
        "distinct-3-nopunct": 0.6260162601626016,
        "vocab_size-3-nopunct": 154,
        "unique-3-nopunct": 97,
        "entropy-3-nopunct": 7.024008395519974,
        "cond_entropy-3-nopunct": 0.24830439154479667,
        "msttr-100": 0.51667,
        "msttr-100_nopunct": 0.54333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 17.00256,
        "nist": 3.025793784943875,
        "rouge1": {
            "precision": 0.5413,
            "recall": 0.50801,
            "fmeasure": 0.50995
        },
        "rouge2": {
            "precision": 0.33439,
            "recall": 0.32339,
            "fmeasure": 0.31879
        },
        "rougeL": {
            "precision": 0.46513,
            "recall": 0.43704,
            "fmeasure": 0.43798
        },
        "rougeLsum": {
            "precision": 0.46513,
            "recall": 0.43704,
            "fmeasure": 0.43798
        },
        "local_recall": {
            "1": 0.41492537313432837
        },
        "meteor": 0.22295932719727402,
        "nubia": {
            "semantic_relation": 3.31827,
            "contradiction": 23.09736,
            "irrelevancy": 20.95814,
            "logical_agreement": 55.9445,
            "grammar_ref": 6.46033,
            "grammar_hyp": 6.48428,
            "nubia_score": 0.45703
        },
        "bleurt": -0.16066,
        "bertscore": {
            "precision": 0.92035,
            "recall": 0.91335,
            "f1": 0.91661
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 4,
        "total_length": 76,
        "mean_pred_length": 19.0,
        "std_pred_length": 7.176350047203662,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 31,
        "distinct-1": 0.6052631578947368,
        "vocab_size-1": 46,
        "unique-1": 27,
        "entropy-1": 5.27403261303565,
        "distinct-2": 0.8055555555555556,
        "vocab_size-2": 58,
        "unique-2": 44,
        "entropy-2": 5.781036112553422,
        "cond_entropy-2": 0.43211276649114433,
        "distinct-3": 0.8676470588235294,
        "vocab_size-3": 59,
        "unique-3": 50,
        "entropy-3": 5.822756958897399,
        "cond_entropy-3": 0.005773133925674086,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.898979485566356,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7166666666666667,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 5.32764247057246,
        "distinct-2-nopunct": 0.8392857142857143,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.485926350629038,
        "cond_entropy-2-nopunct": 0.10733865681910622,
        "distinct-3-nopunct": 0.8846153846153846,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.469670487371863,
        "cond_entropy-3-nopunct": -0.029992126993435272,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 25.42742,
        "nist": 3.497450872262018,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.54545,
            "fmeasure": 0.58041
        },
        "rouge2": {
            "precision": 0.2381,
            "recall": 0.1787,
            "fmeasure": 0.20413
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.49697,
            "fmeasure": 0.52583
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.49697,
            "fmeasure": 0.52583
        },
        "local_recall": {
            "1": 0.2647058823529412,
            "2": 0.6153846153846154,
            "3": 0.6538461538461539
        },
        "meteor": 0.46915524662666946,
        "nubia": {
            "semantic_relation": 3.62752,
            "contradiction": 26.89263,
            "irrelevancy": 23.38396,
            "logical_agreement": 49.72341,
            "grammar_ref": 2.93748,
            "grammar_hyp": 2.84278,
            "nubia_score": 0.69384
        },
        "bleurt": 0.04313,
        "bertscore": {
            "precision": 0.9353,
            "recall": 0.94011,
            "f1": 0.93685
        }
    },
    "schema_guided_dialog_test": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 10000,
        "total_length": 125821,
        "mean_pred_length": 12.5821,
        "std_pred_length": 7.193834831993295,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 54,
        "distinct-1": 0.033269486015847914,
        "vocab_size-1": 4186,
        "unique-1": 1795,
        "entropy-1": 8.045117811627277,
        "distinct-2": 0.1386967821034182,
        "vocab_size-2": 16064,
        "unique-2": 8627,
        "entropy-2": 11.469866661792462,
        "cond_entropy-2": 3.1497453574146093,
        "distinct-3": 0.2785473994557,
        "vocab_size-3": 29477,
        "unique-3": 18804,
        "entropy-3": 12.997161127618087,
        "cond_entropy-3": 1.5456212203725104,
        "total_length-nopunct": 110301,
        "mean_pred_length-nopunct": 11.0301,
        "std_pred_length-nopunct": 6.571437741468757,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.03780564092800609,
        "vocab_size-1-nopunct": 4170,
        "unique-1-nopunct": 1793,
        "entropy-1-nopunct": 8.279308629796336,
        "distinct-2-nopunct": 0.15268043189998107,
        "vocab_size-2-nopunct": 15314,
        "unique-2-nopunct": 8558,
        "entropy-2-nopunct": 11.374410870303423,
        "cond_entropy-2-nopunct": 3.238818698679983,
        "distinct-3-nopunct": 0.30249374349434144,
        "vocab_size-3-nopunct": 27317,
        "unique-3-nopunct": 17972,
        "entropy-3-nopunct": 12.897131772428944,
        "cond_entropy-3-nopunct": 1.571594502508814,
        "msttr-100": 0.68401,
        "msttr-100_nopunct": 0.71403,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 33.01155,
        "nist": 7.1028939133592015,
        "rouge1": {
            "precision": 0.59401,
            "recall": 0.56137,
            "fmeasure": 0.56562
        },
        "rouge2": {
            "precision": 0.37539,
            "recall": 0.35492,
            "fmeasure": 0.35702
        },
        "rougeL": {
            "precision": 0.53585,
            "recall": 0.50586,
            "fmeasure": 0.51005
        },
        "rougeLsum": {
            "precision": 0.53585,
            "recall": 0.50586,
            "fmeasure": 0.51005
        },
        "local_recall": {
            "1": 0.572342637766936
        },
        "meteor": 0.3225056271767188,
        "nubia": {
            "semantic_relation": 3.70258,
            "contradiction": 5.78114,
            "irrelevancy": 19.81471,
            "logical_agreement": 74.40414,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.54253,
            "nubia_score": 0.67149
        },
        "bleurt": -0.03914,
        "bertscore": {
            "precision": 0.87822,
            "recall": 0.86897,
            "f1": 0.87309
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 269,
        "total_length": 8304,
        "mean_pred_length": 30.869888475836433,
        "std_pred_length": 10.841275610595176,
        "median_pred_length": 30.0,
        "min_pred_length": 10,
        "max_pred_length": 106,
        "distinct-1": 0.10127649325626205,
        "vocab_size-1": 841,
        "unique-1": 289,
        "entropy-1": 7.567988753549506,
        "distinct-2": 0.304542626011201,
        "vocab_size-2": 2447,
        "unique-2": 1265,
        "entropy-2": 10.319093309724504,
        "cond_entropy-2": 2.636360102970303,
        "distinct-3": 0.4867370589750193,
        "vocab_size-3": 3780,
        "unique-3": 2417,
        "entropy-3": 11.313896482045923,
        "cond_entropy-3": 1.0252574545933373,
        "total_length-nopunct": 7229,
        "mean_pred_length-nopunct": 26.87360594795539,
        "std_pred_length-nopunct": 9.709479253229112,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 95,
        "distinct-1-nopunct": 0.11509199059344308,
        "vocab_size-1-nopunct": 832,
        "unique-1-nopunct": 288,
        "entropy-1-nopunct": 7.813457843434217,
        "distinct-2-nopunct": 0.3331896551724138,
        "vocab_size-2-nopunct": 2319,
        "unique-2-nopunct": 1276,
        "entropy-2-nopunct": 10.269388113251312,
        "cond_entropy-2-nopunct": 2.5390275810680256,
        "distinct-3-nopunct": 0.5130772679719026,
        "vocab_size-3-nopunct": 3433,
        "unique-3-nopunct": 2287,
        "entropy-3-nopunct": 11.195197371302516,
        "cond_entropy-3-nopunct": 0.9453607871152382,
        "msttr-100": 0.54428,
        "msttr-100_nopunct": 0.56486,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 36.11267,
        "nist": 7.364164171094551,
        "rouge1": {
            "precision": 0.70374,
            "recall": 0.68126,
            "fmeasure": 0.68319
        },
        "rouge2": {
            "precision": 0.40281,
            "recall": 0.3865,
            "fmeasure": 0.38865
        },
        "rougeL": {
            "precision": 0.50173,
            "recall": 0.48773,
            "fmeasure": 0.48746
        },
        "rougeLsum": {
            "precision": 0.50173,
            "recall": 0.48773,
            "fmeasure": 0.48746
        },
        "local_recall": {
            "1": 0.1886289606159313,
            "2": 0.4832325453545904,
            "3": 0.8356708123842286,
            "4": 0.5,
            "5": 1.0
        },
        "meteor": 0.3404539151303993,
        "nubia": {
            "semantic_relation": 4.08455,
            "contradiction": 11.36957,
            "irrelevancy": 10.91416,
            "logical_agreement": 77.71628,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.36731,
            "nubia_score": 0.67783
        },
        "bleurt": -0.0097,
        "bertscore": {
            "precision": 0.8939,
            "recall": 0.89147,
            "f1": 0.891
        }
    },
    "web_nlg_ru_challenge_test_scramble_parent": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 500,
        "total_length": 10344,
        "mean_pred_length": 20.688,
        "std_pred_length": 11.916318894692271,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 73,
        "distinct-1": 0.18919180201082753,
        "vocab_size-1": 1957,
        "unique-1": 843,
        "entropy-1": 8.773678079976955,
        "distinct-2": 0.43508736286062577,
        "vocab_size-2": 4283,
        "unique-2": 2540,
        "entropy-2": 11.368981195590877,
        "cond_entropy-2": 2.3438886418580305,
        "distinct-3": 0.593214897260274,
        "vocab_size-3": 5543,
        "unique-3": 3863,
        "entropy-3": 12.059149307693836,
        "cond_entropy-3": 0.7044077590225173,
        "total_length-nopunct": 8517,
        "mean_pred_length-nopunct": 17.034,
        "std_pred_length-nopunct": 9.924759140654247,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.22883644475754375,
        "vocab_size-1-nopunct": 1949,
        "unique-1-nopunct": 842,
        "entropy-1-nopunct": 9.450312005321843,
        "distinct-2-nopunct": 0.4776100785830111,
        "vocab_size-2-nopunct": 3829,
        "unique-2-nopunct": 2389,
        "entropy-2-nopunct": 11.301849095292791,
        "cond_entropy-2-nopunct": 1.9210269439877152,
        "distinct-3-nopunct": 0.6269788479446587,
        "vocab_size-3-nopunct": 4713,
        "unique-3-nopunct": 3425,
        "entropy-3-nopunct": 11.85386468444659,
        "cond_entropy-3-nopunct": 0.587950043730112,
        "msttr-100": 0.62951,
        "msttr-100_nopunct": 0.69341,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 52.70356,
        "nist": 9.261992517837944,
        "rouge1": {
            "precision": 0.44705,
            "recall": 0.44905,
            "fmeasure": 0.44529
        },
        "rouge2": {
            "precision": 0.24928,
            "recall": 0.2522,
            "fmeasure": 0.24807
        },
        "rougeL": {
            "precision": 0.42957,
            "recall": 0.43237,
            "fmeasure": 0.4282
        },
        "rougeLsum": {
            "precision": 0.42957,
            "recall": 0.43237,
            "fmeasure": 0.4282
        },
        "local_recall": {
            "1": 0.30003259452411996,
            "2": 0.6724242424242424,
            "3": 0.8825021132713441,
            "4": 0.9333333333333333,
            "5": 0.8,
            "6": 1.0
        },
        "meteor": 0.6693295246964258,
        "nubia": {
            "semantic_relation": 4.02314,
            "contradiction": 19.0484,
            "irrelevancy": 22.0713,
            "logical_agreement": 58.8803,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.63414,
            "nubia_score": 0.83887
        },
        "bleurt": 0.22471,
        "bertscore": {
            "precision": 0.95881,
            "recall": 0.95645,
            "f1": 0.95703
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation": {
        "predictions_file": "mT5_xl/schema_guided_dialog_challenge_test_backtranslation",
        "N": 500,
        "total_length": 6239,
        "mean_pred_length": 12.478,
        "std_pred_length": 6.773884852874309,
        "median_pred_length": 11.0,
        "min_pred_length": 3,
        "max_pred_length": 37,
        "distinct-1": 0.17166212534059946,
        "vocab_size-1": 1071,
        "unique-1": 596,
        "entropy-1": 7.952556878152115,
        "distinct-2": 0.5438229656734622,
        "vocab_size-2": 3121,
        "unique-2": 2258,
        "entropy-2": 10.948188624715032,
        "cond_entropy-2": 2.717597672233978,
        "distinct-3": 0.7759114334796717,
        "vocab_size-3": 4065,
        "unique-3": 3488,
        "entropy-3": 11.717903878120506,
        "cond_entropy-3": 0.7709134852375948,
        "total_length-nopunct": 5422,
        "mean_pred_length-nopunct": 10.844,
        "std_pred_length-nopunct": 6.142284916869292,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.19531538177794172,
        "vocab_size-1-nopunct": 1059,
        "unique-1-nopunct": 593,
        "entropy-1-nopunct": 8.190348106519401,
        "distinct-2-nopunct": 0.5676554246241365,
        "vocab_size-2-nopunct": 2794,
        "unique-2-nopunct": 2099,
        "entropy-2-nopunct": 10.780411430984921,
        "cond_entropy-2-nopunct": 2.713042941310708,
        "distinct-3-nopunct": 0.7892356399819086,
        "vocab_size-3-nopunct": 3490,
        "unique-3-nopunct": 3044,
        "entropy-3-nopunct": 11.498212582777244,
        "cond_entropy-3-nopunct": 0.7415485824933108,
        "msttr-100": 0.70274,
        "msttr-100_nopunct": 0.73704,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_backtranslation.json",
        "bleu": 27.38136,
        "nist": 5.507214021092425,
        "rouge1": {
            "precision": 0.51968,
            "recall": 0.50342,
            "fmeasure": 0.49967
        },
        "rouge2": {
            "precision": 0.29669,
            "recall": 0.28663,
            "fmeasure": 0.2842
        },
        "rougeL": {
            "precision": 0.45791,
            "recall": 0.44396,
            "fmeasure": 0.44043
        },
        "rougeLsum": {
            "precision": 0.45791,
            "recall": 0.44396,
            "fmeasure": 0.44043
        },
        "local_recall": {
            "1": 0.5207715133531158
        },
        "meteor": 0.2941550705318972,
        "nubia": {
            "semantic_relation": 3.48453,
            "contradiction": 6.78331,
            "irrelevancy": 25.0886,
            "logical_agreement": 68.1281,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.71501,
            "nubia_score": 0.60183
        },
        "bleurt": -0.17897,
        "bertscore": {
            "precision": 0.85517,
            "recall": 0.85192,
            "f1": 0.85302
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.37792,
        "nist": 1.5855899986607631,
        "rouge1": {
            "precision": 0.40344,
            "recall": 0.66777,
            "fmeasure": 0.4925
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.39744,
            "fmeasure": 0.27682
        },
        "rougeL": {
            "precision": 0.39749,
            "recall": 0.68443,
            "fmeasure": 0.48985
        },
        "rougeLsum": {
            "precision": 0.39749,
            "recall": 0.68443,
            "fmeasure": 0.48985
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "meteor": 0.3040703381787995,
        "nubia": {
            "semantic_relation": 3.63557,
            "contradiction": 0.3468,
            "irrelevancy": 68.32812,
            "logical_agreement": 31.32508,
            "grammar_ref": 5.41182,
            "grammar_hyp": 4.28791,
            "nubia_score": 0.46014
        },
        "bleurt": -0.03107,
        "bertscore": {
            "precision": 0.80752,
            "recall": 0.91969,
            "f1": 0.84535
        }
    },
    "schema_guided_dialog_challenge_test_bfp02": {
        "predictions_file": "mT5_xl/schema_guided_dialog_challenge_test_bfp02",
        "N": 500,
        "total_length": 6481,
        "mean_pred_length": 12.962,
        "std_pred_length": 7.670759805912319,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 44,
        "distinct-1": 0.16525227588335134,
        "vocab_size-1": 1071,
        "unique-1": 595,
        "entropy-1": 7.970566838087739,
        "distinct-2": 0.5336900183915733,
        "vocab_size-2": 3192,
        "unique-2": 2303,
        "entropy-2": 10.971473113006072,
        "cond_entropy-2": 2.7621965104716573,
        "distinct-3": 0.7677431125706988,
        "vocab_size-3": 4208,
        "unique-3": 3585,
        "entropy-3": 11.769093260773197,
        "cond_entropy-3": 0.8148506411841969,
        "total_length-nopunct": 5695,
        "mean_pred_length-nopunct": 11.39,
        "std_pred_length-nopunct": 7.0106989665795805,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.18560140474100087,
        "vocab_size-1-nopunct": 1057,
        "unique-1-nopunct": 590,
        "entropy-1-nopunct": 8.17282049170329,
        "distinct-2-nopunct": 0.5487969201154956,
        "vocab_size-2-nopunct": 2851,
        "unique-2-nopunct": 2094,
        "entropy-2-nopunct": 10.807532412124148,
        "cond_entropy-2-nopunct": 2.760581233382522,
        "distinct-3-nopunct": 0.778747870528109,
        "vocab_size-3-nopunct": 3657,
        "unique-3-nopunct": 3161,
        "entropy-3-nopunct": 11.56429534389162,
        "cond_entropy-3-nopunct": 0.7923252104299927,
        "msttr-100": 0.70188,
        "msttr-100_nopunct": 0.73286,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp02.json",
        "bleu": 27.82842,
        "nist": 5.657674567893702,
        "rouge1": {
            "precision": 0.52433,
            "recall": 0.49685,
            "fmeasure": 0.49648
        },
        "rouge2": {
            "precision": 0.30233,
            "recall": 0.28385,
            "fmeasure": 0.28449
        },
        "rougeL": {
            "precision": 0.45594,
            "recall": 0.4317,
            "fmeasure": 0.43152
        },
        "rougeLsum": {
            "precision": 0.45594,
            "recall": 0.4317,
            "fmeasure": 0.43152
        },
        "local_recall": {
            "1": 0.5194352449015165
        },
        "meteor": 0.29464845260151556,
        "nubia": {
            "semantic_relation": 3.46369,
            "contradiction": 6.11481,
            "irrelevancy": 25.85429,
            "logical_agreement": 68.0309,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.79923,
            "nubia_score": 0.58597
        },
        "bleurt": -0.21275,
        "bertscore": {
            "precision": 0.85571,
            "recall": 0.84728,
            "f1": 0.85089
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 339,
        "total_length": 3399,
        "mean_pred_length": 10.026548672566372,
        "std_pred_length": 3.938599942145451,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 29,
        "distinct-1": 0.34627831715210355,
        "vocab_size-1": 1177,
        "unique-1": 730,
        "entropy-1": 8.495727362025535,
        "distinct-2": 0.6761437908496732,
        "vocab_size-2": 2069,
        "unique-2": 1611,
        "entropy-2": 10.621115668855053,
        "cond_entropy-2": 1.5498321938998374,
        "distinct-3": 0.8224917309812569,
        "vocab_size-3": 2238,
        "unique-3": 1924,
        "entropy-3": 10.98006886317143,
        "cond_entropy-3": 0.3609271563356196,
        "total_length-nopunct": 2747,
        "mean_pred_length-nopunct": 8.103244837758112,
        "std_pred_length-nopunct": 3.4510425215834686,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.42664725154714234,
        "vocab_size-1-nopunct": 1172,
        "unique-1-nopunct": 730,
        "entropy-1-nopunct": 9.200274137858877,
        "distinct-2-nopunct": 0.7018272425249169,
        "vocab_size-2-nopunct": 1690,
        "unique-2-nopunct": 1344,
        "entropy-2-nopunct": 10.363372490921272,
        "cond_entropy-2-nopunct": 1.2780432015235645,
        "distinct-3-nopunct": 0.8337361043982601,
        "vocab_size-3-nopunct": 1725,
        "unique-3-nopunct": 1502,
        "entropy-3-nopunct": 10.612370642867186,
        "cond_entropy-3-nopunct": 0.33116681013789667,
        "msttr-100": 0.65424,
        "msttr-100_nopunct": 0.73074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 58.05634,
        "nist": 8.782346731722932,
        "rouge1": {
            "precision": 0.29499,
            "recall": 0.29085,
            "fmeasure": 0.29203
        },
        "rouge2": {
            "precision": 0.14073,
            "recall": 0.13963,
            "fmeasure": 0.13991
        },
        "rougeL": {
            "precision": 0.29449,
            "recall": 0.29048,
            "fmeasure": 0.29161
        },
        "rougeLsum": {
            "precision": 0.29449,
            "recall": 0.29048,
            "fmeasure": 0.29161
        },
        "local_recall": {
            "1": 0.34226447709593777,
            "2": 0.6817769718948323,
            "3": 0.883248730964467,
            "4": 0.8611111111111112,
            "5": 0.8666666666666667,
            "6": 0.9166666666666666,
            "7": 1.0
        },
        "meteor": 0.7397281123618265,
        "nubia": {
            "semantic_relation": 4.18308,
            "contradiction": 19.74251,
            "irrelevancy": 20.40642,
            "logical_agreement": 59.85107,
            "grammar_ref": 2.83259,
            "grammar_hyp": 2.8211,
            "nubia_score": 0.84867
        },
        "bleurt": 0.35483,
        "bertscore": {
            "precision": 0.9665,
            "recall": 0.96565,
            "f1": 0.96542
        }
    },
    "schema_guided_dialog_challenge_test_bfp05": {
        "predictions_file": "mT5_xl/schema_guided_dialog_challenge_test_bfp05",
        "N": 500,
        "total_length": 6200,
        "mean_pred_length": 12.4,
        "std_pred_length": 7.256169788531688,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 44,
        "distinct-1": 0.17258064516129032,
        "vocab_size-1": 1070,
        "unique-1": 618,
        "entropy-1": 7.916620904946915,
        "distinct-2": 0.5373684210526316,
        "vocab_size-2": 3063,
        "unique-2": 2266,
        "entropy-2": 10.85848579548549,
        "cond_entropy-2": 2.6903906379010465,
        "distinct-3": 0.7646153846153846,
        "vocab_size-3": 3976,
        "unique-3": 3428,
        "entropy-3": 11.647143007145658,
        "cond_entropy-3": 0.8011528360249696,
        "total_length-nopunct": 5413,
        "mean_pred_length-nopunct": 10.826,
        "std_pred_length-nopunct": 6.63774991996535,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.19490116386477,
        "vocab_size-1-nopunct": 1055,
        "unique-1-nopunct": 615,
        "entropy-1-nopunct": 8.12640859892979,
        "distinct-2-nopunct": 0.5524119682475066,
        "vocab_size-2-nopunct": 2714,
        "unique-2-nopunct": 2037,
        "entropy-2-nopunct": 10.682027354001333,
        "cond_entropy-2-nopunct": 2.673719735123051,
        "distinct-3-nopunct": 0.7745808790212959,
        "vocab_size-3-nopunct": 3419,
        "unique-3-nopunct": 2978,
        "entropy-3-nopunct": 11.430020851448672,
        "cond_entropy-3-nopunct": 0.7848937094968094,
        "msttr-100": 0.70306,
        "msttr-100_nopunct": 0.73667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp05.json",
        "bleu": 27.6807,
        "nist": 5.579055084519589,
        "rouge1": {
            "precision": 0.52501,
            "recall": 0.50149,
            "fmeasure": 0.50078
        },
        "rouge2": {
            "precision": 0.30362,
            "recall": 0.29029,
            "fmeasure": 0.28889
        },
        "rougeL": {
            "precision": 0.45941,
            "recall": 0.43849,
            "fmeasure": 0.43802
        },
        "rougeLsum": {
            "precision": 0.45941,
            "recall": 0.43849,
            "fmeasure": 0.43802
        },
        "local_recall": {
            "1": 0.5283986808354708
        },
        "meteor": 0.29390135303317205,
        "nubia": {
            "semantic_relation": 3.46941,
            "contradiction": 4.53464,
            "irrelevancy": 26.23382,
            "logical_agreement": 69.23154,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.84662,
            "nubia_score": 0.58703
        },
        "bleurt": -0.21186,
        "bertscore": {
            "precision": 0.8533,
            "recall": 0.84947,
            "f1": 0.85081
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 1322,
        "total_length": 28863,
        "mean_pred_length": 21.832829046898638,
        "std_pred_length": 11.769150397273775,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 106,
        "distinct-1": 0.052731871253854416,
        "vocab_size-1": 1522,
        "unique-1": 463,
        "entropy-1": 7.943725691756048,
        "distinct-2": 0.1843070331505755,
        "vocab_size-2": 5076,
        "unique-2": 2220,
        "entropy-2": 10.997475395411016,
        "cond_entropy-2": 2.8617204104799163,
        "distinct-3": 0.32552728937030395,
        "vocab_size-3": 8535,
        "unique-3": 4691,
        "entropy-3": 12.128168683614785,
        "cond_entropy-3": 1.191434889593799,
        "total_length-nopunct": 25339,
        "mean_pred_length-nopunct": 19.167170953101362,
        "std_pred_length-nopunct": 10.488451080406733,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 95,
        "distinct-1-nopunct": 0.05959193338332215,
        "vocab_size-1-nopunct": 1510,
        "unique-1-nopunct": 462,
        "entropy-1-nopunct": 8.239325588389958,
        "distinct-2-nopunct": 0.1994004246991714,
        "vocab_size-2-nopunct": 4789,
        "unique-2-nopunct": 2225,
        "entropy-2-nopunct": 10.917055284295161,
        "cond_entropy-2-nopunct": 2.8231843919213055,
        "distinct-3-nopunct": 0.34509803921568627,
        "vocab_size-3-nopunct": 7832,
        "unique-3-nopunct": 4521,
        "entropy-3-nopunct": 12.008131287340113,
        "cond_entropy-3-nopunct": 1.1410774117637503,
        "msttr-100": 0.51934,
        "msttr-100_nopunct": 0.53241,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 48.39657,
        "nist": 8.905946172811388,
        "rouge1": {
            "precision": 0.77142,
            "recall": 0.75341,
            "fmeasure": 0.75505
        },
        "rouge2": {
            "precision": 0.52123,
            "recall": 0.50804,
            "fmeasure": 0.50914
        },
        "rougeL": {
            "precision": 0.63013,
            "recall": 0.61603,
            "fmeasure": 0.61687
        },
        "rougeLsum": {
            "precision": 0.63013,
            "recall": 0.61603,
            "fmeasure": 0.61687
        },
        "local_recall": {
            "1": 0.22390586641835267,
            "2": 0.5846802529866479,
            "3": 0.8695098186178983,
            "4": 0.8431372549019608,
            "5": 0.7619047619047619
        },
        "meteor": 0.3900743894358796,
        "nubia": {
            "semantic_relation": 4.44931,
            "contradiction": 7.96544,
            "irrelevancy": 8.5875,
            "logical_agreement": 83.44706,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.63371,
            "nubia_score": 0.79368
        },
        "bleurt": 0.2535,
        "bertscore": {
            "precision": 0.92616,
            "recall": 0.92417,
            "f1": 0.9238
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 457,
        "total_length": 14318,
        "mean_pred_length": 31.330415754923415,
        "std_pred_length": 12.85596926641503,
        "median_pred_length": 30.0,
        "min_pred_length": 10,
        "max_pred_length": 79,
        "distinct-1": 0.08618522139963682,
        "vocab_size-1": 1234,
        "unique-1": 441,
        "entropy-1": 7.862174564694545,
        "distinct-2": 0.248899790779886,
        "vocab_size-2": 3450,
        "unique-2": 1714,
        "entropy-2": 10.569812704088996,
        "cond_entropy-2": 2.583365364582086,
        "distinct-3": 0.3890629662787228,
        "vocab_size-3": 5215,
        "unique-3": 3217,
        "entropy-3": 11.453019020558983,
        "cond_entropy-3": 0.9287431240846756,
        "total_length-nopunct": 12533,
        "mean_pred_length-nopunct": 27.424507658643325,
        "std_pred_length-nopunct": 11.537935291766344,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 70,
        "distinct-1-nopunct": 0.09758238251017315,
        "vocab_size-1-nopunct": 1223,
        "unique-1-nopunct": 439,
        "entropy-1-nopunct": 8.150185580015902,
        "distinct-2-nopunct": 0.26647896654521364,
        "vocab_size-2-nopunct": 3218,
        "unique-2-nopunct": 1700,
        "entropy-2-nopunct": 10.484738029859521,
        "cond_entropy-2-nopunct": 2.428881937460077,
        "distinct-3-nopunct": 0.40571477751958,
        "vocab_size-3-nopunct": 4714,
        "unique-3-nopunct": 3023,
        "entropy-3-nopunct": 11.311786165310753,
        "cond_entropy-3-nopunct": 0.860281752965733,
        "msttr-100": 0.49112,
        "msttr-100_nopunct": 0.50264,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 50.29931,
        "nist": 8.775383570397919,
        "rouge1": {
            "precision": 0.75117,
            "recall": 0.73393,
            "fmeasure": 0.73624
        },
        "rouge2": {
            "precision": 0.48545,
            "recall": 0.47419,
            "fmeasure": 0.47563
        },
        "rougeL": {
            "precision": 0.5655,
            "recall": 0.55546,
            "fmeasure": 0.55535
        },
        "rougeLsum": {
            "precision": 0.5655,
            "recall": 0.55546,
            "fmeasure": 0.55535
        },
        "local_recall": {
            "1": 0.23717948717948717,
            "2": 0.6074795725958516,
            "3": 0.903864891198441,
            "4": 0.5,
            "5": 1.0
        },
        "meteor": 0.39353334119557876,
        "nubia": {
            "semantic_relation": 4.44407,
            "contradiction": 8.40633,
            "irrelevancy": 6.21563,
            "logical_agreement": 85.37803,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.3253,
            "nubia_score": 0.79871
        },
        "bleurt": 0.13743,
        "bertscore": {
            "precision": 0.91986,
            "recall": 0.91779,
            "f1": 0.91766
        }
    },
    "schema_guided_dialog_challenge_test_nopunc": {
        "predictions_file": "mT5_xl/schema_guided_dialog_challenge_test_nopunc",
        "N": 500,
        "total_length": 6007,
        "mean_pred_length": 12.014,
        "std_pred_length": 6.800132645765081,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 35,
        "distinct-1": 0.18378558348593307,
        "vocab_size-1": 1104,
        "unique-1": 635,
        "entropy-1": 8.151642586946263,
        "distinct-2": 0.5667332485927002,
        "vocab_size-2": 3121,
        "unique-2": 2348,
        "entropy-2": 10.970572931037559,
        "cond_entropy-2": 2.764869348058977,
        "distinct-3": 0.787382711119984,
        "vocab_size-3": 3944,
        "unique-3": 3452,
        "entropy-3": 11.685019560012595,
        "cond_entropy-3": 0.7635038836593389,
        "total_length-nopunct": 5435,
        "mean_pred_length-nopunct": 10.87,
        "std_pred_length-nopunct": 6.278622460380939,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.20110395584176632,
        "vocab_size-1-nopunct": 1093,
        "unique-1-nopunct": 635,
        "entropy-1-nopunct": 8.255783023267448,
        "distinct-2-nopunct": 0.579128672745694,
        "vocab_size-2-nopunct": 2858,
        "unique-2-nopunct": 2183,
        "entropy-2-nopunct": 10.835961314158121,
        "cond_entropy-2-nopunct": 2.696212582866615,
        "distinct-3-nopunct": 0.7967094883930583,
        "vocab_size-3-nopunct": 3535,
        "unique-3-nopunct": 3120,
        "entropy-3-nopunct": 11.531281588129401,
        "cond_entropy-3-nopunct": 0.7286675968704136,
        "msttr-100": 0.73367,
        "msttr-100_nopunct": 0.74296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_nopunc.json",
        "bleu": 25.8552,
        "nist": 5.410655299286913,
        "rouge1": {
            "precision": 0.56219,
            "recall": 0.49423,
            "fmeasure": 0.5126
        },
        "rouge2": {
            "precision": 0.32997,
            "recall": 0.2919,
            "fmeasure": 0.30119
        },
        "rougeL": {
            "precision": 0.49177,
            "recall": 0.43413,
            "fmeasure": 0.44936
        },
        "rougeLsum": {
            "precision": 0.49177,
            "recall": 0.43413,
            "fmeasure": 0.44936
        },
        "local_recall": {
            "1": 0.5108067975581587
        },
        "meteor": 0.28356389726363285,
        "nubia": {
            "semantic_relation": 3.54013,
            "contradiction": 7.09231,
            "irrelevancy": 22.575,
            "logical_agreement": 70.3327,
            "grammar_ref": 4.79983,
            "grammar_hyp": 5.08867,
            "nubia_score": 0.58008
        },
        "bleurt": -0.21916,
        "bertscore": {
            "precision": 0.8608,
            "recall": 0.84077,
            "f1": 0.85013
        }
    },
    "schema_guided_dialog_challenge_test_scramble": {
        "predictions_file": "mT5_xl/schema_guided_dialog_challenge_test_scramble",
        "N": 500,
        "total_length": 6671,
        "mean_pred_length": 13.342,
        "std_pred_length": 7.406823610698448,
        "median_pred_length": 12.0,
        "min_pred_length": 2,
        "max_pred_length": 48,
        "distinct-1": 0.16174486583720582,
        "vocab_size-1": 1079,
        "unique-1": 579,
        "entropy-1": 7.953622864058136,
        "distinct-2": 0.5311942959001783,
        "vocab_size-2": 3278,
        "unique-2": 2366,
        "entropy-2": 10.997886627766155,
        "cond_entropy-2": 2.815378221074812,
        "distinct-3": 0.7711162052548052,
        "vocab_size-3": 4373,
        "unique-3": 3736,
        "entropy-3": 11.828305515459753,
        "cond_entropy-3": 0.8502294068415213,
        "total_length-nopunct": 5834,
        "mean_pred_length-nopunct": 11.668,
        "std_pred_length-nopunct": 6.691320945822282,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.18306479259513198,
        "vocab_size-1-nopunct": 1068,
        "unique-1-nopunct": 577,
        "entropy-1-nopunct": 8.171341357057766,
        "distinct-2-nopunct": 0.5536182977127859,
        "vocab_size-2-nopunct": 2953,
        "unique-2-nopunct": 2195,
        "entropy-2-nopunct": 10.849351534203914,
        "cond_entropy-2-nopunct": 2.803407189058751,
        "distinct-3-nopunct": 0.7836160529582127,
        "vocab_size-3-nopunct": 3788,
        "unique-3-nopunct": 3292,
        "entropy-3-nopunct": 11.619097120066185,
        "cond_entropy-3-nopunct": 0.8056038875476791,
        "msttr-100": 0.69591,
        "msttr-100_nopunct": 0.73017,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_scramble.json",
        "bleu": 26.25452,
        "nist": 5.517597784012266,
        "rouge1": {
            "precision": 0.52608,
            "recall": 0.49919,
            "fmeasure": 0.49866
        },
        "rouge2": {
            "precision": 0.29775,
            "recall": 0.27794,
            "fmeasure": 0.27863
        },
        "rougeL": {
            "precision": 0.46239,
            "recall": 0.43921,
            "fmeasure": 0.43828
        },
        "rougeLsum": {
            "precision": 0.46239,
            "recall": 0.43921,
            "fmeasure": 0.43828
        },
        "local_recall": {
            "1": 0.5167785234899329
        },
        "meteor": 0.28633426416346325,
        "nubia": {
            "semantic_relation": 3.39974,
            "contradiction": 7.51353,
            "irrelevancy": 25.00162,
            "logical_agreement": 67.48485,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.71363,
            "nubia_score": 0.57554
        },
        "bleurt": -0.23582,
        "bertscore": {
            "precision": 0.85351,
            "recall": 0.84763,
            "f1": 0.84999
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 369,
        "total_length": 3737,
        "mean_pred_length": 10.127371273712738,
        "std_pred_length": 2.949904022202182,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.21835697083221836,
        "vocab_size-1": 816,
        "unique-1": 459,
        "entropy-1": 7.550925858302932,
        "distinct-2": 0.5270190023752969,
        "vocab_size-2": 1775,
        "unique-2": 1269,
        "entropy-2": 10.185185450901333,
        "cond_entropy-2": 2.1780319466673586,
        "distinct-3": 0.7082360786928976,
        "vocab_size-3": 2124,
        "unique-3": 1731,
        "entropy-3": 10.747915760141211,
        "cond_entropy-3": 0.6627393206567896,
        "total_length-nopunct": 3258,
        "mean_pred_length-nopunct": 8.829268292682928,
        "std_pred_length-nopunct": 2.7091353546387182,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.2480049109883364,
        "vocab_size-1-nopunct": 808,
        "unique-1-nopunct": 457,
        "entropy-1-nopunct": 7.84652451729573,
        "distinct-2-nopunct": 0.5091727241259951,
        "vocab_size-2-nopunct": 1471,
        "unique-2-nopunct": 1048,
        "entropy-2-nopunct": 9.875905756875488,
        "cond_entropy-2-nopunct": 2.340315239814024,
        "distinct-3-nopunct": 0.6992063492063492,
        "vocab_size-3-nopunct": 1762,
        "unique-3-nopunct": 1431,
        "entropy-3-nopunct": 10.464628281189697,
        "cond_entropy-3-nopunct": 0.7234038202737819,
        "msttr-100": 0.64676,
        "msttr-100_nopunct": 0.69031,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 57.82605,
        "nist": 8.926023628373493,
        "rouge1": {
            "precision": 0.80787,
            "recall": 0.78336,
            "fmeasure": 0.78802
        },
        "rouge2": {
            "precision": 0.58806,
            "recall": 0.56811,
            "fmeasure": 0.57191
        },
        "rougeL": {
            "precision": 0.72324,
            "recall": 0.69973,
            "fmeasure": 0.70453
        },
        "rougeLsum": {
            "precision": 0.72324,
            "recall": 0.69973,
            "fmeasure": 0.70453
        },
        "local_recall": {
            "1": 0.2346398305084746,
            "2": 0.6867862969004894,
            "3": 0.8791500664010624,
            "4": 0.9210526315789473
        },
        "meteor": 0.45769117886542965,
        "nubia": {
            "semantic_relation": 4.60601,
            "contradiction": 7.00728,
            "irrelevancy": 6.65399,
            "logical_agreement": 86.33873,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.25341,
            "nubia_score": 0.83504
        },
        "bleurt": 0.37477,
        "bertscore": {
            "precision": 0.94571,
            "recall": 0.94467,
            "f1": 0.94416
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 350,
        "total_length": 8200,
        "mean_pred_length": 23.428571428571427,
        "std_pred_length": 6.072823369197345,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 54,
        "distinct-1": 0.12317073170731707,
        "vocab_size-1": 1010,
        "unique-1": 315,
        "entropy-1": 7.88187427856134,
        "distinct-2": 0.34764331210191085,
        "vocab_size-2": 2729,
        "unique-2": 1440,
        "entropy-2": 10.614348256512566,
        "cond_entropy-2": 2.5642883215969143,
        "distinct-3": 0.5302666666666667,
        "vocab_size-3": 3977,
        "unique-3": 2641,
        "entropy-3": 11.487616771813283,
        "cond_entropy-3": 0.9203818400792527,
        "total_length-nopunct": 7227,
        "mean_pred_length-nopunct": 20.64857142857143,
        "std_pred_length-nopunct": 5.359577351597335,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.1385083713850837,
        "vocab_size-1-nopunct": 1001,
        "unique-1-nopunct": 313,
        "entropy-1-nopunct": 8.145370793946382,
        "distinct-2-nopunct": 0.36004071542823907,
        "vocab_size-2-nopunct": 2476,
        "unique-2-nopunct": 1368,
        "entropy-2-nopunct": 10.47936885026674,
        "cond_entropy-2-nopunct": 2.457178249737757,
        "distinct-3-nopunct": 0.542668913742914,
        "vocab_size-3-nopunct": 3542,
        "unique-3-nopunct": 2415,
        "entropy-3-nopunct": 11.322521619484467,
        "cond_entropy-3-nopunct": 0.8771040344367711,
        "msttr-100": 0.65585,
        "msttr-100_nopunct": 0.69889,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 47.40674,
        "nist": 8.538121730377286,
        "rouge1": {
            "precision": 0.75006,
            "recall": 0.75551,
            "fmeasure": 0.74502
        },
        "rouge2": {
            "precision": 0.49313,
            "recall": 0.49273,
            "fmeasure": 0.48729
        },
        "rougeL": {
            "precision": 0.59966,
            "recall": 0.60339,
            "fmeasure": 0.59493
        },
        "rougeLsum": {
            "precision": 0.59966,
            "recall": 0.60339,
            "fmeasure": 0.59493
        },
        "local_recall": {
            "1": 0.22830915013325437,
            "2": 0.5945366898768077,
            "3": 0.8790238836967809,
            "4": 0.3,
            "5": 0.8275862068965517
        },
        "meteor": 0.40037702937943764,
        "nubia": {
            "semantic_relation": 4.43454,
            "contradiction": 10.18192,
            "irrelevancy": 9.92977,
            "logical_agreement": 79.88831,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.45105,
            "nubia_score": 0.78661
        },
        "bleurt": 0.20109,
        "bertscore": {
            "precision": 0.9198,
            "recall": 0.9196,
            "f1": 0.91824
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 106,
        "total_length": 2114,
        "mean_pred_length": 19.943396226415093,
        "std_pred_length": 4.268865318460582,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 30,
        "distinct-1": 0.4389782403027436,
        "vocab_size-1": 928,
        "unique-1": 718,
        "entropy-1": 8.302454991928972,
        "distinct-2": 0.8605577689243028,
        "vocab_size-2": 1728,
        "unique-2": 1602,
        "entropy-2": 10.567276318865073,
        "cond_entropy-2": 2.0544780633798854,
        "distinct-3": 0.9663512092534174,
        "vocab_size-3": 1838,
        "unique-3": 1801,
        "entropy-3": 10.809430319781562,
        "cond_entropy-3": 0.24701345751163595,
        "total_length-nopunct": 1962,
        "mean_pred_length-nopunct": 18.50943396226415,
        "std_pred_length-nopunct": 4.0776549009108205,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4689092762487258,
        "vocab_size-1-nopunct": 920,
        "unique-1-nopunct": 718,
        "entropy-1-nopunct": 8.42965847748116,
        "distinct-2-nopunct": 0.8679956896551724,
        "vocab_size-2-nopunct": 1611,
        "unique-2-nopunct": 1502,
        "entropy-2-nopunct": 10.473183150770678,
        "cond_entropy-2-nopunct": 2.144309602565045,
        "distinct-3-nopunct": 0.9742857142857143,
        "vocab_size-3-nopunct": 1705,
        "unique-3-nopunct": 1674,
        "entropy-3-nopunct": 10.713199862154354,
        "cond_entropy-3-nopunct": 0.24502758080817497,
        "msttr-100": 0.73286,
        "msttr-100_nopunct": 0.75421,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 10.53213,
        "nist": 3.278287992318591,
        "rouge1": {
            "precision": 0.44946,
            "recall": 0.37662,
            "fmeasure": 0.40294
        },
        "rouge2": {
            "precision": 0.17208,
            "recall": 0.14541,
            "fmeasure": 0.15485
        },
        "rougeL": {
            "precision": 0.34172,
            "recall": 0.2884,
            "fmeasure": 0.30753
        },
        "rougeLsum": {
            "precision": 0.34172,
            "recall": 0.2884,
            "fmeasure": 0.30753
        },
        "local_recall": {
            "1": 0.3478854024556617
        },
        "meteor": 0.17321210035443377,
        "nubia": {
            "semantic_relation": 3.12356,
            "contradiction": 13.54719,
            "irrelevancy": 62.26235,
            "logical_agreement": 24.19046,
            "grammar_ref": 3.83852,
            "grammar_hyp": 3.63514,
            "nubia_score": 0.47719
        },
        "bleurt": -0.28328,
        "bertscore": {
            "precision": 0.84496,
            "recall": 0.82299,
            "f1": 0.83351
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 114,
        "total_length": 4734,
        "mean_pred_length": 41.526315789473685,
        "std_pred_length": 11.031224046788845,
        "median_pred_length": 40.0,
        "min_pred_length": 22,
        "max_pred_length": 106,
        "distinct-1": 0.1588508660752007,
        "vocab_size-1": 752,
        "unique-1": 264,
        "entropy-1": 7.719885529283369,
        "distinct-2": 0.3683982683982684,
        "vocab_size-2": 1702,
        "unique-2": 873,
        "entropy-2": 10.068995019785888,
        "cond_entropy-2": 2.2573376653036363,
        "distinct-3": 0.5088770528184643,
        "vocab_size-3": 2293,
        "unique-3": 1454,
        "entropy-3": 10.709405895426423,
        "cond_entropy-3": 0.6624649580410414,
        "total_length-nopunct": 4179,
        "mean_pred_length-nopunct": 36.6578947368421,
        "std_pred_length-nopunct": 10.099356369424685,
        "median_pred_length-nopunct": 36.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 95,
        "distinct-1-nopunct": 0.17779373055754966,
        "vocab_size-1-nopunct": 743,
        "unique-1-nopunct": 263,
        "entropy-1-nopunct": 7.972893197301892,
        "distinct-2-nopunct": 0.3933579335793358,
        "vocab_size-2-nopunct": 1599,
        "unique-2-nopunct": 868,
        "entropy-2-nopunct": 10.029033985568756,
        "cond_entropy-2-nopunct": 2.1125374259812713,
        "distinct-3-nopunct": 0.530751708428246,
        "vocab_size-3-nopunct": 2097,
        "unique-3-nopunct": 1385,
        "entropy-3-nopunct": 10.593497860489261,
        "cond_entropy-3-nopunct": 0.5777477791780525,
        "msttr-100": 0.62702,
        "msttr-100_nopunct": 0.67854,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 46.05254,
        "nist": 8.208551059428853,
        "rouge1": {
            "precision": 0.76139,
            "recall": 0.69912,
            "fmeasure": 0.72239
        },
        "rouge2": {
            "precision": 0.46189,
            "recall": 0.42194,
            "fmeasure": 0.43682
        },
        "rougeL": {
            "precision": 0.5317,
            "recall": 0.49528,
            "fmeasure": 0.5083
        },
        "rougeLsum": {
            "precision": 0.5317,
            "recall": 0.49528,
            "fmeasure": 0.5083
        },
        "local_recall": {
            "1": 0.22819932049830124,
            "2": 0.6191756272401434,
            "3": 0.8706766917293233
        },
        "meteor": 0.3635401913922481,
        "nubia": {
            "semantic_relation": 4.23863,
            "contradiction": 6.4734,
            "irrelevancy": 7.26555,
            "logical_agreement": 86.26105,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.10807,
            "nubia_score": 0.73769
        },
        "bleurt": 0.09002,
        "bertscore": {
            "precision": 0.91348,
            "recall": 0.90214,
            "f1": 0.90648
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 305,
        "total_length": 9073,
        "mean_pred_length": 29.74754098360656,
        "std_pred_length": 7.021643508452686,
        "median_pred_length": 30.0,
        "min_pred_length": 12,
        "max_pred_length": 51,
        "distinct-1": 0.12465557147580734,
        "vocab_size-1": 1131,
        "unique-1": 382,
        "entropy-1": 7.935422168940657,
        "distinct-2": 0.3585766423357664,
        "vocab_size-2": 3144,
        "unique-2": 1669,
        "entropy-2": 10.800240361380936,
        "cond_entropy-2": 2.730989429417134,
        "distinct-3": 0.5467328370554178,
        "vocab_size-3": 4627,
        "unique-3": 3068,
        "entropy-3": 11.715982233418556,
        "cond_entropy-3": 0.9523346765858687,
        "total_length-nopunct": 7940,
        "mean_pred_length-nopunct": 26.0327868852459,
        "std_pred_length-nopunct": 6.2451744338073105,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.141183879093199,
        "vocab_size-1-nopunct": 1121,
        "unique-1-nopunct": 380,
        "entropy-1-nopunct": 8.244959234146055,
        "distinct-2-nopunct": 0.38650949574328747,
        "vocab_size-2-nopunct": 2951,
        "unique-2-nopunct": 1683,
        "entropy-2-nopunct": 10.75589282088189,
        "cond_entropy-2-nopunct": 2.608759387686944,
        "distinct-3-nopunct": 0.5684856753069577,
        "vocab_size-3-nopunct": 4167,
        "unique-3-nopunct": 2878,
        "entropy-3-nopunct": 11.583795317971067,
        "cond_entropy-3-nopunct": 0.8540662511498687,
        "msttr-100": 0.643,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 47.19994,
        "nist": 8.618171511976279,
        "rouge1": {
            "precision": 0.7425,
            "recall": 0.72565,
            "fmeasure": 0.72659
        },
        "rouge2": {
            "precision": 0.46922,
            "recall": 0.45975,
            "fmeasure": 0.45957
        },
        "rougeL": {
            "precision": 0.55884,
            "recall": 0.54889,
            "fmeasure": 0.54796
        },
        "rougeLsum": {
            "precision": 0.55884,
            "recall": 0.54889,
            "fmeasure": 0.54796
        },
        "local_recall": {
            "1": 0.21880246222719643,
            "2": 0.5898825654923215,
            "3": 0.8800899325505871
        },
        "meteor": 0.3813104028668875,
        "nubia": {
            "semantic_relation": 4.34786,
            "contradiction": 8.47503,
            "irrelevancy": 9.16376,
            "logical_agreement": 82.36122,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.27803,
            "nubia_score": 0.761
        },
        "bleurt": 0.16969,
        "bertscore": {
            "precision": 0.91362,
            "recall": 0.91085,
            "f1": 0.91102
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 79,
        "total_length": 3855,
        "mean_pred_length": 48.79746835443038,
        "std_pred_length": 12.196056373234963,
        "median_pred_length": 48.0,
        "min_pred_length": 21,
        "max_pred_length": 81,
        "distinct-1": 0.16653696498054474,
        "vocab_size-1": 642,
        "unique-1": 273,
        "entropy-1": 7.609211504363041,
        "distinct-2": 0.3673199152542373,
        "vocab_size-2": 1387,
        "unique-2": 764,
        "entropy-2": 9.807880114224444,
        "cond_entropy-2": 2.122900813200642,
        "distinct-3": 0.4839058696240195,
        "vocab_size-3": 1789,
        "unique-3": 1140,
        "entropy-3": 10.33546883209614,
        "cond_entropy-3": 0.546134340179934,
        "total_length-nopunct": 3391,
        "mean_pred_length-nopunct": 42.924050632911396,
        "std_pred_length-nopunct": 11.260744126207527,
        "median_pred_length-nopunct": 42.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.186670598643468,
        "vocab_size-1-nopunct": 633,
        "unique-1-nopunct": 272,
        "entropy-1-nopunct": 7.8419027216400625,
        "distinct-2-nopunct": 0.391304347826087,
        "vocab_size-2-nopunct": 1296,
        "unique-2-nopunct": 747,
        "entropy-2-nopunct": 9.74656561255522,
        "cond_entropy-2-nopunct": 1.951035731930668,
        "distinct-3-nopunct": 0.5032477575007733,
        "vocab_size-3-nopunct": 1627,
        "unique-3-nopunct": 1077,
        "entropy-3-nopunct": 10.202082042108756,
        "cond_entropy-3-nopunct": 0.4644428400502059,
        "msttr-100": 0.64974,
        "msttr-100_nopunct": 0.68545,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 48.36005,
        "nist": 8.088714639230982,
        "rouge1": {
            "precision": 0.76351,
            "recall": 0.70443,
            "fmeasure": 0.72737
        },
        "rouge2": {
            "precision": 0.47086,
            "recall": 0.43812,
            "fmeasure": 0.4506
        },
        "rougeL": {
            "precision": 0.51159,
            "recall": 0.47599,
            "fmeasure": 0.48972
        },
        "rougeLsum": {
            "precision": 0.51159,
            "recall": 0.47599,
            "fmeasure": 0.48972
        },
        "local_recall": {
            "1": 0.2696078431372549,
            "2": 0.5099075297225891,
            "3": 0.8707833047455689
        },
        "meteor": 0.36116869180439376,
        "nubia": {
            "semantic_relation": 4.13131,
            "contradiction": 5.37951,
            "irrelevancy": 6.17846,
            "logical_agreement": 88.44204,
            "grammar_ref": 3.96506,
            "grammar_hyp": 3.94622,
            "nubia_score": 0.75558
        },
        "bleurt": 0.00098,
        "bertscore": {
            "precision": 0.91126,
            "recall": 0.89949,
            "f1": 0.90445
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 297,
        "total_length": 2895,
        "mean_pred_length": 9.747474747474747,
        "std_pred_length": 2.7609961397484324,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.24006908462867013,
        "vocab_size-1": 695,
        "unique-1": 387,
        "entropy-1": 7.439582894124597,
        "distinct-2": 0.5573518090839107,
        "vocab_size-2": 1448,
        "unique-2": 1036,
        "entropy-2": 9.957018558138017,
        "cond_entropy-2": 2.0467256616550795,
        "distinct-3": 0.7340286831812256,
        "vocab_size-3": 1689,
        "unique-3": 1386,
        "entropy-3": 10.457954952042233,
        "cond_entropy-3": 0.5921700391523034,
        "total_length-nopunct": 2529,
        "mean_pred_length-nopunct": 8.515151515151516,
        "std_pred_length-nopunct": 2.589919475485883,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.27164887307236063,
        "vocab_size-1-nopunct": 687,
        "unique-1-nopunct": 385,
        "entropy-1-nopunct": 7.734049517055571,
        "distinct-2-nopunct": 0.5394265232974911,
        "vocab_size-2-nopunct": 1204,
        "unique-2-nopunct": 856,
        "entropy-2-nopunct": 9.651820978600668,
        "cond_entropy-2-nopunct": 2.2124407234157695,
        "distinct-3-nopunct": 0.7260981912144703,
        "vocab_size-3-nopunct": 1405,
        "unique-3-nopunct": 1149,
        "entropy-3-nopunct": 10.177798612211049,
        "cond_entropy-3-nopunct": 0.6519452133543161,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.6804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 61.02216,
        "nist": 9.028705052621095,
        "rouge1": {
            "precision": 0.81823,
            "recall": 0.78957,
            "fmeasure": 0.79628
        },
        "rouge2": {
            "precision": 0.60396,
            "recall": 0.57992,
            "fmeasure": 0.58559
        },
        "rougeL": {
            "precision": 0.73945,
            "recall": 0.7113,
            "fmeasure": 0.71825
        },
        "rougeLsum": {
            "precision": 0.73945,
            "recall": 0.7113,
            "fmeasure": 0.71825
        },
        "local_recall": {
            "1": 0.2270861833105335,
            "2": 0.6870466321243524,
            "3": 0.8903993203058623,
            "4": 0.9210526315789473
        },
        "meteor": 0.46787618436957623,
        "nubia": {
            "semantic_relation": 4.65046,
            "contradiction": 6.40625,
            "irrelevancy": 5.42798,
            "logical_agreement": 88.16577,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.23131,
            "nubia_score": 0.85149
        },
        "bleurt": 0.41163,
        "bertscore": {
            "precision": 0.95082,
            "recall": 0.94928,
            "f1": 0.94908
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 72,
        "total_length": 842,
        "mean_pred_length": 11.694444444444445,
        "std_pred_length": 3.1782196662461173,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.332541567695962,
        "vocab_size-1": 280,
        "unique-1": 174,
        "entropy-1": 6.813897310586881,
        "distinct-2": 0.6571428571428571,
        "vocab_size-2": 506,
        "unique-2": 388,
        "entropy-2": 8.65916559571218,
        "cond_entropy-2": 1.5478753253800217,
        "distinct-3": 0.7836676217765043,
        "vocab_size-3": 547,
        "unique-3": 460,
        "entropy-3": 8.923628333796081,
        "cond_entropy-3": 0.3318018761456157,
        "total_length-nopunct": 729,
        "mean_pred_length-nopunct": 10.125,
        "std_pred_length-nopunct": 2.8034576865007255,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.37585733882030176,
        "vocab_size-1-nopunct": 274,
        "unique-1-nopunct": 172,
        "entropy-1-nopunct": 6.963231432864041,
        "distinct-2-nopunct": 0.6407914764079148,
        "vocab_size-2-nopunct": 421,
        "unique-2-nopunct": 319,
        "entropy-2-nopunct": 8.372887029554205,
        "cond_entropy-2-nopunct": 1.6324097961491988,
        "distinct-3-nopunct": 0.7760683760683761,
        "vocab_size-3-nopunct": 454,
        "unique-3-nopunct": 381,
        "entropy-3-nopunct": 8.645520609512934,
        "cond_entropy-3-nopunct": 0.35352577618046926,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.65714,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 46.78857,
        "nist": 6.83382306501245,
        "rouge1": {
            "precision": 0.76515,
            "recall": 0.75771,
            "fmeasure": 0.75394
        },
        "rouge2": {
            "precision": 0.52251,
            "recall": 0.51938,
            "fmeasure": 0.51552
        },
        "rougeL": {
            "precision": 0.65639,
            "recall": 0.65203,
            "fmeasure": 0.64795
        },
        "rougeLsum": {
            "precision": 0.65639,
            "recall": 0.65203,
            "fmeasure": 0.64795
        },
        "local_recall": {
            "1": 0.2605633802816901,
            "2": 0.685823754789272,
            "3": 0.8389057750759878
        },
        "meteor": 0.42263461649758666,
        "nubia": {
            "semantic_relation": 4.42265,
            "contradiction": 9.48651,
            "irrelevancy": 11.71132,
            "logical_agreement": 78.80217,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.34459,
            "nubia_score": 0.76721
        },
        "bleurt": 0.22269,
        "bertscore": {
            "precision": 0.92462,
            "recall": 0.92565,
            "f1": 0.9239
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation_parent": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6242,
        "mean_pred_length": 12.484,
        "std_pred_length": 7.036884537918752,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 40,
        "distinct-1": 0.1544376802306953,
        "vocab_size-1": 964,
        "unique-1": 554,
        "entropy-1": 7.7355192290263455,
        "distinct-2": 0.4535005224660397,
        "vocab_size-2": 2604,
        "unique-2": 1813,
        "entropy-2": 10.430585305768972,
        "cond_entropy-2": 2.4246706589095193,
        "distinct-3": 0.6499427699351392,
        "vocab_size-3": 3407,
        "unique-3": 2747,
        "entropy-3": 11.198298747376258,
        "cond_entropy-3": 0.7857519664933595,
        "total_length-nopunct": 5436,
        "mean_pred_length-nopunct": 10.872,
        "std_pred_length-nopunct": 6.413393485511395,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.1749448123620309,
        "vocab_size-1-nopunct": 951,
        "unique-1-nopunct": 550,
        "entropy-1-nopunct": 7.942978904560859,
        "distinct-2-nopunct": 0.47346029173419774,
        "vocab_size-2-nopunct": 2337,
        "unique-2-nopunct": 1677,
        "entropy-2-nopunct": 10.264154320975559,
        "cond_entropy-2-nopunct": 2.4506767995809073,
        "distinct-3-nopunct": 0.6697475202885482,
        "vocab_size-3-nopunct": 2971,
        "unique-3-nopunct": 2458,
        "entropy-3-nopunct": 10.996940440320632,
        "cond_entropy-3-nopunct": 0.7620633968434696,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.71148,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 33.94316,
        "nist": 6.270697172591181,
        "rouge1": {
            "precision": 0.58711,
            "recall": 0.56887,
            "fmeasure": 0.56639
        },
        "rouge2": {
            "precision": 0.36831,
            "recall": 0.35971,
            "fmeasure": 0.35708
        },
        "rougeL": {
            "precision": 0.52901,
            "recall": 0.51265,
            "fmeasure": 0.51058
        },
        "rougeLsum": {
            "precision": 0.52901,
            "recall": 0.51265,
            "fmeasure": 0.51058
        },
        "local_recall": {
            "1": 0.5841988130563798
        },
        "meteor": 0.33038438069459297,
        "nubia": {
            "semantic_relation": 3.73434,
            "contradiction": 5.50156,
            "irrelevancy": 19.45464,
            "logical_agreement": 75.0438,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.45626,
            "nubia_score": 0.68856
        },
        "bleurt": -0.009,
        "bertscore": {
            "precision": 0.87765,
            "recall": 0.87285,
            "f1": 0.87473
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 1295,
        "total_length": 37379,
        "mean_pred_length": 28.864092664092663,
        "std_pred_length": 11.630345088579455,
        "median_pred_length": 27.0,
        "min_pred_length": 7,
        "max_pred_length": 106,
        "distinct-1": 0.044356456834051206,
        "vocab_size-1": 1658,
        "unique-1": 435,
        "entropy-1": 8.06167363699561,
        "distinct-2": 0.16112404389757234,
        "vocab_size-2": 5814,
        "unique-2": 2335,
        "entropy-2": 11.13130830083619,
        "cond_entropy-2": 2.926281209999321,
        "distinct-3": 0.2938285090114691,
        "vocab_size-3": 10222,
        "unique-3": 5393,
        "entropy-3": 12.297595541303785,
        "cond_entropy-3": 1.213979718870735,
        "total_length-nopunct": 32834,
        "mean_pred_length-nopunct": 25.354440154440155,
        "std_pred_length-nopunct": 10.409540915001502,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 95,
        "distinct-1-nopunct": 0.050161418042273254,
        "vocab_size-1-nopunct": 1647,
        "unique-1-nopunct": 435,
        "entropy-1-nopunct": 8.370507743666492,
        "distinct-2-nopunct": 0.18041155394907893,
        "vocab_size-2-nopunct": 5690,
        "unique-2-nopunct": 2498,
        "entropy-2-nopunct": 11.107343730410783,
        "cond_entropy-2-nopunct": 2.8459142554241246,
        "distinct-3-nopunct": 0.31738526649914034,
        "vocab_size-3-nopunct": 9599,
        "unique-3-nopunct": 5394,
        "entropy-3-nopunct": 12.212810087114425,
        "cond_entropy-3-nopunct": 1.1383423876522862,
        "msttr-100": 0.6489,
        "msttr-100_nopunct": 0.68954,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 47.79285,
        "nist": 8.970738068830826,
        "rouge1": {
            "precision": 0.75317,
            "recall": 0.73613,
            "fmeasure": 0.73779
        },
        "rouge2": {
            "precision": 0.48762,
            "recall": 0.47622,
            "fmeasure": 0.47713
        },
        "rougeL": {
            "precision": 0.57707,
            "recall": 0.56662,
            "fmeasure": 0.5663
        },
        "rougeLsum": {
            "precision": 0.57707,
            "recall": 0.56662,
            "fmeasure": 0.5663
        },
        "local_recall": {
            "1": 0.22801768106086365,
            "2": 0.5760589749590451,
            "3": 0.8795371784329848,
            "4": 0.5882352941176471,
            "5": 0.8275862068965517
        },
        "meteor": 0.38262417670030757,
        "nubia": {
            "semantic_relation": 4.38479,
            "contradiction": 8.67072,
            "irrelevancy": 8.62314,
            "logical_agreement": 82.70614,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.35383,
            "nubia_score": 0.77794
        },
        "bleurt": 0.16995,
        "bertscore": {
            "precision": 0.91756,
            "recall": 0.91485,
            "f1": 0.91484
        }
    },
    "schema_guided_dialog_challenge_test_bfp02_parent": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6362,
        "mean_pred_length": 12.724,
        "std_pred_length": 7.224390908581845,
        "median_pred_length": 11.0,
        "min_pred_length": 3,
        "max_pred_length": 40,
        "distinct-1": 0.15325369380697892,
        "vocab_size-1": 975,
        "unique-1": 538,
        "entropy-1": 7.810573945651957,
        "distinct-2": 0.4503582395087001,
        "vocab_size-2": 2640,
        "unique-2": 1791,
        "entropy-2": 10.516162004290777,
        "cond_entropy-2": 2.4644464705367626,
        "distinct-3": 0.65479298769116,
        "vocab_size-3": 3511,
        "unique-3": 2789,
        "entropy-3": 11.328752821936588,
        "cond_entropy-3": 0.8304107128342267,
        "total_length-nopunct": 5594,
        "mean_pred_length-nopunct": 11.188,
        "std_pred_length-nopunct": 6.623039785476153,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.17179120486235253,
        "vocab_size-1-nopunct": 961,
        "unique-1-nopunct": 534,
        "entropy-1-nopunct": 7.994155128113,
        "distinct-2-nopunct": 0.4662347860227719,
        "vocab_size-2-nopunct": 2375,
        "unique-2-nopunct": 1649,
        "entropy-2-nopunct": 10.356047515289482,
        "cond_entropy-2-nopunct": 2.48292054042385,
        "distinct-3-nopunct": 0.6702220287331302,
        "vocab_size-3-nopunct": 3079,
        "unique-3-nopunct": 2502,
        "entropy-3-nopunct": 11.13482952579131,
        "cond_entropy-3-nopunct": 0.815858843113051,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.71491,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 34.51824,
        "nist": 6.433877576251796,
        "rouge1": {
            "precision": 0.60559,
            "recall": 0.56872,
            "fmeasure": 0.57555
        },
        "rouge2": {
            "precision": 0.39472,
            "recall": 0.37142,
            "fmeasure": 0.37499
        },
        "rougeL": {
            "precision": 0.55112,
            "recall": 0.51832,
            "fmeasure": 0.52435
        },
        "rougeLsum": {
            "precision": 0.55112,
            "recall": 0.51832,
            "fmeasure": 0.52435
        },
        "local_recall": {
            "1": 0.5771309046540003
        },
        "meteor": 0.3274238887585461,
        "nubia": {
            "semantic_relation": 3.7466,
            "contradiction": 5.9793,
            "irrelevancy": 18.6183,
            "logical_agreement": 75.4024,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.61773,
            "nubia_score": 0.67723
        },
        "bleurt": -0.03128,
        "bertscore": {
            "precision": 0.88157,
            "recall": 0.86907,
            "f1": 0.8748
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 115,
        "total_length": 2065,
        "mean_pred_length": 17.956521739130434,
        "std_pred_length": 6.710655128191837,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 55,
        "distinct-1": 0.26150121065375304,
        "vocab_size-1": 540,
        "unique-1": 273,
        "entropy-1": 7.414888339737282,
        "distinct-2": 0.5548717948717948,
        "vocab_size-2": 1082,
        "unique-2": 735,
        "entropy-2": 9.592578109886919,
        "cond_entropy-2": 1.976340131268609,
        "distinct-3": 0.7024523160762943,
        "vocab_size-3": 1289,
        "unique-3": 989,
        "entropy-3": 10.077154204729041,
        "cond_entropy-3": 0.5275046353564821,
        "total_length-nopunct": 1780,
        "mean_pred_length-nopunct": 15.478260869565217,
        "std_pred_length-nopunct": 5.762469015043671,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.29943820224719103,
        "vocab_size-1-nopunct": 533,
        "unique-1-nopunct": 272,
        "entropy-1-nopunct": 7.707390458798148,
        "distinct-2-nopunct": 0.5555555555555556,
        "vocab_size-2-nopunct": 925,
        "unique-2-nopunct": 630,
        "entropy-2-nopunct": 9.368401999852985,
        "cond_entropy-2-nopunct": 1.7842560562600407,
        "distinct-3-nopunct": 0.6961290322580646,
        "vocab_size-3-nopunct": 1079,
        "unique-3-nopunct": 822,
        "entropy-3-nopunct": 9.81405546759149,
        "cond_entropy-3-nopunct": 0.4900069722955749,
        "msttr-100": 0.652,
        "msttr-100_nopunct": 0.71118,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 55.67988,
        "nist": 8.307155860177323,
        "rouge1": {
            "precision": 0.77953,
            "recall": 0.77455,
            "fmeasure": 0.76891
        },
        "rouge2": {
            "precision": 0.54315,
            "recall": 0.53903,
            "fmeasure": 0.53497
        },
        "rougeL": {
            "precision": 0.67209,
            "recall": 0.66315,
            "fmeasure": 0.66049
        },
        "rougeLsum": {
            "precision": 0.67209,
            "recall": 0.66315,
            "fmeasure": 0.66049
        },
        "local_recall": {
            "1": 0.21650717703349281,
            "2": 0.6247619047619047,
            "3": 0.8966942148760331
        },
        "meteor": 0.4358096915791209,
        "nubia": {
            "semantic_relation": 4.65229,
            "contradiction": 4.84986,
            "irrelevancy": 4.96465,
            "logical_agreement": 90.18548,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.57138,
            "nubia_score": 0.85828
        },
        "bleurt": 0.34398,
        "bertscore": {
            "precision": 0.93521,
            "recall": 0.938,
            "f1": 0.93496
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 518,
        "total_length": 15425,
        "mean_pred_length": 29.77799227799228,
        "std_pred_length": 13.917258882795533,
        "median_pred_length": 28.0,
        "min_pred_length": 5,
        "max_pred_length": 79,
        "distinct-1": 0.0580226904376013,
        "vocab_size-1": 895,
        "unique-1": 241,
        "entropy-1": 7.687742954238957,
        "distinct-2": 0.16670020795599383,
        "vocab_size-2": 2485,
        "unique-2": 967,
        "entropy-2": 10.092595041964913,
        "cond_entropy-2": 2.2756857604583565,
        "distinct-3": 0.26249218152755577,
        "vocab_size-3": 3777,
        "unique-3": 1852,
        "entropy-3": 10.856548363339638,
        "cond_entropy-3": 0.804837515111409,
        "total_length-nopunct": 13589,
        "mean_pred_length-nopunct": 26.233590733590734,
        "std_pred_length-nopunct": 12.422635921801316,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 70,
        "distinct-1-nopunct": 0.06519979395098977,
        "vocab_size-1-nopunct": 886,
        "unique-1-nopunct": 241,
        "entropy-1-nopunct": 7.955373292737762,
        "distinct-2-nopunct": 0.1803993573559789,
        "vocab_size-2-nopunct": 2358,
        "unique-2-nopunct": 1001,
        "entropy-2-nopunct": 9.99831526145834,
        "cond_entropy-2-nopunct": 2.123620339389515,
        "distinct-3-nopunct": 0.2772245678323907,
        "vocab_size-3-nopunct": 3480,
        "unique-3-nopunct": 1820,
        "entropy-3-nopunct": 10.715153819262799,
        "cond_entropy-3-nopunct": 0.7402160827359712,
        "msttr-100": 0.65929,
        "msttr-100_nopunct": 0.69889,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 59.8272,
        "nist": 9.278515254348918,
        "rouge1": {
            "precision": 0.81579,
            "recall": 0.79115,
            "fmeasure": 0.79884
        },
        "rouge2": {
            "precision": 0.58554,
            "recall": 0.5688,
            "fmeasure": 0.5736
        },
        "rougeL": {
            "precision": 0.65012,
            "recall": 0.63504,
            "fmeasure": 0.63863
        },
        "rougeLsum": {
            "precision": 0.65012,
            "recall": 0.63504,
            "fmeasure": 0.63863
        },
        "local_recall": {
            "1": 0.2671100997724488,
            "2": 0.6565569035239746,
            "3": 0.9336953415261503,
            "4": 0.9210526315789473
        },
        "meteor": 0.4296158055404834,
        "nubia": {
            "semantic_relation": 4.68721,
            "contradiction": 3.35222,
            "irrelevancy": 4.5043,
            "logical_agreement": 92.14348,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.19136,
            "nubia_score": 0.88591
        },
        "bleurt": 0.33355,
        "bertscore": {
            "precision": 0.94375,
            "recall": 0.93934,
            "f1": 0.94067
        }
    },
    "schema_guided_dialog_challenge_test_bfp05_parent": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6114,
        "mean_pred_length": 12.228,
        "std_pred_length": 7.084632382841046,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 44,
        "distinct-1": 0.15554465161923453,
        "vocab_size-1": 951,
        "unique-1": 539,
        "entropy-1": 7.72566795970771,
        "distinct-2": 0.45903099394371216,
        "vocab_size-2": 2577,
        "unique-2": 1818,
        "entropy-2": 10.40026604933832,
        "cond_entropy-2": 2.418272734632812,
        "distinct-3": 0.6523269456394212,
        "vocab_size-3": 3336,
        "unique-3": 2714,
        "entropy-3": 11.159636032267525,
        "cond_entropy-3": 0.7755887573738856,
        "total_length-nopunct": 5375,
        "mean_pred_length-nopunct": 10.75,
        "std_pred_length-nopunct": 6.518243628463115,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.17488372093023255,
        "vocab_size-1-nopunct": 940,
        "unique-1-nopunct": 536,
        "entropy-1-nopunct": 7.90955907139392,
        "distinct-2-nopunct": 0.47405128205128205,
        "vocab_size-2-nopunct": 2311,
        "unique-2-nopunct": 1673,
        "entropy-2-nopunct": 10.222591417729413,
        "cond_entropy-2-nopunct": 2.438925524422056,
        "distinct-3-nopunct": 0.6635428571428571,
        "vocab_size-3-nopunct": 2903,
        "unique-3-nopunct": 2409,
        "entropy-3-nopunct": 10.950026220825997,
        "cond_entropy-3-nopunct": 0.7609915236693233,
        "msttr-100": 0.68656,
        "msttr-100_nopunct": 0.70925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 34.42582,
        "nist": 6.332393382667886,
        "rouge1": {
            "precision": 0.60387,
            "recall": 0.57093,
            "fmeasure": 0.57586
        },
        "rouge2": {
            "precision": 0.38188,
            "recall": 0.36114,
            "fmeasure": 0.36409
        },
        "rougeL": {
            "precision": 0.5465,
            "recall": 0.51574,
            "fmeasure": 0.52093
        },
        "rougeLsum": {
            "precision": 0.5465,
            "recall": 0.51574,
            "fmeasure": 0.52093
        },
        "local_recall": {
            "1": 0.5837303041407109
        },
        "meteor": 0.32611453415813507,
        "nubia": {
            "semantic_relation": 3.68528,
            "contradiction": 5.38314,
            "irrelevancy": 19.6275,
            "logical_agreement": 74.98936,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.5433,
            "nubia_score": 0.66687
        },
        "bleurt": -0.01739,
        "bertscore": {
            "precision": 0.88033,
            "recall": 0.87184,
            "f1": 0.87563
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 106,
        "total_length": 2096,
        "mean_pred_length": 19.77358490566038,
        "std_pred_length": 4.5251561400517035,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 35,
        "distinct-1": 0.4217557251908397,
        "vocab_size-1": 884,
        "unique-1": 658,
        "entropy-1": 8.273419327827224,
        "distinct-2": 0.8537688442211055,
        "vocab_size-2": 1699,
        "unique-2": 1555,
        "entropy-2": 10.544521339660374,
        "cond_entropy-2": 2.0597456405913035,
        "distinct-3": 0.9617834394904459,
        "vocab_size-3": 1812,
        "unique-3": 1759,
        "entropy-3": 10.793501473867444,
        "cond_entropy-3": 0.25979624398808754,
        "total_length-nopunct": 1953,
        "mean_pred_length-nopunct": 18.42452830188679,
        "std_pred_length-nopunct": 4.461466281535082,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.4500768049155146,
        "vocab_size-1-nopunct": 879,
        "unique-1-nopunct": 657,
        "entropy-1-nopunct": 8.418517640997502,
        "distinct-2-nopunct": 0.8538170005414185,
        "vocab_size-2-nopunct": 1577,
        "unique-2-nopunct": 1443,
        "entropy-2-nopunct": 10.435829451293428,
        "cond_entropy-2-nopunct": 2.1177133890168895,
        "distinct-3-nopunct": 0.9649626651349799,
        "vocab_size-3-nopunct": 1680,
        "unique-3-nopunct": 1632,
        "entropy-3-nopunct": 10.689216561461171,
        "cond_entropy-3-nopunct": 0.25826547027887187,
        "msttr-100": 0.7335,
        "msttr-100_nopunct": 0.75789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 10.75928,
        "nist": 3.4770161643289357,
        "rouge1": {
            "precision": 0.47303,
            "recall": 0.39484,
            "fmeasure": 0.42184
        },
        "rouge2": {
            "precision": 0.191,
            "recall": 0.15966,
            "fmeasure": 0.17055
        },
        "rougeL": {
            "precision": 0.37959,
            "recall": 0.31614,
            "fmeasure": 0.33778
        },
        "rougeLsum": {
            "precision": 0.37959,
            "recall": 0.31614,
            "fmeasure": 0.33778
        },
        "local_recall": {
            "1": 0.36801099908340973
        },
        "meteor": 0.18361243719660003,
        "nubia": {
            "semantic_relation": 3.12374,
            "contradiction": 19.41232,
            "irrelevancy": 58.31009,
            "logical_agreement": 22.27759,
            "grammar_ref": 3.63886,
            "grammar_hyp": 3.59064,
            "nubia_score": 0.47528
        },
        "bleurt": -0.26372,
        "bertscore": {
            "precision": 0.85577,
            "recall": 0.83392,
            "f1": 0.84442
        }
    },
    "schema_guided_dialog_challenge_test_nopunc_parent": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6713,
        "mean_pred_length": 13.426,
        "std_pred_length": 7.577105252007524,
        "median_pred_length": 12.0,
        "min_pred_length": 2,
        "max_pred_length": 42,
        "distinct-1": 0.15715775361239387,
        "vocab_size-1": 1055,
        "unique-1": 594,
        "entropy-1": 7.880457795862772,
        "distinct-2": 0.46547561564461615,
        "vocab_size-2": 2892,
        "unique-2": 2038,
        "entropy-2": 10.626220497727592,
        "cond_entropy-2": 2.5139854192227125,
        "distinct-3": 0.66112375284439,
        "vocab_size-3": 3777,
        "unique-3": 3043,
        "entropy-3": 11.42069635559453,
        "cond_entropy-3": 0.8266808102288409,
        "total_length-nopunct": 5900,
        "mean_pred_length-nopunct": 11.8,
        "std_pred_length-nopunct": 6.902753073955348,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.1769491525423729,
        "vocab_size-1-nopunct": 1044,
        "unique-1-nopunct": 593,
        "entropy-1-nopunct": 8.07416850193203,
        "distinct-2-nopunct": 0.48018518518518516,
        "vocab_size-2-nopunct": 2593,
        "unique-2-nopunct": 1862,
        "entropy-2-nopunct": 10.464721453033283,
        "cond_entropy-2-nopunct": 2.5254674550622296,
        "distinct-3-nopunct": 0.6780248928790042,
        "vocab_size-3-nopunct": 3323,
        "unique-3-nopunct": 2724,
        "entropy-3-nopunct": 11.240304336511649,
        "cond_entropy-3-nopunct": 0.8159832991942997,
        "msttr-100": 0.69478,
        "msttr-100_nopunct": 0.72051,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 33.3099,
        "nist": 6.385378812351633,
        "rouge1": {
            "precision": 0.60105,
            "recall": 0.55868,
            "fmeasure": 0.5671
        },
        "rouge2": {
            "precision": 0.3792,
            "recall": 0.34862,
            "fmeasure": 0.35548
        },
        "rougeL": {
            "precision": 0.53767,
            "recall": 0.49806,
            "fmeasure": 0.50657
        },
        "rougeLsum": {
            "precision": 0.53767,
            "recall": 0.49806,
            "fmeasure": 0.50657
        },
        "local_recall": {
            "1": 0.5726777759445636
        },
        "meteor": 0.32374025934658873,
        "nubia": {
            "semantic_relation": 3.75528,
            "contradiction": 6.09674,
            "irrelevancy": 19.3169,
            "logical_agreement": 74.58636,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.55854,
            "nubia_score": 0.6792
        },
        "bleurt": -0.02659,
        "bertscore": {
            "precision": 0.88068,
            "recall": 0.86858,
            "f1": 0.87412
        }
    },
    "schema_guided_dialog_challenge_test_scramble_parent": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6452,
        "mean_pred_length": 12.904,
        "std_pred_length": 7.204913878735817,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 42,
        "distinct-1": 0.15282083075015498,
        "vocab_size-1": 986,
        "unique-1": 529,
        "entropy-1": 7.810341631130033,
        "distinct-2": 0.4620295698924731,
        "vocab_size-2": 2750,
        "unique-2": 1880,
        "entropy-2": 10.583585616277631,
        "cond_entropy-2": 2.519521269373341,
        "distinct-3": 0.6658107116654439,
        "vocab_size-3": 3630,
        "unique-3": 2883,
        "entropy-3": 11.38470633935339,
        "cond_entropy-3": 0.8216290690829541,
        "total_length-nopunct": 5654,
        "mean_pred_length-nopunct": 11.308,
        "std_pred_length-nopunct": 6.530936839382234,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.17244428723027944,
        "vocab_size-1-nopunct": 975,
        "unique-1-nopunct": 527,
        "entropy-1-nopunct": 8.01634084657576,
        "distinct-2-nopunct": 0.4790454016298021,
        "vocab_size-2-nopunct": 2469,
        "unique-2-nopunct": 1733,
        "entropy-2-nopunct": 10.421817868301932,
        "cond_entropy-2-nopunct": 2.5402548404846867,
        "distinct-3-nopunct": 0.6805585392051557,
        "vocab_size-3-nopunct": 3168,
        "unique-3-nopunct": 2573,
        "entropy-3-nopunct": 11.183888953050056,
        "cond_entropy-3-nopunct": 0.8049166117824302,
        "msttr-100": 0.68984,
        "msttr-100_nopunct": 0.72089,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 32.18227,
        "nist": 6.240411394929657,
        "rouge1": {
            "precision": 0.59618,
            "recall": 0.55453,
            "fmeasure": 0.56404
        },
        "rouge2": {
            "precision": 0.36734,
            "recall": 0.34244,
            "fmeasure": 0.34768
        },
        "rougeL": {
            "precision": 0.53423,
            "recall": 0.49634,
            "fmeasure": 0.50511
        },
        "rougeLsum": {
            "precision": 0.53423,
            "recall": 0.49634,
            "fmeasure": 0.50511
        },
        "local_recall": {
            "1": 0.5702977112373085
        },
        "meteor": 0.3172809592950506,
        "nubia": {
            "semantic_relation": 3.64427,
            "contradiction": 6.71599,
            "irrelevancy": 20.51641,
            "logical_agreement": 72.7676,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.57073,
            "nubia_score": 0.65485
        },
        "bleurt": -0.06637,
        "bertscore": {
            "precision": 0.87569,
            "recall": 0.86505,
            "f1": 0.86994
        }
    },
    "xsum_challenge_test_backtranslation_parent": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 500,
        "total_length": 9812,
        "mean_pred_length": 19.624,
        "std_pred_length": 4.358282230420604,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 38,
        "distinct-1": 0.2728291887484713,
        "vocab_size-1": 2677,
        "unique-1": 1744,
        "entropy-1": 8.91566607177019,
        "distinct-2": 0.7159579037800687,
        "vocab_size-2": 6667,
        "unique-2": 5718,
        "entropy-2": 12.18819156928992,
        "cond_entropy-2": 3.025518825997821,
        "distinct-3": 0.9098955969133,
        "vocab_size-3": 8018,
        "unique-3": 7572,
        "entropy-3": 12.862382549939785,
        "cond_entropy-3": 0.6788843295831061,
        "total_length-nopunct": 9085,
        "mean_pred_length-nopunct": 18.17,
        "std_pred_length-nopunct": 4.152721998882178,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.2936708860759494,
        "vocab_size-1-nopunct": 2668,
        "unique-1-nopunct": 1744,
        "entropy-1-nopunct": 9.108505872522905,
        "distinct-2-nopunct": 0.7233546884100175,
        "vocab_size-2-nopunct": 6210,
        "unique-2-nopunct": 5340,
        "entropy-2-nopunct": 12.105106586849711,
        "cond_entropy-2-nopunct": 3.120045511435217,
        "distinct-3-nopunct": 0.9186147186147187,
        "vocab_size-3-nopunct": 7427,
        "unique-3-nopunct": 7030,
        "entropy-3-nopunct": 12.775065103167975,
        "cond_entropy-3-nopunct": 0.680451575875208,
        "msttr-100": 0.7249,
        "msttr-100_nopunct": 0.74878,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 11.48799,
        "nist": 3.9563992252317193,
        "rouge1": {
            "precision": 0.46073,
            "recall": 0.39488,
            "fmeasure": 0.41657
        },
        "rouge2": {
            "precision": 0.19058,
            "recall": 0.16408,
            "fmeasure": 0.17236
        },
        "rougeL": {
            "precision": 0.36622,
            "recall": 0.31459,
            "fmeasure": 0.33137
        },
        "rougeLsum": {
            "precision": 0.36622,
            "recall": 0.31459,
            "fmeasure": 0.33137
        },
        "local_recall": {
            "1": 0.36975639340948147
        },
        "meteor": 0.18301177710893576,
        "nubia": {
            "semantic_relation": 3.08697,
            "contradiction": 16.94052,
            "irrelevancy": 62.07996,
            "logical_agreement": 20.97951,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.64427,
            "nubia_score": 0.47026
        },
        "bleurt": -0.25341,
        "bertscore": {
            "precision": 0.84741,
            "recall": 0.82902,
            "f1": 0.83772
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 12,
        "total_length": 67,
        "mean_pred_length": 5.583333333333333,
        "std_pred_length": 1.1873172373979173,
        "median_pred_length": 5.0,
        "min_pred_length": 5,
        "max_pred_length": 9,
        "distinct-1": 0.417910447761194,
        "vocab_size-1": 28,
        "unique-1": 17,
        "entropy-1": 4.210006946744212,
        "distinct-2": 0.6909090909090909,
        "vocab_size-2": 38,
        "unique-2": 29,
        "entropy-2": 5.053376076846336,
        "cond_entropy-2": 0.466158892209556,
        "distinct-3": 0.7209302325581395,
        "vocab_size-3": 31,
        "unique-3": 25,
        "entropy-3": 4.7627920799816135,
        "cond_entropy-3": -0.30858333091558493,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 4.5,
        "std_pred_length-nopunct": 0.9574271077563381,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.48148148148148145,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.248628977716161,
        "distinct-2-nopunct": 0.6904761904761905,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.665428731993505,
        "cond_entropy-2-nopunct": 0.5829989159039974,
        "distinct-3-nopunct": 0.7333333333333333,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.272905595320056,
        "cond_entropy-3-nopunct": -0.4187601605035751,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 15.01797,
        "nist": 1.275514914576654,
        "rouge1": {
            "precision": 0.53095,
            "recall": 0.35899,
            "fmeasure": 0.42024
        },
        "rouge2": {
            "precision": 0.37222,
            "recall": 0.23795,
            "fmeasure": 0.28346
        },
        "rougeL": {
            "precision": 0.48929,
            "recall": 0.31733,
            "fmeasure": 0.37857
        },
        "rougeLsum": {
            "precision": 0.48929,
            "recall": 0.31733,
            "fmeasure": 0.37857
        },
        "local_recall": {
            "1": 0.2682926829268293
        },
        "meteor": 0.14696356678919595,
        "nubia": {
            "semantic_relation": 2.71716,
            "contradiction": 29.78837,
            "irrelevancy": 16.5758,
            "logical_agreement": 53.63583,
            "grammar_ref": 6.83527,
            "grammar_hyp": 7.33193,
            "nubia_score": 0.26616
        },
        "bleurt": -0.20329,
        "bertscore": {
            "precision": 0.90421,
            "recall": 0.8816,
            "f1": 0.89264
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 1177,
        "total_length": 26797,
        "mean_pred_length": 22.767204757858963,
        "std_pred_length": 11.449798598164643,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 106,
        "distinct-1": 0.044184050453408966,
        "vocab_size-1": 1184,
        "unique-1": 283,
        "entropy-1": 7.68485216700907,
        "distinct-2": 0.17205308352849336,
        "vocab_size-2": 4408,
        "unique-2": 1846,
        "entropy-2": 10.73483305593493,
        "cond_entropy-2": 2.881540852577281,
        "distinct-3": 0.32344638546823223,
        "vocab_size-3": 7906,
        "unique-3": 4391,
        "entropy-3": 11.961891320070224,
        "cond_entropy-3": 1.2888886730486666,
        "total_length-nopunct": 23444,
        "mean_pred_length-nopunct": 19.918436703483433,
        "std_pred_length-nopunct": 10.17636198160094,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 95,
        "distinct-1-nopunct": 0.0499914690325883,
        "vocab_size-1-nopunct": 1172,
        "unique-1-nopunct": 281,
        "entropy-1-nopunct": 7.944571147094224,
        "distinct-2-nopunct": 0.19010194458166793,
        "vocab_size-2-nopunct": 4233,
        "unique-2-nopunct": 1910,
        "entropy-2-nopunct": 10.660536334688151,
        "cond_entropy-2-nopunct": 2.8576365159861563,
        "distinct-3-nopunct": 0.3467520151730678,
        "vocab_size-3-nopunct": 7313,
        "unique-3-nopunct": 4273,
        "entropy-3-nopunct": 11.850766323955916,
        "cond_entropy-3-nopunct": 1.2360934827308665,
        "msttr-100": 0.63045,
        "msttr-100_nopunct": 0.66812,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 41.53078,
        "nist": 8.079571417445365,
        "rouge1": {
            "precision": 0.74045,
            "recall": 0.7274,
            "fmeasure": 0.72592
        },
        "rouge2": {
            "precision": 0.47403,
            "recall": 0.46423,
            "fmeasure": 0.46344
        },
        "rougeL": {
            "precision": 0.59131,
            "recall": 0.58029,
            "fmeasure": 0.57916
        },
        "rougeLsum": {
            "precision": 0.59131,
            "recall": 0.58029,
            "fmeasure": 0.57916
        },
        "local_recall": {
            "1": 0.21054976387775104,
            "2": 0.5536723163841808,
            "3": 0.8491439913985609,
            "4": 0.3,
            "5": 0.8275862068965517
        },
        "meteor": 0.36711985800105207,
        "nubia": {
            "semantic_relation": 4.3353,
            "contradiction": 10.33729,
            "irrelevancy": 9.67686,
            "logical_agreement": 79.98585,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.66465,
            "nubia_score": 0.75372
        },
        "bleurt": 0.16834,
        "bertscore": {
            "precision": 0.91475,
            "recall": 0.91377,
            "f1": 0.91275
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 183,
        "total_length": 2088,
        "mean_pred_length": 11.40983606557377,
        "std_pred_length": 1.6958037169288043,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 14,
        "distinct-1": 0.02346743295019157,
        "vocab_size-1": 49,
        "unique-1": 15,
        "entropy-1": 3.8181962786915298,
        "distinct-2": 0.03727034120734908,
        "vocab_size-2": 71,
        "unique-2": 27,
        "entropy-2": 4.247019443586413,
        "cond_entropy-2": 0.3994288383677218,
        "distinct-3": 0.03832752613240418,
        "vocab_size-3": 66,
        "unique-3": 25,
        "entropy-3": 4.111029520619121,
        "cond_entropy-3": -0.11879931717942491,
        "total_length-nopunct": 1433,
        "mean_pred_length-nopunct": 7.830601092896175,
        "std_pred_length-nopunct": 0.9965751019212236,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.03279832519190509,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.8652183574685433,
        "distinct-2-nopunct": 0.044,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 3.768844646900119,
        "cond_entropy-2-nopunct": -0.07878794512387251,
        "distinct-3-nopunct": 0.04498594189315839,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 3.5515681495528035,
        "cond_entropy-3-nopunct": -0.19324299171153983,
        "msttr-100": 0.183,
        "msttr-100_nopunct": 0.19071,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 5.31881,
        "nist": 0.8803667964640297,
        "rouge1": {
            "precision": 0.23991,
            "recall": 0.3943,
            "fmeasure": 0.28099
        },
        "rouge2": {
            "precision": 0.09863,
            "recall": 0.14846,
            "fmeasure": 0.10664
        },
        "rougeL": {
            "precision": 0.22536,
            "recall": 0.36986,
            "fmeasure": 0.26358
        },
        "rougeLsum": {
            "precision": 0.22536,
            "recall": 0.36986,
            "fmeasure": 0.26358
        },
        "local_recall": {
            "1": 0.16849451645064806
        },
        "meteor": 0.09401161380436565,
        "nubia": {
            "semantic_relation": 2.32489,
            "contradiction": 46.29827,
            "irrelevancy": 40.01762,
            "logical_agreement": 13.68412,
            "grammar_ref": 6.72681,
            "grammar_hyp": 6.23555,
            "nubia_score": 0.22825
        },
        "bleurt": -0.91633,
        "bertscore": {
            "precision": 0.81367,
            "recall": 0.86677,
            "f1": 0.83896
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 56,
        "total_length": 652,
        "mean_pred_length": 11.642857142857142,
        "std_pred_length": 5.459031086938713,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.30368098159509205,
        "vocab_size-1": 198,
        "unique-1": 115,
        "entropy-1": 6.363420613602699,
        "distinct-2": 0.6291946308724832,
        "vocab_size-2": 375,
        "unique-2": 274,
        "entropy-2": 8.205922765176785,
        "cond_entropy-2": 1.5702692849817153,
        "distinct-3": 0.7870370370370371,
        "vocab_size-3": 425,
        "unique-3": 347,
        "entropy-3": 8.571199266537821,
        "cond_entropy-3": 0.3862997538529793,
        "total_length-nopunct": 569,
        "mean_pred_length-nopunct": 10.160714285714286,
        "std_pred_length-nopunct": 5.105238156310934,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.3409490333919156,
        "vocab_size-1-nopunct": 194,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.482083477495828,
        "distinct-2-nopunct": 0.631578947368421,
        "vocab_size-2-nopunct": 324,
        "unique-2-nopunct": 236,
        "entropy-2-nopunct": 7.99297876079595,
        "cond_entropy-2-nopunct": 1.6447581276572258,
        "distinct-3-nopunct": 0.7855579868708972,
        "vocab_size-3-nopunct": 359,
        "unique-3-nopunct": 289,
        "entropy-3-nopunct": 8.334827926117269,
        "cond_entropy-3-nopunct": 0.3570194183378982,
        "msttr-100": 0.59833,
        "msttr-100_nopunct": 0.646,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 50.49617,
        "nist": 6.937587880993066,
        "rouge1": {
            "precision": 0.81348,
            "recall": 0.76933,
            "fmeasure": 0.78322
        },
        "rouge2": {
            "precision": 0.56464,
            "recall": 0.53889,
            "fmeasure": 0.5456
        },
        "rougeL": {
            "precision": 0.69031,
            "recall": 0.66487,
            "fmeasure": 0.67007
        },
        "rougeLsum": {
            "precision": 0.69031,
            "recall": 0.66487,
            "fmeasure": 0.67007
        },
        "local_recall": {
            "1": 0.1936416184971098,
            "2": 0.703125,
            "3": 0.8804347826086957
        },
        "meteor": 0.43608118363854376,
        "nubia": {
            "semantic_relation": 4.65393,
            "contradiction": 0.96341,
            "irrelevancy": 6.59317,
            "logical_agreement": 92.44341,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.37713,
            "nubia_score": 0.85332
        },
        "bleurt": 0.31991,
        "bertscore": {
            "precision": 0.9419,
            "recall": 0.94363,
            "f1": 0.94174
        }
    },
    "xsum_challenge_test_bfp_02_parent": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 500,
        "total_length": 9902,
        "mean_pred_length": 19.804,
        "std_pred_length": 4.443600342064979,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 35,
        "distinct-1": 0.27125833165017166,
        "vocab_size-1": 2686,
        "unique-1": 1757,
        "entropy-1": 8.898912831763912,
        "distinct-2": 0.7155924271431611,
        "vocab_size-2": 6728,
        "unique-2": 5829,
        "entropy-2": 12.180584909724248,
        "cond_entropy-2": 3.0378247024273817,
        "distinct-3": 0.9031678274545046,
        "vocab_size-3": 8040,
        "unique-3": 7575,
        "entropy-3": 12.852960630058444,
        "cond_entropy-3": 0.6797621731540289,
        "total_length-nopunct": 9207,
        "mean_pred_length-nopunct": 18.414,
        "std_pred_length-nopunct": 4.245774840944819,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.2906484196806777,
        "vocab_size-1-nopunct": 2676,
        "unique-1-nopunct": 1755,
        "entropy-1-nopunct": 9.07973264834721,
        "distinct-2-nopunct": 0.7206845067187321,
        "vocab_size-2-nopunct": 6275,
        "unique-2-nopunct": 5443,
        "entropy-2-nopunct": 12.094426882174195,
        "cond_entropy-2-nopunct": 3.1402007599170902,
        "distinct-3-nopunct": 0.910564152552699,
        "vocab_size-3-nopunct": 7473,
        "unique-3-nopunct": 7059,
        "entropy-3-nopunct": 12.768154600501719,
        "cond_entropy-3-nopunct": 0.6881082663436145,
        "msttr-100": 0.72323,
        "msttr-100_nopunct": 0.7463,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 10.55288,
        "nist": 3.79844266831166,
        "rouge1": {
            "precision": 0.45211,
            "recall": 0.38861,
            "fmeasure": 0.41013
        },
        "rouge2": {
            "precision": 0.18662,
            "recall": 0.15981,
            "fmeasure": 0.16865
        },
        "rougeL": {
            "precision": 0.3562,
            "recall": 0.30684,
            "fmeasure": 0.32346
        },
        "rougeLsum": {
            "precision": 0.3562,
            "recall": 0.30684,
            "fmeasure": 0.32346
        },
        "local_recall": {
            "1": 0.3609350237717908
        },
        "meteor": 0.1785227871316149,
        "nubia": {
            "semantic_relation": 3.08492,
            "contradiction": 17.07648,
            "irrelevancy": 61.25423,
            "logical_agreement": 21.66928,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.56488,
            "nubia_score": 0.47401
        },
        "bleurt": -0.25144,
        "bertscore": {
            "precision": 0.84672,
            "recall": 0.82745,
            "f1": 0.83664
        }
    },
    "xsum_challenge_test_bfp_05_parent": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 500,
        "total_length": 9870,
        "mean_pred_length": 19.74,
        "std_pred_length": 4.325783166086807,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 38,
        "distinct-1": 0.27082066869300914,
        "vocab_size-1": 2673,
        "unique-1": 1730,
        "entropy-1": 8.895291235008859,
        "distinct-2": 0.7093916755602988,
        "vocab_size-2": 6647,
        "unique-2": 5696,
        "entropy-2": 12.16350871413125,
        "cond_entropy-2": 3.023795521572745,
        "distinct-3": 0.9011273957158963,
        "vocab_size-3": 7993,
        "unique-3": 7509,
        "entropy-3": 12.848334667244869,
        "cond_entropy-3": 0.6933468888263895,
        "total_length-nopunct": 9174,
        "mean_pred_length-nopunct": 18.348,
        "std_pred_length-nopunct": 4.132662096034467,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.29027686941356007,
        "vocab_size-1-nopunct": 2663,
        "unique-1-nopunct": 1729,
        "entropy-1-nopunct": 9.077708387524842,
        "distinct-2-nopunct": 0.7163938206133272,
        "vocab_size-2-nopunct": 6214,
        "unique-2-nopunct": 5349,
        "entropy-2-nopunct": 12.075133408174112,
        "cond_entropy-2-nopunct": 3.1231801724185146,
        "distinct-3-nopunct": 0.9077563004648886,
        "vocab_size-3-nopunct": 7420,
        "unique-3-nopunct": 6992,
        "entropy-3-nopunct": 12.75476715137027,
        "cond_entropy-3-nopunct": 0.703025441651161,
        "msttr-100": 0.72276,
        "msttr-100_nopunct": 0.74648,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 11.46805,
        "nist": 3.951684933086567,
        "rouge1": {
            "precision": 0.45791,
            "recall": 0.39206,
            "fmeasure": 0.41416
        },
        "rouge2": {
            "precision": 0.19507,
            "recall": 0.16509,
            "fmeasure": 0.17499
        },
        "rougeL": {
            "precision": 0.36509,
            "recall": 0.3131,
            "fmeasure": 0.33039
        },
        "rougeLsum": {
            "precision": 0.36509,
            "recall": 0.3131,
            "fmeasure": 0.33039
        },
        "local_recall": {
            "1": 0.3681800079649542
        },
        "meteor": 0.18446934882878754,
        "nubia": {
            "semantic_relation": 3.06131,
            "contradiction": 18.46965,
            "irrelevancy": 59.0581,
            "logical_agreement": 22.47225,
            "grammar_ref": 3.79385,
            "grammar_hyp": 3.63288,
            "nubia_score": 0.46271
        },
        "bleurt": -0.2435,
        "bertscore": {
            "precision": 0.84987,
            "recall": 0.82875,
            "f1": 0.83881
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 28,
        "total_length": 307,
        "mean_pred_length": 10.964285714285714,
        "std_pred_length": 5.060224041180269,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.40390879478827363,
        "vocab_size-1": 124,
        "unique-1": 84,
        "entropy-1": 5.939514699760368,
        "distinct-2": 0.7670250896057348,
        "vocab_size-2": 214,
        "unique-2": 175,
        "entropy-2": 7.562944161182994,
        "cond_entropy-2": 1.3689806306466392,
        "distinct-3": 0.900398406374502,
        "vocab_size-3": 226,
        "unique-3": 207,
        "entropy-3": 7.7523421594939785,
        "cond_entropy-3": 0.21711940355374032,
        "total_length-nopunct": 270,
        "mean_pred_length-nopunct": 9.642857142857142,
        "std_pred_length-nopunct": 4.344243199867134,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.4444444444444444,
        "vocab_size-1-nopunct": 120,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.015182705053864,
        "distinct-2-nopunct": 0.756198347107438,
        "vocab_size-2-nopunct": 183,
        "unique-2-nopunct": 148,
        "entropy-2-nopunct": 7.327711790886326,
        "cond_entropy-2-nopunct": 1.4663880440125732,
        "distinct-3-nopunct": 0.897196261682243,
        "vocab_size-3-nopunct": 192,
        "unique-3-nopunct": 175,
        "entropy-3-nopunct": 7.515931180296024,
        "cond_entropy-3-nopunct": 0.23946835201790856,
        "msttr-100": 0.53667,
        "msttr-100_nopunct": 0.58,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 61.14314,
        "nist": 6.894843769360128,
        "rouge1": {
            "precision": 0.83783,
            "recall": 0.79895,
            "fmeasure": 0.80605
        },
        "rouge2": {
            "precision": 0.64486,
            "recall": 0.61124,
            "fmeasure": 0.61755
        },
        "rougeL": {
            "precision": 0.71683,
            "recall": 0.68025,
            "fmeasure": 0.68869
        },
        "rougeLsum": {
            "precision": 0.71683,
            "recall": 0.68025,
            "fmeasure": 0.68869
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6276595744680851,
            "3": 0.9111111111111111,
            "4": 1.0
        },
        "meteor": 0.43494474371147157,
        "nubia": {
            "semantic_relation": 4.34585,
            "contradiction": 14.80745,
            "irrelevancy": 3.61125,
            "logical_agreement": 81.58129,
            "grammar_ref": 4.67502,
            "grammar_hyp": 4.99609,
            "nubia_score": 0.73022
        },
        "bleurt": 0.32515,
        "bertscore": {
            "precision": 0.946,
            "recall": 0.93795,
            "f1": 0.94019
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 106,
        "total_length": 2139,
        "mean_pred_length": 20.17924528301887,
        "std_pred_length": 4.420785317862506,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 32,
        "distinct-1": 0.40813464235624125,
        "vocab_size-1": 873,
        "unique-1": 670,
        "entropy-1": 8.134840594737954,
        "distinct-2": 0.8204623708804722,
        "vocab_size-2": 1668,
        "unique-2": 1526,
        "entropy-2": 10.43991865360281,
        "cond_entropy-2": 2.1069451174449427,
        "distinct-3": 0.9590036325895174,
        "vocab_size-3": 1848,
        "unique-3": 1802,
        "entropy-3": 10.804818593737325,
        "cond_entropy-3": 0.37319250743854415,
        "total_length-nopunct": 1990,
        "mean_pred_length-nopunct": 18.77358490566038,
        "std_pred_length-nopunct": 4.236594883282467,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.43467336683417085,
        "vocab_size-1-nopunct": 865,
        "unique-1-nopunct": 667,
        "entropy-1-nopunct": 8.250135176802429,
        "distinct-2-nopunct": 0.8232484076433121,
        "vocab_size-2-nopunct": 1551,
        "unique-2-nopunct": 1419,
        "entropy-2-nopunct": 10.337085985599575,
        "cond_entropy-2-nopunct": 2.1906141226782383,
        "distinct-3-nopunct": 0.9634420697412823,
        "vocab_size-3-nopunct": 1713,
        "unique-3-nopunct": 1671,
        "entropy-3-nopunct": 10.703550591971212,
        "cond_entropy-3-nopunct": 0.3829523650760181,
        "msttr-100": 0.7181,
        "msttr-100_nopunct": 0.73211,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 9.81729,
        "nist": 3.4183633522272614,
        "rouge1": {
            "precision": 0.45534,
            "recall": 0.3891,
            "fmeasure": 0.41087
        },
        "rouge2": {
            "precision": 0.18472,
            "recall": 0.15674,
            "fmeasure": 0.16537
        },
        "rougeL": {
            "precision": 0.36658,
            "recall": 0.31362,
            "fmeasure": 0.33069
        },
        "rougeLsum": {
            "precision": 0.36658,
            "recall": 0.31362,
            "fmeasure": 0.33069
        },
        "local_recall": {
            "1": 0.35959221501390176
        },
        "meteor": 0.1755670928102328,
        "nubia": {
            "semantic_relation": 3.14031,
            "contradiction": 22.47433,
            "irrelevancy": 57.81092,
            "logical_agreement": 19.71475,
            "grammar_ref": 3.80483,
            "grammar_hyp": 3.60318,
            "nubia_score": 0.47608
        },
        "bleurt": -0.23876,
        "bertscore": {
            "precision": 0.84998,
            "recall": 0.83255,
            "f1": 0.84084
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 106,
        "total_length": 2135,
        "mean_pred_length": 20.141509433962263,
        "std_pred_length": 4.993276005667914,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 37,
        "distinct-1": 0.4215456674473068,
        "vocab_size-1": 900,
        "unique-1": 680,
        "entropy-1": 8.203181692366007,
        "distinct-2": 0.8482010842779695,
        "vocab_size-2": 1721,
        "unique-2": 1583,
        "entropy-2": 10.544522097078936,
        "cond_entropy-2": 2.1404499416564597,
        "distinct-3": 0.9719188767550702,
        "vocab_size-3": 1869,
        "unique-3": 1830,
        "entropy-3": 10.845438682564104,
        "cond_entropy-3": 0.31300480759068167,
        "total_length-nopunct": 1980,
        "mean_pred_length-nopunct": 18.67924528301887,
        "std_pred_length-nopunct": 4.679435480005505,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.45,
        "vocab_size-1-nopunct": 891,
        "unique-1-nopunct": 676,
        "entropy-1-nopunct": 8.334147631150293,
        "distinct-2-nopunct": 0.8500533617929562,
        "vocab_size-2-nopunct": 1593,
        "unique-2-nopunct": 1467,
        "entropy-2-nopunct": 10.431264047475723,
        "cond_entropy-2-nopunct": 2.2035484263951504,
        "distinct-3-nopunct": 0.9751131221719457,
        "vocab_size-3-nopunct": 1724,
        "unique-3-nopunct": 1690,
        "entropy-3-nopunct": 10.733098343899945,
        "cond_entropy-3-nopunct": 0.3125235799874137,
        "msttr-100": 0.72571,
        "msttr-100_nopunct": 0.74842,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 8.57596,
        "nist": 3.1751830661031923,
        "rouge1": {
            "precision": 0.40862,
            "recall": 0.35218,
            "fmeasure": 0.37261
        },
        "rouge2": {
            "precision": 0.15535,
            "recall": 0.13297,
            "fmeasure": 0.14097
        },
        "rougeL": {
            "precision": 0.31563,
            "recall": 0.27511,
            "fmeasure": 0.2895
        },
        "rougeLsum": {
            "precision": 0.31563,
            "recall": 0.27511,
            "fmeasure": 0.2895
        },
        "local_recall": {
            "1": 0.3322445170321979
        },
        "meteor": 0.1615793742923897,
        "nubia": {
            "semantic_relation": 2.97356,
            "contradiction": 16.79799,
            "irrelevancy": 61.62992,
            "logical_agreement": 21.57209,
            "grammar_ref": 3.75874,
            "grammar_hyp": 3.57368,
            "nubia_score": 0.4528
        },
        "bleurt": -0.26604,
        "bertscore": {
            "precision": 0.83798,
            "recall": 0.81668,
            "f1": 0.82694
        }
    },
    "xsum_challenge_test_nopunc_parent": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 500,
        "total_length": 9839,
        "mean_pred_length": 19.678,
        "std_pred_length": 4.599382132417353,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 38,
        "distinct-1": 0.27421485923366196,
        "vocab_size-1": 2698,
        "unique-1": 1787,
        "entropy-1": 8.924051373803369,
        "distinct-2": 0.7146375414926651,
        "vocab_size-2": 6674,
        "unique-2": 5727,
        "entropy-2": 12.18893788203245,
        "cond_entropy-2": 3.017515657638277,
        "distinct-3": 0.9075687294942867,
        "vocab_size-3": 8022,
        "unique-3": 7566,
        "entropy-3": 12.860091848716504,
        "cond_entropy-3": 0.6785493808334078,
        "total_length-nopunct": 9145,
        "mean_pred_length-nopunct": 18.29,
        "std_pred_length-nopunct": 4.400670403472635,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.2940404592673592,
        "vocab_size-1-nopunct": 2689,
        "unique-1-nopunct": 1787,
        "entropy-1-nopunct": 9.104817402831497,
        "distinct-2-nopunct": 0.719838056680162,
        "vocab_size-2-nopunct": 6223,
        "unique-2-nopunct": 5353,
        "entropy-2-nopunct": 12.096116279379528,
        "cond_entropy-2-nopunct": 3.1189624138073695,
        "distinct-3-nopunct": 0.9139349294045427,
        "vocab_size-3-nopunct": 7444,
        "unique-3-nopunct": 7035,
        "entropy-3-nopunct": 12.76846916065093,
        "cond_entropy-3-nopunct": 0.6893919394116266,
        "msttr-100": 0.72684,
        "msttr-100_nopunct": 0.74989,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 11.24902,
        "nist": 3.9332552579976072,
        "rouge1": {
            "precision": 0.45883,
            "recall": 0.392,
            "fmeasure": 0.414
        },
        "rouge2": {
            "precision": 0.19086,
            "recall": 0.16302,
            "fmeasure": 0.17191
        },
        "rougeL": {
            "precision": 0.36103,
            "recall": 0.30939,
            "fmeasure": 0.32608
        },
        "rougeLsum": {
            "precision": 0.36103,
            "recall": 0.30939,
            "fmeasure": 0.32608
        },
        "local_recall": {
            "1": 0.3680192848533548
        },
        "meteor": 0.18198384816419289,
        "nubia": {
            "semantic_relation": 3.06759,
            "contradiction": 18.06321,
            "irrelevancy": 58.06931,
            "logical_agreement": 23.86748,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.64407,
            "nubia_score": 0.46556
        },
        "bleurt": -0.26749,
        "bertscore": {
            "precision": 0.84862,
            "recall": 0.8275,
            "f1": 0.83755
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 453,
        "total_length": 5277,
        "mean_pred_length": 11.649006622516556,
        "std_pred_length": 4.598490983165233,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.17528898995641462,
        "vocab_size-1": 925,
        "unique-1": 475,
        "entropy-1": 7.589156208684906,
        "distinct-2": 0.45874792703150913,
        "vocab_size-2": 2213,
        "unique-2": 1490,
        "entropy-2": 10.346251486717666,
        "cond_entropy-2": 2.379917898450542,
        "distinct-3": 0.6490505605124686,
        "vocab_size-3": 2837,
        "unique-3": 2223,
        "entropy-3": 11.05816830008224,
        "cond_entropy-3": 0.8142913164495494,
        "total_length-nopunct": 4575,
        "mean_pred_length-nopunct": 10.099337748344372,
        "std_pred_length-nopunct": 3.9746797395037277,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.2,
        "vocab_size-1-nopunct": 915,
        "unique-1-nopunct": 472,
        "entropy-1-nopunct": 7.876012738210421,
        "distinct-2-nopunct": 0.44905385735080056,
        "vocab_size-2-nopunct": 1851,
        "unique-2-nopunct": 1249,
        "entropy-2-nopunct": 10.053837658229183,
        "cond_entropy-2-nopunct": 2.455323839957618,
        "distinct-3-nopunct": 0.6432270373398746,
        "vocab_size-3-nopunct": 2360,
        "unique-3-nopunct": 1846,
        "entropy-3-nopunct": 10.778674392366632,
        "cond_entropy-3-nopunct": 0.8431825295611274,
        "msttr-100": 0.54365,
        "msttr-100_nopunct": 0.574,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 55.25327,
        "nist": 8.9097068999064,
        "rouge1": {
            "precision": 0.79614,
            "recall": 0.77936,
            "fmeasure": 0.78036
        },
        "rouge2": {
            "precision": 0.57364,
            "recall": 0.55953,
            "fmeasure": 0.56066
        },
        "rougeL": {
            "precision": 0.70257,
            "recall": 0.68454,
            "fmeasure": 0.68679
        },
        "rougeLsum": {
            "precision": 0.70257,
            "recall": 0.68454,
            "fmeasure": 0.68679
        },
        "local_recall": {
            "1": 0.2226923076923077,
            "2": 0.6599496221662469,
            "3": 0.8854685377999094,
            "4": 0.9210526315789473
        },
        "meteor": 0.44586759728392006,
        "nubia": {
            "semantic_relation": 4.59536,
            "contradiction": 7.44551,
            "irrelevancy": 6.48183,
            "logical_agreement": 86.07266,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.16079,
            "nubia_score": 0.83238
        },
        "bleurt": 0.33964,
        "bertscore": {
            "precision": 0.94145,
            "recall": 0.94115,
            "f1": 0.94013
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 106,
        "total_length": 2090,
        "mean_pred_length": 19.71698113207547,
        "std_pred_length": 4.090381531729736,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.4229665071770335,
        "vocab_size-1": 884,
        "unique-1": 676,
        "entropy-1": 8.20921445679887,
        "distinct-2": 0.8472782258064516,
        "vocab_size-2": 1681,
        "unique-2": 1537,
        "entropy-2": 10.522260448332771,
        "cond_entropy-2": 2.1042597745245764,
        "distinct-3": 0.9696485623003195,
        "vocab_size-3": 1821,
        "unique-3": 1776,
        "entropy-3": 10.808477698564039,
        "cond_entropy-3": 0.2969603604042268,
        "total_length-nopunct": 1941,
        "mean_pred_length-nopunct": 18.31132075471698,
        "std_pred_length-nopunct": 3.856783310077194,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.45182895414734675,
        "vocab_size-1-nopunct": 877,
        "unique-1-nopunct": 675,
        "entropy-1-nopunct": 8.340952371110577,
        "distinct-2-nopunct": 0.8485013623978201,
        "vocab_size-2-nopunct": 1557,
        "unique-2-nopunct": 1426,
        "entropy-2-nopunct": 10.411688715671348,
        "cond_entropy-2-nopunct": 2.180986458103933,
        "distinct-3-nopunct": 0.9722382880277617,
        "vocab_size-3-nopunct": 1681,
        "unique-3-nopunct": 1642,
        "entropy-3-nopunct": 10.695491404372556,
        "cond_entropy-3-nopunct": 0.2949966112662042,
        "msttr-100": 0.7195,
        "msttr-100_nopunct": 0.74684,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 8.21591,
        "nist": 3.1517530793584343,
        "rouge1": {
            "precision": 0.43048,
            "recall": 0.36829,
            "fmeasure": 0.38882
        },
        "rouge2": {
            "precision": 0.15498,
            "recall": 0.13236,
            "fmeasure": 0.1395
        },
        "rougeL": {
            "precision": 0.3317,
            "recall": 0.28246,
            "fmeasure": 0.29841
        },
        "rougeLsum": {
            "precision": 0.3317,
            "recall": 0.28246,
            "fmeasure": 0.29841
        },
        "local_recall": {
            "1": 0.3345622119815668
        },
        "meteor": 0.16455637700574272,
        "nubia": {
            "semantic_relation": 2.93131,
            "contradiction": 17.59668,
            "irrelevancy": 66.0893,
            "logical_agreement": 16.31402,
            "grammar_ref": 3.78639,
            "grammar_hyp": 3.59132,
            "nubia_score": 0.42713
        },
        "bleurt": -0.2982,
        "bertscore": {
            "precision": 0.8382,
            "recall": 0.82228,
            "f1": 0.82987
        }
    },
    "xsum_val": {
        "predictions_file": "mT5_xl/xsum_val",
        "N": 1117,
        "total_length": 22574,
        "mean_pred_length": 20.2094897045658,
        "std_pred_length": 4.472033800271567,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.20147071852573759,
        "vocab_size-1": 4548,
        "unique-1": 2692,
        "entropy-1": 9.131891082245174,
        "distinct-2": 0.6270214848301253,
        "vocab_size-2": 13454,
        "unique-2": 11158,
        "entropy-2": 12.914836335285871,
        "cond_entropy-2": 3.5343176125361433,
        "distinct-3": 0.8557030481809242,
        "vocab_size-3": 17405,
        "unique-3": 16114,
        "entropy-3": 13.871034333599289,
        "cond_entropy-3": 0.9531497960154344,
        "total_length-nopunct": 20969,
        "mean_pred_length-nopunct": 18.77260519247986,
        "std_pred_length-nopunct": 4.2861231936606,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.21631932853259572,
        "vocab_size-1-nopunct": 4536,
        "unique-1-nopunct": 2690,
        "entropy-1-nopunct": 9.326638058721157,
        "distinct-2-nopunct": 0.6373161394317953,
        "vocab_size-2-nopunct": 12652,
        "unique-2-nopunct": 10552,
        "entropy-2-nopunct": 12.855935454019772,
        "cond_entropy-2-nopunct": 3.6535989555807813,
        "distinct-3-nopunct": 0.8683213237256472,
        "vocab_size-3-nopunct": 16268,
        "unique-3-nopunct": 15119,
        "entropy-3-nopunct": 13.810307287771032,
        "cond_entropy-3-nopunct": 0.962630444013226,
        "msttr-100": 0.72173,
        "msttr-100_nopunct": 0.74364,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_val.json",
        "bleu": 11.67493,
        "nist": 4.172520701520751,
        "rouge1": {
            "precision": 0.44634,
            "recall": 0.39546,
            "fmeasure": 0.41152
        },
        "rouge2": {
            "precision": 0.18528,
            "recall": 0.16514,
            "fmeasure": 0.17126
        },
        "rougeL": {
            "precision": 0.35244,
            "recall": 0.31284,
            "fmeasure": 0.32519
        },
        "rougeLsum": {
            "precision": 0.35244,
            "recall": 0.31284,
            "fmeasure": 0.32519
        },
        "local_recall": {
            "1": 0.373283339356704
        },
        "meteor": 0.18320913178692116,
        "nubia": {
            "semantic_relation": 3.09036,
            "contradiction": 16.55113,
            "irrelevancy": 63.74188,
            "logical_agreement": 19.70699,
            "grammar_ref": 3.8151,
            "grammar_hyp": 3.62268,
            "nubia_score": 0.4763
        },
        "bleurt": -0.27016,
        "bertscore": {
            "precision": 0.84468,
            "recall": 0.82965,
            "f1": 0.83679
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 267,
        "total_length": 2279,
        "mean_pred_length": 8.535580524344569,
        "std_pred_length": 2.405060196883216,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 18,
        "distinct-1": 0.14874945151382185,
        "vocab_size-1": 339,
        "unique-1": 167,
        "entropy-1": 6.1004375034239695,
        "distinct-2": 0.35984095427435386,
        "vocab_size-2": 724,
        "unique-2": 428,
        "entropy-2": 8.274061150405085,
        "cond_entropy-2": 1.7811047799272863,
        "distinct-3": 0.5065902578796562,
        "vocab_size-3": 884,
        "unique-3": 635,
        "entropy-3": 8.968500058714096,
        "cond_entropy-3": 0.9820205713222019,
        "total_length-nopunct": 1959,
        "mean_pred_length-nopunct": 7.337078651685394,
        "std_pred_length-nopunct": 2.1495256173355326,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.17151607963246554,
        "vocab_size-1-nopunct": 336,
        "unique-1-nopunct": 167,
        "entropy-1-nopunct": 6.287784368067546,
        "distinct-2-nopunct": 0.3185579196217494,
        "vocab_size-2-nopunct": 539,
        "unique-2-nopunct": 310,
        "entropy-2-nopunct": 7.736529915332123,
        "cond_entropy-2-nopunct": 2.0141650714750186,
        "distinct-3-nopunct": 0.4624561403508772,
        "vocab_size-3-nopunct": 659,
        "unique-3-nopunct": 469,
        "entropy-3-nopunct": 8.445168449645465,
        "cond_entropy-3-nopunct": 1.1565286079737762,
        "msttr-100": 0.47545,
        "msttr-100_nopunct": 0.51526,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 26.23231,
        "nist": 4.687089684506923,
        "rouge1": {
            "precision": 0.62276,
            "recall": 0.59577,
            "fmeasure": 0.59681
        },
        "rouge2": {
            "precision": 0.3818,
            "recall": 0.36869,
            "fmeasure": 0.36706
        },
        "rougeL": {
            "precision": 0.57048,
            "recall": 0.5453,
            "fmeasure": 0.54652
        },
        "rougeLsum": {
            "precision": 0.57048,
            "recall": 0.5453,
            "fmeasure": 0.54652
        },
        "local_recall": {
            "1": 0.5557768924302788
        },
        "meteor": 0.2857879124169959,
        "nubia": {
            "semantic_relation": 3.66578,
            "contradiction": 19.93673,
            "irrelevancy": 28.06734,
            "logical_agreement": 51.99593,
            "grammar_ref": 7.44295,
            "grammar_hyp": 7.63465,
            "nubia_score": 0.5434
        },
        "bleurt": -0.00072,
        "bertscore": {
            "precision": 0.91253,
            "recall": 0.9126,
            "f1": 0.91234
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 316,
        "total_length": 6557,
        "mean_pred_length": 20.75,
        "std_pred_length": 7.820220868388549,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 58,
        "distinct-1": 0.2298307152661278,
        "vocab_size-1": 1507,
        "unique-1": 726,
        "entropy-1": 8.553718284912604,
        "distinct-2": 0.5004005768306361,
        "vocab_size-2": 3123,
        "unique-2": 1986,
        "entropy-2": 10.985214165659531,
        "cond_entropy-2": 2.1949137118227044,
        "distinct-3": 0.6582278481012658,
        "vocab_size-3": 3900,
        "unique-3": 2858,
        "entropy-3": 11.631015512460184,
        "cond_entropy-3": 0.6638967951380275,
        "total_length-nopunct": 5382,
        "mean_pred_length-nopunct": 17.031645569620252,
        "std_pred_length-nopunct": 6.710959189375816,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.2788926049795615,
        "vocab_size-1-nopunct": 1501,
        "unique-1-nopunct": 726,
        "entropy-1-nopunct": 9.18951464243268,
        "distinct-2-nopunct": 0.5455981050138176,
        "vocab_size-2-nopunct": 2764,
        "unique-2-nopunct": 1848,
        "entropy-2-nopunct": 10.912527857888241,
        "cond_entropy-2-nopunct": 1.7887571751961777,
        "distinct-3-nopunct": 0.6947368421052632,
        "vocab_size-3-nopunct": 3300,
        "unique-3-nopunct": 2531,
        "entropy-3-nopunct": 11.418402130645864,
        "cond_entropy-3-nopunct": 0.5323022773974899,
        "msttr-100": 0.61954,
        "msttr-100_nopunct": 0.67906,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 49.71727,
        "nist": 8.838907450083761,
        "rouge1": {
            "precision": 0.39621,
            "recall": 0.39954,
            "fmeasure": 0.3946
        },
        "rouge2": {
            "precision": 0.2051,
            "recall": 0.20621,
            "fmeasure": 0.20348
        },
        "rougeL": {
            "precision": 0.38834,
            "recall": 0.39227,
            "fmeasure": 0.38696
        },
        "rougeLsum": {
            "precision": 0.38834,
            "recall": 0.39227,
            "fmeasure": 0.38696
        },
        "local_recall": {
            "1": 0.2839737582005623,
            "2": 0.6695610226724554,
            "3": 0.8964788732394366,
            "4": 1.0,
            "5": 0.9545454545454546,
            "6": 1.0,
            "7": 1.0
        },
        "meteor": 0.6553071506498993,
        "nubia": {
            "semantic_relation": 4.01874,
            "contradiction": 17.77022,
            "irrelevancy": 21.82716,
            "logical_agreement": 60.40262,
            "grammar_ref": 2.6064,
            "grammar_hyp": 2.57329,
            "nubia_score": 0.83752
        },
        "bleurt": 0.15831,
        "bertscore": {
            "precision": 0.95612,
            "recall": 0.95361,
            "f1": 0.95415
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 106,
        "total_length": 2034,
        "mean_pred_length": 19.18867924528302,
        "std_pred_length": 4.2584282855478675,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 32,
        "distinct-1": 0.41494591937069814,
        "vocab_size-1": 844,
        "unique-1": 647,
        "entropy-1": 8.133256574919411,
        "distinct-2": 0.8324688796680498,
        "vocab_size-2": 1605,
        "unique-2": 1464,
        "entropy-2": 10.424059381742767,
        "cond_entropy-2": 2.077974100932858,
        "distinct-3": 0.9566410537870472,
        "vocab_size-3": 1743,
        "unique-3": 1696,
        "entropy-3": 10.72761187991259,
        "cond_entropy-3": 0.31642376447026793,
        "total_length-nopunct": 1895,
        "mean_pred_length-nopunct": 17.87735849056604,
        "std_pred_length-nopunct": 3.975640046224619,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.441688654353562,
        "vocab_size-1-nopunct": 837,
        "unique-1-nopunct": 643,
        "entropy-1-nopunct": 8.26492054955316,
        "distinct-2-nopunct": 0.8328675237562885,
        "vocab_size-2-nopunct": 1490,
        "unique-2-nopunct": 1364,
        "entropy-2-nopunct": 10.310532985745919,
        "cond_entropy-2-nopunct": 2.1535586628859593,
        "distinct-3-nopunct": 0.958407605466429,
        "vocab_size-3-nopunct": 1613,
        "unique-3-nopunct": 1571,
        "entropy-3-nopunct": 10.61763172929999,
        "cond_entropy-3-nopunct": 0.3243134252175067,
        "msttr-100": 0.7185,
        "msttr-100_nopunct": 0.74389,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 8.32741,
        "nist": 3.0359813968417813,
        "rouge1": {
            "precision": 0.42263,
            "recall": 0.35098,
            "fmeasure": 0.37583
        },
        "rouge2": {
            "precision": 0.15906,
            "recall": 0.12645,
            "fmeasure": 0.13785
        },
        "rougeL": {
            "precision": 0.3245,
            "recall": 0.26847,
            "fmeasure": 0.28808
        },
        "rougeLsum": {
            "precision": 0.3245,
            "recall": 0.26847,
            "fmeasure": 0.28808
        },
        "local_recall": {
            "1": 0.32065727699530516
        },
        "meteor": 0.16041380083152518,
        "nubia": {
            "semantic_relation": 2.88308,
            "contradiction": 19.91372,
            "irrelevancy": 58.34946,
            "logical_agreement": 21.73682,
            "grammar_ref": 3.81724,
            "grammar_hyp": 3.61567,
            "nubia_score": 0.42209
        },
        "bleurt": -0.26478,
        "bertscore": {
            "precision": 0.83878,
            "recall": 0.81524,
            "f1": 0.82648
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 414,
        "total_length": 8393,
        "mean_pred_length": 20.27294685990338,
        "std_pred_length": 7.551139179635057,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 55,
        "distinct-1": 0.1388061479804599,
        "vocab_size-1": 1165,
        "unique-1": 434,
        "entropy-1": 7.929467285436925,
        "distinct-2": 0.3781175585913022,
        "vocab_size-2": 3017,
        "unique-2": 1720,
        "entropy-2": 10.723763348105978,
        "cond_entropy-2": 2.597943244121739,
        "distinct-3": 0.5574355584930601,
        "vocab_size-3": 4217,
        "unique-3": 2891,
        "entropy-3": 11.578973316319708,
        "cond_entropy-3": 0.9183146942141691,
        "total_length-nopunct": 7253,
        "mean_pred_length-nopunct": 17.519323671497585,
        "std_pred_length-nopunct": 6.466813350089717,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.15924445057217704,
        "vocab_size-1-nopunct": 1155,
        "unique-1-nopunct": 433,
        "entropy-1-nopunct": 8.266295598815526,
        "distinct-2-nopunct": 0.39596432226933764,
        "vocab_size-2-nopunct": 2708,
        "unique-2-nopunct": 1598,
        "entropy-2-nopunct": 10.599393817849824,
        "cond_entropy-2-nopunct": 2.483969773154362,
        "distinct-3-nopunct": 0.572295719844358,
        "vocab_size-3-nopunct": 3677,
        "unique-3-nopunct": 2572,
        "entropy-3-nopunct": 11.393950399599337,
        "cond_entropy-3-nopunct": 0.8434972457349733,
        "msttr-100": 0.5212,
        "msttr-100_nopunct": 0.54222,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 50.09871,
        "nist": 8.876535602924658,
        "rouge1": {
            "precision": 0.77043,
            "recall": 0.7609,
            "fmeasure": 0.75847
        },
        "rouge2": {
            "precision": 0.52704,
            "recall": 0.52045,
            "fmeasure": 0.51855
        },
        "rougeL": {
            "precision": 0.63573,
            "recall": 0.62866,
            "fmeasure": 0.62616
        },
        "rougeLsum": {
            "precision": 0.63573,
            "recall": 0.62866,
            "fmeasure": 0.62616
        },
        "local_recall": {
            "1": 0.21710713270815574,
            "2": 0.586639879457559,
            "3": 0.8927388535031847,
            "4": 0.8181818181818182,
            "5": 1.0
        },
        "meteor": 0.41128058257034494,
        "nubia": {
            "semantic_relation": 4.51479,
            "contradiction": 8.41972,
            "irrelevancy": 7.6126,
            "logical_agreement": 83.96768,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.58374,
            "nubia_score": 0.81312
        },
        "bleurt": 0.26385,
        "bertscore": {
            "precision": 0.92766,
            "recall": 0.92892,
            "f1": 0.92675
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 106,
        "total_length": 1952,
        "mean_pred_length": 18.41509433962264,
        "std_pred_length": 4.758047650447631,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 35,
        "distinct-1": 0.42366803278688525,
        "vocab_size-1": 827,
        "unique-1": 630,
        "entropy-1": 8.154283232315676,
        "distinct-2": 0.8401950162513543,
        "vocab_size-2": 1551,
        "unique-2": 1412,
        "entropy-2": 10.379742164031923,
        "cond_entropy-2": 2.001357282638285,
        "distinct-3": 0.9505747126436782,
        "vocab_size-3": 1654,
        "unique-3": 1593,
        "entropy-3": 10.65057962439082,
        "cond_entropy-3": 0.28707739997292064,
        "total_length-nopunct": 1812,
        "mean_pred_length-nopunct": 17.09433962264151,
        "std_pred_length-nopunct": 4.622603003305161,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.45364238410596025,
        "vocab_size-1-nopunct": 822,
        "unique-1-nopunct": 630,
        "entropy-1-nopunct": 8.292583437079514,
        "distinct-2-nopunct": 0.8370457209847597,
        "vocab_size-2-nopunct": 1428,
        "unique-2-nopunct": 1298,
        "entropy-2-nopunct": 10.252684705912491,
        "cond_entropy-2-nopunct": 2.077603008262292,
        "distinct-3-nopunct": 0.95125,
        "vocab_size-3-nopunct": 1522,
        "unique-3-nopunct": 1466,
        "entropy-3-nopunct": 10.531819701671136,
        "cond_entropy-3-nopunct": 0.29962385375604994,
        "msttr-100": 0.71684,
        "msttr-100_nopunct": 0.74056,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 7.47322,
        "nist": 2.5995576022802585,
        "rouge1": {
            "precision": 0.38283,
            "recall": 0.30977,
            "fmeasure": 0.33294
        },
        "rouge2": {
            "precision": 0.14269,
            "recall": 0.11287,
            "fmeasure": 0.1222
        },
        "rougeL": {
            "precision": 0.31183,
            "recall": 0.25251,
            "fmeasure": 0.27118
        },
        "rougeLsum": {
            "precision": 0.31183,
            "recall": 0.25251,
            "fmeasure": 0.27118
        },
        "local_recall": {
            "1": 0.2830739299610895
        },
        "meteor": 0.13645851495349196,
        "nubia": {
            "semantic_relation": 2.63454,
            "contradiction": 24.88942,
            "irrelevancy": 57.57932,
            "logical_agreement": 17.53126,
            "grammar_ref": 3.93729,
            "grammar_hyp": 3.71756,
            "nubia_score": 0.35832
        },
        "bleurt": -0.38735,
        "bertscore": {
            "precision": 0.83011,
            "recall": 0.80497,
            "f1": 0.81686
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_xl/e2e_nlg_test",
        "N": 5,
        "total_length": 56,
        "mean_pred_length": 11.2,
        "std_pred_length": 2.4,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 14,
        "distinct-1": 0.5535714285714286,
        "vocab_size-1": 31,
        "unique-1": 17,
        "entropy-1": 4.680222502793968,
        "distinct-2": 0.7058823529411765,
        "vocab_size-2": 36,
        "unique-2": 24,
        "entropy-2": 5.013412783649204,
        "cond_entropy-2": 0.28683071411638017,
        "distinct-3": 0.7608695652173914,
        "vocab_size-3": 35,
        "unique-3": 24,
        "entropy-3": 5.045301086491792,
        "cond_entropy-3": 0.06004184179066535,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.280350850198276,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.58,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.5814678801994475,
        "distinct-2-nopunct": 0.6888888888888889,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.789416641342193,
        "cond_entropy-2-nopunct": 0.2815474622066595,
        "distinct-3-nopunct": 0.75,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.821928094887361,
        "cond_entropy-3-nopunct": 0.07031601041860791,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 7.94206,
        "nist": 1.9199802520293814,
        "rouge1": {
            "precision": 0.50503,
            "recall": 0.45015,
            "fmeasure": 0.45965
        },
        "rouge2": {
            "precision": 0.22667,
            "recall": 0.19318,
            "fmeasure": 0.19838
        },
        "rougeL": {
            "precision": 0.47147,
            "recall": 0.4181,
            "fmeasure": 0.42687
        },
        "rougeLsum": {
            "precision": 0.47147,
            "recall": 0.4181,
            "fmeasure": 0.42687
        },
        "local_recall": {
            "1": 0.44642857142857145
        },
        "meteor": 0.20931535224707282,
        "nubia": {
            "semantic_relation": 2.82514,
            "contradiction": 37.15396,
            "irrelevancy": 62.02449,
            "logical_agreement": 0.82154,
            "grammar_ref": 5.06674,
            "grammar_hyp": 5.27176,
            "nubia_score": 0.313
        },
        "bleurt": -0.49688,
        "bertscore": {
            "precision": 0.85093,
            "recall": 0.82842,
            "f1": 0.83918
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 382,
        "total_length": 10046,
        "mean_pred_length": 26.298429319371728,
        "std_pred_length": 7.6947624564187205,
        "median_pred_length": 25.0,
        "min_pred_length": 9,
        "max_pred_length": 56,
        "distinct-1": 0.11029265379255425,
        "vocab_size-1": 1108,
        "unique-1": 308,
        "entropy-1": 7.937609535836536,
        "distinct-2": 0.320260761589404,
        "vocab_size-2": 3095,
        "unique-2": 1540,
        "entropy-2": 10.729937702176764,
        "cond_entropy-2": 2.639297602029507,
        "distinct-3": 0.49504417151475977,
        "vocab_size-3": 4595,
        "unique-3": 2924,
        "entropy-3": 11.63731438295808,
        "cond_entropy-3": 0.9503915584345656,
        "total_length-nopunct": 8888,
        "mean_pred_length-nopunct": 23.267015706806284,
        "std_pred_length-nopunct": 6.888180254584558,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.12364986498649864,
        "vocab_size-1-nopunct": 1099,
        "unique-1-nopunct": 306,
        "entropy-1-nopunct": 8.216761463394008,
        "distinct-2-nopunct": 0.33811427227839175,
        "vocab_size-2-nopunct": 2876,
        "unique-2-nopunct": 1514,
        "entropy-2-nopunct": 10.639692557366825,
        "cond_entropy-2-nopunct": 2.534929180253971,
        "distinct-3-nopunct": 0.5126784835056623,
        "vocab_size-3-nopunct": 4165,
        "unique-3-nopunct": 2737,
        "entropy-3-nopunct": 11.503604560316688,
        "cond_entropy-3-nopunct": 0.8954720649861302,
        "msttr-100": 0.4972,
        "msttr-100_nopunct": 0.51295,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 48.00951,
        "nist": 8.695668212797504,
        "rouge1": {
            "precision": 0.74881,
            "recall": 0.74839,
            "fmeasure": 0.74182
        },
        "rouge2": {
            "precision": 0.48595,
            "recall": 0.48382,
            "fmeasure": 0.47993
        },
        "rougeL": {
            "precision": 0.5857,
            "recall": 0.58598,
            "fmeasure": 0.58001
        },
        "rougeLsum": {
            "precision": 0.5857,
            "recall": 0.58598,
            "fmeasure": 0.58001
        },
        "local_recall": {
            "1": 0.22830141755782143,
            "2": 0.5881076388888888,
            "3": 0.8828478964401294,
            "4": 0.16666666666666666,
            "5": 0.7619047619047619
        },
        "meteor": 0.39330078620298503,
        "nubia": {
            "semantic_relation": 4.42492,
            "contradiction": 9.62561,
            "irrelevancy": 9.50192,
            "logical_agreement": 80.87247,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.34135,
            "nubia_score": 0.78727
        },
        "bleurt": 0.19834,
        "bertscore": {
            "precision": 0.91917,
            "recall": 0.91829,
            "f1": 0.91745
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 217,
        "total_length": 5256,
        "mean_pred_length": 24.22119815668203,
        "std_pred_length": 7.299195867735886,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 47,
        "distinct-1": 0.265220700152207,
        "vocab_size-1": 1394,
        "unique-1": 695,
        "entropy-1": 8.559256703024866,
        "distinct-2": 0.539392736654098,
        "vocab_size-2": 2718,
        "unique-2": 1715,
        "entropy-2": 10.929202000488562,
        "cond_entropy-2": 2.1665505773939033,
        "distinct-3": 0.6930734135213604,
        "vocab_size-3": 3342,
        "unique-3": 2448,
        "entropy-3": 11.475468944743326,
        "cond_entropy-3": 0.561066226854602,
        "total_length-nopunct": 4336,
        "mean_pred_length-nopunct": 19.981566820276498,
        "std_pred_length-nopunct": 6.331810650714595,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.319880073800738,
        "vocab_size-1-nopunct": 1387,
        "unique-1-nopunct": 693,
        "entropy-1-nopunct": 9.184869501094793,
        "distinct-2-nopunct": 0.5863073561544064,
        "vocab_size-2-nopunct": 2415,
        "unique-2-nopunct": 1590,
        "entropy-2-nopunct": 10.861447079009123,
        "cond_entropy-2-nopunct": 1.738670985239009,
        "distinct-3-nopunct": 0.7255253716043055,
        "vocab_size-3-nopunct": 2831,
        "unique-3-nopunct": 2154,
        "entropy-3-nopunct": 11.262237391046215,
        "cond_entropy-3-nopunct": 0.42537164044593323,
        "msttr-100": 0.62404,
        "msttr-100_nopunct": 0.68721,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 49.74041,
        "nist": 8.695329414437532,
        "rouge1": {
            "precision": 0.52806,
            "recall": 0.54077,
            "fmeasure": 0.52952
        },
        "rouge2": {
            "precision": 0.29205,
            "recall": 0.30334,
            "fmeasure": 0.29232
        },
        "rougeL": {
            "precision": 0.5067,
            "recall": 0.51966,
            "fmeasure": 0.50823
        },
        "rougeLsum": {
            "precision": 0.5067,
            "recall": 0.51966,
            "fmeasure": 0.50823
        },
        "local_recall": {
            "1": 0.27269938650306746,
            "2": 0.6418006430868167,
            "3": 0.8855465884079237,
            "4": 1.0
        },
        "meteor": 0.6413551838800895,
        "nubia": {
            "semantic_relation": 3.95524,
            "contradiction": 18.43474,
            "irrelevancy": 23.50337,
            "logical_agreement": 58.06189,
            "grammar_ref": 2.56565,
            "grammar_hyp": 2.52086,
            "nubia_score": 0.82299
        },
        "bleurt": 0.1277,
        "bertscore": {
            "precision": 0.9521,
            "recall": 0.94909,
            "f1": 0.94979
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 143,
        "total_length": 4476,
        "mean_pred_length": 31.3006993006993,
        "std_pred_length": 10.087058082995249,
        "median_pred_length": 28.0,
        "min_pred_length": 14,
        "max_pred_length": 68,
        "distinct-1": 0.25491510277033064,
        "vocab_size-1": 1141,
        "unique-1": 507,
        "entropy-1": 8.425996671772964,
        "distinct-2": 0.5098084468036003,
        "vocab_size-2": 2209,
        "unique-2": 1257,
        "entropy-2": 10.679227501779367,
        "cond_entropy-2": 2.108986392341348,
        "distinct-3": 0.6391408114558472,
        "vocab_size-3": 2678,
        "unique-3": 1793,
        "entropy-3": 11.12725735813118,
        "cond_entropy-3": 0.45675387995500805,
        "total_length-nopunct": 3651,
        "mean_pred_length-nopunct": 25.53146853146853,
        "std_pred_length-nopunct": 8.01467552166282,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.3108737332237743,
        "vocab_size-1-nopunct": 1135,
        "unique-1-nopunct": 507,
        "entropy-1-nopunct": 9.06513108979927,
        "distinct-2-nopunct": 0.5513112884834663,
        "vocab_size-2-nopunct": 1934,
        "unique-2-nopunct": 1158,
        "entropy-2-nopunct": 10.565715910807475,
        "cond_entropy-2-nopunct": 1.5396626724031854,
        "distinct-3-nopunct": 0.6722139673105498,
        "vocab_size-3-nopunct": 2262,
        "unique-3-nopunct": 1585,
        "entropy-3-nopunct": 10.922478381466137,
        "cond_entropy-3-nopunct": 0.36760911705171573,
        "msttr-100": 0.63386,
        "msttr-100_nopunct": 0.70028,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 52.9821,
        "nist": 8.834386215978881,
        "rouge1": {
            "precision": 0.57148,
            "recall": 0.56619,
            "fmeasure": 0.56489
        },
        "rouge2": {
            "precision": 0.37622,
            "recall": 0.36773,
            "fmeasure": 0.36794
        },
        "rougeL": {
            "precision": 0.52987,
            "recall": 0.52406,
            "fmeasure": 0.52288
        },
        "rougeLsum": {
            "precision": 0.52987,
            "recall": 0.52406,
            "fmeasure": 0.52288
        },
        "local_recall": {
            "1": 0.2816737698566447,
            "2": 0.6775732788002726,
            "3": 0.8922495274102079
        },
        "meteor": 0.6566443342450767,
        "nubia": {
            "semantic_relation": 3.94621,
            "contradiction": 19.25558,
            "irrelevancy": 22.62343,
            "logical_agreement": 58.12098,
            "grammar_ref": 2.5384,
            "grammar_hyp": 2.51967,
            "nubia_score": 0.83556
        },
        "bleurt": 0.13173,
        "bertscore": {
            "precision": 0.95384,
            "recall": 0.95165,
            "f1": 0.95252
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 56,
        "total_length": 1961,
        "mean_pred_length": 35.017857142857146,
        "std_pred_length": 9.984793923455685,
        "median_pred_length": 32.0,
        "min_pred_length": 17,
        "max_pred_length": 73,
        "distinct-1": 0.33044365119836816,
        "vocab_size-1": 648,
        "unique-1": 356,
        "entropy-1": 7.985092977737969,
        "distinct-2": 0.6173228346456693,
        "vocab_size-2": 1176,
        "unique-2": 809,
        "entropy-2": 9.861305739490072,
        "cond_entropy-2": 1.7586814595684446,
        "distinct-3": 0.7517577068685776,
        "vocab_size-3": 1390,
        "unique-3": 1087,
        "entropy-3": 10.255169463762309,
        "cond_entropy-3": 0.3968572431561952,
        "total_length-nopunct": 1647,
        "mean_pred_length-nopunct": 29.410714285714285,
        "std_pred_length-nopunct": 8.278148485436752,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.38919247115968425,
        "vocab_size-1-nopunct": 641,
        "unique-1-nopunct": 356,
        "entropy-1-nopunct": 8.43280491249235,
        "distinct-2-nopunct": 0.6574481458202388,
        "vocab_size-2-nopunct": 1046,
        "unique-2-nopunct": 741,
        "entropy-2-nopunct": 9.748936522276031,
        "cond_entropy-2-nopunct": 1.33982029476467,
        "distinct-3-nopunct": 0.7791530944625407,
        "vocab_size-3-nopunct": 1196,
        "unique-3-nopunct": 960,
        "entropy-3-nopunct": 10.057706857577962,
        "cond_entropy-3-nopunct": 0.3247736134688131,
        "msttr-100": 0.62579,
        "msttr-100_nopunct": 0.66938,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 53.25727,
        "nist": 8.388509273768681,
        "rouge1": {
            "precision": 0.83825,
            "recall": 0.81826,
            "fmeasure": 0.82383
        },
        "rouge2": {
            "precision": 0.62683,
            "recall": 0.61896,
            "fmeasure": 0.61913
        },
        "rougeL": {
            "precision": 0.75866,
            "recall": 0.74214,
            "fmeasure": 0.74571
        },
        "rougeLsum": {
            "precision": 0.75866,
            "recall": 0.74214,
            "fmeasure": 0.74571
        },
        "local_recall": {
            "1": 0.26905417814508725,
            "2": 0.6534181240063593,
            "3": 0.9065255731922398
        },
        "meteor": 0.6451891975288743,
        "nubia": {
            "semantic_relation": 3.77244,
            "contradiction": 18.04203,
            "irrelevancy": 24.5524,
            "logical_agreement": 57.40557,
            "grammar_ref": 2.50981,
            "grammar_hyp": 2.461,
            "nubia_score": 0.84496
        },
        "bleurt": 0.14934,
        "bertscore": {
            "precision": 0.95211,
            "recall": 0.94919,
            "f1": 0.95011
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 251,
        "total_length": 8345,
        "mean_pred_length": 33.24701195219124,
        "std_pred_length": 10.051795197331677,
        "median_pred_length": 32.0,
        "min_pred_length": 12,
        "max_pred_length": 65,
        "distinct-1": 0.11084481725584182,
        "vocab_size-1": 925,
        "unique-1": 240,
        "entropy-1": 7.858639169197237,
        "distinct-2": 0.3096120583148011,
        "vocab_size-2": 2506,
        "unique-2": 1212,
        "entropy-2": 10.445760476221416,
        "cond_entropy-2": 2.4672538959840673,
        "distinct-3": 0.45620298355221217,
        "vocab_size-3": 3578,
        "unique-3": 2187,
        "entropy-3": 11.190112221152512,
        "cond_entropy-3": 0.7771176447946395,
        "total_length-nopunct": 7347,
        "mean_pred_length-nopunct": 29.270916334661354,
        "std_pred_length-nopunct": 8.995700099262349,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.1246767388049544,
        "vocab_size-1-nopunct": 916,
        "unique-1-nopunct": 240,
        "entropy-1-nopunct": 8.136979939454406,
        "distinct-2-nopunct": 0.330467869222097,
        "vocab_size-2-nopunct": 2345,
        "unique-2-nopunct": 1211,
        "entropy-2-nopunct": 10.380317921972416,
        "cond_entropy-2-nopunct": 2.3234669568090616,
        "distinct-3-nopunct": 0.4752373995617239,
        "vocab_size-3-nopunct": 3253,
        "unique-3-nopunct": 2079,
        "entropy-3-nopunct": 11.063295108012577,
        "cond_entropy-3-nopunct": 0.7039903346135964,
        "msttr-100": 0.50205,
        "msttr-100_nopunct": 0.51082,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 49.25359,
        "nist": 8.602417862123811,
        "rouge1": {
            "precision": 0.75878,
            "recall": 0.73615,
            "fmeasure": 0.74036
        },
        "rouge2": {
            "precision": 0.48524,
            "recall": 0.47129,
            "fmeasure": 0.47346
        },
        "rougeL": {
            "precision": 0.56078,
            "recall": 0.5466,
            "fmeasure": 0.5481
        },
        "rougeLsum": {
            "precision": 0.56078,
            "recall": 0.5466,
            "fmeasure": 0.5481
        },
        "local_recall": {
            "1": 0.23937722997080765,
            "2": 0.6312796208530805,
            "3": 0.8932203389830509
        },
        "meteor": 0.38872970840003,
        "nubia": {
            "semantic_relation": 4.4016,
            "contradiction": 6.92562,
            "irrelevancy": 8.57223,
            "logical_agreement": 84.50215,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.24204,
            "nubia_score": 0.77817
        },
        "bleurt": 0.172,
        "bertscore": {
            "precision": 0.91749,
            "recall": 0.91334,
            "f1": 0.91428
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 297,
        "total_length": 3254,
        "mean_pred_length": 10.956228956228957,
        "std_pred_length": 2.7490010284919415,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.11770129071911493,
        "vocab_size-1": 383,
        "unique-1": 159,
        "entropy-1": 6.839603809411458,
        "distinct-2": 0.30267162664863034,
        "vocab_size-2": 895,
        "unique-2": 514,
        "entropy-2": 8.682952836964924,
        "cond_entropy-2": 1.499520961857778,
        "distinct-3": 0.45864661654135336,
        "vocab_size-3": 1220,
        "unique-3": 846,
        "entropy-3": 9.325782823580322,
        "cond_entropy-3": 0.63439914434829,
        "total_length-nopunct": 2806,
        "mean_pred_length-nopunct": 9.447811447811448,
        "std_pred_length-nopunct": 2.49406101129953,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.13506771204561654,
        "vocab_size-1-nopunct": 379,
        "unique-1-nopunct": 159,
        "entropy-1-nopunct": 7.087218861872469,
        "distinct-2-nopunct": 0.3104822638501395,
        "vocab_size-2-nopunct": 779,
        "unique-2-nopunct": 443,
        "entropy-2-nopunct": 8.539225408402226,
        "cond_entropy-2-nopunct": 1.5424874478513548,
        "distinct-3-nopunct": 0.4783001808318264,
        "vocab_size-3-nopunct": 1058,
        "unique-3-nopunct": 752,
        "entropy-3-nopunct": 9.145615291108957,
        "cond_entropy-3-nopunct": 0.6873944195712252,
        "msttr-100": 0.6075,
        "msttr-100_nopunct": 0.64536,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 18.00966,
        "nist": 3.7507101609247466,
        "rouge1": {
            "precision": 0.52206,
            "recall": 0.50489,
            "fmeasure": 0.50158
        },
        "rouge2": {
            "precision": 0.28638,
            "recall": 0.27968,
            "fmeasure": 0.27666
        },
        "rougeL": {
            "precision": 0.46351,
            "recall": 0.44916,
            "fmeasure": 0.44632
        },
        "rougeLsum": {
            "precision": 0.46351,
            "recall": 0.44916,
            "fmeasure": 0.44632
        },
        "local_recall": {
            "1": 0.45302865433442147
        },
        "meteor": 0.22991482733670612,
        "nubia": {
            "semantic_relation": 3.39348,
            "contradiction": 19.47923,
            "irrelevancy": 32.85539,
            "logical_agreement": 47.66537,
            "grammar_ref": 6.65825,
            "grammar_hyp": 6.67314,
            "nubia_score": 0.4939
        },
        "bleurt": -0.17963,
        "bertscore": {
            "precision": 0.89999,
            "recall": 0.89734,
            "f1": 0.89846
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 19,
        "total_length": 743,
        "mean_pred_length": 39.10526315789474,
        "std_pred_length": 7.545613831136778,
        "median_pred_length": 38.0,
        "min_pred_length": 22,
        "max_pred_length": 50,
        "distinct-1": 0.2920592193808883,
        "vocab_size-1": 217,
        "unique-1": 91,
        "entropy-1": 6.789798129865245,
        "distinct-2": 0.49171270718232046,
        "vocab_size-2": 356,
        "unique-2": 189,
        "entropy-2": 8.146360271102232,
        "cond_entropy-2": 1.279800958426694,
        "distinct-3": 0.5943262411347517,
        "vocab_size-3": 419,
        "unique-3": 264,
        "entropy-3": 8.463215832695687,
        "cond_entropy-3": 0.3182577284727779,
        "total_length-nopunct": 640,
        "mean_pred_length-nopunct": 33.68421052631579,
        "std_pred_length-nopunct": 6.989109058339474,
        "median_pred_length-nopunct": 34.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.334375,
        "vocab_size-1-nopunct": 214,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 7.005606307876727,
        "distinct-2-nopunct": 0.5201288244766505,
        "vocab_size-2-nopunct": 323,
        "unique-2-nopunct": 179,
        "entropy-2-nopunct": 8.033125426555035,
        "cond_entropy-2-nopunct": 1.0453672239101284,
        "distinct-3-nopunct": 0.6112956810631229,
        "vocab_size-3-nopunct": 368,
        "unique-3-nopunct": 243,
        "entropy-3-nopunct": 8.269578696221974,
        "cond_entropy-3-nopunct": 0.24861490853528764,
        "msttr-100": 0.60857,
        "msttr-100_nopunct": 0.62833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 59.75221,
        "nist": 7.583047933318105,
        "rouge1": {
            "precision": 0.91992,
            "recall": 0.91089,
            "fmeasure": 0.9075
        },
        "rouge2": {
            "precision": 0.58626,
            "recall": 0.61015,
            "fmeasure": 0.59139
        },
        "rougeL": {
            "precision": 0.84854,
            "recall": 0.83692,
            "fmeasure": 0.83495
        },
        "rougeLsum": {
            "precision": 0.84854,
            "recall": 0.83692,
            "fmeasure": 0.83495
        },
        "local_recall": {
            "1": 0.39322033898305087,
            "2": 0.6992481203007519,
            "3": 0.9455445544554455
        },
        "meteor": 0.7243038869652758,
        "nubia": {
            "semantic_relation": 3.6861,
            "contradiction": 23.51828,
            "irrelevancy": 24.42809,
            "logical_agreement": 52.05364,
            "grammar_ref": 2.51721,
            "grammar_hyp": 2.50522,
            "nubia_score": 0.84314
        },
        "bleurt": 0.1567,
        "bertscore": {
            "precision": 0.95753,
            "recall": 0.95534,
            "f1": 0.95634
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_xl/e2e_nlg_test",
        "N": 120,
        "total_length": 1626,
        "mean_pred_length": 13.55,
        "std_pred_length": 5.873457244247207,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.06949569495694957,
        "vocab_size-1": 113,
        "unique-1": 11,
        "entropy-1": 5.526052862350575,
        "distinct-2": 0.13147410358565736,
        "vocab_size-2": 198,
        "unique-2": 23,
        "entropy-2": 6.743952349223977,
        "cond_entropy-2": 1.0801318651454983,
        "distinct-3": 0.1738816738816739,
        "vocab_size-3": 241,
        "unique-3": 37,
        "entropy-3": 7.266311871342412,
        "cond_entropy-3": 0.5994064861844812,
        "total_length-nopunct": 1481,
        "mean_pred_length-nopunct": 12.341666666666667,
        "std_pred_length-nopunct": 5.586435705249716,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.07562457798784605,
        "vocab_size-1-nopunct": 112,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 5.590914605113424,
        "distinct-2-nopunct": 0.13005143277002204,
        "vocab_size-2-nopunct": 177,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 6.5549875371358555,
        "cond_entropy-2-nopunct": 1.113056049554689,
        "distinct-3-nopunct": 0.17647058823529413,
        "vocab_size-3-nopunct": 219,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 7.111939566141762,
        "cond_entropy-3-nopunct": 0.6359977365051166,
        "msttr-100": 0.28125,
        "msttr-100_nopunct": 0.29143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 24.72476,
        "nist": 4.157546741823049,
        "rouge1": {
            "precision": 0.69476,
            "recall": 0.63316,
            "fmeasure": 0.63234
        },
        "rouge2": {
            "precision": 0.43387,
            "recall": 0.39118,
            "fmeasure": 0.38964
        },
        "rougeL": {
            "precision": 0.56261,
            "recall": 0.51082,
            "fmeasure": 0.50959
        },
        "rougeLsum": {
            "precision": 0.56261,
            "recall": 0.51082,
            "fmeasure": 0.50959
        },
        "local_recall": {
            "1": 0.6055962691538974
        },
        "meteor": 0.3056219197862966,
        "nubia": {
            "semantic_relation": 3.97424,
            "contradiction": 6.13252,
            "irrelevancy": 33.42893,
            "logical_agreement": 60.43854,
            "grammar_ref": 5.42765,
            "grammar_hyp": 5.12971,
            "nubia_score": 0.66269
        },
        "bleurt": -0.07883,
        "bertscore": {
            "precision": 0.90536,
            "recall": 0.88466,
            "f1": 0.894
        }
    },
    "e2e_nlg_challenge_test_scramble_parent": {
        "predictions_file": "mT5_xl/e2e_nlg_test",
        "N": 500,
        "total_length": 12415,
        "mean_pred_length": 24.83,
        "std_pred_length": 7.1381440164793535,
        "median_pred_length": 24.0,
        "min_pred_length": 8,
        "max_pred_length": 43,
        "distinct-1": 0.01369311316955296,
        "vocab_size-1": 170,
        "unique-1": 33,
        "entropy-1": 5.803143590003721,
        "distinct-2": 0.04381032312211498,
        "vocab_size-2": 522,
        "unique-2": 154,
        "entropy-2": 7.44341224634968,
        "cond_entropy-2": 1.5516889029181236,
        "distinct-3": 0.08427507665352606,
        "vocab_size-3": 962,
        "unique-3": 322,
        "entropy-3": 8.440846099685904,
        "cond_entropy-3": 1.0182464508419173,
        "total_length-nopunct": 11353,
        "mean_pred_length-nopunct": 22.706,
        "std_pred_length-nopunct": 6.538773891181741,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.014797850788337884,
        "vocab_size-1-nopunct": 168,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.851703672579705,
        "distinct-2-nopunct": 0.04570164931355385,
        "vocab_size-2-nopunct": 496,
        "unique-2-nopunct": 141,
        "entropy-2-nopunct": 7.418426871579663,
        "cond_entropy-2-nopunct": 1.6047760151042492,
        "distinct-3-nopunct": 0.0896358543417367,
        "vocab_size-3-nopunct": 928,
        "unique-3-nopunct": 300,
        "entropy-3-nopunct": 8.46924209444376,
        "cond_entropy-3-nopunct": 1.0474530147189656,
        "msttr-100": 0.47476,
        "msttr-100_nopunct": 0.48301,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 32.54835,
        "nist": 5.42828502834582,
        "rouge1": {
            "precision": 0.76593,
            "recall": 0.71937,
            "fmeasure": 0.73221
        },
        "rouge2": {
            "precision": 0.46866,
            "recall": 0.43945,
            "fmeasure": 0.44734
        },
        "rougeL": {
            "precision": 0.54608,
            "recall": 0.51144,
            "fmeasure": 0.52111
        },
        "rougeLsum": {
            "precision": 0.54608,
            "recall": 0.51144,
            "fmeasure": 0.52111
        },
        "local_recall": {
            "1": 0.717567190551474
        },
        "meteor": 0.3700084774923807,
        "nubia": {
            "semantic_relation": 4.40699,
            "contradiction": 3.35169,
            "irrelevancy": 13.07796,
            "logical_agreement": 83.57035,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.41881,
            "nubia_score": 0.82058
        },
        "bleurt": 0.22795,
        "bertscore": {
            "precision": 0.92256,
            "recall": 0.90728,
            "f1": 0.91458
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 158,
        "total_length": 5995,
        "mean_pred_length": 37.94303797468354,
        "std_pred_length": 11.81944529042042,
        "median_pred_length": 35.5,
        "min_pred_length": 17,
        "max_pred_length": 73,
        "distinct-1": 0.1336113427856547,
        "vocab_size-1": 801,
        "unique-1": 203,
        "entropy-1": 7.750325378089932,
        "distinct-2": 0.3484666780880589,
        "vocab_size-2": 2034,
        "unique-2": 989,
        "entropy-2": 10.25783193258026,
        "cond_entropy-2": 2.4071202250676973,
        "distinct-3": 0.49938369431237895,
        "vocab_size-3": 2836,
        "unique-3": 1774,
        "entropy-3": 10.961353757556866,
        "cond_entropy-3": 0.7286351180841903,
        "total_length-nopunct": 5302,
        "mean_pred_length-nopunct": 33.55696202531646,
        "std_pred_length-nopunct": 10.661354362681093,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.14937759336099585,
        "vocab_size-1-nopunct": 792,
        "unique-1-nopunct": 202,
        "entropy-1-nopunct": 7.9967165635304625,
        "distinct-2-nopunct": 0.3724727838258165,
        "vocab_size-2-nopunct": 1916,
        "unique-2-nopunct": 984,
        "entropy-2-nopunct": 10.220503665960257,
        "cond_entropy-2-nopunct": 2.2930085202393258,
        "distinct-3-nopunct": 0.5220617729643,
        "vocab_size-3-nopunct": 2603,
        "unique-3-nopunct": 1691,
        "entropy-3-nopunct": 10.860306071388926,
        "cond_entropy-3-nopunct": 0.6583390496461204,
        "msttr-100": 0.52237,
        "msttr-100_nopunct": 0.53925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 46.84984,
        "nist": 8.258814623196209,
        "rouge1": {
            "precision": 0.74067,
            "recall": 0.70052,
            "fmeasure": 0.71486
        },
        "rouge2": {
            "precision": 0.45519,
            "recall": 0.43031,
            "fmeasure": 0.43894
        },
        "rougeL": {
            "precision": 0.52521,
            "recall": 0.50164,
            "fmeasure": 0.50895
        },
        "rougeLsum": {
            "precision": 0.52521,
            "recall": 0.50164,
            "fmeasure": 0.50895
        },
        "local_recall": {
            "1": 0.24528301886792453,
            "2": 0.5214408233276158,
            "3": 0.8746003552397869
        },
        "meteor": 0.368556408219138,
        "nubia": {
            "semantic_relation": 4.29126,
            "contradiction": 7.58701,
            "irrelevancy": 7.8314,
            "logical_agreement": 84.58159,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.12986,
            "nubia_score": 0.76284
        },
        "bleurt": 0.06781,
        "bertscore": {
            "precision": 0.90797,
            "recall": 0.90186,
            "f1": 0.90343
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 5049,
        "total_length": 37383,
        "mean_pred_length": 7.404040404040404,
        "std_pred_length": 2.7008268642757787,
        "median_pred_length": 7.0,
        "min_pred_length": 1,
        "max_pred_length": 34,
        "distinct-1": 0.030093892945991494,
        "vocab_size-1": 1125,
        "unique-1": 459,
        "entropy-1": 6.764993043102902,
        "distinct-2": 0.10898744355786479,
        "vocab_size-2": 3524,
        "unique-2": 1700,
        "entropy-2": 9.142421509240195,
        "cond_entropy-2": 1.9907695586291214,
        "distinct-3": 0.1888078572213875,
        "vocab_size-3": 5152,
        "unique-3": 2945,
        "entropy-3": 9.944810097403881,
        "cond_entropy-3": 0.8256389396317971,
        "total_length-nopunct": 31777,
        "mean_pred_length-nopunct": 6.293721529015647,
        "std_pred_length-nopunct": 2.4904416591936176,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.03508827139125783,
        "vocab_size-1-nopunct": 1115,
        "unique-1-nopunct": 458,
        "entropy-1-nopunct": 6.942803791177602,
        "distinct-2-nopunct": 0.11272822508231069,
        "vocab_size-2-nopunct": 3013,
        "unique-2-nopunct": 1505,
        "entropy-2-nopunct": 8.832817221519377,
        "cond_entropy-2-nopunct": 2.0839258460549357,
        "distinct-3-nopunct": 0.19107134621592953,
        "vocab_size-3-nopunct": 4143,
        "unique-3-nopunct": 2423,
        "entropy-3-nopunct": 9.52538059371026,
        "cond_entropy-3-nopunct": 0.8362401905336406,
        "msttr-100": 0.55879,
        "msttr-100_nopunct": 0.57981,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 27.17554,
        "nist": 4.789896607925173,
        "rouge1": {
            "precision": 0.51808,
            "recall": 0.48882,
            "fmeasure": 0.49067
        },
        "rouge2": {
            "precision": 0.31166,
            "recall": 0.29381,
            "fmeasure": 0.29423
        },
        "rougeL": {
            "precision": 0.4938,
            "recall": 0.46414,
            "fmeasure": 0.467
        },
        "rougeLsum": {
            "precision": 0.4938,
            "recall": 0.46414,
            "fmeasure": 0.467
        },
        "local_recall": {
            "1": 0.4680564501961703
        },
        "meteor": 0.2666893783531851,
        "nubia": {
            "semantic_relation": 3.20091,
            "contradiction": 7.39491,
            "irrelevancy": 22.51627,
            "logical_agreement": 70.08882,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.48494,
            "nubia_score": 0.59346
        },
        "bleurt": -0.0793,
        "bertscore": {
            "precision": 0.86177,
            "recall": 0.8534,
            "f1": 0.85699
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 86,
        "total_length": 1484,
        "mean_pred_length": 17.25581395348837,
        "std_pred_length": 3.8312850674039214,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.19137466307277629,
        "vocab_size-1": 284,
        "unique-1": 120,
        "entropy-1": 6.779602588697952,
        "distinct-2": 0.46494992846924177,
        "vocab_size-2": 650,
        "unique-2": 392,
        "entropy-2": 8.731559839042099,
        "cond_entropy-2": 1.7680129324720095,
        "distinct-3": 0.6501524390243902,
        "vocab_size-3": 853,
        "unique-3": 647,
        "entropy-3": 9.329516492496442,
        "cond_entropy-3": 0.5507002440800713,
        "total_length-nopunct": 1300,
        "mean_pred_length-nopunct": 15.116279069767442,
        "std_pred_length-nopunct": 3.4079885790122897,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.21615384615384614,
        "vocab_size-1-nopunct": 281,
        "unique-1-nopunct": 120,
        "entropy-1-nopunct": 6.975108973477292,
        "distinct-2-nopunct": 0.4950576606260296,
        "vocab_size-2-nopunct": 601,
        "unique-2-nopunct": 375,
        "entropy-2-nopunct": 8.669756826152382,
        "cond_entropy-2-nopunct": 1.7187275948711216,
        "distinct-3-nopunct": 0.6861702127659575,
        "vocab_size-3-nopunct": 774,
        "unique-3-nopunct": 598,
        "entropy-3-nopunct": 9.257510971680963,
        "cond_entropy-3-nopunct": 0.5467547852531777,
        "msttr-100": 0.62143,
        "msttr-100_nopunct": 0.64615,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 19.18601,
        "nist": 4.191054231574496,
        "rouge1": {
            "precision": 0.59007,
            "recall": 0.56868,
            "fmeasure": 0.57278
        },
        "rouge2": {
            "precision": 0.31424,
            "recall": 0.30777,
            "fmeasure": 0.3073
        },
        "rougeL": {
            "precision": 0.47417,
            "recall": 0.46097,
            "fmeasure": 0.46251
        },
        "rougeLsum": {
            "precision": 0.47417,
            "recall": 0.46097,
            "fmeasure": 0.46251
        },
        "local_recall": {
            "1": 0.5079847908745247
        },
        "meteor": 0.2551192880891077,
        "nubia": {
            "semantic_relation": 3.46554,
            "contradiction": 15.54726,
            "irrelevancy": 20.65286,
            "logical_agreement": 63.79988,
            "grammar_ref": 6.22337,
            "grammar_hyp": 6.25153,
            "nubia_score": 0.57605
        },
        "bleurt": 0.0015,
        "bertscore": {
            "precision": 0.92043,
            "recall": 0.91848,
            "f1": 0.91937
        }
    },
    "web_nlg_en_challenge_test_scramble_parent": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 500,
        "total_length": 11987,
        "mean_pred_length": 23.974,
        "std_pred_length": 12.776592816553245,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 106,
        "distinct-1": 0.10619838158004505,
        "vocab_size-1": 1273,
        "unique-1": 401,
        "entropy-1": 8.023748854614663,
        "distinct-2": 0.3188822146774615,
        "vocab_size-2": 3663,
        "unique-2": 1872,
        "entropy-2": 10.924532708966078,
        "cond_entropy-2": 2.725386843328587,
        "distinct-3": 0.5008646582324565,
        "vocab_size-3": 5503,
        "unique-3": 3570,
        "entropy-3": 11.873534568830404,
        "cond_entropy-3": 0.9959110102312304,
        "total_length-nopunct": 10537,
        "mean_pred_length-nopunct": 21.074,
        "std_pred_length-nopunct": 11.34832692514628,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 95,
        "distinct-1-nopunct": 0.11976843503843598,
        "vocab_size-1-nopunct": 1262,
        "unique-1-nopunct": 399,
        "entropy-1-nopunct": 8.320799260284018,
        "distinct-2-nopunct": 0.3386470060775132,
        "vocab_size-2-nopunct": 3399,
        "unique-2-nopunct": 1840,
        "entropy-2-nopunct": 10.841911128695724,
        "cond_entropy-2-nopunct": 2.6443144017730242,
        "distinct-3-nopunct": 0.5194505609730523,
        "vocab_size-3-nopunct": 4954,
        "unique-3-nopunct": 3324,
        "entropy-3-nopunct": 11.73564949092631,
        "cond_entropy-3-nopunct": 0.929213056343764,
        "msttr-100": 0.52773,
        "msttr-100_nopunct": 0.53886,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 48.48533,
        "nist": 8.933482711192367,
        "rouge1": {
            "precision": 0.77042,
            "recall": 0.75082,
            "fmeasure": 0.75404
        },
        "rouge2": {
            "precision": 0.51428,
            "recall": 0.49973,
            "fmeasure": 0.50252
        },
        "rougeL": {
            "precision": 0.61508,
            "recall": 0.6018,
            "fmeasure": 0.60311
        },
        "rougeLsum": {
            "precision": 0.61508,
            "recall": 0.6018,
            "fmeasure": 0.60311
        },
        "local_recall": {
            "1": 0.2233643012453054,
            "2": 0.5965388530709196,
            "3": 0.8844427823485415,
            "4": 0.4,
            "5": 0.8333333333333334
        },
        "meteor": 0.38875793162597405,
        "nubia": {
            "semantic_relation": 4.45032,
            "contradiction": 8.34452,
            "irrelevancy": 7.82618,
            "logical_agreement": 83.8293,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.57977,
            "nubia_score": 0.79613
        },
        "bleurt": 0.23397,
        "bertscore": {
            "precision": 0.92526,
            "recall": 0.92285,
            "f1": 0.92279
        }
    },
    "mlsum_es_val": {
        "predictions_file": "mT5_xl/mlsum_es_val",
        "N": 9977,
        "total_length": 222631,
        "mean_pred_length": 22.314423173298586,
        "std_pred_length": 8.225830859261826,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 98,
        "distinct-1": 0.11627760734129569,
        "vocab_size-1": 25887,
        "unique-1": 14521,
        "entropy-1": 9.984422628470577,
        "distinct-2": 0.48948526714757307,
        "vocab_size-2": 104091,
        "unique-2": 81330,
        "entropy-2": 15.230200143049837,
        "cond_entropy-2": 5.421753878485522,
        "distinct-3": 0.8161557552164281,
        "vocab_size-3": 165416,
        "unique-3": 150002,
        "entropy-3": 17.04798159219994,
        "cond_entropy-3": 1.8621498701440762,
        "total_length-nopunct": 210659,
        "mean_pred_length-nopunct": 21.114463265510675,
        "std_pred_length-nopunct": 7.389771875391718,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 96,
        "distinct-1-nopunct": 0.12280035507621322,
        "vocab_size-1-nopunct": 25869,
        "unique-1-nopunct": 14516,
        "entropy-1-nopunct": 10.14289601818521,
        "distinct-2-nopunct": 0.5118296608564794,
        "vocab_size-2-nopunct": 102715,
        "unique-2-nopunct": 81443,
        "entropy-2-nopunct": 15.308187142013473,
        "cond_entropy-2-nopunct": 5.35223899640884,
        "distinct-3-nopunct": 0.8328517867911172,
        "vocab_size-3-nopunct": 158829,
        "unique-3-nopunct": 145291,
        "entropy-3-nopunct": 17.023395054319668,
        "cond_entropy-3-nopunct": 1.7537777309530302,
        "msttr-100": 0.70686,
        "msttr-100_nopunct": 0.71943,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_val.json",
        "bleu": 11.50848,
        "nist": 3.569400449404395,
        "rouge1": {
            "precision": 0.34166,
            "recall": 0.32738,
            "fmeasure": 0.32205
        },
        "rouge2": {
            "precision": 0.14854,
            "recall": 0.14454,
            "fmeasure": 0.14108
        },
        "rougeL": {
            "precision": 0.27634,
            "recall": 0.26639,
            "fmeasure": 0.2614
        },
        "rougeLsum": {
            "precision": 0.27634,
            "recall": 0.26639,
            "fmeasure": 0.2614
        },
        "local_recall": {
            "1": 0.3063583815028902
        },
        "meteor": 0.24306077031704973,
        "nubia": {
            "semantic_relation": 1.86276,
            "contradiction": 25.30498,
            "irrelevancy": 61.62195,
            "logical_agreement": 13.07308,
            "grammar_ref": 5.2776,
            "grammar_hyp": 5.22793,
            "nubia_score": 0.21215
        },
        "bleurt": -0.39273,
        "bertscore": {
            "precision": 0.84811,
            "recall": 0.84641,
            "f1": 0.84703
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_xl/e2e_nlg_test",
        "N": 389,
        "total_length": 6170,
        "mean_pred_length": 15.861182519280206,
        "std_pred_length": 4.3220317558782915,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.023176661264181525,
        "vocab_size-1": 143,
        "unique-1": 15,
        "entropy-1": 5.793424188822983,
        "distinct-2": 0.056391627746064696,
        "vocab_size-2": 326,
        "unique-2": 66,
        "entropy-2": 7.108570690004898,
        "cond_entropy-2": 1.163779453237945,
        "distinct-3": 0.0897626112759644,
        "vocab_size-3": 484,
        "unique-3": 124,
        "entropy-3": 7.811429574354069,
        "cond_entropy-3": 0.7312974871005521,
        "total_length-nopunct": 5598,
        "mean_pred_length-nopunct": 14.390745501285346,
        "std_pred_length-nopunct": 3.716359540733594,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.025187566988210074,
        "vocab_size-1-nopunct": 141,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 5.855103992936148,
        "distinct-2-nopunct": 0.058168554425033596,
        "vocab_size-2-nopunct": 303,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 6.980189493654371,
        "cond_entropy-2-nopunct": 1.2011191730673951,
        "distinct-3-nopunct": 0.09626556016597511,
        "vocab_size-3-nopunct": 464,
        "unique-3-nopunct": 122,
        "entropy-3-nopunct": 7.742228819985351,
        "cond_entropy-3-nopunct": 0.757420251428155,
        "msttr-100": 0.26295,
        "msttr-100_nopunct": 0.25545,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 30.57199,
        "nist": 4.7286174382839965,
        "rouge1": {
            "precision": 0.75414,
            "recall": 0.65053,
            "fmeasure": 0.68452
        },
        "rouge2": {
            "precision": 0.482,
            "recall": 0.41522,
            "fmeasure": 0.43624
        },
        "rougeL": {
            "precision": 0.60624,
            "recall": 0.52017,
            "fmeasure": 0.5483
        },
        "rougeLsum": {
            "precision": 0.60624,
            "recall": 0.52017,
            "fmeasure": 0.5483
        },
        "local_recall": {
            "1": 0.639290941616523
        },
        "meteor": 0.3409342116709001,
        "nubia": {
            "semantic_relation": 4.14367,
            "contradiction": 5.459,
            "irrelevancy": 18.19439,
            "logical_agreement": 76.34661,
            "grammar_ref": 5.31197,
            "grammar_hyp": 4.96624,
            "nubia_score": 0.73425
        },
        "bleurt": 0.1318,
        "bertscore": {
            "precision": 0.92433,
            "recall": 0.90009,
            "f1": 0.91161
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 80,
        "total_length": 3300,
        "mean_pred_length": 41.25,
        "std_pred_length": 11.7521274669738,
        "median_pred_length": 39.0,
        "min_pred_length": 22,
        "max_pred_length": 106,
        "distinct-1": 0.2015151515151515,
        "vocab_size-1": 665,
        "unique-1": 286,
        "entropy-1": 7.573627024731256,
        "distinct-2": 0.4506211180124224,
        "vocab_size-2": 1451,
        "unique-2": 868,
        "entropy-2": 9.8901881787203,
        "cond_entropy-2": 2.228201930726564,
        "distinct-3": 0.6070063694267516,
        "vocab_size-3": 1906,
        "unique-3": 1367,
        "entropy-3": 10.519981673068926,
        "cond_entropy-3": 0.6502823742242897,
        "total_length-nopunct": 2910,
        "mean_pred_length-nopunct": 36.375,
        "std_pred_length-nopunct": 10.866663471369673,
        "median_pred_length-nopunct": 34.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 95,
        "distinct-1-nopunct": 0.22577319587628866,
        "vocab_size-1-nopunct": 657,
        "unique-1-nopunct": 285,
        "entropy-1-nopunct": 7.802740359116613,
        "distinct-2-nopunct": 0.4787985865724382,
        "vocab_size-2-nopunct": 1355,
        "unique-2-nopunct": 845,
        "entropy-2-nopunct": 9.856046554021884,
        "cond_entropy-2-nopunct": 2.112309030345516,
        "distinct-3-nopunct": 0.6283636363636363,
        "vocab_size-3-nopunct": 1728,
        "unique-3-nopunct": 1271,
        "entropy-3-nopunct": 10.399050679802928,
        "cond_entropy-3-nopunct": 0.5559460520368823,
        "msttr-100": 0.53636,
        "msttr-100_nopunct": 0.55207,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 41.63207,
        "nist": 7.840181256255203,
        "rouge1": {
            "precision": 0.74869,
            "recall": 0.68332,
            "fmeasure": 0.7073
        },
        "rouge2": {
            "precision": 0.44386,
            "recall": 0.39749,
            "fmeasure": 0.41483
        },
        "rougeL": {
            "precision": 0.52213,
            "recall": 0.48142,
            "fmeasure": 0.49606
        },
        "rougeLsum": {
            "precision": 0.52213,
            "recall": 0.48142,
            "fmeasure": 0.49606
        },
        "local_recall": {
            "1": 0.21699544764795145,
            "2": 0.546916890080429,
            "3": 0.8508771929824561
        },
        "meteor": 0.34000260980264085,
        "nubia": {
            "semantic_relation": 4.08891,
            "contradiction": 7.53161,
            "irrelevancy": 9.03436,
            "logical_agreement": 83.43403,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.08779,
            "nubia_score": 0.69924
        },
        "bleurt": 0.05887,
        "bertscore": {
            "precision": 0.9051,
            "recall": 0.89244,
            "f1": 0.89747
        }
    },
    "xsum_test": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 1166,
        "total_length": 22997,
        "mean_pred_length": 19.722984562607206,
        "std_pred_length": 4.432795680130734,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 38,
        "distinct-1": 0.2012871244075314,
        "vocab_size-1": 4629,
        "unique-1": 2749,
        "entropy-1": 9.183532957680836,
        "distinct-2": 0.6332279785625945,
        "vocab_size-2": 13824,
        "unique-2": 11476,
        "entropy-2": 12.981455966772167,
        "cond_entropy-2": 3.5377845872554587,
        "distinct-3": 0.861650133075248,
        "vocab_size-3": 17806,
        "unique-3": 16476,
        "entropy-3": 13.923356229757692,
        "cond_entropy-3": 0.9479480806096094,
        "total_length-nopunct": 21346,
        "mean_pred_length-nopunct": 18.30703259005146,
        "std_pred_length-nopunct": 4.234555463875687,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.21638714513257754,
        "vocab_size-1-nopunct": 4619,
        "unique-1-nopunct": 2748,
        "entropy-1-nopunct": 9.389963875090077,
        "distinct-2-nopunct": 0.6410802775024776,
        "vocab_size-2-nopunct": 12937,
        "unique-2-nopunct": 10801,
        "entropy-2-nopunct": 12.904813651652058,
        "cond_entropy-2-nopunct": 3.6495783607658248,
        "distinct-3-nopunct": 0.8704638687283055,
        "vocab_size-3-nopunct": 16551,
        "unique-3-nopunct": 15362,
        "entropy-3-nopunct": 13.84382752753351,
        "cond_entropy-3-nopunct": 0.9595435830824809,
        "msttr-100": 0.72646,
        "msttr-100_nopunct": 0.74944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 11.25482,
        "nist": 4.091023706713634,
        "rouge1": {
            "precision": 0.45919,
            "recall": 0.39214,
            "fmeasure": 0.41452
        },
        "rouge2": {
            "precision": 0.1927,
            "recall": 0.1643,
            "fmeasure": 0.17339
        },
        "rougeL": {
            "precision": 0.36348,
            "recall": 0.31086,
            "fmeasure": 0.32823
        },
        "rougeLsum": {
            "precision": 0.36348,
            "recall": 0.31086,
            "fmeasure": 0.32823
        },
        "local_recall": {
            "1": 0.3658172194476459
        },
        "meteor": 0.18207784228002966,
        "nubia": {
            "semantic_relation": 3.08059,
            "contradiction": 18.15199,
            "irrelevancy": 59.87042,
            "logical_agreement": 21.9776,
            "grammar_ref": 3.76542,
            "grammar_hyp": 3.61973,
            "nubia_score": 0.4678
        },
        "bleurt": -0.25045,
        "bertscore": {
            "precision": 0.84872,
            "recall": 0.82858,
            "f1": 0.83817
        }
    },
    "web_nlg_en_challenge_test_numbers_parent": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 500,
        "total_length": 12219,
        "mean_pred_length": 24.438,
        "std_pred_length": 12.627199056006045,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 81,
        "distinct-1": 0.10590064653408626,
        "vocab_size-1": 1294,
        "unique-1": 418,
        "entropy-1": 8.037770988673895,
        "distinct-2": 0.3182865432204113,
        "vocab_size-2": 3730,
        "unique-2": 1956,
        "entropy-2": 10.94524173752944,
        "cond_entropy-2": 2.736420787772666,
        "distinct-3": 0.4936268829663963,
        "vocab_size-3": 5538,
        "unique-3": 3626,
        "entropy-3": 11.862212372309877,
        "cond_entropy-3": 0.9704221209302732,
        "total_length-nopunct": 10763,
        "mean_pred_length-nopunct": 21.526,
        "std_pred_length-nopunct": 11.233402156070085,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.11920468270928179,
        "vocab_size-1-nopunct": 1283,
        "unique-1-nopunct": 418,
        "entropy-1-nopunct": 8.32902950342505,
        "distinct-2-nopunct": 0.3353795186592614,
        "vocab_size-2-nopunct": 3442,
        "unique-2-nopunct": 1906,
        "entropy-2-nopunct": 10.84613156088063,
        "cond_entropy-2-nopunct": 2.6418464105110844,
        "distinct-3-nopunct": 0.5090648366280857,
        "vocab_size-3-nopunct": 4970,
        "unique-3-nopunct": 3360,
        "entropy-3-nopunct": 11.713712311894266,
        "cond_entropy-3-nopunct": 0.9074119999965414,
        "msttr-100": 0.65172,
        "msttr-100_nopunct": 0.69561,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 49.71508,
        "nist": 9.001665917758935,
        "rouge1": {
            "precision": 0.77426,
            "recall": 0.75405,
            "fmeasure": 0.75673
        },
        "rouge2": {
            "precision": 0.52545,
            "recall": 0.50925,
            "fmeasure": 0.51199
        },
        "rougeL": {
            "precision": 0.61692,
            "recall": 0.6013,
            "fmeasure": 0.60306
        },
        "rougeLsum": {
            "precision": 0.61692,
            "recall": 0.6013,
            "fmeasure": 0.60306
        },
        "local_recall": {
            "1": 0.23228099519130252,
            "2": 0.6133470932232542,
            "3": 0.8782936010037641,
            "4": 0.5555555555555556,
            "5": 0.8181818181818182
        },
        "meteor": 0.3942465958287785,
        "nubia": {
            "semantic_relation": 4.47507,
            "contradiction": 7.32598,
            "irrelevancy": 8.28657,
            "logical_agreement": 84.38746,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.4983,
            "nubia_score": 0.80394
        },
        "bleurt": 0.21441,
        "bertscore": {
            "precision": 0.9267,
            "recall": 0.92271,
            "f1": 0.92331
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 41,
        "total_length": 1825,
        "mean_pred_length": 44.51219512195122,
        "std_pred_length": 11.063281282802821,
        "median_pred_length": 45.0,
        "min_pred_length": 21,
        "max_pred_length": 81,
        "distinct-1": 0.2635616438356164,
        "vocab_size-1": 481,
        "unique-1": 252,
        "entropy-1": 7.364105184124596,
        "distinct-2": 0.5403587443946188,
        "vocab_size-2": 964,
        "unique-2": 650,
        "entropy-2": 9.464206220273246,
        "cond_entropy-2": 2.0202857353789483,
        "distinct-3": 0.6821572002294893,
        "vocab_size-3": 1189,
        "unique-3": 920,
        "entropy-3": 9.939411255323913,
        "cond_entropy-3": 0.48833383352226606,
        "total_length-nopunct": 1597,
        "mean_pred_length-nopunct": 38.951219512195124,
        "std_pred_length-nopunct": 10.17637440711404,
        "median_pred_length-nopunct": 39.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.2974326862867877,
        "vocab_size-1-nopunct": 475,
        "unique-1-nopunct": 251,
        "entropy-1-nopunct": 7.599280945312631,
        "distinct-2-nopunct": 0.5726221079691517,
        "vocab_size-2-nopunct": 891,
        "unique-2-nopunct": 618,
        "entropy-2-nopunct": 9.409545045884427,
        "cond_entropy-2-nopunct": 1.8620348681021512,
        "distinct-3-nopunct": 0.7042904290429043,
        "vocab_size-3-nopunct": 1067,
        "unique-3-nopunct": 847,
        "entropy-3-nopunct": 9.797884369167093,
        "cond_entropy-3-nopunct": 0.3960598104977478,
        "msttr-100": 0.55778,
        "msttr-100_nopunct": 0.56333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 43.55076,
        "nist": 7.422730067423595,
        "rouge1": {
            "precision": 0.73373,
            "recall": 0.66704,
            "fmeasure": 0.69246
        },
        "rouge2": {
            "precision": 0.43919,
            "recall": 0.40239,
            "fmeasure": 0.41626
        },
        "rougeL": {
            "precision": 0.50653,
            "recall": 0.46486,
            "fmeasure": 0.48072
        },
        "rougeLsum": {
            "precision": 0.50653,
            "recall": 0.46486,
            "fmeasure": 0.48072
        },
        "local_recall": {
            "1": 0.22054380664652568,
            "2": 0.44387755102040816,
            "3": 0.8165548098434005
        },
        "meteor": 0.334690479878398,
        "nubia": {
            "semantic_relation": 3.94781,
            "contradiction": 7.23976,
            "irrelevancy": 8.87465,
            "logical_agreement": 83.88559,
            "grammar_ref": 3.92594,
            "grammar_hyp": 4.0058,
            "nubia_score": 0.68387
        },
        "bleurt": 0.0118,
        "bertscore": {
            "precision": 0.90113,
            "recall": 0.88659,
            "f1": 0.89264
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7760,
        "mean_pred_length": 21.615598885793872,
        "std_pred_length": 9.403512744681423,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.35966494845360825,
        "vocab_size-1": 2791,
        "unique-1": 2028,
        "entropy-1": 9.188144884333632,
        "distinct-2": 0.8255641129577084,
        "vocab_size-2": 6110,
        "unique-2": 5637,
        "entropy-2": 12.224661288830381,
        "cond_entropy-2": 2.8001553479838672,
        "distinct-3": 0.9606645839250213,
        "vocab_size-3": 6765,
        "unique-3": 6634,
        "entropy-3": 12.64580267724211,
        "cond_entropy-3": 0.43695440762963217,
        "total_length-nopunct": 6820,
        "mean_pred_length-nopunct": 18.997214484679667,
        "std_pred_length-nopunct": 8.108765712326052,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.40747800586510263,
        "vocab_size-1-nopunct": 2779,
        "unique-1-nopunct": 2026,
        "entropy-1-nopunct": 9.554039108722176,
        "distinct-2-nopunct": 0.8562142083268843,
        "vocab_size-2-nopunct": 5532,
        "unique-2-nopunct": 5153,
        "entropy-2-nopunct": 12.171902248092573,
        "cond_entropy-2-nopunct": 2.7476322655498087,
        "distinct-3-nopunct": 0.9804981973123567,
        "vocab_size-3-nopunct": 5983,
        "unique-3-nopunct": 5890,
        "entropy-3-nopunct": 12.53167607520254,
        "cond_entropy-3-nopunct": 0.3825261721861503,
        "msttr-100": 0.72299,
        "msttr-100_nopunct": 0.76941,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 86.34939,
        "nist": 13.329512713282538,
        "rouge1": {
            "precision": 0.89874,
            "recall": 0.90638,
            "fmeasure": 0.89862
        },
        "rouge2": {
            "precision": 0.80532,
            "recall": 0.81573,
            "fmeasure": 0.80561
        },
        "rougeL": {
            "precision": 0.88654,
            "recall": 0.89608,
            "fmeasure": 0.88722
        },
        "rougeLsum": {
            "precision": 0.88654,
            "recall": 0.89608,
            "fmeasure": 0.88722
        },
        "local_recall": {
            "1": 0.03381109886071297,
            "2": 0.17452830188679244,
            "3": 0.40602409638554215,
            "4": 0.617737003058104,
            "5": 0.7465857359635811,
            "6": 0.8464788732394366,
            "7": 0.8838797814207651,
            "8": 0.9227985524728589,
            "9": 0.9513227513227513,
            "10": 0.9798449612403101
        },
        "meteor": 0.551356493160983,
        "nubia": {
            "semantic_relation": 4.36984,
            "contradiction": 2.52055,
            "irrelevancy": 33.99611,
            "logical_agreement": 63.48333,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.69195,
            "nubia_score": 0.69208
        },
        "bleurt": 0.30287,
        "bertscore": {
            "precision": 0.9719,
            "recall": 0.97818,
            "f1": 0.97285
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7760,
        "mean_pred_length": 21.615598885793872,
        "std_pred_length": 9.403512744681423,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.35966494845360825,
        "vocab_size-1": 2791,
        "unique-1": 2028,
        "entropy-1": 9.188144884333632,
        "distinct-2": 0.8255641129577084,
        "vocab_size-2": 6110,
        "unique-2": 5637,
        "entropy-2": 12.224661288830381,
        "cond_entropy-2": 2.8001553479838672,
        "distinct-3": 0.9606645839250213,
        "vocab_size-3": 6765,
        "unique-3": 6634,
        "entropy-3": 12.64580267724211,
        "cond_entropy-3": 0.43695440762963217,
        "total_length-nopunct": 6820,
        "mean_pred_length-nopunct": 18.997214484679667,
        "std_pred_length-nopunct": 8.108765712326052,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.40747800586510263,
        "vocab_size-1-nopunct": 2779,
        "unique-1-nopunct": 2026,
        "entropy-1-nopunct": 9.554039108722176,
        "distinct-2-nopunct": 0.8562142083268843,
        "vocab_size-2-nopunct": 5532,
        "unique-2-nopunct": 5153,
        "entropy-2-nopunct": 12.171902248092573,
        "cond_entropy-2-nopunct": 2.7476322655498087,
        "distinct-3-nopunct": 0.9804981973123567,
        "vocab_size-3-nopunct": 5983,
        "unique-3-nopunct": 5890,
        "entropy-3-nopunct": 12.53167607520254,
        "cond_entropy-3-nopunct": 0.3825261721861503,
        "msttr-100": 0.72299,
        "msttr-100_nopunct": 0.76941,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 86.34939,
        "nist": 13.329512713282538,
        "rouge1": {
            "precision": 0.89874,
            "recall": 0.90638,
            "fmeasure": 0.89862
        },
        "rouge2": {
            "precision": 0.80532,
            "recall": 0.81573,
            "fmeasure": 0.80561
        },
        "rougeL": {
            "precision": 0.88654,
            "recall": 0.89608,
            "fmeasure": 0.88722
        },
        "rougeLsum": {
            "precision": 0.88654,
            "recall": 0.89608,
            "fmeasure": 0.88722
        },
        "local_recall": {
            "1": 0.03381109886071297,
            "2": 0.17452830188679244,
            "3": 0.40602409638554215,
            "4": 0.617737003058104,
            "5": 0.7465857359635811,
            "6": 0.8464788732394366,
            "7": 0.8838797814207651,
            "8": 0.9227985524728589,
            "9": 0.9513227513227513,
            "10": 0.9798449612403101
        },
        "meteor": 0.551356493160983,
        "nubia": {
            "semantic_relation": 4.36984,
            "contradiction": 2.52055,
            "irrelevancy": 33.99611,
            "logical_agreement": 63.48333,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.69195,
            "nubia_score": 0.69208
        },
        "bleurt": 0.30287,
        "bertscore": {
            "precision": 0.9719,
            "recall": 0.97818,
            "f1": 0.97285
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_xl/cs_restaurants_test",
        "N": 9,
        "total_length": 140,
        "mean_pred_length": 15.555555555555555,
        "std_pred_length": 4.085505846855608,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.5142857142857142,
        "vocab_size-1": 72,
        "unique-1": 48,
        "entropy-1": 5.730620011480387,
        "distinct-2": 0.8091603053435115,
        "vocab_size-2": 106,
        "unique-2": 86,
        "entropy-2": 6.622931112141899,
        "cond_entropy-2": 0.7601783845943031,
        "distinct-3": 0.8934426229508197,
        "vocab_size-3": 109,
        "unique-3": 97,
        "entropy-3": 6.711434980987789,
        "cond_entropy-3": 0.07640962296979284,
        "total_length-nopunct": 123,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 3.527668414752787,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5691056910569106,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.78038397394277,
        "distinct-2-nopunct": 0.8157894736842105,
        "vocab_size-2-nopunct": 93,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.437981680755508,
        "cond_entropy-2-nopunct": 0.6776788452436506,
        "distinct-3-nopunct": 0.9047619047619048,
        "vocab_size-3-nopunct": 95,
        "unique-3-nopunct": 86,
        "entropy-3-nopunct": 6.516579922407414,
        "cond_entropy-3-nopunct": 0.05368633688279137,
        "msttr-100": 0.58,
        "msttr-100_nopunct": 0.6,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 15.25841,
        "nist": 2.990166741939254,
        "rouge1": {
            "precision": 0.56475,
            "recall": 0.4946,
            "fmeasure": 0.52289
        },
        "rouge2": {
            "precision": 0.29371,
            "recall": 0.25654,
            "fmeasure": 0.27146
        },
        "rougeL": {
            "precision": 0.42929,
            "recall": 0.37051,
            "fmeasure": 0.39458
        },
        "rougeLsum": {
            "precision": 0.42929,
            "recall": 0.37051,
            "fmeasure": 0.39458
        },
        "local_recall": {
            "1": 0.45185185185185184
        },
        "meteor": 0.23292377180559776,
        "nubia": {
            "semantic_relation": 3.41359,
            "contradiction": 18.85,
            "irrelevancy": 28.3834,
            "logical_agreement": 52.7666,
            "grammar_ref": 6.01604,
            "grammar_hyp": 5.94444,
            "nubia_score": 0.53586
        },
        "bleurt": -0.13136,
        "bertscore": {
            "precision": 0.91199,
            "recall": 0.8993,
            "f1": 0.90555
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 7.82886,
        "nist": 2.178663859272816,
        "rouge1": {
            "precision": 0.41481,
            "recall": 0.42222,
            "fmeasure": 0.4152
        },
        "rouge2": {
            "precision": 0.16758,
            "recall": 0.18409,
            "fmeasure": 0.17269
        },
        "rougeL": {
            "precision": 0.36296,
            "recall": 0.36667,
            "fmeasure": 0.36211
        },
        "rougeLsum": {
            "precision": 0.36296,
            "recall": 0.36667,
            "fmeasure": 0.36211
        },
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.3,
            "3": 0.5
        },
        "meteor": 0.21242590407760215,
        "nubia": {
            "semantic_relation": 3.08235,
            "contradiction": 2.2972,
            "irrelevancy": 71.21594,
            "logical_agreement": 26.48686,
            "grammar_ref": 5.71002,
            "grammar_hyp": 4.65453,
            "nubia_score": 0.46978
        },
        "bleurt": -0.18337,
        "bertscore": {
            "precision": 0.8123,
            "recall": 0.82722,
            "f1": 0.8124
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_xl/e2e_nlg_test",
        "N": 737,
        "total_length": 14235,
        "mean_pred_length": 19.314789687924016,
        "std_pred_length": 3.608178707512726,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 30,
        "distinct-1": 0.009272918861959958,
        "vocab_size-1": 132,
        "unique-1": 10,
        "entropy-1": 5.651680470513164,
        "distinct-2": 0.028819084308786488,
        "vocab_size-2": 389,
        "unique-2": 63,
        "entropy-2": 7.126750773461097,
        "cond_entropy-2": 1.364789661946582,
        "distinct-3": 0.05211190345584202,
        "vocab_size-3": 665,
        "unique-3": 131,
        "entropy-3": 7.970805741458434,
        "cond_entropy-3": 0.866114574391437,
        "total_length-nopunct": 13024,
        "mean_pred_length-nopunct": 17.671641791044777,
        "std_pred_length-nopunct": 3.2545839322134604,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.00998157248157248,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 5.697406948335091,
        "distinct-2-nopunct": 0.030031740864328152,
        "vocab_size-2-nopunct": 369,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 7.053819469194639,
        "cond_entropy-2-nopunct": 1.400511516357153,
        "distinct-3-nopunct": 0.055757575757575756,
        "vocab_size-3-nopunct": 644,
        "unique-3-nopunct": 122,
        "entropy-3-nopunct": 7.9508508349675,
        "cond_entropy-3-nopunct": 0.8819499336692402,
        "msttr-100": 0.25746,
        "msttr-100_nopunct": 0.24823,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 32.64163,
        "nist": 5.155674593989003,
        "rouge1": {
            "precision": 0.76772,
            "recall": 0.69982,
            "fmeasure": 0.72109
        },
        "rouge2": {
            "precision": 0.49047,
            "recall": 0.44681,
            "fmeasure": 0.46022
        },
        "rougeL": {
            "precision": 0.59823,
            "recall": 0.54619,
            "fmeasure": 0.56268
        },
        "rougeLsum": {
            "precision": 0.59823,
            "recall": 0.54619,
            "fmeasure": 0.56268
        },
        "local_recall": {
            "1": 0.6910951117847669
        },
        "meteor": 0.3614679397471565,
        "nubia": {
            "semantic_relation": 4.30188,
            "contradiction": 2.74353,
            "irrelevancy": 13.6109,
            "logical_agreement": 83.64557,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.634,
            "nubia_score": 0.78265
        },
        "bleurt": 0.23808,
        "bertscore": {
            "precision": 0.92786,
            "recall": 0.90779,
            "f1": 0.91732
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_xl/e2e_nlg_test",
        "N": 1187,
        "total_length": 27093,
        "mean_pred_length": 22.824768323504635,
        "std_pred_length": 4.492767923590003,
        "median_pred_length": 23.0,
        "min_pred_length": 14,
        "max_pred_length": 34,
        "distinct-1": 0.00494592699221201,
        "vocab_size-1": 134,
        "unique-1": 18,
        "entropy-1": 5.533460700764462,
        "distinct-2": 0.01706168455184127,
        "vocab_size-2": 442,
        "unique-2": 85,
        "entropy-2": 6.986456345883724,
        "cond_entropy-2": 1.3611020451690032,
        "distinct-3": 0.033051498847040735,
        "vocab_size-3": 817,
        "unique-3": 190,
        "entropy-3": 7.848984846741797,
        "cond_entropy-3": 0.8820344181573754,
        "total_length-nopunct": 24717,
        "mean_pred_length-nopunct": 20.82308340353833,
        "std_pred_length-nopunct": 3.9914448860829563,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.005299995954201562,
        "vocab_size-1-nopunct": 131,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 5.589317073238525,
        "distinct-2-nopunct": 0.01806204844878878,
        "vocab_size-2-nopunct": 425,
        "unique-2-nopunct": 82,
        "entropy-2-nopunct": 6.974146864254414,
        "cond_entropy-2-nopunct": 1.414198576546137,
        "distinct-3-nopunct": 0.0358053976636978,
        "vocab_size-3-nopunct": 800,
        "unique-3-nopunct": 188,
        "entropy-3-nopunct": 7.898946623874779,
        "cond_entropy-3-nopunct": 0.9224652427433875,
        "msttr-100": 0.26178,
        "msttr-100_nopunct": 0.25684,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 31.67594,
        "nist": 5.096418235071922,
        "rouge1": {
            "precision": 0.76475,
            "recall": 0.72352,
            "fmeasure": 0.73166
        },
        "rouge2": {
            "precision": 0.45268,
            "recall": 0.4284,
            "fmeasure": 0.43299
        },
        "rougeL": {
            "precision": 0.53887,
            "recall": 0.51127,
            "fmeasure": 0.51617
        },
        "rougeLsum": {
            "precision": 0.53887,
            "recall": 0.51127,
            "fmeasure": 0.51617
        },
        "local_recall": {
            "1": 0.7133953762580536
        },
        "meteor": 0.36594609880188605,
        "nubia": {
            "semantic_relation": 4.38353,
            "contradiction": 1.34402,
            "irrelevancy": 10.88227,
            "logical_agreement": 87.77371,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.46327,
            "nubia_score": 0.82063
        },
        "bleurt": 0.22231,
        "bertscore": {
            "precision": 0.92253,
            "recall": 0.90623,
            "f1": 0.91397
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7760,
        "mean_pred_length": 21.615598885793872,
        "std_pred_length": 9.403512744681423,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.35966494845360825,
        "vocab_size-1": 2791,
        "unique-1": 2028,
        "entropy-1": 9.188144884333632,
        "distinct-2": 0.8255641129577084,
        "vocab_size-2": 6110,
        "unique-2": 5637,
        "entropy-2": 12.224661288830381,
        "cond_entropy-2": 2.8001553479838672,
        "distinct-3": 0.9606645839250213,
        "vocab_size-3": 6765,
        "unique-3": 6634,
        "entropy-3": 12.64580267724211,
        "cond_entropy-3": 0.43695440762963217,
        "total_length-nopunct": 6820,
        "mean_pred_length-nopunct": 18.997214484679667,
        "std_pred_length-nopunct": 8.108765712326052,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.40747800586510263,
        "vocab_size-1-nopunct": 2779,
        "unique-1-nopunct": 2026,
        "entropy-1-nopunct": 9.554039108722176,
        "distinct-2-nopunct": 0.8562142083268843,
        "vocab_size-2-nopunct": 5532,
        "unique-2-nopunct": 5153,
        "entropy-2-nopunct": 12.171902248092573,
        "cond_entropy-2-nopunct": 2.7476322655498087,
        "distinct-3-nopunct": 0.9804981973123567,
        "vocab_size-3-nopunct": 5983,
        "unique-3-nopunct": 5890,
        "entropy-3-nopunct": 12.53167607520254,
        "cond_entropy-3-nopunct": 0.3825261721861503,
        "msttr-100": 0.72299,
        "msttr-100_nopunct": 0.76941,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 86.34939,
        "nist": 13.329512713282538,
        "rouge1": {
            "precision": 0.89874,
            "recall": 0.90638,
            "fmeasure": 0.89862
        },
        "rouge2": {
            "precision": 0.80532,
            "recall": 0.81573,
            "fmeasure": 0.80561
        },
        "rougeL": {
            "precision": 0.88654,
            "recall": 0.89608,
            "fmeasure": 0.88722
        },
        "rougeLsum": {
            "precision": 0.88654,
            "recall": 0.89608,
            "fmeasure": 0.88722
        },
        "local_recall": {
            "1": 0.03381109886071297,
            "2": 0.17452830188679244,
            "3": 0.40602409638554215,
            "4": 0.617737003058104,
            "5": 0.7465857359635811,
            "6": 0.8464788732394366,
            "7": 0.8838797814207651,
            "8": 0.9227985524728589,
            "9": 0.9513227513227513,
            "10": 0.9798449612403101
        },
        "meteor": 0.551356493160983,
        "nubia": {
            "semantic_relation": 4.36984,
            "contradiction": 2.52055,
            "irrelevancy": 33.99611,
            "logical_agreement": 63.48333,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.69195,
            "nubia_score": 0.69208
        },
        "bleurt": 0.30287,
        "bertscore": {
            "precision": 0.9719,
            "recall": 0.97818,
            "f1": 0.97285
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 214,
        "total_length": 5907,
        "mean_pred_length": 27.602803738317757,
        "std_pred_length": 9.245165020225489,
        "median_pred_length": 26.0,
        "min_pred_length": 14,
        "max_pred_length": 68,
        "distinct-1": 0.24665650922634164,
        "vocab_size-1": 1457,
        "unique-1": 711,
        "entropy-1": 8.560415258393865,
        "distinct-2": 0.506411382399438,
        "vocab_size-2": 2883,
        "unique-2": 1722,
        "entropy-2": 10.996122156502905,
        "cond_entropy-2": 2.2634789780011184,
        "distinct-3": 0.6541339660521993,
        "vocab_size-3": 3584,
        "unique-3": 2493,
        "entropy-3": 11.551642873438459,
        "cond_entropy-3": 0.5699756324876799,
        "total_length-nopunct": 4791,
        "mean_pred_length-nopunct": 22.38785046728972,
        "std_pred_length-nopunct": 7.457921966097951,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.3026508035900647,
        "vocab_size-1-nopunct": 1450,
        "unique-1-nopunct": 710,
        "entropy-1-nopunct": 9.258690357440077,
        "distinct-2-nopunct": 0.558444395892506,
        "vocab_size-2-nopunct": 2556,
        "unique-2-nopunct": 1619,
        "entropy-2-nopunct": 10.91307611454704,
        "cond_entropy-2-nopunct": 1.710240321873292,
        "distinct-3-nopunct": 0.6903506761402705,
        "vocab_size-3-nopunct": 3012,
        "unique-3-nopunct": 2191,
        "entropy-3-nopunct": 11.33721029715736,
        "cond_entropy-3-nopunct": 0.4400490895544522,
        "msttr-100": 0.70203,
        "msttr-100_nopunct": 0.79787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 52.557,
        "nist": 9.017402421136849,
        "rouge1": {
            "precision": 0.46425,
            "recall": 0.4596,
            "fmeasure": 0.45824
        },
        "rouge2": {
            "precision": 0.27691,
            "recall": 0.26744,
            "fmeasure": 0.26789
        },
        "rougeL": {
            "precision": 0.43491,
            "recall": 0.42984,
            "fmeasure": 0.4286
        },
        "rougeLsum": {
            "precision": 0.43491,
            "recall": 0.42984,
            "fmeasure": 0.4286
        },
        "local_recall": {
            "1": 0.28852643419572555,
            "2": 0.6847345132743363,
            "3": 0.8989010989010989
        },
        "meteor": 0.6568572859798083,
        "nubia": {
            "semantic_relation": 3.96203,
            "contradiction": 18.54767,
            "irrelevancy": 22.80216,
            "logical_agreement": 58.65018,
            "grammar_ref": 2.5317,
            "grammar_hyp": 2.50717,
            "nubia_score": 0.83625
        },
        "bleurt": 0.12303,
        "bertscore": {
            "precision": 0.95413,
            "recall": 0.95146,
            "f1": 0.95239
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_xl/e2e_nlg_test",
        "N": 1406,
        "total_length": 38445,
        "mean_pred_length": 27.34352773826458,
        "std_pred_length": 4.546666208861906,
        "median_pred_length": 28.0,
        "min_pred_length": 16,
        "max_pred_length": 40,
        "distinct-1": 0.0031993757315645728,
        "vocab_size-1": 123,
        "unique-1": 14,
        "entropy-1": 5.585320363211907,
        "distinct-2": 0.01220335322227922,
        "vocab_size-2": 452,
        "unique-2": 77,
        "entropy-2": 7.172627712079123,
        "cond_entropy-2": 1.5143425030378657,
        "distinct-3": 0.02595908287261808,
        "vocab_size-3": 925,
        "unique-3": 197,
        "entropy-3": 8.115747310963696,
        "cond_entropy-3": 0.9503928081737393,
        "total_length-nopunct": 35225,
        "mean_pred_length-nopunct": 25.05334281650071,
        "std_pred_length-nopunct": 4.061143572764661,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.0034350603264726755,
        "vocab_size-1-nopunct": 121,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 5.618059464539893,
        "distinct-2-nopunct": 0.012980868742422899,
        "vocab_size-2-nopunct": 439,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 7.16399289239272,
        "cond_entropy-2-nopunct": 1.5758926532347681,
        "distinct-3-nopunct": 0.02785919229938605,
        "vocab_size-3-nopunct": 903,
        "unique-3-nopunct": 195,
        "entropy-3-nopunct": 8.152133303889455,
        "cond_entropy-3-nopunct": 0.9908154088552076,
        "msttr-100": 0.28805,
        "msttr-100_nopunct": 0.28057,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 32.59271,
        "nist": 5.2810254502910325,
        "rouge1": {
            "precision": 0.77938,
            "recall": 0.73569,
            "fmeasure": 0.74773
        },
        "rouge2": {
            "precision": 0.47816,
            "recall": 0.45209,
            "fmeasure": 0.4589
        },
        "rougeL": {
            "precision": 0.53369,
            "recall": 0.5041,
            "fmeasure": 0.51219
        },
        "rougeLsum": {
            "precision": 0.53369,
            "recall": 0.5041,
            "fmeasure": 0.51219
        },
        "local_recall": {
            "1": 0.720769160667092
        },
        "meteor": 0.3745494555865888,
        "nubia": {
            "semantic_relation": 4.51043,
            "contradiction": 1.97563,
            "irrelevancy": 10.63719,
            "logical_agreement": 87.38718,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.27654,
            "nubia_score": 0.85173
        },
        "bleurt": 0.28163,
        "bertscore": {
            "precision": 0.92402,
            "recall": 0.91067,
            "f1": 0.91707
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7760,
        "mean_pred_length": 21.615598885793872,
        "std_pred_length": 9.403512744681423,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.35966494845360825,
        "vocab_size-1": 2791,
        "unique-1": 2028,
        "entropy-1": 9.188144884333632,
        "distinct-2": 0.8255641129577084,
        "vocab_size-2": 6110,
        "unique-2": 5637,
        "entropy-2": 12.224661288830381,
        "cond_entropy-2": 2.8001553479838672,
        "distinct-3": 0.9606645839250213,
        "vocab_size-3": 6765,
        "unique-3": 6634,
        "entropy-3": 12.64580267724211,
        "cond_entropy-3": 0.43695440762963217,
        "total_length-nopunct": 6820,
        "mean_pred_length-nopunct": 18.997214484679667,
        "std_pred_length-nopunct": 8.108765712326052,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.40747800586510263,
        "vocab_size-1-nopunct": 2779,
        "unique-1-nopunct": 2026,
        "entropy-1-nopunct": 9.554039108722176,
        "distinct-2-nopunct": 0.8562142083268843,
        "vocab_size-2-nopunct": 5532,
        "unique-2-nopunct": 5153,
        "entropy-2-nopunct": 12.171902248092573,
        "cond_entropy-2-nopunct": 2.7476322655498087,
        "distinct-3-nopunct": 0.9804981973123567,
        "vocab_size-3-nopunct": 5983,
        "unique-3-nopunct": 5890,
        "entropy-3-nopunct": 12.53167607520254,
        "cond_entropy-3-nopunct": 0.3825261721861503,
        "msttr-100": 0.72299,
        "msttr-100_nopunct": 0.76941,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 86.34939,
        "nist": 13.329512713282538,
        "rouge1": {
            "precision": 0.89874,
            "recall": 0.90638,
            "fmeasure": 0.89862
        },
        "rouge2": {
            "precision": 0.80532,
            "recall": 0.81573,
            "fmeasure": 0.80561
        },
        "rougeL": {
            "precision": 0.88654,
            "recall": 0.89608,
            "fmeasure": 0.88722
        },
        "rougeLsum": {
            "precision": 0.88654,
            "recall": 0.89608,
            "fmeasure": 0.88722
        },
        "local_recall": {
            "1": 0.03381109886071297,
            "2": 0.17452830188679244,
            "3": 0.40602409638554215,
            "4": 0.617737003058104,
            "5": 0.7465857359635811,
            "6": 0.8464788732394366,
            "7": 0.8838797814207651,
            "8": 0.9227985524728589,
            "9": 0.9513227513227513,
            "10": 0.9798449612403101
        },
        "meteor": 0.551356493160983,
        "nubia": {
            "semantic_relation": 4.36984,
            "contradiction": 2.52055,
            "irrelevancy": 33.99611,
            "logical_agreement": 63.48333,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.69195,
            "nubia_score": 0.69208
        },
        "bleurt": 0.30287,
        "bertscore": {
            "precision": 0.9719,
            "recall": 0.97818,
            "f1": 0.97285
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 2517,
        "total_length": 36378,
        "mean_pred_length": 14.452920143027413,
        "std_pred_length": 4.219714172598681,
        "median_pred_length": 14.0,
        "min_pred_length": 1,
        "max_pred_length": 33,
        "distinct-1": 0.06745835395018968,
        "vocab_size-1": 2454,
        "unique-1": 1140,
        "entropy-1": 8.10981420163727,
        "distinct-2": 0.24030595670535423,
        "vocab_size-2": 8137,
        "unique-2": 4691,
        "entropy-2": 11.32245235875196,
        "cond_entropy-2": 2.970419131454079,
        "distinct-3": 0.41266549688945603,
        "vocab_size-3": 12935,
        "unique-3": 8869,
        "entropy-3": 12.559610926340737,
        "cond_entropy-3": 1.2896726097137958,
        "total_length-nopunct": 31981,
        "mean_pred_length-nopunct": 12.705999205403257,
        "std_pred_length-nopunct": 3.7695030867287445,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.07629530033457366,
        "vocab_size-1-nopunct": 2440,
        "unique-1-nopunct": 1138,
        "entropy-1-nopunct": 8.335346974596602,
        "distinct-2-nopunct": 0.2563467282106978,
        "vocab_size-2-nopunct": 7553,
        "unique-2-nopunct": 4492,
        "entropy-2-nopunct": 11.194854919243271,
        "cond_entropy-2-nopunct": 3.0292830911983923,
        "distinct-3-nopunct": 0.4319430013359062,
        "vocab_size-3-nopunct": 11640,
        "unique-3-nopunct": 8194,
        "entropy-3-nopunct": 12.399833072168041,
        "cond_entropy-3-nopunct": 1.2919049436857202,
        "msttr-100": 0.69504,
        "msttr-100_nopunct": 0.72605,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 34.77635,
        "nist": 7.128817483700119,
        "rouge1": {
            "precision": 0.6552,
            "recall": 0.62367,
            "fmeasure": 0.62803
        },
        "rouge2": {
            "precision": 0.42409,
            "recall": 0.40405,
            "fmeasure": 0.40628
        },
        "rougeL": {
            "precision": 0.57435,
            "recall": 0.54761,
            "fmeasure": 0.55105
        },
        "rougeLsum": {
            "precision": 0.57435,
            "recall": 0.54761,
            "fmeasure": 0.55105
        },
        "local_recall": {
            "1": 0.5994249820306885
        },
        "meteor": 0.33760297931208116,
        "nubia": {
            "semantic_relation": 4.1351,
            "contradiction": 3.86481,
            "irrelevancy": 18.72127,
            "logical_agreement": 77.41392,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.6366,
            "nubia_score": 0.74132
        },
        "bleurt": -0.00274,
        "bertscore": {
            "precision": 0.89013,
            "recall": 0.88212,
            "f1": 0.8857
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 214,
        "total_length": 4368,
        "mean_pred_length": 20.411214953271028,
        "std_pred_length": 5.616985706803125,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 41,
        "distinct-1": 0.2838827838827839,
        "vocab_size-1": 1240,
        "unique-1": 660,
        "entropy-1": 8.5034972222994,
        "distinct-2": 0.574867597496389,
        "vocab_size-2": 2388,
        "unique-2": 1622,
        "entropy-2": 10.752882149220163,
        "cond_entropy-2": 2.0106187411497816,
        "distinct-3": 0.733756345177665,
        "vocab_size-3": 2891,
        "unique-3": 2271,
        "entropy-3": 11.283241781560498,
        "cond_entropy-3": 0.5401164738641087,
        "total_length-nopunct": 3648,
        "mean_pred_length-nopunct": 17.046728971962615,
        "std_pred_length-nopunct": 5.229111855344335,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.33826754385964913,
        "vocab_size-1-nopunct": 1234,
        "unique-1-nopunct": 659,
        "entropy-1-nopunct": 9.047752191434231,
        "distinct-2-nopunct": 0.6094933022714036,
        "vocab_size-2-nopunct": 2093,
        "unique-2-nopunct": 1467,
        "entropy-2-nopunct": 10.632718269441524,
        "cond_entropy-2-nopunct": 1.6424420145909058,
        "distinct-3-nopunct": 0.7521739130434782,
        "vocab_size-3-nopunct": 2422,
        "unique-3-nopunct": 1945,
        "entropy-3-nopunct": 11.038377799118056,
        "cond_entropy-3-nopunct": 0.4344001964961229,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.78722,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 48.3797,
        "nist": 8.509121378157218,
        "rouge1": {
            "precision": 0.4468,
            "recall": 0.46799,
            "fmeasure": 0.45348
        },
        "rouge2": {
            "precision": 0.23072,
            "recall": 0.24677,
            "fmeasure": 0.23527
        },
        "rougeL": {
            "precision": 0.43255,
            "recall": 0.45359,
            "fmeasure": 0.43914
        },
        "rougeLsum": {
            "precision": 0.43255,
            "recall": 0.45359,
            "fmeasure": 0.43914
        },
        "local_recall": {
            "1": 0.27927595123753235,
            "2": 0.6550416982562547,
            "3": 0.8904593639575972,
            "4": 1.0
        },
        "meteor": 0.6502269672788259,
        "nubia": {
            "semantic_relation": 3.97952,
            "contradiction": 18.65153,
            "irrelevancy": 22.97776,
            "logical_agreement": 58.37071,
            "grammar_ref": 2.61878,
            "grammar_hyp": 2.57467,
            "nubia_score": 0.83245
        },
        "bleurt": 0.13574,
        "bertscore": {
            "precision": 0.95425,
            "recall": 0.95156,
            "f1": 0.95209
        }
    },
    "mlsum_es_test": {
        "predictions_file": "mT5_xl/mlsum_es_test",
        "N": 13366,
        "total_length": 297434,
        "mean_pred_length": 22.25303007631303,
        "std_pred_length": 8.14149086047738,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 170,
        "distinct-1": 0.10276901766442303,
        "vocab_size-1": 30567,
        "unique-1": 16512,
        "entropy-1": 10.023354198023284,
        "distinct-2": 0.45771435008519085,
        "vocab_size-2": 130022,
        "unique-2": 100243,
        "entropy-2": 15.392476276966024,
        "cond_entropy-2": 5.545067193177531,
        "distinct-3": 0.789491765853226,
        "vocab_size-3": 213717,
        "unique-3": 192051,
        "entropy-3": 17.342317212301477,
        "cond_entropy-3": 1.996042395956356,
        "total_length-nopunct": 281116,
        "mean_pred_length-nopunct": 21.032171180607513,
        "std_pred_length-nopunct": 7.254847489079656,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 119,
        "distinct-1-nopunct": 0.10867755659585367,
        "vocab_size-1-nopunct": 30551,
        "unique-1-nopunct": 16511,
        "entropy-1-nopunct": 10.191517053431422,
        "distinct-2-nopunct": 0.4817478991596639,
        "vocab_size-2-nopunct": 128988,
        "unique-2-nopunct": 101249,
        "entropy-2-nopunct": 15.492653343183127,
        "cond_entropy-2-nopunct": 5.48843574370032,
        "distinct-3-nopunct": 0.8093748034467576,
        "vocab_size-3-nopunct": 205892,
        "unique-3-nopunct": 186903,
        "entropy-3-nopunct": 17.332934976183697,
        "cond_entropy-3-nopunct": 1.879373896584002,
        "msttr-100": 0.70775,
        "msttr-100_nopunct": 0.72064,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "bleu": 10.7705,
        "nist": 3.5255691781158562,
        "rouge1": {
            "precision": 0.34289,
            "recall": 0.32419,
            "fmeasure": 0.32139
        },
        "rouge2": {
            "precision": 0.1472,
            "recall": 0.13955,
            "fmeasure": 0.13815
        },
        "rougeL": {
            "precision": 0.2774,
            "recall": 0.26311,
            "fmeasure": 0.26053
        },
        "rougeLsum": {
            "precision": 0.2774,
            "recall": 0.26311,
            "fmeasure": 0.26053
        },
        "local_recall": {
            "1": 0.3011472275334608
        },
        "meteor": 0.23886728502152316,
        "nubia": {
            "semantic_relation": 1.85059,
            "contradiction": 26.00361,
            "irrelevancy": 61.42753,
            "logical_agreement": 12.56886,
            "grammar_ref": 5.26998,
            "grammar_hyp": 5.23298,
            "nubia_score": 0.20993
        },
        "bleurt": -0.4024,
        "bertscore": {
            "precision": 0.84823,
            "recall": 0.84552,
            "f1": 0.84665
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7167,
        "mean_pred_length": 19.963788300835656,
        "std_pred_length": 9.29589858462179,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.3573322171061811,
        "vocab_size-1": 2561,
        "unique-1": 1869,
        "entropy-1": 9.113280774616257,
        "distinct-2": 0.832256169212691,
        "vocab_size-2": 5666,
        "unique-2": 5238,
        "entropy-2": 12.139825987465183,
        "cond_entropy-2": 2.7671722316842198,
        "distinct-3": 0.9615444254923244,
        "vocab_size-3": 6201,
        "unique-3": 6079,
        "entropy-3": 12.526257117156364,
        "cond_entropy-3": 0.4056865141794836,
        "total_length-nopunct": 6341,
        "mean_pred_length-nopunct": 17.662952646239553,
        "std_pred_length-nopunct": 8.092814184272115,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.40198706828575936,
        "vocab_size-1-nopunct": 2549,
        "unique-1-nopunct": 1868,
        "entropy-1-nopunct": 9.453751403450571,
        "distinct-2-nopunct": 0.8567368772985624,
        "vocab_size-2-nopunct": 5125,
        "unique-2-nopunct": 4772,
        "entropy-2-nopunct": 12.061882539880092,
        "cond_entropy-2-nopunct": 2.7488311245862627,
        "distinct-3-nopunct": 0.9779477147430198,
        "vocab_size-3-nopunct": 5499,
        "unique-3-nopunct": 5403,
        "entropy-3-nopunct": 12.407352949029834,
        "cond_entropy-3-nopunct": 0.3694223002622433,
        "msttr-100": 0.7269,
        "msttr-100_nopunct": 0.76762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 67.21602,
        "nist": 11.095537431856437,
        "rouge1": {
            "precision": 0.84507,
            "recall": 0.78787,
            "fmeasure": 0.80316
        },
        "rouge2": {
            "precision": 0.7046,
            "recall": 0.65558,
            "fmeasure": 0.66725
        },
        "rougeL": {
            "precision": 0.81486,
            "recall": 0.76168,
            "fmeasure": 0.77518
        },
        "rougeLsum": {
            "precision": 0.81486,
            "recall": 0.76168,
            "fmeasure": 0.77518
        },
        "local_recall": {
            "1": 0.04647707979626486,
            "2": 0.16219667943805874,
            "3": 0.4026258205689278,
            "4": 0.5404120443740095,
            "5": 0.6355140186915887,
            "6": 0.7518115942028986,
            "7": 0.8694158075601375
        },
        "meteor": 0.45786204822397686,
        "nubia": {
            "semantic_relation": 4.28957,
            "contradiction": 4.23798,
            "irrelevancy": 17.2489,
            "logical_agreement": 78.51313,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.90086,
            "nubia_score": 0.69691
        },
        "bleurt": 0.21354,
        "bertscore": {
            "precision": 0.95341,
            "recall": 0.94332,
            "f1": 0.94609
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7167,
        "mean_pred_length": 19.963788300835656,
        "std_pred_length": 9.29589858462179,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.3573322171061811,
        "vocab_size-1": 2561,
        "unique-1": 1869,
        "entropy-1": 9.113280774616257,
        "distinct-2": 0.832256169212691,
        "vocab_size-2": 5666,
        "unique-2": 5238,
        "entropy-2": 12.139825987465183,
        "cond_entropy-2": 2.7671722316842198,
        "distinct-3": 0.9615444254923244,
        "vocab_size-3": 6201,
        "unique-3": 6079,
        "entropy-3": 12.526257117156364,
        "cond_entropy-3": 0.4056865141794836,
        "total_length-nopunct": 6341,
        "mean_pred_length-nopunct": 17.662952646239553,
        "std_pred_length-nopunct": 8.092814184272115,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.40198706828575936,
        "vocab_size-1-nopunct": 2549,
        "unique-1-nopunct": 1868,
        "entropy-1-nopunct": 9.453751403450571,
        "distinct-2-nopunct": 0.8567368772985624,
        "vocab_size-2-nopunct": 5125,
        "unique-2-nopunct": 4772,
        "entropy-2-nopunct": 12.061882539880092,
        "cond_entropy-2-nopunct": 2.7488311245862627,
        "distinct-3-nopunct": 0.9779477147430198,
        "vocab_size-3-nopunct": 5499,
        "unique-3-nopunct": 5403,
        "entropy-3-nopunct": 12.407352949029834,
        "cond_entropy-3-nopunct": 0.3694223002622433,
        "msttr-100": 0.7269,
        "msttr-100_nopunct": 0.76762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 67.21602,
        "nist": 11.095537431856437,
        "rouge1": {
            "precision": 0.84507,
            "recall": 0.78787,
            "fmeasure": 0.80316
        },
        "rouge2": {
            "precision": 0.7046,
            "recall": 0.65558,
            "fmeasure": 0.66725
        },
        "rougeL": {
            "precision": 0.81486,
            "recall": 0.76168,
            "fmeasure": 0.77518
        },
        "rougeLsum": {
            "precision": 0.81486,
            "recall": 0.76168,
            "fmeasure": 0.77518
        },
        "local_recall": {
            "1": 0.04647707979626486,
            "2": 0.16219667943805874,
            "3": 0.4026258205689278,
            "4": 0.5404120443740095,
            "5": 0.6355140186915887,
            "6": 0.7518115942028986,
            "7": 0.8694158075601375
        },
        "meteor": 0.45786204822397686,
        "nubia": {
            "semantic_relation": 4.28957,
            "contradiction": 4.23798,
            "irrelevancy": 17.2489,
            "logical_agreement": 78.51313,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.90086,
            "nubia_score": 0.69691
        },
        "bleurt": 0.21354,
        "bertscore": {
            "precision": 0.95341,
            "recall": 0.94332,
            "f1": 0.94609
        }
    },
    "mlsum_es_challenge_test_covid": {
        "predictions_file": "mT5_xl/mlsum_es_challenge_test_covid",
        "N": 1938,
        "total_length": 46190,
        "mean_pred_length": 23.833849329205368,
        "std_pred_length": 8.109814521985905,
        "median_pred_length": 23.0,
        "min_pred_length": 4,
        "max_pred_length": 75,
        "distinct-1": 0.19149166486252436,
        "vocab_size-1": 8845,
        "unique-1": 5561,
        "entropy-1": 9.535318487785739,
        "distinct-2": 0.6331013287535027,
        "vocab_size-2": 28016,
        "unique-2": 23475,
        "entropy-2": 13.949707535271239,
        "cond_entropy-2": 4.5390275651785,
        "distinct-3": 0.911305950749161,
        "vocab_size-3": 38561,
        "unique-3": 36534,
        "entropy-3": 15.12892863935195,
        "cond_entropy-3": 1.1930348610321984,
        "total_length-nopunct": 43749,
        "mean_pred_length-nopunct": 22.574303405572756,
        "std_pred_length-nopunct": 7.348602652481951,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.20178746942787262,
        "vocab_size-1-nopunct": 8828,
        "unique-1-nopunct": 5558,
        "entropy-1-nopunct": 9.649029813443178,
        "distinct-2-nopunct": 0.6553538542488819,
        "vocab_size-2-nopunct": 27401,
        "unique-2-nopunct": 23175,
        "entropy-2-nopunct": 13.978890446356033,
        "cond_entropy-2-nopunct": 4.466920037031452,
        "distinct-3-nopunct": 0.9209490131166453,
        "vocab_size-3-nopunct": 36721,
        "unique-3-nopunct": 34980,
        "entropy-3-nopunct": 15.072851395658448,
        "cond_entropy-3-nopunct": 1.1029130070592033,
        "msttr-100": 0.71935,
        "msttr-100_nopunct": 0.72863,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_challenge_test_covid.json",
        "bleu": 4.60295,
        "nist": 2.1634997943859036,
        "rouge1": {
            "precision": 0.28129,
            "recall": 0.25999,
            "fmeasure": 0.25878
        },
        "rouge2": {
            "precision": 0.07765,
            "recall": 0.07068,
            "fmeasure": 0.07099
        },
        "rougeL": {
            "precision": 0.20775,
            "recall": 0.19168,
            "fmeasure": 0.19079
        },
        "rougeLsum": {
            "precision": 0.20775,
            "recall": 0.19168,
            "fmeasure": 0.19079
        },
        "local_recall": {
            "1": 0.238897986706483
        },
        "meteor": 0.17284605860872437,
        "nubia": {
            "semantic_relation": 1.43338,
            "contradiction": 29.95793,
            "irrelevancy": 61.21048,
            "logical_agreement": 8.83158,
            "grammar_ref": 5.23427,
            "grammar_hyp": 5.28013,
            "nubia_score": 0.15305
        },
        "bleurt": -0.49621,
        "bertscore": {
            "precision": 0.83634,
            "recall": 0.83296,
            "f1": 0.83447
        }
    },
    "wiki_lingua_spanish_es_val": {
        "predictions_file": "mT5_xl/wiki_lingua_spanish_es_val",
        "N": 11316,
        "total_length": 376946,
        "mean_pred_length": 33.31088723930718,
        "std_pred_length": 17.02204271011877,
        "median_pred_length": 30.0,
        "min_pred_length": 1,
        "max_pred_length": 122,
        "distinct-1": 0.03875886731786516,
        "vocab_size-1": 14610,
        "unique-1": 5366,
        "entropy-1": 9.025963259746343,
        "distinct-2": 0.2649481716489347,
        "vocab_size-2": 96873,
        "unique-2": 62807,
        "entropy-2": 14.393567620180772,
        "cond_entropy-2": 5.1816476602621755,
        "distinct-3": 0.6070671577551049,
        "vocab_size-3": 215093,
        "unique-3": 174594,
        "entropy-3": 16.88496574568363,
        "cond_entropy-3": 2.488682280680684,
        "total_length-nopunct": 319469,
        "mean_pred_length-nopunct": 28.23161894662425,
        "std_pred_length-nopunct": 15.230501638634506,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 110,
        "distinct-1-nopunct": 0.045653881910294895,
        "vocab_size-1-nopunct": 14585,
        "unique-1-nopunct": 5365,
        "entropy-1-nopunct": 9.851287724974984,
        "distinct-2-nopunct": 0.3877931164287986,
        "vocab_size-2-nopunct": 119500,
        "unique-2-nopunct": 86701,
        "entropy-2-nopunct": 15.131588952879088,
        "cond_entropy-2-nopunct": 5.3897765351440565,
        "distinct-3-nopunct": 0.7379320102816679,
        "vocab_size-3-nopunct": 219047,
        "unique-3-nopunct": 189453,
        "entropy-3-nopunct": 17.298756269876353,
        "cond_entropy-3-nopunct": 2.2051377028712524,
        "msttr-100": 0.58641,
        "msttr-100_nopunct": 0.66008,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_val.json",
        "bleu": 14.31522,
        "nist": 4.8976811094383965,
        "rouge1": {
            "precision": 0.46924,
            "recall": 0.405,
            "fmeasure": 0.41395
        },
        "rouge2": {
            "precision": 0.19523,
            "recall": 0.1695,
            "fmeasure": 0.17301
        },
        "rougeL": {
            "precision": 0.39379,
            "recall": 0.34132,
            "fmeasure": 0.34803
        },
        "rougeLsum": {
            "precision": 0.39379,
            "recall": 0.34132,
            "fmeasure": 0.34803
        },
        "local_recall": {
            "1": 0.3575632970840552
        },
        "sari": 69.5745,
        "meteor": 0.1957126550322882,
        "nubia": {
            "semantic_relation": 3.11866,
            "contradiction": 11.74756,
            "irrelevancy": 42.275,
            "logical_agreement": 45.97744,
            "grammar_ref": 3.95671,
            "grammar_hyp": 3.76005,
            "nubia_score": 0.45633
        },
        "bleurt": -0.23917,
        "bertscore": {
            "precision": 0.87069,
            "recall": 0.85241,
            "f1": 0.8609
        }
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "mT5_xl/wiki_lingua_spanish_es_test",
        "N": 22632,
        "total_length": 751788,
        "mean_pred_length": 33.217921527041355,
        "std_pred_length": 17.096198732225723,
        "median_pred_length": 30.0,
        "min_pred_length": 2,
        "max_pred_length": 128,
        "distinct-1": 0.025930182445051,
        "vocab_size-1": 19494,
        "unique-1": 6880,
        "entropy-1": 9.065699711436737,
        "distinct-2": 0.21329866311187182,
        "vocab_size-2": 155528,
        "unique-2": 97623,
        "entropy-2": 14.643913244520707,
        "cond_entropy-2": 5.390329103875187,
        "distinct-3": 0.5405124242063963,
        "vocab_size-3": 381885,
        "unique-3": 299901,
        "entropy-3": 17.459829685671806,
        "cond_entropy-3": 2.8101779630309127,
        "total_length-nopunct": 637438,
        "mean_pred_length-nopunct": 28.16534110993284,
        "std_pred_length-nopunct": 15.26028631867834,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 109,
        "distinct-1-nopunct": 0.030544147038613953,
        "vocab_size-1-nopunct": 19470,
        "unique-1-nopunct": 6880,
        "entropy-1-nopunct": 9.896800906027638,
        "distinct-2-nopunct": 0.3265143801459322,
        "vocab_size-2-nopunct": 200743,
        "unique-2-nopunct": 140510,
        "entropy-2-nopunct": 15.487414797921641,
        "cond_entropy-2-nopunct": 5.702841463295447,
        "distinct-3-nopunct": 0.6787801620123713,
        "vocab_size-3-nopunct": 401958,
        "unique-3-nopunct": 338642,
        "entropy-3-nopunct": 18.005921744454845,
        "cond_entropy-3-nopunct": 2.5602919801216357,
        "msttr-100": 0.58706,
        "msttr-100_nopunct": 0.66111,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "bleu": 14.01859,
        "nist": 4.881066671314124,
        "rouge1": {
            "precision": 0.4695,
            "recall": 0.40204,
            "fmeasure": 0.41246
        },
        "rouge2": {
            "precision": 0.19465,
            "recall": 0.16768,
            "fmeasure": 0.17188
        },
        "rougeL": {
            "precision": 0.39267,
            "recall": 0.3379,
            "fmeasure": 0.34573
        },
        "rougeLsum": {
            "precision": 0.39267,
            "recall": 0.3379,
            "fmeasure": 0.34573
        },
        "local_recall": {
            "1": 0.35353982147978946
        },
        "sari": 69.54697,
        "meteor": 0.19364664271286683,
        "nubia": {
            "semantic_relation": 3.10362,
            "contradiction": 12.27889,
            "irrelevancy": 42.1434,
            "logical_agreement": 45.57771,
            "grammar_ref": 3.9494,
            "grammar_hyp": 3.76175,
            "nubia_score": 0.45163
        },
        "bleurt": -0.24384,
        "bertscore": {
            "precision": 0.87074,
            "recall": 0.85157,
            "f1": 0.86051
        }
    },
    "wiki_lingua_russian_ru_val": {
        "predictions_file": "mT5_xl/wiki_lingua_russian_ru_val",
        "N": 5288,
        "total_length": 168102,
        "mean_pred_length": 31.7893343419062,
        "std_pred_length": 15.875623556534412,
        "median_pred_length": 29.0,
        "min_pred_length": 3,
        "max_pred_length": 119,
        "distinct-1": 0.05719146708546002,
        "vocab_size-1": 9614,
        "unique-1": 3706,
        "entropy-1": 8.87543783934044,
        "distinct-2": 0.3202304470131561,
        "vocab_size-2": 52138,
        "unique-2": 34353,
        "entropy-2": 13.932454945006048,
        "cond_entropy-2": 4.862990483022756,
        "distinct-3": 0.6644998285997232,
        "vocab_size-3": 104676,
        "unique-3": 86652,
        "entropy-3": 16.060494812124453,
        "cond_entropy-3": 2.130309799498741,
        "total_length-nopunct": 141439,
        "mean_pred_length-nopunct": 26.74716338880484,
        "std_pred_length-nopunct": 14.02605203452742,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 101,
        "distinct-1-nopunct": 0.06781015137267656,
        "vocab_size-1-nopunct": 9591,
        "unique-1-nopunct": 3704,
        "entropy-1-nopunct": 9.721328514977502,
        "distinct-2-nopunct": 0.45189532210560335,
        "vocab_size-2-nopunct": 61526,
        "unique-2-nopunct": 45796,
        "entropy-2-nopunct": 14.565223893609597,
        "cond_entropy-2-nopunct": 4.958295927996386,
        "distinct-3-nopunct": 0.7911556360468581,
        "vocab_size-3-nopunct": 103533,
        "unique-3-nopunct": 91362,
        "entropy-3-nopunct": 16.354082379933338,
        "cond_entropy-3-nopunct": 1.82401440262844,
        "msttr-100": 0.59659,
        "msttr-100_nopunct": 0.6753,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_val.json",
        "bleu": 12.42571,
        "nist": 3.9708987170760492,
        "rouge1": {
            "precision": 0.43349,
            "recall": 0.36178,
            "fmeasure": 0.37332
        },
        "rouge2": {
            "precision": 0.16829,
            "recall": 0.14345,
            "fmeasure": 0.14714
        },
        "rougeL": {
            "precision": 0.35953,
            "recall": 0.30216,
            "fmeasure": 0.31068
        },
        "rougeLsum": {
            "precision": 0.35953,
            "recall": 0.30216,
            "fmeasure": 0.31068
        },
        "local_recall": {
            "1": 0.3160217470312929
        },
        "sari": 70.08361,
        "meteor": 0.17477511674111978,
        "nubia": {
            "semantic_relation": 2.90062,
            "contradiction": 14.49354,
            "irrelevancy": 42.55236,
            "logical_agreement": 42.9541,
            "grammar_ref": 3.95099,
            "grammar_hyp": 3.82326,
            "nubia_score": 0.40495
        },
        "bleurt": -0.30331,
        "bertscore": {
            "precision": 0.86048,
            "recall": 0.84184,
            "f1": 0.85052
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.82724,
        "nist": 4.1772678686203895,
        "rouge1": {
            "precision": 0.63158,
            "recall": 0.58328,
            "fmeasure": 0.60576
        },
        "rouge2": {
            "precision": 0.35135,
            "recall": 0.32633,
            "fmeasure": 0.33767
        },
        "rougeL": {
            "precision": 0.34211,
            "recall": 0.31364,
            "fmeasure": 0.32691
        },
        "rougeLsum": {
            "precision": 0.34211,
            "recall": 0.31364,
            "fmeasure": 0.32691
        },
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "meteor": 0.33334982888118725,
        "nubia": {
            "semantic_relation": 2.71316,
            "contradiction": 15.716,
            "irrelevancy": 54.56408,
            "logical_agreement": 29.71992,
            "grammar_ref": 4.14314,
            "grammar_hyp": 3.95384,
            "nubia_score": 0.39639
        },
        "bleurt": -0.38788,
        "bertscore": {
            "precision": 0.9211,
            "recall": 0.89241,
            "f1": 0.90652
        }
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "mT5_xl/wiki_lingua_russian_ru_test",
        "N": 10580,
        "total_length": 332789,
        "mean_pred_length": 31.45453686200378,
        "std_pred_length": 15.77423161388743,
        "median_pred_length": 29.0,
        "min_pred_length": 2,
        "max_pred_length": 113,
        "distinct-1": 0.038507883373549004,
        "vocab_size-1": 12815,
        "unique-1": 4601,
        "entropy-1": 8.918389675291289,
        "distinct-2": 0.2573484911967077,
        "vocab_size-2": 82920,
        "unique-2": 52589,
        "entropy-2": 14.191539254920757,
        "cond_entropy-2": 5.075979947893807,
        "distinct-3": 0.593311277191789,
        "vocab_size-3": 184893,
        "unique-3": 147897,
        "entropy-3": 16.648360200929023,
        "cond_entropy-3": 2.4547758817075738,
        "total_length-nopunct": 279921,
        "mean_pred_length-nopunct": 26.457561436672968,
        "std_pred_length-nopunct": 13.96988370617966,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 102,
        "distinct-1-nopunct": 0.04568074563894813,
        "vocab_size-1-nopunct": 12787,
        "unique-1-nopunct": 4599,
        "entropy-1-nopunct": 9.778983023714066,
        "distinct-2-nopunct": 0.38311285693600305,
        "vocab_size-2-nopunct": 103188,
        "unique-2-nopunct": 73959,
        "entropy-2-nopunct": 14.957079736789487,
        "cond_entropy-2-nopunct": 5.29444024958944,
        "distinct-3-nopunct": 0.7329370891510765,
        "vocab_size-3-nopunct": 189657,
        "unique-3-nopunct": 163026,
        "entropy-3-nopunct": 17.086512603029924,
        "cond_entropy-3-nopunct": 2.1684938272159924,
        "msttr-100": 0.59619,
        "msttr-100_nopunct": 0.67594,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "bleu": 12.42356,
        "nist": 4.071172185641082,
        "rouge1": {
            "precision": 0.43165,
            "recall": 0.36204,
            "fmeasure": 0.37241
        },
        "rouge2": {
            "precision": 0.16706,
            "recall": 0.14179,
            "fmeasure": 0.14551
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.30155,
            "fmeasure": 0.30912
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.30155,
            "fmeasure": 0.30912
        },
        "local_recall": {
            "1": 0.31608656162974863
        },
        "sari": 69.95697,
        "meteor": 0.17436205626166815,
        "nubia": {
            "semantic_relation": 2.90265,
            "contradiction": 14.06579,
            "irrelevancy": 42.07387,
            "logical_agreement": 43.86034,
            "grammar_ref": 3.95647,
            "grammar_hyp": 3.81669,
            "nubia_score": 0.40683
        },
        "bleurt": -0.30749,
        "bertscore": {
            "precision": 0.86085,
            "recall": 0.8417,
            "f1": 0.85062
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 1328,
        "total_length": 24864,
        "mean_pred_length": 18.72289156626506,
        "std_pred_length": 5.022091564979407,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 45,
        "distinct-1": 0.08027670527670527,
        "vocab_size-1": 1996,
        "unique-1": 965,
        "entropy-1": 7.994394042808749,
        "distinct-2": 0.26159925220938135,
        "vocab_size-2": 6157,
        "unique-2": 3663,
        "entropy-2": 10.996153639630453,
        "cond_entropy-2": 2.819579348296561,
        "distinct-3": 0.4308807636887608,
        "vocab_size-3": 9569,
        "unique-3": 6637,
        "entropy-3": 12.2208636213335,
        "cond_entropy-3": 1.2846114106854227,
        "total_length-nopunct": 21904,
        "mean_pred_length-nopunct": 16.49397590361446,
        "std_pred_length-nopunct": 4.425585507450592,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.09053140978816654,
        "vocab_size-1-nopunct": 1983,
        "unique-1-nopunct": 963,
        "entropy-1-nopunct": 8.21901304827293,
        "distinct-2-nopunct": 0.27984059097978226,
        "vocab_size-2-nopunct": 5758,
        "unique-2-nopunct": 3534,
        "entropy-2-nopunct": 10.922564672535872,
        "cond_entropy-2-nopunct": 2.844012386590168,
        "distinct-3-nopunct": 0.45594347464671653,
        "vocab_size-3-nopunct": 8776,
        "unique-3-nopunct": 6245,
        "entropy-3-nopunct": 12.142085807002944,
        "cond_entropy-3-nopunct": 1.296905943281049,
        "msttr-100": 0.68585,
        "msttr-100_nopunct": 0.71543,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 32.78539,
        "nist": 6.939610083319856,
        "rouge1": {
            "precision": 0.66268,
            "recall": 0.62665,
            "fmeasure": 0.63304
        },
        "rouge2": {
            "precision": 0.42996,
            "recall": 0.40847,
            "fmeasure": 0.41134
        },
        "rougeL": {
            "precision": 0.56199,
            "recall": 0.53188,
            "fmeasure": 0.53734
        },
        "rougeLsum": {
            "precision": 0.56199,
            "recall": 0.53188,
            "fmeasure": 0.53734
        },
        "local_recall": {
            "1": 0.6046681254558717
        },
        "meteor": 0.33745713025464913,
        "nubia": {
            "semantic_relation": 4.2654,
            "contradiction": 3.6567,
            "irrelevancy": 15.69268,
            "logical_agreement": 80.65063,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.64822,
            "nubia_score": 0.7576
        },
        "bleurt": -0.01072,
        "bertscore": {
            "precision": 0.89557,
            "recall": 0.88297,
            "f1": 0.88883
        }
    },
    "wiki_lingua_turkish_tr_val": {
        "predictions_file": "mT5_xl/wiki_lingua_turkish_tr_val",
        "N": 449,
        "total_length": 15408,
        "mean_pred_length": 34.3162583518931,
        "std_pred_length": 17.69218941795956,
        "median_pred_length": 31.0,
        "min_pred_length": 3,
        "max_pred_length": 112,
        "distinct-1": 0.1551791277258567,
        "vocab_size-1": 2391,
        "unique-1": 1136,
        "entropy-1": 8.203741449441202,
        "distinct-2": 0.5036432916638812,
        "vocab_size-2": 7534,
        "unique-2": 5379,
        "entropy-2": 11.964320689123975,
        "cond_entropy-2": 3.602745508357854,
        "distinct-3": 0.7640937284631288,
        "vocab_size-3": 11087,
        "unique-3": 9426,
        "entropy-3": 13.118400145937668,
        "cond_entropy-3": 1.1672751827987111,
        "total_length-nopunct": 12954,
        "mean_pred_length-nopunct": 28.85077951002227,
        "std_pred_length-nopunct": 15.396974381515966,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 103,
        "distinct-1-nopunct": 0.18357264165508724,
        "vocab_size-1-nopunct": 2378,
        "unique-1-nopunct": 1131,
        "entropy-1-nopunct": 8.929480400492405,
        "distinct-2-nopunct": 0.6119952019192323,
        "vocab_size-2-nopunct": 7653,
        "unique-2-nopunct": 5943,
        "entropy-2-nopunct": 12.279522520388998,
        "cond_entropy-2-nopunct": 3.436714236951839,
        "distinct-3-nopunct": 0.8526874585268746,
        "vocab_size-3-nopunct": 10280,
        "unique-3-nopunct": 9178,
        "entropy-3-nopunct": 13.173237215198698,
        "cond_entropy-3-nopunct": 0.9141958905055773,
        "msttr-100": 0.57591,
        "msttr-100_nopunct": 0.65016,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_val.json",
        "bleu": 19.1871,
        "nist": 4.335777361863774,
        "rouge1": {
            "precision": 0.45027,
            "recall": 0.39872,
            "fmeasure": 0.40001
        },
        "rouge2": {
            "precision": 0.20636,
            "recall": 0.19045,
            "fmeasure": 0.18847
        },
        "rougeL": {
            "precision": 0.38058,
            "recall": 0.33933,
            "fmeasure": 0.33917
        },
        "rougeLsum": {
            "precision": 0.38058,
            "recall": 0.33933,
            "fmeasure": 0.33917
        },
        "local_recall": {
            "1": 0.362463924963925
        },
        "sari": 70.27907,
        "meteor": 0.19638251084418926,
        "nubia": {
            "semantic_relation": 2.90517,
            "contradiction": 20.01017,
            "irrelevancy": 42.67335,
            "logical_agreement": 37.31648,
            "grammar_ref": 3.85457,
            "grammar_hyp": 3.80973,
            "nubia_score": 0.39526
        },
        "bleurt": -0.31832,
        "bertscore": {
            "precision": 0.86401,
            "recall": 0.85076,
            "f1": 0.85682
        }
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "mT5_xl/wiki_lingua_turkish_tr_test",
        "N": 900,
        "total_length": 31741,
        "mean_pred_length": 35.26777777777778,
        "std_pred_length": 17.624555646267936,
        "median_pred_length": 33.0,
        "min_pred_length": 3,
        "max_pred_length": 117,
        "distinct-1": 0.1059197882864434,
        "vocab_size-1": 3362,
        "unique-1": 1372,
        "entropy-1": 8.328819587210436,
        "distinct-2": 0.4094549463376674,
        "vocab_size-2": 12628,
        "unique-2": 8254,
        "entropy-2": 12.41459133594682,
        "cond_entropy-2": 3.930167439035221,
        "distinct-3": 0.6829765204902976,
        "vocab_size-3": 20449,
        "unique-3": 16345,
        "entropy-3": 13.86321255523207,
        "cond_entropy-3": 1.4600789775371397,
        "total_length-nopunct": 26613,
        "mean_pred_length-nopunct": 29.57,
        "std_pred_length-nopunct": 15.205649169524683,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 100,
        "distinct-1-nopunct": 0.12569045203471987,
        "vocab_size-1-nopunct": 3345,
        "unique-1-nopunct": 1371,
        "entropy-1-nopunct": 9.078010241925906,
        "distinct-2-nopunct": 0.520126006300315,
        "vocab_size-2-nopunct": 13374,
        "unique-2-nopunct": 9618,
        "entropy-2-nopunct": 12.86697269680183,
        "cond_entropy-2-nopunct": 3.876304912417933,
        "distinct-3-nopunct": 0.787611332769113,
        "vocab_size-3-nopunct": 19543,
        "unique-3-nopunct": 16597,
        "entropy-3-nopunct": 14.023539617922498,
        "cond_entropy-3-nopunct": 1.176190342808584,
        "msttr-100": 0.58101,
        "msttr-100_nopunct": 0.65462,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "bleu": 19.25815,
        "nist": 4.611069635632213,
        "rouge1": {
            "precision": 0.44457,
            "recall": 0.40201,
            "fmeasure": 0.40021
        },
        "rouge2": {
            "precision": 0.20156,
            "recall": 0.18406,
            "fmeasure": 0.18342
        },
        "rougeL": {
            "precision": 0.36945,
            "recall": 0.33584,
            "fmeasure": 0.33314
        },
        "rougeLsum": {
            "precision": 0.36945,
            "recall": 0.33584,
            "fmeasure": 0.33314
        },
        "local_recall": {
            "1": 0.3728966481707042
        },
        "sari": 69.62585,
        "meteor": 0.20069210722952427,
        "nubia": {
            "semantic_relation": 2.84499,
            "contradiction": 18.59604,
            "irrelevancy": 44.12333,
            "logical_agreement": 37.28063,
            "grammar_ref": 3.87672,
            "grammar_hyp": 3.72024,
            "nubia_score": 0.38409
        },
        "bleurt": -0.32264,
        "bertscore": {
            "precision": 0.862,
            "recall": 0.85021,
            "f1": 0.85553
        }
    },
    "wiki_lingua_vietnamese_vi_val": {
        "predictions_file": "mT5_xl/wiki_lingua_vietnamese_vi_val",
        "N": 1957,
        "total_length": 63198,
        "mean_pred_length": 32.29330608073582,
        "std_pred_length": 14.910011834066632,
        "median_pred_length": 30.0,
        "min_pred_length": 3,
        "max_pred_length": 110,
        "distinct-1": 0.08593626380581663,
        "vocab_size-1": 5431,
        "unique-1": 2226,
        "entropy-1": 8.645621390325312,
        "distinct-2": 0.3861628647474731,
        "vocab_size-2": 23649,
        "unique-2": 15953,
        "entropy-2": 13.185710183156232,
        "cond_entropy-2": 4.354211148789561,
        "distinct-3": 0.7080999932528169,
        "vocab_size-3": 41979,
        "unique-3": 35292,
        "entropy-3": 14.883501841878891,
        "cond_entropy-3": 1.7032613638353162,
        "total_length-nopunct": 53143,
        "mean_pred_length-nopunct": 27.155339805825243,
        "std_pred_length-nopunct": 13.241107093685297,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 99,
        "distinct-1-nopunct": 0.10195133884048699,
        "vocab_size-1-nopunct": 5418,
        "unique-1-nopunct": 2225,
        "entropy-1-nopunct": 9.476130909559831,
        "distinct-2-nopunct": 0.5166061032313524,
        "vocab_size-2-nopunct": 26443,
        "unique-2-nopunct": 20043,
        "entropy-2-nopunct": 13.692290416424807,
        "cond_entropy-2-nopunct": 4.3186620258435715,
        "distinct-3-nopunct": 0.8229295740315667,
        "vocab_size-3-nopunct": 40512,
        "unique-3-nopunct": 36151,
        "entropy-3-nopunct": 15.073700556385381,
        "cond_entropy-3-nopunct": 1.40718396370056,
        "msttr-100": 0.59775,
        "msttr-100_nopunct": 0.68089,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_val.json",
        "bleu": 13.00895,
        "nist": 4.0240456352340646,
        "rouge1": {
            "precision": 0.41721,
            "recall": 0.36141,
            "fmeasure": 0.36778
        },
        "rouge2": {
            "precision": 0.16256,
            "recall": 0.14117,
            "fmeasure": 0.14381
        },
        "rougeL": {
            "precision": 0.34588,
            "recall": 0.30143,
            "fmeasure": 0.30569
        },
        "rougeLsum": {
            "precision": 0.34588,
            "recall": 0.30143,
            "fmeasure": 0.30569
        },
        "local_recall": {
            "1": 0.3212776432938087
        },
        "sari": 68.64039,
        "meteor": 0.1782439249261105,
        "nubia": {
            "semantic_relation": 2.84886,
            "contradiction": 13.70963,
            "irrelevancy": 43.44404,
            "logical_agreement": 42.84633,
            "grammar_ref": 3.90718,
            "grammar_hyp": 3.74636,
            "nubia_score": 0.38022
        },
        "bleurt": -0.28272,
        "bertscore": {
            "precision": 0.85975,
            "recall": 0.84429,
            "f1": 0.85144
        }
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "mT5_xl/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "total_length": 125368,
        "mean_pred_length": 32.00612713811591,
        "std_pred_length": 15.306550588680684,
        "median_pred_length": 30.0,
        "min_pred_length": 2,
        "max_pred_length": 121,
        "distinct-1": 0.060071150532831345,
        "vocab_size-1": 7531,
        "unique-1": 2852,
        "entropy-1": 8.770650267032243,
        "distinct-2": 0.3199891314192555,
        "vocab_size-2": 38863,
        "unique-2": 25091,
        "entropy-2": 13.59610973596105,
        "cond_entropy-2": 4.634153338762085,
        "distinct-3": 0.6462130107032859,
        "vocab_size-3": 75952,
        "unique-3": 61748,
        "entropy-3": 15.585898110669948,
        "cond_entropy-3": 1.9893713434082734,
        "total_length-nopunct": 105253,
        "mean_pred_length-nopunct": 26.870819504723002,
        "std_pred_length-nopunct": 13.587419982817899,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 110,
        "distinct-1-nopunct": 0.07134238454010812,
        "vocab_size-1-nopunct": 7509,
        "unique-1-nopunct": 2852,
        "entropy-1-nopunct": 9.621369305405095,
        "distinct-2-nopunct": 0.44945527749269754,
        "vocab_size-2-nopunct": 45546,
        "unique-2-nopunct": 33231,
        "entropy-2-nopunct": 14.226298355713906,
        "cond_entropy-2-nopunct": 4.7074766725036765,
        "distinct-3-nopunct": 0.7732087866967768,
        "vocab_size-3-nopunct": 75326,
        "unique-3-nopunct": 65503,
        "entropy-3-nopunct": 15.874735331452163,
        "cond_entropy-3-nopunct": 1.676734382230365,
        "msttr-100": 0.59702,
        "msttr-100_nopunct": 0.67847,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "bleu": 13.82163,
        "nist": 4.265914231101436,
        "rouge1": {
            "precision": 0.42448,
            "recall": 0.36919,
            "fmeasure": 0.37571
        },
        "rouge2": {
            "precision": 0.16768,
            "recall": 0.14637,
            "fmeasure": 0.14885
        },
        "rougeL": {
            "precision": 0.35139,
            "recall": 0.30801,
            "fmeasure": 0.31215
        },
        "rougeLsum": {
            "precision": 0.35139,
            "recall": 0.30801,
            "fmeasure": 0.31215
        },
        "local_recall": {
            "1": 0.33106237134408206
        },
        "sari": 68.57683,
        "meteor": 0.18343480904442933,
        "nubia": {
            "semantic_relation": 2.89752,
            "contradiction": 13.12797,
            "irrelevancy": 42.61498,
            "logical_agreement": 44.25705,
            "grammar_ref": 3.92068,
            "grammar_hyp": 3.785,
            "nubia_score": 0.39457
        },
        "bleurt": -0.28107,
        "bertscore": {
            "precision": 0.86168,
            "recall": 0.84604,
            "f1": 0.85329
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "mT5_xl/e2e_nlg_test",
        "N": 774,
        "total_length": 25950,
        "mean_pred_length": 33.52713178294574,
        "std_pred_length": 4.227223545675562,
        "median_pred_length": 33.0,
        "min_pred_length": 20,
        "max_pred_length": 44,
        "distinct-1": 0.004508670520231214,
        "vocab_size-1": 117,
        "unique-1": 9,
        "entropy-1": 5.7174891773555245,
        "distinct-2": 0.01513346043851287,
        "vocab_size-2": 381,
        "unique-2": 46,
        "entropy-2": 7.230867374501368,
        "cond_entropy-2": 1.4555865632369527,
        "distinct-3": 0.029792639947545285,
        "vocab_size-3": 727,
        "unique-3": 116,
        "entropy-3": 8.141646706810425,
        "cond_entropy-3": 0.924210086796404,
        "total_length-nopunct": 23801,
        "mean_pred_length-nopunct": 30.75064599483204,
        "std_pred_length-nopunct": 3.7710433989203582,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.0048317297592538125,
        "vocab_size-1-nopunct": 115,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 5.7282348871843025,
        "distinct-2-nopunct": 0.016111521257654058,
        "vocab_size-2-nopunct": 371,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 7.204531500716599,
        "cond_entropy-2-nopunct": 1.5018593585709923,
        "distinct-3-nopunct": 0.03181593493012178,
        "vocab_size-3-nopunct": 708,
        "unique-3-nopunct": 115,
        "entropy-3-nopunct": 8.130500978197386,
        "cond_entropy-3-nopunct": 0.9328321563812808,
        "msttr-100": 0.32023,
        "msttr-100_nopunct": 0.30874,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 35.546,
        "nist": 5.620760052390879,
        "rouge1": {
            "precision": 0.79415,
            "recall": 0.76791,
            "fmeasure": 0.776
        },
        "rouge2": {
            "precision": 0.48967,
            "recall": 0.47452,
            "fmeasure": 0.47898
        },
        "rougeL": {
            "precision": 0.52038,
            "recall": 0.50429,
            "fmeasure": 0.50906
        },
        "rougeLsum": {
            "precision": 0.52038,
            "recall": 0.50429,
            "fmeasure": 0.50906
        },
        "local_recall": {
            "1": 0.7523405840980018
        },
        "meteor": 0.3860605012816583,
        "nubia": {
            "semantic_relation": 4.56268,
            "contradiction": 3.07941,
            "irrelevancy": 12.59634,
            "logical_agreement": 84.32425,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.08348,
            "nubia_score": 0.8716
        },
        "bleurt": 0.30696,
        "bertscore": {
            "precision": 0.92365,
            "recall": 0.91504,
            "f1": 0.91918
        }
    },
    "xsum_challenge_test_backtranslation": {
        "predictions_file": "mT5_xl/xsum_challenge_test_backtranslation",
        "N": 500,
        "total_length": 11373,
        "mean_pred_length": 22.746,
        "std_pred_length": 5.319161964069153,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 40,
        "distinct-1": 0.290248834959993,
        "vocab_size-1": 3301,
        "unique-1": 2204,
        "entropy-1": 9.289266089312425,
        "distinct-2": 0.7740274073392808,
        "vocab_size-2": 8416,
        "unique-2": 7485,
        "entropy-2": 12.627600841676706,
        "cond_entropy-2": 3.1194020263090017,
        "distinct-3": 0.9514123204473152,
        "vocab_size-3": 9869,
        "unique-3": 9559,
        "entropy-3": 13.215211287726957,
        "cond_entropy-3": 0.5986641746112485,
        "total_length-nopunct": 10550,
        "mean_pred_length-nopunct": 21.1,
        "std_pred_length-nopunct": 4.951969305236049,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.31156398104265404,
        "vocab_size-1-nopunct": 3287,
        "unique-1-nopunct": 2200,
        "entropy-1-nopunct": 9.47772842596043,
        "distinct-2-nopunct": 0.7812935323383084,
        "vocab_size-2-nopunct": 7852,
        "unique-2-nopunct": 7020,
        "entropy-2-nopunct": 12.535001403038335,
        "cond_entropy-2-nopunct": 3.1681973261753766,
        "distinct-3-nopunct": 0.9559162303664921,
        "vocab_size-3-nopunct": 9129,
        "unique-3-nopunct": 8857,
        "entropy-3-nopunct": 13.113384257277094,
        "cond_entropy-3-nopunct": 0.5959400842973098,
        "msttr-100": 0.76062,
        "msttr-100_nopunct": 0.77762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_backtranslation.json",
        "bleu": 5.22536,
        "nist": 2.6592724183924905,
        "rouge1": {
            "precision": 0.30992,
            "recall": 0.30847,
            "fmeasure": 0.30223
        },
        "rouge2": {
            "precision": 0.08606,
            "recall": 0.08599,
            "fmeasure": 0.08366
        },
        "rougeL": {
            "precision": 0.23276,
            "recall": 0.23148,
            "fmeasure": 0.22679
        },
        "rougeLsum": {
            "precision": 0.23276,
            "recall": 0.23148,
            "fmeasure": 0.22679
        },
        "local_recall": {
            "1": 0.2862630142525018
        },
        "meteor": 0.1341888584792275,
        "nubia": {
            "semantic_relation": 2.27397,
            "contradiction": 28.29781,
            "irrelevancy": 65.51426,
            "logical_agreement": 6.18793,
            "grammar_ref": 3.78538,
            "grammar_hyp": 4.11632,
            "nubia_score": 0.268
        },
        "bleurt": -0.52929,
        "bertscore": {
            "precision": 0.80154,
            "recall": 0.80027,
            "f1": 0.80061
        }
    },
    "xsum_challenge_test_bfp_02": {
        "predictions_file": "mT5_xl/xsum_challenge_test_bfp_02",
        "N": 500,
        "total_length": 10900,
        "mean_pred_length": 21.8,
        "std_pred_length": 5.195382565317015,
        "median_pred_length": 22.0,
        "min_pred_length": 1,
        "max_pred_length": 44,
        "distinct-1": 0.2953211009174312,
        "vocab_size-1": 3219,
        "unique-1": 2144,
        "entropy-1": 9.277325046458126,
        "distinct-2": 0.7752884615384615,
        "vocab_size-2": 8063,
        "unique-2": 7196,
        "entropy-2": 12.572424471841202,
        "cond_entropy-2": 3.0649643130486135,
        "distinct-3": 0.946975053024947,
        "vocab_size-3": 9376,
        "unique-3": 9074,
        "entropy-3": 13.133084452915602,
        "cond_entropy-3": 0.5617688548494525,
        "total_length-nopunct": 10124,
        "mean_pred_length-nopunct": 20.248,
        "std_pred_length-nopunct": 4.970562945985092,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.316772026866851,
        "vocab_size-1-nopunct": 3207,
        "unique-1-nopunct": 2142,
        "entropy-1-nopunct": 9.474564999324718,
        "distinct-2-nopunct": 0.7851428571428571,
        "vocab_size-2-nopunct": 7557,
        "unique-2-nopunct": 6790,
        "entropy-2-nopunct": 12.490623539469698,
        "cond_entropy-2-nopunct": 3.1197434096598964,
        "distinct-3-nopunct": 0.953101030024107,
        "vocab_size-3-nopunct": 8698,
        "unique-3-nopunct": 8450,
        "entropy-3-nopunct": 13.03459965715348,
        "cond_entropy-3-nopunct": 0.5596244739954527,
        "msttr-100": 0.75596,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_02.json",
        "bleu": 6.80969,
        "nist": 3.1660866164090953,
        "rouge1": {
            "precision": 0.35966,
            "recall": 0.34186,
            "fmeasure": 0.34318
        },
        "rouge2": {
            "precision": 0.1184,
            "recall": 0.11223,
            "fmeasure": 0.1127
        },
        "rougeL": {
            "precision": 0.27098,
            "recall": 0.25727,
            "fmeasure": 0.2584
        },
        "rougeLsum": {
            "precision": 0.27098,
            "recall": 0.25727,
            "fmeasure": 0.2584
        },
        "local_recall": {
            "1": 0.313094294770206
        },
        "meteor": 0.1498847150761743,
        "nubia": {
            "semantic_relation": 2.63346,
            "contradiction": 22.52005,
            "irrelevancy": 66.17351,
            "logical_agreement": 11.30645,
            "grammar_ref": 3.74155,
            "grammar_hyp": 4.34657,
            "nubia_score": 0.31665
        },
        "bleurt": -0.55108,
        "bertscore": {
            "precision": 0.81334,
            "recall": 0.81015,
            "f1": 0.81143
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "mT5_xl/e2e_nlg_test",
        "N": 73,
        "total_length": 2553,
        "mean_pred_length": 34.97260273972603,
        "std_pred_length": 4.236089572894031,
        "median_pred_length": 34.0,
        "min_pred_length": 27,
        "max_pred_length": 45,
        "distinct-1": 0.0426948687818253,
        "vocab_size-1": 109,
        "unique-1": 13,
        "entropy-1": 5.658698456110622,
        "distinct-2": 0.11935483870967742,
        "vocab_size-2": 296,
        "unique-2": 69,
        "entropy-2": 7.184377592754532,
        "cond_entropy-2": 1.4681200943533173,
        "distinct-3": 0.2044038221852929,
        "vocab_size-3": 492,
        "unique-3": 166,
        "entropy-3": 8.057297568372674,
        "cond_entropy-3": 0.8884740782795457,
        "total_length-nopunct": 2344,
        "mean_pred_length-nopunct": 32.10958904109589,
        "std_pred_length-nopunct": 3.639816508379842,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.045648464163822525,
        "vocab_size-1-nopunct": 107,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 5.6881223081882375,
        "distinct-2-nopunct": 0.12549537648612946,
        "vocab_size-2-nopunct": 285,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 7.182784051619591,
        "cond_entropy-2-nopunct": 1.5217409864103375,
        "distinct-3-nopunct": 0.2183803457688808,
        "vocab_size-3-nopunct": 480,
        "unique-3-nopunct": 171,
        "entropy-3-nopunct": 8.076727005559752,
        "cond_entropy-3-nopunct": 0.8988053023644678,
        "msttr-100": 0.3832,
        "msttr-100_nopunct": 0.38435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 38.64756,
        "nist": 5.351027471872441,
        "rouge1": {
            "precision": 0.76916,
            "recall": 0.80315,
            "fmeasure": 0.78179
        },
        "rouge2": {
            "precision": 0.50792,
            "recall": 0.5312,
            "fmeasure": 0.5165
        },
        "rougeL": {
            "precision": 0.516,
            "recall": 0.54212,
            "fmeasure": 0.52607
        },
        "rougeLsum": {
            "precision": 0.516,
            "recall": 0.54212,
            "fmeasure": 0.52607
        },
        "local_recall": {
            "1": 0.7936991869918699
        },
        "meteor": 0.4066256697628197,
        "nubia": {
            "semantic_relation": 4.47191,
            "contradiction": 5.59396,
            "irrelevancy": 16.00695,
            "logical_agreement": 78.39909,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.10142,
            "nubia_score": 0.85934
        },
        "bleurt": 0.30854,
        "bertscore": {
            "precision": 0.92322,
            "recall": 0.92182,
            "f1": 0.92242
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "mT5_xl/e2e_nlg_test",
        "N": 2,
        "total_length": 70,
        "mean_pred_length": 35.0,
        "std_pred_length": 0.0,
        "median_pred_length": 35.0,
        "min_pred_length": 35,
        "max_pred_length": 35,
        "distinct-1": 0.4142857142857143,
        "vocab_size-1": 29,
        "unique-1": 0,
        "entropy-1": 4.743289445392766,
        "distinct-2": 0.4852941176470588,
        "vocab_size-2": 33,
        "unique-2": 0,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.2672908538444003,
        "distinct-3": 0.5,
        "vocab_size-3": 33,
        "unique-3": 0,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": 0.01753733871417469,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 33.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 33,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.42424242424242425,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.695613058621276,
        "distinct-2-nopunct": 0.484375,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.9375,
        "cond_entropy-2-nopunct": 0.2527863495267632,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": 0.0187124394191333,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 42.92815,
        "nist": 4.31332022613165,
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.72682,
            "fmeasure": 0.79512
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.51285,
            "fmeasure": 0.56303
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.33897,
            "fmeasure": 0.37052
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.33897,
            "fmeasure": 0.37052
        },
        "local_recall": {
            "1": 0.7428571428571429
        },
        "meteor": 0.42214728590612227,
        "nubia": {
            "semantic_relation": 3.96806,
            "contradiction": 2.8201,
            "irrelevancy": 0.73401,
            "logical_agreement": 96.44589,
            "grammar_ref": 4.16331,
            "grammar_hyp": 4.6289,
            "nubia_score": 0.60578
        },
        "bleurt": 0.10471,
        "bertscore": {
            "precision": 0.93972,
            "recall": 0.90516,
            "f1": 0.92212
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 213,
        "total_length": 7558,
        "mean_pred_length": 35.48356807511737,
        "std_pred_length": 8.447349360154458,
        "median_pred_length": 34.0,
        "min_pred_length": 17,
        "max_pred_length": 73,
        "distinct-1": 0.13045779306694893,
        "vocab_size-1": 986,
        "unique-1": 277,
        "entropy-1": 7.923007957590927,
        "distinct-2": 0.36283185840707965,
        "vocab_size-2": 2665,
        "unique-2": 1367,
        "entropy-2": 10.630790706678166,
        "cond_entropy-2": 2.5935229383352874,
        "distinct-3": 0.5389792484576557,
        "vocab_size-3": 3844,
        "unique-3": 2506,
        "entropy-3": 11.465699292279128,
        "cond_entropy-3": 0.8616294149586705,
        "total_length-nopunct": 6687,
        "mean_pred_length-nopunct": 31.3943661971831,
        "std_pred_length-nopunct": 7.652939304434279,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.14610438163601017,
        "vocab_size-1-nopunct": 977,
        "unique-1-nopunct": 275,
        "entropy-1-nopunct": 8.19726899693966,
        "distinct-2-nopunct": 0.38832252085264135,
        "vocab_size-2-nopunct": 2514,
        "unique-2-nopunct": 1361,
        "entropy-2-nopunct": 10.601769156324028,
        "cond_entropy-2-nopunct": 2.4843810507931123,
        "distinct-3-nopunct": 0.5630091039770004,
        "vocab_size-3-nopunct": 3525,
        "unique-3-nopunct": 2380,
        "entropy-3-nopunct": 11.36982693773795,
        "cond_entropy-3-nopunct": 0.7882023747887144,
        "msttr-100": 0.64253,
        "msttr-100_nopunct": 0.68455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 45.26298,
        "nist": 8.473951805013042,
        "rouge1": {
            "precision": 0.73336,
            "recall": 0.7003,
            "fmeasure": 0.71138
        },
        "rouge2": {
            "precision": 0.44846,
            "recall": 0.42574,
            "fmeasure": 0.43335
        },
        "rougeL": {
            "precision": 0.52799,
            "recall": 0.50671,
            "fmeasure": 0.51273
        },
        "rougeLsum": {
            "precision": 0.52799,
            "recall": 0.50671,
            "fmeasure": 0.51273
        },
        "local_recall": {
            "1": 0.224263431542461,
            "2": 0.5376607470912431,
            "3": 0.877486307293168
        },
        "meteor": 0.36776694224016776,
        "nubia": {
            "semantic_relation": 4.33378,
            "contradiction": 8.35439,
            "irrelevancy": 7.86934,
            "logical_agreement": 83.77627,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.15495,
            "nubia_score": 0.76423
        },
        "bleurt": 0.10064,
        "bertscore": {
            "precision": 0.90948,
            "recall": 0.90487,
            "f1": 0.90593
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 349,
        "total_length": 6024,
        "mean_pred_length": 17.26074498567335,
        "std_pred_length": 4.9909006618388085,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 55,
        "distinct-1": 0.1641766268260292,
        "vocab_size-1": 989,
        "unique-1": 412,
        "entropy-1": 7.7665894965443085,
        "distinct-2": 0.41215859030837004,
        "vocab_size-2": 2339,
        "unique-2": 1390,
        "entropy-2": 10.417210609318634,
        "cond_entropy-2": 2.426268126708768,
        "distinct-3": 0.5837401426962073,
        "vocab_size-3": 3109,
        "unique-3": 2222,
        "entropy-3": 11.158367316179168,
        "cond_entropy-3": 0.8230731166732601,
        "total_length-nopunct": 5190,
        "mean_pred_length-nopunct": 14.87106017191977,
        "std_pred_length-nopunct": 4.255856476529122,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.18863198458574182,
        "vocab_size-1-nopunct": 979,
        "unique-1-nopunct": 410,
        "entropy-1-nopunct": 8.114219050179326,
        "distinct-2-nopunct": 0.4222268126420161,
        "vocab_size-2-nopunct": 2044,
        "unique-2-nopunct": 1247,
        "entropy-2-nopunct": 10.257789186800428,
        "cond_entropy-2-nopunct": 2.3218618025278412,
        "distinct-3-nopunct": 0.5919412288512912,
        "vocab_size-3-nopunct": 2659,
        "unique-3-nopunct": 1923,
        "entropy-3-nopunct": 10.948432983987542,
        "cond_entropy-3-nopunct": 0.7573097320531409,
        "msttr-100": 0.65067,
        "msttr-100_nopunct": 0.70471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 53.83654,
        "nist": 8.886755336227385,
        "rouge1": {
            "precision": 0.78137,
            "recall": 0.77965,
            "fmeasure": 0.77408
        },
        "rouge2": {
            "precision": 0.55256,
            "recall": 0.55193,
            "fmeasure": 0.54723
        },
        "rougeL": {
            "precision": 0.66123,
            "recall": 0.65743,
            "fmeasure": 0.65364
        },
        "rougeLsum": {
            "precision": 0.66123,
            "recall": 0.65743,
            "fmeasure": 0.65364
        },
        "local_recall": {
            "1": 0.2174432497013142,
            "2": 0.5929919137466307,
            "3": 0.898838004101162,
            "4": 1.0
        },
        "meteor": 0.43116786225267184,
        "nubia": {
            "semantic_relation": 4.59157,
            "contradiction": 7.723,
            "irrelevancy": 7.09166,
            "logical_agreement": 85.18533,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.6882,
            "nubia_score": 0.83709
        },
        "bleurt": 0.30297,
        "bertscore": {
            "precision": 0.93226,
            "recall": 0.93493,
            "f1": 0.93193
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 469,
        "total_length": 9992,
        "mean_pred_length": 21.30490405117271,
        "std_pred_length": 5.261072944774615,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 40,
        "distinct-1": 0.11699359487590072,
        "vocab_size-1": 1169,
        "unique-1": 592,
        "entropy-1": 7.76797493320393,
        "distinct-2": 0.3142917147957576,
        "vocab_size-2": 2993,
        "unique-2": 1851,
        "entropy-2": 10.248647362686826,
        "cond_entropy-2": 2.3401637060206197,
        "distinct-3": 0.48751932847360285,
        "vocab_size-3": 4414,
        "unique-3": 3095,
        "entropy-3": 11.345958287845393,
        "cond_entropy-3": 1.1346378286337087,
        "total_length-nopunct": 8914,
        "mean_pred_length-nopunct": 19.00639658848614,
        "std_pred_length-nopunct": 4.62056698406499,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.13024455912048463,
        "vocab_size-1-nopunct": 1161,
        "unique-1-nopunct": 592,
        "entropy-1-nopunct": 7.942511695613543,
        "distinct-2-nopunct": 0.33321492007104797,
        "vocab_size-2-nopunct": 2814,
        "unique-2-nopunct": 1781,
        "entropy-2-nopunct": 10.195945917472509,
        "cond_entropy-2-nopunct": 2.347192951309839,
        "distinct-3-nopunct": 0.5165496489468405,
        "vocab_size-3-nopunct": 4120,
        "unique-3-nopunct": 2957,
        "entropy-3-nopunct": 11.30919473835837,
        "cond_entropy-3-nopunct": 1.1418594230697972,
        "msttr-100": 0.6897,
        "msttr-100_nopunct": 0.71584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 35.93697,
        "nist": 6.894807224879272,
        "rouge1": {
            "precision": 0.69265,
            "recall": 0.67751,
            "fmeasure": 0.67358
        },
        "rouge2": {
            "precision": 0.46217,
            "recall": 0.45148,
            "fmeasure": 0.44914
        },
        "rougeL": {
            "precision": 0.59391,
            "recall": 0.58082,
            "fmeasure": 0.57786
        },
        "rougeLsum": {
            "precision": 0.59391,
            "recall": 0.58082,
            "fmeasure": 0.57786
        },
        "local_recall": {
            "1": 0.6585987261146496
        },
        "meteor": 0.35743384596089717,
        "nubia": {
            "semantic_relation": 4.39363,
            "contradiction": 4.49061,
            "irrelevancy": 16.04759,
            "logical_agreement": 79.4618,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.67015,
            "nubia_score": 0.7868
        },
        "bleurt": 0.03763,
        "bertscore": {
            "precision": 0.89831,
            "recall": 0.89289,
            "f1": 0.89521
        }
    },
    "xsum_challenge_test_bfp_05": {
        "predictions_file": "mT5_xl/xsum_challenge_test_bfp_05",
        "N": 500,
        "total_length": 10871,
        "mean_pred_length": 21.742,
        "std_pred_length": 4.9152249185566275,
        "median_pred_length": 21.0,
        "min_pred_length": 1,
        "max_pred_length": 37,
        "distinct-1": 0.3200257566001288,
        "vocab_size-1": 3479,
        "unique-1": 2478,
        "entropy-1": 9.370113750021426,
        "distinct-2": 0.7909555491273744,
        "vocab_size-2": 8203,
        "unique-2": 7394,
        "entropy-2": 12.61644705271265,
        "cond_entropy-2": 3.013712491060546,
        "distinct-3": 0.9554294975688817,
        "vocab_size-3": 9432,
        "unique-3": 9165,
        "entropy-3": 13.154558938603794,
        "cond_entropy-3": 0.5388701151069968,
        "total_length-nopunct": 10109,
        "mean_pred_length-nopunct": 20.218,
        "std_pred_length-nopunct": 4.738615409589599,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.34276387377584333,
        "vocab_size-1-nopunct": 3465,
        "unique-1-nopunct": 2477,
        "entropy-1-nopunct": 9.564789629240192,
        "distinct-2-nopunct": 0.7975855968362993,
        "vocab_size-2-nopunct": 7664,
        "unique-2-nopunct": 6943,
        "entropy-2-nopunct": 12.52595653718287,
        "cond_entropy-2-nopunct": 3.0631366097628225,
        "distinct-3-nopunct": 0.9593852908891328,
        "vocab_size-3-nopunct": 8740,
        "unique-3-nopunct": 8506,
        "entropy-3-nopunct": 13.052326317334105,
        "cond_entropy-3-nopunct": 0.5404605707053882,
        "msttr-100": 0.76093,
        "msttr-100_nopunct": 0.78307,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_05.json",
        "bleu": 6.18228,
        "nist": 3.0262498288108524,
        "rouge1": {
            "precision": 0.34291,
            "recall": 0.32529,
            "fmeasure": 0.32683
        },
        "rouge2": {
            "precision": 0.10717,
            "recall": 0.10171,
            "fmeasure": 0.1022
        },
        "rougeL": {
            "precision": 0.26239,
            "recall": 0.24866,
            "fmeasure": 0.24994
        },
        "rougeLsum": {
            "precision": 0.26239,
            "recall": 0.24866,
            "fmeasure": 0.24994
        },
        "local_recall": {
            "1": 0.30007964954201516
        },
        "meteor": 0.14340134949893382,
        "nubia": {
            "semantic_relation": 2.53576,
            "contradiction": 23.43128,
            "irrelevancy": 65.5491,
            "logical_agreement": 11.01962,
            "grammar_ref": 3.79385,
            "grammar_hyp": 4.77606,
            "nubia_score": 0.27344
        },
        "bleurt": -0.66913,
        "bertscore": {
            "precision": 0.80642,
            "recall": 0.80633,
            "f1": 0.80607
        }
    },
    "xsum_challenge_test_nopunc": {
        "predictions_file": "mT5_xl/xsum_challenge_test_nopunc",
        "N": 500,
        "total_length": 10771,
        "mean_pred_length": 21.542,
        "std_pred_length": 4.936419350095776,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 38,
        "distinct-1": 0.2905022746263114,
        "vocab_size-1": 3129,
        "unique-1": 2043,
        "entropy-1": 9.243686584911217,
        "distinct-2": 0.7749002044591569,
        "vocab_size-2": 7959,
        "unique-2": 7076,
        "entropy-2": 12.554884838313155,
        "cond_entropy-2": 3.079329552345464,
        "distinct-3": 0.947702384607512,
        "vocab_size-3": 9260,
        "unique-3": 8937,
        "entropy-3": 13.121627124613576,
        "cond_entropy-3": 0.5660870044836308,
        "total_length-nopunct": 10013,
        "mean_pred_length-nopunct": 20.026,
        "std_pred_length-nopunct": 4.689277556297985,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.3111954459203036,
        "vocab_size-1-nopunct": 3116,
        "unique-1-nopunct": 2039,
        "entropy-1-nopunct": 9.436374918671902,
        "distinct-2-nopunct": 0.7841900557132345,
        "vocab_size-2-nopunct": 7460,
        "unique-2-nopunct": 6660,
        "entropy-2-nopunct": 12.477938120864842,
        "cond_entropy-2-nopunct": 3.147258116222968,
        "distinct-3-nopunct": 0.9548430045489849,
        "vocab_size-3-nopunct": 8606,
        "unique-3-nopunct": 8323,
        "entropy-3-nopunct": 13.030601303483508,
        "cond_entropy-3-nopunct": 0.5619820236707381,
        "msttr-100": 0.7515,
        "msttr-100_nopunct": 0.7751,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_nopunc.json",
        "bleu": 8.4999,
        "nist": 3.450597995560682,
        "rouge1": {
            "precision": 0.37752,
            "recall": 0.35606,
            "fmeasure": 0.35856
        },
        "rouge2": {
            "precision": 0.13719,
            "recall": 0.12832,
            "fmeasure": 0.12951
        },
        "rougeL": {
            "precision": 0.29595,
            "recall": 0.27612,
            "fmeasure": 0.27931
        },
        "rougeLsum": {
            "precision": 0.29595,
            "recall": 0.27612,
            "fmeasure": 0.27931
        },
        "local_recall": {
            "1": 0.3335676978706308
        },
        "meteor": 0.16054587814781043,
        "nubia": {
            "semantic_relation": 2.78083,
            "contradiction": 20.92675,
            "irrelevancy": 67.72627,
            "logical_agreement": 11.34698,
            "grammar_ref": 3.78318,
            "grammar_hyp": 4.00931,
            "nubia_score": 0.36718
        },
        "bleurt": -0.40057,
        "bertscore": {
            "precision": 0.82661,
            "recall": 0.81812,
            "f1": 0.82199
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 335,
        "total_length": 8525,
        "mean_pred_length": 25.44776119402985,
        "std_pred_length": 5.1748057345887775,
        "median_pred_length": 25.0,
        "min_pred_length": 14,
        "max_pred_length": 52,
        "distinct-1": 0.1036950146627566,
        "vocab_size-1": 884,
        "unique-1": 435,
        "entropy-1": 7.421857992424556,
        "distinct-2": 0.27326007326007323,
        "vocab_size-2": 2238,
        "unique-2": 1325,
        "entropy-2": 9.746895757546438,
        "cond_entropy-2": 2.2293211802091273,
        "distinct-3": 0.4310630171865054,
        "vocab_size-3": 3386,
        "unique-3": 2308,
        "entropy-3": 10.826970181759428,
        "cond_entropy-3": 1.0567913021815514,
        "total_length-nopunct": 7770,
        "mean_pred_length-nopunct": 23.19402985074627,
        "std_pred_length-nopunct": 4.356634350594571,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.11222651222651223,
        "vocab_size-1-nopunct": 872,
        "unique-1-nopunct": 433,
        "entropy-1-nopunct": 7.481197213546676,
        "distinct-2-nopunct": 0.2844653665097512,
        "vocab_size-2-nopunct": 2115,
        "unique-2-nopunct": 1260,
        "entropy-2-nopunct": 9.70532849198699,
        "cond_entropy-2-nopunct": 2.2349571024051595,
        "distinct-3-nopunct": 0.4473239436619718,
        "vocab_size-3-nopunct": 3176,
        "unique-3-nopunct": 2210,
        "entropy-3-nopunct": 10.729755432163062,
        "cond_entropy-3-nopunct": 1.0462760294620037,
        "msttr-100": 0.64659,
        "msttr-100_nopunct": 0.65545,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 41.77932,
        "nist": 7.195431606796599,
        "rouge1": {
            "precision": 0.76421,
            "recall": 0.69511,
            "fmeasure": 0.72127
        },
        "rouge2": {
            "precision": 0.54878,
            "recall": 0.49917,
            "fmeasure": 0.51777
        },
        "rougeL": {
            "precision": 0.65602,
            "recall": 0.59811,
            "fmeasure": 0.61991
        },
        "rougeLsum": {
            "precision": 0.65602,
            "recall": 0.59811,
            "fmeasure": 0.61991
        },
        "local_recall": {
            "1": 0.6764331210191082
        },
        "meteor": 0.38681016139909197,
        "nubia": {
            "semantic_relation": 4.50123,
            "contradiction": 4.75468,
            "irrelevancy": 12.33492,
            "logical_agreement": 82.9104,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.42137,
            "nubia_score": 0.81315
        },
        "bleurt": 0.08202,
        "bertscore": {
            "precision": 0.9174,
            "recall": 0.90155,
            "f1": 0.90916
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 17,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.59448,
        "nist": 6.225972862168346,
        "rouge1": {
            "precision": 0.7307,
            "recall": 0.71077,
            "fmeasure": 0.7063
        },
        "rouge2": {
            "precision": 0.56867,
            "recall": 0.53171,
            "fmeasure": 0.53848
        },
        "rougeL": {
            "precision": 0.66983,
            "recall": 0.65179,
            "fmeasure": 0.64767
        },
        "rougeLsum": {
            "precision": 0.66983,
            "recall": 0.65179,
            "fmeasure": 0.64767
        },
        "local_recall": {
            "1": 0.10526315789473684,
            "2": 0.546875,
            "3": 0.847953216374269
        },
        "meteor": 0.4370065596320827,
        "nubia": {
            "semantic_relation": 4.03935,
            "contradiction": 9.94148,
            "irrelevancy": 27.81356,
            "logical_agreement": 62.24496,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.1121,
            "nubia_score": 0.71835
        },
        "bleurt": 0.22629,
        "bertscore": {
            "precision": 0.92309,
            "recall": 0.91993,
            "f1": 0.92053
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 256,
        "total_length": 7316,
        "mean_pred_length": 28.578125,
        "std_pred_length": 7.465137070702386,
        "median_pred_length": 28.0,
        "min_pred_length": 13,
        "max_pred_length": 54,
        "distinct-1": 0.08187534171678512,
        "vocab_size-1": 599,
        "unique-1": 248,
        "entropy-1": 7.107102760493744,
        "distinct-2": 0.2460339943342776,
        "vocab_size-2": 1737,
        "unique-2": 893,
        "entropy-2": 9.553499626007111,
        "cond_entropy-2": 2.372846293611015,
        "distinct-3": 0.4350382128159906,
        "vocab_size-3": 2960,
        "unique-3": 1944,
        "entropy-3": 10.765200086483507,
        "cond_entropy-3": 1.244744720908706,
        "total_length-nopunct": 6694,
        "mean_pred_length-nopunct": 26.1484375,
        "std_pred_length-nopunct": 6.456694495528943,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.0884374066328055,
        "vocab_size-1-nopunct": 592,
        "unique-1-nopunct": 248,
        "entropy-1-nopunct": 7.1535941985024945,
        "distinct-2-nopunct": 0.25473749611680646,
        "vocab_size-2-nopunct": 1640,
        "unique-2-nopunct": 854,
        "entropy-2-nopunct": 9.48118601351297,
        "cond_entropy-2-nopunct": 2.3893540059480065,
        "distinct-3-nopunct": 0.45082497573600777,
        "vocab_size-3-nopunct": 2787,
        "unique-3-nopunct": 1857,
        "entropy-3-nopunct": 10.693870191930342,
        "cond_entropy-3-nopunct": 1.2460977705331584,
        "msttr-100": 0.62726,
        "msttr-100_nopunct": 0.63212,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 34.81659,
        "nist": 6.318952284745762,
        "rouge1": {
            "precision": 0.71615,
            "recall": 0.63451,
            "fmeasure": 0.66229
        },
        "rouge2": {
            "precision": 0.47611,
            "recall": 0.4208,
            "fmeasure": 0.43921
        },
        "rougeL": {
            "precision": 0.58702,
            "recall": 0.51924,
            "fmeasure": 0.54259
        },
        "rougeLsum": {
            "precision": 0.58702,
            "recall": 0.51924,
            "fmeasure": 0.54259
        },
        "local_recall": {
            "1": 0.621477306437259
        },
        "meteor": 0.3438189256230618,
        "nubia": {
            "semantic_relation": 4.05374,
            "contradiction": 4.05982,
            "irrelevancy": 15.44826,
            "logical_agreement": 80.49192,
            "grammar_ref": 4.19274,
            "grammar_hyp": 4.14119,
            "nubia_score": 0.68444
        },
        "bleurt": -0.0499,
        "bertscore": {
            "precision": 0.90442,
            "recall": 0.88343,
            "f1": 0.89342
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.07178,
        "nist": 1.068908979010361,
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.40541,
            "fmeasure": 0.55556
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.33333,
            "fmeasure": 0.46154
        },
        "rougeL": {
            "precision": 0.58824,
            "recall": 0.27027,
            "fmeasure": 0.37037
        },
        "rougeLsum": {
            "precision": 0.58824,
            "recall": 0.27027,
            "fmeasure": 0.37037
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.47058823529411764
        },
        "meteor": 0.2609676466219328,
        "nubia": {
            "semantic_relation": 3.21434,
            "contradiction": 7.02483,
            "irrelevancy": 31.70933,
            "logical_agreement": 61.26584,
            "grammar_ref": 4.39709,
            "grammar_hyp": 4.47777,
            "nubia_score": 0.35282
        },
        "bleurt": -0.27276,
        "bertscore": {
            "precision": 0.9391,
            "recall": 0.83382,
            "f1": 0.88333
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 46,
        "total_length": 1363,
        "mean_pred_length": 29.630434782608695,
        "std_pred_length": 6.394150504995117,
        "median_pred_length": 29.5,
        "min_pred_length": 18,
        "max_pred_length": 53,
        "distinct-1": 0.1467351430667645,
        "vocab_size-1": 200,
        "unique-1": 76,
        "entropy-1": 6.427799441756549,
        "distinct-2": 0.41078208048595294,
        "vocab_size-2": 541,
        "unique-2": 307,
        "entropy-2": 8.4172507345476,
        "cond_entropy-2": 1.9419019882437247,
        "distinct-3": 0.6184107002360346,
        "vocab_size-3": 786,
        "unique-3": 583,
        "entropy-3": 9.26195445583908,
        "cond_entropy-3": 0.847097511164577,
        "total_length-nopunct": 1261,
        "mean_pred_length-nopunct": 27.41304347826087,
        "std_pred_length-nopunct": 5.63211322976485,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.15543219666931007,
        "vocab_size-1-nopunct": 196,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.403281490687686,
        "distinct-2-nopunct": 0.4148148148148148,
        "vocab_size-2-nopunct": 504,
        "unique-2-nopunct": 288,
        "entropy-2-nopunct": 8.30327748578517,
        "cond_entropy-2-nopunct": 1.9145541177143885,
        "distinct-3-nopunct": 0.6201881950384944,
        "vocab_size-3-nopunct": 725,
        "unique-3-nopunct": 540,
        "entropy-3-nopunct": 9.141112033924236,
        "cond_entropy-3-nopunct": 0.8470399609169723,
        "msttr-100": 0.57769,
        "msttr-100_nopunct": 0.56333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 34.63182,
        "nist": 5.4082428266468945,
        "rouge1": {
            "precision": 0.67266,
            "recall": 0.66614,
            "fmeasure": 0.65917
        },
        "rouge2": {
            "precision": 0.42132,
            "recall": 0.42551,
            "fmeasure": 0.41701
        },
        "rougeL": {
            "precision": 0.53841,
            "recall": 0.53859,
            "fmeasure": 0.5306
        },
        "rougeLsum": {
            "precision": 0.53841,
            "recall": 0.53859,
            "fmeasure": 0.5306
        },
        "local_recall": {
            "1": 0.6490503715937241
        },
        "meteor": 0.3284551004157656,
        "nubia": {
            "semantic_relation": 4.03429,
            "contradiction": 25.05482,
            "irrelevancy": 19.30168,
            "logical_agreement": 55.6435,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.47961,
            "nubia_score": 0.64998
        },
        "bleurt": -0.04995,
        "bertscore": {
            "precision": 0.89393,
            "recall": 0.89306,
            "f1": 0.89324
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 1397,
        "total_length": 27059,
        "mean_pred_length": 19.369362920544024,
        "std_pred_length": 6.5690217184258515,
        "median_pred_length": 18.0,
        "min_pred_length": 4,
        "max_pred_length": 54,
        "distinct-1": 0.06282567722384419,
        "vocab_size-1": 1700,
        "unique-1": 792,
        "entropy-1": 7.430600487012862,
        "distinct-2": 0.20158210583742497,
        "vocab_size-2": 5173,
        "unique-2": 3050,
        "entropy-2": 10.17058793909009,
        "cond_entropy-2": 2.617462166844152,
        "distinct-3": 0.36674222130640843,
        "vocab_size-3": 8899,
        "unique-3": 6216,
        "entropy-3": 11.63315894011688,
        "cond_entropy-3": 1.4890087801248801,
        "total_length-nopunct": 24505,
        "mean_pred_length-nopunct": 17.5411596277738,
        "std_pred_length-nopunct": 6.133382804390983,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.06884309324627627,
        "vocab_size-1-nopunct": 1687,
        "unique-1-nopunct": 789,
        "entropy-1-nopunct": 7.499652610807464,
        "distinct-2-nopunct": 0.21351912757486585,
        "vocab_size-2-nopunct": 4934,
        "unique-2-nopunct": 2956,
        "entropy-2-nopunct": 10.104706561495668,
        "cond_entropy-2-nopunct": 2.6878043885376908,
        "distinct-3-nopunct": 0.38630187462576576,
        "vocab_size-3-nopunct": 8387,
        "unique-3-nopunct": 5931,
        "entropy-3-nopunct": 11.575728874331437,
        "cond_entropy-3-nopunct": 1.5128869214485605,
        "msttr-100": 0.62037,
        "msttr-100_nopunct": 0.62637,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 36.90619,
        "nist": 6.988080771841241,
        "rouge1": {
            "precision": 0.69229,
            "recall": 0.65516,
            "fmeasure": 0.66049
        },
        "rouge2": {
            "precision": 0.47531,
            "recall": 0.44971,
            "fmeasure": 0.45312
        },
        "rougeL": {
            "precision": 0.59913,
            "recall": 0.56884,
            "fmeasure": 0.57275
        },
        "rougeLsum": {
            "precision": 0.59913,
            "recall": 0.56884,
            "fmeasure": 0.57275
        },
        "local_recall": {
            "1": 0.6408702724684832
        },
        "meteor": 0.3500985827725804,
        "nubia": {
            "semantic_relation": 4.21479,
            "contradiction": 3.35753,
            "irrelevancy": 16.09122,
            "logical_agreement": 80.55125,
            "grammar_ref": 4.97201,
            "grammar_hyp": 4.90301,
            "nubia_score": 0.72734
        },
        "bleurt": -0.01111,
        "bertscore": {
            "precision": 0.89208,
            "recall": 0.88219,
            "f1": 0.88665
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.17547,
        "nist": 1.2114120042209615,
        "rouge1": {
            "precision": 0.31111,
            "recall": 0.19838,
            "fmeasure": 0.24103
        },
        "rouge2": {
            "precision": 0.04762,
            "recall": 0.02667,
            "fmeasure": 0.03419
        },
        "rougeL": {
            "precision": 0.31111,
            "recall": 0.19838,
            "fmeasure": 0.24103
        },
        "rougeLsum": {
            "precision": 0.31111,
            "recall": 0.19838,
            "fmeasure": 0.24103
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.14285714285714285
        },
        "meteor": 0.0859375,
        "nubia": {
            "semantic_relation": 1.97753,
            "contradiction": 10.54781,
            "irrelevancy": 67.63958,
            "logical_agreement": 21.8126,
            "grammar_ref": 4.75948,
            "grammar_hyp": 4.82525,
            "nubia_score": 0.13274
        },
        "bleurt": -0.67158,
        "bertscore": {
            "precision": 0.81179,
            "recall": 0.78632,
            "f1": 0.79885
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 983,
        "total_length": 5463,
        "mean_pred_length": 5.557477110885046,
        "std_pred_length": 1.7365974329665927,
        "median_pred_length": 5.0,
        "min_pred_length": 1,
        "max_pred_length": 12,
        "distinct-1": 0.011715174812374154,
        "vocab_size-1": 64,
        "unique-1": 11,
        "entropy-1": 3.773876977655067,
        "distinct-2": 0.02544642857142857,
        "vocab_size-2": 114,
        "unique-2": 29,
        "entropy-2": 4.454882672464554,
        "cond_entropy-2": 0.5847474508044057,
        "distinct-3": 0.03945111492281304,
        "vocab_size-3": 138,
        "unique-3": 39,
        "entropy-3": 5.115936368057811,
        "cond_entropy-3": 0.5144096816314544,
        "total_length-nopunct": 4416,
        "mean_pred_length-nopunct": 4.4923702950152595,
        "std_pred_length-nopunct": 1.3560807543888451,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.01381340579710145,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5291446906591406,
        "distinct-2-nopunct": 0.025924847072531315,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.124655999360621,
        "cond_entropy-2-nopunct": 0.4141930350399954,
        "distinct-3-nopunct": 0.03712770297837617,
        "vocab_size-3-nopunct": 91,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.4097845509337645,
        "cond_entropy-3-nopunct": 0.4261324695274957,
        "msttr-100": 0.20278,
        "msttr-100_nopunct": 0.19205,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 30.93266,
        "nist": 2.864950406396286,
        "rouge1": {
            "precision": 0.54741,
            "recall": 0.52384,
            "fmeasure": 0.52593
        },
        "rouge2": {
            "precision": 0.37171,
            "recall": 0.35257,
            "fmeasure": 0.35497
        },
        "rougeL": {
            "precision": 0.54656,
            "recall": 0.5231,
            "fmeasure": 0.52514
        },
        "rougeLsum": {
            "precision": 0.54656,
            "recall": 0.5231,
            "fmeasure": 0.52514
        },
        "local_recall": {
            "1": 0.5086705202312138
        },
        "meteor": 0.2821785955056109,
        "nubia": {
            "semantic_relation": 3.17988,
            "contradiction": 2.00502,
            "irrelevancy": 23.74625,
            "logical_agreement": 74.24873,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.50256,
            "nubia_score": 0.61101
        },
        "bleurt": 0.16411,
        "bertscore": {
            "precision": 0.86208,
            "recall": 0.85744,
            "f1": 0.85929
        }
    },
    "xsum_challenge_test_covid": {
        "predictions_file": "mT5_xl/xsum_challenge_test_covid",
        "N": 401,
        "total_length": 9246,
        "mean_pred_length": 23.057356608478802,
        "std_pred_length": 6.0623692721602165,
        "median_pred_length": 23.0,
        "min_pred_length": 6,
        "max_pred_length": 48,
        "distinct-1": 0.23329007138221933,
        "vocab_size-1": 2157,
        "unique-1": 1363,
        "entropy-1": 8.650504621691821,
        "distinct-2": 0.6703222159412098,
        "vocab_size-2": 5929,
        "unique-2": 5030,
        "entropy-2": 11.91856888947231,
        "cond_entropy-2": 3.0857978674836684,
        "distinct-3": 0.8800331596399811,
        "vocab_size-3": 7431,
        "unique-3": 6976,
        "entropy-3": 12.68131126225699,
        "cond_entropy-3": 0.7447071045605269,
        "total_length-nopunct": 8525,
        "mean_pred_length-nopunct": 21.25935162094763,
        "std_pred_length-nopunct": 5.677761542915315,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.2518475073313783,
        "vocab_size-1-nopunct": 2147,
        "unique-1-nopunct": 1362,
        "entropy-1-nopunct": 8.821572216951868,
        "distinct-2-nopunct": 0.688577055637617,
        "vocab_size-2-nopunct": 5594,
        "unique-2-nopunct": 4802,
        "entropy-2-nopunct": 11.85714609515647,
        "cond_entropy-2-nopunct": 3.1041244609945426,
        "distinct-3-nopunct": 0.892787776770685,
        "vocab_size-3-nopunct": 6895,
        "unique-3-nopunct": 6511,
        "entropy-3-nopunct": 12.593795871459667,
        "cond_entropy-3-nopunct": 0.7272113691067174,
        "msttr-100": 0.73022,
        "msttr-100_nopunct": 0.75518,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_covid.json",
        "bleu": 5.87302,
        "nist": 2.506254854859981,
        "rouge1": {
            "precision": 0.30355,
            "recall": 0.29002,
            "fmeasure": 0.28721
        },
        "rouge2": {
            "precision": 0.09035,
            "recall": 0.08874,
            "fmeasure": 0.08682
        },
        "rougeL": {
            "precision": 0.22706,
            "recall": 0.21825,
            "fmeasure": 0.21525
        },
        "rougeLsum": {
            "precision": 0.22706,
            "recall": 0.21825,
            "fmeasure": 0.21525
        },
        "local_recall": {
            "1": 0.2691013935607881
        },
        "meteor": 0.1276436588298979,
        "nubia": {
            "semantic_relation": 2.21811,
            "contradiction": 18.26823,
            "irrelevancy": 70.96837,
            "logical_agreement": 10.76339,
            "grammar_ref": 4.04957,
            "grammar_hyp": 4.17937,
            "nubia_score": 0.27174
        },
        "bleurt": -0.59714,
        "bertscore": {
            "precision": 0.79382,
            "recall": 0.78587,
            "f1": 0.78945
        }
    },
    "common_gen_test": {
        "predictions_file": "mT5_xl/common_gen_test",
        "N": 1497
    },
    "common_gen_challenge_test_scramble": {
        "predictions_file": "mT5_xl/common_gen_challenge_test_scramble",
        "N": 500
    },
    "dart_val": {
        "predictions_file": "mT5_xl/dart_val",
        "N": 2768
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 200,
        "total_length": 3064,
        "mean_pred_length": 15.32,
        "std_pred_length": 5.9209458703825355,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 56,
        "distinct-1": 0.33779373368146215,
        "vocab_size-1": 1035,
        "unique-1": 628,
        "entropy-1": 8.38122847714392,
        "distinct-2": 0.6466480446927374,
        "vocab_size-2": 1852,
        "unique-2": 1360,
        "entropy-2": 10.48616999192681,
        "cond_entropy-2": 1.7877980174632668,
        "distinct-3": 0.7961711711711712,
        "vocab_size-3": 2121,
        "unique-3": 1761,
        "entropy-3": 10.896349245370677,
        "cond_entropy-3": 0.4279463262462937,
        "total_length-nopunct": 2519,
        "mean_pred_length-nopunct": 12.595,
        "std_pred_length-nopunct": 4.93669677010853,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.40849543469630806,
        "vocab_size-1-nopunct": 1029,
        "unique-1-nopunct": 628,
        "entropy-1-nopunct": 8.95429163916327,
        "distinct-2-nopunct": 0.6757222940922811,
        "vocab_size-2-nopunct": 1567,
        "unique-2-nopunct": 1187,
        "entropy-2-nopunct": 10.28582514427088,
        "cond_entropy-2-nopunct": 1.413009951633339,
        "distinct-3-nopunct": 0.8206701274185937,
        "vocab_size-3-nopunct": 1739,
        "unique-3-nopunct": 1482,
        "entropy-3-nopunct": 10.629796864645268,
        "cond_entropy-3-nopunct": 0.3769408708911532,
        "msttr-100": 0.73033,
        "msttr-100_nopunct": 0.8124,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 54.97449,
        "nist": 8.703490765360085,
        "rouge1": {
            "precision": 0.38642,
            "recall": 0.39106,
            "fmeasure": 0.38564
        },
        "rouge2": {
            "precision": 0.20614,
            "recall": 0.21104,
            "fmeasure": 0.20611
        },
        "rougeL": {
            "precision": 0.37732,
            "recall": 0.38228,
            "fmeasure": 0.37667
        },
        "rougeLsum": {
            "precision": 0.37732,
            "recall": 0.38228,
            "fmeasure": 0.37667
        },
        "local_recall": {
            "1": 0.26637341153470184,
            "2": 0.6229838709677419,
            "3": 0.9102730819245773,
            "4": 1.0,
            "5": 0.9615384615384616,
            "6": 1.0,
            "7": 1.0
        },
        "meteor": 0.7071493640938914,
        "nubia": {
            "semantic_relation": 4.04251,
            "contradiction": 16.77998,
            "irrelevancy": 22.69706,
            "logical_agreement": 60.52296,
            "grammar_ref": 2.7039,
            "grammar_hyp": 2.68643,
            "nubia_score": 0.83247
        },
        "bleurt": 0.222,
        "bertscore": {
            "precision": 0.96061,
            "recall": 0.95886,
            "f1": 0.95864
        }
    },
    "dart_test": {
        "predictions_file": "mT5_xl/dart_test",
        "N": 6959
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 32,
        "total_length": 1280,
        "mean_pred_length": 40.0,
        "std_pred_length": 8.234834546000302,
        "median_pred_length": 39.0,
        "min_pred_length": 22,
        "max_pred_length": 57,
        "distinct-1": 0.2921875,
        "vocab_size-1": 374,
        "unique-1": 181,
        "entropy-1": 7.355152192509163,
        "distinct-2": 0.5224358974358975,
        "vocab_size-2": 652,
        "unique-2": 372,
        "entropy-2": 8.992352430182422,
        "cond_entropy-2": 1.5480677352766263,
        "distinct-3": 0.6422697368421053,
        "vocab_size-3": 781,
        "unique-3": 523,
        "entropy-3": 9.376040082874733,
        "cond_entropy-3": 0.3818984154861634,
        "total_length-nopunct": 1098,
        "mean_pred_length-nopunct": 34.3125,
        "std_pred_length-nopunct": 7.530925822898537,
        "median_pred_length-nopunct": 34.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 50,
        "distinct-1-nopunct": 0.33515482695810567,
        "vocab_size-1-nopunct": 368,
        "unique-1-nopunct": 178,
        "entropy-1-nopunct": 7.652426206668623,
        "distinct-2-nopunct": 0.5534709193245778,
        "vocab_size-2-nopunct": 590,
        "unique-2-nopunct": 348,
        "entropy-2-nopunct": 8.892489653398433,
        "cond_entropy-2-nopunct": 1.249517002847009,
        "distinct-3-nopunct": 0.6528046421663443,
        "vocab_size-3-nopunct": 675,
        "unique-3-nopunct": 464,
        "entropy-3-nopunct": 9.165207586281626,
        "cond_entropy-3-nopunct": 0.2846081051451206,
        "msttr-100": 0.67917,
        "msttr-100_nopunct": 0.746,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 57.24377,
        "nist": 7.899866848101522,
        "rouge1": {
            "precision": 0.8535,
            "recall": 0.87117,
            "fmeasure": 0.85617
        },
        "rouge2": {
            "precision": 0.59679,
            "recall": 0.61302,
            "fmeasure": 0.59982
        },
        "rougeL": {
            "precision": 0.80781,
            "recall": 0.82134,
            "fmeasure": 0.80876
        },
        "rougeLsum": {
            "precision": 0.80781,
            "recall": 0.82134,
            "fmeasure": 0.80876
        },
        "local_recall": {
            "1": 0.3413793103448276,
            "2": 0.7427293064876958,
            "3": 0.9329073482428115
        },
        "meteor": 0.6975194762596256,
        "nubia": {
            "semantic_relation": 3.76765,
            "contradiction": 21.03,
            "irrelevancy": 25.56825,
            "logical_agreement": 53.40175,
            "grammar_ref": 2.45871,
            "grammar_hyp": 2.45061,
            "nubia_score": 0.85711
        },
        "bleurt": 0.24483,
        "bertscore": {
            "precision": 0.95608,
            "recall": 0.95554,
            "f1": 0.95551
        }
    },
    "e2e_nlg_val": {
        "predictions_file": "mT5_xl/e2e_nlg_val",
        "N": 4299,
        "total_length": 110547,
        "mean_pred_length": 25.714584787159804,
        "std_pred_length": 7.836530537863307,
        "median_pred_length": 26.0,
        "min_pred_length": 7,
        "max_pred_length": 44,
        "distinct-1": 0.0023700326557934636,
        "vocab_size-1": 262,
        "unique-1": 46,
        "entropy-1": 5.7794770782237235,
        "distinct-2": 0.008480159626534147,
        "vocab_size-2": 901,
        "unique-2": 198,
        "entropy-2": 7.347240295885508,
        "cond_entropy-2": 1.4844352587208045,
        "distinct-3": 0.016773092428567223,
        "vocab_size-3": 1710,
        "unique-3": 422,
        "entropy-3": 8.32732351101326,
        "cond_entropy-3": 1.0143214443417852,
        "total_length-nopunct": 100596,
        "mean_pred_length-nopunct": 23.39986043265876,
        "std_pred_length-nopunct": 7.135377852698586,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.0025746550558670327,
        "vocab_size-1-nopunct": 259,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.816986648278612,
        "distinct-2-nopunct": 0.009076087520898887,
        "vocab_size-2-nopunct": 874,
        "unique-2-nopunct": 201,
        "entropy-2-nopunct": 7.280121535310239,
        "cond_entropy-2-nopunct": 1.5097376818532593,
        "distinct-3-nopunct": 0.01810908932802887,
        "vocab_size-3-nopunct": 1666,
        "unique-3-nopunct": 414,
        "entropy-3-nopunct": 8.31804389954696,
        "cond_entropy-3-nopunct": 1.0426420453273635,
        "msttr-100": 0.28806,
        "msttr-100_nopunct": 0.27838,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_val.json",
        "bleu": 34.73852,
        "nist": 5.220291209472937,
        "rouge1": {
            "precision": 0.71061,
            "recall": 0.73928,
            "fmeasure": 0.71535
        },
        "rouge2": {
            "precision": 0.44726,
            "recall": 0.46534,
            "fmeasure": 0.45033
        },
        "rougeL": {
            "precision": 0.52448,
            "recall": 0.54465,
            "fmeasure": 0.52751
        },
        "rougeLsum": {
            "precision": 0.52448,
            "recall": 0.54465,
            "fmeasure": 0.52751
        },
        "local_recall": {
            "1": 0.7351339527279844
        },
        "meteor": 0.38440798812214527,
        "nubia": {
            "semantic_relation": 4.35399,
            "contradiction": 3.09581,
            "irrelevancy": 18.17796,
            "logical_agreement": 78.72623,
            "grammar_ref": 4.85661,
            "grammar_hyp": 4.2646,
            "nubia_score": 0.81823
        },
        "bleurt": 0.2383,
        "bertscore": {
            "precision": 0.91052,
            "recall": 0.90811,
            "f1": 0.90902
        }
    },
    "e2e_nlg_test": {
        "predictions_file": "mT5_xl/e2e_nlg_test",
        "N": 4693,
        "total_length": 116198,
        "mean_pred_length": 24.75985510334541,
        "std_pred_length": 7.13625504705563,
        "median_pred_length": 24.0,
        "min_pred_length": 7,
        "max_pred_length": 45,
        "distinct-1": 0.0020310160243721923,
        "vocab_size-1": 236,
        "unique-1": 25,
        "entropy-1": 5.795619781793585,
        "distinct-2": 0.007757499663692211,
        "vocab_size-2": 865,
        "unique-2": 146,
        "entropy-2": 7.471325805930735,
        "cond_entropy-2": 1.5864908593402591,
        "distinct-3": 0.01642137587536981,
        "vocab_size-3": 1754,
        "unique-3": 363,
        "entropy-3": 8.51399233238241,
        "cond_entropy-3": 1.0605521649948462,
        "total_length-nopunct": 106306,
        "mean_pred_length-nopunct": 22.652034945663754,
        "std_pred_length-nopunct": 6.5117503172313915,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.002191785976332474,
        "vocab_size-1-nopunct": 233,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 5.844979917007448,
        "distinct-2-nopunct": 0.008237135012252369,
        "vocab_size-2-nopunct": 837,
        "unique-2-nopunct": 153,
        "entropy-2-nopunct": 7.453289407663871,
        "cond_entropy-2-nopunct": 1.6454986514396697,
        "distinct-3-nopunct": 0.017560874948411062,
        "vocab_size-3-nopunct": 1702,
        "unique-3-nopunct": 365,
        "entropy-3-nopunct": 8.553106647598614,
        "cond_entropy-3-nopunct": 1.0975955263452464,
        "msttr-100": 0.28451,
        "msttr-100_nopunct": 0.27769,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 33.00077,
        "nist": 5.493210233872269,
        "rouge1": {
            "precision": 0.77162,
            "recall": 0.72336,
            "fmeasure": 0.7362
        },
        "rouge2": {
            "precision": 0.47499,
            "recall": 0.44534,
            "fmeasure": 0.45288
        },
        "rougeL": {
            "precision": 0.5493,
            "recall": 0.51449,
            "fmeasure": 0.5236
        },
        "rougeLsum": {
            "precision": 0.5493,
            "recall": 0.51449,
            "fmeasure": 0.5236
        },
        "local_recall": {
            "1": 0.7164849516196055
        },
        "meteor": 0.37094681395205203,
        "nubia": {
            "semantic_relation": 4.40746,
            "contradiction": 2.60766,
            "irrelevancy": 12.83254,
            "logical_agreement": 84.5598,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.42553,
            "nubia_score": 0.82116
        },
        "bleurt": 0.24184,
        "bertscore": {
            "precision": 0.92365,
            "recall": 0.90836,
            "f1": 0.91563
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 254,
        "total_length": 2205,
        "mean_pred_length": 8.681102362204724,
        "std_pred_length": 2.8040811731728543,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 19,
        "distinct-1": 0.4231292517006803,
        "vocab_size-1": 933,
        "unique-1": 635,
        "entropy-1": 8.384963320461955,
        "distinct-2": 0.7585853408508457,
        "vocab_size-2": 1480,
        "unique-2": 1218,
        "entropy-2": 10.273631951272037,
        "cond_entropy-2": 1.2029486887470724,
        "distinct-3": 0.8738951090159104,
        "vocab_size-3": 1483,
        "unique-3": 1326,
        "entropy-3": 10.439420722570414,
        "cond_entropy-3": 0.14682774554094485,
        "total_length-nopunct": 1774,
        "mean_pred_length-nopunct": 6.984251968503937,
        "std_pred_length-nopunct": 2.5176049484915923,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5231116121758738,
        "vocab_size-1-nopunct": 928,
        "unique-1-nopunct": 635,
        "entropy-1-nopunct": 9.111361893425205,
        "distinct-2-nopunct": 0.7769736842105263,
        "vocab_size-2-nopunct": 1181,
        "unique-2-nopunct": 988,
        "entropy-2-nopunct": 9.965272519022859,
        "cond_entropy-2-nopunct": 0.9539133803019714,
        "distinct-3-nopunct": 0.8759873617693523,
        "vocab_size-3-nopunct": 1109,
        "unique-3-nopunct": 997,
        "entropy-3-nopunct": 10.019341258578901,
        "cond_entropy-3-nopunct": 0.1282257510714179,
        "msttr-100": 0.77182,
        "msttr-100_nopunct": 0.88471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 61.2799,
        "nist": 8.506259528726288,
        "rouge1": {
            "precision": 0.34252,
            "recall": 0.337,
            "fmeasure": 0.33858
        },
        "rouge2": {
            "precision": 0.18783,
            "recall": 0.18635,
            "fmeasure": 0.18673
        },
        "rougeL": {
            "precision": 0.34186,
            "recall": 0.3365,
            "fmeasure": 0.33802
        },
        "rougeLsum": {
            "precision": 0.34186,
            "recall": 0.3365,
            "fmeasure": 0.33802
        },
        "local_recall": {
            "1": 0.389945652173913,
            "2": 0.7226074895977809,
            "3": 0.8395904436860068,
            "4": 0.8571428571428571,
            "5": 0.8181818181818182,
            "6": 0.9,
            "7": 1.0
        },
        "meteor": 0.7577309436457313,
        "nubia": {
            "semantic_relation": 4.21297,
            "contradiction": 20.46901,
            "irrelevancy": 19.78927,
            "logical_agreement": 59.74171,
            "grammar_ref": 2.90382,
            "grammar_hyp": 2.88681,
            "nubia_score": 0.85056
        },
        "bleurt": 0.39035,
        "bertscore": {
            "precision": 0.96775,
            "recall": 0.96764,
            "f1": 0.96724
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 1027,
        "total_length": 10562,
        "mean_pred_length": 10.284323271665043,
        "std_pred_length": 4.420781410687994,
        "median_pred_length": 9.0,
        "min_pred_length": 1,
        "max_pred_length": 26,
        "distinct-1": 0.10755538723726567,
        "vocab_size-1": 1136,
        "unique-1": 597,
        "entropy-1": 7.36083490440903,
        "distinct-2": 0.2983744100681699,
        "vocab_size-2": 2845,
        "unique-2": 1729,
        "entropy-2": 10.104822727136305,
        "cond_entropy-2": 2.354719371600943,
        "distinct-3": 0.4810200963685509,
        "vocab_size-3": 4093,
        "unique-3": 2861,
        "entropy-3": 11.191874802397253,
        "cond_entropy-3": 1.134326651392035,
        "total_length-nopunct": 9037,
        "mean_pred_length-nopunct": 8.799415774099318,
        "std_pred_length-nopunct": 4.1107690580654435,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.12482018368927741,
        "vocab_size-1-nopunct": 1128,
        "unique-1-nopunct": 597,
        "entropy-1-nopunct": 7.67988475650177,
        "distinct-2-nopunct": 0.3139825218476904,
        "vocab_size-2-nopunct": 2515,
        "unique-2-nopunct": 1536,
        "entropy-2-nopunct": 9.962900301523103,
        "cond_entropy-2-nopunct": 2.5276845783204203,
        "distinct-3-nopunct": 0.5015032211882605,
        "vocab_size-3-nopunct": 3503,
        "unique-3-nopunct": 2493,
        "entropy-3-nopunct": 11.005692197322391,
        "cond_entropy-3-nopunct": 1.1852349676125302,
        "msttr-100": 0.62419,
        "msttr-100_nopunct": 0.66767,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 46.36886,
        "nist": 7.495506395559129,
        "rouge1": {
            "precision": 0.69268,
            "recall": 0.66524,
            "fmeasure": 0.66753
        },
        "rouge2": {
            "precision": 0.49517,
            "recall": 0.47618,
            "fmeasure": 0.47532
        },
        "rougeL": {
            "precision": 0.63861,
            "recall": 0.61223,
            "fmeasure": 0.61456
        },
        "rougeLsum": {
            "precision": 0.63861,
            "recall": 0.61223,
            "fmeasure": 0.61456
        },
        "local_recall": {
            "1": 0.6351798719929376
        },
        "meteor": 0.38318848382682447,
        "nubia": {
            "semantic_relation": 4.19657,
            "contradiction": 3.79621,
            "irrelevancy": 11.50888,
            "logical_agreement": 84.69491,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.7424,
            "nubia_score": 0.78821
        },
        "bleurt": 0.2491,
        "bertscore": {
            "precision": 0.9101,
            "recall": 0.90415,
            "f1": 0.90675
        }
    },
    "totto_val": {
        "predictions_file": "mT5_xl/totto_val",
        "N": 7700,
        "total_length": 130117,
        "mean_pred_length": 16.89831168831169,
        "std_pred_length": 6.883307288471562,
        "median_pred_length": 16.0,
        "min_pred_length": 4,
        "max_pred_length": 73,
        "distinct-1": 0.16962426124180546,
        "vocab_size-1": 22071,
        "unique-1": 15155,
        "entropy-1": 10.04336938214388,
        "distinct-2": 0.5454634568728199,
        "vocab_size-2": 66774,
        "unique-2": 55697,
        "entropy-2": 14.666868603846178,
        "cond_entropy-2": 4.246986748859452,
        "distinct-3": 0.7867447719169783,
        "vocab_size-3": 90253,
        "unique-3": 82268,
        "entropy-3": 16.004634967584092,
        "cond_entropy-3": 1.3160995552540147,
        "total_length-nopunct": 112761,
        "mean_pred_length-nopunct": 14.644285714285715,
        "std_pred_length-nopunct": 5.885075759715257,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 60,
        "distinct-1-nopunct": 0.19556406913737906,
        "vocab_size-1-nopunct": 22052,
        "unique-1-nopunct": 15154,
        "entropy-1-nopunct": 10.627337844108162,
        "distinct-2-nopunct": 0.594026327562083,
        "vocab_size-2-nopunct": 62409,
        "unique-2-nopunct": 53292,
        "entropy-2-nopunct": 14.6848930920447,
        "cond_entropy-2-nopunct": 4.229615687327068,
        "distinct-3-nopunct": 0.8155318864843213,
        "vocab_size-3-nopunct": 79401,
        "unique-3-nopunct": 73359,
        "entropy-3-nopunct": 15.881980031053297,
        "cond_entropy-3-nopunct": 1.2686073065875405,
        "msttr-100": 0.71907,
        "msttr-100_nopunct": 0.7753,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_val.json",
        "bleu": 47.59895,
        "nist": 10.86624031485722,
        "rouge1": {
            "precision": 0.75038,
            "recall": 0.74302,
            "fmeasure": 0.73554
        },
        "rouge2": {
            "precision": 0.52799,
            "recall": 0.52498,
            "fmeasure": 0.51843
        },
        "rougeL": {
            "precision": 0.65157,
            "recall": 0.64908,
            "fmeasure": 0.64034
        },
        "rougeLsum": {
            "precision": 0.65157,
            "recall": 0.64908,
            "fmeasure": 0.64034
        },
        "local_recall": {
            "1": 0.22981851030631517,
            "2": 0.47427215872331246,
            "3": 0.7825002819301565
        },
        "meteor": 0.40066758582693124,
        "nubia": {
            "semantic_relation": 4.19277,
            "contradiction": 7.85519,
            "irrelevancy": 31.27167,
            "logical_agreement": 60.87315,
            "grammar_ref": 4.66172,
            "grammar_hyp": 4.58926,
            "nubia_score": 0.73575
        },
        "bleurt": 0.2834,
        "bertscore": {
            "precision": 0.92762,
            "recall": 0.92716,
            "f1": 0.9258
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 159,
        "total_length": 4866,
        "mean_pred_length": 30.60377358490566,
        "std_pred_length": 7.042564987922622,
        "median_pred_length": 29.0,
        "min_pred_length": 17,
        "max_pred_length": 73,
        "distinct-1": 0.260583641594739,
        "vocab_size-1": 1268,
        "unique-1": 611,
        "entropy-1": 8.462396751474163,
        "distinct-2": 0.543870830677714,
        "vocab_size-2": 2560,
        "unique-2": 1649,
        "entropy-2": 10.812511554886088,
        "cond_entropy-2": 2.197028991307162,
        "distinct-3": 0.6961301671064204,
        "vocab_size-3": 3166,
        "unique-3": 2340,
        "entropy-3": 11.395117583055605,
        "cond_entropy-3": 0.5966655340166066,
        "total_length-nopunct": 3992,
        "mean_pred_length-nopunct": 25.10691823899371,
        "std_pred_length-nopunct": 6.407141450907065,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.3161322645290581,
        "vocab_size-1-nopunct": 1262,
        "unique-1-nopunct": 611,
        "entropy-1-nopunct": 9.11490122997022,
        "distinct-2-nopunct": 0.5984868249412992,
        "vocab_size-2-nopunct": 2294,
        "unique-2-nopunct": 1547,
        "entropy-2-nopunct": 10.789488773605504,
        "cond_entropy-2-nopunct": 1.720835103483018,
        "distinct-3-nopunct": 0.7343494828524768,
        "vocab_size-3-nopunct": 2698,
        "unique-3-nopunct": 2078,
        "entropy-3-nopunct": 11.198028997441483,
        "cond_entropy-3-nopunct": 0.4248700540654997,
        "msttr-100": 0.70771,
        "msttr-100_nopunct": 0.79744,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 48.59271,
        "nist": 8.695061187981556,
        "rouge1": {
            "precision": 0.53273,
            "recall": 0.51936,
            "fmeasure": 0.52336
        },
        "rouge2": {
            "precision": 0.30304,
            "recall": 0.2971,
            "fmeasure": 0.29779
        },
        "rougeL": {
            "precision": 0.49554,
            "recall": 0.48534,
            "fmeasure": 0.48744
        },
        "rougeLsum": {
            "precision": 0.49554,
            "recall": 0.48534,
            "fmeasure": 0.48744
        },
        "local_recall": {
            "1": 0.26900584795321636,
            "2": 0.637299035369775,
            "3": 0.8909249563699826
        },
        "meteor": 0.6195870744723522,
        "nubia": {
            "semantic_relation": 3.95794,
            "contradiction": 18.90387,
            "irrelevancy": 21.83495,
            "logical_agreement": 59.26118,
            "grammar_ref": 2.45758,
            "grammar_hyp": 2.41661,
            "nubia_score": 0.82922
        },
        "bleurt": 0.11474,
        "bertscore": {
            "precision": 0.95051,
            "recall": 0.94667,
            "f1": 0.94811
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.39229,
        "nist": 1.8049600107233854,
        "rouge1": {
            "precision": 0.66282,
            "recall": 0.49054,
            "fmeasure": 0.56127
        },
        "rouge2": {
            "precision": 0.31,
            "recall": 0.24617,
            "fmeasure": 0.27431
        },
        "rougeL": {
            "precision": 0.61154,
            "recall": 0.4567,
            "fmeasure": 0.5208
        },
        "rougeLsum": {
            "precision": 0.61154,
            "recall": 0.4567,
            "fmeasure": 0.5208
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.36363636363636365
        },
        "meteor": 0.23345677157335382,
        "nubia": {
            "semantic_relation": 3.7609,
            "contradiction": 46.27555,
            "irrelevancy": 50.1175,
            "logical_agreement": 3.60694,
            "grammar_ref": 3.96887,
            "grammar_hyp": 4.31312,
            "nubia_score": 0.51956
        },
        "bleurt": 0.00257,
        "bertscore": {
            "precision": 0.89177,
            "recall": 0.85917,
            "f1": 0.87429
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 12,
        "total_length": 543,
        "mean_pred_length": 45.25,
        "std_pred_length": 8.176439730510259,
        "median_pred_length": 45.5,
        "min_pred_length": 30,
        "max_pred_length": 59,
        "distinct-1": 0.3333333333333333,
        "vocab_size-1": 181,
        "unique-1": 75,
        "entropy-1": 6.643346014442208,
        "distinct-2": 0.5461393596986818,
        "vocab_size-2": 290,
        "unique-2": 152,
        "entropy-2": 7.910544147210689,
        "cond_entropy-2": 1.2046446640166468,
        "distinct-3": 0.6473988439306358,
        "vocab_size-3": 336,
        "unique-3": 206,
        "entropy-3": 8.22086829969344,
        "cond_entropy-3": 0.3152073159542478,
        "total_length-nopunct": 464,
        "mean_pred_length-nopunct": 38.666666666666664,
        "std_pred_length-nopunct": 6.871842709362768,
        "median_pred_length-nopunct": 39.5,
        "min_pred_length-nopunct": 27,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.38362068965517243,
        "vocab_size-1-nopunct": 178,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.836494005352665,
        "distinct-2-nopunct": 0.5685840707964602,
        "vocab_size-2-nopunct": 257,
        "unique-2-nopunct": 140,
        "entropy-2-nopunct": 7.773094872014645,
        "cond_entropy-2-nopunct": 0.9502360577510603,
        "distinct-3-nopunct": 0.6590909090909091,
        "vocab_size-3-nopunct": 290,
        "unique-3-nopunct": 181,
        "entropy-3-nopunct": 8.02168638275344,
        "cond_entropy-3-nopunct": 0.2540348836555071,
        "msttr-100": 0.626,
        "msttr-100_nopunct": 0.655,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 59.1217,
        "nist": 7.259307070148724,
        "rouge1": {
            "precision": 0.95741,
            "recall": 0.94438,
            "fmeasure": 0.94772
        },
        "rouge2": {
            "precision": 0.58472,
            "recall": 0.58472,
            "fmeasure": 0.57781
        },
        "rougeL": {
            "precision": 0.86204,
            "recall": 0.86174,
            "fmeasure": 0.85643
        },
        "rougeLsum": {
            "precision": 0.86204,
            "recall": 0.86174,
            "fmeasure": 0.85643
        },
        "local_recall": {
            "1": 0.4215686274509804,
            "2": 0.6609195402298851,
            "3": 0.9240506329113924
        },
        "meteor": 0.726487077861224,
        "nubia": {
            "semantic_relation": 3.56308,
            "contradiction": 22.66051,
            "irrelevancy": 23.8645,
            "logical_agreement": 53.47499,
            "grammar_ref": 2.55511,
            "grammar_hyp": 2.5203,
            "nubia_score": 0.85424
        },
        "bleurt": 0.17452,
        "bertscore": {
            "precision": 0.95657,
            "recall": 0.9551,
            "f1": 0.95552
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 958,
        "total_length": 19941,
        "mean_pred_length": 20.815240083507305,
        "std_pred_length": 6.069732008438239,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.08128980492452735,
        "vocab_size-1": 1621,
        "unique-1": 762,
        "entropy-1": 7.616236469952642,
        "distinct-2": 0.23694884897013116,
        "vocab_size-2": 4498,
        "unique-2": 2643,
        "entropy-2": 10.307618343615514,
        "cond_entropy-2": 2.5450316776937307,
        "distinct-3": 0.38540915395284325,
        "vocab_size-3": 6947,
        "unique-3": 4636,
        "entropy-3": 11.581642354027048,
        "cond_entropy-3": 1.3495482516440367,
        "total_length-nopunct": 17509,
        "mean_pred_length-nopunct": 18.276617954070982,
        "std_pred_length-nopunct": 5.498500103147431,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.09189559655034554,
        "vocab_size-1-nopunct": 1609,
        "unique-1-nopunct": 761,
        "entropy-1-nopunct": 7.847809934761481,
        "distinct-2-nopunct": 0.2546673916983868,
        "vocab_size-2-nopunct": 4215,
        "unique-2-nopunct": 2538,
        "entropy-2-nopunct": 10.285152130343699,
        "cond_entropy-2-nopunct": 2.5849933932318674,
        "distinct-3-nopunct": 0.4144808567947156,
        "vocab_size-3-nopunct": 6463,
        "unique-3-nopunct": 4414,
        "entropy-3-nopunct": 11.592723726727291,
        "cond_entropy-3-nopunct": 1.3992317814901623,
        "msttr-100": 0.65136,
        "msttr-100_nopunct": 0.68097,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 33.84251,
        "nist": 6.920843892667585,
        "rouge1": {
            "precision": 0.67535,
            "recall": 0.63373,
            "fmeasure": 0.6439
        },
        "rouge2": {
            "precision": 0.43435,
            "recall": 0.40777,
            "fmeasure": 0.41393
        },
        "rougeL": {
            "precision": 0.58875,
            "recall": 0.5516,
            "fmeasure": 0.56107
        },
        "rougeLsum": {
            "precision": 0.58875,
            "recall": 0.5516,
            "fmeasure": 0.56107
        },
        "local_recall": {
            "1": 0.6216491924057806
        },
        "meteor": 0.3498512434426359,
        "nubia": {
            "semantic_relation": 4.41417,
            "contradiction": 4.07358,
            "irrelevancy": 16.75237,
            "logical_agreement": 79.17406,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.76172,
            "nubia_score": 0.77921
        },
        "bleurt": -0.01307,
        "bertscore": {
            "precision": 0.89513,
            "recall": 0.88479,
            "f1": 0.88958
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 29,
        "total_length": 1245,
        "mean_pred_length": 42.93103448275862,
        "std_pred_length": 8.391009287378957,
        "median_pred_length": 43.0,
        "min_pred_length": 30,
        "max_pred_length": 61,
        "distinct-1": 0.28353413654618476,
        "vocab_size-1": 353,
        "unique-1": 167,
        "entropy-1": 7.2252455802811335,
        "distinct-2": 0.5074013157894737,
        "vocab_size-2": 617,
        "unique-2": 355,
        "entropy-2": 8.859441374816852,
        "cond_entropy-2": 1.5530447517833124,
        "distinct-3": 0.6234203875315922,
        "vocab_size-3": 740,
        "unique-3": 493,
        "entropy-3": 9.267423474731167,
        "cond_entropy-3": 0.4152098764497502,
        "total_length-nopunct": 1045,
        "mean_pred_length-nopunct": 36.03448275862069,
        "std_pred_length-nopunct": 7.199055295401922,
        "median_pred_length-nopunct": 35.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.3320574162679426,
        "vocab_size-1-nopunct": 347,
        "unique-1-nopunct": 165,
        "entropy-1-nopunct": 7.556200251700196,
        "distinct-2-nopunct": 0.5403543307086615,
        "vocab_size-2-nopunct": 549,
        "unique-2-nopunct": 338,
        "entropy-2-nopunct": 8.737731422812676,
        "cond_entropy-2-nopunct": 1.2020425778748212,
        "distinct-3-nopunct": 0.6453900709219859,
        "vocab_size-3-nopunct": 637,
        "unique-3-nopunct": 445,
        "entropy-3-nopunct": 9.060166360821954,
        "cond_entropy-3-nopunct": 0.32877545943403425,
        "msttr-100": 0.67833,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 56.2813,
        "nist": 7.8079211843240515,
        "rouge1": {
            "precision": 0.90192,
            "recall": 0.85711,
            "fmeasure": 0.87176
        },
        "rouge2": {
            "precision": 0.62414,
            "recall": 0.61182,
            "fmeasure": 0.61203
        },
        "rougeL": {
            "precision": 0.85,
            "recall": 0.81046,
            "fmeasure": 0.82154
        },
        "rougeLsum": {
            "precision": 0.85,
            "recall": 0.81046,
            "fmeasure": 0.82154
        },
        "local_recall": {
            "1": 0.32867132867132864,
            "2": 0.6588235294117647,
            "3": 0.8885630498533724
        },
        "meteor": 0.686304086944833,
        "nubia": {
            "semantic_relation": 3.67811,
            "contradiction": 20.57524,
            "irrelevancy": 21.4915,
            "logical_agreement": 57.93326,
            "grammar_ref": 2.50557,
            "grammar_hyp": 2.4758,
            "nubia_score": 0.86581
        },
        "bleurt": 0.18252,
        "bertscore": {
            "precision": 0.95588,
            "recall": 0.95188,
            "f1": 0.95365
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.81046,
        "nist": 4.413386661749345,
        "rouge1": {
            "precision": 0.69753,
            "recall": 0.72341,
            "fmeasure": 0.70737
        },
        "rouge2": {
            "precision": 0.47417,
            "recall": 0.47693,
            "fmeasure": 0.47304
        },
        "rougeL": {
            "precision": 0.60677,
            "recall": 0.62377,
            "fmeasure": 0.61303
        },
        "rougeLsum": {
            "precision": 0.60677,
            "recall": 0.62377,
            "fmeasure": 0.61303
        },
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.3076923076923077,
            "3": 0.7066666666666667
        },
        "meteor": 0.3410048447601496,
        "nubia": {
            "semantic_relation": 3.91736,
            "contradiction": 2.21252,
            "irrelevancy": 47.24148,
            "logical_agreement": 50.54601,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.45219,
            "nubia_score": 0.63849
        },
        "bleurt": 0.16258,
        "bertscore": {
            "precision": 0.91093,
            "recall": 0.90432,
            "f1": 0.90472
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 1099,
        "total_length": 22874,
        "mean_pred_length": 20.813466787989082,
        "std_pred_length": 11.303278880886202,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 73,
        "distinct-1": 0.11419078429658128,
        "vocab_size-1": 2612,
        "unique-1": 807,
        "entropy-1": 8.919793359219566,
        "distinct-2": 0.29818599311136623,
        "vocab_size-2": 6493,
        "unique-2": 3065,
        "entropy-2": 11.734949184089382,
        "cond_entropy-2": 2.5569630758980275,
        "distinct-3": 0.4448152447281873,
        "vocab_size-3": 9197,
        "unique-3": 5382,
        "entropy-3": 12.594673253310184,
        "cond_entropy-3": 0.8811832283344039,
        "total_length-nopunct": 18825,
        "mean_pred_length-nopunct": 17.129208371246587,
        "std_pred_length-nopunct": 9.540472306924956,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.13832669322709162,
        "vocab_size-1-nopunct": 2604,
        "unique-1-nopunct": 806,
        "entropy-1-nopunct": 9.624050204915479,
        "distinct-2-nopunct": 0.3367934108089812,
        "vocab_size-2-nopunct": 5970,
        "unique-2-nopunct": 3046,
        "entropy-2-nopunct": 11.713312015733722,
        "cond_entropy-2-nopunct": 2.165860793864261,
        "distinct-3-nopunct": 0.4843928549948878,
        "vocab_size-3-nopunct": 8054,
        "unique-3-nopunct": 5071,
        "entropy-3-nopunct": 12.429429115102193,
        "cond_entropy-3-nopunct": 0.7611639571047911,
        "msttr-100": 0.63882,
        "msttr-100_nopunct": 0.69809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 52.46996,
        "nist": 9.603104810102499,
        "rouge1": {
            "precision": 0.45261,
            "recall": 0.4528,
            "fmeasure": 0.44962
        },
        "rouge2": {
            "precision": 0.25746,
            "recall": 0.25858,
            "fmeasure": 0.25534
        },
        "rougeL": {
            "precision": 0.43424,
            "recall": 0.43488,
            "fmeasure": 0.43139
        },
        "rougeLsum": {
            "precision": 0.43424,
            "recall": 0.43488,
            "fmeasure": 0.43139
        },
        "local_recall": {
            "1": 0.2937598397023043,
            "2": 0.6674017918676775,
            "3": 0.8957043706621647,
            "4": 0.935064935064935,
            "5": 0.918918918918919,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "meteor": 0.6682105467418034,
        "nubia": {
            "semantic_relation": 4.02482,
            "contradiction": 18.83629,
            "irrelevancy": 22.03213,
            "logical_agreement": 59.13158,
            "grammar_ref": 2.65247,
            "grammar_hyp": 2.62462,
            "nubia_score": 0.83874
        },
        "bleurt": 0.20912,
        "bertscore": {
            "precision": 0.95804,
            "recall": 0.956,
            "f1": 0.9564
        }
    },
    "e2e_nlg_challenge_test_scramble": {
        "predictions_file": "mT5_xl/e2e_nlg_challenge_test_scramble",
        "N": 500,
        "total_length": 12718,
        "mean_pred_length": 25.436,
        "std_pred_length": 6.967776115806248,
        "median_pred_length": 25.0,
        "min_pred_length": 7,
        "max_pred_length": 46,
        "distinct-1": 0.027834565183204905,
        "vocab_size-1": 354,
        "unique-1": 120,
        "entropy-1": 6.322490520373719,
        "distinct-2": 0.14740546734326404,
        "vocab_size-2": 1801,
        "unique-2": 980,
        "entropy-2": 8.890220784545635,
        "cond_entropy-2": 2.488304585767686,
        "distinct-3": 0.3226659839563065,
        "vocab_size-3": 3781,
        "unique-3": 2486,
        "entropy-3": 10.488527899277006,
        "cond_entropy-3": 1.606249124863268,
        "total_length-nopunct": 11589,
        "mean_pred_length-nopunct": 23.178,
        "std_pred_length-nopunct": 6.361314015201577,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.030287341444473207,
        "vocab_size-1-nopunct": 351,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 6.377748680951309,
        "distinct-2-nopunct": 0.15997835693029128,
        "vocab_size-2-nopunct": 1774,
        "unique-2-nopunct": 1002,
        "entropy-2-nopunct": 8.840360950606563,
        "cond_entropy-2-nopunct": 2.5006556146575383,
        "distinct-3-nopunct": 0.3407309472093682,
        "vocab_size-3-nopunct": 3608,
        "unique-3-nopunct": 2403,
        "entropy-3-nopunct": 10.466535285413615,
        "cond_entropy-3-nopunct": 1.6083243114873638,
        "msttr-100": 0.5474,
        "msttr-100_nopunct": 0.5567,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_challenge_test_scramble.json",
        "bleu": 24.99759,
        "nist": 4.829214881316249,
        "rouge1": {
            "precision": 0.70444,
            "recall": 0.67783,
            "fmeasure": 0.68129
        },
        "rouge2": {
            "precision": 0.38474,
            "recall": 0.36922,
            "fmeasure": 0.37129
        },
        "rougeL": {
            "precision": 0.45814,
            "recall": 0.44119,
            "fmeasure": 0.44309
        },
        "rougeLsum": {
            "precision": 0.45814,
            "recall": 0.44119,
            "fmeasure": 0.44309
        },
        "local_recall": {
            "1": 0.6731144796800893
        },
        "meteor": 0.3429763694583062,
        "nubia": {
            "semantic_relation": 4.22303,
            "contradiction": 5.40667,
            "irrelevancy": 26.40982,
            "logical_agreement": 68.18351,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.74775,
            "nubia_score": 0.73129
        },
        "bleurt": 0.05381,
        "bertscore": {
            "precision": 0.9009,
            "recall": 0.89667,
            "f1": 0.89848
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 72,
        "total_length": 2304,
        "mean_pred_length": 32.0,
        "std_pred_length": 8.60716755578357,
        "median_pred_length": 31.0,
        "min_pred_length": 14,
        "max_pred_length": 53,
        "distinct-1": 0.17447916666666666,
        "vocab_size-1": 402,
        "unique-1": 217,
        "entropy-1": 6.997447297180675,
        "distinct-2": 0.4014336917562724,
        "vocab_size-2": 896,
        "unique-2": 596,
        "entropy-2": 8.871119433659805,
        "cond_entropy-2": 1.8149893387663678,
        "distinct-3": 0.5509259259259259,
        "vocab_size-3": 1190,
        "unique-3": 903,
        "entropy-3": 9.553473327727026,
        "cond_entropy-3": 0.6793307131930667,
        "total_length-nopunct": 2040,
        "mean_pred_length-nopunct": 28.333333333333332,
        "std_pred_length-nopunct": 8.07258735887489,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.19362745098039216,
        "vocab_size-1-nopunct": 395,
        "unique-1-nopunct": 216,
        "entropy-1-nopunct": 7.074844282969381,
        "distinct-2-nopunct": 0.429369918699187,
        "vocab_size-2-nopunct": 845,
        "unique-2-nopunct": 571,
        "entropy-2-nopunct": 8.852837282345865,
        "cond_entropy-2-nopunct": 1.7931204040847315,
        "distinct-3-nopunct": 0.5806962025316456,
        "vocab_size-3-nopunct": 1101,
        "unique-3-nopunct": 852,
        "entropy-3-nopunct": 9.501282263180412,
        "cond_entropy-3-nopunct": 0.6767234997124026,
        "msttr-100": 0.63478,
        "msttr-100_nopunct": 0.651,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 36.17337,
        "nist": 5.942371698018103,
        "rouge1": {
            "precision": 0.67093,
            "recall": 0.6079,
            "fmeasure": 0.63119
        },
        "rouge2": {
            "precision": 0.42921,
            "recall": 0.39186,
            "fmeasure": 0.40523
        },
        "rougeL": {
            "precision": 0.54272,
            "recall": 0.49395,
            "fmeasure": 0.51177
        },
        "rougeLsum": {
            "precision": 0.54272,
            "recall": 0.49395,
            "fmeasure": 0.51177
        },
        "local_recall": {
            "1": 0.6306620209059234
        },
        "meteor": 0.3482544481138731,
        "nubia": {
            "semantic_relation": 4.1444,
            "contradiction": 3.06716,
            "irrelevancy": 11.59078,
            "logical_agreement": 85.34206,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.0946,
            "nubia_score": 0.73038
        },
        "bleurt": -0.01928,
        "bertscore": {
            "precision": 0.89757,
            "recall": 0.88501,
            "f1": 0.89101
        }
    },
    "web_nlg_en_val": {
        "predictions_file": "mT5_xl/web_nlg_en_val",
        "N": 1667,
        "total_length": 36277,
        "mean_pred_length": 21.761847630473905,
        "std_pred_length": 11.065883667801186,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 66,
        "distinct-1": 0.09692091407779034,
        "vocab_size-1": 3516,
        "unique-1": 1118,
        "entropy-1": 8.721019980410784,
        "distinct-2": 0.30956370991043053,
        "vocab_size-2": 10714,
        "unique-2": 5569,
        "entropy-2": 12.163551386035547,
        "cond_entropy-2": 3.2099802334683525,
        "distinct-3": 0.5003187323558874,
        "vocab_size-3": 16482,
        "unique-3": 10681,
        "entropy-3": 13.34809208621549,
        "cond_entropy-3": 1.231927393521319,
        "total_length-nopunct": 31634,
        "mean_pred_length-nopunct": 18.976604679064188,
        "std_pred_length-nopunct": 9.759743953049398,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 63,
        "distinct-1-nopunct": 0.11076689637731554,
        "vocab_size-1-nopunct": 3504,
        "unique-1-nopunct": 1116,
        "entropy-1-nopunct": 9.165510602719367,
        "distinct-2-nopunct": 0.33012980945706943,
        "vocab_size-2-nopunct": 9893,
        "unique-2-nopunct": 5364,
        "entropy-2-nopunct": 12.087092322295756,
        "cond_entropy-2-nopunct": 3.0622050857441487,
        "distinct-3-nopunct": 0.5192932862190812,
        "vocab_size-3-nopunct": 14696,
        "unique-3-nopunct": 9818,
        "entropy-3-nopunct": 13.194491084152004,
        "cond_entropy-3-nopunct": 1.1556579507333775,
        "msttr-100": 0.54809,
        "msttr-100_nopunct": 0.5794,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_val.json",
        "bleu": 65.20342,
        "nist": 11.66049832771497,
        "rouge1": {
            "precision": 0.8413,
            "recall": 0.82255,
            "fmeasure": 0.82688
        },
        "rouge2": {
            "precision": 0.63663,
            "recall": 0.62419,
            "fmeasure": 0.62652
        },
        "rougeL": {
            "precision": 0.71403,
            "recall": 0.70035,
            "fmeasure": 0.70281
        },
        "rougeLsum": {
            "precision": 0.71403,
            "recall": 0.70035,
            "fmeasure": 0.70281
        },
        "local_recall": {
            "1": 0.3153753933762925,
            "2": 0.7366858237547893,
            "3": 0.9438749545619775,
            "4": 0.9574468085106383,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0,
            "8": 1.0
        },
        "meteor": 0.46523530776668987,
        "nubia": {
            "semantic_relation": 4.77533,
            "contradiction": 2.5873,
            "irrelevancy": 3.54725,
            "logical_agreement": 93.86546,
            "grammar_ref": 4.59465,
            "grammar_hyp": 4.51085,
            "nubia_score": 0.90646
        },
        "bleurt": 0.45353,
        "bertscore": {
            "precision": 0.95675,
            "recall": 0.95589,
            "f1": 0.95553
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 3,
        "total_length": 61,
        "mean_pred_length": 20.333333333333332,
        "std_pred_length": 9.392668535736915,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.5901639344262295,
        "vocab_size-1": 36,
        "unique-1": 26,
        "entropy-1": 4.718802078777026,
        "distinct-2": 0.8793103448275862,
        "vocab_size-2": 51,
        "unique-2": 45,
        "entropy-2": 5.603586383021304,
        "cond_entropy-2": 0.8654897917303853,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 50,
        "unique-3": 45,
        "entropy-3": 5.599541531706474,
        "cond_entropy-3": 0.00983121843642338,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 6.531972647421808,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.927798970294787,
        "distinct-2-nopunct": 0.8974358974358975,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.080274013734042,
        "cond_entropy-2-nopunct": 0.18820723209187118,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.003258334775643,
        "cond_entropy-3-nopunct": -0.05992166186438028,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 73.02272,
        "nist": 5.701487245886103,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "local_recall": {
            "1": 0.2702702702702703,
            "2": 0.16666666666666666,
            "3": 0.7857142857142857
        },
        "meteor": 0.7684375078909639,
        "nubia": {
            "semantic_relation": 3.78486,
            "contradiction": 30.00827,
            "irrelevancy": 20.89242,
            "logical_agreement": 49.09931,
            "grammar_ref": 2.52713,
            "grammar_hyp": 2.68452,
            "nubia_score": 0.74585
        },
        "bleurt": 0.15915,
        "bertscore": {
            "precision": 0.96078,
            "recall": 0.95193,
            "f1": 0.95384
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 1024,
        "total_length": 9722,
        "mean_pred_length": 9.494140625,
        "std_pred_length": 5.909470421934999,
        "median_pred_length": 6.0,
        "min_pred_length": 1,
        "max_pred_length": 35,
        "distinct-1": 0.0760131660152232,
        "vocab_size-1": 739,
        "unique-1": 415,
        "entropy-1": 6.217715013756251,
        "distinct-2": 0.213382386755576,
        "vocab_size-2": 1856,
        "unique-2": 1149,
        "entropy-2": 8.590454508575942,
        "cond_entropy-2": 2.0468141829304827,
        "distinct-3": 0.35387622149837134,
        "vocab_size-3": 2716,
        "unique-3": 1912,
        "entropy-3": 9.594513999473154,
        "cond_entropy-3": 0.9666510980644465,
        "total_length-nopunct": 8236,
        "mean_pred_length-nopunct": 8.04296875,
        "std_pred_length-nopunct": 5.186568946473519,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.08875667799902866,
        "vocab_size-1-nopunct": 731,
        "unique-1-nopunct": 414,
        "entropy-1-nopunct": 6.4523801892317705,
        "distinct-2-nopunct": 0.23544093178036607,
        "vocab_size-2-nopunct": 1698,
        "unique-2-nopunct": 1078,
        "entropy-2-nopunct": 8.498483591507085,
        "cond_entropy-2-nopunct": 2.19021238347646,
        "distinct-3-nopunct": 0.39828728389077395,
        "vocab_size-3-nopunct": 2465,
        "unique-3-nopunct": 1800,
        "entropy-3-nopunct": 9.54541913603546,
        "cond_entropy-3-nopunct": 1.0082155986612082,
        "msttr-100": 0.4766,
        "msttr-100_nopunct": 0.50695,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 24.4651,
        "nist": 4.400057994014352,
        "rouge1": {
            "precision": 0.43678,
            "recall": 0.39813,
            "fmeasure": 0.40684
        },
        "rouge2": {
            "precision": 0.21919,
            "recall": 0.20433,
            "fmeasure": 0.20646
        },
        "rougeL": {
            "precision": 0.3972,
            "recall": 0.36089,
            "fmeasure": 0.36916
        },
        "rougeLsum": {
            "precision": 0.3972,
            "recall": 0.36089,
            "fmeasure": 0.36916
        },
        "local_recall": {
            "1": 0.42111610569016555
        },
        "meteor": 0.24494485047912018,
        "nubia": {
            "semantic_relation": 2.58476,
            "contradiction": 8.7739,
            "irrelevancy": 26.38418,
            "logical_agreement": 64.84192,
            "grammar_ref": 5.2128,
            "grammar_hyp": 5.03473,
            "nubia_score": 0.43985
        },
        "bleurt": -0.53859,
        "bertscore": {
            "precision": 0.85377,
            "recall": 0.83995,
            "f1": 0.84642
        }
    },
    "web_nlg_en_test": {
        "predictions_file": "mT5_xl/web_nlg_en_test",
        "N": 1779,
        "total_length": 43181,
        "mean_pred_length": 24.272625070264194,
        "std_pred_length": 12.751765340669401,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 106,
        "distinct-1": 0.041847108682059236,
        "vocab_size-1": 1807,
        "unique-1": 414,
        "entropy-1": 8.095492876385062,
        "distinct-2": 0.1582532244819091,
        "vocab_size-2": 6552,
        "unique-2": 2599,
        "entropy-2": 11.247341254439478,
        "cond_entropy-2": 2.97552027277019,
        "distinct-3": 0.29318829972490723,
        "vocab_size-3": 11617,
        "unique-3": 6163,
        "entropy-3": 12.448596507326105,
        "cond_entropy-3": 1.260794265389751,
        "total_length-nopunct": 37872,
        "mean_pred_length-nopunct": 21.288364249578414,
        "std_pred_length-nopunct": 11.356135572602152,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 95,
        "distinct-1-nopunct": 0.04739649345162653,
        "vocab_size-1-nopunct": 1795,
        "unique-1-nopunct": 413,
        "entropy-1-nopunct": 8.4126871533954,
        "distinct-2-nopunct": 0.17526944282824924,
        "vocab_size-2-nopunct": 6326,
        "unique-2-nopunct": 2738,
        "entropy-2-nopunct": 11.190409406853117,
        "cond_entropy-2-nopunct": 2.9123977861278476,
        "distinct-3-nopunct": 0.3141574867401061,
        "vocab_size-3-nopunct": 10780,
        "unique-3-nopunct": 6061,
        "entropy-3-nopunct": 12.341302634371063,
        "cond_entropy-3-nopunct": 1.1979596652055686,
        "msttr-100": 0.65019,
        "msttr-100_nopunct": 0.69508,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 49.07018,
        "nist": 9.159003774526077,
        "rouge1": {
            "precision": 0.76622,
            "recall": 0.74841,
            "fmeasure": 0.75022
        },
        "rouge2": {
            "precision": 0.51204,
            "recall": 0.49934,
            "fmeasure": 0.50053
        },
        "rougeL": {
            "precision": 0.61353,
            "recall": 0.60047,
            "fmeasure": 0.60106
        },
        "rougeLsum": {
            "precision": 0.61353,
            "recall": 0.60047,
            "fmeasure": 0.60106
        },
        "local_recall": {
            "1": 0.22818291353491307,
            "2": 0.591725745362727,
            "3": 0.8803589743589744,
            "4": 0.8181818181818182,
            "5": 0.8275862068965517
        },
        "meteor": 0.3912305854045382,
        "nubia": {
            "semantic_relation": 4.44797,
            "contradiction": 8.0787,
            "irrelevancy": 7.9782,
            "logical_agreement": 83.9431,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.55449,
            "nubia_score": 0.79498
        },
        "bleurt": 0.22369,
        "bertscore": {
            "precision": 0.92454,
            "recall": 0.92253,
            "f1": 0.92223
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 1246,
        "total_length": 18523,
        "mean_pred_length": 14.86597110754414,
        "std_pred_length": 5.137172712601847,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 42,
        "distinct-1": 0.09879609134589429,
        "vocab_size-1": 1830,
        "unique-1": 849,
        "entropy-1": 7.918453346192762,
        "distinct-2": 0.2736586212884181,
        "vocab_size-2": 4728,
        "unique-2": 2777,
        "entropy-2": 10.506195559864079,
        "cond_entropy-2": 2.3652718130371153,
        "distinct-3": 0.42392863826336474,
        "vocab_size-3": 6796,
        "unique-3": 4612,
        "entropy-3": 11.637785255768133,
        "cond_entropy-3": 1.186826280824115,
        "total_length-nopunct": 16504,
        "mean_pred_length-nopunct": 13.245585874799358,
        "std_pred_length-nopunct": 4.608496821666051,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.109973339796413,
        "vocab_size-1-nopunct": 1815,
        "unique-1-nopunct": 846,
        "entropy-1-nopunct": 8.096916200800344,
        "distinct-2-nopunct": 0.2812295189408835,
        "vocab_size-2-nopunct": 4291,
        "unique-2-nopunct": 2587,
        "entropy-2-nopunct": 10.358584717848634,
        "cond_entropy-2-nopunct": 2.4114108122262934,
        "distinct-3-nopunct": 0.4356266057664859,
        "vocab_size-3-nopunct": 6104,
        "unique-3-nopunct": 4217,
        "entropy-3-nopunct": 11.48805904472299,
        "cond_entropy-3-nopunct": 1.221564121983604,
        "msttr-100": 0.67259,
        "msttr-100_nopunct": 0.69339,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 40.64588,
        "nist": 7.559614743229276,
        "rouge1": {
            "precision": 0.71977,
            "recall": 0.67952,
            "fmeasure": 0.6887
        },
        "rouge2": {
            "precision": 0.51169,
            "recall": 0.483,
            "fmeasure": 0.48898
        },
        "rougeL": {
            "precision": 0.62893,
            "recall": 0.5944,
            "fmeasure": 0.6023
        },
        "rougeLsum": {
            "precision": 0.62893,
            "recall": 0.5944,
            "fmeasure": 0.6023
        },
        "local_recall": {
            "1": 0.6533229924829973
        },
        "meteor": 0.37855935836006394,
        "nubia": {
            "semantic_relation": 4.38679,
            "contradiction": 5.21507,
            "irrelevancy": 18.1877,
            "logical_agreement": 76.59723,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.79141,
            "nubia_score": 0.79934
        },
        "bleurt": 0.0431,
        "bertscore": {
            "precision": 0.90735,
            "recall": 0.89501,
            "f1": 0.90073
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.16764,
        "nist": 1.28275019220987,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.26667,
            "fmeasure": 0.2963
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.07143,
            "fmeasure": 0.08
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333
        },
        "meteor": 0.1511719100037575,
        "nubia": {
            "semantic_relation": 2.73321,
            "contradiction": 42.7709,
            "irrelevancy": 51.85838,
            "logical_agreement": 5.37072,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.24916,
            "nubia_score": 0.32813
        },
        "bleurt": -0.38979,
        "bertscore": {
            "precision": 0.79606,
            "recall": 0.79087,
            "f1": 0.79345
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.29573,
        "nist": 2.9408885901947857,
        "rouge1": {
            "precision": 0.57955,
            "recall": 0.60741,
            "fmeasure": 0.58543
        },
        "rouge2": {
            "precision": 0.30124,
            "recall": 0.34392,
            "fmeasure": 0.31592
        },
        "rougeL": {
            "precision": 0.56566,
            "recall": 0.5955,
            "fmeasure": 0.5726
        },
        "rougeLsum": {
            "precision": 0.56566,
            "recall": 0.5955,
            "fmeasure": 0.5726
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.18181818181818182,
            "3": 0.65625
        },
        "meteor": 0.3181493831006907,
        "nubia": {
            "semantic_relation": 3.765,
            "contradiction": 31.59065,
            "irrelevancy": 11.60738,
            "logical_agreement": 56.80197,
            "grammar_ref": 5.04645,
            "grammar_hyp": 4.7568,
            "nubia_score": 0.5505
        },
        "bleurt": 0.16743,
        "bertscore": {
            "precision": 0.90057,
            "recall": 0.91739,
            "f1": 0.90881
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 2.82895,
        "nist": 0.40236960819228146,
        "rouge1": {
            "precision": 0.11111,
            "recall": 0.06667,
            "fmeasure": 0.08333
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.11111,
            "recall": 0.06667,
            "fmeasure": 0.08333
        },
        "rougeLsum": {
            "precision": 0.11111,
            "recall": 0.06667,
            "fmeasure": 0.08333
        },
        "local_recall": {
            "1": 0,
            "2": 0.07692307692307693
        },
        "meteor": 0.04698972099853157,
        "nubia": {
            "semantic_relation": 2.05948,
            "contradiction": 92.88923,
            "irrelevancy": 6.14067,
            "logical_agreement": 0.9701,
            "grammar_ref": 5.57252,
            "grammar_hyp": 5.66086,
            "nubia_score": 0.11301
        },
        "bleurt": -0.85676,
        "bertscore": {
            "precision": 0.71742,
            "recall": 0.72452,
            "f1": 0.72095
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 54,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.03042,
        "nist": 6.742760766293189,
        "rouge1": {
            "precision": 0.72907,
            "recall": 0.72109,
            "fmeasure": 0.71301
        },
        "rouge2": {
            "precision": 0.4962,
            "recall": 0.48006,
            "fmeasure": 0.48104
        },
        "rougeL": {
            "precision": 0.61794,
            "recall": 0.60229,
            "fmeasure": 0.59952
        },
        "rougeLsum": {
            "precision": 0.61794,
            "recall": 0.60229,
            "fmeasure": 0.59952
        },
        "local_recall": {
            "1": 0.27932960893854747,
            "2": 0.32,
            "3": 0.7612903225806451
        },
        "meteor": 0.38352743543091006,
        "nubia": {
            "semantic_relation": 4.14231,
            "contradiction": 5.47235,
            "irrelevancy": 30.00681,
            "logical_agreement": 64.52084,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.53164,
            "nubia_score": 0.72482
        },
        "bleurt": 0.22371,
        "bertscore": {
            "precision": 0.92339,
            "recall": 0.92129,
            "f1": 0.92036
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 986,
        "total_length": 20217,
        "mean_pred_length": 20.504056795131845,
        "std_pred_length": 11.645650703029744,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 73,
        "distinct-1": 0.12212494435376169,
        "vocab_size-1": 2469,
        "unique-1": 827,
        "entropy-1": 8.884416157395663,
        "distinct-2": 0.31064427226873276,
        "vocab_size-2": 5974,
        "unique-2": 2929,
        "entropy-2": 11.650918399487797,
        "cond_entropy-2": 2.5057496881345434,
        "distinct-3": 0.45513839408057,
        "vocab_size-3": 8304,
        "unique-3": 4963,
        "entropy-3": 12.458495102965337,
        "cond_entropy-3": 0.831032928715171,
        "total_length-nopunct": 16589,
        "mean_pred_length-nopunct": 16.824543610547668,
        "std_pred_length-nopunct": 9.787221355973111,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.14835131713786243,
        "vocab_size-1-nopunct": 2461,
        "unique-1-nopunct": 826,
        "entropy-1-nopunct": 9.593017859857035,
        "distinct-2-nopunct": 0.3483304492725758,
        "vocab_size-2-nopunct": 5435,
        "unique-2-nopunct": 2852,
        "entropy-2-nopunct": 11.61029478001422,
        "cond_entropy-2-nopunct": 2.0948998597734367,
        "distinct-3-nopunct": 0.4920982417732777,
        "vocab_size-3-nopunct": 7193,
        "unique-3-nopunct": 4575,
        "entropy-3-nopunct": 12.279737657616666,
        "cond_entropy-3-nopunct": 0.7147323181992026,
        "msttr-100": 0.6347,
        "msttr-100_nopunct": 0.6977,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 53.27081,
        "nist": 9.571237421802572,
        "rouge1": {
            "precision": 0.48564,
            "recall": 0.48542,
            "fmeasure": 0.48216
        },
        "rouge2": {
            "precision": 0.27763,
            "recall": 0.27888,
            "fmeasure": 0.27527
        },
        "rougeL": {
            "precision": 0.46591,
            "recall": 0.46607,
            "fmeasure": 0.46254
        },
        "rougeLsum": {
            "precision": 0.46591,
            "recall": 0.46607,
            "fmeasure": 0.46254
        },
        "local_recall": {
            "1": 0.298406211687781,
            "2": 0.6661473749805266,
            "3": 0.8940481215702828,
            "4": 0.935064935064935,
            "5": 0.918918918918919,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "meteor": 0.6738555176618379,
        "nubia": {
            "semantic_relation": 4.02261,
            "contradiction": 18.93121,
            "irrelevancy": 22.18834,
            "logical_agreement": 58.88046,
            "grammar_ref": 2.66553,
            "grammar_hyp": 2.63998,
            "nubia_score": 0.83822
        },
        "bleurt": 0.21773,
        "bertscore": {
            "precision": 0.95842,
            "recall": 0.95664,
            "f1": 0.95691
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 116,
        "total_length": 2718,
        "mean_pred_length": 23.43103448275862,
        "std_pred_length": 7.231664254883704,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 45,
        "distinct-1": 0.24282560706401765,
        "vocab_size-1": 660,
        "unique-1": 306,
        "entropy-1": 7.774237317837488,
        "distinct-2": 0.4853958493466564,
        "vocab_size-2": 1263,
        "unique-2": 755,
        "entropy-2": 9.727274150595044,
        "cond_entropy-2": 1.7782568228670514,
        "distinct-3": 0.6295253419147224,
        "vocab_size-3": 1565,
        "unique-3": 1081,
        "entropy-3": 10.296513972255388,
        "cond_entropy-3": 0.573655419623509,
        "total_length-nopunct": 2278,
        "mean_pred_length-nopunct": 19.637931034482758,
        "std_pred_length-nopunct": 6.511788450405155,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.28753292361720806,
        "vocab_size-1-nopunct": 655,
        "unique-1-nopunct": 306,
        "entropy-1-nopunct": 8.201417888171473,
        "distinct-2-nopunct": 0.5175763182238667,
        "vocab_size-2-nopunct": 1119,
        "unique-2-nopunct": 700,
        "entropy-2-nopunct": 9.601743757902677,
        "cond_entropy-2-nopunct": 1.4370964696139277,
        "distinct-3-nopunct": 0.6480938416422287,
        "vocab_size-3-nopunct": 1326,
        "unique-3-nopunct": 953,
        "entropy-3-nopunct": 10.056087539456398,
        "cond_entropy-3-nopunct": 0.486410145101261,
        "msttr-100": 0.57407,
        "msttr-100_nopunct": 0.62364,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 46.96457,
        "nist": 7.892211817690492,
        "rouge1": {
            "precision": 0.1602,
            "recall": 0.16379,
            "fmeasure": 0.1614
        },
        "rouge2": {
            "precision": 0.07937,
            "recall": 0.07937,
            "fmeasure": 0.07937
        },
        "rougeL": {
            "precision": 0.15376,
            "recall": 0.15858,
            "fmeasure": 0.15541
        },
        "rougeLsum": {
            "precision": 0.15376,
            "recall": 0.15858,
            "fmeasure": 0.15541
        },
        "local_recall": {
            "1": 0.26126126126126126,
            "2": 0.6698113207547169,
            "3": 0.9033816425120773
        },
        "meteor": 0.6282915915346123,
        "nubia": {
            "semantic_relation": 4.03738,
            "contradiction": 18.31844,
            "irrelevancy": 20.67489,
            "logical_agreement": 61.00667,
            "grammar_ref": 2.53819,
            "grammar_hyp": 2.49555,
            "nubia_score": 0.84081
        },
        "bleurt": 0.13461,
        "bertscore": {
            "precision": 0.95489,
            "recall": 0.95048,
            "f1": 0.95204
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 8.97297,
        "nist": 1.9015243359140728,
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.64359,
            "fmeasure": 0.63879
        },
        "rouge2": {
            "precision": 0.24242,
            "recall": 0.38889,
            "fmeasure": 0.28889
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.61026,
            "fmeasure": 0.60848
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.61026,
            "fmeasure": 0.60848
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.6666666666666666
        },
        "meteor": 0.3318959598167138,
        "nubia": {
            "semantic_relation": 3.05762,
            "contradiction": 91.31939,
            "irrelevancy": 3.137,
            "logical_agreement": 5.54362,
            "grammar_ref": 6.66832,
            "grammar_hyp": 4.6443,
            "nubia_score": 0.46786
        },
        "bleurt": 0.39949,
        "bertscore": {
            "precision": 0.91865,
            "recall": 0.96193,
            "f1": 0.90361
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 500,
        "total_length": 4107,
        "mean_pred_length": 8.214,
        "std_pred_length": 1.514002642005621,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 14,
        "distinct-1": 0.019478938397857318,
        "vocab_size-1": 80,
        "unique-1": 19,
        "entropy-1": 4.689221653778612,
        "distinct-2": 0.05655669531466593,
        "vocab_size-2": 204,
        "unique-2": 59,
        "entropy-2": 6.017020284014474,
        "cond_entropy-2": 1.1017783849055058,
        "distinct-3": 0.10170582555519794,
        "vocab_size-3": 316,
        "unique-3": 107,
        "entropy-3": 6.590815435131357,
        "cond_entropy-3": 0.658344150099437,
        "total_length-nopunct": 3608,
        "mean_pred_length-nopunct": 7.216,
        "std_pred_length-nopunct": 1.5130578310163827,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.021618625277161862,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.7274113833719715,
        "distinct-2-nopunct": 0.05791505791505792,
        "vocab_size-2-nopunct": 180,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.717198658273462,
        "cond_entropy-2-nopunct": 1.1798375389475009,
        "distinct-3-nopunct": 0.10199386503067484,
        "vocab_size-3-nopunct": 266,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.217445807041496,
        "cond_entropy-3-nopunct": 0.7386395493795198,
        "msttr-100": 0.30585,
        "msttr-100_nopunct": 0.30833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 28.12404,
        "nist": 3.737248580827683,
        "rouge1": {
            "precision": 0.58072,
            "recall": 0.54544,
            "fmeasure": 0.55337
        },
        "rouge2": {
            "precision": 0.34289,
            "recall": 0.32028,
            "fmeasure": 0.32469
        },
        "rougeL": {
            "precision": 0.55992,
            "recall": 0.52652,
            "fmeasure": 0.53397
        },
        "rougeLsum": {
            "precision": 0.55992,
            "recall": 0.52652,
            "fmeasure": 0.53397
        },
        "local_recall": {
            "1": 0.5306610034510221
        },
        "meteor": 0.2928025347580895,
        "nubia": {
            "semantic_relation": 3.65824,
            "contradiction": 7.15857,
            "irrelevancy": 17.18505,
            "logical_agreement": 75.65638,
            "grammar_ref": 4.43492,
            "grammar_hyp": 3.94123,
            "nubia_score": 0.71256
        },
        "bleurt": 0.08767,
        "bertscore": {
            "precision": 0.89277,
            "recall": 0.8863,
            "f1": 0.88919
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "mT5_xl/web_nlg_ru_test",
        "N": 642,
        "total_length": 11663,
        "mean_pred_length": 18.166666666666668,
        "std_pred_length": 11.771789412002747,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 73,
        "distinct-1": 0.15879276343993826,
        "vocab_size-1": 1852,
        "unique-1": 715,
        "entropy-1": 8.737384784789846,
        "distinct-2": 0.3711096996642773,
        "vocab_size-2": 4090,
        "unique-2": 2182,
        "entropy-2": 11.26975203099423,
        "cond_entropy-2": 2.241882307116687,
        "distinct-3": 0.5149821755467772,
        "vocab_size-3": 5345,
        "unique-3": 3416,
        "entropy-3": 11.915057826541691,
        "cond_entropy-3": 0.6571015429374584,
        "total_length-nopunct": 9634,
        "mean_pred_length-nopunct": 15.006230529595015,
        "std_pred_length-nopunct": 9.835245213410559,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.19150923811500933,
        "vocab_size-1-nopunct": 1845,
        "unique-1-nopunct": 714,
        "entropy-1-nopunct": 9.371582166485732,
        "distinct-2-nopunct": 0.40091192170818507,
        "vocab_size-2-nopunct": 3605,
        "unique-2-nopunct": 2019,
        "entropy-2-nopunct": 11.14307195372545,
        "cond_entropy-2-nopunct": 1.8473800359162562,
        "distinct-3-nopunct": 0.5398802395209581,
        "vocab_size-3-nopunct": 4508,
        "unique-3-nopunct": 2996,
        "entropy-3-nopunct": 11.691202744819856,
        "cond_entropy-3-nopunct": 0.601982703760587,
        "msttr-100": 0.62845,
        "msttr-100_nopunct": 0.67604,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 55.61624,
        "nist": 9.400151508206202,
        "rouge1": {
            "precision": 0.51205,
            "recall": 0.51554,
            "fmeasure": 0.51017
        },
        "rouge2": {
            "precision": 0.32112,
            "recall": 0.32607,
            "fmeasure": 0.32016
        },
        "rougeL": {
            "precision": 0.48574,
            "recall": 0.48947,
            "fmeasure": 0.48392
        },
        "rougeLsum": {
            "precision": 0.48574,
            "recall": 0.48947,
            "fmeasure": 0.48392
        },
        "local_recall": {
            "1": 0.3083125641401554,
            "2": 0.6653950953678475,
            "3": 0.8939818054583625,
            "4": 0.9342105263157895,
            "5": 0.9090909090909091,
            "6": 0.9090909090909091,
            "7": 1.0
        },
        "meteor": 0.690889119754117,
        "nubia": {
            "semantic_relation": 4.03517,
            "contradiction": 19.19796,
            "irrelevancy": 22.09952,
            "logical_agreement": 58.70252,
            "grammar_ref": 2.74601,
            "grammar_hyp": 2.71464,
            "nubia_score": 0.83684
        },
        "bleurt": 0.24226,
        "bertscore": {
            "precision": 0.95999,
            "recall": 0.9589,
            "f1": 0.95884
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.97569,
        "nist": 4.3826922976150895,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.69667,
            "fmeasure": 0.73312
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.51901,
            "fmeasure": 0.54779
        },
        "rougeL": {
            "precision": 0.46032,
            "recall": 0.41,
            "fmeasure": 0.43266
        },
        "rougeLsum": {
            "precision": 0.46032,
            "recall": 0.41,
            "fmeasure": 0.43266
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "meteor": 0.4028034041998378,
        "nubia": {
            "semantic_relation": 3.29946,
            "contradiction": 1.07553,
            "irrelevancy": 67.76813,
            "logical_agreement": 31.15633,
            "grammar_ref": 4.19943,
            "grammar_hyp": 4.43659,
            "nubia_score": 0.4551
        },
        "bleurt": -0.43219,
        "bertscore": {
            "precision": 0.92694,
            "recall": 0.90164,
            "f1": 0.91411
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 70.06223,
        "nist": 5.265076070076478,
        "rouge1": {
            "precision": 0.94271,
            "recall": 0.91633,
            "fmeasure": 0.92725
        },
        "rouge2": {
            "precision": 0.84018,
            "recall": 0.82778,
            "fmeasure": 0.8327
        },
        "rougeL": {
            "precision": 0.91146,
            "recall": 0.88407,
            "fmeasure": 0.8955
        },
        "rougeLsum": {
            "precision": 0.91146,
            "recall": 0.88407,
            "fmeasure": 0.8955
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8783783783783784
        },
        "meteor": 0.5238448752710548,
        "nubia": {
            "semantic_relation": 4.85765,
            "contradiction": 0.39086,
            "irrelevancy": 0.76492,
            "logical_agreement": 98.84422,
            "grammar_ref": 5.92578,
            "grammar_hyp": 6.08435,
            "nubia_score": 0.92248
        },
        "bleurt": 0.79825,
        "bertscore": {
            "precision": 0.98521,
            "recall": 0.97908,
            "f1": 0.98208
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.05982,
        "nist": 0.7869716851116623,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.52381,
            "fmeasure": 0.63184
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.29842,
            "fmeasure": 0.36074
        },
        "rougeL": {
            "precision": 0.48,
            "recall": 0.31429,
            "fmeasure": 0.3791
        },
        "rougeLsum": {
            "precision": 0.48,
            "recall": 0.31429,
            "fmeasure": 0.3791
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714
        },
        "meteor": 0.2528690640668743,
        "nubia": {
            "semantic_relation": 3.71889,
            "contradiction": 7.97246,
            "irrelevancy": 2.02299,
            "logical_agreement": 90.00454,
            "grammar_ref": 3.72412,
            "grammar_hyp": 5.61874,
            "nubia_score": 0.38873
        },
        "bleurt": -0.01991,
        "bertscore": {
            "precision": 0.91318,
            "recall": 0.78778,
            "f1": 0.84586
        }
    },
    "web_nlg_en_challenge_test_scramble": {
        "predictions_file": "mT5_xl/web_nlg_en_challenge_test_scramble",
        "N": 500,
        "total_length": 12273,
        "mean_pred_length": 24.546,
        "std_pred_length": 13.141532787312142,
        "median_pred_length": 22.5,
        "min_pred_length": 6,
        "max_pred_length": 95,
        "distinct-1": 0.11667888861728999,
        "vocab_size-1": 1432,
        "unique-1": 525,
        "entropy-1": 8.108880450189385,
        "distinct-2": 0.39165888048925507,
        "vocab_size-2": 4611,
        "unique-2": 2821,
        "entropy-2": 11.271417240377463,
        "cond_entropy-2": 2.9890781590913775,
        "distinct-3": 0.6206865962920252,
        "vocab_size-3": 6997,
        "unique-3": 5257,
        "entropy-3": 12.33563035315133,
        "cond_entropy-3": 1.1039714439571582,
        "total_length-nopunct": 10778,
        "mean_pred_length-nopunct": 21.556,
        "std_pred_length-nopunct": 11.752738574477014,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 83,
        "distinct-1-nopunct": 0.13193542401187605,
        "vocab_size-1-nopunct": 1422,
        "unique-1-nopunct": 525,
        "entropy-1-nopunct": 8.415086182970672,
        "distinct-2-nopunct": 0.41107219303366416,
        "vocab_size-2-nopunct": 4225,
        "unique-2-nopunct": 2685,
        "entropy-2-nopunct": 11.170680637162896,
        "cond_entropy-2-nopunct": 2.876295090112945,
        "distinct-3-nopunct": 0.6366332583350378,
        "vocab_size-3-nopunct": 6225,
        "unique-3-nopunct": 4792,
        "entropy-3-nopunct": 12.174768058889738,
        "cond_entropy-3-nopunct": 1.0307305720907312,
        "msttr-100": 0.5409,
        "msttr-100_nopunct": 0.56009,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_scramble.json",
        "bleu": 42.09677,
        "nist": 8.327790952244955,
        "rouge1": {
            "precision": 0.73452,
            "recall": 0.72781,
            "fmeasure": 0.72422
        },
        "rouge2": {
            "precision": 0.4671,
            "recall": 0.46175,
            "fmeasure": 0.45917
        },
        "rougeL": {
            "precision": 0.57295,
            "recall": 0.56771,
            "fmeasure": 0.56424
        },
        "rougeLsum": {
            "precision": 0.57295,
            "recall": 0.56771,
            "fmeasure": 0.56424
        },
        "local_recall": {
            "1": 0.2158529353627199,
            "2": 0.5629453681710214,
            "3": 0.856581899775617,
            "4": 0.4,
            "5": 0.8333333333333334
        },
        "meteor": 0.37272494998087025,
        "nubia": {
            "semantic_relation": 4.34789,
            "contradiction": 11.4471,
            "irrelevancy": 9.9352,
            "logical_agreement": 78.6177,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.70958,
            "nubia_score": 0.74928
        },
        "bleurt": 0.14759,
        "bertscore": {
            "precision": 0.91302,
            "recall": 0.91516,
            "f1": 0.91292
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 2078,
        "total_length": 21386,
        "mean_pred_length": 10.29162656400385,
        "std_pred_length": 5.478511451995922,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 45,
        "distinct-1": 0.021556158234358927,
        "vocab_size-1": 461,
        "unique-1": 129,
        "entropy-1": 6.152749222597861,
        "distinct-2": 0.09845659830122229,
        "vocab_size-2": 1901,
        "unique-2": 768,
        "entropy-2": 8.748611370825849,
        "cond_entropy-2": 2.2883151474400076,
        "distinct-3": 0.2037144515380151,
        "vocab_size-3": 3510,
        "unique-3": 1875,
        "entropy-3": 9.951273679920257,
        "cond_entropy-3": 1.2688265217344095,
        "total_length-nopunct": 18505,
        "mean_pred_length-nopunct": 8.905197305101058,
        "std_pred_length-nopunct": 4.915274647954507,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.02464198865171575,
        "vocab_size-1-nopunct": 456,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.335999812574037,
        "distinct-2-nopunct": 0.11012357703780362,
        "vocab_size-2-nopunct": 1809,
        "unique-2-nopunct": 823,
        "entropy-2-nopunct": 8.5057197375249,
        "cond_entropy-2-nopunct": 2.3646462683353957,
        "distinct-3-nopunct": 0.21874564459930312,
        "vocab_size-3-nopunct": 3139,
        "unique-3-nopunct": 1815,
        "entropy-3-nopunct": 9.678161063093668,
        "cond_entropy-3-nopunct": 1.2811642881353242,
        "msttr-100": 0.49418,
        "msttr-100_nopunct": 0.51951,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 17.92857,
        "nist": 3.675879485875489,
        "rouge1": {
            "precision": 0.47822,
            "recall": 0.43296,
            "fmeasure": 0.44016
        },
        "rouge2": {
            "precision": 0.24745,
            "recall": 0.22475,
            "fmeasure": 0.22693
        },
        "rougeL": {
            "precision": 0.44069,
            "recall": 0.39953,
            "fmeasure": 0.40622
        },
        "rougeLsum": {
            "precision": 0.44069,
            "recall": 0.39953,
            "fmeasure": 0.40622
        },
        "local_recall": {
            "1": 0.4258808920163502
        },
        "meteor": 0.23713839300218517,
        "nubia": {
            "semantic_relation": 3.17412,
            "contradiction": 11.19091,
            "irrelevancy": 23.99131,
            "logical_agreement": 64.81778,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.31055,
            "nubia_score": 0.5492
        },
        "bleurt": -0.23512,
        "bertscore": {
            "precision": 0.84959,
            "recall": 0.83603,
            "f1": 0.84204
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 71,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.32759,
        "nist": 6.488365511409439,
        "rouge1": {
            "precision": 0.70539,
            "recall": 0.72178,
            "fmeasure": 0.69385
        },
        "rouge2": {
            "precision": 0.49655,
            "recall": 0.52186,
            "fmeasure": 0.49215
        },
        "rougeL": {
            "precision": 0.65444,
            "recall": 0.67849,
            "fmeasure": 0.64737
        },
        "rougeLsum": {
            "precision": 0.65444,
            "recall": 0.67849,
            "fmeasure": 0.64737
        },
        "local_recall": {
            "1": 0.3128491620111732,
            "2": 0.5894736842105263,
            "3": 0.7449799196787149
        },
        "meteor": 0.3974039519131694,
        "nubia": {
            "semantic_relation": 3.9672,
            "contradiction": 5.41806,
            "irrelevancy": 48.85486,
            "logical_agreement": 45.72709,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.29501,
            "nubia_score": 0.65283
        },
        "bleurt": 0.27933,
        "bertscore": {
            "precision": 0.92916,
            "recall": 0.93332,
            "f1": 0.929
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 68.64428,
        "nist": 5.160940658467246,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.92099,
            "fmeasure": 0.93415
        },
        "rouge2": {
            "precision": 0.75763,
            "recall": 0.72463,
            "fmeasure": 0.7382
        },
        "rougeL": {
            "precision": 0.74351,
            "recall": 0.72463,
            "fmeasure": 0.73137
        },
        "rougeLsum": {
            "precision": 0.74351,
            "recall": 0.72463,
            "fmeasure": 0.73137
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9333333333333333
        },
        "meteor": 0.5120468500381186,
        "nubia": {
            "semantic_relation": 4.52253,
            "contradiction": 0.16776,
            "irrelevancy": 16.70882,
            "logical_agreement": 83.12342,
            "grammar_ref": 4.80653,
            "grammar_hyp": 4.83674,
            "nubia_score": 0.83655
        },
        "bleurt": 0.41806,
        "bertscore": {
            "precision": 0.96679,
            "recall": 0.95715,
            "f1": 0.96191
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.35216,
        "nist": 2.839071159373045,
        "rouge1": {
            "precision": 0.88462,
            "recall": 0.68056,
            "fmeasure": 0.76863
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.34706,
            "fmeasure": 0.39464
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.62153,
            "fmeasure": 0.70189
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.62153,
            "fmeasure": 0.70189
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.8333333333333334
        },
        "meteor": 0.41897587587744356,
        "nubia": {
            "semantic_relation": 4.68031,
            "contradiction": 0.4588,
            "irrelevancy": 0.58237,
            "logical_agreement": 98.95883,
            "grammar_ref": 4.60656,
            "grammar_hyp": 5.32907,
            "nubia_score": 0.7952
        },
        "bleurt": 0.45813,
        "bertscore": {
            "precision": 0.96277,
            "recall": 0.94643,
            "f1": 0.95453
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "mT5_xl/schema_guided_dialog_test",
        "N": 715,
        "total_length": 6754,
        "mean_pred_length": 9.446153846153846,
        "std_pred_length": 3.195424377974284,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 25,
        "distinct-1": 0.015398282499259699,
        "vocab_size-1": 104,
        "unique-1": 29,
        "entropy-1": 4.281316963005105,
        "distinct-2": 0.043219076005961254,
        "vocab_size-2": 261,
        "unique-2": 104,
        "entropy-2": 5.128347115644321,
        "cond_entropy-2": 0.7262364136140144,
        "distinct-3": 0.06630353117956424,
        "vocab_size-3": 353,
        "unique-3": 168,
        "entropy-3": 5.372441044578027,
        "cond_entropy-3": 0.24660951066724082,
        "total_length-nopunct": 5941,
        "mean_pred_length-nopunct": 8.309090909090909,
        "std_pred_length-nopunct": 2.8216671432435136,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.017000504965494025,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.1686736755464615,
        "distinct-2-nopunct": 0.04496747034060467,
        "vocab_size-2-nopunct": 235,
        "unique-2-nopunct": 97,
        "entropy-2-nopunct": 4.8530509042945935,
        "cond_entropy-2-nopunct": 0.6441135329821472,
        "distinct-3-nopunct": 0.06894258479272888,
        "vocab_size-3-nopunct": 311,
        "unique-3-nopunct": 151,
        "entropy-3-nopunct": 5.091136336151944,
        "cond_entropy-3-nopunct": 0.18216739745467395,
        "msttr-100": 0.22448,
        "msttr-100_nopunct": 0.21525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 27.82979,
        "nist": 3.047892585038356,
        "rouge1": {
            "precision": 0.55945,
            "recall": 0.59113,
            "fmeasure": 0.56306
        },
        "rouge2": {
            "precision": 0.3094,
            "recall": 0.31918,
            "fmeasure": 0.30736
        },
        "rougeL": {
            "precision": 0.47443,
            "recall": 0.49414,
            "fmeasure": 0.47414
        },
        "rougeLsum": {
            "precision": 0.47443,
            "recall": 0.49414,
            "fmeasure": 0.47414
        },
        "local_recall": {
            "1": 0.5840660326574556
        },
        "meteor": 0.2988875985069503,
        "nubia": {
            "semantic_relation": 3.68835,
            "contradiction": 1.13506,
            "irrelevancy": 21.67339,
            "logical_agreement": 77.19155,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.31358,
            "nubia_score": 0.76327
        },
        "bleurt": 0.22854,
        "bertscore": {
            "precision": 0.86016,
            "recall": 0.86548,
            "f1": 0.86227
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.86041,
        "nist": 3.685927046802142,
        "rouge1": {
            "precision": 0.56667,
            "recall": 0.625,
            "fmeasure": 0.57714
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.33041,
            "fmeasure": 0.278
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.475,
            "fmeasure": 0.42286
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.475,
            "fmeasure": 0.42286
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.8571428571428571
        },
        "meteor": 0.4117058131012642,
        "nubia": {
            "semantic_relation": 3.1273,
            "contradiction": 84.01191,
            "irrelevancy": 13.95385,
            "logical_agreement": 2.03424,
            "grammar_ref": 5.69136,
            "grammar_hyp": 5.67438,
            "nubia_score": 0.32376
        },
        "bleurt": 0.04574,
        "bertscore": {
            "precision": 0.89278,
            "recall": 0.94756,
            "f1": 0.91936
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.71022,
        "nist": 1.755769686751366,
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.37121,
            "fmeasure": 0.44202
        },
        "rouge2": {
            "precision": 0.22,
            "recall": 0.11782,
            "fmeasure": 0.15096
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.30455,
            "fmeasure": 0.37059
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.30455,
            "fmeasure": 0.37059
        },
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.36363636363636365
        },
        "meteor": 0.19677593303017926,
        "nubia": {
            "semantic_relation": 2.50427,
            "contradiction": 87.01608,
            "irrelevancy": 6.21839,
            "logical_agreement": 6.76553,
            "grammar_ref": 4.34131,
            "grammar_hyp": 4.04949,
            "nubia_score": 0.20759
        },
        "bleurt": -0.0533,
        "bertscore": {
            "precision": 0.91808,
            "recall": 0.83156,
            "f1": 0.86382
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 106,
        "total_length": 2093,
        "mean_pred_length": 19.745283018867923,
        "std_pred_length": 4.150611050160162,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.42474916387959866,
        "vocab_size-1": 889,
        "unique-1": 679,
        "entropy-1": 8.289093512446719,
        "distinct-2": 0.8510317060895822,
        "vocab_size-2": 1691,
        "unique-2": 1547,
        "entropy-2": 10.54884884887844,
        "cond_entropy-2": 2.0471334535426284,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 1824,
        "unique-3": 1783,
        "entropy-3": 10.807957377545497,
        "cond_entropy-3": 0.2574781364191175,
        "total_length-nopunct": 1928,
        "mean_pred_length-nopunct": 18.18867924528302,
        "std_pred_length-nopunct": 3.8561717440692296,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.45643153526970953,
        "vocab_size-1-nopunct": 880,
        "unique-1-nopunct": 677,
        "entropy-1-nopunct": 8.434819894305583,
        "distinct-2-nopunct": 0.8605927552140505,
        "vocab_size-2-nopunct": 1568,
        "unique-2-nopunct": 1439,
        "entropy-2-nopunct": 10.455071284227152,
        "cond_entropy-2-nopunct": 2.104758450974645,
        "distinct-3-nopunct": 0.9761072261072261,
        "vocab_size-3-nopunct": 1675,
        "unique-3-nopunct": 1642,
        "entropy-3-nopunct": 10.693243321757533,
        "cond_entropy-3-nopunct": 0.23595145843617932,
        "msttr-100": 0.736,
        "msttr-100_nopunct": 0.76211,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 20.06665,
        "nist": 4.633403895029085,
        "rouge1": {
            "precision": 0.53309,
            "recall": 0.49284,
            "fmeasure": 0.49832
        },
        "rouge2": {
            "precision": 0.2815,
            "recall": 0.26141,
            "fmeasure": 0.26243
        },
        "rougeL": {
            "precision": 0.43836,
            "recall": 0.40586,
            "fmeasure": 0.4099
        },
        "rougeLsum": {
            "precision": 0.43836,
            "recall": 0.40586,
            "fmeasure": 0.4099
        },
        "local_recall": {
            "1": 0.4637607704004055
        },
        "meteor": 0.2382522299646116,
        "nubia": {
            "semantic_relation": 3.39666,
            "contradiction": 16.13881,
            "irrelevancy": 56.77161,
            "logical_agreement": 27.08957,
            "grammar_ref": 3.74062,
            "grammar_hyp": 3.61692,
            "nubia_score": 0.55047
        },
        "bleurt": -0.13329,
        "bertscore": {
            "precision": 0.86841,
            "recall": 0.85443,
            "f1": 0.86082
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "mT5_xl/xsum_test",
        "N": 106,
        "total_length": 2090,
        "mean_pred_length": 19.71698113207547,
        "std_pred_length": 3.9159921680234957,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 34,
        "distinct-1": 0.42248803827751197,
        "vocab_size-1": 883,
        "unique-1": 672,
        "entropy-1": 8.230459756986368,
        "distinct-2": 0.8417338709677419,
        "vocab_size-2": 1670,
        "unique-2": 1534,
        "entropy-2": 10.489477849409587,
        "cond_entropy-2": 2.04909679385145,
        "distinct-3": 0.9616613418530351,
        "vocab_size-3": 1806,
        "unique-3": 1752,
        "entropy-3": 10.787788266736424,
        "cond_entropy-3": 0.29924246304609836,
        "total_length-nopunct": 1943,
        "mean_pred_length-nopunct": 18.330188679245282,
        "std_pred_length-nopunct": 3.7156519987373544,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.45136387030365416,
        "vocab_size-1-nopunct": 877,
        "unique-1-nopunct": 669,
        "entropy-1-nopunct": 8.377352458345902,
        "distinct-2-nopunct": 0.8486663037561241,
        "vocab_size-2-nopunct": 1559,
        "unique-2-nopunct": 1436,
        "entropy-2-nopunct": 10.398186408609046,
        "cond_entropy-2-nopunct": 2.116593596458814,
        "distinct-3-nopunct": 0.9699595609474292,
        "vocab_size-3-nopunct": 1679,
        "unique-3-nopunct": 1636,
        "entropy-3-nopunct": 10.69204083809027,
        "cond_entropy-3-nopunct": 0.29765457775632437,
        "msttr-100": 0.7295,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 13.92303,
        "nist": 4.068030788302702,
        "rouge1": {
            "precision": 0.51623,
            "recall": 0.44414,
            "fmeasure": 0.4706
        },
        "rouge2": {
            "precision": 0.24299,
            "recall": 0.208,
            "fmeasure": 0.22055
        },
        "rougeL": {
            "precision": 0.40913,
            "recall": 0.34971,
            "fmeasure": 0.37171
        },
        "rougeLsum": {
            "precision": 0.40913,
            "recall": 0.34971,
            "fmeasure": 0.37171
        },
        "local_recall": {
            "1": 0.42160113690194223
        },
        "meteor": 0.2137707651653543,
        "nubia": {
            "semantic_relation": 3.40142,
            "contradiction": 16.34515,
            "irrelevancy": 59.27347,
            "logical_agreement": 24.38138,
            "grammar_ref": 3.75111,
            "grammar_hyp": 3.66094,
            "nubia_score": 0.5465
        },
        "bleurt": -0.14636,
        "bertscore": {
            "precision": 0.86239,
            "recall": 0.8423,
            "f1": 0.85193
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.11298,
        "nist": 1.7414895787249667,
        "rouge1": {
            "precision": 0.28571,
            "recall": 0.28356,
            "fmeasure": 0.28355
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.2619,
            "recall": 0.26395,
            "fmeasure": 0.26205
        },
        "rougeLsum": {
            "precision": 0.2619,
            "recall": 0.26395,
            "fmeasure": 0.26205
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "meteor": 0.1262438552331713,
        "nubia": {
            "semantic_relation": 1.90761,
            "contradiction": 6.01198,
            "irrelevancy": 64.89264,
            "logical_agreement": 29.09537,
            "grammar_ref": 4.12033,
            "grammar_hyp": 4.47646,
            "nubia_score": 0.1788
        },
        "bleurt": -0.04961,
        "bertscore": {
            "precision": 0.83065,
            "recall": 0.8101,
            "f1": 0.82025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 28,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.27343,
        "nist": 6.312470869505644,
        "rouge1": {
            "precision": 0.77345,
            "recall": 0.69448,
            "fmeasure": 0.72369
        },
        "rouge2": {
            "precision": 0.54139,
            "recall": 0.49956,
            "fmeasure": 0.51415
        },
        "rougeL": {
            "precision": 0.65596,
            "recall": 0.5995,
            "fmeasure": 0.61976
        },
        "rougeLsum": {
            "precision": 0.65596,
            "recall": 0.5995,
            "fmeasure": 0.61976
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.44,
            "3": 0.7251461988304093
        },
        "meteor": 0.3846758149647295,
        "nubia": {
            "semantic_relation": 3.97463,
            "contradiction": 12.05499,
            "irrelevancy": 31.70911,
            "logical_agreement": 56.23589,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.64891,
            "nubia_score": 0.66865
        },
        "bleurt": 0.2279,
        "bertscore": {
            "precision": 0.92228,
            "recall": 0.91585,
            "f1": 0.9163
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 68.92147,
        "nist": 3.98168498643785,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.85348,
            "fmeasure": 0.84303
        },
        "rouge2": {
            "precision": 0.64103,
            "recall": 0.65598,
            "fmeasure": 0.64821
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.85348,
            "fmeasure": 0.84303
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.85348,
            "fmeasure": 0.84303
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.9
        },
        "meteor": 0.47142184089545913,
        "nubia": {
            "semantic_relation": 2.54414,
            "contradiction": 83.53505,
            "irrelevancy": 11.51652,
            "logical_agreement": 4.94843,
            "grammar_ref": 4.48671,
            "grammar_hyp": 4.18092,
            "nubia_score": 0.28905
        },
        "bleurt": 0.25288,
        "bertscore": {
            "precision": 0.96071,
            "recall": 0.97189,
            "f1": 0.96627
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.44147,
        "nist": 0.771320596681796,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.35294,
            "fmeasure": 0.44444
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.25,
            "fmeasure": 0.32
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.35294,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.35294,
            "fmeasure": 0.44444
        },
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "meteor": 0.22923407173743382,
        "nubia": {
            "semantic_relation": 2.57864,
            "contradiction": 86.37915,
            "irrelevancy": 2.79062,
            "logical_agreement": 10.83023,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.04631,
            "nubia_score": 0.25015
        },
        "bleurt": -0.13221,
        "bertscore": {
            "precision": 0.91732,
            "recall": 0.81471,
            "f1": 0.86297
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 44,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.52432,
        "nist": 6.76052368528003,
        "rouge1": {
            "precision": 0.74037,
            "recall": 0.72025,
            "fmeasure": 0.71946
        },
        "rouge2": {
            "precision": 0.4887,
            "recall": 0.49168,
            "fmeasure": 0.482
        },
        "rougeL": {
            "precision": 0.65625,
            "recall": 0.64681,
            "fmeasure": 0.64064
        },
        "rougeLsum": {
            "precision": 0.65625,
            "recall": 0.64681,
            "fmeasure": 0.64064
        },
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.5833333333333334,
            "3": 0.7632850241545893
        },
        "meteor": 0.4005040714515876,
        "nubia": {
            "semantic_relation": 4.29275,
            "contradiction": 7.12111,
            "irrelevancy": 36.42082,
            "logical_agreement": 56.45808,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.6066,
            "nubia_score": 0.74678
        },
        "bleurt": 0.30193,
        "bertscore": {
            "precision": 0.9288,
            "recall": 0.92487,
            "f1": 0.9249
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.14348,
        "nist": 2.731058148919434,
        "rouge1": {
            "precision": 0.46429,
            "recall": 0.41935,
            "fmeasure": 0.44068
        },
        "rouge2": {
            "precision": 0.25926,
            "recall": 0.23333,
            "fmeasure": 0.24561
        },
        "rougeL": {
            "precision": 0.46429,
            "recall": 0.41935,
            "fmeasure": 0.44068
        },
        "rougeLsum": {
            "precision": 0.46429,
            "recall": 0.41935,
            "fmeasure": 0.44068
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5714285714285714,
            "3": 0.4444444444444444
        },
        "meteor": 0.2682296725932508,
        "nubia": {
            "semantic_relation": 2.15022,
            "contradiction": 88.50655,
            "irrelevancy": 8.28597,
            "logical_agreement": 3.20748,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.82658,
            "nubia_score": 0.17367
        },
        "bleurt": -0.17695,
        "bertscore": {
            "precision": 0.90446,
            "recall": 0.89129,
            "f1": 0.89783
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.53891,
        "nist": 2.349099019744386,
        "rouge1": {
            "precision": 0.56652,
            "recall": 0.47134,
            "fmeasure": 0.49866
        },
        "rouge2": {
            "precision": 0.33457,
            "recall": 0.36115,
            "fmeasure": 0.33362
        },
        "rougeL": {
            "precision": 0.44751,
            "recall": 0.46888,
            "fmeasure": 0.44176
        },
        "rougeLsum": {
            "precision": 0.44751,
            "recall": 0.46888,
            "fmeasure": 0.44176
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.18181818181818182,
            "3": 0.46875
        },
        "meteor": 0.21971536864361724,
        "nubia": {
            "semantic_relation": 3.90358,
            "contradiction": 1.27071,
            "irrelevancy": 65.8688,
            "logical_agreement": 32.86049,
            "grammar_ref": 4.07664,
            "grammar_hyp": 4.68888,
            "nubia_score": 0.60235
        },
        "bleurt": -0.06806,
        "bertscore": {
            "precision": 0.86748,
            "recall": 0.86734,
            "f1": 0.85449
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.41902,
        "nist": 1.1154297150316326,
        "rouge1": {
            "precision": 0.36364,
            "recall": 0.33333,
            "fmeasure": 0.34783
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.27273,
            "recall": 0.25,
            "fmeasure": 0.26087
        },
        "rougeLsum": {
            "precision": 0.27273,
            "recall": 0.25,
            "fmeasure": 0.26087
        },
        "local_recall": {
            "1": 0,
            "2": 0.5
        },
        "meteor": 0.19616638765257968,
        "nubia": {
            "semantic_relation": 2.79067,
            "contradiction": 0.30646,
            "irrelevancy": 99.62136,
            "logical_agreement": 0.07218,
            "grammar_ref": 3.85254,
            "grammar_hyp": 4.69041,
            "nubia_score": 0.26592
        },
        "bleurt": -0.59064,
        "bertscore": {
            "precision": 0.83381,
            "recall": 0.85716,
            "f1": 0.84532
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 47,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.40514,
        "nist": 6.47657441569003,
        "rouge1": {
            "precision": 0.78377,
            "recall": 0.71574,
            "fmeasure": 0.74114
        },
        "rouge2": {
            "precision": 0.52017,
            "recall": 0.48451,
            "fmeasure": 0.49689
        },
        "rougeL": {
            "precision": 0.67761,
            "recall": 0.62822,
            "fmeasure": 0.64561
        },
        "rougeLsum": {
            "precision": 0.67761,
            "recall": 0.62822,
            "fmeasure": 0.64561
        },
        "local_recall": {
            "1": 0.1415929203539823,
            "2": 0.4470588235294118,
            "3": 0.7666666666666667
        },
        "meteor": 0.38450880671066495,
        "nubia": {
            "semantic_relation": 4.31477,
            "contradiction": 9.41823,
            "irrelevancy": 19.52131,
            "logical_agreement": 71.06047,
            "grammar_ref": 4.69178,
            "grammar_hyp": 4.87897,
            "nubia_score": 0.74958
        },
        "bleurt": 0.32778,
        "bertscore": {
            "precision": 0.93632,
            "recall": 0.92318,
            "f1": 0.92902
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 15,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.3914,
        "nist": 6.157816825449687,
        "rouge1": {
            "precision": 0.80593,
            "recall": 0.7431,
            "fmeasure": 0.7657
        },
        "rouge2": {
            "precision": 0.608,
            "recall": 0.56697,
            "fmeasure": 0.58117
        },
        "rougeL": {
            "precision": 0.7542,
            "recall": 0.69799,
            "fmeasure": 0.71735
        },
        "rougeLsum": {
            "precision": 0.7542,
            "recall": 0.69799,
            "fmeasure": 0.71735
        },
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.5384615384615384,
            "3": 0.7708333333333334
        },
        "meteor": 0.3998988475463041,
        "nubia": {
            "semantic_relation": 4.2755,
            "contradiction": 8.36366,
            "irrelevancy": 34.85088,
            "logical_agreement": 56.78546,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.40087,
            "nubia_score": 0.74836
        },
        "bleurt": 0.35215,
        "bertscore": {
            "precision": 0.94323,
            "recall": 0.93284,
            "f1": 0.93528
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.93655,
        "nist": 5.312282009594708,
        "rouge1": {
            "precision": 0.7578,
            "recall": 0.77743,
            "fmeasure": 0.762
        },
        "rouge2": {
            "precision": 0.53956,
            "recall": 0.56199,
            "fmeasure": 0.54625
        },
        "rougeL": {
            "precision": 0.67421,
            "recall": 0.69511,
            "fmeasure": 0.68013
        },
        "rougeLsum": {
            "precision": 0.67421,
            "recall": 0.69511,
            "fmeasure": 0.68013
        },
        "local_recall": {
            "1": 0.3684210526315789,
            "2": 0.4,
            "3": 0.8205128205128205
        },
        "meteor": 0.44983562200959404,
        "nubia": {
            "semantic_relation": 4.37401,
            "contradiction": 14.63799,
            "irrelevancy": 13.33886,
            "logical_agreement": 72.02315,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.62514,
            "nubia_score": 0.78959
        },
        "bleurt": 0.29622,
        "bertscore": {
            "precision": 0.94555,
            "recall": 0.94045,
            "f1": 0.94069
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 42,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.50617,
        "nist": 6.776293697830064,
        "rouge1": {
            "precision": 0.75229,
            "recall": 0.74929,
            "fmeasure": 0.74418
        },
        "rouge2": {
            "precision": 0.5079,
            "recall": 0.51086,
            "fmeasure": 0.50353
        },
        "rougeL": {
            "precision": 0.64888,
            "recall": 0.6426,
            "fmeasure": 0.64
        },
        "rougeLsum": {
            "precision": 0.64888,
            "recall": 0.6426,
            "fmeasure": 0.64
        },
        "local_recall": {
            "1": 0.16379310344827586,
            "2": 0.4528301886792453,
            "3": 0.7752808988764045
        },
        "meteor": 0.3963724596585158,
        "nubia": {
            "semantic_relation": 4.28817,
            "contradiction": 5.44974,
            "irrelevancy": 33.44127,
            "logical_agreement": 61.10899,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.5136,
            "nubia_score": 0.7688
        },
        "bleurt": 0.28317,
        "bertscore": {
            "precision": 0.93237,
            "recall": 0.92957,
            "f1": 0.92915
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 15,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.19021,
        "nist": 5.2183021336955,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.69453,
            "fmeasure": 0.7118
        },
        "rouge2": {
            "precision": 0.48887,
            "recall": 0.46168,
            "fmeasure": 0.46488
        },
        "rougeL": {
            "precision": 0.68277,
            "recall": 0.60188,
            "fmeasure": 0.62529
        },
        "rougeLsum": {
            "precision": 0.68277,
            "recall": 0.60188,
            "fmeasure": 0.62529
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.3181818181818182,
            "3": 0.7707006369426752
        },
        "meteor": 0.3620712958190763,
        "nubia": {
            "semantic_relation": 4.17886,
            "contradiction": 3.59343,
            "irrelevancy": 34.02039,
            "logical_agreement": 62.38617,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.82819,
            "nubia_score": 0.68011
        },
        "bleurt": 0.2487,
        "bertscore": {
            "precision": 0.92411,
            "recall": 0.91179,
            "f1": 0.91738
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.63952,
        "nist": 4.195080165127842,
        "rouge1": {
            "precision": 0.76347,
            "recall": 0.6406,
            "fmeasure": 0.68799
        },
        "rouge2": {
            "precision": 0.43417,
            "recall": 0.3568,
            "fmeasure": 0.38589
        },
        "rougeL": {
            "precision": 0.63185,
            "recall": 0.53285,
            "fmeasure": 0.57127
        },
        "rougeLsum": {
            "precision": 0.63185,
            "recall": 0.53285,
            "fmeasure": 0.57127
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6944444444444444
        },
        "meteor": 0.3397701905038361,
        "nubia": {
            "semantic_relation": 4.33033,
            "contradiction": 0.33689,
            "irrelevancy": 20.67065,
            "logical_agreement": 78.99246,
            "grammar_ref": 4.6156,
            "grammar_hyp": 4.9022,
            "nubia_score": 0.76416
        },
        "bleurt": 0.23737,
        "bertscore": {
            "precision": 0.91863,
            "recall": 0.89779,
            "f1": 0.90795
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 10,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.37673,
        "nist": 2.809568868250617,
        "rouge1": {
            "precision": 0.60554,
            "recall": 0.51814,
            "fmeasure": 0.52347
        },
        "rouge2": {
            "precision": 0.28057,
            "recall": 0.22288,
            "fmeasure": 0.23001
        },
        "rougeL": {
            "precision": 0.45969,
            "recall": 0.39651,
            "fmeasure": 0.39596
        },
        "rougeLsum": {
            "precision": 0.45969,
            "recall": 0.39651,
            "fmeasure": 0.39596
        },
        "local_recall": {
            "1": 0.05084745762711865,
            "2": 0.07692307692307693,
            "3": 0.5294117647058824
        },
        "meteor": 0.23438678226425214,
        "nubia": {
            "semantic_relation": 3.76292,
            "contradiction": 1.01604,
            "irrelevancy": 40.78382,
            "logical_agreement": 58.20014,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.61733,
            "nubia_score": 0.58919
        },
        "bleurt": -0.01616,
        "bertscore": {
            "precision": 0.8826,
            "recall": 0.85755,
            "f1": 0.86787
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 52,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.80972,
        "nist": 6.665243179338546,
        "rouge1": {
            "precision": 0.72352,
            "recall": 0.76945,
            "fmeasure": 0.73151
        },
        "rouge2": {
            "precision": 0.53279,
            "recall": 0.54204,
            "fmeasure": 0.52851
        },
        "rougeL": {
            "precision": 0.66453,
            "recall": 0.70763,
            "fmeasure": 0.672
        },
        "rougeLsum": {
            "precision": 0.66453,
            "recall": 0.70763,
            "fmeasure": 0.672
        },
        "local_recall": {
            "1": 0.2894736842105263,
            "2": 0.5837837837837838,
            "3": 0.8071979434447301
        },
        "meteor": 0.4266482868167817,
        "nubia": {
            "semantic_relation": 4.09224,
            "contradiction": 12.20527,
            "irrelevancy": 30.21225,
            "logical_agreement": 57.58248,
            "grammar_ref": 5.15177,
            "grammar_hyp": 4.9013,
            "nubia_score": 0.69305
        },
        "bleurt": 0.3631,
        "bertscore": {
            "precision": 0.93086,
            "recall": 0.93748,
            "f1": 0.93163
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 62,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.69803,
        "nist": 7.368624704107172,
        "rouge1": {
            "precision": 0.77289,
            "recall": 0.7619,
            "fmeasure": 0.75601
        },
        "rouge2": {
            "precision": 0.55608,
            "recall": 0.54666,
            "fmeasure": 0.5431
        },
        "rougeL": {
            "precision": 0.66777,
            "recall": 0.66312,
            "fmeasure": 0.65497
        },
        "rougeLsum": {
            "precision": 0.66777,
            "recall": 0.66312,
            "fmeasure": 0.65497
        },
        "local_recall": {
            "1": 0.1744186046511628,
            "2": 0.4124293785310734,
            "3": 0.8104956268221575
        },
        "meteor": 0.4037671553493613,
        "nubia": {
            "semantic_relation": 4.28398,
            "contradiction": 5.64308,
            "irrelevancy": 29.62483,
            "logical_agreement": 64.73209,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.49533,
            "nubia_score": 0.7631
        },
        "bleurt": 0.2936,
        "bertscore": {
            "precision": 0.92774,
            "recall": 0.92302,
            "f1": 0.92273
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 35,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.82938,
        "nist": 6.531343053226306,
        "rouge1": {
            "precision": 0.76981,
            "recall": 0.75257,
            "fmeasure": 0.74982
        },
        "rouge2": {
            "precision": 0.51643,
            "recall": 0.50873,
            "fmeasure": 0.50414
        },
        "rougeL": {
            "precision": 0.67402,
            "recall": 0.66678,
            "fmeasure": 0.66058
        },
        "rougeLsum": {
            "precision": 0.67402,
            "recall": 0.66678,
            "fmeasure": 0.66058
        },
        "local_recall": {
            "1": 0.1595744680851064,
            "2": 0.4336283185840708,
            "3": 0.7732997481108312
        },
        "meteor": 0.40023186623759144,
        "nubia": {
            "semantic_relation": 4.16682,
            "contradiction": 7.00421,
            "irrelevancy": 29.26224,
            "logical_agreement": 63.73356,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.48548,
            "nubia_score": 0.7351
        },
        "bleurt": 0.26262,
        "bertscore": {
            "precision": 0.93257,
            "recall": 0.93141,
            "f1": 0.93042
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 18,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.25749,
        "nist": 5.648688775440024,
        "rouge1": {
            "precision": 0.76709,
            "recall": 0.72301,
            "fmeasure": 0.72832
        },
        "rouge2": {
            "precision": 0.48741,
            "recall": 0.48797,
            "fmeasure": 0.47165
        },
        "rougeL": {
            "precision": 0.66148,
            "recall": 0.64628,
            "fmeasure": 0.63446
        },
        "rougeLsum": {
            "precision": 0.66148,
            "recall": 0.64628,
            "fmeasure": 0.63446
        },
        "local_recall": {
            "1": 0.2692307692307692,
            "2": 0.20689655172413793,
            "3": 0.7717391304347826
        },
        "meteor": 0.39542926312366944,
        "nubia": {
            "semantic_relation": 4.22303,
            "contradiction": 3.57861,
            "irrelevancy": 27.9346,
            "logical_agreement": 68.48678,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.7406,
            "nubia_score": 0.73634
        },
        "bleurt": 0.21675,
        "bertscore": {
            "precision": 0.92855,
            "recall": 0.92426,
            "f1": 0.92452
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 20,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.38937,
        "nist": 6.620162959579926,
        "rouge1": {
            "precision": 0.77622,
            "recall": 0.79454,
            "fmeasure": 0.78104
        },
        "rouge2": {
            "precision": 0.61177,
            "recall": 0.6248,
            "fmeasure": 0.61522
        },
        "rougeL": {
            "precision": 0.65691,
            "recall": 0.66548,
            "fmeasure": 0.65695
        },
        "rougeLsum": {
            "precision": 0.65691,
            "recall": 0.66548,
            "fmeasure": 0.65695
        },
        "local_recall": {
            "1": 0.13725490196078433,
            "2": 0.46296296296296297,
            "3": 0.8711111111111111
        },
        "meteor": 0.4439987022221711,
        "nubia": {
            "semantic_relation": 4.42227,
            "contradiction": 2.67113,
            "irrelevancy": 31.8887,
            "logical_agreement": 65.44016,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.45941,
            "nubia_score": 0.81967
        },
        "bleurt": 0.44102,
        "bertscore": {
            "precision": 0.93801,
            "recall": 0.93975,
            "f1": 0.93779
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 10,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.98252,
        "nist": 5.9579608559653225,
        "rouge1": {
            "precision": 0.75878,
            "recall": 0.7758,
            "fmeasure": 0.75862
        },
        "rouge2": {
            "precision": 0.54583,
            "recall": 0.5501,
            "fmeasure": 0.54231
        },
        "rougeL": {
            "precision": 0.64773,
            "recall": 0.64535,
            "fmeasure": 0.63837
        },
        "rougeLsum": {
            "precision": 0.64773,
            "recall": 0.64535,
            "fmeasure": 0.63837
        },
        "local_recall": {
            "1": 0.45161290322580644,
            "2": 0.4,
            "3": 0.7477477477477478
        },
        "meteor": 0.38450967590151386,
        "nubia": {
            "semantic_relation": 3.97502,
            "contradiction": 11.99351,
            "irrelevancy": 53.32831,
            "logical_agreement": 34.67818,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.73301,
            "nubia_score": 0.6271
        },
        "bleurt": 0.12706,
        "bertscore": {
            "precision": 0.92003,
            "recall": 0.93153,
            "f1": 0.92386
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 18,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.73646,
        "nist": 5.286026965494843,
        "rouge1": {
            "precision": 0.62472,
            "recall": 0.67893,
            "fmeasure": 0.63637
        },
        "rouge2": {
            "precision": 0.39855,
            "recall": 0.42344,
            "fmeasure": 0.40089
        },
        "rougeL": {
            "precision": 0.51377,
            "recall": 0.55423,
            "fmeasure": 0.52139
        },
        "rougeLsum": {
            "precision": 0.51377,
            "recall": 0.55423,
            "fmeasure": 0.52139
        },
        "local_recall": {
            "1": 0.22058823529411764,
            "2": 0.6056338028169014,
            "3": 0.6935483870967742
        },
        "meteor": 0.3484288623464862,
        "nubia": {
            "semantic_relation": 3.93655,
            "contradiction": 10.25325,
            "irrelevancy": 39.68499,
            "logical_agreement": 50.06176,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.23498,
            "nubia_score": 0.66523
        },
        "bleurt": 0.05151,
        "bertscore": {
            "precision": 0.896,
            "recall": 0.90369,
            "f1": 0.89784
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 17,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.83853,
        "nist": 6.2688423482903595,
        "rouge1": {
            "precision": 0.80671,
            "recall": 0.7429,
            "fmeasure": 0.76942
        },
        "rouge2": {
            "precision": 0.55376,
            "recall": 0.50362,
            "fmeasure": 0.52459
        },
        "rougeL": {
            "precision": 0.7108,
            "recall": 0.6496,
            "fmeasure": 0.67513
        },
        "rougeLsum": {
            "precision": 0.7108,
            "recall": 0.6496,
            "fmeasure": 0.67513
        },
        "local_recall": {
            "1": 0.10416666666666667,
            "2": 0.625,
            "3": 0.7511961722488039
        },
        "meteor": 0.4000665922372789,
        "nubia": {
            "semantic_relation": 4.26501,
            "contradiction": 9.74329,
            "irrelevancy": 22.12236,
            "logical_agreement": 68.13435,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.58468,
            "nubia_score": 0.7283
        },
        "bleurt": 0.34351,
        "bertscore": {
            "precision": 0.94095,
            "recall": 0.92779,
            "f1": 0.93398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 46,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.21613,
        "nist": 6.558265168618069,
        "rouge1": {
            "precision": 0.75951,
            "recall": 0.73296,
            "fmeasure": 0.73504
        },
        "rouge2": {
            "precision": 0.52274,
            "recall": 0.50933,
            "fmeasure": 0.50835
        },
        "rougeL": {
            "precision": 0.67383,
            "recall": 0.65236,
            "fmeasure": 0.65334
        },
        "rougeLsum": {
            "precision": 0.67383,
            "recall": 0.65236,
            "fmeasure": 0.65334
        },
        "local_recall": {
            "1": 0.2818181818181818,
            "2": 0.40875912408759124,
            "3": 0.7391304347826086
        },
        "meteor": 0.3737815049848721,
        "nubia": {
            "semantic_relation": 4.27744,
            "contradiction": 5.1911,
            "irrelevancy": 39.50128,
            "logical_agreement": 55.30762,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.72389,
            "nubia_score": 0.74148
        },
        "bleurt": 0.33654,
        "bertscore": {
            "precision": 0.92718,
            "recall": 0.92201,
            "f1": 0.92327
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.18556,
        "nist": 5.28582692264725,
        "rouge1": {
            "precision": 0.7615,
            "recall": 0.72546,
            "fmeasure": 0.73592
        },
        "rouge2": {
            "precision": 0.52569,
            "recall": 0.48703,
            "fmeasure": 0.49952
        },
        "rougeL": {
            "precision": 0.62217,
            "recall": 0.58111,
            "fmeasure": 0.59537
        },
        "rougeLsum": {
            "precision": 0.62217,
            "recall": 0.58111,
            "fmeasure": 0.59537
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.6410256410256411,
            "3": 0.6896551724137931
        },
        "meteor": 0.36750114707535153,
        "nubia": {
            "semantic_relation": 3.85791,
            "contradiction": 3.82886,
            "irrelevancy": 45.93336,
            "logical_agreement": 50.23778,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.35347,
            "nubia_score": 0.63135
        },
        "bleurt": 0.08618,
        "bertscore": {
            "precision": 0.92007,
            "recall": 0.91769,
            "f1": 0.91652
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.68934,
        "nist": 4.919065702113439,
        "rouge1": {
            "precision": 0.73585,
            "recall": 0.73292,
            "fmeasure": 0.72454
        },
        "rouge2": {
            "precision": 0.49141,
            "recall": 0.45548,
            "fmeasure": 0.46641
        },
        "rougeL": {
            "precision": 0.58122,
            "recall": 0.56841,
            "fmeasure": 0.56787
        },
        "rougeLsum": {
            "precision": 0.58122,
            "recall": 0.56841,
            "fmeasure": 0.56787
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.3888888888888889,
            "3": 0.8095238095238095
        },
        "meteor": 0.36837280595383615,
        "nubia": {
            "semantic_relation": 4.30035,
            "contradiction": 16.16826,
            "irrelevancy": 22.36039,
            "logical_agreement": 61.47134,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.2058,
            "nubia_score": 0.77833
        },
        "bleurt": 0.24474,
        "bertscore": {
            "precision": 0.92435,
            "recall": 0.92648,
            "f1": 0.9247
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 79,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.7501,
        "nist": 7.032072539166239,
        "rouge1": {
            "precision": 0.7357,
            "recall": 0.68585,
            "fmeasure": 0.69318
        },
        "rouge2": {
            "precision": 0.49197,
            "recall": 0.4531,
            "fmeasure": 0.4594
        },
        "rougeL": {
            "precision": 0.61756,
            "recall": 0.58114,
            "fmeasure": 0.58468
        },
        "rougeLsum": {
            "precision": 0.61756,
            "recall": 0.58114,
            "fmeasure": 0.58468
        },
        "local_recall": {
            "1": 0.24115755627009647,
            "2": 0.3972602739726027,
            "3": 0.7509881422924901
        },
        "meteor": 0.3690856860991011,
        "nubia": {
            "semantic_relation": 4.02604,
            "contradiction": 8.84033,
            "irrelevancy": 36.23031,
            "logical_agreement": 54.92936,
            "grammar_ref": 4.80224,
            "grammar_hyp": 4.96241,
            "nubia_score": 0.65763
        },
        "bleurt": 0.16142,
        "bertscore": {
            "precision": 0.92367,
            "recall": 0.91428,
            "f1": 0.91695
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.88057,
        "nist": 4.3834149777173685,
        "rouge1": {
            "precision": 0.84074,
            "recall": 0.7734,
            "fmeasure": 0.78975
        },
        "rouge2": {
            "precision": 0.65863,
            "recall": 0.59434,
            "fmeasure": 0.61248
        },
        "rougeL": {
            "precision": 0.76389,
            "recall": 0.71785,
            "fmeasure": 0.7258
        },
        "rougeLsum": {
            "precision": 0.76389,
            "recall": 0.71785,
            "fmeasure": 0.7258
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "meteor": 0.4400328117133674,
        "nubia": {
            "semantic_relation": 4.44443,
            "contradiction": 0.8349,
            "irrelevancy": 24.63222,
            "logical_agreement": 74.53288,
            "grammar_ref": 6.02061,
            "grammar_hyp": 6.40052,
            "nubia_score": 0.73301
        },
        "bleurt": 0.48858,
        "bertscore": {
            "precision": 0.95872,
            "recall": 0.9593,
            "f1": 0.95848
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.59031,
        "nist": 3.884879729419123,
        "rouge1": {
            "precision": 0.8007,
            "recall": 0.88528,
            "fmeasure": 0.84012
        },
        "rouge2": {
            "precision": 0.63095,
            "recall": 0.7,
            "fmeasure": 0.66297
        },
        "rougeL": {
            "precision": 0.73951,
            "recall": 0.81602,
            "fmeasure": 0.77519
        },
        "rougeLsum": {
            "precision": 0.73951,
            "recall": 0.81602,
            "fmeasure": 0.77519
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8846153846153846
        },
        "meteor": 0.4793717982300027,
        "nubia": {
            "semantic_relation": 4.9525,
            "contradiction": 0.26375,
            "irrelevancy": 2.98357,
            "logical_agreement": 96.75268,
            "grammar_ref": 5.14789,
            "grammar_hyp": 4.66828,
            "nubia_score": 0.97827
        },
        "bleurt": 0.69896,
        "bertscore": {
            "precision": 0.95359,
            "recall": 0.96944,
            "f1": 0.96139
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 11,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.06697,
        "nist": 5.493863401108478,
        "rouge1": {
            "precision": 0.71938,
            "recall": 0.7262,
            "fmeasure": 0.7118
        },
        "rouge2": {
            "precision": 0.45495,
            "recall": 0.48071,
            "fmeasure": 0.45971
        },
        "rougeL": {
            "precision": 0.60708,
            "recall": 0.64308,
            "fmeasure": 0.61293
        },
        "rougeLsum": {
            "precision": 0.60708,
            "recall": 0.64308,
            "fmeasure": 0.61293
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.21428571428571427,
            "3": 0.7401574803149606
        },
        "meteor": 0.35247377060742424,
        "nubia": {
            "semantic_relation": 3.84893,
            "contradiction": 18.4029,
            "irrelevancy": 50.69249,
            "logical_agreement": 30.90461,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.5304,
            "nubia_score": 0.6234
        },
        "bleurt": 0.18771,
        "bertscore": {
            "precision": 0.91777,
            "recall": 0.92707,
            "f1": 0.92007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 36,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.68166,
        "nist": 5.849730965743049,
        "rouge1": {
            "precision": 0.71593,
            "recall": 0.67846,
            "fmeasure": 0.67698
        },
        "rouge2": {
            "precision": 0.47926,
            "recall": 0.46204,
            "fmeasure": 0.45583
        },
        "rougeL": {
            "precision": 0.64148,
            "recall": 0.61164,
            "fmeasure": 0.60851
        },
        "rougeLsum": {
            "precision": 0.64148,
            "recall": 0.61164,
            "fmeasure": 0.60851
        },
        "local_recall": {
            "1": 0.1485148514851485,
            "2": 0.4365079365079365,
            "3": 0.7067448680351907
        },
        "meteor": 0.35519584532805376,
        "nubia": {
            "semantic_relation": 3.97035,
            "contradiction": 10.46729,
            "irrelevancy": 32.28624,
            "logical_agreement": 57.24647,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.66094,
            "nubia_score": 0.66638
        },
        "bleurt": 0.19246,
        "bertscore": {
            "precision": 0.91921,
            "recall": 0.90232,
            "f1": 0.90819
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 17,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.78195,
        "nist": 6.484953446142571,
        "rouge1": {
            "precision": 0.80382,
            "recall": 0.79565,
            "fmeasure": 0.79133
        },
        "rouge2": {
            "precision": 0.5906,
            "recall": 0.58628,
            "fmeasure": 0.5825
        },
        "rougeL": {
            "precision": 0.67831,
            "recall": 0.67549,
            "fmeasure": 0.66994
        },
        "rougeLsum": {
            "precision": 0.67831,
            "recall": 0.67549,
            "fmeasure": 0.66994
        },
        "local_recall": {
            "1": 0.16923076923076924,
            "2": 0.5614035087719298,
            "3": 0.8546511627906976
        },
        "meteor": 0.43697914414037764,
        "nubia": {
            "semantic_relation": 4.29969,
            "contradiction": 4.65602,
            "irrelevancy": 27.89989,
            "logical_agreement": 67.44409,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.79997,
            "nubia_score": 0.7619
        },
        "bleurt": 0.29633,
        "bertscore": {
            "precision": 0.94585,
            "recall": 0.94505,
            "f1": 0.94363
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.19557,
        "nist": 1.5652175776270818,
        "rouge1": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "rouge2": {
            "precision": 0.27451,
            "recall": 0.48148,
            "fmeasure": 0.34948
        },
        "rougeL": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "rougeLsum": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "meteor": 0.3765336700589018,
        "nubia": {
            "semantic_relation": 3.96037,
            "contradiction": 0.18805,
            "irrelevancy": 41.18447,
            "logical_agreement": 58.62748,
            "grammar_ref": 5.00001,
            "grammar_hyp": 3.99765,
            "nubia_score": 0.56163
        },
        "bleurt": 0.19996,
        "bertscore": {
            "precision": 0.86048,
            "recall": 0.91595,
            "f1": 0.88735
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 78,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.62652,
        "nist": 7.632307032162791,
        "rouge1": {
            "precision": 0.76024,
            "recall": 0.74628,
            "fmeasure": 0.74327
        },
        "rouge2": {
            "precision": 0.5357,
            "recall": 0.52264,
            "fmeasure": 0.52104
        },
        "rougeL": {
            "precision": 0.69354,
            "recall": 0.67764,
            "fmeasure": 0.67603
        },
        "rougeLsum": {
            "precision": 0.69354,
            "recall": 0.67764,
            "fmeasure": 0.67603
        },
        "local_recall": {
            "1": 0.24892703862660945,
            "2": 0.5234042553191489,
            "3": 0.7992700729927007
        },
        "meteor": 0.42146536610737606,
        "nubia": {
            "semantic_relation": 4.33347,
            "contradiction": 7.14833,
            "irrelevancy": 28.02058,
            "logical_agreement": 64.83109,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.59569,
            "nubia_score": 0.77761
        },
        "bleurt": 0.35046,
        "bertscore": {
            "precision": 0.93236,
            "recall": 0.93609,
            "f1": 0.9329
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 25,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.36795,
        "nist": 6.914876194522565,
        "rouge1": {
            "precision": 0.81174,
            "recall": 0.80315,
            "fmeasure": 0.80016
        },
        "rouge2": {
            "precision": 0.64077,
            "recall": 0.63314,
            "fmeasure": 0.63007
        },
        "rougeL": {
            "precision": 0.73788,
            "recall": 0.72661,
            "fmeasure": 0.72508
        },
        "rougeLsum": {
            "precision": 0.73788,
            "recall": 0.72661,
            "fmeasure": 0.72508
        },
        "local_recall": {
            "1": 0.16071428571428573,
            "2": 0.3488372093023256,
            "3": 0.8636363636363636
        },
        "meteor": 0.4606897423462232,
        "nubia": {
            "semantic_relation": 4.32788,
            "contradiction": 5.54076,
            "irrelevancy": 28.09468,
            "logical_agreement": 66.36456,
            "grammar_ref": 4.85173,
            "grammar_hyp": 4.85085,
            "nubia_score": 0.76252
        },
        "bleurt": 0.43091,
        "bertscore": {
            "precision": 0.94815,
            "recall": 0.94418,
            "f1": 0.94568
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 48,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.5157,
        "nist": 6.630491560542142,
        "rouge1": {
            "precision": 0.73741,
            "recall": 0.68333,
            "fmeasure": 0.69815
        },
        "rouge2": {
            "precision": 0.48234,
            "recall": 0.45515,
            "fmeasure": 0.46074
        },
        "rougeL": {
            "precision": 0.61945,
            "recall": 0.57951,
            "fmeasure": 0.58959
        },
        "rougeLsum": {
            "precision": 0.61945,
            "recall": 0.57951,
            "fmeasure": 0.58959
        },
        "local_recall": {
            "1": 0.23391812865497075,
            "2": 0.532051282051282,
            "3": 0.722007722007722
        },
        "meteor": 0.3689664505837175,
        "nubia": {
            "semantic_relation": 4.0259,
            "contradiction": 8.19371,
            "irrelevancy": 29.79117,
            "logical_agreement": 62.01512,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.61118,
            "nubia_score": 0.68707
        },
        "bleurt": 0.16483,
        "bertscore": {
            "precision": 0.9257,
            "recall": 0.91002,
            "f1": 0.91504
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.47165,
        "nist": 4.106453475410098,
        "rouge1": {
            "precision": 0.6294,
            "recall": 0.61414,
            "fmeasure": 0.60971
        },
        "rouge2": {
            "precision": 0.36562,
            "recall": 0.36413,
            "fmeasure": 0.35763
        },
        "rougeL": {
            "precision": 0.46925,
            "recall": 0.53622,
            "fmeasure": 0.48027
        },
        "rougeLsum": {
            "precision": 0.46925,
            "recall": 0.53622,
            "fmeasure": 0.48027
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.34375,
            "3": 0.675
        },
        "meteor": 0.3247902334931136,
        "nubia": {
            "semantic_relation": 3.71771,
            "contradiction": 3.94254,
            "irrelevancy": 58.17101,
            "logical_agreement": 37.88645,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.00143,
            "nubia_score": 0.59059
        },
        "bleurt": -0.00264,
        "bertscore": {
            "precision": 0.89833,
            "recall": 0.90474,
            "f1": 0.89471
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 11.0448,
        "nist": 0.8345864788028046,
        "rouge1": {
            "precision": 0.59259,
            "recall": 0.47037,
            "fmeasure": 0.5083
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.20175,
            "fmeasure": 0.21605
        },
        "rougeL": {
            "precision": 0.48148,
            "recall": 0.37963,
            "fmeasure": 0.41124
        },
        "rougeLsum": {
            "precision": 0.48148,
            "recall": 0.37963,
            "fmeasure": 0.41124
        },
        "local_recall": {
            "1": 0,
            "2": 0.1111111111111111,
            "3": 0.5
        },
        "meteor": 0.20516733047640073,
        "nubia": {
            "semantic_relation": 2.70078,
            "contradiction": 91.14661,
            "irrelevancy": 6.79946,
            "logical_agreement": 2.05393,
            "grammar_ref": 4.8547,
            "grammar_hyp": 5.37065,
            "nubia_score": 0.16868
        },
        "bleurt": -0.60636,
        "bertscore": {
            "precision": 0.88692,
            "recall": 0.89284,
            "f1": 0.88755
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 12,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.94082,
        "nist": 5.431429256707032,
        "rouge1": {
            "precision": 0.74414,
            "recall": 0.73758,
            "fmeasure": 0.73142
        },
        "rouge2": {
            "precision": 0.49035,
            "recall": 0.48012,
            "fmeasure": 0.47828
        },
        "rougeL": {
            "precision": 0.62016,
            "recall": 0.61298,
            "fmeasure": 0.60959
        },
        "rougeLsum": {
            "precision": 0.62016,
            "recall": 0.61298,
            "fmeasure": 0.60959
        },
        "local_recall": {
            "1": 0.16,
            "2": 0.19230769230769232,
            "3": 0.7411764705882353
        },
        "meteor": 0.3460561601807033,
        "nubia": {
            "semantic_relation": 4.15312,
            "contradiction": 13.61651,
            "irrelevancy": 27.8057,
            "logical_agreement": 58.57778,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.19357,
            "nubia_score": 0.75511
        },
        "bleurt": 0.22841,
        "bertscore": {
            "precision": 0.92224,
            "recall": 0.91202,
            "f1": 0.91551
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 18,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.293,
        "nist": 5.241771199196493,
        "rouge1": {
            "precision": 0.65615,
            "recall": 0.70265,
            "fmeasure": 0.67159
        },
        "rouge2": {
            "precision": 0.40238,
            "recall": 0.42901,
            "fmeasure": 0.41079
        },
        "rougeL": {
            "precision": 0.53741,
            "recall": 0.57961,
            "fmeasure": 0.55171
        },
        "rougeLsum": {
            "precision": 0.53741,
            "recall": 0.57961,
            "fmeasure": 0.55171
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.4642857142857143,
            "3": 0.788235294117647
        },
        "meteor": 0.35789027130818973,
        "nubia": {
            "semantic_relation": 4.19616,
            "contradiction": 0.89725,
            "irrelevancy": 47.57718,
            "logical_agreement": 51.52557,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.61391,
            "nubia_score": 0.74721
        },
        "bleurt": 0.24119,
        "bertscore": {
            "precision": 0.90834,
            "recall": 0.92082,
            "f1": 0.91286
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 22,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.63209,
        "nist": 5.968039869224728,
        "rouge1": {
            "precision": 0.73354,
            "recall": 0.76671,
            "fmeasure": 0.73934
        },
        "rouge2": {
            "precision": 0.4883,
            "recall": 0.50757,
            "fmeasure": 0.48907
        },
        "rougeL": {
            "precision": 0.61691,
            "recall": 0.65502,
            "fmeasure": 0.62563
        },
        "rougeLsum": {
            "precision": 0.61691,
            "recall": 0.65502,
            "fmeasure": 0.62563
        },
        "local_recall": {
            "1": 0.28,
            "2": 0.4727272727272727,
            "3": 0.8369565217391305
        },
        "meteor": 0.3981845544983204,
        "nubia": {
            "semantic_relation": 4.27173,
            "contradiction": 10.45189,
            "irrelevancy": 27.96174,
            "logical_agreement": 61.58637,
            "grammar_ref": 5.03776,
            "grammar_hyp": 4.88991,
            "nubia_score": 0.73133
        },
        "bleurt": 0.20656,
        "bertscore": {
            "precision": 0.91993,
            "recall": 0.93324,
            "f1": 0.92503
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 41,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.5129,
        "nist": 6.339474912338303,
        "rouge1": {
            "precision": 0.73723,
            "recall": 0.75656,
            "fmeasure": 0.7419
        },
        "rouge2": {
            "precision": 0.52579,
            "recall": 0.53106,
            "fmeasure": 0.52493
        },
        "rougeL": {
            "precision": 0.63242,
            "recall": 0.64855,
            "fmeasure": 0.63547
        },
        "rougeLsum": {
            "precision": 0.63242,
            "recall": 0.64855,
            "fmeasure": 0.63547
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.4793388429752066,
            "3": 0.8090909090909091
        },
        "meteor": 0.41667321946190494,
        "nubia": {
            "semantic_relation": 4.14194,
            "contradiction": 5.80274,
            "irrelevancy": 38.49735,
            "logical_agreement": 55.69991,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.33447,
            "nubia_score": 0.75865
        },
        "bleurt": 0.37752,
        "bertscore": {
            "precision": 0.93047,
            "recall": 0.93632,
            "f1": 0.9321
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.00664,
        "nist": 5.1816534612736715,
        "rouge1": {
            "precision": 0.75667,
            "recall": 0.89244,
            "fmeasure": 0.80616
        },
        "rouge2": {
            "precision": 0.55853,
            "recall": 0.63137,
            "fmeasure": 0.58321
        },
        "rougeL": {
            "precision": 0.71222,
            "recall": 0.8434,
            "fmeasure": 0.75966
        },
        "rougeLsum": {
            "precision": 0.71222,
            "recall": 0.8434,
            "fmeasure": 0.75966
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.75,
            "3": 0.9130434782608695
        },
        "meteor": 0.43784095454099947,
        "nubia": {
            "semantic_relation": 4.41046,
            "contradiction": 4.5692,
            "irrelevancy": 25.77911,
            "logical_agreement": 69.65169,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.37589,
            "nubia_score": 0.83896
        },
        "bleurt": 0.33686,
        "bertscore": {
            "precision": 0.92762,
            "recall": 0.95809,
            "f1": 0.94039
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 72.11936,
        "nist": 5.252629686365957,
        "rouge1": {
            "precision": 0.79895,
            "recall": 0.81932,
            "fmeasure": 0.80817
        },
        "rouge2": {
            "precision": 0.61333,
            "recall": 0.62568,
            "fmeasure": 0.61873
        },
        "rougeL": {
            "precision": 0.71562,
            "recall": 0.78995,
            "fmeasure": 0.74872
        },
        "rougeLsum": {
            "precision": 0.71562,
            "recall": 0.78995,
            "fmeasure": 0.74872
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8518518518518519
        },
        "meteor": 0.4848542549999902,
        "nubia": {
            "semantic_relation": 4.63195,
            "contradiction": 0.48693,
            "irrelevancy": 17.35687,
            "logical_agreement": 82.1562,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.28349,
            "nubia_score": 0.83078
        },
        "bleurt": 0.42752,
        "bertscore": {
            "precision": 0.95111,
            "recall": 0.92684,
            "f1": 0.93869
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 21,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.57157,
        "nist": 5.96910745924452,
        "rouge1": {
            "precision": 0.70316,
            "recall": 0.68067,
            "fmeasure": 0.67967
        },
        "rouge2": {
            "precision": 0.43304,
            "recall": 0.44387,
            "fmeasure": 0.43098
        },
        "rougeL": {
            "precision": 0.56263,
            "recall": 0.55208,
            "fmeasure": 0.54788
        },
        "rougeLsum": {
            "precision": 0.56263,
            "recall": 0.55208,
            "fmeasure": 0.54788
        },
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.4574468085106383,
            "3": 0.7216494845360825
        },
        "meteor": 0.3555641012839841,
        "nubia": {
            "semantic_relation": 4.1002,
            "contradiction": 15.17569,
            "irrelevancy": 29.2119,
            "logical_agreement": 55.61241,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.82928,
            "nubia_score": 0.64782
        },
        "bleurt": 0.20708,
        "bertscore": {
            "precision": 0.92183,
            "recall": 0.91719,
            "f1": 0.91804
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 17,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.66621,
        "nist": 6.552441523693102,
        "rouge1": {
            "precision": 0.79403,
            "recall": 0.76824,
            "fmeasure": 0.76988
        },
        "rouge2": {
            "precision": 0.59449,
            "recall": 0.58104,
            "fmeasure": 0.57778
        },
        "rougeL": {
            "precision": 0.68541,
            "recall": 0.66296,
            "fmeasure": 0.66395
        },
        "rougeLsum": {
            "precision": 0.68541,
            "recall": 0.66296,
            "fmeasure": 0.66395
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5510204081632653,
            "3": 0.8010752688172043
        },
        "meteor": 0.4040661089026944,
        "nubia": {
            "semantic_relation": 4.35109,
            "contradiction": 2.37172,
            "irrelevancy": 28.18277,
            "logical_agreement": 69.4455,
            "grammar_ref": 4.21928,
            "grammar_hyp": 4.05545,
            "nubia_score": 0.82792
        },
        "bleurt": 0.2975,
        "bertscore": {
            "precision": 0.93588,
            "recall": 0.9294,
            "f1": 0.92824
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 36,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.91108,
        "nist": 7.129310768770808,
        "rouge1": {
            "precision": 0.7964,
            "recall": 0.76116,
            "fmeasure": 0.76572
        },
        "rouge2": {
            "precision": 0.53781,
            "recall": 0.51927,
            "fmeasure": 0.51953
        },
        "rougeL": {
            "precision": 0.69234,
            "recall": 0.66942,
            "fmeasure": 0.66929
        },
        "rougeLsum": {
            "precision": 0.69234,
            "recall": 0.66942,
            "fmeasure": 0.66929
        },
        "local_recall": {
            "1": 0.25675675675675674,
            "2": 0.449438202247191,
            "3": 0.7990314769975787
        },
        "meteor": 0.4017710940505716,
        "nubia": {
            "semantic_relation": 4.30701,
            "contradiction": 1.0259,
            "irrelevancy": 29.96635,
            "logical_agreement": 69.00775,
            "grammar_ref": 4.82696,
            "grammar_hyp": 4.95825,
            "nubia_score": 0.73455
        },
        "bleurt": 0.28646,
        "bertscore": {
            "precision": 0.93517,
            "recall": 0.92967,
            "f1": 0.93109
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 31,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.16762,
        "nist": 7.226666154392695,
        "rouge1": {
            "precision": 0.79511,
            "recall": 0.79057,
            "fmeasure": 0.78359
        },
        "rouge2": {
            "precision": 0.60993,
            "recall": 0.60957,
            "fmeasure": 0.60273
        },
        "rougeL": {
            "precision": 0.71006,
            "recall": 0.70782,
            "fmeasure": 0.70087
        },
        "rougeLsum": {
            "precision": 0.71006,
            "recall": 0.70782,
            "fmeasure": 0.70087
        },
        "local_recall": {
            "1": 0.20353982300884957,
            "2": 0.5510204081632653,
            "3": 0.8126721763085399
        },
        "meteor": 0.4508020747677332,
        "nubia": {
            "semantic_relation": 4.22804,
            "contradiction": 8.60134,
            "irrelevancy": 29.01824,
            "logical_agreement": 62.38042,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.76868,
            "nubia_score": 0.73757
        },
        "bleurt": 0.36092,
        "bertscore": {
            "precision": 0.93748,
            "recall": 0.93875,
            "f1": 0.93684
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 12,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.7212,
        "nist": 5.6312673323992,
        "rouge1": {
            "precision": 0.74842,
            "recall": 0.72158,
            "fmeasure": 0.72723
        },
        "rouge2": {
            "precision": 0.50133,
            "recall": 0.48771,
            "fmeasure": 0.48875
        },
        "rougeL": {
            "precision": 0.66701,
            "recall": 0.64946,
            "fmeasure": 0.65125
        },
        "rougeLsum": {
            "precision": 0.66701,
            "recall": 0.64946,
            "fmeasure": 0.65125
        },
        "local_recall": {
            "1": 0.17142857142857143,
            "2": 0.1724137931034483,
            "3": 0.7768595041322314
        },
        "meteor": 0.39981541973796003,
        "nubia": {
            "semantic_relation": 4.49006,
            "contradiction": 4.00372,
            "irrelevancy": 27.84778,
            "logical_agreement": 68.1485,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.37849,
            "nubia_score": 0.82672
        },
        "bleurt": 0.50096,
        "bertscore": {
            "precision": 0.94545,
            "recall": 0.94438,
            "f1": 0.94421
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 10,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.70952,
        "nist": 5.777788251011236,
        "rouge1": {
            "precision": 0.79103,
            "recall": 0.77116,
            "fmeasure": 0.77501
        },
        "rouge2": {
            "precision": 0.48844,
            "recall": 0.46692,
            "fmeasure": 0.47233
        },
        "rougeL": {
            "precision": 0.64013,
            "recall": 0.6322,
            "fmeasure": 0.62989
        },
        "rougeLsum": {
            "precision": 0.64013,
            "recall": 0.6322,
            "fmeasure": 0.62989
        },
        "local_recall": {
            "1": 0.4074074074074074,
            "2": 0.5882352941176471,
            "3": 0.7735849056603774
        },
        "meteor": 0.3840863450303239,
        "nubia": {
            "semantic_relation": 4.6037,
            "contradiction": 1.2456,
            "irrelevancy": 22.73085,
            "logical_agreement": 76.02354,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.24881,
            "nubia_score": 0.82221
        },
        "bleurt": 0.30182,
        "bertscore": {
            "precision": 0.93467,
            "recall": 0.93411,
            "f1": 0.9328
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 169,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.4169,
        "nist": 7.891547645811215,
        "rouge1": {
            "precision": 0.76082,
            "recall": 0.7566,
            "fmeasure": 0.7487
        },
        "rouge2": {
            "precision": 0.52879,
            "recall": 0.52398,
            "fmeasure": 0.51895
        },
        "rougeL": {
            "precision": 0.6509,
            "recall": 0.64994,
            "fmeasure": 0.64182
        },
        "rougeLsum": {
            "precision": 0.6509,
            "recall": 0.64994,
            "fmeasure": 0.64182
        },
        "local_recall": {
            "1": 0.200836820083682,
            "2": 0.4606741573033708,
            "3": 0.7922008547008547
        },
        "meteor": 0.3981686196980558,
        "nubia": {
            "semantic_relation": 4.26549,
            "contradiction": 6.64047,
            "irrelevancy": 30.17297,
            "logical_agreement": 63.18656,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.61276,
            "nubia_score": 0.76203
        },
        "bleurt": 0.32427,
        "bertscore": {
            "precision": 0.92847,
            "recall": 0.92803,
            "f1": 0.92665
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 114,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.14005,
        "nist": 6.971167467243222,
        "rouge1": {
            "precision": 0.71346,
            "recall": 0.70824,
            "fmeasure": 0.69785
        },
        "rouge2": {
            "precision": 0.45805,
            "recall": 0.45695,
            "fmeasure": 0.44886
        },
        "rougeL": {
            "precision": 0.60834,
            "recall": 0.60755,
            "fmeasure": 0.59703
        },
        "rougeLsum": {
            "precision": 0.60834,
            "recall": 0.60755,
            "fmeasure": 0.59703
        },
        "local_recall": {
            "1": 0.22885572139303484,
            "2": 0.48223350253807107,
            "3": 0.752414398595259
        },
        "meteor": 0.3660644140620105,
        "nubia": {
            "semantic_relation": 4.14932,
            "contradiction": 9.25851,
            "irrelevancy": 35.32344,
            "logical_agreement": 55.41804,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.57443,
            "nubia_score": 0.7078
        },
        "bleurt": 0.20375,
        "bertscore": {
            "precision": 0.9164,
            "recall": 0.92171,
            "f1": 0.91718
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.24027,
        "nist": 4.72231847955668,
        "rouge1": {
            "precision": 0.6645,
            "recall": 0.68289,
            "fmeasure": 0.66657
        },
        "rouge2": {
            "precision": 0.38947,
            "recall": 0.39228,
            "fmeasure": 0.38582
        },
        "rougeL": {
            "precision": 0.48271,
            "recall": 0.50864,
            "fmeasure": 0.49053
        },
        "rougeLsum": {
            "precision": 0.48271,
            "recall": 0.50864,
            "fmeasure": 0.49053
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.6923076923076923,
            "3": 0.7241379310344828
        },
        "meteor": 0.36128753233013045,
        "nubia": {
            "semantic_relation": 4.05553,
            "contradiction": 1.35027,
            "irrelevancy": 65.11741,
            "logical_agreement": 33.53231,
            "grammar_ref": 3.92533,
            "grammar_hyp": 3.83791,
            "nubia_score": 0.755
        },
        "bleurt": 0.17733,
        "bertscore": {
            "precision": 0.90748,
            "recall": 0.91309,
            "f1": 0.9101
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 37,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.73861,
        "nist": 6.565273728897212,
        "rouge1": {
            "precision": 0.72205,
            "recall": 0.73434,
            "fmeasure": 0.71341
        },
        "rouge2": {
            "precision": 0.47988,
            "recall": 0.48879,
            "fmeasure": 0.47422
        },
        "rougeL": {
            "precision": 0.61366,
            "recall": 0.62058,
            "fmeasure": 0.60457
        },
        "rougeLsum": {
            "precision": 0.61366,
            "recall": 0.62058,
            "fmeasure": 0.60457
        },
        "local_recall": {
            "1": 0.3014705882352941,
            "2": 0.46938775510204084,
            "3": 0.7367149758454107
        },
        "meteor": 0.38684706801104995,
        "nubia": {
            "semantic_relation": 4.08308,
            "contradiction": 7.53728,
            "irrelevancy": 39.31871,
            "logical_agreement": 53.14401,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.73944,
            "nubia_score": 0.69719
        },
        "bleurt": 0.13195,
        "bertscore": {
            "precision": 0.91759,
            "recall": 0.91981,
            "f1": 0.91699
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.57776,
        "nist": 3.571330472109945,
        "rouge1": {
            "precision": 0.62698,
            "recall": 0.66815,
            "fmeasure": 0.64014
        },
        "rouge2": {
            "precision": 0.45299,
            "recall": 0.43889,
            "fmeasure": 0.44461
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.65508,
            "fmeasure": 0.62581
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.65508,
            "fmeasure": 0.62581
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.4444444444444444,
            "3": 0.7727272727272727
        },
        "meteor": 0.39961261433366313,
        "nubia": {
            "semantic_relation": 4.1017,
            "contradiction": 0.43236,
            "irrelevancy": 44.30244,
            "logical_agreement": 55.2652,
            "grammar_ref": 5.944,
            "grammar_hyp": 5.84832,
            "nubia_score": 0.69616
        },
        "bleurt": 0.31648,
        "bertscore": {
            "precision": 0.90922,
            "recall": 0.92144,
            "f1": 0.91494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 75,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.50261,
        "nist": 7.448950542082674,
        "rouge1": {
            "precision": 0.74179,
            "recall": 0.76503,
            "fmeasure": 0.74201
        },
        "rouge2": {
            "precision": 0.53036,
            "recall": 0.56461,
            "fmeasure": 0.53808
        },
        "rougeL": {
            "precision": 0.64355,
            "recall": 0.67682,
            "fmeasure": 0.64987
        },
        "rougeLsum": {
            "precision": 0.64355,
            "recall": 0.67682,
            "fmeasure": 0.64987
        },
        "local_recall": {
            "1": 0.2641509433962264,
            "2": 0.48148148148148145,
            "3": 0.821656050955414
        },
        "meteor": 0.40954125029797306,
        "nubia": {
            "semantic_relation": 4.18126,
            "contradiction": 10.12806,
            "irrelevancy": 37.76159,
            "logical_agreement": 52.11035,
            "grammar_ref": 4.90125,
            "grammar_hyp": 4.75215,
            "nubia_score": 0.7165
        },
        "bleurt": 0.26594,
        "bertscore": {
            "precision": 0.9302,
            "recall": 0.93259,
            "f1": 0.9293
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 23,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.01294,
        "nist": 5.932225677902112,
        "rouge1": {
            "precision": 0.71916,
            "recall": 0.74697,
            "fmeasure": 0.72514
        },
        "rouge2": {
            "precision": 0.49999,
            "recall": 0.52838,
            "fmeasure": 0.50887
        },
        "rougeL": {
            "precision": 0.62587,
            "recall": 0.67231,
            "fmeasure": 0.6412
        },
        "rougeLsum": {
            "precision": 0.62587,
            "recall": 0.67231,
            "fmeasure": 0.6412
        },
        "local_recall": {
            "1": 0.24,
            "2": 0.6065573770491803,
            "3": 0.7542372881355932
        },
        "meteor": 0.3996521020179561,
        "nubia": {
            "semantic_relation": 4.26821,
            "contradiction": 5.30826,
            "irrelevancy": 37.06303,
            "logical_agreement": 57.62871,
            "grammar_ref": 4.22562,
            "grammar_hyp": 3.99488,
            "nubia_score": 0.77091
        },
        "bleurt": 0.27836,
        "bertscore": {
            "precision": 0.9181,
            "recall": 0.92234,
            "f1": 0.91844
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 24,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.19054,
        "nist": 5.703761345382617,
        "rouge1": {
            "precision": 0.772,
            "recall": 0.70771,
            "fmeasure": 0.73107
        },
        "rouge2": {
            "precision": 0.54216,
            "recall": 0.49207,
            "fmeasure": 0.51023
        },
        "rougeL": {
            "precision": 0.71943,
            "recall": 0.65529,
            "fmeasure": 0.67905
        },
        "rougeLsum": {
            "precision": 0.71943,
            "recall": 0.65529,
            "fmeasure": 0.67905
        },
        "local_recall": {
            "1": 0.1276595744680851,
            "2": 0.2558139534883721,
            "3": 0.8016877637130801
        },
        "meteor": 0.3728791899405947,
        "nubia": {
            "semantic_relation": 4.17875,
            "contradiction": 9.57451,
            "irrelevancy": 30.36698,
            "logical_agreement": 60.0585,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.70404,
            "nubia_score": 0.72291
        },
        "bleurt": 0.30054,
        "bertscore": {
            "precision": 0.93419,
            "recall": 0.92941,
            "f1": 0.93078
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 18,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.47208,
        "nist": 5.534729305066072,
        "rouge1": {
            "precision": 0.67867,
            "recall": 0.62561,
            "fmeasure": 0.62895
        },
        "rouge2": {
            "precision": 0.43836,
            "recall": 0.42021,
            "fmeasure": 0.40866
        },
        "rougeL": {
            "precision": 0.57805,
            "recall": 0.55139,
            "fmeasure": 0.5401
        },
        "rougeLsum": {
            "precision": 0.57805,
            "recall": 0.55139,
            "fmeasure": 0.5401
        },
        "local_recall": {
            "1": 0.21359223300970873,
            "2": 0.45454545454545453,
            "3": 0.6938775510204082
        },
        "meteor": 0.3430003481779342,
        "nubia": {
            "semantic_relation": 3.81684,
            "contradiction": 8.9718,
            "irrelevancy": 50.71596,
            "logical_agreement": 40.31224,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.57037,
            "nubia_score": 0.60648
        },
        "bleurt": -0.05947,
        "bertscore": {
            "precision": 0.88956,
            "recall": 0.88655,
            "f1": 0.88605
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 23,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.16389,
        "nist": 6.894215358695929,
        "rouge1": {
            "precision": 0.76474,
            "recall": 0.73926,
            "fmeasure": 0.73869
        },
        "rouge2": {
            "precision": 0.57339,
            "recall": 0.55671,
            "fmeasure": 0.55562
        },
        "rougeL": {
            "precision": 0.68108,
            "recall": 0.67112,
            "fmeasure": 0.66549
        },
        "rougeLsum": {
            "precision": 0.68108,
            "recall": 0.67112,
            "fmeasure": 0.66549
        },
        "local_recall": {
            "1": 0.3972602739726027,
            "2": 0.3488372093023256,
            "3": 0.811965811965812
        },
        "meteor": 0.41304584734995914,
        "nubia": {
            "semantic_relation": 4.34546,
            "contradiction": 3.64102,
            "irrelevancy": 28.62385,
            "logical_agreement": 67.73513,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.42532,
            "nubia_score": 0.77961
        },
        "bleurt": 0.34685,
        "bertscore": {
            "precision": 0.94233,
            "recall": 0.93229,
            "f1": 0.93477
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.16096,
        "nist": 4.16254693371727,
        "rouge1": {
            "precision": 0.74261,
            "recall": 0.72621,
            "fmeasure": 0.71826
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.48171,
            "fmeasure": 0.46723
        },
        "rougeL": {
            "precision": 0.64076,
            "recall": 0.67074,
            "fmeasure": 0.64517
        },
        "rougeLsum": {
            "precision": 0.64076,
            "recall": 0.67074,
            "fmeasure": 0.64517
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.42857142857142855,
            "3": 0.7027027027027027
        },
        "meteor": 0.35768691948593406,
        "nubia": {
            "semantic_relation": 4.05273,
            "contradiction": 26.07295,
            "irrelevancy": 35.05712,
            "logical_agreement": 38.86994,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.72826,
            "nubia_score": 0.6959
        },
        "bleurt": 0.33109,
        "bertscore": {
            "precision": 0.91775,
            "recall": 0.92524,
            "f1": 0.91762
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.8881,
        "nist": 1.7545968262860026,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "meteor": 0.309443795471007,
        "nubia": {
            "semantic_relation": 4.00332,
            "contradiction": 1.11626,
            "irrelevancy": 7.90769,
            "logical_agreement": 90.97605,
            "grammar_ref": 6.80479,
            "grammar_hyp": 6.0996,
            "nubia_score": 0.76201
        },
        "bleurt": -0.75815,
        "bertscore": {
            "precision": 0.87386,
            "recall": 0.88783,
            "f1": 0.88079
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.68742,
        "nist": 5.150371820164032,
        "rouge1": {
            "precision": 0.86325,
            "recall": 0.81543,
            "fmeasure": 0.83767
        },
        "rouge2": {
            "precision": 0.70185,
            "recall": 0.64772,
            "fmeasure": 0.6728
        },
        "rougeL": {
            "precision": 0.777,
            "recall": 0.73616,
            "fmeasure": 0.75515
        },
        "rougeLsum": {
            "precision": 0.777,
            "recall": 0.73616,
            "fmeasure": 0.75515
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.2857142857142857,
            "3": 0.8928571428571429
        },
        "meteor": 0.4517957257458094,
        "nubia": {
            "semantic_relation": 4.73477,
            "contradiction": 0.33273,
            "irrelevancy": 4.36074,
            "logical_agreement": 95.30653,
            "grammar_ref": 5.80868,
            "grammar_hyp": 5.92859,
            "nubia_score": 0.86944
        },
        "bleurt": 0.35184,
        "bertscore": {
            "precision": 0.94906,
            "recall": 0.94371,
            "f1": 0.94321
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.49813,
        "nist": 4.829209929176092,
        "rouge1": {
            "precision": 0.70563,
            "recall": 0.83916,
            "fmeasure": 0.76195
        },
        "rouge2": {
            "precision": 0.51753,
            "recall": 0.62285,
            "fmeasure": 0.5608
        },
        "rougeL": {
            "precision": 0.62169,
            "recall": 0.74371,
            "fmeasure": 0.67201
        },
        "rougeLsum": {
            "precision": 0.62169,
            "recall": 0.74371,
            "fmeasure": 0.67201
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.7,
            "3": 0.7959183673469388
        },
        "meteor": 0.3978878567030806,
        "nubia": {
            "semantic_relation": 4.00565,
            "contradiction": 8.54513,
            "irrelevancy": 33.22151,
            "logical_agreement": 58.23336,
            "grammar_ref": 5.56433,
            "grammar_hyp": 4.52353,
            "nubia_score": 0.78158
        },
        "bleurt": 0.30311,
        "bertscore": {
            "precision": 0.92879,
            "recall": 0.93518,
            "f1": 0.93165
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 11,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.12553,
        "nist": 4.922200403459204,
        "rouge1": {
            "precision": 0.70274,
            "recall": 0.72599,
            "fmeasure": 0.70432
        },
        "rouge2": {
            "precision": 0.4889,
            "recall": 0.50175,
            "fmeasure": 0.4872
        },
        "rougeL": {
            "precision": 0.62765,
            "recall": 0.64809,
            "fmeasure": 0.62789
        },
        "rougeLsum": {
            "precision": 0.62765,
            "recall": 0.64809,
            "fmeasure": 0.62789
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.41379310344827586,
            "3": 0.7634408602150538
        },
        "meteor": 0.396091272269557,
        "nubia": {
            "semantic_relation": 4.15305,
            "contradiction": 26.05904,
            "irrelevancy": 40.67079,
            "logical_agreement": 33.27017,
            "grammar_ref": 5.00152,
            "grammar_hyp": 4.89981,
            "nubia_score": 0.67253
        },
        "bleurt": 0.23497,
        "bertscore": {
            "precision": 0.91913,
            "recall": 0.92462,
            "f1": 0.91927
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 14,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.92243,
        "nist": 5.568161229195273,
        "rouge1": {
            "precision": 0.73464,
            "recall": 0.69671,
            "fmeasure": 0.70567
        },
        "rouge2": {
            "precision": 0.49391,
            "recall": 0.47913,
            "fmeasure": 0.48063
        },
        "rougeL": {
            "precision": 0.66255,
            "recall": 0.61944,
            "fmeasure": 0.63254
        },
        "rougeLsum": {
            "precision": 0.66255,
            "recall": 0.61944,
            "fmeasure": 0.63254
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.4074074074074074,
            "3": 0.6764705882352942
        },
        "meteor": 0.36751857752848033,
        "nubia": {
            "semantic_relation": 4.32365,
            "contradiction": 11.56357,
            "irrelevancy": 8.83959,
            "logical_agreement": 79.59684,
            "grammar_ref": 4.7817,
            "grammar_hyp": 4.87327,
            "nubia_score": 0.76518
        },
        "bleurt": 0.38442,
        "bertscore": {
            "precision": 0.93669,
            "recall": 0.92993,
            "f1": 0.93202
        }
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 300,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.00889,
        "nist": 8.794681549353557,
        "rouge1": {
            "precision": 0.79217,
            "recall": 0.77675,
            "fmeasure": 0.7763
        },
        "rouge2": {
            "precision": 0.57044,
            "recall": 0.55861,
            "fmeasure": 0.55812
        },
        "rougeL": {
            "precision": 0.6798,
            "recall": 0.66983,
            "fmeasure": 0.66746
        },
        "rougeLsum": {
            "precision": 0.6798,
            "recall": 0.66983,
            "fmeasure": 0.66746
        },
        "local_recall": {
            "1": 0.19486581096849476,
            "2": 0.42509603072983354,
            "3": 0.8158536585365853
        },
        "meteor": 0.4156213761085003,
        "nubia": {
            "semantic_relation": 4.42749,
            "contradiction": 4.31364,
            "irrelevancy": 23.61534,
            "logical_agreement": 72.07102,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.7978,
            "nubia_score": 0.80029
        },
        "bleurt": 0.39205,
        "bertscore": {
            "precision": 0.94114,
            "recall": 0.93859,
            "f1": 0.9387
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.79365,
        "nist": 5.032739450905187,
        "rouge1": {
            "precision": 0.78223,
            "recall": 0.74966,
            "fmeasure": 0.75866
        },
        "rouge2": {
            "precision": 0.60348,
            "recall": 0.57485,
            "fmeasure": 0.58412
        },
        "rougeL": {
            "precision": 0.74558,
            "recall": 0.69724,
            "fmeasure": 0.71327
        },
        "rougeLsum": {
            "precision": 0.74558,
            "recall": 0.69724,
            "fmeasure": 0.71327
        },
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.16666666666666666,
            "3": 0.8518518518518519
        },
        "meteor": 0.39155697525009897,
        "nubia": {
            "semantic_relation": 4.30843,
            "contradiction": 1.38923,
            "irrelevancy": 34.69607,
            "logical_agreement": 63.9147,
            "grammar_ref": 5.04309,
            "grammar_hyp": 4.90256,
            "nubia_score": 0.77143
        },
        "bleurt": 0.32149,
        "bertscore": {
            "precision": 0.9282,
            "recall": 0.92663,
            "f1": 0.92674
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 56,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.59281,
        "nist": 7.1716528986690555,
        "rouge1": {
            "precision": 0.75366,
            "recall": 0.7424,
            "fmeasure": 0.73831
        },
        "rouge2": {
            "precision": 0.53502,
            "recall": 0.52457,
            "fmeasure": 0.52272
        },
        "rougeL": {
            "precision": 0.66136,
            "recall": 0.65193,
            "fmeasure": 0.64766
        },
        "rougeLsum": {
            "precision": 0.66136,
            "recall": 0.65193,
            "fmeasure": 0.64766
        },
        "local_recall": {
            "1": 0.18518518518518517,
            "2": 0.5063291139240507,
            "3": 0.780373831775701
        },
        "meteor": 0.41125075025577573,
        "nubia": {
            "semantic_relation": 4.2393,
            "contradiction": 13.67952,
            "irrelevancy": 29.01809,
            "logical_agreement": 57.30239,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.71212,
            "nubia_score": 0.73644
        },
        "bleurt": 0.31119,
        "bertscore": {
            "precision": 0.9294,
            "recall": 0.92771,
            "f1": 0.92744
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 42,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.92006,
        "nist": 6.7435950271425815,
        "rouge1": {
            "precision": 0.76666,
            "recall": 0.80114,
            "fmeasure": 0.77574
        },
        "rouge2": {
            "precision": 0.58059,
            "recall": 0.6075,
            "fmeasure": 0.58814
        },
        "rougeL": {
            "precision": 0.66519,
            "recall": 0.69084,
            "fmeasure": 0.67071
        },
        "rougeLsum": {
            "precision": 0.66519,
            "recall": 0.69084,
            "fmeasure": 0.67071
        },
        "local_recall": {
            "1": 0.16521739130434782,
            "2": 0.5268817204301075,
            "3": 0.7995867768595041
        },
        "meteor": 0.42136831248523865,
        "nubia": {
            "semantic_relation": 4.27731,
            "contradiction": 14.48193,
            "irrelevancy": 24.73597,
            "logical_agreement": 60.78209,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.48541,
            "nubia_score": 0.75436
        },
        "bleurt": 0.3898,
        "bertscore": {
            "precision": 0.93701,
            "recall": 0.94057,
            "f1": 0.93805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 144,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.35763,
        "nist": 7.775780260961177,
        "rouge1": {
            "precision": 0.75148,
            "recall": 0.73578,
            "fmeasure": 0.72734
        },
        "rouge2": {
            "precision": 0.51951,
            "recall": 0.50742,
            "fmeasure": 0.50187
        },
        "rougeL": {
            "precision": 0.65226,
            "recall": 0.64819,
            "fmeasure": 0.63453
        },
        "rougeLsum": {
            "precision": 0.65226,
            "recall": 0.64819,
            "fmeasure": 0.63453
        },
        "local_recall": {
            "1": 0.2821011673151751,
            "2": 0.5187637969094923,
            "3": 0.7828793774319066
        },
        "meteor": 0.40886567631756576,
        "nubia": {
            "semantic_relation": 4.09734,
            "contradiction": 5.60586,
            "irrelevancy": 38.4147,
            "logical_agreement": 55.97943,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.67648,
            "nubia_score": 0.71133
        },
        "bleurt": 0.24412,
        "bertscore": {
            "precision": 0.92612,
            "recall": 0.92504,
            "f1": 0.92343
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 55,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.63215,
        "nist": 7.003160262911804,
        "rouge1": {
            "precision": 0.72483,
            "recall": 0.71867,
            "fmeasure": 0.71032
        },
        "rouge2": {
            "precision": 0.50075,
            "recall": 0.48992,
            "fmeasure": 0.48717
        },
        "rougeL": {
            "precision": 0.63156,
            "recall": 0.62579,
            "fmeasure": 0.61868
        },
        "rougeLsum": {
            "precision": 0.63156,
            "recall": 0.62579,
            "fmeasure": 0.61868
        },
        "local_recall": {
            "1": 0.29901960784313725,
            "2": 0.40437158469945356,
            "3": 0.7695167286245354
        },
        "meteor": 0.39034399160480343,
        "nubia": {
            "semantic_relation": 4.16387,
            "contradiction": 3.81,
            "irrelevancy": 35.83688,
            "logical_agreement": 60.35312,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.72953,
            "nubia_score": 0.72751
        },
        "bleurt": 0.20704,
        "bertscore": {
            "precision": 0.91918,
            "recall": 0.92076,
            "f1": 0.91842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 50,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.78818,
        "nist": 6.899002443512136,
        "rouge1": {
            "precision": 0.77928,
            "recall": 0.71182,
            "fmeasure": 0.7301
        },
        "rouge2": {
            "precision": 0.54411,
            "recall": 0.50439,
            "fmeasure": 0.51332
        },
        "rougeL": {
            "precision": 0.71166,
            "recall": 0.65868,
            "fmeasure": 0.67098
        },
        "rougeLsum": {
            "precision": 0.71166,
            "recall": 0.65868,
            "fmeasure": 0.67098
        },
        "local_recall": {
            "1": 0.18,
            "2": 0.5157232704402516,
            "3": 0.75
        },
        "meteor": 0.3793249080555262,
        "nubia": {
            "semantic_relation": 4.17859,
            "contradiction": 6.44268,
            "irrelevancy": 32.03397,
            "logical_agreement": 61.52335,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.80596,
            "nubia_score": 0.70823
        },
        "bleurt": 0.22565,
        "bertscore": {
            "precision": 0.93264,
            "recall": 0.91133,
            "f1": 0.91977
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 81,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.77427,
        "nist": 7.263465396039211,
        "rouge1": {
            "precision": 0.73568,
            "recall": 0.75528,
            "fmeasure": 0.72949
        },
        "rouge2": {
            "precision": 0.52467,
            "recall": 0.52601,
            "fmeasure": 0.51433
        },
        "rougeL": {
            "precision": 0.62632,
            "recall": 0.63419,
            "fmeasure": 0.6172
        },
        "rougeLsum": {
            "precision": 0.62632,
            "recall": 0.63419,
            "fmeasure": 0.6172
        },
        "local_recall": {
            "1": 0.26621160409556316,
            "2": 0.5387596899224806,
            "3": 0.8079625292740047
        },
        "meteor": 0.41271788119157915,
        "nubia": {
            "semantic_relation": 4.18563,
            "contradiction": 6.41132,
            "irrelevancy": 32.32746,
            "logical_agreement": 61.26121,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.50522,
            "nubia_score": 0.72597
        },
        "bleurt": 0.25195,
        "bertscore": {
            "precision": 0.92441,
            "recall": 0.93167,
            "f1": 0.92604
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 14,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.43646,
        "nist": 5.393985415500367,
        "rouge1": {
            "precision": 0.70708,
            "recall": 0.66417,
            "fmeasure": 0.6781
        },
        "rouge2": {
            "precision": 0.44646,
            "recall": 0.41058,
            "fmeasure": 0.4216
        },
        "rougeL": {
            "precision": 0.56288,
            "recall": 0.52956,
            "fmeasure": 0.53969
        },
        "rougeLsum": {
            "precision": 0.56288,
            "recall": 0.52956,
            "fmeasure": 0.53969
        },
        "local_recall": {
            "1": 0.19672131147540983,
            "2": 0.34285714285714286,
            "3": 0.7169811320754716
        },
        "meteor": 0.3487702064822465,
        "nubia": {
            "semantic_relation": 4.2082,
            "contradiction": 0.84462,
            "irrelevancy": 41.02534,
            "logical_agreement": 58.13003,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.49038,
            "nubia_score": 0.76579
        },
        "bleurt": 0.25748,
        "bertscore": {
            "precision": 0.91491,
            "recall": 0.91384,
            "f1": 0.91081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.33655,
        "nist": 2.6894521798916835,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.91667,
            "fmeasure": 0.70356
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.77381,
            "fmeasure": 0.57778
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.91667,
            "fmeasure": 0.70356
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.91667,
            "fmeasure": 0.70356
        },
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 0.3900184928779059,
        "nubia": {
            "semantic_relation": 4.74577,
            "contradiction": 3.113,
            "irrelevancy": 6.19832,
            "logical_agreement": 90.68868,
            "grammar_ref": 4.0172,
            "grammar_hyp": 3.5888,
            "nubia_score": 0.75227
        },
        "bleurt": 0.32756,
        "bertscore": {
            "precision": 0.92354,
            "recall": 0.92533,
            "f1": 0.92443
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 17,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.03044,
        "nist": 5.77920716938136,
        "rouge1": {
            "precision": 0.73582,
            "recall": 0.68705,
            "fmeasure": 0.70207
        },
        "rouge2": {
            "precision": 0.45978,
            "recall": 0.43709,
            "fmeasure": 0.4423
        },
        "rougeL": {
            "precision": 0.61953,
            "recall": 0.573,
            "fmeasure": 0.58746
        },
        "rougeLsum": {
            "precision": 0.61953,
            "recall": 0.573,
            "fmeasure": 0.58746
        },
        "local_recall": {
            "1": 0.18055555555555555,
            "2": 0.4426229508196721,
            "3": 0.7515527950310559
        },
        "meteor": 0.3884682529700972,
        "nubia": {
            "semantic_relation": 4.13093,
            "contradiction": 10.91989,
            "irrelevancy": 24.09983,
            "logical_agreement": 64.98028,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.68659,
            "nubia_score": 0.71421
        },
        "bleurt": 0.31739,
        "bertscore": {
            "precision": 0.93275,
            "recall": 0.92714,
            "f1": 0.92892
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 12,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.84614,
        "nist": 6.465874424985446,
        "rouge1": {
            "precision": 0.74899,
            "recall": 0.76714,
            "fmeasure": 0.75649
        },
        "rouge2": {
            "precision": 0.5963,
            "recall": 0.61546,
            "fmeasure": 0.60366
        },
        "rougeL": {
            "precision": 0.70929,
            "recall": 0.72395,
            "fmeasure": 0.71452
        },
        "rougeLsum": {
            "precision": 0.70929,
            "recall": 0.72395,
            "fmeasure": 0.71452
        },
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.5833333333333334,
            "3": 0.8776978417266187
        },
        "meteor": 0.4771553534361797,
        "nubia": {
            "semantic_relation": 4.01799,
            "contradiction": 15.0231,
            "irrelevancy": 36.27991,
            "logical_agreement": 48.69699,
            "grammar_ref": 4.07585,
            "grammar_hyp": 4.03957,
            "nubia_score": 0.71086
        },
        "bleurt": 0.33887,
        "bertscore": {
            "precision": 0.93249,
            "recall": 0.93777,
            "f1": 0.93495
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 31,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.7133,
        "nist": 6.159488520327608,
        "rouge1": {
            "precision": 0.7527,
            "recall": 0.6929,
            "fmeasure": 0.70779
        },
        "rouge2": {
            "precision": 0.5004,
            "recall": 0.4747,
            "fmeasure": 0.47769
        },
        "rougeL": {
            "precision": 0.63533,
            "recall": 0.5909,
            "fmeasure": 0.5999
        },
        "rougeLsum": {
            "precision": 0.63533,
            "recall": 0.5909,
            "fmeasure": 0.5999
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.4639175257731959,
            "3": 0.7651006711409396
        },
        "meteor": 0.37744285907210184,
        "nubia": {
            "semantic_relation": 4.16703,
            "contradiction": 3.85538,
            "irrelevancy": 32.30581,
            "logical_agreement": 63.83881,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.50555,
            "nubia_score": 0.72696
        },
        "bleurt": 0.26121,
        "bertscore": {
            "precision": 0.92409,
            "recall": 0.91795,
            "f1": 0.91947
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 57,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.0028,
        "nist": 6.9767023847454,
        "rouge1": {
            "precision": 0.73423,
            "recall": 0.75904,
            "fmeasure": 0.73376
        },
        "rouge2": {
            "precision": 0.5151,
            "recall": 0.53687,
            "fmeasure": 0.51515
        },
        "rougeL": {
            "precision": 0.62186,
            "recall": 0.64687,
            "fmeasure": 0.62331
        },
        "rougeLsum": {
            "precision": 0.62186,
            "recall": 0.64687,
            "fmeasure": 0.62331
        },
        "local_recall": {
            "1": 0.2119815668202765,
            "2": 0.5073170731707317,
            "3": 0.8083491461100569
        },
        "meteor": 0.41433075399777997,
        "nubia": {
            "semantic_relation": 4.16782,
            "contradiction": 9.31131,
            "irrelevancy": 35.48834,
            "logical_agreement": 55.20035,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.61892,
            "nubia_score": 0.73678
        },
        "bleurt": 0.21126,
        "bertscore": {
            "precision": 0.92095,
            "recall": 0.92767,
            "f1": 0.92158
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 11,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.44034,
        "nist": 6.1543649830712335,
        "rouge1": {
            "precision": 0.74667,
            "recall": 0.76543,
            "fmeasure": 0.74062
        },
        "rouge2": {
            "precision": 0.51671,
            "recall": 0.53492,
            "fmeasure": 0.51721
        },
        "rougeL": {
            "precision": 0.63953,
            "recall": 0.66325,
            "fmeasure": 0.63861
        },
        "rougeLsum": {
            "precision": 0.63953,
            "recall": 0.66325,
            "fmeasure": 0.63861
        },
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.5806451612903226,
            "3": 0.8152173913043478
        },
        "meteor": 0.44108691080606105,
        "nubia": {
            "semantic_relation": 4.13654,
            "contradiction": 7.94711,
            "irrelevancy": 41.613,
            "logical_agreement": 50.43989,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.43322,
            "nubia_score": 0.72288
        },
        "bleurt": 0.26252,
        "bertscore": {
            "precision": 0.93546,
            "recall": 0.94942,
            "f1": 0.94055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.21194,
        "nist": 2.415947705372627,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "meteor": 0.4235494540099438,
        "nubia": {
            "semantic_relation": 3.9393,
            "contradiction": 0.50698,
            "irrelevancy": 97.97126,
            "logical_agreement": 1.52176,
            "grammar_ref": 6.33221,
            "grammar_hyp": 5.93182,
            "nubia_score": 0.68311
        },
        "bleurt": 0.64341,
        "bertscore": {
            "precision": 0.93993,
            "recall": 0.96605,
            "f1": 0.95235
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 47,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.5214,
        "nist": 6.242797783535585,
        "rouge1": {
            "precision": 0.69381,
            "recall": 0.69147,
            "fmeasure": 0.68222
        },
        "rouge2": {
            "precision": 0.45454,
            "recall": 0.45095,
            "fmeasure": 0.44508
        },
        "rougeL": {
            "precision": 0.62883,
            "recall": 0.62122,
            "fmeasure": 0.61588
        },
        "rougeLsum": {
            "precision": 0.62883,
            "recall": 0.62122,
            "fmeasure": 0.61588
        },
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.38848920863309355,
            "3": 0.6989247311827957
        },
        "meteor": 0.3682080778291783,
        "nubia": {
            "semantic_relation": 3.90014,
            "contradiction": 17.45789,
            "irrelevancy": 25.19985,
            "logical_agreement": 57.34226,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.35442,
            "nubia_score": 0.66142
        },
        "bleurt": 0.22882,
        "bertscore": {
            "precision": 0.91669,
            "recall": 0.91422,
            "f1": 0.91382
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 11,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.51099,
        "nist": 5.629734059161767,
        "rouge1": {
            "precision": 0.74847,
            "recall": 0.76077,
            "fmeasure": 0.74846
        },
        "rouge2": {
            "precision": 0.55018,
            "recall": 0.55532,
            "fmeasure": 0.54832
        },
        "rougeL": {
            "precision": 0.60469,
            "recall": 0.60948,
            "fmeasure": 0.60113
        },
        "rougeLsum": {
            "precision": 0.60469,
            "recall": 0.60948,
            "fmeasure": 0.60113
        },
        "local_recall": {
            "1": 0.27906976744186046,
            "2": 0.47368421052631576,
            "3": 0.7794117647058824
        },
        "meteor": 0.4224214436272639,
        "nubia": {
            "semantic_relation": 4.41131,
            "contradiction": 1.50704,
            "irrelevancy": 23.53522,
            "logical_agreement": 74.95773,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.4378,
            "nubia_score": 0.80595
        },
        "bleurt": 0.23695,
        "bertscore": {
            "precision": 0.91821,
            "recall": 0.93239,
            "f1": 0.92319
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 15,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.08686,
        "nist": 5.565155576618961,
        "rouge1": {
            "precision": 0.72536,
            "recall": 0.67371,
            "fmeasure": 0.69015
        },
        "rouge2": {
            "precision": 0.457,
            "recall": 0.435,
            "fmeasure": 0.44056
        },
        "rougeL": {
            "precision": 0.60476,
            "recall": 0.56669,
            "fmeasure": 0.57891
        },
        "rougeLsum": {
            "precision": 0.60476,
            "recall": 0.56669,
            "fmeasure": 0.57891
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.2625,
            "3": 0.7660818713450293
        },
        "meteor": 0.3672118484598636,
        "nubia": {
            "semantic_relation": 4.13264,
            "contradiction": 14.76425,
            "irrelevancy": 34.04848,
            "logical_agreement": 51.18726,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.88962,
            "nubia_score": 0.67019
        },
        "bleurt": 0.12173,
        "bertscore": {
            "precision": 0.90384,
            "recall": 0.90129,
            "f1": 0.90035
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 18,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.31236,
        "nist": 6.758096576246446,
        "rouge1": {
            "precision": 0.78285,
            "recall": 0.76979,
            "fmeasure": 0.7698
        },
        "rouge2": {
            "precision": 0.57821,
            "recall": 0.56185,
            "fmeasure": 0.56296
        },
        "rougeL": {
            "precision": 0.71462,
            "recall": 0.69767,
            "fmeasure": 0.70036
        },
        "rougeLsum": {
            "precision": 0.71462,
            "recall": 0.69767,
            "fmeasure": 0.70036
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.29411764705882354,
            "3": 0.8078602620087336
        },
        "meteor": 0.42932851772919745,
        "nubia": {
            "semantic_relation": 4.29675,
            "contradiction": 4.18498,
            "irrelevancy": 29.53655,
            "logical_agreement": 66.27848,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.51563,
            "nubia_score": 0.75245
        },
        "bleurt": 0.30894,
        "bertscore": {
            "precision": 0.93631,
            "recall": 0.93609,
            "f1": 0.93565
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.64147,
        "nist": 4.744903971355807,
        "rouge1": {
            "precision": 0.71314,
            "recall": 0.734,
            "fmeasure": 0.71116
        },
        "rouge2": {
            "precision": 0.52956,
            "recall": 0.55743,
            "fmeasure": 0.53337
        },
        "rougeL": {
            "precision": 0.6014,
            "recall": 0.63872,
            "fmeasure": 0.60897
        },
        "rougeLsum": {
            "precision": 0.6014,
            "recall": 0.63872,
            "fmeasure": 0.60897
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.1,
            "3": 0.7261904761904762
        },
        "meteor": 0.3901113346505096,
        "nubia": {
            "semantic_relation": 4.2044,
            "contradiction": 12.20453,
            "irrelevancy": 33.07017,
            "logical_agreement": 54.7253,
            "grammar_ref": 5.14697,
            "grammar_hyp": 5.2654,
            "nubia_score": 0.68998
        },
        "bleurt": 0.25532,
        "bertscore": {
            "precision": 0.92574,
            "recall": 0.92961,
            "f1": 0.92592
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.31833,
        "nist": 4.493233329997827,
        "rouge1": {
            "precision": 0.59265,
            "recall": 0.49472,
            "fmeasure": 0.53041
        },
        "rouge2": {
            "precision": 0.2166,
            "recall": 0.18657,
            "fmeasure": 0.19855
        },
        "rougeL": {
            "precision": 0.5062,
            "recall": 0.39945,
            "fmeasure": 0.44132
        },
        "rougeLsum": {
            "precision": 0.5062,
            "recall": 0.39945,
            "fmeasure": 0.44132
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.2222222222222222,
            "3": 0.5974025974025974
        },
        "meteor": 0.28862595970315075,
        "nubia": {
            "semantic_relation": 3.54268,
            "contradiction": 15.30197,
            "irrelevancy": 29.36267,
            "logical_agreement": 55.33536,
            "grammar_ref": 4.85958,
            "grammar_hyp": 5.4164,
            "nubia_score": 0.48896
        },
        "bleurt": -0.15021,
        "bertscore": {
            "precision": 0.88995,
            "recall": 0.84465,
            "f1": 0.86418
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 20,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.24511,
        "nist": 5.311741119156971,
        "rouge1": {
            "precision": 0.69416,
            "recall": 0.7422,
            "fmeasure": 0.70126
        },
        "rouge2": {
            "precision": 0.4477,
            "recall": 0.46305,
            "fmeasure": 0.44692
        },
        "rougeL": {
            "precision": 0.54323,
            "recall": 0.58957,
            "fmeasure": 0.55268
        },
        "rougeLsum": {
            "precision": 0.54323,
            "recall": 0.58957,
            "fmeasure": 0.55268
        },
        "local_recall": {
            "1": 0.28,
            "2": 0.47540983606557374,
            "3": 0.7696335078534031
        },
        "meteor": 0.3804114922175242,
        "nubia": {
            "semantic_relation": 4.14145,
            "contradiction": 2.12807,
            "irrelevancy": 43.11635,
            "logical_agreement": 54.75558,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.5335,
            "nubia_score": 0.70301
        },
        "bleurt": 0.20608,
        "bertscore": {
            "precision": 0.90573,
            "recall": 0.91304,
            "f1": 0.90809
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 17,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.47649,
        "nist": 6.976098717727962,
        "rouge1": {
            "precision": 0.80265,
            "recall": 0.79082,
            "fmeasure": 0.78897
        },
        "rouge2": {
            "precision": 0.60835,
            "recall": 0.61083,
            "fmeasure": 0.60103
        },
        "rougeL": {
            "precision": 0.66052,
            "recall": 0.65308,
            "fmeasure": 0.6511
        },
        "rougeLsum": {
            "precision": 0.66052,
            "recall": 0.65308,
            "fmeasure": 0.6511
        },
        "local_recall": {
            "1": 0.19148936170212766,
            "2": 0.3157894736842105,
            "3": 0.8387096774193549
        },
        "meteor": 0.4673829625325872,
        "nubia": {
            "semantic_relation": 4.52953,
            "contradiction": 5.23778,
            "irrelevancy": 20.81722,
            "logical_agreement": 73.945,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.53599,
            "nubia_score": 0.83291
        },
        "bleurt": 0.43288,
        "bertscore": {
            "precision": 0.94263,
            "recall": 0.94546,
            "f1": 0.94323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 43,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.96813,
        "nist": 6.784974400340211,
        "rouge1": {
            "precision": 0.774,
            "recall": 0.78237,
            "fmeasure": 0.76783
        },
        "rouge2": {
            "precision": 0.58273,
            "recall": 0.58689,
            "fmeasure": 0.57756
        },
        "rougeL": {
            "precision": 0.68894,
            "recall": 0.70893,
            "fmeasure": 0.68838
        },
        "rougeLsum": {
            "precision": 0.68894,
            "recall": 0.70893,
            "fmeasure": 0.68838
        },
        "local_recall": {
            "1": 0.27586206896551724,
            "2": 0.48120300751879697,
            "3": 0.7971698113207547
        },
        "meteor": 0.40543678003000233,
        "nubia": {
            "semantic_relation": 4.24708,
            "contradiction": 7.10853,
            "irrelevancy": 36.37223,
            "logical_agreement": 56.51924,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.38657,
            "nubia_score": 0.76385
        },
        "bleurt": 0.3192,
        "bertscore": {
            "precision": 0.92982,
            "recall": 0.93276,
            "f1": 0.92896
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 14,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.12212,
        "nist": 5.229013071699831,
        "rouge1": {
            "precision": 0.66954,
            "recall": 0.73386,
            "fmeasure": 0.69251
        },
        "rouge2": {
            "precision": 0.42166,
            "recall": 0.45697,
            "fmeasure": 0.43507
        },
        "rougeL": {
            "precision": 0.55924,
            "recall": 0.60792,
            "fmeasure": 0.57598
        },
        "rougeLsum": {
            "precision": 0.55924,
            "recall": 0.60792,
            "fmeasure": 0.57598
        },
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.5384615384615384,
            "3": 0.7698412698412699
        },
        "meteor": 0.3987853925522752,
        "nubia": {
            "semantic_relation": 4.11782,
            "contradiction": 12.90183,
            "irrelevancy": 31.44651,
            "logical_agreement": 55.65166,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.48417,
            "nubia_score": 0.73824
        },
        "bleurt": 0.24919,
        "bertscore": {
            "precision": 0.90802,
            "recall": 0.92027,
            "f1": 0.91268
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 14,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.58686,
        "nist": 5.5352157585602795,
        "rouge1": {
            "precision": 0.64674,
            "recall": 0.67228,
            "fmeasure": 0.64651
        },
        "rouge2": {
            "precision": 0.40756,
            "recall": 0.41831,
            "fmeasure": 0.40334
        },
        "rougeL": {
            "precision": 0.53525,
            "recall": 0.55464,
            "fmeasure": 0.53405
        },
        "rougeLsum": {
            "precision": 0.53525,
            "recall": 0.55464,
            "fmeasure": 0.53405
        },
        "local_recall": {
            "1": 0.3220338983050847,
            "2": 0.34782608695652173,
            "3": 0.7272727272727273
        },
        "meteor": 0.370478403621887,
        "nubia": {
            "semantic_relation": 3.87998,
            "contradiction": 13.48746,
            "irrelevancy": 35.50647,
            "logical_agreement": 51.00607,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.26465,
            "nubia_score": 0.65961
        },
        "bleurt": 0.09886,
        "bertscore": {
            "precision": 0.89914,
            "recall": 0.9036,
            "f1": 0.89986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 19.83544,
        "nist": 2.6099772787902444,
        "rouge1": {
            "precision": 0.64815,
            "recall": 0.71503,
            "fmeasure": 0.67937
        },
        "rouge2": {
            "precision": 0.39216,
            "recall": 0.46667,
            "fmeasure": 0.42608
        },
        "rougeL": {
            "precision": 0.48148,
            "recall": 0.53072,
            "fmeasure": 0.50447
        },
        "rougeLsum": {
            "precision": 0.48148,
            "recall": 0.53072,
            "fmeasure": 0.50447
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.6363636363636364
        },
        "meteor": 0.32897120677969066,
        "nubia": {
            "semantic_relation": 3.59988,
            "contradiction": 97.25537,
            "irrelevancy": 2.02448,
            "logical_agreement": 0.72014,
            "grammar_ref": 5.18542,
            "grammar_hyp": 5.08689,
            "nubia_score": 0.50984
        },
        "bleurt": 0.01621,
        "bertscore": {
            "precision": 0.88159,
            "recall": 0.93244,
            "f1": 0.9063
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 40,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.24424,
        "nist": 6.867911900300786,
        "rouge1": {
            "precision": 0.78379,
            "recall": 0.73542,
            "fmeasure": 0.74198
        },
        "rouge2": {
            "precision": 0.56141,
            "recall": 0.53616,
            "fmeasure": 0.53827
        },
        "rougeL": {
            "precision": 0.70493,
            "recall": 0.66099,
            "fmeasure": 0.6666
        },
        "rougeLsum": {
            "precision": 0.70493,
            "recall": 0.66099,
            "fmeasure": 0.6666
        },
        "local_recall": {
            "1": 0.2564102564102564,
            "2": 0.3230769230769231,
            "3": 0.7659574468085106
        },
        "meteor": 0.41337881437777263,
        "nubia": {
            "semantic_relation": 4.2509,
            "contradiction": 2.96256,
            "irrelevancy": 25.13951,
            "logical_agreement": 71.89793,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.56746,
            "nubia_score": 0.75581
        },
        "bleurt": 0.3636,
        "bertscore": {
            "precision": 0.93575,
            "recall": 0.93067,
            "f1": 0.93148
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 35,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.63821,
        "nist": 6.586875115691973,
        "rouge1": {
            "precision": 0.70538,
            "recall": 0.69621,
            "fmeasure": 0.68678
        },
        "rouge2": {
            "precision": 0.46624,
            "recall": 0.45029,
            "fmeasure": 0.44903
        },
        "rougeL": {
            "precision": 0.6011,
            "recall": 0.5828,
            "fmeasure": 0.5806
        },
        "rougeLsum": {
            "precision": 0.6011,
            "recall": 0.5828,
            "fmeasure": 0.5806
        },
        "local_recall": {
            "1": 0.32989690721649484,
            "2": 0.40540540540540543,
            "3": 0.7318435754189944
        },
        "meteor": 0.36067336176020365,
        "nubia": {
            "semantic_relation": 3.97169,
            "contradiction": 7.75888,
            "irrelevancy": 38.11107,
            "logical_agreement": 54.13005,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.57574,
            "nubia_score": 0.65926
        },
        "bleurt": 0.16011,
        "bertscore": {
            "precision": 0.92051,
            "recall": 0.91282,
            "f1": 0.91565
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.81453,
        "nist": 2.7062469502387927,
        "rouge1": {
            "precision": 0.4941,
            "recall": 0.68202,
            "fmeasure": 0.55875
        },
        "rouge2": {
            "precision": 0.30158,
            "recall": 0.38288,
            "fmeasure": 0.33287
        },
        "rougeL": {
            "precision": 0.30447,
            "recall": 0.45452,
            "fmeasure": 0.3532
        },
        "rougeLsum": {
            "precision": 0.30447,
            "recall": 0.45452,
            "fmeasure": 0.3532
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.7777777777777778
        },
        "meteor": 0.36484577659966355,
        "nubia": {
            "semantic_relation": 3.86194,
            "contradiction": 0.47515,
            "irrelevancy": 81.23483,
            "logical_agreement": 18.29003,
            "grammar_ref": 4.57112,
            "grammar_hyp": 4.0202,
            "nubia_score": 0.5387
        },
        "bleurt": -0.12077,
        "bertscore": {
            "precision": 0.84867,
            "recall": 0.91449,
            "f1": 0.87974
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 32,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.31169,
        "nist": 6.909306903153852,
        "rouge1": {
            "precision": 0.77594,
            "recall": 0.77595,
            "fmeasure": 0.76782
        },
        "rouge2": {
            "precision": 0.56676,
            "recall": 0.58034,
            "fmeasure": 0.5671
        },
        "rougeL": {
            "precision": 0.65726,
            "recall": 0.67233,
            "fmeasure": 0.65745
        },
        "rougeLsum": {
            "precision": 0.65726,
            "recall": 0.67233,
            "fmeasure": 0.65745
        },
        "local_recall": {
            "1": 0.20408163265306123,
            "2": 0.3614457831325301,
            "3": 0.8494897959183674
        },
        "meteor": 0.4070757142034526,
        "nubia": {
            "semantic_relation": 4.30175,
            "contradiction": 13.22154,
            "irrelevancy": 31.86579,
            "logical_agreement": 54.91267,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.29002,
            "nubia_score": 0.77287
        },
        "bleurt": 0.34591,
        "bertscore": {
            "precision": 0.93327,
            "recall": 0.93412,
            "f1": 0.9319
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.16526,
        "nist": 4.464240946784056,
        "rouge1": {
            "precision": 0.79394,
            "recall": 0.77975,
            "fmeasure": 0.78471
        },
        "rouge2": {
            "precision": 0.49766,
            "recall": 0.48684,
            "fmeasure": 0.49071
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.52137,
            "fmeasure": 0.52588
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.52137,
            "fmeasure": 0.52588
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.8484848484848485
        },
        "meteor": 0.43280534793338904,
        "nubia": {
            "semantic_relation": 4.55179,
            "contradiction": 1.13895,
            "irrelevancy": 25.10606,
            "logical_agreement": 73.75499,
            "grammar_ref": 5.15044,
            "grammar_hyp": 5.65381,
            "nubia_score": 0.72007
        },
        "bleurt": 0.29468,
        "bertscore": {
            "precision": 0.93331,
            "recall": 0.94331,
            "f1": 0.93828
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.04736,
        "nist": 2.0321700940308065,
        "rouge1": {
            "precision": 0.44322,
            "recall": 0.4966,
            "fmeasure": 0.46573
        },
        "rouge2": {
            "precision": 0.26389,
            "recall": 0.31389,
            "fmeasure": 0.28532
        },
        "rougeL": {
            "precision": 0.41346,
            "recall": 0.46972,
            "fmeasure": 0.43748
        },
        "rougeLsum": {
            "precision": 0.41346,
            "recall": 0.46972,
            "fmeasure": 0.43748
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5454545454545454,
            "3": 0.3076923076923077
        },
        "meteor": 0.19281337291823455,
        "nubia": {
            "semantic_relation": 3.03284,
            "contradiction": 2.52544,
            "irrelevancy": 96.57455,
            "logical_agreement": 0.90001,
            "grammar_ref": 4.83168,
            "grammar_hyp": 5.43257,
            "nubia_score": 0.31051
        },
        "bleurt": -0.58441,
        "bertscore": {
            "precision": 0.82758,
            "recall": 0.84345,
            "f1": 0.83525
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 31,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.66004,
        "nist": 7.421153399115476,
        "rouge1": {
            "precision": 0.82742,
            "recall": 0.78735,
            "fmeasure": 0.79945
        },
        "rouge2": {
            "precision": 0.60722,
            "recall": 0.58055,
            "fmeasure": 0.58827
        },
        "rougeL": {
            "precision": 0.6992,
            "recall": 0.66242,
            "fmeasure": 0.6737
        },
        "rougeLsum": {
            "precision": 0.6992,
            "recall": 0.66242,
            "fmeasure": 0.6737
        },
        "local_recall": {
            "1": 0.2616822429906542,
            "2": 0.3670886075949367,
            "3": 0.8251748251748252
        },
        "meteor": 0.4349256305618487,
        "nubia": {
            "semantic_relation": 4.3018,
            "contradiction": 5.8708,
            "irrelevancy": 17.36982,
            "logical_agreement": 76.75939,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.68174,
            "nubia_score": 0.7686
        },
        "bleurt": 0.3397,
        "bertscore": {
            "precision": 0.94723,
            "recall": 0.9409,
            "f1": 0.94302
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 48,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.6571,
        "nist": 7.304038384370764,
        "rouge1": {
            "precision": 0.75797,
            "recall": 0.76893,
            "fmeasure": 0.75549
        },
        "rouge2": {
            "precision": 0.51181,
            "recall": 0.50796,
            "fmeasure": 0.50363
        },
        "rougeL": {
            "precision": 0.59489,
            "recall": 0.59764,
            "fmeasure": 0.58906
        },
        "rougeLsum": {
            "precision": 0.59489,
            "recall": 0.59764,
            "fmeasure": 0.58906
        },
        "local_recall": {
            "1": 0.21476510067114093,
            "2": 0.46875,
            "3": 0.8237623762376237
        },
        "meteor": 0.4084687798036704,
        "nubia": {
            "semantic_relation": 4.30895,
            "contradiction": 2.48653,
            "irrelevancy": 27.28153,
            "logical_agreement": 70.23194,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.76462,
            "nubia_score": 0.76824
        },
        "bleurt": 0.30633,
        "bertscore": {
            "precision": 0.92711,
            "recall": 0.93327,
            "f1": 0.92885
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 59,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.98966,
        "nist": 7.434060868510565,
        "rouge1": {
            "precision": 0.77616,
            "recall": 0.75664,
            "fmeasure": 0.75828
        },
        "rouge2": {
            "precision": 0.55092,
            "recall": 0.5417,
            "fmeasure": 0.54044
        },
        "rougeL": {
            "precision": 0.68324,
            "recall": 0.66305,
            "fmeasure": 0.66588
        },
        "rougeLsum": {
            "precision": 0.68324,
            "recall": 0.66305,
            "fmeasure": 0.66588
        },
        "local_recall": {
            "1": 0.27044025157232704,
            "2": 0.48120300751879697,
            "3": 0.8012519561815337
        },
        "meteor": 0.4126985053514815,
        "nubia": {
            "semantic_relation": 4.3704,
            "contradiction": 5.30965,
            "irrelevancy": 28.25076,
            "logical_agreement": 66.43959,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.51427,
            "nubia_score": 0.79321
        },
        "bleurt": 0.37632,
        "bertscore": {
            "precision": 0.93821,
            "recall": 0.93551,
            "f1": 0.93473
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 84.62454,
        "nist": 4.62659561422963,
        "rouge1": {
            "precision": 0.9119,
            "recall": 0.92857,
            "fmeasure": 0.9198
        },
        "rouge2": {
            "precision": 0.84758,
            "recall": 0.86378,
            "fmeasure": 0.8552
        },
        "rougeL": {
            "precision": 0.9119,
            "recall": 0.92857,
            "fmeasure": 0.9198
        },
        "rougeLsum": {
            "precision": 0.9119,
            "recall": 0.92857,
            "fmeasure": 0.9198
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9130434782608695
        },
        "meteor": 0.5980597342300946,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.72774,
            "irrelevancy": 0.64505,
            "logical_agreement": 98.62721,
            "grammar_ref": 4.84371,
            "grammar_hyp": 4.70968,
            "nubia_score": 0.98621
        },
        "bleurt": 0.87341,
        "bertscore": {
            "precision": 0.99346,
            "recall": 0.99346,
            "f1": 0.99346
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 76,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.15979,
        "nist": 7.035654680235078,
        "rouge1": {
            "precision": 0.70437,
            "recall": 0.71553,
            "fmeasure": 0.69136
        },
        "rouge2": {
            "precision": 0.44869,
            "recall": 0.46413,
            "fmeasure": 0.44494
        },
        "rougeL": {
            "precision": 0.59607,
            "recall": 0.61385,
            "fmeasure": 0.59011
        },
        "rougeLsum": {
            "precision": 0.59607,
            "recall": 0.61385,
            "fmeasure": 0.59011
        },
        "local_recall": {
            "1": 0.24749163879598662,
            "2": 0.5040650406504065,
            "3": 0.7686980609418282
        },
        "meteor": 0.38222379541432333,
        "nubia": {
            "semantic_relation": 4.10688,
            "contradiction": 6.09137,
            "irrelevancy": 39.09587,
            "logical_agreement": 54.81276,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.61085,
            "nubia_score": 0.68532
        },
        "bleurt": 0.20794,
        "bertscore": {
            "precision": 0.91827,
            "recall": 0.9213,
            "f1": 0.91806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 8.06629,
        "nist": 2.5606336388731283,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.63158,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.22222,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.42105,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.42105,
            "fmeasure": 0.44444
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6470588235294118
        },
        "meteor": 0.3130580319950328,
        "nubia": {
            "semantic_relation": 4.39782,
            "contradiction": 0.40584,
            "irrelevancy": 12.49023,
            "logical_agreement": 87.10394,
            "grammar_ref": 4.70075,
            "grammar_hyp": 5.01578,
            "nubia_score": 0.71432
        },
        "bleurt": 0.20758,
        "bertscore": {
            "precision": 0.90446,
            "recall": 0.88903,
            "f1": 0.89608
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 16,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.39286,
        "nist": 6.301621589320861,
        "rouge1": {
            "precision": 0.79518,
            "recall": 0.80126,
            "fmeasure": 0.78836
        },
        "rouge2": {
            "precision": 0.57535,
            "recall": 0.59154,
            "fmeasure": 0.57435
        },
        "rougeL": {
            "precision": 0.68047,
            "recall": 0.69179,
            "fmeasure": 0.67681
        },
        "rougeLsum": {
            "precision": 0.68047,
            "recall": 0.69179,
            "fmeasure": 0.67681
        },
        "local_recall": {
            "1": 0.13636363636363635,
            "2": 0.425,
            "3": 0.8663101604278075
        },
        "meteor": 0.4314377413285762,
        "nubia": {
            "semantic_relation": 4.46187,
            "contradiction": 1.04535,
            "irrelevancy": 23.0032,
            "logical_agreement": 75.95145,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.65977,
            "nubia_score": 0.81707
        },
        "bleurt": 0.35421,
        "bertscore": {
            "precision": 0.93977,
            "recall": 0.94628,
            "f1": 0.94033
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 18,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.15883,
        "nist": 5.896285526546464,
        "rouge1": {
            "precision": 0.67935,
            "recall": 0.73258,
            "fmeasure": 0.69327
        },
        "rouge2": {
            "precision": 0.46672,
            "recall": 0.51817,
            "fmeasure": 0.48223
        },
        "rougeL": {
            "precision": 0.58856,
            "recall": 0.61792,
            "fmeasure": 0.59391
        },
        "rougeLsum": {
            "precision": 0.58856,
            "recall": 0.61792,
            "fmeasure": 0.59391
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.5084745762711864,
            "3": 0.7950310559006211
        },
        "meteor": 0.3802734055038062,
        "nubia": {
            "semantic_relation": 4.19851,
            "contradiction": 9.50169,
            "irrelevancy": 50.42119,
            "logical_agreement": 40.07712,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.46493,
            "nubia_score": 0.73867
        },
        "bleurt": 0.22047,
        "bertscore": {
            "precision": 0.91412,
            "recall": 0.92569,
            "f1": 0.91797
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 19.62791,
        "nist": 1.085634160729733,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.5037,
            "fmeasure": 0.56607
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.21429,
            "fmeasure": 0.24127
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.38519,
            "fmeasure": 0.42967
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.38519,
            "fmeasure": 0.42967
        },
        "local_recall": {
            "1": 0,
            "2": 0.2,
            "3": 0.5555555555555556
        },
        "meteor": 0.27975593149805933,
        "nubia": {
            "semantic_relation": 3.96147,
            "contradiction": 0.06657,
            "irrelevancy": 34.01062,
            "logical_agreement": 65.92281,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.85218,
            "nubia_score": 0.58749
        },
        "bleurt": 0.14163,
        "bertscore": {
            "precision": 0.92415,
            "recall": 0.90727,
            "f1": 0.91079
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 80,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.3497,
        "nist": 6.957467445200559,
        "rouge1": {
            "precision": 0.69326,
            "recall": 0.71099,
            "fmeasure": 0.68928
        },
        "rouge2": {
            "precision": 0.45611,
            "recall": 0.47741,
            "fmeasure": 0.45658
        },
        "rougeL": {
            "precision": 0.57688,
            "recall": 0.59804,
            "fmeasure": 0.57388
        },
        "rougeLsum": {
            "precision": 0.57688,
            "recall": 0.59804,
            "fmeasure": 0.57388
        },
        "local_recall": {
            "1": 0.2457627118644068,
            "2": 0.52046783625731,
            "3": 0.7567917205692108
        },
        "meteor": 0.37421276620163235,
        "nubia": {
            "semantic_relation": 3.96304,
            "contradiction": 12.08632,
            "irrelevancy": 38.36777,
            "logical_agreement": 49.54591,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.4013,
            "nubia_score": 0.66794
        },
        "bleurt": 0.16083,
        "bertscore": {
            "precision": 0.90763,
            "recall": 0.91358,
            "f1": 0.90908
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 43,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.07681,
        "nist": 7.656624251899048,
        "rouge1": {
            "precision": 0.83077,
            "recall": 0.81241,
            "fmeasure": 0.81392
        },
        "rouge2": {
            "precision": 0.61996,
            "recall": 0.60607,
            "fmeasure": 0.60708
        },
        "rougeL": {
            "precision": 0.72079,
            "recall": 0.69976,
            "fmeasure": 0.70389
        },
        "rougeLsum": {
            "precision": 0.72079,
            "recall": 0.69976,
            "fmeasure": 0.70389
        },
        "local_recall": {
            "1": 0.2713178294573643,
            "2": 0.6810344827586207,
            "3": 0.8493449781659389
        },
        "meteor": 0.4491045101543412,
        "nubia": {
            "semantic_relation": 4.49281,
            "contradiction": 2.96569,
            "irrelevancy": 25.85148,
            "logical_agreement": 71.18284,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.50856,
            "nubia_score": 0.82076
        },
        "bleurt": 0.43564,
        "bertscore": {
            "precision": 0.94753,
            "recall": 0.94604,
            "f1": 0.94581
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 13,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 62.42251,
        "nist": 6.526271179475389,
        "rouge1": {
            "precision": 0.87253,
            "recall": 0.87983,
            "fmeasure": 0.87369
        },
        "rouge2": {
            "precision": 0.69535,
            "recall": 0.71396,
            "fmeasure": 0.70234
        },
        "rougeL": {
            "precision": 0.75892,
            "recall": 0.76811,
            "fmeasure": 0.7609
        },
        "rougeLsum": {
            "precision": 0.75892,
            "recall": 0.76811,
            "fmeasure": 0.7609
        },
        "local_recall": {
            "1": 0.07407407407407407,
            "2": 0.09090909090909091,
            "3": 0.9276315789473685
        },
        "meteor": 0.4926585818184424,
        "nubia": {
            "semantic_relation": 4.61264,
            "contradiction": 0.68045,
            "irrelevancy": 19.50754,
            "logical_agreement": 79.81201,
            "grammar_ref": 5.1809,
            "grammar_hyp": 5.18634,
            "nubia_score": 0.85571
        },
        "bleurt": 0.57725,
        "bertscore": {
            "precision": 0.95776,
            "recall": 0.96222,
            "f1": 0.95943
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.51747,
        "nist": 3.5376700436018975,
        "rouge1": {
            "precision": 0.66257,
            "recall": 0.72706,
            "fmeasure": 0.67917
        },
        "rouge2": {
            "precision": 0.46371,
            "recall": 0.51647,
            "fmeasure": 0.47653
        },
        "rougeL": {
            "precision": 0.53732,
            "recall": 0.60575,
            "fmeasure": 0.55588
        },
        "rougeLsum": {
            "precision": 0.53732,
            "recall": 0.60575,
            "fmeasure": 0.55588
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2962962962962963,
            "3": 0.7619047619047619
        },
        "meteor": 0.333480393514871,
        "nubia": {
            "semantic_relation": 4.26756,
            "contradiction": 8.49162,
            "irrelevancy": 23.4095,
            "logical_agreement": 68.09888,
            "grammar_ref": 3.91039,
            "grammar_hyp": 3.67078,
            "nubia_score": 0.78023
        },
        "bleurt": 0.20188,
        "bertscore": {
            "precision": 0.89643,
            "recall": 0.91883,
            "f1": 0.90201
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 11,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.9037,
        "nist": 5.3328437243395825,
        "rouge1": {
            "precision": 0.76524,
            "recall": 0.70569,
            "fmeasure": 0.72163
        },
        "rouge2": {
            "precision": 0.48335,
            "recall": 0.4413,
            "fmeasure": 0.45378
        },
        "rougeL": {
            "precision": 0.6642,
            "recall": 0.60278,
            "fmeasure": 0.62224
        },
        "rougeLsum": {
            "precision": 0.6642,
            "recall": 0.60278,
            "fmeasure": 0.62224
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3181818181818182,
            "3": 0.7619047619047619
        },
        "meteor": 0.401041116640861,
        "nubia": {
            "semantic_relation": 4.17757,
            "contradiction": 24.00596,
            "irrelevancy": 33.43864,
            "logical_agreement": 42.5554,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.67464,
            "nubia_score": 0.68925
        },
        "bleurt": 0.23147,
        "bertscore": {
            "precision": 0.9314,
            "recall": 0.92738,
            "f1": 0.92805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 77,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.37843,
        "nist": 7.477868771921729,
        "rouge1": {
            "precision": 0.77303,
            "recall": 0.74,
            "fmeasure": 0.74482
        },
        "rouge2": {
            "precision": 0.54773,
            "recall": 0.52071,
            "fmeasure": 0.52501
        },
        "rougeL": {
            "precision": 0.68715,
            "recall": 0.65654,
            "fmeasure": 0.66132
        },
        "rougeLsum": {
            "precision": 0.68715,
            "recall": 0.65654,
            "fmeasure": 0.66132
        },
        "local_recall": {
            "1": 0.22568093385214008,
            "2": 0.4418604651162791,
            "3": 0.788036410923277
        },
        "meteor": 0.39961721689019036,
        "nubia": {
            "semantic_relation": 4.2116,
            "contradiction": 4.46091,
            "irrelevancy": 24.8963,
            "logical_agreement": 70.64279,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.65154,
            "nubia_score": 0.73753
        },
        "bleurt": 0.31314,
        "bertscore": {
            "precision": 0.93368,
            "recall": 0.92666,
            "f1": 0.92799
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 24,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.52569,
        "nist": 6.745052134317476,
        "rouge1": {
            "precision": 0.78007,
            "recall": 0.78334,
            "fmeasure": 0.77305
        },
        "rouge2": {
            "precision": 0.53963,
            "recall": 0.53667,
            "fmeasure": 0.53132
        },
        "rougeL": {
            "precision": 0.67789,
            "recall": 0.6707,
            "fmeasure": 0.66866
        },
        "rougeLsum": {
            "precision": 0.67789,
            "recall": 0.6707,
            "fmeasure": 0.66866
        },
        "local_recall": {
            "1": 0.11607142857142858,
            "2": 0.41935483870967744,
            "3": 0.8888888888888888
        },
        "meteor": 0.42901493113155337,
        "nubia": {
            "semantic_relation": 4.20935,
            "contradiction": 6.0629,
            "irrelevancy": 32.72424,
            "logical_agreement": 61.21286,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.50927,
            "nubia_score": 0.74263
        },
        "bleurt": 0.32877,
        "bertscore": {
            "precision": 0.94097,
            "recall": 0.93519,
            "f1": 0.93597
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 483,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.45402,
        "nist": 8.912343112328061,
        "rouge1": {
            "precision": 0.74308,
            "recall": 0.74263,
            "fmeasure": 0.73384
        },
        "rouge2": {
            "precision": 0.49308,
            "recall": 0.49518,
            "fmeasure": 0.48796
        },
        "rougeL": {
            "precision": 0.60236,
            "recall": 0.60568,
            "fmeasure": 0.59623
        },
        "rougeLsum": {
            "precision": 0.60236,
            "recall": 0.60568,
            "fmeasure": 0.59623
        },
        "local_recall": {
            "1": 0.24316463059918558,
            "2": 0.44516129032258067,
            "3": 0.7784588441330998
        },
        "meteor": 0.39234204207190254,
        "nubia": {
            "semantic_relation": 4.17659,
            "contradiction": 7.49664,
            "irrelevancy": 36.69292,
            "logical_agreement": 55.81044,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.21581,
            "nubia_score": 0.73917
        },
        "bleurt": 0.21257,
        "bertscore": {
            "precision": 0.92184,
            "recall": 0.92273,
            "f1": 0.92052
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 31,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.89596,
        "nist": 5.983854432741636,
        "rouge1": {
            "precision": 0.71903,
            "recall": 0.74569,
            "fmeasure": 0.72278
        },
        "rouge2": {
            "precision": 0.4888,
            "recall": 0.51604,
            "fmeasure": 0.49483
        },
        "rougeL": {
            "precision": 0.61091,
            "recall": 0.63714,
            "fmeasure": 0.61635
        },
        "rougeLsum": {
            "precision": 0.61091,
            "recall": 0.63714,
            "fmeasure": 0.61635
        },
        "local_recall": {
            "1": 0.24050632911392406,
            "2": 0.5222222222222223,
            "3": 0.7492957746478873
        },
        "meteor": 0.38905530358515994,
        "nubia": {
            "semantic_relation": 4.10351,
            "contradiction": 8.62327,
            "irrelevancy": 36.75389,
            "logical_agreement": 54.62284,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.39886,
            "nubia_score": 0.71089
        },
        "bleurt": 0.22003,
        "bertscore": {
            "precision": 0.91376,
            "recall": 0.91915,
            "f1": 0.9152
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.92334,
        "nist": 2.527344737297572,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.76667,
            "fmeasure": 0.60409
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.30303,
            "fmeasure": 0.23111
        },
        "rougeL": {
            "precision": 0.26471,
            "recall": 0.41667,
            "fmeasure": 0.32312
        },
        "rougeLsum": {
            "precision": 0.26471,
            "recall": 0.41667,
            "fmeasure": 0.32312
        },
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.75
        },
        "meteor": 0.38788996998365866,
        "nubia": {
            "semantic_relation": 4.9637,
            "contradiction": 5.05368,
            "irrelevancy": 0.84187,
            "logical_agreement": 94.10444,
            "grammar_ref": 5.93899,
            "grammar_hyp": 4.27931,
            "nubia_score": 0.98921
        },
        "bleurt": 0.24314,
        "bertscore": {
            "precision": 0.87909,
            "recall": 0.90372,
            "f1": 0.89123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.97245,
        "nist": 4.620571782404516,
        "rouge1": {
            "precision": 0.7104,
            "recall": 0.7308,
            "fmeasure": 0.69494
        },
        "rouge2": {
            "precision": 0.54766,
            "recall": 0.55283,
            "fmeasure": 0.5291
        },
        "rougeL": {
            "precision": 0.62326,
            "recall": 0.63724,
            "fmeasure": 0.60624
        },
        "rougeLsum": {
            "precision": 0.62326,
            "recall": 0.63724,
            "fmeasure": 0.60624
        },
        "local_recall": {
            "1": 0.5294117647058824,
            "2": 0.4482758620689655,
            "3": 0.7627118644067796
        },
        "meteor": 0.35270204654873766,
        "nubia": {
            "semantic_relation": 4.29633,
            "contradiction": 4.66284,
            "irrelevancy": 33.31252,
            "logical_agreement": 62.02464,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.30251,
            "nubia_score": 0.78777
        },
        "bleurt": 0.31246,
        "bertscore": {
            "precision": 0.9148,
            "recall": 0.91593,
            "f1": 0.91415
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 18,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.13291,
        "nist": 6.038686535622358,
        "rouge1": {
            "precision": 0.73325,
            "recall": 0.70104,
            "fmeasure": 0.70548
        },
        "rouge2": {
            "precision": 0.52123,
            "recall": 0.50567,
            "fmeasure": 0.50159
        },
        "rougeL": {
            "precision": 0.60953,
            "recall": 0.60194,
            "fmeasure": 0.59448
        },
        "rougeLsum": {
            "precision": 0.60953,
            "recall": 0.60194,
            "fmeasure": 0.59448
        },
        "local_recall": {
            "1": 0.34444444444444444,
            "2": 0.3,
            "3": 0.7171717171717171
        },
        "meteor": 0.3935814419032343,
        "nubia": {
            "semantic_relation": 3.90577,
            "contradiction": 25.73824,
            "irrelevancy": 27.33113,
            "logical_agreement": 46.93063,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.31759,
            "nubia_score": 0.65088
        },
        "bleurt": 0.10876,
        "bertscore": {
            "precision": 0.91884,
            "recall": 0.91442,
            "f1": 0.91249
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 29,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.18382,
        "nist": 6.328927348584011,
        "rouge1": {
            "precision": 0.75398,
            "recall": 0.76295,
            "fmeasure": 0.74751
        },
        "rouge2": {
            "precision": 0.51082,
            "recall": 0.51733,
            "fmeasure": 0.50704
        },
        "rougeL": {
            "precision": 0.65313,
            "recall": 0.66381,
            "fmeasure": 0.64912
        },
        "rougeLsum": {
            "precision": 0.65313,
            "recall": 0.66381,
            "fmeasure": 0.64912
        },
        "local_recall": {
            "1": 0.21359223300970873,
            "2": 0.43023255813953487,
            "3": 0.7781456953642384
        },
        "meteor": 0.3888577953833728,
        "nubia": {
            "semantic_relation": 4.27787,
            "contradiction": 5.30922,
            "irrelevancy": 30.63458,
            "logical_agreement": 64.0562,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.47598,
            "nubia_score": 0.76903
        },
        "bleurt": 0.34755,
        "bertscore": {
            "precision": 0.92976,
            "recall": 0.93377,
            "f1": 0.9304
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 23,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.49458,
        "nist": 6.275008601812667,
        "rouge1": {
            "precision": 0.74852,
            "recall": 0.73852,
            "fmeasure": 0.73726
        },
        "rouge2": {
            "precision": 0.52375,
            "recall": 0.51573,
            "fmeasure": 0.51584
        },
        "rougeL": {
            "precision": 0.65662,
            "recall": 0.64468,
            "fmeasure": 0.64417
        },
        "rougeLsum": {
            "precision": 0.65662,
            "recall": 0.64468,
            "fmeasure": 0.64417
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5797101449275363,
            "3": 0.793859649122807
        },
        "meteor": 0.4054882604615004,
        "nubia": {
            "semantic_relation": 4.17442,
            "contradiction": 5.10844,
            "irrelevancy": 36.5927,
            "logical_agreement": 58.29886,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.63098,
            "nubia_score": 0.75569
        },
        "bleurt": 0.25682,
        "bertscore": {
            "precision": 0.93119,
            "recall": 0.92839,
            "f1": 0.92916
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 11,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.39307,
        "nist": 4.112043465904497,
        "rouge1": {
            "precision": 0.61652,
            "recall": 0.64419,
            "fmeasure": 0.6158
        },
        "rouge2": {
            "precision": 0.35025,
            "recall": 0.33929,
            "fmeasure": 0.33387
        },
        "rougeL": {
            "precision": 0.47396,
            "recall": 0.48029,
            "fmeasure": 0.46494
        },
        "rougeLsum": {
            "precision": 0.47396,
            "recall": 0.48029,
            "fmeasure": 0.46494
        },
        "local_recall": {
            "1": 0.08108108108108109,
            "2": 0.55,
            "3": 0.6890756302521008
        },
        "meteor": 0.3131557553337825,
        "nubia": {
            "semantic_relation": 3.62686,
            "contradiction": 18.19894,
            "irrelevancy": 24.1286,
            "logical_agreement": 57.67247,
            "grammar_ref": 4.70623,
            "grammar_hyp": 4.7916,
            "nubia_score": 0.58218
        },
        "bleurt": 0.02336,
        "bertscore": {
            "precision": 0.8868,
            "recall": 0.89178,
            "f1": 0.88624
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 105,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.90878,
        "nist": 6.399897279994089,
        "rouge1": {
            "precision": 0.63388,
            "recall": 0.60981,
            "fmeasure": 0.60015
        },
        "rouge2": {
            "precision": 0.40227,
            "recall": 0.38991,
            "fmeasure": 0.38035
        },
        "rougeL": {
            "precision": 0.54133,
            "recall": 0.52577,
            "fmeasure": 0.51405
        },
        "rougeLsum": {
            "precision": 0.54133,
            "recall": 0.52577,
            "fmeasure": 0.51405
        },
        "local_recall": {
            "1": 0.2254335260115607,
            "2": 0.3653250773993808,
            "3": 0.6935483870967742
        },
        "meteor": 0.34143961534335276,
        "nubia": {
            "semantic_relation": 3.56444,
            "contradiction": 15.44893,
            "irrelevancy": 34.82376,
            "logical_agreement": 49.72731,
            "grammar_ref": 4.94529,
            "grammar_hyp": 4.82312,
            "nubia_score": 0.60685
        },
        "bleurt": 0.08217,
        "bertscore": {
            "precision": 0.8923,
            "recall": 0.8885,
            "f1": 0.88872
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 23,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.78268,
        "nist": 6.302666413912307,
        "rouge1": {
            "precision": 0.74561,
            "recall": 0.74788,
            "fmeasure": 0.73294
        },
        "rouge2": {
            "precision": 0.51437,
            "recall": 0.52275,
            "fmeasure": 0.50839
        },
        "rougeL": {
            "precision": 0.64579,
            "recall": 0.65716,
            "fmeasure": 0.6384
        },
        "rougeLsum": {
            "precision": 0.64579,
            "recall": 0.65716,
            "fmeasure": 0.6384
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.3614457831325301,
            "3": 0.7777777777777778
        },
        "meteor": 0.3933904602475942,
        "nubia": {
            "semantic_relation": 4.15983,
            "contradiction": 2.18194,
            "irrelevancy": 41.38927,
            "logical_agreement": 56.42879,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.35682,
            "nubia_score": 0.72849
        },
        "bleurt": 0.21371,
        "bertscore": {
            "precision": 0.91969,
            "recall": 0.92216,
            "f1": 0.91833
        }
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 300,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.62614,
        "nist": 8.720651481025127,
        "rouge1": {
            "precision": 0.78099,
            "recall": 0.77276,
            "fmeasure": 0.76922
        },
        "rouge2": {
            "precision": 0.53403,
            "recall": 0.52722,
            "fmeasure": 0.52476
        },
        "rougeL": {
            "precision": 0.65655,
            "recall": 0.64853,
            "fmeasure": 0.64565
        },
        "rougeLsum": {
            "precision": 0.65655,
            "recall": 0.64853,
            "fmeasure": 0.64565
        },
        "local_recall": {
            "1": 0.20317820658342792,
            "2": 0.3714689265536723,
            "3": 0.8131094257854822
        },
        "meteor": 0.4097528324178954,
        "nubia": {
            "semantic_relation": 4.43762,
            "contradiction": 3.89589,
            "irrelevancy": 25.31237,
            "logical_agreement": 70.79174,
            "grammar_ref": 4.91577,
            "grammar_hyp": 4.85883,
            "nubia_score": 0.78887
        },
        "bleurt": 0.34471,
        "bertscore": {
            "precision": 0.93602,
            "recall": 0.93633,
            "f1": 0.93484
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 17,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.44836,
        "nist": 6.518596116017499,
        "rouge1": {
            "precision": 0.79077,
            "recall": 0.7987,
            "fmeasure": 0.78498
        },
        "rouge2": {
            "precision": 0.55321,
            "recall": 0.56365,
            "fmeasure": 0.55019
        },
        "rougeL": {
            "precision": 0.67994,
            "recall": 0.67928,
            "fmeasure": 0.67078
        },
        "rougeLsum": {
            "precision": 0.67994,
            "recall": 0.67928,
            "fmeasure": 0.67078
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.8254716981132075
        },
        "meteor": 0.4289760755676351,
        "nubia": {
            "semantic_relation": 4.4122,
            "contradiction": 2.97834,
            "irrelevancy": 35.45742,
            "logical_agreement": 61.56424,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.69364,
            "nubia_score": 0.76728
        },
        "bleurt": 0.32559,
        "bertscore": {
            "precision": 0.93826,
            "recall": 0.9344,
            "f1": 0.93267
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 19,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.08185,
        "nist": 5.940617699968596,
        "rouge1": {
            "precision": 0.7496,
            "recall": 0.67831,
            "fmeasure": 0.69953
        },
        "rouge2": {
            "precision": 0.53732,
            "recall": 0.50123,
            "fmeasure": 0.50974
        },
        "rougeL": {
            "precision": 0.65262,
            "recall": 0.59974,
            "fmeasure": 0.61504
        },
        "rougeLsum": {
            "precision": 0.65262,
            "recall": 0.59974,
            "fmeasure": 0.61504
        },
        "local_recall": {
            "1": 0.23376623376623376,
            "2": 0.37254901960784315,
            "3": 0.6810344827586207
        },
        "meteor": 0.37764075586504026,
        "nubia": {
            "semantic_relation": 4.04787,
            "contradiction": 10.51013,
            "irrelevancy": 25.17838,
            "logical_agreement": 64.31149,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.44137,
            "nubia_score": 0.69756
        },
        "bleurt": 0.21726,
        "bertscore": {
            "precision": 0.9254,
            "recall": 0.90815,
            "f1": 0.91476
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 11,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.58366,
        "nist": 6.246611010609693,
        "rouge1": {
            "precision": 0.79453,
            "recall": 0.82966,
            "fmeasure": 0.80111
        },
        "rouge2": {
            "precision": 0.61307,
            "recall": 0.64053,
            "fmeasure": 0.61775
        },
        "rougeL": {
            "precision": 0.73387,
            "recall": 0.75514,
            "fmeasure": 0.7349
        },
        "rougeLsum": {
            "precision": 0.73387,
            "recall": 0.75514,
            "fmeasure": 0.7349
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.47368421052631576,
            "3": 0.8428571428571429
        },
        "meteor": 0.4747063035032487,
        "nubia": {
            "semantic_relation": 4.29353,
            "contradiction": 8.83204,
            "irrelevancy": 39.76781,
            "logical_agreement": 51.40015,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.21261,
            "nubia_score": 0.78368
        },
        "bleurt": 0.31163,
        "bertscore": {
            "precision": 0.92776,
            "recall": 0.93742,
            "f1": 0.93059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 10,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.10814,
        "nist": 4.677266142484378,
        "rouge1": {
            "precision": 0.63353,
            "recall": 0.69147,
            "fmeasure": 0.65263
        },
        "rouge2": {
            "precision": 0.3622,
            "recall": 0.37352,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.48007,
            "recall": 0.51473,
            "fmeasure": 0.4909
        },
        "rougeLsum": {
            "precision": 0.48007,
            "recall": 0.51473,
            "fmeasure": 0.4909
        },
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.5263157894736842,
            "3": 0.7821782178217822
        },
        "meteor": 0.37435115900841504,
        "nubia": {
            "semantic_relation": 4.14034,
            "contradiction": 18.85233,
            "irrelevancy": 18.54167,
            "logical_agreement": 62.606,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.68346,
            "nubia_score": 0.73808
        },
        "bleurt": 0.24724,
        "bertscore": {
            "precision": 0.9017,
            "recall": 0.90777,
            "f1": 0.90316
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.74184,
        "nist": 5.3880034025086525,
        "rouge1": {
            "precision": 0.80526,
            "recall": 0.76944,
            "fmeasure": 0.78603
        },
        "rouge2": {
            "precision": 0.63545,
            "recall": 0.62133,
            "fmeasure": 0.62771
        },
        "rougeL": {
            "precision": 0.71567,
            "recall": 0.689,
            "fmeasure": 0.70139
        },
        "rougeLsum": {
            "precision": 0.71567,
            "recall": 0.689,
            "fmeasure": 0.70139
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.6,
            "3": 0.7678571428571429
        },
        "meteor": 0.3970344680424182,
        "nubia": {
            "semantic_relation": 4.63644,
            "contradiction": 0.4361,
            "irrelevancy": 17.47258,
            "logical_agreement": 82.09133,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.49063,
            "nubia_score": 0.88918
        },
        "bleurt": 0.48821,
        "bertscore": {
            "precision": 0.95477,
            "recall": 0.94441,
            "f1": 0.94927
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 16,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.83059,
        "nist": 6.14772206874567,
        "rouge1": {
            "precision": 0.77556,
            "recall": 0.8153,
            "fmeasure": 0.78962
        },
        "rouge2": {
            "precision": 0.55954,
            "recall": 0.58975,
            "fmeasure": 0.5708
        },
        "rougeL": {
            "precision": 0.67751,
            "recall": 0.70454,
            "fmeasure": 0.68703
        },
        "rougeLsum": {
            "precision": 0.67751,
            "recall": 0.70454,
            "fmeasure": 0.68703
        },
        "local_recall": {
            "1": 0.2926829268292683,
            "2": 0.43478260869565216,
            "3": 0.8536585365853658
        },
        "meteor": 0.4350663743490825,
        "nubia": {
            "semantic_relation": 4.54505,
            "contradiction": 5.48627,
            "irrelevancy": 29.89711,
            "logical_agreement": 64.61662,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.45501,
            "nubia_score": 0.83391
        },
        "bleurt": 0.438,
        "bertscore": {
            "precision": 0.93066,
            "recall": 0.94368,
            "f1": 0.93538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 9,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.43082,
        "nist": 5.471609162742357,
        "rouge1": {
            "precision": 0.74084,
            "recall": 0.79491,
            "fmeasure": 0.76222
        },
        "rouge2": {
            "precision": 0.50814,
            "recall": 0.55072,
            "fmeasure": 0.52491
        },
        "rougeL": {
            "precision": 0.63014,
            "recall": 0.68095,
            "fmeasure": 0.65066
        },
        "rougeLsum": {
            "precision": 0.63014,
            "recall": 0.68095,
            "fmeasure": 0.65066
        },
        "local_recall": {
            "1": 0.4090909090909091,
            "2": 0.3125,
            "3": 0.808695652173913
        },
        "meteor": 0.4021222592058851,
        "nubia": {
            "semantic_relation": 4.46547,
            "contradiction": 7.13833,
            "irrelevancy": 22.03513,
            "logical_agreement": 70.82654,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.44692,
            "nubia_score": 0.82742
        },
        "bleurt": 0.31454,
        "bertscore": {
            "precision": 0.92816,
            "recall": 0.93452,
            "f1": 0.93099
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 12,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.86419,
        "nist": 5.543023786922077,
        "rouge1": {
            "precision": 0.73245,
            "recall": 0.69357,
            "fmeasure": 0.70174
        },
        "rouge2": {
            "precision": 0.55688,
            "recall": 0.5305,
            "fmeasure": 0.53535
        },
        "rougeL": {
            "precision": 0.62969,
            "recall": 0.59864,
            "fmeasure": 0.60442
        },
        "rougeLsum": {
            "precision": 0.62969,
            "recall": 0.59864,
            "fmeasure": 0.60442
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.41935483870967744,
            "3": 0.7022900763358778
        },
        "meteor": 0.37478603748559536,
        "nubia": {
            "semantic_relation": 3.85517,
            "contradiction": 6.43262,
            "irrelevancy": 39.78609,
            "logical_agreement": 53.78129,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.40061,
            "nubia_score": 0.64883
        },
        "bleurt": 0.12892,
        "bertscore": {
            "precision": 0.9275,
            "recall": 0.91728,
            "f1": 0.92155
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.1627,
        "nist": 2.1987287446889794,
        "rouge1": {
            "precision": 0.56,
            "recall": 0.5,
            "fmeasure": 0.5283
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2963,
            "fmeasure": 0.31373
        },
        "rougeL": {
            "precision": 0.44,
            "recall": 0.39286,
            "fmeasure": 0.41509
        },
        "rougeLsum": {
            "precision": 0.44,
            "recall": 0.39286,
            "fmeasure": 0.41509
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.8888888888888888
        },
        "meteor": 0.3062031761164262,
        "nubia": {
            "semantic_relation": 3.25049,
            "contradiction": 1.71292,
            "irrelevancy": 1.69935,
            "logical_agreement": 96.58773,
            "grammar_ref": 3.99891,
            "grammar_hyp": 3.8663,
            "nubia_score": 0.53798
        },
        "bleurt": -0.10083,
        "bertscore": {
            "precision": 0.86369,
            "recall": 0.88674,
            "f1": 0.87097
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 44,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.58914,
        "nist": 6.793934311614559,
        "rouge1": {
            "precision": 0.7596,
            "recall": 0.78276,
            "fmeasure": 0.76125
        },
        "rouge2": {
            "precision": 0.53208,
            "recall": 0.55567,
            "fmeasure": 0.5368
        },
        "rougeL": {
            "precision": 0.67248,
            "recall": 0.69287,
            "fmeasure": 0.67326
        },
        "rougeLsum": {
            "precision": 0.67248,
            "recall": 0.69287,
            "fmeasure": 0.67326
        },
        "local_recall": {
            "1": 0.21782178217821782,
            "2": 0.536,
            "3": 0.8099352051835853
        },
        "meteor": 0.4190271705467395,
        "nubia": {
            "semantic_relation": 4.29354,
            "contradiction": 5.78124,
            "irrelevancy": 28.98661,
            "logical_agreement": 65.23214,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.58952,
            "nubia_score": 0.75957
        },
        "bleurt": 0.3483,
        "bertscore": {
            "precision": 0.92762,
            "recall": 0.93283,
            "f1": 0.92951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 36,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.66633,
        "nist": 6.270087317258938,
        "rouge1": {
            "precision": 0.70754,
            "recall": 0.78552,
            "fmeasure": 0.73372
        },
        "rouge2": {
            "precision": 0.50889,
            "recall": 0.57415,
            "fmeasure": 0.52987
        },
        "rougeL": {
            "precision": 0.60946,
            "recall": 0.68433,
            "fmeasure": 0.63421
        },
        "rougeLsum": {
            "precision": 0.60946,
            "recall": 0.68433,
            "fmeasure": 0.63421
        },
        "local_recall": {
            "1": 0.19135802469135801,
            "2": 0.6694915254237288,
            "3": 0.796923076923077
        },
        "meteor": 0.42063512788412344,
        "nubia": {
            "semantic_relation": 4.22191,
            "contradiction": 3.27233,
            "irrelevancy": 47.95751,
            "logical_agreement": 48.77016,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.2856,
            "nubia_score": 0.73823
        },
        "bleurt": 0.25183,
        "bertscore": {
            "precision": 0.92056,
            "recall": 0.93694,
            "f1": 0.92746
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 29,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.32568,
        "nist": 7.4641283409871955,
        "rouge1": {
            "precision": 0.83071,
            "recall": 0.80053,
            "fmeasure": 0.80986
        },
        "rouge2": {
            "precision": 0.63501,
            "recall": 0.61163,
            "fmeasure": 0.61818
        },
        "rougeL": {
            "precision": 0.71916,
            "recall": 0.69042,
            "fmeasure": 0.69927
        },
        "rougeLsum": {
            "precision": 0.71916,
            "recall": 0.69042,
            "fmeasure": 0.69927
        },
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.4489795918367347,
            "3": 0.817910447761194
        },
        "meteor": 0.45155867944842243,
        "nubia": {
            "semantic_relation": 4.5935,
            "contradiction": 3.28075,
            "irrelevancy": 21.87013,
            "logical_agreement": 74.84912,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.58109,
            "nubia_score": 0.85303
        },
        "bleurt": 0.46722,
        "bertscore": {
            "precision": 0.95606,
            "recall": 0.94584,
            "f1": 0.95012
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 10,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.56241,
        "nist": 6.257968622358169,
        "rouge1": {
            "precision": 0.79017,
            "recall": 0.80308,
            "fmeasure": 0.78607
        },
        "rouge2": {
            "precision": 0.54089,
            "recall": 0.55609,
            "fmeasure": 0.54013
        },
        "rougeL": {
            "precision": 0.6891,
            "recall": 0.70649,
            "fmeasure": 0.68855
        },
        "rougeLsum": {
            "precision": 0.6891,
            "recall": 0.70649,
            "fmeasure": 0.68855
        },
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.5806451612903226,
            "3": 0.8877551020408163
        },
        "meteor": 0.44866553731291253,
        "nubia": {
            "semantic_relation": 4.37456,
            "contradiction": 6.53545,
            "irrelevancy": 36.30691,
            "logical_agreement": 57.15764,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.37275,
            "nubia_score": 0.80737
        },
        "bleurt": 0.36183,
        "bertscore": {
            "precision": 0.93745,
            "recall": 0.9402,
            "f1": 0.93713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 9,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.35504,
        "nist": 5.010873635257346,
        "rouge1": {
            "precision": 0.71157,
            "recall": 0.73237,
            "fmeasure": 0.71567
        },
        "rouge2": {
            "precision": 0.46039,
            "recall": 0.48488,
            "fmeasure": 0.46662
        },
        "rougeL": {
            "precision": 0.61898,
            "recall": 0.66419,
            "fmeasure": 0.63227
        },
        "rougeLsum": {
            "precision": 0.61898,
            "recall": 0.66419,
            "fmeasure": 0.63227
        },
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.5454545454545454,
            "3": 0.8059701492537313
        },
        "meteor": 0.36142233535073953,
        "nubia": {
            "semantic_relation": 4.24223,
            "contradiction": 2.22873,
            "irrelevancy": 32.28828,
            "logical_agreement": 65.48299,
            "grammar_ref": 5.14381,
            "grammar_hyp": 4.83323,
            "nubia_score": 0.74567
        },
        "bleurt": 0.2939,
        "bertscore": {
            "precision": 0.91843,
            "recall": 0.9274,
            "f1": 0.92225
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 9,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.18857,
        "nist": 4.193353013593426,
        "rouge1": {
            "precision": 0.73428,
            "recall": 0.671,
            "fmeasure": 0.68563
        },
        "rouge2": {
            "precision": 0.47015,
            "recall": 0.45765,
            "fmeasure": 0.45243
        },
        "rougeL": {
            "precision": 0.67267,
            "recall": 0.62712,
            "fmeasure": 0.63435
        },
        "rougeLsum": {
            "precision": 0.67267,
            "recall": 0.62712,
            "fmeasure": 0.63435
        },
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.42857142857142855,
            "3": 0.6623376623376623
        },
        "meteor": 0.34589184035505155,
        "nubia": {
            "semantic_relation": 4.12768,
            "contradiction": 11.90102,
            "irrelevancy": 22.73965,
            "logical_agreement": 65.35933,
            "grammar_ref": 5.16318,
            "grammar_hyp": 5.20681,
            "nubia_score": 0.6819
        },
        "bleurt": 0.31669,
        "bertscore": {
            "precision": 0.93145,
            "recall": 0.91313,
            "f1": 0.92128
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 14,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.30636,
        "nist": 5.304794550190755,
        "rouge1": {
            "precision": 0.77171,
            "recall": 0.71545,
            "fmeasure": 0.72651
        },
        "rouge2": {
            "precision": 0.51622,
            "recall": 0.50654,
            "fmeasure": 0.49657
        },
        "rougeL": {
            "precision": 0.68967,
            "recall": 0.66407,
            "fmeasure": 0.65511
        },
        "rougeLsum": {
            "precision": 0.68967,
            "recall": 0.66407,
            "fmeasure": 0.65511
        },
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.43333333333333335,
            "3": 0.71875
        },
        "meteor": 0.40032979141220243,
        "nubia": {
            "semantic_relation": 4.23908,
            "contradiction": 5.51995,
            "irrelevancy": 26.2442,
            "logical_agreement": 68.23585,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.44998,
            "nubia_score": 0.73923
        },
        "bleurt": 0.3135,
        "bertscore": {
            "precision": 0.93294,
            "recall": 0.92204,
            "f1": 0.92623
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.22643,
        "nist": 3.619110733188948,
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.64815,
            "fmeasure": 0.671
        },
        "rouge2": {
            "precision": 0.50196,
            "recall": 0.45192,
            "fmeasure": 0.4721
        },
        "rougeL": {
            "precision": 0.56566,
            "recall": 0.51689,
            "fmeasure": 0.53704
        },
        "rougeLsum": {
            "precision": 0.56566,
            "recall": 0.51689,
            "fmeasure": 0.53704
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.25,
            "3": 0.7777777777777778
        },
        "meteor": 0.28603991022380243,
        "nubia": {
            "semantic_relation": 4.24236,
            "contradiction": 0.31902,
            "irrelevancy": 49.91535,
            "logical_agreement": 49.76562,
            "grammar_ref": 4.99819,
            "grammar_hyp": 4.87608,
            "nubia_score": 0.74683
        },
        "bleurt": 0.27531,
        "bertscore": {
            "precision": 0.89062,
            "recall": 0.89319,
            "f1": 0.88966
        }
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 128,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.7282,
        "nist": 7.616079036171677,
        "rouge1": {
            "precision": 0.79746,
            "recall": 0.7675,
            "fmeasure": 0.77284
        },
        "rouge2": {
            "precision": 0.54465,
            "recall": 0.53447,
            "fmeasure": 0.5327
        },
        "rougeL": {
            "precision": 0.68768,
            "recall": 0.66789,
            "fmeasure": 0.66877
        },
        "rougeLsum": {
            "precision": 0.68768,
            "recall": 0.66789,
            "fmeasure": 0.66877
        },
        "local_recall": {
            "1": 0.1606060606060606,
            "2": 0.31893687707641194,
            "3": 0.7921462423832092
        },
        "meteor": 0.398663660068901,
        "nubia": {
            "semantic_relation": 4.39033,
            "contradiction": 5.60025,
            "irrelevancy": 27.62361,
            "logical_agreement": 66.77614,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.21416,
            "nubia_score": 0.81244
        },
        "bleurt": 0.34807,
        "bertscore": {
            "precision": 0.93573,
            "recall": 0.93524,
            "f1": 0.93368
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 13,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.55858,
        "nist": 5.44128881184872,
        "rouge1": {
            "precision": 0.72186,
            "recall": 0.72643,
            "fmeasure": 0.7198
        },
        "rouge2": {
            "precision": 0.53083,
            "recall": 0.54308,
            "fmeasure": 0.53388
        },
        "rougeL": {
            "precision": 0.58964,
            "recall": 0.59505,
            "fmeasure": 0.58904
        },
        "rougeLsum": {
            "precision": 0.58964,
            "recall": 0.59505,
            "fmeasure": 0.58904
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.11764705882352941,
            "3": 0.7973856209150327
        },
        "meteor": 0.4088477623771156,
        "nubia": {
            "semantic_relation": 4.29693,
            "contradiction": 1.66122,
            "irrelevancy": 25.17317,
            "logical_agreement": 73.16561,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.64664,
            "nubia_score": 0.77681
        },
        "bleurt": 0.41127,
        "bertscore": {
            "precision": 0.93192,
            "recall": 0.9282,
            "f1": 0.92943
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.79434,
        "nist": 3.1120330959208617,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.54278,
            "fmeasure": 0.58084
        },
        "rouge2": {
            "precision": 0.17391,
            "recall": 0.18462,
            "fmeasure": 0.17845
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.39804,
            "fmeasure": 0.42595
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.39804,
            "fmeasure": 0.42595
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.7222222222222222
        },
        "meteor": 0.26011598374899364,
        "nubia": {
            "semantic_relation": 4.00027,
            "contradiction": 0.2231,
            "irrelevancy": 92.70327,
            "logical_agreement": 7.07363,
            "grammar_ref": 3.87789,
            "grammar_hyp": 3.1707,
            "nubia_score": 0.79109
        },
        "bleurt": -0.10872,
        "bertscore": {
            "precision": 0.90633,
            "recall": 0.87586,
            "f1": 0.89083
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 122,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.22599,
        "nist": 7.41106750988786,
        "rouge1": {
            "precision": 0.74417,
            "recall": 0.71876,
            "fmeasure": 0.71951
        },
        "rouge2": {
            "precision": 0.49815,
            "recall": 0.47599,
            "fmeasure": 0.47801
        },
        "rougeL": {
            "precision": 0.6278,
            "recall": 0.59628,
            "fmeasure": 0.60107
        },
        "rougeLsum": {
            "precision": 0.6278,
            "recall": 0.59628,
            "fmeasure": 0.60107
        },
        "local_recall": {
            "1": 0.19325842696629214,
            "2": 0.3887240356083086,
            "3": 0.7594374537379719
        },
        "meteor": 0.3802026032755671,
        "nubia": {
            "semantic_relation": 4.17685,
            "contradiction": 6.43954,
            "irrelevancy": 28.93884,
            "logical_agreement": 64.62161,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.7227,
            "nubia_score": 0.71011
        },
        "bleurt": 0.22875,
        "bertscore": {
            "precision": 0.92165,
            "recall": 0.91757,
            "f1": 0.91779
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 80.04504,
        "nist": 5.9501276184215355,
        "rouge1": {
            "precision": 0.84381,
            "recall": 0.94174,
            "fmeasure": 0.88333
        },
        "rouge2": {
            "precision": 0.74063,
            "recall": 0.82947,
            "fmeasure": 0.77552
        },
        "rougeL": {
            "precision": 0.7761,
            "recall": 0.87265,
            "fmeasure": 0.81322
        },
        "rougeLsum": {
            "precision": 0.7761,
            "recall": 0.87265,
            "fmeasure": 0.81322
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.8181818181818182,
            "3": 1.0
        },
        "meteor": 0.5657433968363852,
        "nubia": {
            "semantic_relation": 4.58213,
            "contradiction": 1.0996,
            "irrelevancy": 40.9749,
            "logical_agreement": 57.9255,
            "grammar_ref": 4.43427,
            "grammar_hyp": 3.94932,
            "nubia_score": 0.88067
        },
        "bleurt": 0.5997,
        "bertscore": {
            "precision": 0.96926,
            "recall": 0.98251,
            "f1": 0.97455
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.11924,
        "nist": 5.698062572776918,
        "rouge1": {
            "precision": 0.78316,
            "recall": 0.79851,
            "fmeasure": 0.78419
        },
        "rouge2": {
            "precision": 0.57132,
            "recall": 0.56869,
            "fmeasure": 0.56415
        },
        "rougeL": {
            "precision": 0.67763,
            "recall": 0.72265,
            "fmeasure": 0.69295
        },
        "rougeLsum": {
            "precision": 0.67763,
            "recall": 0.72265,
            "fmeasure": 0.69295
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.2222222222222222,
            "3": 0.86
        },
        "meteor": 0.4521125562384641,
        "nubia": {
            "semantic_relation": 4.67481,
            "contradiction": 4.44218,
            "irrelevancy": 12.47444,
            "logical_agreement": 83.08338,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.92184,
            "nubia_score": 0.82668
        },
        "bleurt": 0.43778,
        "bertscore": {
            "precision": 0.94675,
            "recall": 0.94782,
            "f1": 0.94721
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.02035,
        "nist": 5.091618316373488,
        "rouge1": {
            "precision": 0.66501,
            "recall": 0.68609,
            "fmeasure": 0.66844
        },
        "rouge2": {
            "precision": 0.4686,
            "recall": 0.48245,
            "fmeasure": 0.46807
        },
        "rougeL": {
            "precision": 0.61342,
            "recall": 0.59649,
            "fmeasure": 0.59709
        },
        "rougeLsum": {
            "precision": 0.61342,
            "recall": 0.59649,
            "fmeasure": 0.59709
        },
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.45,
            "3": 0.7692307692307693
        },
        "meteor": 0.3644363491155027,
        "nubia": {
            "semantic_relation": 4.16327,
            "contradiction": 0.62861,
            "irrelevancy": 52.52018,
            "logical_agreement": 46.85121,
            "grammar_ref": 5.24762,
            "grammar_hyp": 4.94717,
            "nubia_score": 0.71958
        },
        "bleurt": 0.1348,
        "bertscore": {
            "precision": 0.90829,
            "recall": 0.91272,
            "f1": 0.90678
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.96662,
        "nist": 3.2155700743944724,
        "rouge1": {
            "precision": 0.59821,
            "recall": 0.72362,
            "fmeasure": 0.64511
        },
        "rouge2": {
            "precision": 0.35097,
            "recall": 0.44643,
            "fmeasure": 0.38568
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.56585,
            "fmeasure": 0.49864
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.56585,
            "fmeasure": 0.49864
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.7894736842105263
        },
        "meteor": 0.373702101409933,
        "nubia": {
            "semantic_relation": 3.88792,
            "contradiction": 12.78535,
            "irrelevancy": 66.82906,
            "logical_agreement": 20.38559,
            "grammar_ref": 4.97036,
            "grammar_hyp": 4.79012,
            "nubia_score": 0.48884
        },
        "bleurt": -0.09172,
        "bertscore": {
            "precision": 0.88092,
            "recall": 0.9037,
            "f1": 0.89196
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 22,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 64.46762,
        "nist": 6.692496102449429,
        "rouge1": {
            "precision": 0.83804,
            "recall": 0.87059,
            "fmeasure": 0.84931
        },
        "rouge2": {
            "precision": 0.70189,
            "recall": 0.72149,
            "fmeasure": 0.70761
        },
        "rougeL": {
            "precision": 0.78403,
            "recall": 0.81321,
            "fmeasure": 0.79431
        },
        "rougeLsum": {
            "precision": 0.78403,
            "recall": 0.81321,
            "fmeasure": 0.79431
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.8972332015810277
        },
        "meteor": 0.5127786690562137,
        "nubia": {
            "semantic_relation": 4.59097,
            "contradiction": 1.10692,
            "irrelevancy": 26.12858,
            "logical_agreement": 72.7645,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.15387,
            "nubia_score": 0.89018
        },
        "bleurt": 0.53883,
        "bertscore": {
            "precision": 0.95731,
            "recall": 0.96265,
            "f1": 0.95929
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 33,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.97922,
        "nist": 7.489419316739529,
        "rouge1": {
            "precision": 0.80477,
            "recall": 0.80051,
            "fmeasure": 0.79792
        },
        "rouge2": {
            "precision": 0.59976,
            "recall": 0.60068,
            "fmeasure": 0.59674
        },
        "rougeL": {
            "precision": 0.70853,
            "recall": 0.70781,
            "fmeasure": 0.70354
        },
        "rougeLsum": {
            "precision": 0.70853,
            "recall": 0.70781,
            "fmeasure": 0.70354
        },
        "local_recall": {
            "1": 0.1625,
            "2": 0.22388059701492538,
            "3": 0.8463414634146341
        },
        "meteor": 0.4418554823888598,
        "nubia": {
            "semantic_relation": 4.57092,
            "contradiction": 4.3613,
            "irrelevancy": 16.93451,
            "logical_agreement": 78.70419,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.89016,
            "nubia_score": 0.83478
        },
        "bleurt": 0.41502,
        "bertscore": {
            "precision": 0.94933,
            "recall": 0.94575,
            "f1": 0.94637
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 9,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 64.19341,
        "nist": 6.250668411366154,
        "rouge1": {
            "precision": 0.87215,
            "recall": 0.81673,
            "fmeasure": 0.83305
        },
        "rouge2": {
            "precision": 0.67661,
            "recall": 0.63329,
            "fmeasure": 0.6447
        },
        "rougeL": {
            "precision": 0.81758,
            "recall": 0.78564,
            "fmeasure": 0.79316
        },
        "rougeLsum": {
            "precision": 0.81758,
            "recall": 0.78564,
            "fmeasure": 0.79316
        },
        "local_recall": {
            "1": 0.35135135135135137,
            "2": 0.7,
            "3": 0.8588235294117647
        },
        "meteor": 0.4511359935044581,
        "nubia": {
            "semantic_relation": 4.42325,
            "contradiction": 0.41947,
            "irrelevancy": 24.77977,
            "logical_agreement": 74.80077,
            "grammar_ref": 4.78166,
            "grammar_hyp": 4.95301,
            "nubia_score": 0.77492
        },
        "bleurt": 0.39506,
        "bertscore": {
            "precision": 0.96517,
            "recall": 0.95218,
            "f1": 0.95775
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.96445,
        "nist": 4.155853147031354,
        "rouge1": {
            "precision": 0.79858,
            "recall": 0.70928,
            "fmeasure": 0.72763
        },
        "rouge2": {
            "precision": 0.61712,
            "recall": 0.53744,
            "fmeasure": 0.55949
        },
        "rougeL": {
            "precision": 0.71646,
            "recall": 0.6457,
            "fmeasure": 0.66101
        },
        "rougeLsum": {
            "precision": 0.71646,
            "recall": 0.6457,
            "fmeasure": 0.66101
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.6041666666666666,
            "3": 0.6338028169014085
        },
        "meteor": 0.3586623754978962,
        "nubia": {
            "semantic_relation": 4.15889,
            "contradiction": 14.18773,
            "irrelevancy": 18.24872,
            "logical_agreement": 67.56355,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.64751,
            "nubia_score": 0.72124
        },
        "bleurt": 0.35925,
        "bertscore": {
            "precision": 0.93822,
            "recall": 0.91683,
            "f1": 0.92556
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 73,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.33797,
        "nist": 7.785672640393317,
        "rouge1": {
            "precision": 0.81391,
            "recall": 0.78022,
            "fmeasure": 0.78873
        },
        "rouge2": {
            "precision": 0.60922,
            "recall": 0.58043,
            "fmeasure": 0.58687
        },
        "rougeL": {
            "precision": 0.72867,
            "recall": 0.70319,
            "fmeasure": 0.70754
        },
        "rougeLsum": {
            "precision": 0.72867,
            "recall": 0.70319,
            "fmeasure": 0.70754
        },
        "local_recall": {
            "1": 0.24651162790697675,
            "2": 0.4397590361445783,
            "3": 0.8084848484848485
        },
        "meteor": 0.4254037508240777,
        "nubia": {
            "semantic_relation": 4.31777,
            "contradiction": 4.27993,
            "irrelevancy": 25.72199,
            "logical_agreement": 69.99808,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.58246,
            "nubia_score": 0.78443
        },
        "bleurt": 0.34588,
        "bertscore": {
            "precision": 0.94527,
            "recall": 0.93994,
            "f1": 0.94133
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 26,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.41016,
        "nist": 6.7845045056848505,
        "rouge1": {
            "precision": 0.77049,
            "recall": 0.73876,
            "fmeasure": 0.7416
        },
        "rouge2": {
            "precision": 0.54087,
            "recall": 0.52366,
            "fmeasure": 0.5231
        },
        "rougeL": {
            "precision": 0.6554,
            "recall": 0.6442,
            "fmeasure": 0.63858
        },
        "rougeLsum": {
            "precision": 0.6554,
            "recall": 0.6442,
            "fmeasure": 0.63858
        },
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.6268656716417911,
            "3": 0.7598425196850394
        },
        "meteor": 0.4076868740454058,
        "nubia": {
            "semantic_relation": 4.10399,
            "contradiction": 12.86517,
            "irrelevancy": 34.46256,
            "logical_agreement": 52.67227,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.68915,
            "nubia_score": 0.68626
        },
        "bleurt": 0.20661,
        "bertscore": {
            "precision": 0.92357,
            "recall": 0.92737,
            "f1": 0.92302
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 31,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.07203,
        "nist": 7.465700790801031,
        "rouge1": {
            "precision": 0.7974,
            "recall": 0.84677,
            "fmeasure": 0.81232
        },
        "rouge2": {
            "precision": 0.615,
            "recall": 0.64654,
            "fmeasure": 0.62339
        },
        "rougeL": {
            "precision": 0.68932,
            "recall": 0.7289,
            "fmeasure": 0.7005
        },
        "rougeLsum": {
            "precision": 0.68932,
            "recall": 0.7289,
            "fmeasure": 0.7005
        },
        "local_recall": {
            "1": 0.23148148148148148,
            "2": 0.4,
            "3": 0.9351351351351351
        },
        "meteor": 0.4800748571278349,
        "nubia": {
            "semantic_relation": 4.45676,
            "contradiction": 4.24488,
            "irrelevancy": 24.93312,
            "logical_agreement": 70.82199,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.50543,
            "nubia_score": 0.80559
        },
        "bleurt": 0.44528,
        "bertscore": {
            "precision": 0.94848,
            "recall": 0.95395,
            "f1": 0.94959
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 30,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.97523,
        "nist": 6.398019362798572,
        "rouge1": {
            "precision": 0.74843,
            "recall": 0.72741,
            "fmeasure": 0.72618
        },
        "rouge2": {
            "precision": 0.51372,
            "recall": 0.50819,
            "fmeasure": 0.50243
        },
        "rougeL": {
            "precision": 0.60455,
            "recall": 0.60199,
            "fmeasure": 0.59299
        },
        "rougeLsum": {
            "precision": 0.60455,
            "recall": 0.60199,
            "fmeasure": 0.59299
        },
        "local_recall": {
            "1": 0.19387755102040816,
            "2": 0.40186915887850466,
            "3": 0.7970149253731343
        },
        "meteor": 0.3980462484625558,
        "nubia": {
            "semantic_relation": 4.14941,
            "contradiction": 11.42628,
            "irrelevancy": 26.57413,
            "logical_agreement": 61.99959,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.79062,
            "nubia_score": 0.68159
        },
        "bleurt": 0.27248,
        "bertscore": {
            "precision": 0.92891,
            "recall": 0.92509,
            "f1": 0.92424
        }
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 128,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.27383,
        "nist": 7.844956530470147,
        "rouge1": {
            "precision": 0.78872,
            "recall": 0.7757,
            "fmeasure": 0.77482
        },
        "rouge2": {
            "precision": 0.53224,
            "recall": 0.52341,
            "fmeasure": 0.52235
        },
        "rougeL": {
            "precision": 0.66525,
            "recall": 0.65458,
            "fmeasure": 0.65355
        },
        "rougeLsum": {
            "precision": 0.66525,
            "recall": 0.65458,
            "fmeasure": 0.65355
        },
        "local_recall": {
            "1": 0.18289085545722714,
            "2": 0.2897959183673469,
            "3": 0.810391363022942
        },
        "meteor": 0.4022631327784608,
        "nubia": {
            "semantic_relation": 4.43861,
            "contradiction": 5.61676,
            "irrelevancy": 22.67423,
            "logical_agreement": 71.709,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.56703,
            "nubia_score": 0.80592
        },
        "bleurt": 0.37164,
        "bertscore": {
            "precision": 0.93477,
            "recall": 0.93293,
            "f1": 0.93259
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.09238,
        "nist": 3.730681862814304,
        "rouge1": {
            "precision": 0.79563,
            "recall": 0.92857,
            "fmeasure": 0.85682
        },
        "rouge2": {
            "precision": 0.53929,
            "recall": 0.64828,
            "fmeasure": 0.58863
        },
        "rougeL": {
            "precision": 0.71726,
            "recall": 0.84788,
            "fmeasure": 0.77688
        },
        "rougeLsum": {
            "precision": 0.71726,
            "recall": 0.84788,
            "fmeasure": 0.77688
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9473684210526315
        },
        "meteor": 0.48079178815199003,
        "nubia": {
            "semantic_relation": 4.74299,
            "contradiction": 0.18006,
            "irrelevancy": 0.58455,
            "logical_agreement": 99.23539,
            "grammar_ref": 5.56806,
            "grammar_hyp": 4.99859,
            "nubia_score": 0.92474
        },
        "bleurt": 0.63577,
        "bertscore": {
            "precision": 0.96902,
            "recall": 0.97242,
            "f1": 0.97069
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.14689,
        "nist": 3.3586216055654705,
        "rouge1": {
            "precision": 0.65909,
            "recall": 0.62882,
            "fmeasure": 0.63877
        },
        "rouge2": {
            "precision": 0.38636,
            "recall": 0.3641,
            "fmeasure": 0.3716
        },
        "rougeL": {
            "precision": 0.56061,
            "recall": 0.55971,
            "fmeasure": 0.54284
        },
        "rougeLsum": {
            "precision": 0.56061,
            "recall": 0.55971,
            "fmeasure": 0.54284
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 0.7058823529411765
        },
        "meteor": 0.36690038962487925,
        "nubia": {
            "semantic_relation": 4.31506,
            "contradiction": 2.89759,
            "irrelevancy": 28.60648,
            "logical_agreement": 68.49593,
            "grammar_ref": 5.15434,
            "grammar_hyp": 4.88941,
            "nubia_score": 0.76252
        },
        "bleurt": 0.35057,
        "bertscore": {
            "precision": 0.90733,
            "recall": 0.89509,
            "f1": 0.90006
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.97511,
        "nist": 5.880668050570632,
        "rouge1": {
            "precision": 0.79009,
            "recall": 0.82248,
            "fmeasure": 0.80417
        },
        "rouge2": {
            "precision": 0.57849,
            "recall": 0.60468,
            "fmeasure": 0.59006
        },
        "rougeL": {
            "precision": 0.63691,
            "recall": 0.65985,
            "fmeasure": 0.64549
        },
        "rougeLsum": {
            "precision": 0.63691,
            "recall": 0.65985,
            "fmeasure": 0.64549
        },
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.4444444444444444,
            "3": 0.8888888888888888
        },
        "meteor": 0.4479400566837689,
        "nubia": {
            "semantic_relation": 4.40731,
            "contradiction": 33.25797,
            "irrelevancy": 24.18527,
            "logical_agreement": 42.55675,
            "grammar_ref": 4.74863,
            "grammar_hyp": 4.8218,
            "nubia_score": 0.72634
        },
        "bleurt": 0.2117,
        "bertscore": {
            "precision": 0.94892,
            "recall": 0.95,
            "f1": 0.94849
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 11,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.24122,
        "nist": 6.247474972742,
        "rouge1": {
            "precision": 0.80086,
            "recall": 0.88648,
            "fmeasure": 0.83607
        },
        "rouge2": {
            "precision": 0.64186,
            "recall": 0.71463,
            "fmeasure": 0.67192
        },
        "rougeL": {
            "precision": 0.7365,
            "recall": 0.82331,
            "fmeasure": 0.77255
        },
        "rougeLsum": {
            "precision": 0.7365,
            "recall": 0.82331,
            "fmeasure": 0.77255
        },
        "local_recall": {
            "1": 0.40625,
            "2": 0.375,
            "3": 0.943089430894309
        },
        "meteor": 0.49644573984273277,
        "nubia": {
            "semantic_relation": 4.75539,
            "contradiction": 2.00099,
            "irrelevancy": 22.13776,
            "logical_agreement": 75.86125,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.003,
            "nubia_score": 0.92131
        },
        "bleurt": 0.54348,
        "bertscore": {
            "precision": 0.95662,
            "recall": 0.96716,
            "f1": 0.96051
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 12,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.79901,
        "nist": 4.896451259098759,
        "rouge1": {
            "precision": 0.79457,
            "recall": 0.70753,
            "fmeasure": 0.73927
        },
        "rouge2": {
            "precision": 0.51954,
            "recall": 0.46734,
            "fmeasure": 0.48563
        },
        "rougeL": {
            "precision": 0.68349,
            "recall": 0.61769,
            "fmeasure": 0.64036
        },
        "rougeLsum": {
            "precision": 0.68349,
            "recall": 0.61769,
            "fmeasure": 0.64036
        },
        "local_recall": {
            "1": 0.1724137931034483,
            "2": 0.5,
            "3": 0.7009345794392523
        },
        "meteor": 0.3687541059679616,
        "nubia": {
            "semantic_relation": 4.30501,
            "contradiction": 11.9329,
            "irrelevancy": 19.45071,
            "logical_agreement": 68.61639,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.41863,
            "nubia_score": 0.69264
        },
        "bleurt": 0.11962,
        "bertscore": {
            "precision": 0.91112,
            "recall": 0.90799,
            "f1": 0.90775
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.49321,
        "nist": 4.334281477115628,
        "rouge1": {
            "precision": 0.81893,
            "recall": 0.64816,
            "fmeasure": 0.70262
        },
        "rouge2": {
            "precision": 0.57131,
            "recall": 0.48081,
            "fmeasure": 0.50995
        },
        "rougeL": {
            "precision": 0.68592,
            "recall": 0.56168,
            "fmeasure": 0.60075
        },
        "rougeLsum": {
            "precision": 0.68592,
            "recall": 0.56168,
            "fmeasure": 0.60075
        },
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.3404255319148936,
            "3": 0.7419354838709677
        },
        "meteor": 0.36988102205272133,
        "nubia": {
            "semantic_relation": 4.0552,
            "contradiction": 19.36838,
            "irrelevancy": 21.51783,
            "logical_agreement": 59.11379,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.77361,
            "nubia_score": 0.6576
        },
        "bleurt": 0.01075,
        "bertscore": {
            "precision": 0.93921,
            "recall": 0.89067,
            "f1": 0.91356
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 20,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.47396,
        "nist": 6.200244804004781,
        "rouge1": {
            "precision": 0.80708,
            "recall": 0.73953,
            "fmeasure": 0.75716
        },
        "rouge2": {
            "precision": 0.58351,
            "recall": 0.53475,
            "fmeasure": 0.54522
        },
        "rougeL": {
            "precision": 0.70995,
            "recall": 0.65734,
            "fmeasure": 0.66893
        },
        "rougeLsum": {
            "precision": 0.70995,
            "recall": 0.65734,
            "fmeasure": 0.66893
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.3787878787878788,
            "3": 0.8009708737864077
        },
        "meteor": 0.4172994473503316,
        "nubia": {
            "semantic_relation": 4.29994,
            "contradiction": 11.76337,
            "irrelevancy": 25.53388,
            "logical_agreement": 62.70275,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.80504,
            "nubia_score": 0.73533
        },
        "bleurt": 0.35504,
        "bertscore": {
            "precision": 0.93721,
            "recall": 0.92801,
            "f1": 0.92952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 51,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.89769,
        "nist": 7.52402576228135,
        "rouge1": {
            "precision": 0.7792,
            "recall": 0.79138,
            "fmeasure": 0.77193
        },
        "rouge2": {
            "precision": 0.54736,
            "recall": 0.55952,
            "fmeasure": 0.5441
        },
        "rougeL": {
            "precision": 0.66006,
            "recall": 0.67469,
            "fmeasure": 0.65569
        },
        "rougeLsum": {
            "precision": 0.66006,
            "recall": 0.67469,
            "fmeasure": 0.65569
        },
        "local_recall": {
            "1": 0.265625,
            "2": 0.5,
            "3": 0.8264014466546112
        },
        "meteor": 0.4177448700146105,
        "nubia": {
            "semantic_relation": 4.30183,
            "contradiction": 2.43078,
            "irrelevancy": 36.89692,
            "logical_agreement": 60.6723,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.74716,
            "nubia_score": 0.74029
        },
        "bleurt": 0.3234,
        "bertscore": {
            "precision": 0.93757,
            "recall": 0.93676,
            "f1": 0.9358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.41862,
        "nist": 4.543742467483298,
        "rouge1": {
            "precision": 0.74446,
            "recall": 0.75767,
            "fmeasure": 0.74119
        },
        "rouge2": {
            "precision": 0.53752,
            "recall": 0.53244,
            "fmeasure": 0.53073
        },
        "rougeL": {
            "precision": 0.66424,
            "recall": 0.69759,
            "fmeasure": 0.66517
        },
        "rougeLsum": {
            "precision": 0.66424,
            "recall": 0.69759,
            "fmeasure": 0.66517
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.625,
            "3": 0.7551020408163265
        },
        "meteor": 0.393270105839326,
        "nubia": {
            "semantic_relation": 4.07918,
            "contradiction": 39.56232,
            "irrelevancy": 29.08833,
            "logical_agreement": 31.34936,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.50364,
            "nubia_score": 0.6088
        },
        "bleurt": 0.33126,
        "bertscore": {
            "precision": 0.93522,
            "recall": 0.94131,
            "f1": 0.93805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 19,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.34323,
        "nist": 5.660803524067198,
        "rouge1": {
            "precision": 0.70977,
            "recall": 0.71766,
            "fmeasure": 0.70515
        },
        "rouge2": {
            "precision": 0.44913,
            "recall": 0.45608,
            "fmeasure": 0.44556
        },
        "rougeL": {
            "precision": 0.65024,
            "recall": 0.65364,
            "fmeasure": 0.64377
        },
        "rougeLsum": {
            "precision": 0.65024,
            "recall": 0.65364,
            "fmeasure": 0.64377
        },
        "local_recall": {
            "1": 0.19672131147540983,
            "2": 0.4745762711864407,
            "3": 0.7294685990338164
        },
        "meteor": 0.3765244834581066,
        "nubia": {
            "semantic_relation": 4.02052,
            "contradiction": 1.66076,
            "irrelevancy": 44.72755,
            "logical_agreement": 53.61169,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.30137,
            "nubia_score": 0.71739
        },
        "bleurt": 0.19757,
        "bertscore": {
            "precision": 0.91596,
            "recall": 0.92008,
            "f1": 0.91599
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.35188,
        "nist": 2.401829852592209,
        "rouge1": {
            "precision": 0.83284,
            "recall": 0.65957,
            "fmeasure": 0.70405
        },
        "rouge2": {
            "precision": 0.5187,
            "recall": 0.45673,
            "fmeasure": 0.46827
        },
        "rougeL": {
            "precision": 0.72708,
            "recall": 0.60298,
            "fmeasure": 0.63182
        },
        "rougeLsum": {
            "precision": 0.72708,
            "recall": 0.60298,
            "fmeasure": 0.63182
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.375,
            "3": 0.603448275862069
        },
        "meteor": 0.32652103425075757,
        "nubia": {
            "semantic_relation": 4.38334,
            "contradiction": 0.97723,
            "irrelevancy": 26.17115,
            "logical_agreement": 72.85162,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.81162,
            "nubia_score": 0.76439
        },
        "bleurt": 0.2286,
        "bertscore": {
            "precision": 0.93014,
            "recall": 0.90482,
            "f1": 0.91195
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.39418,
        "nist": 4.00624109773785,
        "rouge1": {
            "precision": 0.65415,
            "recall": 0.70961,
            "fmeasure": 0.67104
        },
        "rouge2": {
            "precision": 0.42499,
            "recall": 0.46671,
            "fmeasure": 0.43825
        },
        "rougeL": {
            "precision": 0.53776,
            "recall": 0.57775,
            "fmeasure": 0.54895
        },
        "rougeLsum": {
            "precision": 0.53776,
            "recall": 0.57775,
            "fmeasure": 0.54895
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.6470588235294118,
            "3": 0.6811594202898551
        },
        "meteor": 0.3755998734701351,
        "nubia": {
            "semantic_relation": 3.90228,
            "contradiction": 13.10583,
            "irrelevancy": 48.76651,
            "logical_agreement": 38.12766,
            "grammar_ref": 4.06397,
            "grammar_hyp": 4.01407,
            "nubia_score": 0.71352
        },
        "bleurt": 0.12071,
        "bertscore": {
            "precision": 0.90093,
            "recall": 0.91552,
            "f1": 0.90631
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.43995,
        "nist": 2.3226123810297867,
        "rouge1": {
            "precision": 0.53167,
            "recall": 0.85859,
            "fmeasure": 0.6285
        },
        "rouge2": {
            "precision": 0.38542,
            "recall": 0.63939,
            "fmeasure": 0.45643
        },
        "rougeL": {
            "precision": 0.53167,
            "recall": 0.85859,
            "fmeasure": 0.6285
        },
        "rougeLsum": {
            "precision": 0.53167,
            "recall": 0.85859,
            "fmeasure": 0.6285
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "meteor": 0.4948504981892212,
        "nubia": {
            "semantic_relation": 4.06251,
            "contradiction": 0.42524,
            "irrelevancy": 58.01538,
            "logical_agreement": 41.55937,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.36495,
            "nubia_score": 0.77154
        },
        "bleurt": 0.22425,
        "bertscore": {
            "precision": 0.8825,
            "recall": 0.95589,
            "f1": 0.91707
        }
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 45,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.55257,
        "nist": 7.3789294689481055,
        "rouge1": {
            "precision": 0.79158,
            "recall": 0.77458,
            "fmeasure": 0.77451
        },
        "rouge2": {
            "precision": 0.54728,
            "recall": 0.54022,
            "fmeasure": 0.53724
        },
        "rougeL": {
            "precision": 0.64158,
            "recall": 0.62756,
            "fmeasure": 0.62725
        },
        "rougeLsum": {
            "precision": 0.64158,
            "recall": 0.62756,
            "fmeasure": 0.62725
        },
        "local_recall": {
            "1": 0.22666666666666666,
            "2": 0.4921875,
            "3": 0.8076923076923077
        },
        "meteor": 0.418981157023215,
        "nubia": {
            "semantic_relation": 4.5024,
            "contradiction": 5.44907,
            "irrelevancy": 21.60651,
            "logical_agreement": 72.94442,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.83906,
            "nubia_score": 0.81396
        },
        "bleurt": 0.37626,
        "bertscore": {
            "precision": 0.94197,
            "recall": 0.94013,
            "f1": 0.94059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.62087,
        "nist": 5.219056198955125,
        "rouge1": {
            "precision": 0.71907,
            "recall": 0.70005,
            "fmeasure": 0.70036
        },
        "rouge2": {
            "precision": 0.48983,
            "recall": 0.4909,
            "fmeasure": 0.48437
        },
        "rougeL": {
            "precision": 0.58807,
            "recall": 0.57874,
            "fmeasure": 0.57692
        },
        "rougeLsum": {
            "precision": 0.58807,
            "recall": 0.57874,
            "fmeasure": 0.57692
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.125,
            "3": 0.7692307692307693
        },
        "meteor": 0.3998745491298381,
        "nubia": {
            "semantic_relation": 3.90154,
            "contradiction": 16.51028,
            "irrelevancy": 36.41238,
            "logical_agreement": 47.07734,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.31192,
            "nubia_score": 0.64212
        },
        "bleurt": 0.07732,
        "bertscore": {
            "precision": 0.90338,
            "recall": 0.90377,
            "f1": 0.9019
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 49,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.45609,
        "nist": 7.303083668366293,
        "rouge1": {
            "precision": 0.75047,
            "recall": 0.73695,
            "fmeasure": 0.73564
        },
        "rouge2": {
            "precision": 0.50747,
            "recall": 0.49516,
            "fmeasure": 0.49579
        },
        "rougeL": {
            "precision": 0.63692,
            "recall": 0.62065,
            "fmeasure": 0.62203
        },
        "rougeLsum": {
            "precision": 0.63692,
            "recall": 0.62065,
            "fmeasure": 0.62203
        },
        "local_recall": {
            "1": 0.24742268041237114,
            "2": 0.4624277456647399,
            "3": 0.8007590132827325
        },
        "meteor": 0.39837756748772263,
        "nubia": {
            "semantic_relation": 4.32236,
            "contradiction": 4.56726,
            "irrelevancy": 28.17933,
            "logical_agreement": 67.25342,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.63922,
            "nubia_score": 0.77623
        },
        "bleurt": 0.33361,
        "bertscore": {
            "precision": 0.93294,
            "recall": 0.92653,
            "f1": 0.92815
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.44738,
        "nist": 4.898283649709202,
        "rouge1": {
            "precision": 0.6501,
            "recall": 0.66045,
            "fmeasure": 0.6326
        },
        "rouge2": {
            "precision": 0.43119,
            "recall": 0.41418,
            "fmeasure": 0.40739
        },
        "rougeL": {
            "precision": 0.57376,
            "recall": 0.56631,
            "fmeasure": 0.54866
        },
        "rougeLsum": {
            "precision": 0.57376,
            "recall": 0.56631,
            "fmeasure": 0.54866
        },
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.25,
            "3": 0.7894736842105263
        },
        "meteor": 0.3748245162767369,
        "nubia": {
            "semantic_relation": 3.98851,
            "contradiction": 14.24467,
            "irrelevancy": 36.29721,
            "logical_agreement": 49.45811,
            "grammar_ref": 4.75129,
            "grammar_hyp": 4.6527,
            "nubia_score": 0.68694
        },
        "bleurt": 0.22272,
        "bertscore": {
            "precision": 0.90215,
            "recall": 0.90175,
            "f1": 0.89846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 78.25423,
        "nist": 4.189149368285628,
        "rouge1": {
            "precision": 0.9,
            "recall": 0.87273,
            "fmeasure": 0.88571
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.68889,
            "fmeasure": 0.71345
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.77879,
            "fmeasure": 0.80476
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.77879,
            "fmeasure": 0.80476
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.875
        },
        "meteor": 0.48700800154546436,
        "nubia": {
            "semantic_relation": 3.6235,
            "contradiction": 98.3679,
            "irrelevancy": 0.84099,
            "logical_agreement": 0.79111,
            "grammar_ref": 3.16175,
            "grammar_hyp": 3.05201,
            "nubia_score": 0.63696
        },
        "bleurt": 0.57246,
        "bertscore": {
            "precision": 0.986,
            "recall": 0.9773,
            "f1": 0.98109
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 14,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.10098,
        "nist": 5.335814685509757,
        "rouge1": {
            "precision": 0.68363,
            "recall": 0.70426,
            "fmeasure": 0.68124
        },
        "rouge2": {
            "precision": 0.41963,
            "recall": 0.45821,
            "fmeasure": 0.42873
        },
        "rougeL": {
            "precision": 0.57418,
            "recall": 0.60194,
            "fmeasure": 0.57681
        },
        "rougeLsum": {
            "precision": 0.57418,
            "recall": 0.60194,
            "fmeasure": 0.57681
        },
        "local_recall": {
            "1": 0.25862068965517243,
            "2": 0.4883720930232558,
            "3": 0.7737226277372263
        },
        "meteor": 0.3833487558484859,
        "nubia": {
            "semantic_relation": 4.06387,
            "contradiction": 18.17571,
            "irrelevancy": 36.25798,
            "logical_agreement": 45.56631,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.46225,
            "nubia_score": 0.69146
        },
        "bleurt": 0.21693,
        "bertscore": {
            "precision": 0.91229,
            "recall": 0.92347,
            "f1": 0.91626
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 16,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.46509,
        "nist": 6.349919565207098,
        "rouge1": {
            "precision": 0.76268,
            "recall": 0.80671,
            "fmeasure": 0.77817
        },
        "rouge2": {
            "precision": 0.54886,
            "recall": 0.57849,
            "fmeasure": 0.55896
        },
        "rougeL": {
            "precision": 0.66835,
            "recall": 0.7055,
            "fmeasure": 0.68097
        },
        "rougeLsum": {
            "precision": 0.66835,
            "recall": 0.7055,
            "fmeasure": 0.68097
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4146341463414634,
            "3": 0.8162162162162162
        },
        "meteor": 0.42067250785480337,
        "nubia": {
            "semantic_relation": 4.5848,
            "contradiction": 0.8965,
            "irrelevancy": 23.22322,
            "logical_agreement": 75.88029,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.27642,
            "nubia_score": 0.87706
        },
        "bleurt": 0.51419,
        "bertscore": {
            "precision": 0.94403,
            "recall": 0.95492,
            "f1": 0.94745
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 21,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.39675,
        "nist": 5.417721594201657,
        "rouge1": {
            "precision": 0.72707,
            "recall": 0.72087,
            "fmeasure": 0.70937
        },
        "rouge2": {
            "precision": 0.4988,
            "recall": 0.47926,
            "fmeasure": 0.48019
        },
        "rougeL": {
            "precision": 0.64209,
            "recall": 0.64678,
            "fmeasure": 0.63037
        },
        "rougeLsum": {
            "precision": 0.64209,
            "recall": 0.64678,
            "fmeasure": 0.63037
        },
        "local_recall": {
            "1": 0.15942028985507245,
            "2": 0.39622641509433965,
            "3": 0.75
        },
        "meteor": 0.3711060543987571,
        "nubia": {
            "semantic_relation": 3.83505,
            "contradiction": 9.24208,
            "irrelevancy": 38.43414,
            "logical_agreement": 52.32379,
            "grammar_ref": 4.80447,
            "grammar_hyp": 4.94866,
            "nubia_score": 0.62578
        },
        "bleurt": 0.19209,
        "bertscore": {
            "precision": 0.92334,
            "recall": 0.91038,
            "f1": 0.91425
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.12181,
        "nist": 5.898794419037583,
        "rouge1": {
            "precision": 0.76934,
            "recall": 0.82071,
            "fmeasure": 0.79139
        },
        "rouge2": {
            "precision": 0.52669,
            "recall": 0.56437,
            "fmeasure": 0.54318
        },
        "rougeL": {
            "precision": 0.64779,
            "recall": 0.69294,
            "fmeasure": 0.66723
        },
        "rougeLsum": {
            "precision": 0.64779,
            "recall": 0.69294,
            "fmeasure": 0.66723
        },
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.4857142857142857,
            "3": 0.9710144927536232
        },
        "meteor": 0.4520435752941748,
        "nubia": {
            "semantic_relation": 4.45308,
            "contradiction": 17.01963,
            "irrelevancy": 19.74434,
            "logical_agreement": 63.23604,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.52662,
            "nubia_score": 0.80627
        },
        "bleurt": 0.32432,
        "bertscore": {
            "precision": 0.9432,
            "recall": 0.96259,
            "f1": 0.95199
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 13,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.69234,
        "nist": 5.13595383600436,
        "rouge1": {
            "precision": 0.66683,
            "recall": 0.71585,
            "fmeasure": 0.68114
        },
        "rouge2": {
            "precision": 0.40722,
            "recall": 0.44845,
            "fmeasure": 0.42196
        },
        "rougeL": {
            "precision": 0.53852,
            "recall": 0.58745,
            "fmeasure": 0.55237
        },
        "rougeLsum": {
            "precision": 0.53852,
            "recall": 0.58745,
            "fmeasure": 0.55237
        },
        "local_recall": {
            "1": 0.19718309859154928,
            "2": 0.49056603773584906,
            "3": 0.7698412698412699
        },
        "meteor": 0.36849216980001515,
        "nubia": {
            "semantic_relation": 3.80721,
            "contradiction": 23.80431,
            "irrelevancy": 40.07492,
            "logical_agreement": 36.12077,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.27458,
            "nubia_score": 0.62628
        },
        "bleurt": 0.098,
        "bertscore": {
            "precision": 0.91147,
            "recall": 0.91304,
            "f1": 0.91082
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.61017,
        "nist": 5.282867261142493,
        "rouge1": {
            "precision": 0.86897,
            "recall": 0.73852,
            "fmeasure": 0.7922
        },
        "rouge2": {
            "precision": 0.68662,
            "recall": 0.57125,
            "fmeasure": 0.61674
        },
        "rougeL": {
            "precision": 0.76464,
            "recall": 0.65403,
            "fmeasure": 0.6997
        },
        "rougeLsum": {
            "precision": 0.76464,
            "recall": 0.65403,
            "fmeasure": 0.6997
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.26666666666666666,
            "3": 0.7857142857142857
        },
        "meteor": 0.4205561333142229,
        "nubia": {
            "semantic_relation": 4.43039,
            "contradiction": 0.46264,
            "irrelevancy": 14.26075,
            "logical_agreement": 85.27661,
            "grammar_ref": 4.74509,
            "grammar_hyp": 4.57965,
            "nubia_score": 0.84597
        },
        "bleurt": 0.33121,
        "bertscore": {
            "precision": 0.9511,
            "recall": 0.92969,
            "f1": 0.93896
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 162,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.46335,
        "nist": 7.603857023189864,
        "rouge1": {
            "precision": 0.7179,
            "recall": 0.72536,
            "fmeasure": 0.71178
        },
        "rouge2": {
            "precision": 0.46443,
            "recall": 0.46984,
            "fmeasure": 0.459
        },
        "rougeL": {
            "precision": 0.59329,
            "recall": 0.60163,
            "fmeasure": 0.58785
        },
        "rougeLsum": {
            "precision": 0.59329,
            "recall": 0.60163,
            "fmeasure": 0.58785
        },
        "local_recall": {
            "1": 0.22935779816513763,
            "2": 0.416289592760181,
            "3": 0.7724094087730451
        },
        "meteor": 0.3907524274512623,
        "nubia": {
            "semantic_relation": 4.21359,
            "contradiction": 5.98376,
            "irrelevancy": 33.12984,
            "logical_agreement": 60.8864,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.45496,
            "nubia_score": 0.7584
        },
        "bleurt": 0.2561,
        "bertscore": {
            "precision": 0.92157,
            "recall": 0.92152,
            "f1": 0.91911
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 14,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 63.60564,
        "nist": 6.616358722453005,
        "rouge1": {
            "precision": 0.83084,
            "recall": 0.83799,
            "fmeasure": 0.82995
        },
        "rouge2": {
            "precision": 0.69633,
            "recall": 0.70299,
            "fmeasure": 0.69586
        },
        "rougeL": {
            "precision": 0.74001,
            "recall": 0.76357,
            "fmeasure": 0.74646
        },
        "rougeLsum": {
            "precision": 0.74001,
            "recall": 0.76357,
            "fmeasure": 0.74646
        },
        "local_recall": {
            "1": 0.45454545454545453,
            "2": 0.4772727272727273,
            "3": 0.8785714285714286
        },
        "meteor": 0.47976655092409515,
        "nubia": {
            "semantic_relation": 4.46189,
            "contradiction": 5.86525,
            "irrelevancy": 22.13683,
            "logical_agreement": 71.99792,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.54632,
            "nubia_score": 0.8411
        },
        "bleurt": 0.50409,
        "bertscore": {
            "precision": 0.95687,
            "recall": 0.95576,
            "f1": 0.95494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.25224,
        "nist": 5.759757104270222,
        "rouge1": {
            "precision": 0.78669,
            "recall": 0.81436,
            "fmeasure": 0.79897
        },
        "rouge2": {
            "precision": 0.59306,
            "recall": 0.62239,
            "fmeasure": 0.60611
        },
        "rougeL": {
            "precision": 0.69029,
            "recall": 0.7399,
            "fmeasure": 0.71329
        },
        "rougeLsum": {
            "precision": 0.69029,
            "recall": 0.7399,
            "fmeasure": 0.71329
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5714285714285714,
            "3": 0.8412698412698413
        },
        "meteor": 0.4503339934270547,
        "nubia": {
            "semantic_relation": 4.2917,
            "contradiction": 0.38534,
            "irrelevancy": 64.45905,
            "logical_agreement": 35.15561,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.30005,
            "nubia_score": 0.78607
        },
        "bleurt": 0.088,
        "bertscore": {
            "precision": 0.94343,
            "recall": 0.95045,
            "f1": 0.94393
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.3243,
        "nist": 3.277088980104999,
        "rouge1": {
            "precision": 0.63743,
            "recall": 0.72087,
            "fmeasure": 0.66995
        },
        "rouge2": {
            "precision": 0.28268,
            "recall": 0.31603,
            "fmeasure": 0.29614
        },
        "rougeL": {
            "precision": 0.42982,
            "recall": 0.48954,
            "fmeasure": 0.45446
        },
        "rougeLsum": {
            "precision": 0.42982,
            "recall": 0.48954,
            "fmeasure": 0.45446
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6896551724137931
        },
        "meteor": 0.3572614762291986,
        "nubia": {
            "semantic_relation": 4.48601,
            "contradiction": 1.87098,
            "irrelevancy": 2.98051,
            "logical_agreement": 95.14851,
            "grammar_ref": 4.49155,
            "grammar_hyp": 3.93162,
            "nubia_score": 0.9304
        },
        "bleurt": 0.34973,
        "bertscore": {
            "precision": 0.88171,
            "recall": 0.90885,
            "f1": 0.89498
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.7973,
        "nist": 3.681802781398524,
        "rouge1": {
            "precision": 0.57853,
            "recall": 0.60542,
            "fmeasure": 0.56877
        },
        "rouge2": {
            "precision": 0.24822,
            "recall": 0.30069,
            "fmeasure": 0.26032
        },
        "rougeL": {
            "precision": 0.43371,
            "recall": 0.47352,
            "fmeasure": 0.4322
        },
        "rougeLsum": {
            "precision": 0.43371,
            "recall": 0.47352,
            "fmeasure": 0.4322
        },
        "local_recall": {
            "1": 0.3103448275862069,
            "2": 0.5217391304347826,
            "3": 0.5614035087719298
        },
        "meteor": 0.2746696144357698,
        "nubia": {
            "semantic_relation": 3.83004,
            "contradiction": 1.42058,
            "irrelevancy": 54.91285,
            "logical_agreement": 43.66657,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.5482,
            "nubia_score": 0.63966
        },
        "bleurt": -0.05497,
        "bertscore": {
            "precision": 0.88582,
            "recall": 0.8894,
            "f1": 0.88246
        }
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 150,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.38921,
        "nist": 8.479779042792277,
        "rouge1": {
            "precision": 0.81078,
            "recall": 0.7902,
            "fmeasure": 0.79301
        },
        "rouge2": {
            "precision": 0.59056,
            "recall": 0.58141,
            "fmeasure": 0.58033
        },
        "rougeL": {
            "precision": 0.6952,
            "recall": 0.68079,
            "fmeasure": 0.68098
        },
        "rougeLsum": {
            "precision": 0.6952,
            "recall": 0.68079,
            "fmeasure": 0.68098
        },
        "local_recall": {
            "1": 0.17738359201773837,
            "2": 0.4756756756756757,
            "3": 0.8127147766323024
        },
        "meteor": 0.42173809344395435,
        "nubia": {
            "semantic_relation": 4.47966,
            "contradiction": 4.73154,
            "irrelevancy": 22.20274,
            "logical_agreement": 73.06571,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.16052,
            "nubia_score": 0.78953
        },
        "bleurt": 0.39854,
        "bertscore": {
            "precision": 0.94969,
            "recall": 0.94573,
            "f1": 0.94664
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 64,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.89226,
        "nist": 7.0812216853259455,
        "rouge1": {
            "precision": 0.74755,
            "recall": 0.71638,
            "fmeasure": 0.72251
        },
        "rouge2": {
            "precision": 0.483,
            "recall": 0.47256,
            "fmeasure": 0.4719
        },
        "rougeL": {
            "precision": 0.63598,
            "recall": 0.61093,
            "fmeasure": 0.6151
        },
        "rougeLsum": {
            "precision": 0.63598,
            "recall": 0.61093,
            "fmeasure": 0.6151
        },
        "local_recall": {
            "1": 0.19230769230769232,
            "2": 0.45374449339207046,
            "3": 0.7566433566433567
        },
        "meteor": 0.38882940127470117,
        "nubia": {
            "semantic_relation": 4.25886,
            "contradiction": 5.23281,
            "irrelevancy": 30.51534,
            "logical_agreement": 64.25185,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.65134,
            "nubia_score": 0.73843
        },
        "bleurt": 0.25786,
        "bertscore": {
            "precision": 0.92938,
            "recall": 0.9221,
            "f1": 0.92385
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 29,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.42569,
        "nist": 7.009215015756043,
        "rouge1": {
            "precision": 0.83239,
            "recall": 0.81927,
            "fmeasure": 0.81662
        },
        "rouge2": {
            "precision": 0.64473,
            "recall": 0.64099,
            "fmeasure": 0.63698
        },
        "rougeL": {
            "precision": 0.76143,
            "recall": 0.74472,
            "fmeasure": 0.74424
        },
        "rougeLsum": {
            "precision": 0.76143,
            "recall": 0.74472,
            "fmeasure": 0.74424
        },
        "local_recall": {
            "1": 0.17105263157894737,
            "2": 0.5223880597014925,
            "3": 0.8230088495575221
        },
        "meteor": 0.44445966794262437,
        "nubia": {
            "semantic_relation": 4.42763,
            "contradiction": 8.65671,
            "irrelevancy": 25.30765,
            "logical_agreement": 66.03565,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.81866,
            "nubia_score": 0.79178
        },
        "bleurt": 0.48968,
        "bertscore": {
            "precision": 0.95319,
            "recall": 0.95267,
            "f1": 0.95256
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 73.6025,
        "nist": 4.4284072890109485,
        "rouge1": {
            "precision": 0.74646,
            "recall": 0.63573,
            "fmeasure": 0.67516
        },
        "rouge2": {
            "precision": 0.67619,
            "recall": 0.58333,
            "fmeasure": 0.61571
        },
        "rougeL": {
            "precision": 0.74646,
            "recall": 0.63573,
            "fmeasure": 0.67516
        },
        "rougeLsum": {
            "precision": 0.74646,
            "recall": 0.63573,
            "fmeasure": 0.67516
        },
        "local_recall": {
            "1": 0.3125,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "meteor": 0.3648048798179826,
        "nubia": {
            "semantic_relation": 3.27695,
            "contradiction": 29.59194,
            "irrelevancy": 13.85049,
            "logical_agreement": 56.55757,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.48544,
            "nubia_score": 0.48454
        },
        "bleurt": 0.08221,
        "bertscore": {
            "precision": 0.92695,
            "recall": 0.91294,
            "f1": 0.91132
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 19,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.94246,
        "nist": 4.831475503267792,
        "rouge1": {
            "precision": 0.60921,
            "recall": 0.64352,
            "fmeasure": 0.61192
        },
        "rouge2": {
            "precision": 0.39756,
            "recall": 0.41926,
            "fmeasure": 0.39819
        },
        "rougeL": {
            "precision": 0.52834,
            "recall": 0.5618,
            "fmeasure": 0.53103
        },
        "rougeLsum": {
            "precision": 0.52834,
            "recall": 0.5618,
            "fmeasure": 0.53103
        },
        "local_recall": {
            "1": 0.22058823529411764,
            "2": 0.3956043956043956,
            "3": 0.7109826589595376
        },
        "meteor": 0.30948528286706,
        "nubia": {
            "semantic_relation": 3.82278,
            "contradiction": 15.84367,
            "irrelevancy": 46.60879,
            "logical_agreement": 37.54754,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.4965,
            "nubia_score": 0.61369
        },
        "bleurt": 0.11233,
        "bertscore": {
            "precision": 0.88489,
            "recall": 0.90076,
            "f1": 0.89028
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 379,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.90646,
        "nist": 8.633773291647941,
        "rouge1": {
            "precision": 0.74255,
            "recall": 0.72613,
            "fmeasure": 0.72502
        },
        "rouge2": {
            "precision": 0.48081,
            "recall": 0.47309,
            "fmeasure": 0.47093
        },
        "rougeL": {
            "precision": 0.59199,
            "recall": 0.58623,
            "fmeasure": 0.58145
        },
        "rougeLsum": {
            "precision": 0.59199,
            "recall": 0.58623,
            "fmeasure": 0.58145
        },
        "local_recall": {
            "1": 0.22916666666666666,
            "2": 0.4326788218793829,
            "3": 0.7677279305354558
        },
        "meteor": 0.37798187637447356,
        "nubia": {
            "semantic_relation": 4.08708,
            "contradiction": 9.21105,
            "irrelevancy": 30.82037,
            "logical_agreement": 59.96858,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.19481,
            "nubia_score": 0.71107
        },
        "bleurt": 0.19733,
        "bertscore": {
            "precision": 0.92188,
            "recall": 0.91735,
            "f1": 0.91786
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 4.9055199766139435,
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.93333,
            "fmeasure": 0.87179
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.93333
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.93333
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.18583,
            "contradiction": 0.32484,
            "irrelevancy": 35.51392,
            "logical_agreement": 64.16124,
            "grammar_ref": 4.09688,
            "grammar_hyp": 3.75691,
            "nubia_score": 0.79418
        },
        "bleurt": 0.42629,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 31,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.73583,
        "nist": 6.6375508880787715,
        "rouge1": {
            "precision": 0.78139,
            "recall": 0.75039,
            "fmeasure": 0.75402
        },
        "rouge2": {
            "precision": 0.57057,
            "recall": 0.55579,
            "fmeasure": 0.55595
        },
        "rougeL": {
            "precision": 0.65141,
            "recall": 0.62979,
            "fmeasure": 0.62931
        },
        "rougeLsum": {
            "precision": 0.65141,
            "recall": 0.62979,
            "fmeasure": 0.62931
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.6075949367088608,
            "3": 0.771875
        },
        "meteor": 0.40487416042866137,
        "nubia": {
            "semantic_relation": 4.33134,
            "contradiction": 2.1315,
            "irrelevancy": 31.88576,
            "logical_agreement": 65.98273,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.7275,
            "nubia_score": 0.75028
        },
        "bleurt": 0.32266,
        "bertscore": {
            "precision": 0.92888,
            "recall": 0.92297,
            "f1": 0.92451
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.28927,
        "nist": 3.875968138183132,
        "rouge1": {
            "precision": 0.5081,
            "recall": 0.49997,
            "fmeasure": 0.50288
        },
        "rouge2": {
            "precision": 0.30068,
            "recall": 0.29953,
            "fmeasure": 0.29927
        },
        "rougeL": {
            "precision": 0.36336,
            "recall": 0.36515,
            "fmeasure": 0.36346
        },
        "rougeLsum": {
            "precision": 0.36336,
            "recall": 0.36515,
            "fmeasure": 0.36346
        },
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.5526315789473685
        },
        "meteor": 0.3057354435902888,
        "nubia": {
            "semantic_relation": 3.75729,
            "contradiction": 8.42763,
            "irrelevancy": 66.41188,
            "logical_agreement": 25.16049,
            "grammar_ref": 4.45404,
            "grammar_hyp": 4.52575,
            "nubia_score": 0.569
        },
        "bleurt": -0.12791,
        "bertscore": {
            "precision": 0.8868,
            "recall": 0.87464,
            "f1": 0.8806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.56718,
        "nist": 4.670948800065638,
        "rouge1": {
            "precision": 0.7918,
            "recall": 0.78108,
            "fmeasure": 0.77908
        },
        "rouge2": {
            "precision": 0.56548,
            "recall": 0.55794,
            "fmeasure": 0.55652
        },
        "rougeL": {
            "precision": 0.70863,
            "recall": 0.70748,
            "fmeasure": 0.70238
        },
        "rougeLsum": {
            "precision": 0.70863,
            "recall": 0.70748,
            "fmeasure": 0.70238
        },
        "local_recall": {
            "1": 0.0625,
            "2": 0.6153846153846154,
            "3": 0.8035714285714286
        },
        "meteor": 0.4325151065332441,
        "nubia": {
            "semantic_relation": 4.42364,
            "contradiction": 18.67854,
            "irrelevancy": 21.69875,
            "logical_agreement": 59.62271,
            "grammar_ref": 5.14386,
            "grammar_hyp": 5.05308,
            "nubia_score": 0.80137
        },
        "bleurt": 0.50201,
        "bertscore": {
            "precision": 0.94433,
            "recall": 0.94494,
            "f1": 0.94428
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 36,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.68409,
        "nist": 6.846506591993036,
        "rouge1": {
            "precision": 0.75862,
            "recall": 0.75298,
            "fmeasure": 0.74861
        },
        "rouge2": {
            "precision": 0.54366,
            "recall": 0.54627,
            "fmeasure": 0.53986
        },
        "rougeL": {
            "precision": 0.68297,
            "recall": 0.68699,
            "fmeasure": 0.67774
        },
        "rougeLsum": {
            "precision": 0.68297,
            "recall": 0.68699,
            "fmeasure": 0.67774
        },
        "local_recall": {
            "1": 0.3508771929824561,
            "2": 0.4716981132075472,
            "3": 0.782991202346041
        },
        "meteor": 0.4448892982252279,
        "nubia": {
            "semantic_relation": 4.14392,
            "contradiction": 4.10921,
            "irrelevancy": 35.41098,
            "logical_agreement": 60.47981,
            "grammar_ref": 3.9304,
            "grammar_hyp": 3.89784,
            "nubia_score": 0.77228
        },
        "bleurt": 0.39202,
        "bertscore": {
            "precision": 0.93964,
            "recall": 0.94103,
            "f1": 0.93883
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 11,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.68964,
        "nist": 5.326673182732055,
        "rouge1": {
            "precision": 0.73422,
            "recall": 0.7113,
            "fmeasure": 0.71703
        },
        "rouge2": {
            "precision": 0.43965,
            "recall": 0.40998,
            "fmeasure": 0.42095
        },
        "rougeL": {
            "precision": 0.60977,
            "recall": 0.58112,
            "fmeasure": 0.59024
        },
        "rougeLsum": {
            "precision": 0.60977,
            "recall": 0.58112,
            "fmeasure": 0.59024
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.4,
            "3": 0.7730496453900709
        },
        "meteor": 0.37256525488175646,
        "nubia": {
            "semantic_relation": 4.36082,
            "contradiction": 1.37981,
            "irrelevancy": 30.66644,
            "logical_agreement": 67.95376,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.59965,
            "nubia_score": 0.80293
        },
        "bleurt": 0.26014,
        "bertscore": {
            "precision": 0.90973,
            "recall": 0.91926,
            "f1": 0.91182
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 31,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.22209,
        "nist": 7.062602695444626,
        "rouge1": {
            "precision": 0.77144,
            "recall": 0.76503,
            "fmeasure": 0.76217
        },
        "rouge2": {
            "precision": 0.53988,
            "recall": 0.52492,
            "fmeasure": 0.52742
        },
        "rougeL": {
            "precision": 0.68112,
            "recall": 0.68185,
            "fmeasure": 0.67597
        },
        "rougeLsum": {
            "precision": 0.68112,
            "recall": 0.68185,
            "fmeasure": 0.67597
        },
        "local_recall": {
            "1": 0.2072072072072072,
            "2": 0.5180722891566265,
            "3": 0.8106666666666666
        },
        "meteor": 0.410474717962903,
        "nubia": {
            "semantic_relation": 4.39715,
            "contradiction": 8.13938,
            "irrelevancy": 21.20538,
            "logical_agreement": 70.65524,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.82205,
            "nubia_score": 0.7861
        },
        "bleurt": 0.39521,
        "bertscore": {
            "precision": 0.93741,
            "recall": 0.93878,
            "f1": 0.93767
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.74196,
        "nist": 5.639931173655106,
        "rouge1": {
            "precision": 0.75811,
            "recall": 0.79179,
            "fmeasure": 0.7687
        },
        "rouge2": {
            "precision": 0.57179,
            "recall": 0.58615,
            "fmeasure": 0.57366
        },
        "rougeL": {
            "precision": 0.67548,
            "recall": 0.70623,
            "fmeasure": 0.68424
        },
        "rougeLsum": {
            "precision": 0.67548,
            "recall": 0.70623,
            "fmeasure": 0.68424
        },
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.875,
            "3": 0.8055555555555556
        },
        "meteor": 0.4292079064751142,
        "nubia": {
            "semantic_relation": 4.3222,
            "contradiction": 12.31774,
            "irrelevancy": 36.20953,
            "logical_agreement": 51.47274,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.48484,
            "nubia_score": 0.76124
        },
        "bleurt": 0.28522,
        "bertscore": {
            "precision": 0.9284,
            "recall": 0.94163,
            "f1": 0.93421
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 62.72517,
        "nist": 3.384408553884113,
        "rouge1": {
            "precision": 0.80392,
            "recall": 0.9375,
            "fmeasure": 0.86478
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.80855,
            "fmeasure": 0.74231
        },
        "rougeL": {
            "precision": 0.76471,
            "recall": 0.88988,
            "fmeasure": 0.82177
        },
        "rougeLsum": {
            "precision": 0.76471,
            "recall": 0.88988,
            "fmeasure": 0.82177
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 1.0
        },
        "meteor": 0.5473793577579883,
        "nubia": {
            "semantic_relation": 4.67353,
            "contradiction": 0.08083,
            "irrelevancy": 0.95461,
            "logical_agreement": 98.96456,
            "grammar_ref": 3.66146,
            "grammar_hyp": 3.33356,
            "nubia_score": 0.94292
        },
        "bleurt": 0.49824,
        "bertscore": {
            "precision": 0.94336,
            "recall": 0.98169,
            "f1": 0.96214
        }
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 150,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.61935,
        "nist": 8.107572048771969,
        "rouge1": {
            "precision": 0.77445,
            "recall": 0.76142,
            "fmeasure": 0.75931
        },
        "rouge2": {
            "precision": 0.52974,
            "recall": 0.51536,
            "fmeasure": 0.51571
        },
        "rougeL": {
            "precision": 0.65209,
            "recall": 0.64071,
            "fmeasure": 0.63845
        },
        "rougeLsum": {
            "precision": 0.65209,
            "recall": 0.64071,
            "fmeasure": 0.63845
        },
        "local_recall": {
            "1": 0.21336206896551724,
            "2": 0.4297297297297297,
            "3": 0.8143459915611815
        },
        "meteor": 0.4080396538406893,
        "nubia": {
            "semantic_relation": 4.42622,
            "contradiction": 5.04194,
            "irrelevancy": 22.93831,
            "logical_agreement": 72.01975,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.78062,
            "nubia_score": 0.7958
        },
        "bleurt": 0.36781,
        "bertscore": {
            "precision": 0.93641,
            "recall": 0.93476,
            "f1": 0.93376
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.95221,
        "nist": 4.547763398049345,
        "rouge1": {
            "precision": 0.70098,
            "recall": 0.82177,
            "fmeasure": 0.74586
        },
        "rouge2": {
            "precision": 0.49117,
            "recall": 0.58997,
            "fmeasure": 0.52536
        },
        "rougeL": {
            "precision": 0.63214,
            "recall": 0.74935,
            "fmeasure": 0.67411
        },
        "rougeLsum": {
            "precision": 0.63214,
            "recall": 0.74935,
            "fmeasure": 0.67411
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.8714285714285714
        },
        "meteor": 0.4194161628534277,
        "nubia": {
            "semantic_relation": 4.08796,
            "contradiction": 17.81905,
            "irrelevancy": 46.41575,
            "logical_agreement": 35.7652,
            "grammar_ref": 5.40206,
            "grammar_hyp": 4.75166,
            "nubia_score": 0.6965
        },
        "bleurt": 0.23374,
        "bertscore": {
            "precision": 0.91761,
            "recall": 0.93325,
            "f1": 0.92213
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 19.25161,
        "nist": 1.9019550008653876,
        "rouge1": {
            "precision": 0.57143,
            "recall": 1.0,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.57143,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.875,
            "fmeasure": 0.63636
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.875,
            "fmeasure": 0.63636
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 0.43240874576063026,
        "nubia": {
            "semantic_relation": 4.32555,
            "contradiction": 0.10888,
            "irrelevancy": 96.82464,
            "logical_agreement": 3.06647,
            "grammar_ref": 5.02153,
            "grammar_hyp": 4.26769,
            "nubia_score": 0.73125
        },
        "bleurt": 0.32323,
        "bertscore": {
            "precision": 0.89637,
            "recall": 0.9712,
            "f1": 0.93229
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 12,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.65001,
        "nist": 4.581035815036728,
        "rouge1": {
            "precision": 0.6962,
            "recall": 0.68324,
            "fmeasure": 0.67916
        },
        "rouge2": {
            "precision": 0.49417,
            "recall": 0.47849,
            "fmeasure": 0.4798
        },
        "rougeL": {
            "precision": 0.6082,
            "recall": 0.59938,
            "fmeasure": 0.59446
        },
        "rougeLsum": {
            "precision": 0.6082,
            "recall": 0.59938,
            "fmeasure": 0.59446
        },
        "local_recall": {
            "1": 0.12121212121212122,
            "2": 0.42857142857142855,
            "3": 0.75
        },
        "meteor": 0.3645353845228757,
        "nubia": {
            "semantic_relation": 4.1507,
            "contradiction": 1.51621,
            "irrelevancy": 40.72162,
            "logical_agreement": 57.76217,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.21866,
            "nubia_score": 0.73192
        },
        "bleurt": 0.2158,
        "bertscore": {
            "precision": 0.90692,
            "recall": 0.91731,
            "f1": 0.90959
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.1437,
        "nist": 3.3681075050251343,
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.92674,
            "fmeasure": 0.79973
        },
        "rouge2": {
            "precision": 0.43137,
            "recall": 0.59829,
            "fmeasure": 0.50115
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.60073,
            "fmeasure": 0.51075
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.60073,
            "fmeasure": 0.51075
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 1.0
        },
        "meteor": 0.48929835514662473,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24693,
            "irrelevancy": 69.42086,
            "logical_agreement": 30.33221,
            "grammar_ref": 5.12321,
            "grammar_hyp": 3.69824,
            "nubia_score": 1.0
        },
        "bleurt": 0.51449,
        "bertscore": {
            "precision": 0.91376,
            "recall": 0.94274,
            "f1": 0.92392
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.30309,
        "nist": 4.509510801257838,
        "rouge1": {
            "precision": 0.78226,
            "recall": 0.83154,
            "fmeasure": 0.79949
        },
        "rouge2": {
            "precision": 0.59079,
            "recall": 0.61262,
            "fmeasure": 0.59675
        },
        "rougeL": {
            "precision": 0.72698,
            "recall": 0.75944,
            "fmeasure": 0.73824
        },
        "rougeLsum": {
            "precision": 0.72698,
            "recall": 0.75944,
            "fmeasure": 0.73824
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.75,
            "3": 0.868421052631579
        },
        "meteor": 0.45916577609548564,
        "nubia": {
            "semantic_relation": 4.47689,
            "contradiction": 0.35154,
            "irrelevancy": 29.80101,
            "logical_agreement": 69.84745,
            "grammar_ref": 5.12632,
            "grammar_hyp": 5.1426,
            "nubia_score": 0.8234
        },
        "bleurt": 0.43574,
        "bertscore": {
            "precision": 0.94535,
            "recall": 0.94552,
            "f1": 0.94439
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 72.18546,
        "nist": 6.024289936264899,
        "rouge1": {
            "precision": 0.81864,
            "recall": 0.76627,
            "fmeasure": 0.78719
        },
        "rouge2": {
            "precision": 0.65681,
            "recall": 0.63985,
            "fmeasure": 0.64637
        },
        "rougeL": {
            "precision": 0.78777,
            "recall": 0.74462,
            "fmeasure": 0.76168
        },
        "rougeLsum": {
            "precision": 0.78777,
            "recall": 0.74462,
            "fmeasure": 0.76168
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.855072463768116
        },
        "meteor": 0.48399596919375387,
        "nubia": {
            "semantic_relation": 4.60517,
            "contradiction": 0.70193,
            "irrelevancy": 22.18485,
            "logical_agreement": 77.11322,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.93702,
            "nubia_score": 0.82416
        },
        "bleurt": 0.40642,
        "bertscore": {
            "precision": 0.95951,
            "recall": 0.94177,
            "f1": 0.94949
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.02494,
        "nist": 4.503116252293312,
        "rouge1": {
            "precision": 0.62708,
            "recall": 0.66644,
            "fmeasure": 0.6359
        },
        "rouge2": {
            "precision": 0.39846,
            "recall": 0.409,
            "fmeasure": 0.39756
        },
        "rougeL": {
            "precision": 0.45887,
            "recall": 0.51654,
            "fmeasure": 0.47928
        },
        "rougeLsum": {
            "precision": 0.45887,
            "recall": 0.51654,
            "fmeasure": 0.47928
        },
        "local_recall": {
            "1": 0.2641509433962264,
            "2": 0.7297297297297297,
            "3": 0.8095238095238095
        },
        "meteor": 0.3769691178121039,
        "nubia": {
            "semantic_relation": 3.9789,
            "contradiction": 2.1821,
            "irrelevancy": 47.52955,
            "logical_agreement": 50.28836,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.33936,
            "nubia_score": 0.68913
        },
        "bleurt": 0.00592,
        "bertscore": {
            "precision": 0.90492,
            "recall": 0.92484,
            "f1": 0.91311
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.36213,
        "nist": 3.822084170020711,
        "rouge1": {
            "precision": 0.56574,
            "recall": 0.62337,
            "fmeasure": 0.56431
        },
        "rouge2": {
            "precision": 0.25926,
            "recall": 0.34444,
            "fmeasure": 0.29109
        },
        "rougeL": {
            "precision": 0.50227,
            "recall": 0.52678,
            "fmeasure": 0.48855
        },
        "rougeLsum": {
            "precision": 0.50227,
            "recall": 0.52678,
            "fmeasure": 0.48855
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.5625,
            "3": 0.8666666666666667
        },
        "meteor": 0.36787319922887957,
        "nubia": {
            "semantic_relation": 3.35054,
            "contradiction": 2.83233,
            "irrelevancy": 63.13218,
            "logical_agreement": 34.03548,
            "grammar_ref": 4.86076,
            "grammar_hyp": 4.57681,
            "nubia_score": 0.54956
        },
        "bleurt": 0.06109,
        "bertscore": {
            "precision": 0.88218,
            "recall": 0.88343,
            "f1": 0.88146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.67304,
        "nist": 5.396172422923819,
        "rouge1": {
            "precision": 0.78872,
            "recall": 0.76546,
            "fmeasure": 0.76533
        },
        "rouge2": {
            "precision": 0.54661,
            "recall": 0.51221,
            "fmeasure": 0.52036
        },
        "rougeL": {
            "precision": 0.70074,
            "recall": 0.69493,
            "fmeasure": 0.68908
        },
        "rougeLsum": {
            "precision": 0.70074,
            "recall": 0.69493,
            "fmeasure": 0.68908
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.8,
            "3": 0.782608695652174
        },
        "meteor": 0.39294032802947754,
        "nubia": {
            "semantic_relation": 4.22116,
            "contradiction": 19.11571,
            "irrelevancy": 29.05848,
            "logical_agreement": 51.82581,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.47018,
            "nubia_score": 0.77369
        },
        "bleurt": 0.17856,
        "bertscore": {
            "precision": 0.92827,
            "recall": 0.92033,
            "f1": 0.92302
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.0442,
        "nist": 0.427899183043676,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69444,
            "fmeasure": 0.80214
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.53333,
            "fmeasure": 0.59259
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5
        },
        "meteor": 0.3274499237462559,
        "nubia": {
            "semantic_relation": 3.9192,
            "contradiction": 0.33634,
            "irrelevancy": 33.45921,
            "logical_agreement": 66.20444,
            "grammar_ref": 6.47099,
            "grammar_hyp": 8.78862,
            "nubia_score": 0.50144
        },
        "bleurt": -0.01027,
        "bertscore": {
            "precision": 0.89229,
            "recall": 0.85481,
            "f1": 0.87315
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 14,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.13923,
        "nist": 4.979449371086038,
        "rouge1": {
            "precision": 0.62147,
            "recall": 0.64922,
            "fmeasure": 0.62452
        },
        "rouge2": {
            "precision": 0.39087,
            "recall": 0.39706,
            "fmeasure": 0.38563
        },
        "rougeL": {
            "precision": 0.50186,
            "recall": 0.52581,
            "fmeasure": 0.50453
        },
        "rougeLsum": {
            "precision": 0.50186,
            "recall": 0.52581,
            "fmeasure": 0.50453
        },
        "local_recall": {
            "1": 0.2328767123287671,
            "2": 0.5230769230769231,
            "3": 0.7652173913043478
        },
        "meteor": 0.33612235859024925,
        "nubia": {
            "semantic_relation": 3.79783,
            "contradiction": 1.19071,
            "irrelevancy": 77.64204,
            "logical_agreement": 21.16725,
            "grammar_ref": 4.00042,
            "grammar_hyp": 3.96498,
            "nubia_score": 0.65884
        },
        "bleurt": -0.03742,
        "bertscore": {
            "precision": 0.8958,
            "recall": 0.90516,
            "f1": 0.89874
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.90418,
        "nist": 5.427887676056057,
        "rouge1": {
            "precision": 0.8304,
            "recall": 0.842,
            "fmeasure": 0.83247
        },
        "rouge2": {
            "precision": 0.63274,
            "recall": 0.64313,
            "fmeasure": 0.63562
        },
        "rougeL": {
            "precision": 0.70701,
            "recall": 0.71373,
            "fmeasure": 0.70705
        },
        "rougeLsum": {
            "precision": 0.70701,
            "recall": 0.71373,
            "fmeasure": 0.70705
        },
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.375,
            "3": 0.8734177215189873
        },
        "meteor": 0.4378301371685221,
        "nubia": {
            "semantic_relation": 4.47653,
            "contradiction": 1.70814,
            "irrelevancy": 25.88943,
            "logical_agreement": 72.40243,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.49958,
            "nubia_score": 0.83892
        },
        "bleurt": 0.51594,
        "bertscore": {
            "precision": 0.95721,
            "recall": 0.95582,
            "f1": 0.95635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 81.96501,
        "nist": 4.00193538757769,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "meteor": 0.5249299242820813,
        "nubia": {
            "semantic_relation": 4.91472,
            "contradiction": 0.30946,
            "irrelevancy": 2.79721,
            "logical_agreement": 96.89333,
            "grammar_ref": 3.61542,
            "grammar_hyp": 3.03745,
            "nubia_score": 1.0
        },
        "bleurt": 0.86304,
        "bertscore": {
            "precision": 0.99614,
            "recall": 0.98503,
            "f1": 0.99055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 66,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.26722,
        "nist": 6.950148665087304,
        "rouge1": {
            "precision": 0.73435,
            "recall": 0.72371,
            "fmeasure": 0.71924
        },
        "rouge2": {
            "precision": 0.51832,
            "recall": 0.51992,
            "fmeasure": 0.51213
        },
        "rougeL": {
            "precision": 0.65485,
            "recall": 0.65253,
            "fmeasure": 0.64401
        },
        "rougeLsum": {
            "precision": 0.65485,
            "recall": 0.65253,
            "fmeasure": 0.64401
        },
        "local_recall": {
            "1": 0.22885572139303484,
            "2": 0.4030612244897959,
            "3": 0.7600574712643678
        },
        "meteor": 0.388734728057941,
        "nubia": {
            "semantic_relation": 4.16024,
            "contradiction": 6.65403,
            "irrelevancy": 35.2241,
            "logical_agreement": 58.12187,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.28347,
            "nubia_score": 0.7492
        },
        "bleurt": 0.28717,
        "bertscore": {
            "precision": 0.92289,
            "recall": 0.92172,
            "f1": 0.92066
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.20251,
        "nist": 2.542758964186693,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.67424,
            "fmeasure": 0.6058
        },
        "rouge2": {
            "precision": 0.42424,
            "recall": 0.52381,
            "fmeasure": 0.46561
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.67424,
            "fmeasure": 0.6058
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.67424,
            "fmeasure": 0.6058
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8
        },
        "meteor": 0.3801734539295942,
        "nubia": {
            "semantic_relation": 4.97609,
            "contradiction": 0.14746,
            "irrelevancy": 27.82365,
            "logical_agreement": 72.02889,
            "grammar_ref": 3.38649,
            "grammar_hyp": 3.44703,
            "nubia_score": 0.91553
        },
        "bleurt": 0.56434,
        "bertscore": {
            "precision": 0.9265,
            "recall": 0.94687,
            "f1": 0.9336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.31136,
        "nist": 5.2187806902783835,
        "rouge1": {
            "precision": 0.84905,
            "recall": 0.94344,
            "fmeasure": 0.89212
        },
        "rouge2": {
            "precision": 0.65024,
            "recall": 0.72941,
            "fmeasure": 0.68606
        },
        "rougeL": {
            "precision": 0.73273,
            "recall": 0.83564,
            "fmeasure": 0.77999
        },
        "rougeLsum": {
            "precision": 0.73273,
            "recall": 0.83564,
            "fmeasure": 0.77999
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8461538461538461,
            "3": 1.0
        },
        "meteor": 0.4702215841823995,
        "nubia": {
            "semantic_relation": 4.55834,
            "contradiction": 10.42558,
            "irrelevancy": 57.14955,
            "logical_agreement": 32.42487,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.22499,
            "nubia_score": 0.76531
        },
        "bleurt": 0.47675,
        "bertscore": {
            "precision": 0.95234,
            "recall": 0.97069,
            "f1": 0.96117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.7427,
        "nist": 1.4088554498254706,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.47619,
            "fmeasure": 0.62016
        },
        "rouge2": {
            "precision": 0.61905,
            "recall": 0.34691,
            "fmeasure": 0.44285
        },
        "rougeL": {
            "precision": 0.75556,
            "recall": 0.44444,
            "fmeasure": 0.55728
        },
        "rougeLsum": {
            "precision": 0.75556,
            "recall": 0.44444,
            "fmeasure": 0.55728
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4,
            "3": 0.6428571428571429
        },
        "meteor": 0.2798988165334471,
        "nubia": {
            "semantic_relation": 3.53269,
            "contradiction": 0.11167,
            "irrelevancy": 64.72782,
            "logical_agreement": 35.16051,
            "grammar_ref": 3.5675,
            "grammar_hyp": 3.86717,
            "nubia_score": 0.52693
        },
        "bleurt": -0.02592,
        "bertscore": {
            "precision": 0.95972,
            "recall": 0.87038,
            "f1": 0.91287
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.24861,
        "nist": 4.935512400368969,
        "rouge1": {
            "precision": 0.72875,
            "recall": 0.68276,
            "fmeasure": 0.69496
        },
        "rouge2": {
            "precision": 0.49262,
            "recall": 0.47716,
            "fmeasure": 0.48071
        },
        "rougeL": {
            "precision": 0.64087,
            "recall": 0.6021,
            "fmeasure": 0.61387
        },
        "rougeLsum": {
            "precision": 0.64087,
            "recall": 0.6021,
            "fmeasure": 0.61387
        },
        "local_recall": {
            "1": 0.08,
            "2": 0.3181818181818182,
            "3": 0.7127659574468085
        },
        "meteor": 0.36535166887646564,
        "nubia": {
            "semantic_relation": 3.73971,
            "contradiction": 36.68404,
            "irrelevancy": 27.53823,
            "logical_agreement": 35.77773,
            "grammar_ref": 5.01189,
            "grammar_hyp": 5.02486,
            "nubia_score": 0.5622
        },
        "bleurt": 0.20076,
        "bertscore": {
            "precision": 0.92847,
            "recall": 0.91837,
            "f1": 0.92255
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 124,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.90876,
        "nist": 7.7157467602139915,
        "rouge1": {
            "precision": 0.71955,
            "recall": 0.70421,
            "fmeasure": 0.70305
        },
        "rouge2": {
            "precision": 0.44797,
            "recall": 0.44834,
            "fmeasure": 0.44157
        },
        "rougeL": {
            "precision": 0.57727,
            "recall": 0.56786,
            "fmeasure": 0.56523
        },
        "rougeLsum": {
            "precision": 0.57727,
            "recall": 0.56786,
            "fmeasure": 0.56523
        },
        "local_recall": {
            "1": 0.2567287784679089,
            "2": 0.44469525959367945,
            "3": 0.7494939271255061
        },
        "meteor": 0.36260749490383837,
        "nubia": {
            "semantic_relation": 3.95645,
            "contradiction": 10.76904,
            "irrelevancy": 38.21993,
            "logical_agreement": 51.01104,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.19212,
            "nubia_score": 0.66988
        },
        "bleurt": 0.13125,
        "bertscore": {
            "precision": 0.91707,
            "recall": 0.91232,
            "f1": 0.91321
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 12,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.43302,
        "nist": 4.8396622006442875,
        "rouge1": {
            "precision": 0.67006,
            "recall": 0.72406,
            "fmeasure": 0.68303
        },
        "rouge2": {
            "precision": 0.42414,
            "recall": 0.47621,
            "fmeasure": 0.4384
        },
        "rougeL": {
            "precision": 0.57665,
            "recall": 0.63214,
            "fmeasure": 0.59105
        },
        "rougeLsum": {
            "precision": 0.57665,
            "recall": 0.63214,
            "fmeasure": 0.59105
        },
        "local_recall": {
            "1": 0.2894736842105263,
            "2": 0.4838709677419355,
            "3": 0.6923076923076923
        },
        "meteor": 0.37446825973584297,
        "nubia": {
            "semantic_relation": 3.91267,
            "contradiction": 13.2034,
            "irrelevancy": 52.9101,
            "logical_agreement": 33.8865,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.39965,
            "nubia_score": 0.65332
        },
        "bleurt": 0.10242,
        "bertscore": {
            "precision": 0.90627,
            "recall": 0.91407,
            "f1": 0.90761
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.12379,
        "nist": 4.506570204461564,
        "rouge1": {
            "precision": 0.73457,
            "recall": 0.60878,
            "fmeasure": 0.66046
        },
        "rouge2": {
            "precision": 0.47917,
            "recall": 0.41257,
            "fmeasure": 0.4425
        },
        "rougeL": {
            "precision": 0.62346,
            "recall": 0.51389,
            "fmeasure": 0.56065
        },
        "rougeLsum": {
            "precision": 0.62346,
            "recall": 0.51389,
            "fmeasure": 0.56065
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.3333333333333333,
            "3": 0.7058823529411765
        },
        "meteor": 0.42017261164950703,
        "nubia": {
            "semantic_relation": 3.99659,
            "contradiction": 0.21547,
            "irrelevancy": 48.14578,
            "logical_agreement": 51.63875,
            "grammar_ref": 4.82994,
            "grammar_hyp": 4.14945,
            "nubia_score": 0.73607
        },
        "bleurt": 0.23198,
        "bertscore": {
            "precision": 0.93286,
            "recall": 0.92212,
            "f1": 0.92675
        }
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 150,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.39474,
        "nist": 8.379242507542683,
        "rouge1": {
            "precision": 0.80451,
            "recall": 0.7823,
            "fmeasure": 0.78721
        },
        "rouge2": {
            "precision": 0.56996,
            "recall": 0.55079,
            "fmeasure": 0.55543
        },
        "rougeL": {
            "precision": 0.6885,
            "recall": 0.66375,
            "fmeasure": 0.67042
        },
        "rougeLsum": {
            "precision": 0.6885,
            "recall": 0.66375,
            "fmeasure": 0.67042
        },
        "local_recall": {
            "1": 0.16467780429594273,
            "2": 0.31802120141342755,
            "3": 0.817937701396348
        },
        "meteor": 0.4176703876134805,
        "nubia": {
            "semantic_relation": 4.48758,
            "contradiction": 3.50643,
            "irrelevancy": 21.87227,
            "logical_agreement": 74.6213,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.57007,
            "nubia_score": 0.81808
        },
        "bleurt": 0.38376,
        "bertscore": {
            "precision": 0.93853,
            "recall": 0.93852,
            "f1": 0.93734
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.56813,
        "nist": 5.585408385781289,
        "rouge1": {
            "precision": 0.72118,
            "recall": 0.75016,
            "fmeasure": 0.71869
        },
        "rouge2": {
            "precision": 0.43596,
            "recall": 0.4627,
            "fmeasure": 0.43719
        },
        "rougeL": {
            "precision": 0.54524,
            "recall": 0.5729,
            "fmeasure": 0.54777
        },
        "rougeLsum": {
            "precision": 0.54524,
            "recall": 0.5729,
            "fmeasure": 0.54777
        },
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.52,
            "3": 0.7894736842105263
        },
        "meteor": 0.3685168557516744,
        "nubia": {
            "semantic_relation": 4.0447,
            "contradiction": 6.6257,
            "irrelevancy": 38.74483,
            "logical_agreement": 54.62948,
            "grammar_ref": 4.94279,
            "grammar_hyp": 4.96297,
            "nubia_score": 0.64362
        },
        "bleurt": 0.04287,
        "bertscore": {
            "precision": 0.92597,
            "recall": 0.90972,
            "f1": 0.91675
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 18,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.29624,
        "nist": 5.659445589846068,
        "rouge1": {
            "precision": 0.70673,
            "recall": 0.70737,
            "fmeasure": 0.70185
        },
        "rouge2": {
            "precision": 0.46727,
            "recall": 0.46384,
            "fmeasure": 0.46352
        },
        "rougeL": {
            "precision": 0.62624,
            "recall": 0.62274,
            "fmeasure": 0.62061
        },
        "rougeLsum": {
            "precision": 0.62624,
            "recall": 0.62274,
            "fmeasure": 0.62061
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.21428571428571427,
            "3": 0.7315789473684211
        },
        "meteor": 0.37161288135412307,
        "nubia": {
            "semantic_relation": 4.08482,
            "contradiction": 7.49893,
            "irrelevancy": 34.16944,
            "logical_agreement": 58.33163,
            "grammar_ref": 5.08526,
            "grammar_hyp": 4.89888,
            "nubia_score": 0.70287
        },
        "bleurt": 0.27974,
        "bertscore": {
            "precision": 0.91241,
            "recall": 0.91636,
            "f1": 0.91307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 103,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.63151,
        "nist": 7.883532709910443,
        "rouge1": {
            "precision": 0.76058,
            "recall": 0.76044,
            "fmeasure": 0.74687
        },
        "rouge2": {
            "precision": 0.52967,
            "recall": 0.54149,
            "fmeasure": 0.5249
        },
        "rougeL": {
            "precision": 0.66959,
            "recall": 0.68012,
            "fmeasure": 0.66207
        },
        "rougeLsum": {
            "precision": 0.66959,
            "recall": 0.68012,
            "fmeasure": 0.66207
        },
        "local_recall": {
            "1": 0.23170731707317074,
            "2": 0.4444444444444444,
            "3": 0.8096085409252669
        },
        "meteor": 0.41056688479951164,
        "nubia": {
            "semantic_relation": 4.29159,
            "contradiction": 6.67043,
            "irrelevancy": 29.47205,
            "logical_agreement": 63.85751,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.56293,
            "nubia_score": 0.74965
        },
        "bleurt": 0.30393,
        "bertscore": {
            "precision": 0.93146,
            "recall": 0.9304,
            "f1": 0.92975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.15381,
        "nist": 3.054710144537756,
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.78333,
            "fmeasure": 0.7764
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.71717,
            "fmeasure": 0.70677
        },
        "rougeL": {
            "precision": 0.77273,
            "recall": 0.78333,
            "fmeasure": 0.7764
        },
        "rougeLsum": {
            "precision": 0.77273,
            "recall": 0.78333,
            "fmeasure": 0.7764
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.875
        },
        "meteor": 0.4828313957069677,
        "nubia": {
            "semantic_relation": 4.35347,
            "contradiction": 0.52359,
            "irrelevancy": 95.76836,
            "logical_agreement": 3.70805,
            "grammar_ref": 4.59758,
            "grammar_hyp": 4.00611,
            "nubia_score": 0.86795
        },
        "bleurt": 0.5308,
        "bertscore": {
            "precision": 0.85732,
            "recall": 0.92802,
            "f1": 0.89127
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 47,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.15522,
        "nist": 6.630612263931022,
        "rouge1": {
            "precision": 0.74574,
            "recall": 0.74801,
            "fmeasure": 0.73113
        },
        "rouge2": {
            "precision": 0.50736,
            "recall": 0.51127,
            "fmeasure": 0.49862
        },
        "rougeL": {
            "precision": 0.63597,
            "recall": 0.64056,
            "fmeasure": 0.62448
        },
        "rougeLsum": {
            "precision": 0.63597,
            "recall": 0.64056,
            "fmeasure": 0.62448
        },
        "local_recall": {
            "1": 0.21875,
            "2": 0.3953488372093023,
            "3": 0.7709090909090909
        },
        "meteor": 0.3955893501049154,
        "nubia": {
            "semantic_relation": 4.21841,
            "contradiction": 6.84872,
            "irrelevancy": 33.04856,
            "logical_agreement": 60.10271,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.29147,
            "nubia_score": 0.7362
        },
        "bleurt": 0.29005,
        "bertscore": {
            "precision": 0.92421,
            "recall": 0.9264,
            "f1": 0.92353
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.47795,
        "nist": 2.182650875192532,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "meteor": 0.40017244547454695,
        "nubia": {
            "semantic_relation": 4.89542,
            "contradiction": 0.19694,
            "irrelevancy": 0.42997,
            "logical_agreement": 99.37309,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.93105,
            "nubia_score": 0.96616
        },
        "bleurt": 0.73499,
        "bertscore": {
            "precision": 0.94718,
            "recall": 0.95007,
            "f1": 0.94862
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.1986532337201607,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        },
        "bleurt": 0.99035,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 71.65758,
        "nist": 5.775667183087698,
        "rouge1": {
            "precision": 0.90633,
            "recall": 0.96268,
            "fmeasure": 0.93028
        },
        "rouge2": {
            "precision": 0.80093,
            "recall": 0.82427,
            "fmeasure": 0.81081
        },
        "rougeL": {
            "precision": 0.82597,
            "recall": 0.87801,
            "fmeasure": 0.84356
        },
        "rougeLsum": {
            "precision": 0.82597,
            "recall": 0.87801,
            "fmeasure": 0.84356
        },
        "local_recall": {
            "1": 0.4666666666666667,
            "2": 0.8333333333333334,
            "3": 1.0
        },
        "meteor": 0.5602083030169211,
        "nubia": {
            "semantic_relation": 4.64061,
            "contradiction": 12.68611,
            "irrelevancy": 25.79465,
            "logical_agreement": 61.51924,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.28231,
            "nubia_score": 0.83999
        },
        "bleurt": 0.6491,
        "bertscore": {
            "precision": 0.97225,
            "recall": 0.98244,
            "f1": 0.97723
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 14,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.02478,
        "nist": 6.137746456712613,
        "rouge1": {
            "precision": 0.84299,
            "recall": 0.79456,
            "fmeasure": 0.80461
        },
        "rouge2": {
            "precision": 0.66087,
            "recall": 0.63052,
            "fmeasure": 0.63735
        },
        "rougeL": {
            "precision": 0.71835,
            "recall": 0.67297,
            "fmeasure": 0.68221
        },
        "rougeLsum": {
            "precision": 0.71835,
            "recall": 0.67297,
            "fmeasure": 0.68221
        },
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.34375,
            "3": 0.8782051282051282
        },
        "meteor": 0.44570096832883754,
        "nubia": {
            "semantic_relation": 4.23154,
            "contradiction": 4.89302,
            "irrelevancy": 16.78663,
            "logical_agreement": 78.32034,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.98937,
            "nubia_score": 0.73289
        },
        "bleurt": 0.38214,
        "bertscore": {
            "precision": 0.94668,
            "recall": 0.92701,
            "f1": 0.93616
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 114,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.51885,
        "nist": 7.461005030465322,
        "rouge1": {
            "precision": 0.73838,
            "recall": 0.74569,
            "fmeasure": 0.72996
        },
        "rouge2": {
            "precision": 0.4856,
            "recall": 0.49379,
            "fmeasure": 0.48148
        },
        "rougeL": {
            "precision": 0.60068,
            "recall": 0.62262,
            "fmeasure": 0.60078
        },
        "rougeLsum": {
            "precision": 0.60068,
            "recall": 0.62262,
            "fmeasure": 0.60078
        },
        "local_recall": {
            "1": 0.22133333333333333,
            "2": 0.5197044334975369,
            "3": 0.7989371124889283
        },
        "meteor": 0.3872674880304749,
        "nubia": {
            "semantic_relation": 4.23582,
            "contradiction": 8.237,
            "irrelevancy": 29.57206,
            "logical_agreement": 62.19094,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.69099,
            "nubia_score": 0.73073
        },
        "bleurt": 0.28498,
        "bertscore": {
            "precision": 0.925,
            "recall": 0.9244,
            "f1": 0.92359
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 17,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.37547,
        "nist": 5.512687268481502,
        "rouge1": {
            "precision": 0.73105,
            "recall": 0.69996,
            "fmeasure": 0.69845
        },
        "rouge2": {
            "precision": 0.48266,
            "recall": 0.45858,
            "fmeasure": 0.4594
        },
        "rougeL": {
            "precision": 0.6038,
            "recall": 0.60451,
            "fmeasure": 0.5884
        },
        "rougeLsum": {
            "precision": 0.6038,
            "recall": 0.60451,
            "fmeasure": 0.5884
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3764705882352941,
            "3": 0.726775956284153
        },
        "meteor": 0.3687745935013295,
        "nubia": {
            "semantic_relation": 4.07172,
            "contradiction": 22.87034,
            "irrelevancy": 30.2044,
            "logical_agreement": 46.92526,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.48344,
            "nubia_score": 0.68013
        },
        "bleurt": 0.13386,
        "bertscore": {
            "precision": 0.91779,
            "recall": 0.91758,
            "f1": 0.91482
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 128,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.96837,
        "nist": 8.200840082885946,
        "rouge1": {
            "precision": 0.74491,
            "recall": 0.73596,
            "fmeasure": 0.73128
        },
        "rouge2": {
            "precision": 0.51012,
            "recall": 0.50595,
            "fmeasure": 0.50184
        },
        "rougeL": {
            "precision": 0.61676,
            "recall": 0.61365,
            "fmeasure": 0.60766
        },
        "rougeLsum": {
            "precision": 0.61676,
            "recall": 0.61365,
            "fmeasure": 0.60766
        },
        "local_recall": {
            "1": 0.2471655328798186,
            "2": 0.44573643410852715,
            "3": 0.7868480725623582
        },
        "meteor": 0.4039153561275398,
        "nubia": {
            "semantic_relation": 3.96821,
            "contradiction": 13.06479,
            "irrelevancy": 28.79281,
            "logical_agreement": 58.1424,
            "grammar_ref": 4.11595,
            "grammar_hyp": 4.03902,
            "nubia_score": 0.67024
        },
        "bleurt": 0.17216,
        "bertscore": {
            "precision": 0.9248,
            "recall": 0.92076,
            "f1": 0.92149
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.98089,
        "nist": 3.8296825592346386,
        "rouge1": {
            "precision": 0.77143,
            "recall": 0.78371,
            "fmeasure": 0.77593
        },
        "rouge2": {
            "precision": 0.55019,
            "recall": 0.55681,
            "fmeasure": 0.55216
        },
        "rougeL": {
            "precision": 0.66032,
            "recall": 0.68938,
            "fmeasure": 0.67381
        },
        "rougeLsum": {
            "precision": 0.66032,
            "recall": 0.68938,
            "fmeasure": 0.67381
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.7352941176470589
        },
        "meteor": 0.37681050423988616,
        "nubia": {
            "semantic_relation": 4.45725,
            "contradiction": 0.63885,
            "irrelevancy": 33.56044,
            "logical_agreement": 65.8007,
            "grammar_ref": 4.67072,
            "grammar_hyp": 3.90775,
            "nubia_score": 0.91529
        },
        "bleurt": 0.46314,
        "bertscore": {
            "precision": 0.91898,
            "recall": 0.95288,
            "f1": 0.93478
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 63.70092,
        "nist": 5.587499680427071,
        "rouge1": {
            "precision": 0.8961,
            "recall": 0.83941,
            "fmeasure": 0.85655
        },
        "rouge2": {
            "precision": 0.77645,
            "recall": 0.74343,
            "fmeasure": 0.75335
        },
        "rougeL": {
            "precision": 0.86634,
            "recall": 0.81304,
            "fmeasure": 0.82958
        },
        "rougeLsum": {
            "precision": 0.86634,
            "recall": 0.81304,
            "fmeasure": 0.82958
        },
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.125,
            "3": 0.7872340425531915
        },
        "meteor": 0.4659077683570436,
        "nubia": {
            "semantic_relation": 4.72438,
            "contradiction": 0.19467,
            "irrelevancy": 0.6767,
            "logical_agreement": 99.12863,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.49288,
            "nubia_score": 0.90107
        },
        "bleurt": 0.7218,
        "bertscore": {
            "precision": 0.97702,
            "recall": 0.95927,
            "f1": 0.9675
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.29664,
        "nist": 4.485066402322131,
        "rouge1": {
            "precision": 0.63186,
            "recall": 0.82691,
            "fmeasure": 0.68373
        },
        "rouge2": {
            "precision": 0.42633,
            "recall": 0.58954,
            "fmeasure": 0.47162
        },
        "rougeL": {
            "precision": 0.55696,
            "recall": 0.77246,
            "fmeasure": 0.62457
        },
        "rougeLsum": {
            "precision": 0.55696,
            "recall": 0.77246,
            "fmeasure": 0.62457
        },
        "local_recall": {
            "1": 0.42105263157894735,
            "2": 0.7428571428571429,
            "3": 0.625
        },
        "meteor": 0.4410048125343643,
        "nubia": {
            "semantic_relation": 4.11128,
            "contradiction": 0.35295,
            "irrelevancy": 69.72657,
            "logical_agreement": 29.92049,
            "grammar_ref": 5.36601,
            "grammar_hyp": 4.3634,
            "nubia_score": 0.75074
        },
        "bleurt": 0.16727,
        "bertscore": {
            "precision": 0.88305,
            "recall": 0.92482,
            "f1": 0.8983
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.38502,
        "nist": 2.3996142879231073,
        "rouge1": {
            "precision": 0.58667,
            "recall": 0.67677,
            "fmeasure": 0.62843
        },
        "rouge2": {
            "precision": 0.36111,
            "recall": 0.41905,
            "fmeasure": 0.38788
        },
        "rougeL": {
            "precision": 0.44,
            "recall": 0.51587,
            "fmeasure": 0.47487
        },
        "rougeLsum": {
            "precision": 0.44,
            "recall": 0.51587,
            "fmeasure": 0.47487
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.5333333333333333
        },
        "meteor": 0.359170448197036,
        "nubia": {
            "semantic_relation": 3.51584,
            "contradiction": 69.23368,
            "irrelevancy": 30.0967,
            "logical_agreement": 0.66963,
            "grammar_ref": 3.42286,
            "grammar_hyp": 3.57445,
            "nubia_score": 0.55847
        },
        "bleurt": -0.01726,
        "bertscore": {
            "precision": 0.90752,
            "recall": 0.87886,
            "f1": 0.89296
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 9,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.14676,
        "nist": 4.4822740808574695,
        "rouge1": {
            "precision": 0.61066,
            "recall": 0.6539,
            "fmeasure": 0.61788
        },
        "rouge2": {
            "precision": 0.3806,
            "recall": 0.40656,
            "fmeasure": 0.38188
        },
        "rougeL": {
            "precision": 0.54138,
            "recall": 0.58749,
            "fmeasure": 0.54996
        },
        "rougeLsum": {
            "precision": 0.54138,
            "recall": 0.58749,
            "fmeasure": 0.54996
        },
        "local_recall": {
            "1": 0.20754716981132076,
            "2": 0.46938775510204084,
            "3": 0.8028169014084507
        },
        "meteor": 0.3552414844341843,
        "nubia": {
            "semantic_relation": 3.71923,
            "contradiction": 1.1066,
            "irrelevancy": 45.70088,
            "logical_agreement": 53.19252,
            "grammar_ref": 4.84583,
            "grammar_hyp": 4.739,
            "nubia_score": 0.60744
        },
        "bleurt": 0.09807,
        "bertscore": {
            "precision": 0.89272,
            "recall": 0.91224,
            "f1": 0.8993
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.94247,
        "nist": 4.555196620341767,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.92584,
            "fmeasure": 0.81527
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.74961,
            "fmeasure": 0.68325
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.90848,
            "fmeasure": 0.81074
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.90848,
            "fmeasure": 0.81074
        },
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.0,
            "3": 0.9473684210526315
        },
        "meteor": 0.554721158816585,
        "nubia": {
            "semantic_relation": 4.88669,
            "contradiction": 0.31729,
            "irrelevancy": 29.16131,
            "logical_agreement": 70.52139,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.29491,
            "nubia_score": 0.7858
        },
        "bleurt": 0.68014,
        "bertscore": {
            "precision": 0.95035,
            "recall": 0.97955,
            "f1": 0.96449
        }
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 105,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.05963,
        "nist": 7.592202343122797,
        "rouge1": {
            "precision": 0.77866,
            "recall": 0.75458,
            "fmeasure": 0.75648
        },
        "rouge2": {
            "precision": 0.52733,
            "recall": 0.50874,
            "fmeasure": 0.5108
        },
        "rougeL": {
            "precision": 0.6617,
            "recall": 0.64126,
            "fmeasure": 0.64296
        },
        "rougeLsum": {
            "precision": 0.6617,
            "recall": 0.64126,
            "fmeasure": 0.64296
        },
        "local_recall": {
            "1": 0.24367088607594936,
            "2": 0.326271186440678,
            "3": 0.7754056362083689
        },
        "meteor": 0.3856617074586553,
        "nubia": {
            "semantic_relation": 4.44378,
            "contradiction": 3.67109,
            "irrelevancy": 25.66041,
            "logical_agreement": 70.6685,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.07259,
            "nubia_score": 0.7861
        },
        "bleurt": 0.35919,
        "bertscore": {
            "precision": 0.93333,
            "recall": 0.93184,
            "f1": 0.93149
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.25743,
        "nist": 5.345656720002249,
        "rouge1": {
            "precision": 0.77786,
            "recall": 0.85201,
            "fmeasure": 0.8007
        },
        "rouge2": {
            "precision": 0.5628,
            "recall": 0.59136,
            "fmeasure": 0.56615
        },
        "rougeL": {
            "precision": 0.63128,
            "recall": 0.73449,
            "fmeasure": 0.66655
        },
        "rougeLsum": {
            "precision": 0.63128,
            "recall": 0.73449,
            "fmeasure": 0.66655
        },
        "local_recall": {
            "1": 0.0625,
            "2": 0.5,
            "3": 0.8415841584158416
        },
        "meteor": 0.446029235785338,
        "nubia": {
            "semantic_relation": 4.43089,
            "contradiction": 2.94925,
            "irrelevancy": 26.57275,
            "logical_agreement": 70.478,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.43194,
            "nubia_score": 0.84676
        },
        "bleurt": 0.48211,
        "bertscore": {
            "precision": 0.93884,
            "recall": 0.94972,
            "f1": 0.94346
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 61,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.53688,
        "nist": 6.797733415782011,
        "rouge1": {
            "precision": 0.69668,
            "recall": 0.67709,
            "fmeasure": 0.67698
        },
        "rouge2": {
            "precision": 0.40185,
            "recall": 0.39652,
            "fmeasure": 0.3937
        },
        "rougeL": {
            "precision": 0.52526,
            "recall": 0.51373,
            "fmeasure": 0.51191
        },
        "rougeLsum": {
            "precision": 0.52526,
            "recall": 0.51373,
            "fmeasure": 0.51191
        },
        "local_recall": {
            "1": 0.1989247311827957,
            "2": 0.4343891402714932,
            "3": 0.7160751565762005
        },
        "meteor": 0.34350859699652325,
        "nubia": {
            "semantic_relation": 3.91315,
            "contradiction": 12.51269,
            "irrelevancy": 30.8622,
            "logical_agreement": 56.62511,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.22112,
            "nubia_score": 0.65884
        },
        "bleurt": 0.10221,
        "bertscore": {
            "precision": 0.90765,
            "recall": 0.90468,
            "f1": 0.90505
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.38363,
        "nist": 3.357407650952167,
        "rouge1": {
            "precision": 0.74762,
            "recall": 0.63933,
            "fmeasure": 0.62713
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.29581,
            "fmeasure": 0.29809
        },
        "rougeL": {
            "precision": 0.47857,
            "recall": 0.41367,
            "fmeasure": 0.39708
        },
        "rougeLsum": {
            "precision": 0.47857,
            "recall": 0.41367,
            "fmeasure": 0.39708
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "meteor": 0.3211279092581693,
        "nubia": {
            "semantic_relation": 4.10913,
            "contradiction": 0.24484,
            "irrelevancy": 47.36385,
            "logical_agreement": 52.39131,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.81882,
            "nubia_score": 0.62323
        },
        "bleurt": 0.16891,
        "bertscore": {
            "precision": 0.92246,
            "recall": 0.91105,
            "f1": 0.91383
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 11,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.59953,
        "nist": 5.675286963538773,
        "rouge1": {
            "precision": 0.79008,
            "recall": 0.78299,
            "fmeasure": 0.77079
        },
        "rouge2": {
            "precision": 0.55029,
            "recall": 0.55271,
            "fmeasure": 0.53706
        },
        "rougeL": {
            "precision": 0.68388,
            "recall": 0.6698,
            "fmeasure": 0.66183
        },
        "rougeLsum": {
            "precision": 0.68388,
            "recall": 0.6698,
            "fmeasure": 0.66183
        },
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.47368421052631576,
            "3": 0.8225806451612904
        },
        "meteor": 0.4139897792026048,
        "nubia": {
            "semantic_relation": 4.73159,
            "contradiction": 3.28768,
            "irrelevancy": 17.78928,
            "logical_agreement": 78.92304,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.42809,
            "nubia_score": 0.90381
        },
        "bleurt": 0.51894,
        "bertscore": {
            "precision": 0.94257,
            "recall": 0.93387,
            "f1": 0.9364
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 20,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.46033,
        "nist": 6.367893202855637,
        "rouge1": {
            "precision": 0.80813,
            "recall": 0.81298,
            "fmeasure": 0.79869
        },
        "rouge2": {
            "precision": 0.64709,
            "recall": 0.65057,
            "fmeasure": 0.63814
        },
        "rougeL": {
            "precision": 0.69714,
            "recall": 0.70204,
            "fmeasure": 0.68963
        },
        "rougeLsum": {
            "precision": 0.69714,
            "recall": 0.70204,
            "fmeasure": 0.68963
        },
        "local_recall": {
            "1": 0.22972972972972974,
            "2": 0.47692307692307695,
            "3": 0.8421052631578947
        },
        "meteor": 0.4311396250358304,
        "nubia": {
            "semantic_relation": 4.20523,
            "contradiction": 10.18862,
            "irrelevancy": 17.78097,
            "logical_agreement": 72.03041,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.45483,
            "nubia_score": 0.73959
        },
        "bleurt": 0.34513,
        "bertscore": {
            "precision": 0.94408,
            "recall": 0.94364,
            "f1": 0.94188
        }
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 79,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.92528,
        "nist": 7.888181582066016,
        "rouge1": {
            "precision": 0.81151,
            "recall": 0.79101,
            "fmeasure": 0.79555
        },
        "rouge2": {
            "precision": 0.58923,
            "recall": 0.57761,
            "fmeasure": 0.57913
        },
        "rougeL": {
            "precision": 0.67278,
            "recall": 0.65771,
            "fmeasure": 0.66096
        },
        "rougeLsum": {
            "precision": 0.67278,
            "recall": 0.65771,
            "fmeasure": 0.66096
        },
        "local_recall": {
            "1": 0.20833333333333334,
            "2": 0.42718446601941745,
            "3": 0.8122977346278317
        },
        "meteor": 0.4188460334869402,
        "nubia": {
            "semantic_relation": 4.43683,
            "contradiction": 6.61626,
            "irrelevancy": 21.31586,
            "logical_agreement": 72.06787,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.76815,
            "nubia_score": 0.79677
        },
        "bleurt": 0.43784,
        "bertscore": {
            "precision": 0.94668,
            "recall": 0.9432,
            "f1": 0.9437
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.84688,
        "nist": 4.468820450428324,
        "rouge1": {
            "precision": 0.77896,
            "recall": 0.77328,
            "fmeasure": 0.77228
        },
        "rouge2": {
            "precision": 0.51716,
            "recall": 0.50784,
            "fmeasure": 0.50917
        },
        "rougeL": {
            "precision": 0.72896,
            "recall": 0.72566,
            "fmeasure": 0.72356
        },
        "rougeLsum": {
            "precision": 0.72896,
            "recall": 0.72566,
            "fmeasure": 0.72356
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.625,
            "3": 0.7368421052631579
        },
        "meteor": 0.4296248755329404,
        "nubia": {
            "semantic_relation": 4.3812,
            "contradiction": 0.46321,
            "irrelevancy": 52.56271,
            "logical_agreement": 46.97408,
            "grammar_ref": 5.90284,
            "grammar_hyp": 4.84224,
            "nubia_score": 0.86346
        },
        "bleurt": 0.30348,
        "bertscore": {
            "precision": 0.92844,
            "recall": 0.9267,
            "f1": 0.92754
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 40,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.08308,
        "nist": 7.077517288812474,
        "rouge1": {
            "precision": 0.75372,
            "recall": 0.7171,
            "fmeasure": 0.72415
        },
        "rouge2": {
            "precision": 0.5038,
            "recall": 0.4795,
            "fmeasure": 0.48495
        },
        "rougeL": {
            "precision": 0.5921,
            "recall": 0.57034,
            "fmeasure": 0.57234
        },
        "rougeLsum": {
            "precision": 0.5921,
            "recall": 0.57034,
            "fmeasure": 0.57234
        },
        "local_recall": {
            "1": 0.19863013698630136,
            "2": 0.46153846153846156,
            "3": 0.7763975155279503
        },
        "meteor": 0.37466341078848847,
        "nubia": {
            "semantic_relation": 4.05332,
            "contradiction": 13.99421,
            "irrelevancy": 25.42658,
            "logical_agreement": 60.57921,
            "grammar_ref": 4.29053,
            "grammar_hyp": 4.1137,
            "nubia_score": 0.69065
        },
        "bleurt": 0.18258,
        "bertscore": {
            "precision": 0.92073,
            "recall": 0.91918,
            "f1": 0.91783
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.74689,
        "nist": 5.249273650720712,
        "rouge1": {
            "precision": 0.73438,
            "recall": 0.78817,
            "fmeasure": 0.74978
        },
        "rouge2": {
            "precision": 0.47475,
            "recall": 0.53443,
            "fmeasure": 0.49296
        },
        "rougeL": {
            "precision": 0.61658,
            "recall": 0.68863,
            "fmeasure": 0.64066
        },
        "rougeLsum": {
            "precision": 0.61658,
            "recall": 0.68863,
            "fmeasure": 0.64066
        },
        "local_recall": {
            "1": 0.2962962962962963,
            "2": 0.5333333333333333,
            "3": 0.7692307692307693
        },
        "meteor": 0.4073950344462754,
        "nubia": {
            "semantic_relation": 4.11197,
            "contradiction": 6.36029,
            "irrelevancy": 34.32319,
            "logical_agreement": 59.31652,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.22895,
            "nubia_score": 0.75817
        },
        "bleurt": 0.3242,
        "bertscore": {
            "precision": 0.93948,
            "recall": 0.94382,
            "f1": 0.93854
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 131,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.24582,
        "nist": 7.747207928824125,
        "rouge1": {
            "precision": 0.75928,
            "recall": 0.72562,
            "fmeasure": 0.73097
        },
        "rouge2": {
            "precision": 0.51211,
            "recall": 0.48795,
            "fmeasure": 0.49177
        },
        "rougeL": {
            "precision": 0.64132,
            "recall": 0.61157,
            "fmeasure": 0.61648
        },
        "rougeLsum": {
            "precision": 0.64132,
            "recall": 0.61157,
            "fmeasure": 0.61648
        },
        "local_recall": {
            "1": 0.23872679045092837,
            "2": 0.49038461538461536,
            "3": 0.7349228611500701
        },
        "meteor": 0.3818971932993421,
        "nubia": {
            "semantic_relation": 4.19721,
            "contradiction": 8.66271,
            "irrelevancy": 26.72441,
            "logical_agreement": 64.61288,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.69015,
            "nubia_score": 0.71424
        },
        "bleurt": 0.25106,
        "bertscore": {
            "precision": 0.92836,
            "recall": 0.92239,
            "f1": 0.92397
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.40156,
        "nist": 5.407835666776347,
        "rouge1": {
            "precision": 0.78623,
            "recall": 0.75976,
            "fmeasure": 0.75365
        },
        "rouge2": {
            "precision": 0.54552,
            "recall": 0.52127,
            "fmeasure": 0.52273
        },
        "rougeL": {
            "precision": 0.59372,
            "recall": 0.56228,
            "fmeasure": 0.56484
        },
        "rougeLsum": {
            "precision": 0.59372,
            "recall": 0.56228,
            "fmeasure": 0.56484
        },
        "local_recall": {
            "1": 0.21739130434782608,
            "2": 0.34615384615384615,
            "3": 0.8076923076923077
        },
        "meteor": 0.3902612982942364,
        "nubia": {
            "semantic_relation": 4.37828,
            "contradiction": 2.88328,
            "irrelevancy": 28.6056,
            "logical_agreement": 68.51112,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.69101,
            "nubia_score": 0.74424
        },
        "bleurt": 0.30593,
        "bertscore": {
            "precision": 0.927,
            "recall": 0.93062,
            "f1": 0.92778
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 20,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.55505,
        "nist": 5.932091617362247,
        "rouge1": {
            "precision": 0.65444,
            "recall": 0.66887,
            "fmeasure": 0.64915
        },
        "rouge2": {
            "precision": 0.40344,
            "recall": 0.42077,
            "fmeasure": 0.40312
        },
        "rougeL": {
            "precision": 0.49877,
            "recall": 0.53565,
            "fmeasure": 0.5019
        },
        "rougeLsum": {
            "precision": 0.49877,
            "recall": 0.53565,
            "fmeasure": 0.5019
        },
        "local_recall": {
            "1": 0.22988505747126436,
            "2": 0.38461538461538464,
            "3": 0.7710843373493976
        },
        "meteor": 0.35796005867810654,
        "nubia": {
            "semantic_relation": 3.67954,
            "contradiction": 12.10575,
            "irrelevancy": 34.63007,
            "logical_agreement": 53.26418,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.14283,
            "nubia_score": 0.58675
        },
        "bleurt": -0.01201,
        "bertscore": {
            "precision": 0.89523,
            "recall": 0.89666,
            "f1": 0.8904
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 10,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 67.37528,
        "nist": 5.928380855910103,
        "rouge1": {
            "precision": 0.84673,
            "recall": 0.88994,
            "fmeasure": 0.86331
        },
        "rouge2": {
            "precision": 0.69661,
            "recall": 0.72026,
            "fmeasure": 0.70616
        },
        "rougeL": {
            "precision": 0.80258,
            "recall": 0.83606,
            "fmeasure": 0.81502
        },
        "rougeLsum": {
            "precision": 0.80258,
            "recall": 0.83606,
            "fmeasure": 0.81502
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.18181818181818182,
            "3": 0.9245283018867925
        },
        "meteor": 0.5246092280408422,
        "nubia": {
            "semantic_relation": 4.80684,
            "contradiction": 0.25486,
            "irrelevancy": 12.00304,
            "logical_agreement": 87.74211,
            "grammar_ref": 5.03704,
            "grammar_hyp": 4.905,
            "nubia_score": 0.93334
        },
        "bleurt": 0.71956,
        "bertscore": {
            "precision": 0.96773,
            "recall": 0.97081,
            "f1": 0.96857
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 26,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.19012,
        "nist": 6.730276847074037,
        "rouge1": {
            "precision": 0.74438,
            "recall": 0.71367,
            "fmeasure": 0.71495
        },
        "rouge2": {
            "precision": 0.48912,
            "recall": 0.46982,
            "fmeasure": 0.47102
        },
        "rougeL": {
            "precision": 0.60395,
            "recall": 0.57476,
            "fmeasure": 0.57789
        },
        "rougeLsum": {
            "precision": 0.60395,
            "recall": 0.57476,
            "fmeasure": 0.57789
        },
        "local_recall": {
            "1": 0.225,
            "2": 0.3697478991596639,
            "3": 0.788546255506608
        },
        "meteor": 0.3771119080741869,
        "nubia": {
            "semantic_relation": 3.89093,
            "contradiction": 10.24941,
            "irrelevancy": 29.90397,
            "logical_agreement": 59.84663,
            "grammar_ref": 4.04917,
            "grammar_hyp": 4.01974,
            "nubia_score": 0.63383
        },
        "bleurt": 0.11567,
        "bertscore": {
            "precision": 0.91474,
            "recall": 0.91291,
            "f1": 0.91142
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.55576,
        "nist": 4.341019135468263,
        "rouge1": {
            "precision": 0.71474,
            "recall": 0.78386,
            "fmeasure": 0.74081
        },
        "rouge2": {
            "precision": 0.46528,
            "recall": 0.52253,
            "fmeasure": 0.48368
        },
        "rougeL": {
            "precision": 0.66798,
            "recall": 0.74536,
            "fmeasure": 0.69512
        },
        "rougeLsum": {
            "precision": 0.66798,
            "recall": 0.74536,
            "fmeasure": 0.69512
        },
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.7333333333333333,
            "3": 0.8787878787878788
        },
        "meteor": 0.42157263052650557,
        "nubia": {
            "semantic_relation": 3.72346,
            "contradiction": 17.86375,
            "irrelevancy": 29.2991,
            "logical_agreement": 52.83715,
            "grammar_ref": 5.1808,
            "grammar_hyp": 5.02721,
            "nubia_score": 0.60289
        },
        "bleurt": 0.0609,
        "bertscore": {
            "precision": 0.90391,
            "recall": 0.91555,
            "f1": 0.90944
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.38272,
        "nist": 3.6068322697936237,
        "rouge1": {
            "precision": 0.63784,
            "recall": 0.73044,
            "fmeasure": 0.64289
        },
        "rouge2": {
            "precision": 0.47155,
            "recall": 0.51567,
            "fmeasure": 0.46186
        },
        "rougeL": {
            "precision": 0.61007,
            "recall": 0.69919,
            "fmeasure": 0.61348
        },
        "rougeLsum": {
            "precision": 0.61007,
            "recall": 0.69919,
            "fmeasure": 0.61348
        },
        "local_recall": {
            "1": 0.6,
            "2": 0.4166666666666667,
            "3": 0.75
        },
        "meteor": 0.3814418383751919,
        "nubia": {
            "semantic_relation": 3.69232,
            "contradiction": 20.54003,
            "irrelevancy": 44.24019,
            "logical_agreement": 35.21978,
            "grammar_ref": 4.25456,
            "grammar_hyp": 4.0253,
            "nubia_score": 0.606
        },
        "bleurt": 0.03826,
        "bertscore": {
            "precision": 0.89076,
            "recall": 0.90672,
            "f1": 0.89708
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 10,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.92397,
        "nist": 5.177631793336139,
        "rouge1": {
            "precision": 0.67303,
            "recall": 0.67318,
            "fmeasure": 0.65128
        },
        "rouge2": {
            "precision": 0.42333,
            "recall": 0.442,
            "fmeasure": 0.41776
        },
        "rougeL": {
            "precision": 0.51861,
            "recall": 0.52593,
            "fmeasure": 0.50648
        },
        "rougeLsum": {
            "precision": 0.51861,
            "recall": 0.52593,
            "fmeasure": 0.50648
        },
        "local_recall": {
            "1": 0.1506849315068493,
            "2": 0.3898305084745763,
            "3": 0.7397260273972602
        },
        "meteor": 0.35850811692250195,
        "nubia": {
            "semantic_relation": 3.64456,
            "contradiction": 14.89335,
            "irrelevancy": 34.64921,
            "logical_agreement": 50.45744,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.26378,
            "nubia_score": 0.55694
        },
        "bleurt": -0.03575,
        "bertscore": {
            "precision": 0.91049,
            "recall": 0.90371,
            "f1": 0.90379
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 39,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.9382,
        "nist": 7.308665967421585,
        "rouge1": {
            "precision": 0.79742,
            "recall": 0.7237,
            "fmeasure": 0.74949
        },
        "rouge2": {
            "precision": 0.55797,
            "recall": 0.51205,
            "fmeasure": 0.52766
        },
        "rougeL": {
            "precision": 0.6767,
            "recall": 0.6259,
            "fmeasure": 0.64236
        },
        "rougeLsum": {
            "precision": 0.6767,
            "recall": 0.6259,
            "fmeasure": 0.64236
        },
        "local_recall": {
            "1": 0.17293233082706766,
            "2": 0.6613756613756614,
            "3": 0.771712158808933
        },
        "meteor": 0.40962712020777226,
        "nubia": {
            "semantic_relation": 4.19066,
            "contradiction": 7.8892,
            "irrelevancy": 26.71983,
            "logical_agreement": 65.39097,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.25448,
            "nubia_score": 0.73684
        },
        "bleurt": 0.33319,
        "bertscore": {
            "precision": 0.93634,
            "recall": 0.92743,
            "f1": 0.93082
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.56147,
        "nist": 4.175903201790395,
        "rouge1": {
            "precision": 0.80025,
            "recall": 0.68494,
            "fmeasure": 0.73747
        },
        "rouge2": {
            "precision": 0.50149,
            "recall": 0.4537,
            "fmeasure": 0.47492
        },
        "rougeL": {
            "precision": 0.71201,
            "recall": 0.66365,
            "fmeasure": 0.68423
        },
        "rougeLsum": {
            "precision": 0.71201,
            "recall": 0.66365,
            "fmeasure": 0.68423
        },
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.4,
            "3": 0.9285714285714286
        },
        "meteor": 0.4234791433525808,
        "nubia": {
            "semantic_relation": 4.34869,
            "contradiction": 0.20328,
            "irrelevancy": 0.8291,
            "logical_agreement": 98.96762,
            "grammar_ref": 4.57807,
            "grammar_hyp": 4.68427,
            "nubia_score": 0.81563
        },
        "bleurt": 0.46354,
        "bertscore": {
            "precision": 0.96168,
            "recall": 0.94401,
            "f1": 0.95047
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 14,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.61257,
        "nist": 5.317382482758853,
        "rouge1": {
            "precision": 0.63602,
            "recall": 0.70123,
            "fmeasure": 0.65858
        },
        "rouge2": {
            "precision": 0.39317,
            "recall": 0.43663,
            "fmeasure": 0.40808
        },
        "rougeL": {
            "precision": 0.54947,
            "recall": 0.60604,
            "fmeasure": 0.5689
        },
        "rougeLsum": {
            "precision": 0.54947,
            "recall": 0.60604,
            "fmeasure": 0.5689
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.4782608695652174,
            "3": 0.7288135593220338
        },
        "meteor": 0.3691843877660149,
        "nubia": {
            "semantic_relation": 3.77549,
            "contradiction": 17.51048,
            "irrelevancy": 25.84191,
            "logical_agreement": 56.64761,
            "grammar_ref": 4.37064,
            "grammar_hyp": 4.07514,
            "nubia_score": 0.61709
        },
        "bleurt": 0.13955,
        "bertscore": {
            "precision": 0.90332,
            "recall": 0.91754,
            "f1": 0.90981
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.76996,
        "nist": 4.771589562841643,
        "rouge1": {
            "precision": 0.69829,
            "recall": 0.66241,
            "fmeasure": 0.66715
        },
        "rouge2": {
            "precision": 0.49223,
            "recall": 0.45025,
            "fmeasure": 0.46108
        },
        "rougeL": {
            "precision": 0.59047,
            "recall": 0.55703,
            "fmeasure": 0.56495
        },
        "rougeLsum": {
            "precision": 0.59047,
            "recall": 0.55703,
            "fmeasure": 0.56495
        },
        "local_recall": {
            "1": 0.46153846153846156,
            "2": 0.5925925925925926,
            "3": 0.6461538461538462
        },
        "meteor": 0.33328253109535794,
        "nubia": {
            "semantic_relation": 4.12837,
            "contradiction": 8.65686,
            "irrelevancy": 34.70961,
            "logical_agreement": 56.63353,
            "grammar_ref": 4.57813,
            "grammar_hyp": 4.2397,
            "nubia_score": 0.69831
        },
        "bleurt": 0.16877,
        "bertscore": {
            "precision": 0.9179,
            "recall": 0.91599,
            "f1": 0.9163
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.43851,
        "nist": 3.3472913635898944,
        "rouge1": {
            "precision": 0.70009,
            "recall": 0.57521,
            "fmeasure": 0.61543
        },
        "rouge2": {
            "precision": 0.45194,
            "recall": 0.3625,
            "fmeasure": 0.39289
        },
        "rougeL": {
            "precision": 0.60577,
            "recall": 0.49533,
            "fmeasure": 0.53222
        },
        "rougeLsum": {
            "precision": 0.60577,
            "recall": 0.49533,
            "fmeasure": 0.53222
        },
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.16666666666666666,
            "3": 0.625
        },
        "meteor": 0.30442779573330686,
        "nubia": {
            "semantic_relation": 4.09033,
            "contradiction": 0.50916,
            "irrelevancy": 44.13728,
            "logical_agreement": 55.35356,
            "grammar_ref": 4.84918,
            "grammar_hyp": 5.65402,
            "nubia_score": 0.64223
        },
        "bleurt": 0.17941,
        "bertscore": {
            "precision": 0.93805,
            "recall": 0.90548,
            "f1": 0.92032
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 69.2262,
        "nist": 5.619242560494988,
        "rouge1": {
            "precision": 0.86897,
            "recall": 0.86641,
            "fmeasure": 0.86537
        },
        "rouge2": {
            "precision": 0.76721,
            "recall": 0.75732,
            "fmeasure": 0.76037
        },
        "rougeL": {
            "precision": 0.84056,
            "recall": 0.82344,
            "fmeasure": 0.83023
        },
        "rougeLsum": {
            "precision": 0.84056,
            "recall": 0.82344,
            "fmeasure": 0.83023
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.16666666666666666,
            "3": 0.9012345679012346
        },
        "meteor": 0.5090114509706886,
        "nubia": {
            "semantic_relation": 4.4718,
            "contradiction": 0.60953,
            "irrelevancy": 22.10255,
            "logical_agreement": 77.28792,
            "grammar_ref": 5.07225,
            "grammar_hyp": 4.94126,
            "nubia_score": 0.86079
        },
        "bleurt": 0.63576,
        "bertscore": {
            "precision": 0.96198,
            "recall": 0.96032,
            "f1": 0.96098
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 13,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.75956,
        "nist": 5.482616093729549,
        "rouge1": {
            "precision": 0.74753,
            "recall": 0.7381,
            "fmeasure": 0.73388
        },
        "rouge2": {
            "precision": 0.5445,
            "recall": 0.53794,
            "fmeasure": 0.5335
        },
        "rougeL": {
            "precision": 0.63204,
            "recall": 0.61944,
            "fmeasure": 0.61773
        },
        "rougeLsum": {
            "precision": 0.63204,
            "recall": 0.61944,
            "fmeasure": 0.61773
        },
        "local_recall": {
            "1": 0.08823529411764706,
            "2": 0.5882352941176471,
            "3": 0.7804878048780488
        },
        "meteor": 0.4027542942753139,
        "nubia": {
            "semantic_relation": 4.09336,
            "contradiction": 4.6413,
            "irrelevancy": 33.40263,
            "logical_agreement": 61.95607,
            "grammar_ref": 4.86507,
            "grammar_hyp": 4.73984,
            "nubia_score": 0.71832
        },
        "bleurt": 0.20453,
        "bertscore": {
            "precision": 0.91294,
            "recall": 0.91128,
            "f1": 0.91097
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.37803,
        "nist": 4.548010068075705,
        "rouge1": {
            "precision": 0.725,
            "recall": 0.69883,
            "fmeasure": 0.70524
        },
        "rouge2": {
            "precision": 0.45994,
            "recall": 0.43909,
            "fmeasure": 0.44366
        },
        "rougeL": {
            "precision": 0.62083,
            "recall": 0.58992,
            "fmeasure": 0.5987
        },
        "rougeLsum": {
            "precision": 0.62083,
            "recall": 0.58992,
            "fmeasure": 0.5987
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 0.75
        },
        "meteor": 0.3828305910360917,
        "nubia": {
            "semantic_relation": 4.31904,
            "contradiction": 24.07681,
            "irrelevancy": 1.62296,
            "logical_agreement": 74.30023,
            "grammar_ref": 4.90076,
            "grammar_hyp": 5.06733,
            "nubia_score": 0.76016
        },
        "bleurt": 0.12599,
        "bertscore": {
            "precision": 0.92487,
            "recall": 0.91897,
            "f1": 0.92164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.70785,
        "nist": 4.124405913615812,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.88129,
            "fmeasure": 0.7969
        },
        "rouge2": {
            "precision": 0.5884,
            "recall": 0.72028,
            "fmeasure": 0.64344
        },
        "rougeL": {
            "precision": 0.64815,
            "recall": 0.76703,
            "fmeasure": 0.69915
        },
        "rougeLsum": {
            "precision": 0.64815,
            "recall": 0.76703,
            "fmeasure": 0.69915
        },
        "local_recall": {
            "1": 0.8571428571428571,
            "2": 0.4,
            "3": 0.896551724137931
        },
        "meteor": 0.5113292483956289,
        "nubia": {
            "semantic_relation": 4.22406,
            "contradiction": 0.40187,
            "irrelevancy": 54.52453,
            "logical_agreement": 45.07361,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.21921,
            "nubia_score": 0.76378
        },
        "bleurt": 0.24872,
        "bertscore": {
            "precision": 0.93227,
            "recall": 0.9601,
            "f1": 0.94445
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 83,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.51272,
        "nist": 7.64064364696601,
        "rouge1": {
            "precision": 0.75071,
            "recall": 0.74895,
            "fmeasure": 0.73924
        },
        "rouge2": {
            "precision": 0.52504,
            "recall": 0.52091,
            "fmeasure": 0.51551
        },
        "rougeL": {
            "precision": 0.64659,
            "recall": 0.64654,
            "fmeasure": 0.63775
        },
        "rougeLsum": {
            "precision": 0.64659,
            "recall": 0.64654,
            "fmeasure": 0.63775
        },
        "local_recall": {
            "1": 0.25806451612903225,
            "2": 0.540650406504065,
            "3": 0.7799145299145299
        },
        "meteor": 0.40125358455454807,
        "nubia": {
            "semantic_relation": 4.29578,
            "contradiction": 6.96932,
            "irrelevancy": 28.47527,
            "logical_agreement": 64.55541,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.55576,
            "nubia_score": 0.75365
        },
        "bleurt": 0.31748,
        "bertscore": {
            "precision": 0.9303,
            "recall": 0.92845,
            "f1": 0.92791
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 14,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.32867,
        "nist": 4.679322561144562,
        "rouge1": {
            "precision": 0.58456,
            "recall": 0.57083,
            "fmeasure": 0.56603
        },
        "rouge2": {
            "precision": 0.29084,
            "recall": 0.28573,
            "fmeasure": 0.28209
        },
        "rougeL": {
            "precision": 0.43829,
            "recall": 0.44302,
            "fmeasure": 0.43228
        },
        "rougeLsum": {
            "precision": 0.43829,
            "recall": 0.44302,
            "fmeasure": 0.43228
        },
        "local_recall": {
            "1": 0.30952380952380953,
            "2": 0.20588235294117646,
            "3": 0.5931558935361216
        },
        "meteor": 0.2756616861729878,
        "nubia": {
            "semantic_relation": 3.52632,
            "contradiction": 17.79294,
            "irrelevancy": 40.51521,
            "logical_agreement": 41.69185,
            "grammar_ref": 3.91022,
            "grammar_hyp": 3.96717,
            "nubia_score": 0.57344
        },
        "bleurt": -0.12244,
        "bertscore": {
            "precision": 0.87108,
            "recall": 0.86732,
            "f1": 0.86766
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.00938,
        "nist": 2.3936047624864267,
        "rouge1": {
            "precision": 0.45238,
            "recall": 0.43732,
            "fmeasure": 0.44213
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.44444,
            "fmeasure": 0.39365
        },
        "rougeL": {
            "precision": 0.40476,
            "recall": 0.49288,
            "fmeasure": 0.44122
        },
        "rougeLsum": {
            "precision": 0.40476,
            "recall": 0.49288,
            "fmeasure": 0.44122
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 1.0,
            "3": 0.5714285714285714
        },
        "meteor": 0.30036399762261334,
        "nubia": {
            "semantic_relation": 1.51614,
            "contradiction": 95.66057,
            "irrelevancy": 3.91165,
            "logical_agreement": 0.42778,
            "grammar_ref": 4.13721,
            "grammar_hyp": 3.28719,
            "nubia_score": 0.13516
        },
        "bleurt": -0.20978,
        "bertscore": {
            "precision": 0.84533,
            "recall": 0.88079,
            "f1": 0.85417
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 25,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.20048,
        "nist": 6.592856170362962,
        "rouge1": {
            "precision": 0.75739,
            "recall": 0.78574,
            "fmeasure": 0.7627
        },
        "rouge2": {
            "precision": 0.53489,
            "recall": 0.54623,
            "fmeasure": 0.53432
        },
        "rougeL": {
            "precision": 0.64665,
            "recall": 0.66872,
            "fmeasure": 0.65155
        },
        "rougeLsum": {
            "precision": 0.64665,
            "recall": 0.66872,
            "fmeasure": 0.65155
        },
        "local_recall": {
            "1": 0.22826086956521738,
            "2": 0.453125,
            "3": 0.8100358422939068
        },
        "meteor": 0.41758810592843465,
        "nubia": {
            "semantic_relation": 4.3358,
            "contradiction": 5.23268,
            "irrelevancy": 25.0743,
            "logical_agreement": 69.69302,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.56037,
            "nubia_score": 0.78336
        },
        "bleurt": 0.33876,
        "bertscore": {
            "precision": 0.93529,
            "recall": 0.9393,
            "f1": 0.93492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 12,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.51432,
        "nist": 5.461665949354769,
        "rouge1": {
            "precision": 0.74597,
            "recall": 0.69443,
            "fmeasure": 0.71414
        },
        "rouge2": {
            "precision": 0.4898,
            "recall": 0.45377,
            "fmeasure": 0.46744
        },
        "rougeL": {
            "precision": 0.57502,
            "recall": 0.539,
            "fmeasure": 0.55311
        },
        "rougeLsum": {
            "precision": 0.57502,
            "recall": 0.539,
            "fmeasure": 0.55311
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.4,
            "3": 0.7538461538461538
        },
        "meteor": 0.3593515751342971,
        "nubia": {
            "semantic_relation": 4.08155,
            "contradiction": 5.23874,
            "irrelevancy": 30.26032,
            "logical_agreement": 64.50094,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.3775,
            "nubia_score": 0.76567
        },
        "bleurt": 0.23202,
        "bertscore": {
            "precision": 0.92667,
            "recall": 0.92063,
            "f1": 0.92292
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.32063,
        "nist": 5.481946427262348,
        "rouge1": {
            "precision": 0.76044,
            "recall": 0.65857,
            "fmeasure": 0.69465
        },
        "rouge2": {
            "precision": 0.4723,
            "recall": 0.44585,
            "fmeasure": 0.45203
        },
        "rougeL": {
            "precision": 0.60454,
            "recall": 0.55213,
            "fmeasure": 0.56791
        },
        "rougeLsum": {
            "precision": 0.60454,
            "recall": 0.55213,
            "fmeasure": 0.56791
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.48333333333333334,
            "3": 0.7717391304347826
        },
        "meteor": 0.35742312578631186,
        "nubia": {
            "semantic_relation": 3.24875,
            "contradiction": 41.79067,
            "irrelevancy": 37.1694,
            "logical_agreement": 21.03994,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.45158,
            "nubia_score": 0.44803
        },
        "bleurt": 0.00241,
        "bertscore": {
            "precision": 0.92488,
            "recall": 0.89882,
            "f1": 0.90871
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.94357,
        "nist": 3.5360276044371006,
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.55754,
            "fmeasure": 0.5901
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.29524,
            "fmeasure": 0.32018
        },
        "rougeL": {
            "precision": 0.58974,
            "recall": 0.49405,
            "fmeasure": 0.51167
        },
        "rougeLsum": {
            "precision": 0.58974,
            "recall": 0.49405,
            "fmeasure": 0.51167
        },
        "local_recall": {
            "1": 0.625,
            "2": 0.0,
            "3": 0.625
        },
        "meteor": 0.28443334970803846,
        "nubia": {
            "semantic_relation": 4.23909,
            "contradiction": 2.95245,
            "irrelevancy": 66.39995,
            "logical_agreement": 30.6476,
            "grammar_ref": 5.89248,
            "grammar_hyp": 6.62487,
            "nubia_score": 0.5444
        },
        "bleurt": 0.03973,
        "bertscore": {
            "precision": 0.91129,
            "recall": 0.93731,
            "f1": 0.89683
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.57867,
        "nist": 2.023720454115748,
        "rouge1": {
            "precision": 0.68182,
            "recall": 0.81871,
            "fmeasure": 0.7439
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.46187,
            "fmeasure": 0.41745
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.49123,
            "fmeasure": 0.44634
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.49123,
            "fmeasure": 0.44634
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "meteor": 0.3740991464153029,
        "nubia": {
            "semantic_relation": 4.98103,
            "contradiction": 0.09233,
            "irrelevancy": 1.01049,
            "logical_agreement": 98.89718,
            "grammar_ref": 4.92793,
            "grammar_hyp": 3.84651,
            "nubia_score": 1.0
        },
        "bleurt": 0.44417,
        "bertscore": {
            "precision": 0.87461,
            "recall": 0.91386,
            "f1": 0.89367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 26,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.99461,
        "nist": 6.084892846684016,
        "rouge1": {
            "precision": 0.70822,
            "recall": 0.72973,
            "fmeasure": 0.70377
        },
        "rouge2": {
            "precision": 0.49537,
            "recall": 0.49884,
            "fmeasure": 0.4849
        },
        "rougeL": {
            "precision": 0.64642,
            "recall": 0.66489,
            "fmeasure": 0.64124
        },
        "rougeLsum": {
            "precision": 0.64642,
            "recall": 0.66489,
            "fmeasure": 0.64124
        },
        "local_recall": {
            "1": 0.26436781609195403,
            "2": 0.5483870967741935,
            "3": 0.7424892703862661
        },
        "meteor": 0.3576958091022517,
        "nubia": {
            "semantic_relation": 3.73694,
            "contradiction": 13.16654,
            "irrelevancy": 44.75794,
            "logical_agreement": 42.07552,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.569,
            "nubia_score": 0.59723
        },
        "bleurt": 0.08727,
        "bertscore": {
            "precision": 0.91034,
            "recall": 0.91025,
            "f1": 0.90898
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.76949,
        "nist": 5.560570344520202,
        "rouge1": {
            "precision": 0.74003,
            "recall": 0.67097,
            "fmeasure": 0.69994
        },
        "rouge2": {
            "precision": 0.55494,
            "recall": 0.51451,
            "fmeasure": 0.5311
        },
        "rougeL": {
            "precision": 0.64393,
            "recall": 0.59153,
            "fmeasure": 0.61326
        },
        "rougeLsum": {
            "precision": 0.64393,
            "recall": 0.59153,
            "fmeasure": 0.61326
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.3888888888888889,
            "3": 0.6991150442477876
        },
        "meteor": 0.3658827482120883,
        "nubia": {
            "semantic_relation": 3.66312,
            "contradiction": 16.15261,
            "irrelevancy": 28.60019,
            "logical_agreement": 55.2472,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.50178,
            "nubia_score": 0.62027
        },
        "bleurt": 0.17479,
        "bertscore": {
            "precision": 0.91324,
            "recall": 0.90472,
            "f1": 0.9059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.09472,
        "nist": 4.700368039414794,
        "rouge1": {
            "precision": 0.86019,
            "recall": 0.78556,
            "fmeasure": 0.81453
        },
        "rouge2": {
            "precision": 0.70683,
            "recall": 0.64315,
            "fmeasure": 0.66702
        },
        "rougeL": {
            "precision": 0.74907,
            "recall": 0.67374,
            "fmeasure": 0.7031
        },
        "rougeLsum": {
            "precision": 0.74907,
            "recall": 0.67374,
            "fmeasure": 0.7031
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6,
            "3": 0.8285714285714286
        },
        "meteor": 0.46479712632233694,
        "nubia": {
            "semantic_relation": 4.39367,
            "contradiction": 0.2304,
            "irrelevancy": 16.82743,
            "logical_agreement": 82.94216,
            "grammar_ref": 5.35172,
            "grammar_hyp": 5.04509,
            "nubia_score": 0.8038
        },
        "bleurt": 0.21788,
        "bertscore": {
            "precision": 0.95144,
            "recall": 0.94156,
            "f1": 0.94536
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.48452,
        "nist": 3.6898903605521975,
        "rouge1": {
            "precision": 0.62415,
            "recall": 0.58997,
            "fmeasure": 0.59891
        },
        "rouge2": {
            "precision": 0.42371,
            "recall": 0.40307,
            "fmeasure": 0.40883
        },
        "rougeL": {
            "precision": 0.56787,
            "recall": 0.54995,
            "fmeasure": 0.55229
        },
        "rougeLsum": {
            "precision": 0.56787,
            "recall": 0.54995,
            "fmeasure": 0.55229
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.5483870967741935,
            "3": 0.64
        },
        "meteor": 0.278894574595482,
        "nubia": {
            "semantic_relation": 3.76885,
            "contradiction": 15.94082,
            "irrelevancy": 42.05352,
            "logical_agreement": 42.00565,
            "grammar_ref": 3.62435,
            "grammar_hyp": 3.23637,
            "nubia_score": 0.69201
        },
        "bleurt": -0.10371,
        "bertscore": {
            "precision": 0.88918,
            "recall": 0.87719,
            "f1": 0.88186
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.31869,
        "nist": 4.8305779682743815,
        "rouge1": {
            "precision": 0.7494,
            "recall": 0.81509,
            "fmeasure": 0.76619
        },
        "rouge2": {
            "precision": 0.55856,
            "recall": 0.63866,
            "fmeasure": 0.58072
        },
        "rougeL": {
            "precision": 0.66775,
            "recall": 0.74659,
            "fmeasure": 0.69234
        },
        "rougeLsum": {
            "precision": 0.66775,
            "recall": 0.74659,
            "fmeasure": 0.69234
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.75,
            "3": 0.7619047619047619
        },
        "meteor": 0.42084727583892423,
        "nubia": {
            "semantic_relation": 4.21919,
            "contradiction": 0.71683,
            "irrelevancy": 33.04254,
            "logical_agreement": 66.24062,
            "grammar_ref": 4.75156,
            "grammar_hyp": 5.04052,
            "nubia_score": 0.71248
        },
        "bleurt": 0.34756,
        "bertscore": {
            "precision": 0.92726,
            "recall": 0.93235,
            "f1": 0.92932
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.59884,
        "nist": 4.767979282236421,
        "rouge1": {
            "precision": 0.71447,
            "recall": 0.68444,
            "fmeasure": 0.69877
        },
        "rouge2": {
            "precision": 0.50201,
            "recall": 0.48414,
            "fmeasure": 0.4927
        },
        "rougeL": {
            "precision": 0.58618,
            "recall": 0.56058,
            "fmeasure": 0.57275
        },
        "rougeLsum": {
            "precision": 0.58618,
            "recall": 0.56058,
            "fmeasure": 0.57275
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.47619047619047616,
            "3": 0.7333333333333333
        },
        "meteor": 0.3331685524491618,
        "nubia": {
            "semantic_relation": 3.81469,
            "contradiction": 12.19012,
            "irrelevancy": 16.20665,
            "logical_agreement": 71.60322,
            "grammar_ref": 3.87874,
            "grammar_hyp": 3.65769,
            "nubia_score": 0.73611
        },
        "bleurt": 0.16094,
        "bertscore": {
            "precision": 0.92567,
            "recall": 0.91503,
            "f1": 0.92011
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.80983,
        "nist": 2.7093539136962272,
        "rouge1": {
            "precision": 0.68182,
            "recall": 0.625,
            "fmeasure": 0.65217
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.26087,
            "fmeasure": 0.27273
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.375,
            "fmeasure": 0.3913
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.375,
            "fmeasure": 0.3913
        },
        "local_recall": {
            "1": 0,
            "2": 0.75,
            "3": 0.5833333333333334
        },
        "meteor": 0.2979978499168921,
        "nubia": {
            "semantic_relation": 3.39683,
            "contradiction": 83.0442,
            "irrelevancy": 12.67474,
            "logical_agreement": 4.28106,
            "grammar_ref": 4.791,
            "grammar_hyp": 4.83196,
            "nubia_score": 0.46596
        },
        "bleurt": -0.0622,
        "bertscore": {
            "precision": 0.88285,
            "recall": 0.89834,
            "f1": 0.89053
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.63253,
        "nist": 5.657528508372544,
        "rouge1": {
            "precision": 0.80839,
            "recall": 0.84158,
            "fmeasure": 0.81532
        },
        "rouge2": {
            "precision": 0.55023,
            "recall": 0.61472,
            "fmeasure": 0.57261
        },
        "rougeL": {
            "precision": 0.66769,
            "recall": 0.71562,
            "fmeasure": 0.67855
        },
        "rougeLsum": {
            "precision": 0.66769,
            "recall": 0.71562,
            "fmeasure": 0.67855
        },
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.5333333333333333,
            "3": 0.9090909090909091
        },
        "meteor": 0.4595709781766945,
        "nubia": {
            "semantic_relation": 4.4296,
            "contradiction": 2.25342,
            "irrelevancy": 25.9661,
            "logical_agreement": 71.78048,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.58885,
            "nubia_score": 0.80979
        },
        "bleurt": 0.41228,
        "bertscore": {
            "precision": 0.93316,
            "recall": 0.93627,
            "f1": 0.9289
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.1566,
        "nist": 3.4598507971787016,
        "rouge1": {
            "precision": 0.50191,
            "recall": 0.54447,
            "fmeasure": 0.5143
        },
        "rouge2": {
            "precision": 0.30338,
            "recall": 0.32053,
            "fmeasure": 0.30712
        },
        "rougeL": {
            "precision": 0.42495,
            "recall": 0.48567,
            "fmeasure": 0.44224
        },
        "rougeLsum": {
            "precision": 0.42495,
            "recall": 0.48567,
            "fmeasure": 0.44224
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.45454545454545453,
            "3": 0.7142857142857143
        },
        "meteor": 0.2903714155192688,
        "nubia": {
            "semantic_relation": 3.26314,
            "contradiction": 38.54349,
            "irrelevancy": 48.08469,
            "logical_agreement": 13.37182,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.14541,
            "nubia_score": 0.48083
        },
        "bleurt": -0.07541,
        "bertscore": {
            "precision": 0.86116,
            "recall": 0.88514,
            "f1": 0.87213
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 91.46912,
        "nist": 4.20271956237473,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 0.5118198837985161,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.61375,
            "irrelevancy": 0.83168,
            "logical_agreement": 98.55457,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.55122,
            "nubia_score": 0.97788
        },
        "bleurt": 0.8833,
        "bertscore": {
            "precision": 0.9928,
            "recall": 0.9928,
            "f1": 0.9928
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.90246,
        "nist": 4.442331044652348,
        "rouge1": {
            "precision": 0.65669,
            "recall": 0.62788,
            "fmeasure": 0.63057
        },
        "rouge2": {
            "precision": 0.39188,
            "recall": 0.36609,
            "fmeasure": 0.37036
        },
        "rougeL": {
            "precision": 0.47628,
            "recall": 0.45104,
            "fmeasure": 0.45591
        },
        "rougeLsum": {
            "precision": 0.47628,
            "recall": 0.45104,
            "fmeasure": 0.45591
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.40625,
            "3": 0.7407407407407407
        },
        "meteor": 0.3224085053553092,
        "nubia": {
            "semantic_relation": 3.68195,
            "contradiction": 10.86652,
            "irrelevancy": 33.42072,
            "logical_agreement": 55.71276,
            "grammar_ref": 4.13756,
            "grammar_hyp": 4.07827,
            "nubia_score": 0.56718
        },
        "bleurt": 0.02999,
        "bertscore": {
            "precision": 0.90815,
            "recall": 0.89358,
            "f1": 0.90038
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.56782,
        "nist": 3.909689916604926,
        "rouge1": {
            "precision": 0.64646,
            "recall": 0.69478,
            "fmeasure": 0.66338
        },
        "rouge2": {
            "precision": 0.37268,
            "recall": 0.43922,
            "fmeasure": 0.39499
        },
        "rougeL": {
            "precision": 0.5101,
            "recall": 0.57081,
            "fmeasure": 0.52965
        },
        "rougeLsum": {
            "precision": 0.5101,
            "recall": 0.57081,
            "fmeasure": 0.52965
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.15384615384615385,
            "3": 0.7666666666666667
        },
        "meteor": 0.41382085976553706,
        "nubia": {
            "semantic_relation": 4.1269,
            "contradiction": 1.07919,
            "irrelevancy": 74.76631,
            "logical_agreement": 24.1545,
            "grammar_ref": 4.38609,
            "grammar_hyp": 4.34407,
            "nubia_score": 0.6874
        },
        "bleurt": 0.27144,
        "bertscore": {
            "precision": 0.89334,
            "recall": 0.93607,
            "f1": 0.91254
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.71068,
        "nist": 4.399094261165875,
        "rouge1": {
            "precision": 0.8109,
            "recall": 0.73614,
            "fmeasure": 0.77091
        },
        "rouge2": {
            "precision": 0.47421,
            "recall": 0.41035,
            "fmeasure": 0.43909
        },
        "rougeL": {
            "precision": 0.80288,
            "recall": 0.66797,
            "fmeasure": 0.72708
        },
        "rougeLsum": {
            "precision": 0.80288,
            "recall": 0.66797,
            "fmeasure": 0.72708
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.8823529411764706
        },
        "meteor": 0.3956895863827771,
        "nubia": {
            "semantic_relation": 4.33987,
            "contradiction": 0.31877,
            "irrelevancy": 0.87126,
            "logical_agreement": 98.80997,
            "grammar_ref": 5.06568,
            "grammar_hyp": 4.73214,
            "nubia_score": 0.83358
        },
        "bleurt": 0.43281,
        "bertscore": {
            "precision": 0.95044,
            "recall": 0.93047,
            "f1": 0.93704
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 158,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.61017,
        "nist": 7.641695190749828,
        "rouge1": {
            "precision": 0.72449,
            "recall": 0.71902,
            "fmeasure": 0.70916
        },
        "rouge2": {
            "precision": 0.47436,
            "recall": 0.47258,
            "fmeasure": 0.4656
        },
        "rougeL": {
            "precision": 0.60591,
            "recall": 0.60734,
            "fmeasure": 0.59648
        },
        "rougeLsum": {
            "precision": 0.60591,
            "recall": 0.60734,
            "fmeasure": 0.59648
        },
        "local_recall": {
            "1": 0.2314487632508834,
            "2": 0.4525691699604743,
            "3": 0.7595491546649968
        },
        "meteor": 0.3858075652766782,
        "nubia": {
            "semantic_relation": 4.13057,
            "contradiction": 6.56368,
            "irrelevancy": 34.23565,
            "logical_agreement": 59.20067,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.5757,
            "nubia_score": 0.72238
        },
        "bleurt": 0.21104,
        "bertscore": {
            "precision": 0.91945,
            "recall": 0.91765,
            "f1": 0.91701
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.0991,
        "nist": 2.196546104755717,
        "rouge1": {
            "precision": 0.68333,
            "recall": 0.51235,
            "fmeasure": 0.58557
        },
        "rouge2": {
            "precision": 0.36842,
            "recall": 0.28,
            "fmeasure": 0.31818
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.38462,
            "fmeasure": 0.43478
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.38462,
            "fmeasure": 0.43478
        },
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.47058823529411764
        },
        "meteor": 0.2414888142243821,
        "nubia": {
            "semantic_relation": 2.94259,
            "contradiction": 4.98947,
            "irrelevancy": 86.28072,
            "logical_agreement": 8.72981,
            "grammar_ref": 4.71547,
            "grammar_hyp": 4.90397,
            "nubia_score": 0.27907
        },
        "bleurt": -0.69842,
        "bertscore": {
            "precision": 0.86573,
            "recall": 0.86508,
            "f1": 0.86523
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.99585,
        "nist": 3.6345112630460954,
        "rouge1": {
            "precision": 0.73275,
            "recall": 0.70928,
            "fmeasure": 0.70787
        },
        "rouge2": {
            "precision": 0.50324,
            "recall": 0.44976,
            "fmeasure": 0.46404
        },
        "rougeL": {
            "precision": 0.65006,
            "recall": 0.61959,
            "fmeasure": 0.62315
        },
        "rougeLsum": {
            "precision": 0.65006,
            "recall": 0.61959,
            "fmeasure": 0.62315
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.75
        },
        "meteor": 0.38050547864194084,
        "nubia": {
            "semantic_relation": 4.15502,
            "contradiction": 4.53428,
            "irrelevancy": 43.04042,
            "logical_agreement": 52.42531,
            "grammar_ref": 5.27719,
            "grammar_hyp": 5.07509,
            "nubia_score": 0.69497
        },
        "bleurt": 0.22208,
        "bertscore": {
            "precision": 0.91792,
            "recall": 0.91933,
            "f1": 0.91782
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.67154,
        "nist": 1.891759392565773,
        "rouge1": {
            "precision": 0.70556,
            "recall": 0.58471,
            "fmeasure": 0.61277
        },
        "rouge2": {
            "precision": 0.34436,
            "recall": 0.29582,
            "fmeasure": 0.30885
        },
        "rougeL": {
            "precision": 0.50606,
            "recall": 0.40911,
            "fmeasure": 0.43474
        },
        "rougeLsum": {
            "precision": 0.50606,
            "recall": 0.40911,
            "fmeasure": 0.43474
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5595238095238095
        },
        "meteor": 0.23595565831315318,
        "nubia": {
            "semantic_relation": 3.29273,
            "contradiction": 29.85528,
            "irrelevancy": 24.19182,
            "logical_agreement": 45.95291,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.80641,
            "nubia_score": 0.47789
        },
        "bleurt": 0.04459,
        "bertscore": {
            "precision": 0.90428,
            "recall": 0.85029,
            "f1": 0.87466
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 8.57989,
        "nist": 0.35465585582346726,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.29524,
            "fmeasure": 0.37778
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.0924,
            "fmeasure": 0.12943
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.2381,
            "fmeasure": 0.30556
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.2381,
            "fmeasure": 0.30556
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.09090909090909091,
            "3": 0.4444444444444444
        },
        "meteor": 0.15673127303076978,
        "nubia": {
            "semantic_relation": 3.44813,
            "contradiction": 0.84378,
            "irrelevancy": 98.08339,
            "logical_agreement": 1.07283,
            "grammar_ref": 4.03834,
            "grammar_hyp": 4.62187,
            "nubia_score": 0.3713
        },
        "bleurt": 0.08732,
        "bertscore": {
            "precision": 0.9018,
            "recall": 0.86138,
            "f1": 0.87581
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.33368,
        "nist": 5.836568198730816,
        "rouge1": {
            "precision": 0.87158,
            "recall": 0.82878,
            "fmeasure": 0.84188
        },
        "rouge2": {
            "precision": 0.69603,
            "recall": 0.66846,
            "fmeasure": 0.67736
        },
        "rougeL": {
            "precision": 0.75609,
            "recall": 0.72465,
            "fmeasure": 0.73456
        },
        "rougeLsum": {
            "precision": 0.75609,
            "recall": 0.72465,
            "fmeasure": 0.73456
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.16666666666666666,
            "3": 0.8131868131868132
        },
        "meteor": 0.455194459865222,
        "nubia": {
            "semantic_relation": 4.69415,
            "contradiction": 0.35852,
            "irrelevancy": 15.53434,
            "logical_agreement": 84.10714,
            "grammar_ref": 4.9924,
            "grammar_hyp": 5.19906,
            "nubia_score": 0.8578
        },
        "bleurt": 0.58359,
        "bertscore": {
            "precision": 0.97535,
            "recall": 0.96799,
            "f1": 0.97156
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.06864,
        "nist": 2.6245638732661956,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.39744,
            "fmeasure": 0.48106
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.23214,
            "fmeasure": 0.28636
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.3641,
            "fmeasure": 0.43939
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.3641,
            "fmeasure": 0.43939
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6363636363636364
        },
        "meteor": 0.31036779879620235,
        "nubia": {
            "semantic_relation": 3.14909,
            "contradiction": 0.11938,
            "irrelevancy": 99.77466,
            "logical_agreement": 0.10595,
            "grammar_ref": 4.56931,
            "grammar_hyp": 4.08943,
            "nubia_score": 0.53237
        },
        "bleurt": -0.22953,
        "bertscore": {
            "precision": 0.86034,
            "recall": 0.86282,
            "f1": 0.86158
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.22222,
        "nist": 2.8410465657877046,
        "rouge1": {
            "precision": 0.58116,
            "recall": 0.47223,
            "fmeasure": 0.52018
        },
        "rouge2": {
            "precision": 0.27597,
            "recall": 0.20178,
            "fmeasure": 0.2324
        },
        "rougeL": {
            "precision": 0.46812,
            "recall": 0.3489,
            "fmeasure": 0.39883
        },
        "rougeLsum": {
            "precision": 0.46812,
            "recall": 0.3489,
            "fmeasure": 0.39883
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.38095238095238093,
            "3": 0.631578947368421
        },
        "meteor": 0.24697449003953684,
        "nubia": {
            "semantic_relation": 3.1131,
            "contradiction": 52.30712,
            "irrelevancy": 28.13476,
            "logical_agreement": 19.55812,
            "grammar_ref": 4.17,
            "grammar_hyp": 4.63133,
            "nubia_score": 0.34661
        },
        "bleurt": -0.19499,
        "bertscore": {
            "precision": 0.89262,
            "recall": 0.86956,
            "f1": 0.88
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 62.49539,
        "nist": 4.74547078108293,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.78199,
            "fmeasure": 0.81114
        },
        "rouge2": {
            "precision": 0.59091,
            "recall": 0.53056,
            "fmeasure": 0.54686
        },
        "rougeL": {
            "precision": 0.7963,
            "recall": 0.6951,
            "fmeasure": 0.72438
        },
        "rougeLsum": {
            "precision": 0.7963,
            "recall": 0.6951,
            "fmeasure": 0.72438
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6153846153846154,
            "3": 0.9259259259259259
        },
        "meteor": 0.4516947985454428,
        "nubia": {
            "semantic_relation": 4.57401,
            "contradiction": 1.20388,
            "irrelevancy": 6.90088,
            "logical_agreement": 91.89525,
            "grammar_ref": 4.97796,
            "grammar_hyp": 5.54138,
            "nubia_score": 0.75957
        },
        "bleurt": 0.43435,
        "bertscore": {
            "precision": 0.94003,
            "recall": 0.92454,
            "f1": 0.93118
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 80,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.08565,
        "nist": 7.265530838355625,
        "rouge1": {
            "precision": 0.74493,
            "recall": 0.70958,
            "fmeasure": 0.71724
        },
        "rouge2": {
            "precision": 0.49284,
            "recall": 0.469,
            "fmeasure": 0.47368
        },
        "rougeL": {
            "precision": 0.62806,
            "recall": 0.59869,
            "fmeasure": 0.60457
        },
        "rougeLsum": {
            "precision": 0.62806,
            "recall": 0.59869,
            "fmeasure": 0.60457
        },
        "local_recall": {
            "1": 0.288135593220339,
            "2": 0.38497652582159625,
            "3": 0.7524972253052165
        },
        "meteor": 0.3834955532959288,
        "nubia": {
            "semantic_relation": 4.2434,
            "contradiction": 9.82758,
            "irrelevancy": 28.28645,
            "logical_agreement": 61.88597,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.78635,
            "nubia_score": 0.73944
        },
        "bleurt": 0.26428,
        "bertscore": {
            "precision": 0.92501,
            "recall": 0.92118,
            "f1": 0.92126
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.26399,
        "nist": 1.977957716175425,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.675,
            "fmeasure": 0.63333
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.12698,
            "fmeasure": 0.11806
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.3375,
            "fmeasure": 0.31667
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.3375,
            "fmeasure": 0.31667
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "meteor": 0.31976261434649494,
        "nubia": {
            "semantic_relation": 4.29192,
            "contradiction": 6.50999,
            "irrelevancy": 1.05929,
            "logical_agreement": 92.43073,
            "grammar_ref": 6.57359,
            "grammar_hyp": 5.5711,
            "nubia_score": 0.66387
        },
        "bleurt": 0.00883,
        "bertscore": {
            "precision": 0.88584,
            "recall": 0.91564,
            "f1": 0.9005
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.03018,
        "nist": 3.969815440603964,
        "rouge1": {
            "precision": 0.79487,
            "recall": 0.81119,
            "fmeasure": 0.80235
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.54722,
            "fmeasure": 0.54419
        },
        "rougeL": {
            "precision": 0.67949,
            "recall": 0.7028,
            "fmeasure": 0.69017
        },
        "rougeLsum": {
            "precision": 0.67949,
            "recall": 0.7028,
            "fmeasure": 0.69017
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.8
        },
        "meteor": 0.3905089706619567,
        "nubia": {
            "semantic_relation": 4.75956,
            "contradiction": 0.4203,
            "irrelevancy": 0.91587,
            "logical_agreement": 98.66383,
            "grammar_ref": 3.96214,
            "grammar_hyp": 4.03339,
            "nubia_score": 0.92384
        },
        "bleurt": 0.51981,
        "bertscore": {
            "precision": 0.9267,
            "recall": 0.92173,
            "f1": 0.9242
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.27825,
        "nist": 4.307266999747409,
        "rouge1": {
            "precision": 0.81212,
            "recall": 0.7127,
            "fmeasure": 0.73728
        },
        "rouge2": {
            "precision": 0.57778,
            "recall": 0.50794,
            "fmeasure": 0.5214
        },
        "rougeL": {
            "precision": 0.6303,
            "recall": 0.61673,
            "fmeasure": 0.59354
        },
        "rougeLsum": {
            "precision": 0.6303,
            "recall": 0.61673,
            "fmeasure": 0.59354
        },
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.7727272727272727
        },
        "meteor": 0.40898494966786847,
        "nubia": {
            "semantic_relation": 4.024,
            "contradiction": 5.39109,
            "irrelevancy": 43.55216,
            "logical_agreement": 51.05675,
            "grammar_ref": 5.1114,
            "grammar_hyp": 5.20663,
            "nubia_score": 0.67106
        },
        "bleurt": 0.03244,
        "bertscore": {
            "precision": 0.93161,
            "recall": 0.92276,
            "f1": 0.92668
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.02975,
        "nist": 5.27228501258658,
        "rouge1": {
            "precision": 0.73757,
            "recall": 0.79538,
            "fmeasure": 0.75348
        },
        "rouge2": {
            "precision": 0.50088,
            "recall": 0.52117,
            "fmeasure": 0.50403
        },
        "rougeL": {
            "precision": 0.58614,
            "recall": 0.609,
            "fmeasure": 0.5898
        },
        "rougeLsum": {
            "precision": 0.58614,
            "recall": 0.609,
            "fmeasure": 0.5898
        },
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.8666666666666667,
            "3": 0.8333333333333334
        },
        "meteor": 0.3982546656833393,
        "nubia": {
            "semantic_relation": 4.29105,
            "contradiction": 6.92325,
            "irrelevancy": 24.1869,
            "logical_agreement": 68.88985,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.12952,
            "nubia_score": 0.73222
        },
        "bleurt": 0.33305,
        "bertscore": {
            "precision": 0.93387,
            "recall": 0.93003,
            "f1": 0.93004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 25,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.93001,
        "nist": 6.5175103264672405,
        "rouge1": {
            "precision": 0.74651,
            "recall": 0.73712,
            "fmeasure": 0.73346
        },
        "rouge2": {
            "precision": 0.53403,
            "recall": 0.52603,
            "fmeasure": 0.52432
        },
        "rougeL": {
            "precision": 0.64245,
            "recall": 0.63621,
            "fmeasure": 0.63272
        },
        "rougeLsum": {
            "precision": 0.64245,
            "recall": 0.63621,
            "fmeasure": 0.63272
        },
        "local_recall": {
            "1": 0.21739130434782608,
            "2": 0.4927536231884058,
            "3": 0.7526501766784452
        },
        "meteor": 0.3978997452560574,
        "nubia": {
            "semantic_relation": 3.93806,
            "contradiction": 11.04127,
            "irrelevancy": 26.52043,
            "logical_agreement": 62.4383,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.84206,
            "nubia_score": 0.66396
        },
        "bleurt": 0.149,
        "bertscore": {
            "precision": 0.92458,
            "recall": 0.92,
            "f1": 0.92147
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.92334,
        "nist": 2.0,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.76923,
            "fmeasure": 0.64516
        },
        "rouge2": {
            "precision": 0.35294,
            "recall": 0.5,
            "fmeasure": 0.41379
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.76923,
            "fmeasure": 0.64516
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.76923,
            "fmeasure": 0.64516
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6923076923076923
        },
        "meteor": 0.35759220058641883,
        "nubia": {
            "semantic_relation": 3.68935,
            "contradiction": 0.18204,
            "irrelevancy": 99.70919,
            "logical_agreement": 0.10876,
            "grammar_ref": 3.82301,
            "grammar_hyp": 3.60153,
            "nubia_score": 0.71934
        },
        "bleurt": 0.17246,
        "bertscore": {
            "precision": 0.89143,
            "recall": 0.90304,
            "f1": 0.8972
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 36,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.90799,
        "nist": 6.703387857004057,
        "rouge1": {
            "precision": 0.73991,
            "recall": 0.74961,
            "fmeasure": 0.73565
        },
        "rouge2": {
            "precision": 0.48474,
            "recall": 0.48082,
            "fmeasure": 0.47694
        },
        "rougeL": {
            "precision": 0.60248,
            "recall": 0.6117,
            "fmeasure": 0.59953
        },
        "rougeLsum": {
            "precision": 0.60248,
            "recall": 0.6117,
            "fmeasure": 0.59953
        },
        "local_recall": {
            "1": 0.28205128205128205,
            "2": 0.5735294117647058,
            "3": 0.7839195979899497
        },
        "meteor": 0.38635678796313194,
        "nubia": {
            "semantic_relation": 4.21686,
            "contradiction": 6.6568,
            "irrelevancy": 29.88098,
            "logical_agreement": 63.46222,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.651,
            "nubia_score": 0.74476
        },
        "bleurt": 0.27224,
        "bertscore": {
            "precision": 0.9279,
            "recall": 0.9281,
            "f1": 0.92647
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 89.19892,
        "nist": 5.4214460798039195,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.92955,
            "fmeasure": 0.94172
        },
        "rouge2": {
            "precision": 0.82222,
            "recall": 0.79737,
            "fmeasure": 0.80946
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.92955,
            "fmeasure": 0.94172
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.92955,
            "fmeasure": 0.94172
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.9583333333333334
        },
        "meteor": 0.5780195960646539,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.55035,
            "irrelevancy": 0.65133,
            "logical_agreement": 98.79832,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.33193,
            "nubia_score": 0.98631
        },
        "bleurt": 0.78135,
        "bertscore": {
            "precision": 0.98488,
            "recall": 0.98085,
            "f1": 0.98286
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 68.47907,
        "nist": 6.130796650959548,
        "rouge1": {
            "precision": 0.89924,
            "recall": 0.85086,
            "fmeasure": 0.86469
        },
        "rouge2": {
            "precision": 0.76265,
            "recall": 0.74705,
            "fmeasure": 0.74852
        },
        "rougeL": {
            "precision": 0.83413,
            "recall": 0.80661,
            "fmeasure": 0.81276
        },
        "rougeLsum": {
            "precision": 0.83413,
            "recall": 0.80661,
            "fmeasure": 0.81276
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8773584905660378
        },
        "meteor": 0.4768231305329159,
        "nubia": {
            "semantic_relation": 4.45165,
            "contradiction": 12.15584,
            "irrelevancy": 5.56699,
            "logical_agreement": 82.27717,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.04614,
            "nubia_score": 0.79441
        },
        "bleurt": 0.57753,
        "bertscore": {
            "precision": 0.96667,
            "recall": 0.95162,
            "f1": 0.95835
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.945,
        "nist": 4.985459978731097,
        "rouge1": {
            "precision": 0.6981,
            "recall": 0.74192,
            "fmeasure": 0.70807
        },
        "rouge2": {
            "precision": 0.49152,
            "recall": 0.55032,
            "fmeasure": 0.50803
        },
        "rougeL": {
            "precision": 0.61484,
            "recall": 0.66889,
            "fmeasure": 0.6307
        },
        "rougeLsum": {
            "precision": 0.61484,
            "recall": 0.66889,
            "fmeasure": 0.6307
        },
        "local_recall": {
            "1": 0.1388888888888889,
            "2": 0.7333333333333333,
            "3": 0.7534246575342466
        },
        "meteor": 0.4076277247504203,
        "nubia": {
            "semantic_relation": 4.18203,
            "contradiction": 7.15569,
            "irrelevancy": 41.07655,
            "logical_agreement": 51.76776,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.96524,
            "nubia_score": 0.70649
        },
        "bleurt": 0.10132,
        "bertscore": {
            "precision": 0.90552,
            "recall": 0.92655,
            "f1": 0.91321
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 66.66467,
        "nist": 4.116908500925143,
        "rouge1": {
            "precision": 0.9537,
            "recall": 0.84361,
            "fmeasure": 0.88986
        },
        "rouge2": {
            "precision": 0.85294,
            "recall": 0.78139,
            "fmeasure": 0.81309
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.83597,
            "fmeasure": 0.87195
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.83597,
            "fmeasure": 0.87195
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.8461538461538461
        },
        "meteor": 0.4789822425117563,
        "nubia": {
            "semantic_relation": 4.31343,
            "contradiction": 0.30187,
            "irrelevancy": 0.53999,
            "logical_agreement": 99.15814,
            "grammar_ref": 4.36539,
            "grammar_hyp": 4.36917,
            "nubia_score": 0.77969
        },
        "bleurt": 0.55197,
        "bertscore": {
            "precision": 0.97608,
            "recall": 0.94547,
            "f1": 0.95793
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 83.91673,
        "nist": 5.39157857055832,
        "rouge1": {
            "precision": 0.94345,
            "recall": 0.92582,
            "fmeasure": 0.93429
        },
        "rouge2": {
            "precision": 0.84848,
            "recall": 0.83333,
            "fmeasure": 0.84058
        },
        "rougeL": {
            "precision": 0.94345,
            "recall": 0.92582,
            "fmeasure": 0.93429
        },
        "rougeLsum": {
            "precision": 0.94345,
            "recall": 0.92582,
            "fmeasure": 0.93429
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9183673469387755
        },
        "meteor": 0.5920970787479097,
        "nubia": {
            "semantic_relation": 4.88231,
            "contradiction": 0.48183,
            "irrelevancy": 0.60391,
            "logical_agreement": 98.91426,
            "grammar_ref": 5.0449,
            "grammar_hyp": 5.18142,
            "nubia_score": 0.93664
        },
        "bleurt": 0.92267,
        "bertscore": {
            "precision": 0.98881,
            "recall": 0.98554,
            "f1": 0.98716
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.23035,
        "nist": 5.23307042897296,
        "rouge1": {
            "precision": 0.81672,
            "recall": 0.783,
            "fmeasure": 0.79539
        },
        "rouge2": {
            "precision": 0.6244,
            "recall": 0.59479,
            "fmeasure": 0.60701
        },
        "rougeL": {
            "precision": 0.68056,
            "recall": 0.64487,
            "fmeasure": 0.66003
        },
        "rougeLsum": {
            "precision": 0.68056,
            "recall": 0.64487,
            "fmeasure": 0.66003
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.16666666666666666,
            "3": 0.8333333333333334
        },
        "meteor": 0.3828455259908348,
        "nubia": {
            "semantic_relation": 4.05188,
            "contradiction": 44.30703,
            "irrelevancy": 24.37389,
            "logical_agreement": 31.31908,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.46653,
            "nubia_score": 0.69031
        },
        "bleurt": 0.38221,
        "bertscore": {
            "precision": 0.9429,
            "recall": 0.93442,
            "f1": 0.93849
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.42764,
        "nist": 5.525466377394984,
        "rouge1": {
            "precision": 0.77644,
            "recall": 0.78691,
            "fmeasure": 0.77693
        },
        "rouge2": {
            "precision": 0.50458,
            "recall": 0.51107,
            "fmeasure": 0.50399
        },
        "rougeL": {
            "precision": 0.64041,
            "recall": 0.64344,
            "fmeasure": 0.6384
        },
        "rougeLsum": {
            "precision": 0.64041,
            "recall": 0.64344,
            "fmeasure": 0.6384
        },
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.8709677419354839,
            "3": 0.7777777777777778
        },
        "meteor": 0.41773490591646956,
        "nubia": {
            "semantic_relation": 4.46728,
            "contradiction": 1.82112,
            "irrelevancy": 20.8526,
            "logical_agreement": 77.32629,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.46007,
            "nubia_score": 0.76214
        },
        "bleurt": 0.31696,
        "bertscore": {
            "precision": 0.93278,
            "recall": 0.92812,
            "f1": 0.92787
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.66404,
        "nist": 3.7325795648877094,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.78333,
            "fmeasure": 0.71846
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.43915,
            "fmeasure": 0.39835
        },
        "rougeL": {
            "precision": 0.57576,
            "recall": 0.675,
            "fmeasure": 0.61988
        },
        "rougeLsum": {
            "precision": 0.57576,
            "recall": 0.675,
            "fmeasure": 0.61988
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0,
            "3": 0.75
        },
        "meteor": 0.41873293793358235,
        "nubia": {
            "semantic_relation": 4.31634,
            "contradiction": 0.55872,
            "irrelevancy": 26.12812,
            "logical_agreement": 73.31315,
            "grammar_ref": 5.68329,
            "grammar_hyp": 4.6799,
            "nubia_score": 0.8195
        },
        "bleurt": 0.43703,
        "bertscore": {
            "precision": 0.96164,
            "recall": 0.96951,
            "f1": 0.96556
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.59331,
        "nist": 5.4660259925377,
        "rouge1": {
            "precision": 0.83993,
            "recall": 0.78846,
            "fmeasure": 0.81187
        },
        "rouge2": {
            "precision": 0.68,
            "recall": 0.62868,
            "fmeasure": 0.6518
        },
        "rougeL": {
            "precision": 0.70215,
            "recall": 0.66035,
            "fmeasure": 0.6792
        },
        "rougeLsum": {
            "precision": 0.70215,
            "recall": 0.66035,
            "fmeasure": 0.6792
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.375,
            "3": 0.7792207792207793
        },
        "meteor": 0.46790835329257957,
        "nubia": {
            "semantic_relation": 4.67908,
            "contradiction": 0.38989,
            "irrelevancy": 1.00934,
            "logical_agreement": 98.60077,
            "grammar_ref": 4.65184,
            "grammar_hyp": 4.97597,
            "nubia_score": 0.86389
        },
        "bleurt": 0.54533,
        "bertscore": {
            "precision": 0.9518,
            "recall": 0.95226,
            "f1": 0.95192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.67379,
        "nist": 4.038998461562282,
        "rouge1": {
            "precision": 0.65804,
            "recall": 0.57141,
            "fmeasure": 0.58939
        },
        "rouge2": {
            "precision": 0.4959,
            "recall": 0.44213,
            "fmeasure": 0.44565
        },
        "rougeL": {
            "precision": 0.56577,
            "recall": 0.50195,
            "fmeasure": 0.50655
        },
        "rougeLsum": {
            "precision": 0.56577,
            "recall": 0.50195,
            "fmeasure": 0.50655
        },
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.42105263157894735,
            "3": 0.75
        },
        "meteor": 0.36264858186351434,
        "nubia": {
            "semantic_relation": 3.43723,
            "contradiction": 25.85669,
            "irrelevancy": 51.05056,
            "logical_agreement": 23.09275,
            "grammar_ref": 4.83501,
            "grammar_hyp": 4.40935,
            "nubia_score": 0.50465
        },
        "bleurt": -0.22075,
        "bertscore": {
            "precision": 0.87652,
            "recall": 0.87416,
            "f1": 0.87198
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 78.67012,
        "nist": 4.997400644669717,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96078,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.7381,
            "fmeasure": 0.77143
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "meteor": 0.5302622459418969,
        "nubia": {
            "semantic_relation": 4.74121,
            "contradiction": 0.21038,
            "irrelevancy": 0.47513,
            "logical_agreement": 99.31449,
            "grammar_ref": 4.24096,
            "grammar_hyp": 4.22897,
            "nubia_score": 0.92017
        },
        "bleurt": 0.63445,
        "bertscore": {
            "precision": 0.96928,
            "recall": 0.96681,
            "f1": 0.96805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.03079,
        "nist": 4.665657894085979,
        "rouge1": {
            "precision": 0.72058,
            "recall": 0.78551,
            "fmeasure": 0.74701
        },
        "rouge2": {
            "precision": 0.50384,
            "recall": 0.56372,
            "fmeasure": 0.52837
        },
        "rougeL": {
            "precision": 0.60033,
            "recall": 0.66106,
            "fmeasure": 0.62535
        },
        "rougeLsum": {
            "precision": 0.60033,
            "recall": 0.66106,
            "fmeasure": 0.62535
        },
        "local_recall": {
            "1": 0.36666666666666664,
            "2": 0.125,
            "3": 0.75
        },
        "meteor": 0.37902494393300873,
        "nubia": {
            "semantic_relation": 4.09561,
            "contradiction": 21.62082,
            "irrelevancy": 30.66983,
            "logical_agreement": 47.70935,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.27007,
            "nubia_score": 0.70935
        },
        "bleurt": 0.11046,
        "bertscore": {
            "precision": 0.91856,
            "recall": 0.92429,
            "f1": 0.92065
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 74.54065,
        "nist": 5.799658202776459,
        "rouge1": {
            "precision": 0.83131,
            "recall": 0.90122,
            "fmeasure": 0.85614
        },
        "rouge2": {
            "precision": 0.73141,
            "recall": 0.75519,
            "fmeasure": 0.739
        },
        "rougeL": {
            "precision": 0.80522,
            "recall": 0.87513,
            "fmeasure": 0.83005
        },
        "rougeLsum": {
            "precision": 0.80522,
            "recall": 0.87513,
            "fmeasure": 0.83005
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5714285714285714,
            "3": 0.90625
        },
        "meteor": 0.5311333924184187,
        "nubia": {
            "semantic_relation": 4.62932,
            "contradiction": 0.14753,
            "irrelevancy": 20.36616,
            "logical_agreement": 79.48631,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.76317,
            "nubia_score": 0.88841
        },
        "bleurt": 0.5877,
        "bertscore": {
            "precision": 0.9538,
            "recall": 0.96857,
            "f1": 0.95944
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.67088,
        "nist": 2.4107918909526207,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.67949,
            "fmeasure": 0.57586
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.875
        },
        "meteor": 0.40718621833397906,
        "nubia": {
            "semantic_relation": 2.78002,
            "contradiction": 64.88485,
            "irrelevancy": 34.33798,
            "logical_agreement": 0.77717,
            "grammar_ref": 3.57757,
            "grammar_hyp": 2.90765,
            "nubia_score": 0.45753
        },
        "bleurt": 0.4141,
        "bertscore": {
            "precision": 0.91266,
            "recall": 0.96825,
            "f1": 0.93963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 110,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.99474,
        "nist": 7.89109102915646,
        "rouge1": {
            "precision": 0.7502,
            "recall": 0.74398,
            "fmeasure": 0.73498
        },
        "rouge2": {
            "precision": 0.5242,
            "recall": 0.51894,
            "fmeasure": 0.51274
        },
        "rougeL": {
            "precision": 0.6371,
            "recall": 0.63256,
            "fmeasure": 0.62401
        },
        "rougeLsum": {
            "precision": 0.6371,
            "recall": 0.63256,
            "fmeasure": 0.62401
        },
        "local_recall": {
            "1": 0.24867724867724866,
            "2": 0.4986737400530504,
            "3": 0.8113207547169812
        },
        "meteor": 0.40300279267507066,
        "nubia": {
            "semantic_relation": 4.27963,
            "contradiction": 6.47364,
            "irrelevancy": 26.06162,
            "logical_agreement": 67.46474,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.78568,
            "nubia_score": 0.74414
        },
        "bleurt": 0.30503,
        "bertscore": {
            "precision": 0.93391,
            "recall": 0.93093,
            "f1": 0.93118
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.84945,
        "nist": 5.5331401103524795,
        "rouge1": {
            "precision": 0.80246,
            "recall": 0.75988,
            "fmeasure": 0.77583
        },
        "rouge2": {
            "precision": 0.62223,
            "recall": 0.58277,
            "fmeasure": 0.59844
        },
        "rougeL": {
            "precision": 0.71172,
            "recall": 0.70039,
            "fmeasure": 0.70178
        },
        "rougeLsum": {
            "precision": 0.71172,
            "recall": 0.70039,
            "fmeasure": 0.70178
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.42857142857142855,
            "3": 0.7666666666666667
        },
        "meteor": 0.4283176243269168,
        "nubia": {
            "semantic_relation": 4.05497,
            "contradiction": 15.10091,
            "irrelevancy": 39.47246,
            "logical_agreement": 45.42663,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.63526,
            "nubia_score": 0.68682
        },
        "bleurt": 0.1775,
        "bertscore": {
            "precision": 0.9447,
            "recall": 0.93231,
            "f1": 0.9377
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.10127,
        "nist": 4.060147347426856,
        "rouge1": {
            "precision": 0.75489,
            "recall": 0.66314,
            "fmeasure": 0.69395
        },
        "rouge2": {
            "precision": 0.42247,
            "recall": 0.37387,
            "fmeasure": 0.38949
        },
        "rougeL": {
            "precision": 0.60926,
            "recall": 0.53641,
            "fmeasure": 0.56078
        },
        "rougeLsum": {
            "precision": 0.60926,
            "recall": 0.53641,
            "fmeasure": 0.56078
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.8571428571428571,
            "3": 0.5454545454545454
        },
        "meteor": 0.378774115528547,
        "nubia": {
            "semantic_relation": 4.17206,
            "contradiction": 0.27318,
            "irrelevancy": 33.66968,
            "logical_agreement": 66.05713,
            "grammar_ref": 3.54742,
            "grammar_hyp": 3.78048,
            "nubia_score": 0.81226
        },
        "bleurt": 0.27582,
        "bertscore": {
            "precision": 0.91693,
            "recall": 0.89284,
            "f1": 0.90404
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.76836,
        "nist": 4.022256526967185,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.68465,
            "fmeasure": 0.69638
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.43996,
            "fmeasure": 0.4455
        },
        "rougeL": {
            "precision": 0.57576,
            "recall": 0.5964,
            "fmeasure": 0.57276
        },
        "rougeLsum": {
            "precision": 0.57576,
            "recall": 0.5964,
            "fmeasure": 0.57276
        },
        "local_recall": {
            "1": 0.8,
            "2": 0.25,
            "3": 0.75
        },
        "meteor": 0.3616614991541891,
        "nubia": {
            "semantic_relation": 3.97349,
            "contradiction": 14.90218,
            "irrelevancy": 35.31973,
            "logical_agreement": 49.77809,
            "grammar_ref": 5.19402,
            "grammar_hyp": 5.67085,
            "nubia_score": 0.52582
        },
        "bleurt": 0.12495,
        "bertscore": {
            "precision": 0.91614,
            "recall": 0.9286,
            "f1": 0.91992
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.40212,
        "nist": 2.6207956285580805,
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.64286,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.38462,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.57143,
            "fmeasure": 0.59259
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.57143,
            "fmeasure": 0.59259
        },
        "local_recall": {
            "1": 0,
            "2": 0.75,
            "3": 0.5
        },
        "meteor": 0.3199005346877066,
        "nubia": {
            "semantic_relation": 3.8855,
            "contradiction": 0.18419,
            "irrelevancy": 99.72604,
            "logical_agreement": 0.08976,
            "grammar_ref": 4.76643,
            "grammar_hyp": 4.43046,
            "nubia_score": 0.71879
        },
        "bleurt": 0.31493,
        "bertscore": {
            "precision": 0.90549,
            "recall": 0.91205,
            "f1": 0.90296
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 35,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.42381,
        "nist": 6.72541155556751,
        "rouge1": {
            "precision": 0.79959,
            "recall": 0.78314,
            "fmeasure": 0.78561
        },
        "rouge2": {
            "precision": 0.55606,
            "recall": 0.55068,
            "fmeasure": 0.5497
        },
        "rougeL": {
            "precision": 0.66296,
            "recall": 0.66438,
            "fmeasure": 0.65888
        },
        "rougeLsum": {
            "precision": 0.66296,
            "recall": 0.66438,
            "fmeasure": 0.65888
        },
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.5,
            "3": 0.7953890489913544
        },
        "meteor": 0.4201503427876739,
        "nubia": {
            "semantic_relation": 4.30789,
            "contradiction": 0.48333,
            "irrelevancy": 27.18356,
            "logical_agreement": 72.33311,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.13227,
            "nubia_score": 0.81383
        },
        "bleurt": 0.41347,
        "bertscore": {
            "precision": 0.93943,
            "recall": 0.94071,
            "f1": 0.93892
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.94812,
        "nist": 4.8115935917200625,
        "rouge1": {
            "precision": 0.70006,
            "recall": 0.61153,
            "fmeasure": 0.64859
        },
        "rouge2": {
            "precision": 0.50708,
            "recall": 0.43435,
            "fmeasure": 0.46479
        },
        "rougeL": {
            "precision": 0.64926,
            "recall": 0.56894,
            "fmeasure": 0.60232
        },
        "rougeLsum": {
            "precision": 0.64926,
            "recall": 0.56894,
            "fmeasure": 0.60232
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6590909090909091,
            "3": 0.5789473684210527
        },
        "meteor": 0.3358886586419679,
        "nubia": {
            "semantic_relation": 3.54233,
            "contradiction": 20.21528,
            "irrelevancy": 21.29702,
            "logical_agreement": 58.4877,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.46776,
            "nubia_score": 0.55635
        },
        "bleurt": -0.10259,
        "bertscore": {
            "precision": 0.8713,
            "recall": 0.87643,
            "f1": 0.87242
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.49864,
        "nist": 5.561890739632153,
        "rouge1": {
            "precision": 0.76029,
            "recall": 0.77433,
            "fmeasure": 0.76034
        },
        "rouge2": {
            "precision": 0.56032,
            "recall": 0.60587,
            "fmeasure": 0.57137
        },
        "rougeL": {
            "precision": 0.65758,
            "recall": 0.68508,
            "fmeasure": 0.66518
        },
        "rougeLsum": {
            "precision": 0.65758,
            "recall": 0.68508,
            "fmeasure": 0.66518
        },
        "local_recall": {
            "1": 0.36585365853658536,
            "2": 0.7619047619047619,
            "3": 0.8125
        },
        "meteor": 0.4622982152484606,
        "nubia": {
            "semantic_relation": 4.21721,
            "contradiction": 16.18043,
            "irrelevancy": 28.40493,
            "logical_agreement": 55.41464,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.70217,
            "nubia_score": 0.75633
        },
        "bleurt": 0.34726,
        "bertscore": {
            "precision": 0.95115,
            "recall": 0.95312,
            "f1": 0.95014
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.10119,
        "nist": 1.890251253847523,
        "rouge1": {
            "precision": 0.79464,
            "recall": 0.60714,
            "fmeasure": 0.67532
        },
        "rouge2": {
            "precision": 0.52381,
            "recall": 0.35897,
            "fmeasure": 0.41667
        },
        "rougeL": {
            "precision": 0.70238,
            "recall": 0.52381,
            "fmeasure": 0.58874
        },
        "rougeLsum": {
            "precision": 0.70238,
            "recall": 0.52381,
            "fmeasure": 0.58874
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "meteor": 0.37372760093730273,
        "nubia": {
            "semantic_relation": 3.9933,
            "contradiction": 7.32566,
            "irrelevancy": 17.54576,
            "logical_agreement": 75.12858,
            "grammar_ref": 4.81259,
            "grammar_hyp": 5.3134,
            "nubia_score": 0.58986
        },
        "bleurt": 0.05963,
        "bertscore": {
            "precision": 0.9433,
            "recall": 0.90254,
            "f1": 0.92226
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.49491,
        "nist": 5.391892685072659,
        "rouge1": {
            "precision": 0.78413,
            "recall": 0.77611,
            "fmeasure": 0.77989
        },
        "rouge2": {
            "precision": 0.52156,
            "recall": 0.53443,
            "fmeasure": 0.52286
        },
        "rougeL": {
            "precision": 0.67756,
            "recall": 0.73993,
            "fmeasure": 0.695
        },
        "rougeLsum": {
            "precision": 0.67756,
            "recall": 0.73993,
            "fmeasure": 0.695
        },
        "local_recall": {
            "1": 0.16,
            "2": 0.7666666666666667,
            "3": 0.8
        },
        "meteor": 0.4355308653331461,
        "nubia": {
            "semantic_relation": 4.15138,
            "contradiction": 0.61698,
            "irrelevancy": 31.70381,
            "logical_agreement": 67.67921,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.20141,
            "nubia_score": 0.73039
        },
        "bleurt": 0.38082,
        "bertscore": {
            "precision": 0.946,
            "recall": 0.94354,
            "f1": 0.93885
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.4364,
        "nist": 5.598387045200365,
        "rouge1": {
            "precision": 0.85709,
            "recall": 0.8237,
            "fmeasure": 0.83717
        },
        "rouge2": {
            "precision": 0.59753,
            "recall": 0.58319,
            "fmeasure": 0.58867
        },
        "rougeL": {
            "precision": 0.70212,
            "recall": 0.68137,
            "fmeasure": 0.68956
        },
        "rougeLsum": {
            "precision": 0.70212,
            "recall": 0.68137,
            "fmeasure": 0.68956
        },
        "local_recall": {
            "1": 0.7,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "meteor": 0.4769291796354136,
        "nubia": {
            "semantic_relation": 4.83878,
            "contradiction": 0.35454,
            "irrelevancy": 52.92859,
            "logical_agreement": 46.71687,
            "grammar_ref": 4.0888,
            "grammar_hyp": 4.06382,
            "nubia_score": 0.93674
        },
        "bleurt": 0.55529,
        "bertscore": {
            "precision": 0.9623,
            "recall": 0.95488,
            "f1": 0.95821
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.55447,
        "nist": 0.3763365521660779,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.27561,
            "fmeasure": 0.37769
        },
        "rouge2": {
            "precision": 0.18519,
            "recall": 0.0831,
            "fmeasure": 0.11453
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.12795,
            "fmeasure": 0.17262
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.12795,
            "fmeasure": 0.17262
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.21428571428571427
        },
        "meteor": 0.14492849054923504,
        "nubia": {
            "semantic_relation": 3.25428,
            "contradiction": 0.11329,
            "irrelevancy": 68.06159,
            "logical_agreement": 31.82512,
            "grammar_ref": 4.70322,
            "grammar_hyp": 6.92236,
            "nubia_score": 0.19475
        },
        "bleurt": -0.97321,
        "bertscore": {
            "precision": 0.8285,
            "recall": 0.71634,
            "f1": 0.76835
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.44742,
        "nist": 5.324864324944016,
        "rouge1": {
            "precision": 0.83446,
            "recall": 0.85348,
            "fmeasure": 0.837
        },
        "rouge2": {
            "precision": 0.65049,
            "recall": 0.65572,
            "fmeasure": 0.64675
        },
        "rougeL": {
            "precision": 0.74999,
            "recall": 0.75519,
            "fmeasure": 0.7457
        },
        "rougeLsum": {
            "precision": 0.74999,
            "recall": 0.75519,
            "fmeasure": 0.7457
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.6666666666666666,
            "3": 0.8260869565217391
        },
        "meteor": 0.453518689270021,
        "nubia": {
            "semantic_relation": 4.43485,
            "contradiction": 32.3872,
            "irrelevancy": 23.04017,
            "logical_agreement": 44.57263,
            "grammar_ref": 4.9652,
            "grammar_hyp": 5.09482,
            "nubia_score": 0.78207
        },
        "bleurt": 0.48492,
        "bertscore": {
            "precision": 0.94966,
            "recall": 0.94906,
            "f1": 0.94835
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.0226,
        "nist": 2.0026951327414553,
        "rouge1": {
            "precision": 0.36232,
            "recall": 0.76313,
            "fmeasure": 0.48876
        },
        "rouge2": {
            "precision": 0.17712,
            "recall": 0.39345,
            "fmeasure": 0.24289
        },
        "rougeL": {
            "precision": 0.30725,
            "recall": 0.64225,
            "fmeasure": 0.41345
        },
        "rougeLsum": {
            "precision": 0.30725,
            "recall": 0.64225,
            "fmeasure": 0.41345
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.75
        },
        "meteor": 0.27675188671327405,
        "nubia": {
            "semantic_relation": 2.98663,
            "contradiction": 46.66679,
            "irrelevancy": 44.82978,
            "logical_agreement": 8.50342,
            "grammar_ref": 4.76014,
            "grammar_hyp": 3.49288,
            "nubia_score": 0.37917
        },
        "bleurt": -0.34827,
        "bertscore": {
            "precision": 0.76495,
            "recall": 0.89008,
            "f1": 0.81841
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.98716,
        "nist": 4.663140940452728,
        "rouge1": {
            "precision": 0.85802,
            "recall": 0.83598,
            "fmeasure": 0.83629
        },
        "rouge2": {
            "precision": 0.65033,
            "recall": 0.60185,
            "fmeasure": 0.61715
        },
        "rougeL": {
            "precision": 0.78395,
            "recall": 0.76455,
            "fmeasure": 0.76272
        },
        "rougeLsum": {
            "precision": 0.78395,
            "recall": 0.76455,
            "fmeasure": 0.76272
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5294117647058824,
            "3": 0.875
        },
        "meteor": 0.368512487966398,
        "nubia": {
            "semantic_relation": 4.3595,
            "contradiction": 0.50995,
            "irrelevancy": 26.0884,
            "logical_agreement": 73.40165,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.78106,
            "nubia_score": 0.81408
        },
        "bleurt": 0.47271,
        "bertscore": {
            "precision": 0.95396,
            "recall": 0.96333,
            "f1": 0.95855
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.10671,
        "nist": 3.721268003966325,
        "rouge1": {
            "precision": 0.8065,
            "recall": 0.88889,
            "fmeasure": 0.84509
        },
        "rouge2": {
            "precision": 0.67708,
            "recall": 0.78859,
            "fmeasure": 0.72786
        },
        "rougeL": {
            "precision": 0.8065,
            "recall": 0.88889,
            "fmeasure": 0.84509
        },
        "rougeLsum": {
            "precision": 0.8065,
            "recall": 0.88889,
            "fmeasure": 0.84509
        },
        "local_recall": {
            "1": 0,
            "2": 0.625,
            "3": 0.9047619047619048
        },
        "meteor": 0.5347583111938513,
        "nubia": {
            "semantic_relation": 3.54015,
            "contradiction": 46.52862,
            "irrelevancy": 51.10893,
            "logical_agreement": 2.36245,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.35364,
            "nubia_score": 0.6343
        },
        "bleurt": 0.4007,
        "bertscore": {
            "precision": 0.94173,
            "recall": 0.97943,
            "f1": 0.95722
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.20236,
        "nist": 4.141222366055114,
        "rouge1": {
            "precision": 0.67708,
            "recall": 0.6877,
            "fmeasure": 0.67528
        },
        "rouge2": {
            "precision": 0.48049,
            "recall": 0.46142,
            "fmeasure": 0.46565
        },
        "rougeL": {
            "precision": 0.65923,
            "recall": 0.66825,
            "fmeasure": 0.65626
        },
        "rougeLsum": {
            "precision": 0.65923,
            "recall": 0.66825,
            "fmeasure": 0.65626
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2,
            "3": 0.88
        },
        "meteor": 0.42973036207767223,
        "nubia": {
            "semantic_relation": 4.1311,
            "contradiction": 20.36871,
            "irrelevancy": 27.9182,
            "logical_agreement": 51.71309,
            "grammar_ref": 4.98306,
            "grammar_hyp": 4.47919,
            "nubia_score": 0.71972
        },
        "bleurt": 0.43283,
        "bertscore": {
            "precision": 0.93387,
            "recall": 0.94129,
            "f1": 0.93743
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 73.11104,
        "nist": 4.777806403564686,
        "rouge1": {
            "precision": 0.87179,
            "recall": 0.80952,
            "fmeasure": 0.83951
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.61538,
            "fmeasure": 0.64
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 0.69048,
            "fmeasure": 0.71605
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 0.69048,
            "fmeasure": 0.71605
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "meteor": 0.4718059540396743,
        "nubia": {
            "semantic_relation": 4.80674,
            "contradiction": 0.22764,
            "irrelevancy": 0.4644,
            "logical_agreement": 99.30796,
            "grammar_ref": 5.70189,
            "grammar_hyp": 5.01094,
            "nubia_score": 0.97119
        },
        "bleurt": 0.51047,
        "bertscore": {
            "precision": 0.97601,
            "recall": 0.96838,
            "f1": 0.97218
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.44579,
        "nist": 4.433385477090914,
        "rouge1": {
            "precision": 0.70231,
            "recall": 0.84427,
            "fmeasure": 0.76287
        },
        "rouge2": {
            "precision": 0.44996,
            "recall": 0.52023,
            "fmeasure": 0.48027
        },
        "rougeL": {
            "precision": 0.50319,
            "recall": 0.5648,
            "fmeasure": 0.53128
        },
        "rougeLsum": {
            "precision": 0.50319,
            "recall": 0.5648,
            "fmeasure": 0.53128
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.6,
            "3": 0.8727272727272727
        },
        "meteor": 0.4023276799705059,
        "nubia": {
            "semantic_relation": 4.3172,
            "contradiction": 2.04981,
            "irrelevancy": 64.03463,
            "logical_agreement": 33.91556,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.20012,
            "nubia_score": 0.75452
        },
        "bleurt": 0.17628,
        "bertscore": {
            "precision": 0.90659,
            "recall": 0.93477,
            "f1": 0.91881
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.68017,
        "nist": 3.343717495002991,
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.73077,
            "fmeasure": 0.68376
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.51748,
            "fmeasure": 0.48718
        },
        "rougeL": {
            "precision": 0.59524,
            "recall": 0.62302,
            "fmeasure": 0.60806
        },
        "rougeLsum": {
            "precision": 0.59524,
            "recall": 0.62302,
            "fmeasure": 0.60806
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "meteor": 0.45550145750521864,
        "nubia": {
            "semantic_relation": 4.57933,
            "contradiction": 0.23429,
            "irrelevancy": 71.20972,
            "logical_agreement": 28.556,
            "grammar_ref": 5.03839,
            "grammar_hyp": 4.37913,
            "nubia_score": 0.8945
        },
        "bleurt": 0.34003,
        "bertscore": {
            "precision": 0.94025,
            "recall": 0.94222,
            "f1": 0.9401
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.13931,
        "nist": 3.547954933877875,
        "rouge1": {
            "precision": 0.8006,
            "recall": 0.68304,
            "fmeasure": 0.69773
        },
        "rouge2": {
            "precision": 0.55278,
            "recall": 0.50794,
            "fmeasure": 0.50183
        },
        "rougeL": {
            "precision": 0.78744,
            "recall": 0.66741,
            "fmeasure": 0.68344
        },
        "rougeLsum": {
            "precision": 0.78744,
            "recall": 0.66741,
            "fmeasure": 0.68344
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.42857142857142855,
            "3": 0.6774193548387096
        },
        "meteor": 0.3478000583624247,
        "nubia": {
            "semantic_relation": 4.50471,
            "contradiction": 0.97521,
            "irrelevancy": 40.20849,
            "logical_agreement": 58.8163,
            "grammar_ref": 4.09757,
            "grammar_hyp": 4.12042,
            "nubia_score": 0.86007
        },
        "bleurt": 0.31629,
        "bertscore": {
            "precision": 0.94809,
            "recall": 0.92223,
            "f1": 0.93133
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.20877,
        "nist": 5.119611907036568,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.81101,
            "fmeasure": 0.83702
        },
        "rouge2": {
            "precision": 0.66429,
            "recall": 0.60701,
            "fmeasure": 0.63333
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.73896,
            "fmeasure": 0.76712
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.73896,
            "fmeasure": 0.76712
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8709677419354839
        },
        "meteor": 0.4581341430215555,
        "nubia": {
            "semantic_relation": 3.65437,
            "contradiction": 17.01829,
            "irrelevancy": 30.5941,
            "logical_agreement": 52.38761,
            "grammar_ref": 5.38335,
            "grammar_hyp": 5.35506,
            "nubia_score": 0.56298
        },
        "bleurt": 0.24972,
        "bertscore": {
            "precision": 0.92516,
            "recall": 0.95554,
            "f1": 0.93685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.11332,
        "nist": 3.1564358056371256,
        "rouge1": {
            "precision": 0.71678,
            "recall": 0.72937,
            "fmeasure": 0.72134
        },
        "rouge2": {
            "precision": 0.50278,
            "recall": 0.52259,
            "fmeasure": 0.51099
        },
        "rougeL": {
            "precision": 0.67832,
            "recall": 0.69444,
            "fmeasure": 0.68474
        },
        "rougeLsum": {
            "precision": 0.67832,
            "recall": 0.69444,
            "fmeasure": 0.68474
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7142857142857143
        },
        "meteor": 0.4320191019052963,
        "nubia": {
            "semantic_relation": 4.74746,
            "contradiction": 0.19232,
            "irrelevancy": 15.09011,
            "logical_agreement": 84.71756,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.79358,
            "nubia_score": 0.84261
        },
        "bleurt": 0.54445,
        "bertscore": {
            "precision": 0.92349,
            "recall": 0.91582,
            "f1": 0.91958
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.64947,
        "nist": 3.436538417062733,
        "rouge1": {
            "precision": 0.84722,
            "recall": 0.67066,
            "fmeasure": 0.74717
        },
        "rouge2": {
            "precision": 0.6532,
            "recall": 0.50449,
            "fmeasure": 0.56772
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.56438,
            "fmeasure": 0.61749
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.56438,
            "fmeasure": 0.61749
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.42857142857142855,
            "3": 0.7027027027027027
        },
        "meteor": 0.3561947737247713,
        "nubia": {
            "semantic_relation": 3.77617,
            "contradiction": 0.24855,
            "irrelevancy": 12.87764,
            "logical_agreement": 86.87381,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.85758,
            "nubia_score": 0.6033
        },
        "bleurt": -0.0348,
        "bertscore": {
            "precision": 0.92702,
            "recall": 0.88952,
            "f1": 0.90657
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 4.01117167855772,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.66362,
            "contradiction": 2.49017,
            "irrelevancy": 1.24853,
            "logical_agreement": 96.2613,
            "grammar_ref": 6.06085,
            "grammar_hyp": 5.70692,
            "nubia_score": 0.90186
        },
        "bleurt": 0.77386,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.62102,
        "nist": 4.216229695469515,
        "rouge1": {
            "precision": 0.8733,
            "recall": 0.80598,
            "fmeasure": 0.8366
        },
        "rouge2": {
            "precision": 0.69792,
            "recall": 0.64956,
            "fmeasure": 0.67143
        },
        "rougeL": {
            "precision": 0.78507,
            "recall": 0.73217,
            "fmeasure": 0.75623
        },
        "rougeLsum": {
            "precision": 0.78507,
            "recall": 0.73217,
            "fmeasure": 0.75623
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.84
        },
        "meteor": 0.3975326450724071,
        "nubia": {
            "semantic_relation": 4.47621,
            "contradiction": 0.81817,
            "irrelevancy": 4.39213,
            "logical_agreement": 94.7897,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.75536,
            "nubia_score": 0.79797
        },
        "bleurt": 0.31304,
        "bertscore": {
            "precision": 0.94885,
            "recall": 0.94087,
            "f1": 0.94098
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.75374,
        "nist": 4.006512434161132,
        "rouge1": {
            "precision": 0.70243,
            "recall": 0.73751,
            "fmeasure": 0.70292
        },
        "rouge2": {
            "precision": 0.47734,
            "recall": 0.4759,
            "fmeasure": 0.46435
        },
        "rougeL": {
            "precision": 0.61267,
            "recall": 0.636,
            "fmeasure": 0.60493
        },
        "rougeLsum": {
            "precision": 0.61267,
            "recall": 0.636,
            "fmeasure": 0.60493
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8
        },
        "meteor": 0.38492861546184776,
        "nubia": {
            "semantic_relation": 4.43149,
            "contradiction": 7.63777,
            "irrelevancy": 37.15744,
            "logical_agreement": 55.20479,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.20602,
            "nubia_score": 0.7189
        },
        "bleurt": 0.22727,
        "bertscore": {
            "precision": 0.91005,
            "recall": 0.91611,
            "f1": 0.90998
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.57777,
        "nist": 2.4358538275580255,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.82576,
            "fmeasure": 0.57446
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.59259,
            "fmeasure": 0.40139
        },
        "rougeL": {
            "precision": 0.34568,
            "recall": 0.64015,
            "fmeasure": 0.44635
        },
        "rougeLsum": {
            "precision": 0.34568,
            "recall": 0.64015,
            "fmeasure": 0.44635
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "meteor": 0.4122408937080405,
        "nubia": {
            "semantic_relation": 3.57168,
            "contradiction": 0.39542,
            "irrelevancy": 53.66279,
            "logical_agreement": 45.94179,
            "grammar_ref": 5.84412,
            "grammar_hyp": 4.09203,
            "nubia_score": 0.30295
        },
        "bleurt": -0.07918,
        "bertscore": {
            "precision": 0.87707,
            "recall": 0.94975,
            "f1": 0.91196
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 66.20037,
        "nist": 4.019670514328165,
        "rouge1": {
            "precision": 0.81944,
            "recall": 1.0,
            "fmeasure": 0.90063
        },
        "rouge2": {
            "precision": 0.71014,
            "recall": 0.87427,
            "fmeasure": 0.78358
        },
        "rougeL": {
            "precision": 0.81944,
            "recall": 1.0,
            "fmeasure": 0.90063
        },
        "rougeLsum": {
            "precision": 0.81944,
            "recall": 1.0,
            "fmeasure": 0.90063
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 1.0
        },
        "meteor": 0.57649049673364,
        "nubia": {
            "semantic_relation": 3.99704,
            "contradiction": 7.11352,
            "irrelevancy": 89.46814,
            "logical_agreement": 3.41834,
            "grammar_ref": 3.98302,
            "grammar_hyp": 3.97413,
            "nubia_score": 0.65366
        },
        "bleurt": 0.35323,
        "bertscore": {
            "precision": 0.9524,
            "recall": 0.9898,
            "f1": 0.97074
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.18623,
        "nist": 4.778289709165748,
        "rouge1": {
            "precision": 0.67571,
            "recall": 0.73842,
            "fmeasure": 0.69889
        },
        "rouge2": {
            "precision": 0.38926,
            "recall": 0.41659,
            "fmeasure": 0.3981
        },
        "rougeL": {
            "precision": 0.56038,
            "recall": 0.58567,
            "fmeasure": 0.56662
        },
        "rougeLsum": {
            "precision": 0.56038,
            "recall": 0.58567,
            "fmeasure": 0.56662
        },
        "local_recall": {
            "1": 0.07317073170731707,
            "2": 0.32,
            "3": 0.9130434782608695
        },
        "meteor": 0.39110270924332674,
        "nubia": {
            "semantic_relation": 3.82931,
            "contradiction": 6.42452,
            "irrelevancy": 47.26262,
            "logical_agreement": 46.31286,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.68771,
            "nubia_score": 0.64244
        },
        "bleurt": 0.11884,
        "bertscore": {
            "precision": 0.90083,
            "recall": 0.91105,
            "f1": 0.90371
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.19669,
        "nist": 3.152490908912743,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.76441,
            "fmeasure": 0.75672
        },
        "rouge2": {
            "precision": 0.36842,
            "recall": 0.37593,
            "fmeasure": 0.37191
        },
        "rougeL": {
            "precision": 0.38333,
            "recall": 0.36523,
            "fmeasure": 0.37363
        },
        "rougeLsum": {
            "precision": 0.38333,
            "recall": 0.36523,
            "fmeasure": 0.37363
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "meteor": 0.3630179538456088,
        "nubia": {
            "semantic_relation": 4.48994,
            "contradiction": 0.32756,
            "irrelevancy": 5.12187,
            "logical_agreement": 94.55057,
            "grammar_ref": 5.09304,
            "grammar_hyp": 4.51705,
            "nubia_score": 0.84892
        },
        "bleurt": 0.08565,
        "bertscore": {
            "precision": 0.92206,
            "recall": 0.92552,
            "f1": 0.92379
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.56883,
        "nist": 3.730572723894495,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.81283,
            "fmeasure": 0.79808
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.49444
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.60428,
            "fmeasure": 0.59615
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.60428,
            "fmeasure": 0.59615
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "meteor": 0.405957264726726,
        "nubia": {
            "semantic_relation": 4.23853,
            "contradiction": 0.96214,
            "irrelevancy": 60.36963,
            "logical_agreement": 38.66823,
            "grammar_ref": 5.72031,
            "grammar_hyp": 4.82502,
            "nubia_score": 0.77828
        },
        "bleurt": 0.22626,
        "bertscore": {
            "precision": 0.91921,
            "recall": 0.92125,
            "f1": 0.92023
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.51155,
        "nist": 3.982220008759265,
        "rouge1": {
            "precision": 0.63604,
            "recall": 0.57116,
            "fmeasure": 0.57374
        },
        "rouge2": {
            "precision": 0.42892,
            "recall": 0.35747,
            "fmeasure": 0.37049
        },
        "rougeL": {
            "precision": 0.599,
            "recall": 0.54278,
            "fmeasure": 0.54161
        },
        "rougeLsum": {
            "precision": 0.599,
            "recall": 0.54278,
            "fmeasure": 0.54161
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.8
        },
        "meteor": 0.38998886840036134,
        "nubia": {
            "semantic_relation": 3.35289,
            "contradiction": 33.08418,
            "irrelevancy": 49.41711,
            "logical_agreement": 17.49872,
            "grammar_ref": 5.06451,
            "grammar_hyp": 4.65864,
            "nubia_score": 0.56379
        },
        "bleurt": -0.20035,
        "bertscore": {
            "precision": 0.91214,
            "recall": 0.91262,
            "f1": 0.911
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.79322,
        "nist": 4.704468204617686,
        "rouge1": {
            "precision": 0.82181,
            "recall": 0.843,
            "fmeasure": 0.83057
        },
        "rouge2": {
            "precision": 0.68279,
            "recall": 0.70309,
            "fmeasure": 0.69169
        },
        "rougeL": {
            "precision": 0.7894,
            "recall": 0.81144,
            "fmeasure": 0.79909
        },
        "rougeLsum": {
            "precision": 0.7894,
            "recall": 0.81144,
            "fmeasure": 0.79909
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.8305084745762712
        },
        "meteor": 0.4352645583949892,
        "nubia": {
            "semantic_relation": 4.42993,
            "contradiction": 0.61197,
            "irrelevancy": 0.78171,
            "logical_agreement": 98.60632,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.69105,
            "nubia_score": 0.80392
        },
        "bleurt": 0.74438,
        "bertscore": {
            "precision": 0.97665,
            "recall": 0.96883,
            "f1": 0.97232
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.32504,
        "nist": 2.893985157737385,
        "rouge1": {
            "precision": 0.46429,
            "recall": 0.54365,
            "fmeasure": 0.49534
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.35577,
            "fmeasure": 0.32601
        },
        "rougeL": {
            "precision": 0.32143,
            "recall": 0.38095,
            "fmeasure": 0.34472
        },
        "rougeLsum": {
            "precision": 0.32143,
            "recall": 0.38095,
            "fmeasure": 0.34472
        },
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.5
        },
        "meteor": 0.331290953776181,
        "nubia": {
            "semantic_relation": 3.25746,
            "contradiction": 0.09606,
            "irrelevancy": 50.19172,
            "logical_agreement": 49.71223,
            "grammar_ref": 5.77141,
            "grammar_hyp": 4.2394,
            "nubia_score": 0.58294
        },
        "bleurt": 0.06005,
        "bertscore": {
            "precision": 0.92695,
            "recall": 0.92604,
            "f1": 0.92649
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.52981,
        "nist": 4.074170145565851,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.7744,
            "fmeasure": 0.73229
        },
        "rouge2": {
            "precision": 0.48352,
            "recall": 0.52222,
            "fmeasure": 0.49343
        },
        "rougeL": {
            "precision": 0.54048,
            "recall": 0.59219,
            "fmeasure": 0.5568
        },
        "rougeLsum": {
            "precision": 0.54048,
            "recall": 0.59219,
            "fmeasure": 0.5568
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.2,
            "3": 0.8
        },
        "meteor": 0.4262385426208789,
        "nubia": {
            "semantic_relation": 4.50851,
            "contradiction": 0.18178,
            "irrelevancy": 32.84203,
            "logical_agreement": 66.97619,
            "grammar_ref": 5.35082,
            "grammar_hyp": 4.89376,
            "nubia_score": 0.85749
        },
        "bleurt": 0.26632,
        "bertscore": {
            "precision": 0.92407,
            "recall": 0.94956,
            "f1": 0.93635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.8709,
        "nist": 2.3307656971933164,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.58824,
            "fmeasure": 0.625
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.0625,
            "fmeasure": 0.06667
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.29412,
            "fmeasure": 0.3125
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.29412,
            "fmeasure": 0.3125
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "meteor": 0.2994940153951527,
        "nubia": {
            "semantic_relation": 3.45951,
            "contradiction": 2.81848,
            "irrelevancy": 90.04921,
            "logical_agreement": 7.13231,
            "grammar_ref": 3.58521,
            "grammar_hyp": 4.84415,
            "nubia_score": 0.41947
        },
        "bleurt": -0.56138,
        "bertscore": {
            "precision": 0.86942,
            "recall": 0.87011,
            "f1": 0.86976
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 78.42054,
        "nist": 5.295851504144285,
        "rouge1": {
            "precision": 0.87863,
            "recall": 0.84203,
            "fmeasure": 0.85919
        },
        "rouge2": {
            "precision": 0.67262,
            "recall": 0.6622,
            "fmeasure": 0.66706
        },
        "rougeL": {
            "precision": 0.80085,
            "recall": 0.78778,
            "fmeasure": 0.79391
        },
        "rougeLsum": {
            "precision": 0.80085,
            "recall": 0.78778,
            "fmeasure": 0.79391
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 1.0,
            "3": 0.9047619047619048
        },
        "meteor": 0.4730786928372307,
        "nubia": {
            "semantic_relation": 4.96299,
            "contradiction": 0.44744,
            "irrelevancy": 1.03637,
            "logical_agreement": 98.51619,
            "grammar_ref": 5.26806,
            "grammar_hyp": 4.67632,
            "nubia_score": 0.98458
        },
        "bleurt": 0.59972,
        "bertscore": {
            "precision": 0.95583,
            "recall": 0.96214,
            "f1": 0.95887
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.50789957099271,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        },
        "bleurt": 0.89367,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.28146,
        "nist": 4.914079321151252,
        "rouge1": {
            "precision": 0.86039,
            "recall": 0.80994,
            "fmeasure": 0.8307
        },
        "rouge2": {
            "precision": 0.70139,
            "recall": 0.71266,
            "fmeasure": 0.70333
        },
        "rougeL": {
            "precision": 0.79373,
            "recall": 0.75786,
            "fmeasure": 0.77222
        },
        "rougeLsum": {
            "precision": 0.79373,
            "recall": 0.75786,
            "fmeasure": 0.77222
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.5,
            "3": 0.7547169811320755
        },
        "meteor": 0.4241298926727409,
        "nubia": {
            "semantic_relation": 4.62893,
            "contradiction": 0.1463,
            "irrelevancy": 32.67276,
            "logical_agreement": 67.18094,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.27937,
            "nubia_score": 0.87536
        },
        "bleurt": 0.59045,
        "bertscore": {
            "precision": 0.96068,
            "recall": 0.94152,
            "f1": 0.95014
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.91111,
        "nist": 6.042611491021692,
        "rouge1": {
            "precision": 0.90808,
            "recall": 0.84246,
            "fmeasure": 0.87038
        },
        "rouge2": {
            "precision": 0.7022,
            "recall": 0.66011,
            "fmeasure": 0.67795
        },
        "rougeL": {
            "precision": 0.72806,
            "recall": 0.6841,
            "fmeasure": 0.70274
        },
        "rougeLsum": {
            "precision": 0.72806,
            "recall": 0.6841,
            "fmeasure": 0.70274
        },
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.5625,
            "3": 0.8854166666666666
        },
        "meteor": 0.47550688246590384,
        "nubia": {
            "semantic_relation": 4.49743,
            "contradiction": 8.84229,
            "irrelevancy": 11.17635,
            "logical_agreement": 79.98137,
            "grammar_ref": 4.87577,
            "grammar_hyp": 5.01528,
            "nubia_score": 0.79715
        },
        "bleurt": 0.46576,
        "bertscore": {
            "precision": 0.95791,
            "recall": 0.95794,
            "f1": 0.95723
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 71.64036,
        "nist": 5.352120808578938,
        "rouge1": {
            "precision": 0.88337,
            "recall": 0.79516,
            "fmeasure": 0.83566
        },
        "rouge2": {
            "precision": 0.69066,
            "recall": 0.62605,
            "fmeasure": 0.65576
        },
        "rougeL": {
            "precision": 0.81855,
            "recall": 0.74403,
            "fmeasure": 0.77852
        },
        "rougeLsum": {
            "precision": 0.81855,
            "recall": 0.74403,
            "fmeasure": 0.77852
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.2222222222222222,
            "3": 0.8478260869565217
        },
        "meteor": 0.4841365428931994,
        "nubia": {
            "semantic_relation": 4.79545,
            "contradiction": 0.38456,
            "irrelevancy": 0.62528,
            "logical_agreement": 98.99016,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.74816,
            "nubia_score": 0.93347
        },
        "bleurt": 0.53575,
        "bertscore": {
            "precision": 0.97323,
            "recall": 0.95762,
            "f1": 0.96214
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 78.39204,
        "nist": 4.433288378057127,
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rougeLsum": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 0.5347033086663171,
        "nubia": {
            "semantic_relation": 4.85453,
            "contradiction": 0.33848,
            "irrelevancy": 2.11318,
            "logical_agreement": 97.54834,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.31084,
            "nubia_score": 0.99053
        },
        "bleurt": 0.61374,
        "bertscore": {
            "precision": 0.96805,
            "recall": 0.97648,
            "f1": 0.97224
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.82198,
        "nist": 3.0889425391010983,
        "rouge1": {
            "precision": 0.72549,
            "recall": 0.60946,
            "fmeasure": 0.66111
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.26094,
            "fmeasure": 0.2838
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.34706,
            "fmeasure": 0.37593
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.34706,
            "fmeasure": 0.37593
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "meteor": 0.30558972243952476,
        "nubia": {
            "semantic_relation": 3.91822,
            "contradiction": 1.47595,
            "irrelevancy": 5.39868,
            "logical_agreement": 93.12537,
            "grammar_ref": 4.86737,
            "grammar_hyp": 6.22961,
            "nubia_score": 0.49312
        },
        "bleurt": -0.25563,
        "bertscore": {
            "precision": 0.86585,
            "recall": 0.85431,
            "f1": 0.86004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 4.490498678107601,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        },
        "bleurt": 0.92254,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 74.4782,
        "nist": 3.273102223467071,
        "rouge1": {
            "precision": 0.84615,
            "recall": 1.0,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.9,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 1.0,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 1.0,
            "fmeasure": 0.91667
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 0.5684154278946507,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.10633,
            "irrelevancy": 97.37607,
            "logical_agreement": 2.5176,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.75663,
            "nubia_score": 1.0
        },
        "bleurt": 0.56168,
        "bertscore": {
            "precision": 0.94392,
            "recall": 0.99289,
            "f1": 0.96779
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.06976,
        "nist": 0.9464281433050077,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.55897,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.42593,
            "fmeasure": 0.51754
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.55897,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.55897,
            "fmeasure": 0.66667
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.5
        },
        "meteor": 0.4652668047265597,
        "nubia": {
            "semantic_relation": 4.52376,
            "contradiction": 0.23168,
            "irrelevancy": 0.49339,
            "logical_agreement": 99.27493,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.5506,
            "nubia_score": 0.85423
        },
        "bleurt": 0.49097,
        "bertscore": {
            "precision": 0.93954,
            "recall": 0.8942,
            "f1": 0.90947
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.24677,
        "nist": 4.3401552960617495,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.73623,
            "fmeasure": 0.69192
        },
        "rouge2": {
            "precision": 0.425,
            "recall": 0.46429,
            "fmeasure": 0.43838
        },
        "rougeL": {
            "precision": 0.59524,
            "recall": 0.64783,
            "fmeasure": 0.61364
        },
        "rougeLsum": {
            "precision": 0.59524,
            "recall": 0.64783,
            "fmeasure": 0.61364
        },
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.75
        },
        "meteor": 0.39233521192564663,
        "nubia": {
            "semantic_relation": 3.64873,
            "contradiction": 3.05954,
            "irrelevancy": 94.08887,
            "logical_agreement": 2.85159,
            "grammar_ref": 5.51157,
            "grammar_hyp": 5.08717,
            "nubia_score": 0.55576
        },
        "bleurt": -0.14278,
        "bertscore": {
            "precision": 0.93448,
            "recall": 0.94505,
            "f1": 0.93974
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 67.2107,
        "nist": 4.558015776597046,
        "rouge1": {
            "precision": 0.87771,
            "recall": 0.95833,
            "fmeasure": 0.91514
        },
        "rouge2": {
            "precision": 0.69744,
            "recall": 0.75421,
            "fmeasure": 0.72368
        },
        "rougeL": {
            "precision": 0.84199,
            "recall": 0.91667,
            "fmeasure": 0.87668
        },
        "rougeLsum": {
            "precision": 0.84199,
            "recall": 0.91667,
            "fmeasure": 0.87668
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.9473684210526315
        },
        "meteor": 0.5267985314384827,
        "nubia": {
            "semantic_relation": 4.95576,
            "contradiction": 0.13008,
            "irrelevancy": 0.78543,
            "logical_agreement": 99.0845,
            "grammar_ref": 4.16906,
            "grammar_hyp": 4.28386,
            "nubia_score": 0.93717
        },
        "bleurt": 0.78443,
        "bertscore": {
            "precision": 0.96341,
            "recall": 0.9715,
            "f1": 0.96742
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.0932,
        "nist": 3.1279553622998932,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.42719,
            "fmeasure": 0.49264
        },
        "rouge2": {
            "precision": 0.26228,
            "recall": 0.2,
            "fmeasure": 0.22676
        },
        "rougeL": {
            "precision": 0.47778,
            "recall": 0.34522,
            "fmeasure": 0.39015
        },
        "rougeLsum": {
            "precision": 0.47778,
            "recall": 0.34522,
            "fmeasure": 0.39015
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.2,
            "3": 0.6363636363636364
        },
        "meteor": 0.2714996467748611,
        "nubia": {
            "semantic_relation": 3.26687,
            "contradiction": 34.96672,
            "irrelevancy": 14.28134,
            "logical_agreement": 50.75194,
            "grammar_ref": 3.79025,
            "grammar_hyp": 4.90466,
            "nubia_score": 0.54305
        },
        "bleurt": -0.1047,
        "bertscore": {
            "precision": 0.88149,
            "recall": 0.85884,
            "f1": 0.86591
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.93313,
        "nist": 4.584201463304644,
        "rouge1": {
            "precision": 0.6479,
            "recall": 0.65375,
            "fmeasure": 0.63674
        },
        "rouge2": {
            "precision": 0.359,
            "recall": 0.34889,
            "fmeasure": 0.34468
        },
        "rougeL": {
            "precision": 0.53998,
            "recall": 0.54066,
            "fmeasure": 0.52698
        },
        "rougeLsum": {
            "precision": 0.53998,
            "recall": 0.54066,
            "fmeasure": 0.52698
        },
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.75,
            "3": 0.6521739130434783
        },
        "meteor": 0.3502569417802173,
        "nubia": {
            "semantic_relation": 3.9145,
            "contradiction": 14.94642,
            "irrelevancy": 34.77555,
            "logical_agreement": 50.27803,
            "grammar_ref": 5.09695,
            "grammar_hyp": 4.79986,
            "nubia_score": 0.65041
        },
        "bleurt": 0.20049,
        "bertscore": {
            "precision": 0.91221,
            "recall": 0.91067,
            "f1": 0.91131
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 10,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.32537,
        "nist": 6.153599566051739,
        "rouge1": {
            "precision": 0.82586,
            "recall": 0.75231,
            "fmeasure": 0.75426
        },
        "rouge2": {
            "precision": 0.6383,
            "recall": 0.52884,
            "fmeasure": 0.55255
        },
        "rougeL": {
            "precision": 0.71631,
            "recall": 0.62998,
            "fmeasure": 0.64437
        },
        "rougeLsum": {
            "precision": 0.71631,
            "recall": 0.62998,
            "fmeasure": 0.64437
        },
        "local_recall": {
            "1": 0.3695652173913043,
            "2": 0.6666666666666666,
            "3": 0.7789473684210526
        },
        "meteor": 0.42210239488237017,
        "nubia": {
            "semantic_relation": 4.25377,
            "contradiction": 5.55309,
            "irrelevancy": 29.96891,
            "logical_agreement": 64.478,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.4657,
            "nubia_score": 0.69078
        },
        "bleurt": 0.23325,
        "bertscore": {
            "precision": 0.93219,
            "recall": 0.911,
            "f1": 0.91835
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.68651,
        "nist": 4.238135767995471,
        "rouge1": {
            "precision": 0.90794,
            "recall": 0.68828,
            "fmeasure": 0.7784
        },
        "rouge2": {
            "precision": 0.68889,
            "recall": 0.52359,
            "fmeasure": 0.59106
        },
        "rougeL": {
            "precision": 0.8904,
            "recall": 0.67561,
            "fmeasure": 0.7637
        },
        "rougeLsum": {
            "precision": 0.8904,
            "recall": 0.67561,
            "fmeasure": 0.7637
        },
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.6825396825396826
        },
        "meteor": 0.39266579693397474,
        "nubia": {
            "semantic_relation": 3.94021,
            "contradiction": 13.53534,
            "irrelevancy": 36.03448,
            "logical_agreement": 50.43018,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.97154,
            "nubia_score": 0.65161
        },
        "bleurt": 0.12868,
        "bertscore": {
            "precision": 0.94211,
            "recall": 0.90614,
            "f1": 0.9234
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.14156,
        "nist": 3.4595216280661427,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.71429,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.4359,
            "fmeasure": 0.49275
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8
        },
        "meteor": 0.3918734238227112,
        "nubia": {
            "semantic_relation": 4.61109,
            "contradiction": 3.09482,
            "irrelevancy": 8.3594,
            "logical_agreement": 88.54578,
            "grammar_ref": 4.18993,
            "grammar_hyp": 4.96442,
            "nubia_score": 0.74324
        },
        "bleurt": 0.44858,
        "bertscore": {
            "precision": 0.96123,
            "recall": 0.92567,
            "f1": 0.94312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 91.53254,
        "nist": 4.982855333410896,
        "rouge1": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "rougeLsum": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9629629629629629
        },
        "meteor": 0.6276979374374717,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31768,
            "irrelevancy": 0.57052,
            "logical_agreement": 99.11181,
            "grammar_ref": 5.04945,
            "grammar_hyp": 4.81437,
            "nubia_score": 1.0
        },
        "bleurt": 0.87023,
        "bertscore": {
            "precision": 0.99594,
            "recall": 0.99594,
            "f1": 0.99594
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.3219280948873626,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.33373,
            "irrelevancy": 0.59046,
            "logical_agreement": 99.07581,
            "grammar_ref": 6.68645,
            "grammar_hyp": 6.68645,
            "nubia_score": 1.0
        },
        "bleurt": 1.00634,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.52297,
        "nist": 2.8835314119818927,
        "rouge1": {
            "precision": 0.71861,
            "recall": 0.57868,
            "fmeasure": 0.63942
        },
        "rouge2": {
            "precision": 0.475,
            "recall": 0.35157,
            "fmeasure": 0.40231
        },
        "rougeL": {
            "precision": 0.64719,
            "recall": 0.50261,
            "fmeasure": 0.5635
        },
        "rougeLsum": {
            "precision": 0.64719,
            "recall": 0.50261,
            "fmeasure": 0.5635
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "meteor": 0.29164411390228334,
        "nubia": {
            "semantic_relation": 3.75286,
            "contradiction": 47.0687,
            "irrelevancy": 2.74208,
            "logical_agreement": 50.18922,
            "grammar_ref": 3.82725,
            "grammar_hyp": 4.07594,
            "nubia_score": 0.59568
        },
        "bleurt": 0.26675,
        "bertscore": {
            "precision": 0.91508,
            "recall": 0.86973,
            "f1": 0.89015
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.18824,
        "nist": 0.3036309411359068,
        "rouge1": {
            "precision": 0.80702,
            "recall": 0.35984,
            "fmeasure": 0.49744
        },
        "rouge2": {
            "precision": 0.46296,
            "recall": 0.1876,
            "fmeasure": 0.26698
        },
        "rougeL": {
            "precision": 0.75439,
            "recall": 0.31588,
            "fmeasure": 0.44526
        },
        "rougeLsum": {
            "precision": 0.75439,
            "recall": 0.31588,
            "fmeasure": 0.44526
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.4230769230769231
        },
        "meteor": 0.17914541554472918,
        "nubia": {
            "semantic_relation": 3.29492,
            "contradiction": 2.90694,
            "irrelevancy": 95.30153,
            "logical_agreement": 1.79153,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.2606,
            "nubia_score": 0.28391
        },
        "bleurt": -0.6058,
        "bertscore": {
            "precision": 0.9051,
            "recall": 0.8112,
            "f1": 0.85558
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 83.90527,
        "nist": 4.287165657505093,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 0.6317139091272116,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.36033,
            "irrelevancy": 0.57765,
            "logical_agreement": 99.06202,
            "grammar_ref": 6.12532,
            "grammar_hyp": 5.69755,
            "nubia_score": 1.0
        },
        "bleurt": 0.88717,
        "bertscore": {
            "precision": 0.97954,
            "recall": 0.99788,
            "f1": 0.98854
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 76.50922,
        "nist": 4.988961634091554,
        "rouge1": {
            "precision": 0.83516,
            "recall": 0.89899,
            "fmeasure": 0.86558
        },
        "rouge2": {
            "precision": 0.71389,
            "recall": 0.76914,
            "fmeasure": 0.74019
        },
        "rougeL": {
            "precision": 0.83516,
            "recall": 0.89899,
            "fmeasure": 0.86558
        },
        "rougeLsum": {
            "precision": 0.83516,
            "recall": 0.89899,
            "fmeasure": 0.86558
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.9615384615384616
        },
        "meteor": 0.5553026687084012,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24945,
            "irrelevancy": 1.08375,
            "logical_agreement": 98.6668,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.59183,
            "nubia_score": 0.99286
        },
        "bleurt": 0.76317,
        "bertscore": {
            "precision": 0.97506,
            "recall": 0.97921,
            "f1": 0.97713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.88975,
        "nist": 4.499134247810462,
        "rouge1": {
            "precision": 0.6678,
            "recall": 0.74581,
            "fmeasure": 0.70004
        },
        "rouge2": {
            "precision": 0.38736,
            "recall": 0.40465,
            "fmeasure": 0.39077
        },
        "rougeL": {
            "precision": 0.59268,
            "recall": 0.65741,
            "fmeasure": 0.61937
        },
        "rougeLsum": {
            "precision": 0.59268,
            "recall": 0.65741,
            "fmeasure": 0.61937
        },
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.375,
            "3": 0.7777777777777778
        },
        "meteor": 0.3713850157402118,
        "nubia": {
            "semantic_relation": 4.41448,
            "contradiction": 32.32058,
            "irrelevancy": 11.6264,
            "logical_agreement": 56.05302,
            "grammar_ref": 4.10939,
            "grammar_hyp": 3.95896,
            "nubia_score": 0.82241
        },
        "bleurt": 0.2088,
        "bertscore": {
            "precision": 0.92291,
            "recall": 0.93569,
            "f1": 0.92443
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 90.8655,
        "nist": 4.476798555485602,
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9375
        },
        "meteor": 0.5772487688020834,
        "nubia": {
            "semantic_relation": 3.73924,
            "contradiction": 97.74814,
            "irrelevancy": 1.732,
            "logical_agreement": 0.51986,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.11348,
            "nubia_score": 0.53087
        },
        "bleurt": 0.71432,
        "bertscore": {
            "precision": 0.98484,
            "recall": 0.98886,
            "f1": 0.98685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.41303,
        "nist": 3.350916713670631,
        "rouge1": {
            "precision": 0.72917,
            "recall": 0.63322,
            "fmeasure": 0.67689
        },
        "rouge2": {
            "precision": 0.31183,
            "recall": 0.2549,
            "fmeasure": 0.2801
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.54355,
            "fmeasure": 0.58066
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.54355,
            "fmeasure": 0.58066
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.8695652173913043
        },
        "meteor": 0.340147872731139,
        "nubia": {
            "semantic_relation": 3.87713,
            "contradiction": 0.15527,
            "irrelevancy": 87.42458,
            "logical_agreement": 12.42015,
            "grammar_ref": 5.19058,
            "grammar_hyp": 4.95801,
            "nubia_score": 0.67405
        },
        "bleurt": 0.34847,
        "bertscore": {
            "precision": 0.92859,
            "recall": 0.92153,
            "f1": 0.92202
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 10,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.05119,
        "nist": 5.900818829711895,
        "rouge1": {
            "precision": 0.79817,
            "recall": 0.75104,
            "fmeasure": 0.76885
        },
        "rouge2": {
            "precision": 0.61932,
            "recall": 0.59408,
            "fmeasure": 0.60179
        },
        "rougeL": {
            "precision": 0.70674,
            "recall": 0.66865,
            "fmeasure": 0.6824
        },
        "rougeLsum": {
            "precision": 0.70674,
            "recall": 0.66865,
            "fmeasure": 0.6824
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.5555555555555556,
            "3": 0.811965811965812
        },
        "meteor": 0.437170876325763,
        "nubia": {
            "semantic_relation": 4.3197,
            "contradiction": 18.23768,
            "irrelevancy": 28.12776,
            "logical_agreement": 53.63456,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.25225,
            "nubia_score": 0.76736
        },
        "bleurt": 0.43294,
        "bertscore": {
            "precision": 0.94336,
            "recall": 0.94486,
            "f1": 0.94333
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.5215,
        "nist": 1.4761610297087115,
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.58333,
            "fmeasure": 0.51852
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.27273,
            "fmeasure": 0.24
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.41667,
            "fmeasure": 0.37037
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.41667,
            "fmeasure": 0.37037
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "meteor": 0.3066423912784973,
        "nubia": {
            "semantic_relation": 4.32842,
            "contradiction": 0.67715,
            "irrelevancy": 91.55393,
            "logical_agreement": 7.76891,
            "grammar_ref": 5.68739,
            "grammar_hyp": 3.80567,
            "nubia_score": 0.84837
        },
        "bleurt": 0.37815,
        "bertscore": {
            "precision": 0.83394,
            "recall": 0.82768,
            "f1": 0.8308
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.82785,
        "nist": 4.503343760573446,
        "rouge1": {
            "precision": 0.85606,
            "recall": 0.86995,
            "fmeasure": 0.84856
        },
        "rouge2": {
            "precision": 0.64385,
            "recall": 0.60475,
            "fmeasure": 0.61404
        },
        "rougeL": {
            "precision": 0.7803,
            "recall": 0.78314,
            "fmeasure": 0.76742
        },
        "rougeLsum": {
            "precision": 0.7803,
            "recall": 0.78314,
            "fmeasure": 0.76742
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.625,
            "3": 0.95
        },
        "meteor": 0.4626477942431567,
        "nubia": {
            "semantic_relation": 4.5219,
            "contradiction": 0.53303,
            "irrelevancy": 16.79177,
            "logical_agreement": 82.6752,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.37877,
            "nubia_score": 0.8555
        },
        "bleurt": 0.49153,
        "bertscore": {
            "precision": 0.95759,
            "recall": 0.96642,
            "f1": 0.96166
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.98677,
        "nist": 1.5190575580308916,
        "rouge1": {
            "precision": 0.38462,
            "recall": 0.45635,
            "fmeasure": 0.41246
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.10096,
            "fmeasure": 0.09
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.45635,
            "fmeasure": 0.41246
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.45635,
            "fmeasure": 0.41246
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.7142857142857143
        },
        "meteor": 0.2897854994570225,
        "nubia": {
            "semantic_relation": 2.72124,
            "contradiction": 40.85315,
            "irrelevancy": 58.11107,
            "logical_agreement": 1.03578,
            "grammar_ref": 5.58883,
            "grammar_hyp": 4.11355,
            "nubia_score": 0.33116
        },
        "bleurt": 0.07445,
        "bertscore": {
            "precision": 0.82319,
            "recall": 0.8945,
            "f1": 0.85736
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.34885,
        "nist": 4.149418089698814,
        "rouge1": {
            "precision": 0.72243,
            "recall": 0.67588,
            "fmeasure": 0.69002
        },
        "rouge2": {
            "precision": 0.49317,
            "recall": 0.46655,
            "fmeasure": 0.47504
        },
        "rougeL": {
            "precision": 0.6821,
            "recall": 0.64249,
            "fmeasure": 0.65569
        },
        "rougeLsum": {
            "precision": 0.6821,
            "recall": 0.64249,
            "fmeasure": 0.65569
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.15384615384615385,
            "3": 0.8048780487804879
        },
        "meteor": 0.3826675450205834,
        "nubia": {
            "semantic_relation": 4.16126,
            "contradiction": 3.71589,
            "irrelevancy": 39.5615,
            "logical_agreement": 56.72261,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.53682,
            "nubia_score": 0.68168
        },
        "bleurt": 0.1313,
        "bertscore": {
            "precision": 0.92606,
            "recall": 0.91322,
            "f1": 0.91951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 79,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.15692,
        "nist": 7.6503175158323415,
        "rouge1": {
            "precision": 0.7807,
            "recall": 0.75606,
            "fmeasure": 0.75792
        },
        "rouge2": {
            "precision": 0.57798,
            "recall": 0.55585,
            "fmeasure": 0.5591
        },
        "rougeL": {
            "precision": 0.68208,
            "recall": 0.66413,
            "fmeasure": 0.66438
        },
        "rougeLsum": {
            "precision": 0.68208,
            "recall": 0.66413,
            "fmeasure": 0.66438
        },
        "local_recall": {
            "1": 0.1700404858299595,
            "2": 0.5181159420289855,
            "3": 0.8145620022753128
        },
        "meteor": 0.41177970484624066,
        "nubia": {
            "semantic_relation": 4.20548,
            "contradiction": 8.86301,
            "irrelevancy": 30.89075,
            "logical_agreement": 60.24625,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.33522,
            "nubia_score": 0.7439
        },
        "bleurt": 0.33228,
        "bertscore": {
            "precision": 0.93606,
            "recall": 0.93444,
            "f1": 0.93372
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 77.16836,
        "nist": 5.020945219921343,
        "rouge1": {
            "precision": 0.86012,
            "recall": 0.90331,
            "fmeasure": 0.88047
        },
        "rouge2": {
            "precision": 0.79088,
            "recall": 0.86061,
            "fmeasure": 0.82096
        },
        "rougeL": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "rougeLsum": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9354838709677419
        },
        "meteor": 0.5769639229603134,
        "nubia": {
            "semantic_relation": 4.5356,
            "contradiction": 0.50583,
            "irrelevancy": 46.81276,
            "logical_agreement": 52.68141,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.822,
            "nubia_score": 0.83797
        },
        "bleurt": 0.65711,
        "bertscore": {
            "precision": 0.96702,
            "recall": 0.97968,
            "f1": 0.97166
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.74696,
        "nist": 5.340208893043594,
        "rouge1": {
            "precision": 0.79083,
            "recall": 0.7985,
            "fmeasure": 0.75068
        },
        "rouge2": {
            "precision": 0.51218,
            "recall": 0.5339,
            "fmeasure": 0.50862
        },
        "rougeL": {
            "precision": 0.69294,
            "recall": 0.71721,
            "fmeasure": 0.67395
        },
        "rougeLsum": {
            "precision": 0.69294,
            "recall": 0.71721,
            "fmeasure": 0.67395
        },
        "local_recall": {
            "1": 0.1875,
            "2": 0.875,
            "3": 0.7619047619047619
        },
        "meteor": 0.41677511687650787,
        "nubia": {
            "semantic_relation": 3.92597,
            "contradiction": 39.46227,
            "irrelevancy": 37.72813,
            "logical_agreement": 22.8096,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.46654,
            "nubia_score": 0.63178
        },
        "bleurt": 0.23812,
        "bertscore": {
            "precision": 0.92686,
            "recall": 0.92767,
            "f1": 0.92544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.31183,
        "nist": 3.3044718739787506,
        "rouge1": {
            "precision": 0.66369,
            "recall": 0.92037,
            "fmeasure": 0.7707
        },
        "rouge2": {
            "precision": 0.39744,
            "recall": 0.60833,
            "fmeasure": 0.48016
        },
        "rougeL": {
            "precision": 0.60119,
            "recall": 0.83704,
            "fmeasure": 0.69928
        },
        "rougeLsum": {
            "precision": 0.60119,
            "recall": 0.83704,
            "fmeasure": 0.69928
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.9090909090909091
        },
        "meteor": 0.4384576381617188,
        "nubia": {
            "semantic_relation": 4.57717,
            "contradiction": 6.80735,
            "irrelevancy": 38.13462,
            "logical_agreement": 55.05803,
            "grammar_ref": 5.35128,
            "grammar_hyp": 5.04526,
            "nubia_score": 0.84196
        },
        "bleurt": 0.16131,
        "bertscore": {
            "precision": 0.91442,
            "recall": 0.92666,
            "f1": 0.92022
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.15114,
        "nist": 4.526409325664804,
        "rouge1": {
            "precision": 0.74803,
            "recall": 0.80089,
            "fmeasure": 0.77139
        },
        "rouge2": {
            "precision": 0.56603,
            "recall": 0.62113,
            "fmeasure": 0.59194
        },
        "rougeL": {
            "precision": 0.69855,
            "recall": 0.72728,
            "fmeasure": 0.71114
        },
        "rougeLsum": {
            "precision": 0.69855,
            "recall": 0.72728,
            "fmeasure": 0.71114
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.5625,
            "3": 0.9642857142857143
        },
        "meteor": 0.4276321636100229,
        "nubia": {
            "semantic_relation": 3.98854,
            "contradiction": 31.41766,
            "irrelevancy": 24.05041,
            "logical_agreement": 44.53193,
            "grammar_ref": 4.44265,
            "grammar_hyp": 4.05073,
            "nubia_score": 0.71977
        },
        "bleurt": 0.43896,
        "bertscore": {
            "precision": 0.9396,
            "recall": 0.94814,
            "f1": 0.94029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.20705,
        "nist": 1.9310908623735377,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.90236,
            "fmeasure": 0.70716
        },
        "rouge2": {
            "precision": 0.35556,
            "recall": 0.56667,
            "fmeasure": 0.43594
        },
        "rougeL": {
            "precision": 0.52083,
            "recall": 0.80471,
            "fmeasure": 0.63111
        },
        "rougeLsum": {
            "precision": 0.52083,
            "recall": 0.80471,
            "fmeasure": 0.63111
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.75
        },
        "meteor": 0.3678946465265116,
        "nubia": {
            "semantic_relation": 4.06167,
            "contradiction": 3.47017,
            "irrelevancy": 92.76981,
            "logical_agreement": 3.76002,
            "grammar_ref": 6.0554,
            "grammar_hyp": 5.50026,
            "nubia_score": 0.54714
        },
        "bleurt": -0.30603,
        "bertscore": {
            "precision": 0.85368,
            "recall": 0.92296,
            "f1": 0.88697
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.49462,
        "nist": 5.294946046700487,
        "rouge1": {
            "precision": 0.91426,
            "recall": 0.81423,
            "fmeasure": 0.85262
        },
        "rouge2": {
            "precision": 0.63488,
            "recall": 0.55344,
            "fmeasure": 0.58506
        },
        "rougeL": {
            "precision": 0.76415,
            "recall": 0.68678,
            "fmeasure": 0.7168
        },
        "rougeLsum": {
            "precision": 0.76415,
            "recall": 0.68678,
            "fmeasure": 0.7168
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.835820895522388
        },
        "meteor": 0.4357377611393962,
        "nubia": {
            "semantic_relation": 4.57749,
            "contradiction": 0.51201,
            "irrelevancy": 31.68615,
            "logical_agreement": 67.80184,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.79353,
            "nubia_score": 0.77782
        },
        "bleurt": 0.3562,
        "bertscore": {
            "precision": 0.96198,
            "recall": 0.93254,
            "f1": 0.94654
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.48102,
        "nist": 1.0230496061214491,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.34066,
            "fmeasure": 0.45079
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.2094,
            "fmeasure": 0.2846
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.34066,
            "fmeasure": 0.45079
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.34066,
            "fmeasure": 0.45079
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.3
        },
        "meteor": 0.20608244278312962,
        "nubia": {
            "semantic_relation": 3.33875,
            "contradiction": 1.05113,
            "irrelevancy": 6.92351,
            "logical_agreement": 92.02536,
            "grammar_ref": 5.35534,
            "grammar_hyp": 5.13983,
            "nubia_score": 0.48202
        },
        "bleurt": -0.21541,
        "bertscore": {
            "precision": 0.90173,
            "recall": 0.81711,
            "f1": 0.85734
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.27308,
        "nist": 2.679697244721718,
        "rouge1": {
            "precision": 0.60962,
            "recall": 0.58241,
            "fmeasure": 0.57887
        },
        "rouge2": {
            "precision": 0.30429,
            "recall": 0.33621,
            "fmeasure": 0.31029
        },
        "rougeL": {
            "precision": 0.54613,
            "recall": 0.53282,
            "fmeasure": 0.52445
        },
        "rougeLsum": {
            "precision": 0.54613,
            "recall": 0.53282,
            "fmeasure": 0.52445
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.16666666666666666,
            "3": 0.782608695652174
        },
        "meteor": 0.25166150829198686,
        "nubia": {
            "semantic_relation": 3.71199,
            "contradiction": 2.45792,
            "irrelevancy": 33.96613,
            "logical_agreement": 63.57595,
            "grammar_ref": 4.9362,
            "grammar_hyp": 5.16236,
            "nubia_score": 0.59947
        },
        "bleurt": -0.07945,
        "bertscore": {
            "precision": 0.88683,
            "recall": 0.84773,
            "f1": 0.86188
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 76.11606,
        "nist": 4.090634124990776,
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "meteor": 0.5715186082473627,
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        },
        "bleurt": 0.48581,
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.32768,
        "nist": 3.1279996569375683,
        "rouge1": {
            "precision": 0.68421,
            "recall": 0.68421,
            "fmeasure": 0.68421
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.47368,
            "recall": 0.47368,
            "fmeasure": 0.47368
        },
        "rougeLsum": {
            "precision": 0.47368,
            "recall": 0.47368,
            "fmeasure": 0.47368
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "meteor": 0.3412689966604225,
        "nubia": {
            "semantic_relation": 4.0467,
            "contradiction": 0.1709,
            "irrelevancy": 1.43185,
            "logical_agreement": 98.39726,
            "grammar_ref": 4.21408,
            "grammar_hyp": 5.27575,
            "nubia_score": 0.58896
        },
        "bleurt": 0.35845,
        "bertscore": {
            "precision": 0.92242,
            "recall": 0.89058,
            "f1": 0.90622
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.24247,
        "nist": 1.7838057700073988,
        "rouge1": {
            "precision": 0.45833,
            "recall": 0.6875,
            "fmeasure": 0.55
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.42857,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.6875,
            "fmeasure": 0.55
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.6875,
            "fmeasure": 0.55
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.7142857142857143
        },
        "meteor": 0.32052760142913544,
        "nubia": {
            "semantic_relation": 3.69963,
            "contradiction": 1.05846,
            "irrelevancy": 98.13313,
            "logical_agreement": 0.80841,
            "grammar_ref": 5.1072,
            "grammar_hyp": 5.6565,
            "nubia_score": 0.41034
        },
        "bleurt": -1.03933,
        "bertscore": {
            "precision": 0.84105,
            "recall": 0.93123,
            "f1": 0.88384
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 79.61398,
        "nist": 4.413538218275817,
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.9,
            "fmeasure": 0.91228
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.85185,
            "fmeasure": 0.86275
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.86667,
            "fmeasure": 0.87719
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.86667,
            "fmeasure": 0.87719
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.7,
            "3": 1.0
        },
        "meteor": 0.5605502867884248,
        "nubia": {
            "semantic_relation": 4.65167,
            "contradiction": 0.57252,
            "irrelevancy": 15.6934,
            "logical_agreement": 83.73408,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.78744,
            "nubia_score": 0.86596
        },
        "bleurt": 0.70404,
        "bertscore": {
            "precision": 0.97883,
            "recall": 0.96357,
            "f1": 0.97101
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.768492245572466,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.373,
            "irrelevancy": 0.51156,
            "logical_agreement": 99.11544,
            "grammar_ref": 5.07856,
            "grammar_hyp": 5.22425,
            "nubia_score": 0.9763
        },
        "bleurt": 0.97268,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.86002,
        "nist": 4.411390407833928,
        "rouge1": {
            "precision": 0.69544,
            "recall": 0.84668,
            "fmeasure": 0.75283
        },
        "rouge2": {
            "precision": 0.49991,
            "recall": 0.57774,
            "fmeasure": 0.53128
        },
        "rougeL": {
            "precision": 0.55357,
            "recall": 0.70229,
            "fmeasure": 0.60992
        },
        "rougeLsum": {
            "precision": 0.55357,
            "recall": 0.70229,
            "fmeasure": 0.60992
        },
        "local_recall": {
            "1": 0.4375,
            "2": 0.5,
            "3": 0.9736842105263158
        },
        "meteor": 0.4392595993146373,
        "nubia": {
            "semantic_relation": 4.67877,
            "contradiction": 3.82299,
            "irrelevancy": 25.58457,
            "logical_agreement": 70.59243,
            "grammar_ref": 4.54108,
            "grammar_hyp": 3.78954,
            "nubia_score": 0.88803
        },
        "bleurt": 0.48304,
        "bertscore": {
            "precision": 0.91098,
            "recall": 0.92983,
            "f1": 0.9198
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.06103,
        "nist": 3.6711250846630596,
        "rouge1": {
            "precision": 0.56944,
            "recall": 0.68333,
            "fmeasure": 0.62121
        },
        "rouge2": {
            "precision": 0.23188,
            "recall": 0.2846,
            "fmeasure": 0.25552
        },
        "rougeL": {
            "precision": 0.43056,
            "recall": 0.52456,
            "fmeasure": 0.47287
        },
        "rougeLsum": {
            "precision": 0.43056,
            "recall": 0.52456,
            "fmeasure": 0.47287
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.75
        },
        "meteor": 0.3147339658967909,
        "nubia": {
            "semantic_relation": 3.93328,
            "contradiction": 83.4648,
            "irrelevancy": 4.53975,
            "logical_agreement": 11.99545,
            "grammar_ref": 5.26752,
            "grammar_hyp": 4.75614,
            "nubia_score": 0.63329
        },
        "bleurt": -0.09062,
        "bertscore": {
            "precision": 0.85939,
            "recall": 0.87819,
            "f1": 0.86868
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.59596,
        "nist": 2.9153548583181332,
        "rouge1": {
            "precision": 0.5359,
            "recall": 0.49789,
            "fmeasure": 0.51189
        },
        "rouge2": {
            "precision": 0.26528,
            "recall": 0.23977,
            "fmeasure": 0.24875
        },
        "rougeL": {
            "precision": 0.47105,
            "recall": 0.4286,
            "fmeasure": 0.44498
        },
        "rougeLsum": {
            "precision": 0.47105,
            "recall": 0.4286,
            "fmeasure": 0.44498
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.38461538461538464,
            "3": 0.48
        },
        "meteor": 0.27338243972449483,
        "nubia": {
            "semantic_relation": 3.79526,
            "contradiction": 15.08522,
            "irrelevancy": 43.87663,
            "logical_agreement": 41.03815,
            "grammar_ref": 4.28129,
            "grammar_hyp": 4.27888,
            "nubia_score": 0.61943
        },
        "bleurt": 0.10653,
        "bertscore": {
            "precision": 0.88867,
            "recall": 0.88534,
            "f1": 0.88599
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.98806,
        "nist": 4.237054596070422,
        "rouge1": {
            "precision": 0.73237,
            "recall": 0.84202,
            "fmeasure": 0.77045
        },
        "rouge2": {
            "precision": 0.62222,
            "recall": 0.67659,
            "fmeasure": 0.63989
        },
        "rougeL": {
            "precision": 0.73237,
            "recall": 0.84202,
            "fmeasure": 0.77045
        },
        "rougeLsum": {
            "precision": 0.73237,
            "recall": 0.84202,
            "fmeasure": 0.77045
        },
        "local_recall": {
            "1": 0.1875,
            "2": 0.8461538461538461,
            "3": 0.9166666666666666
        },
        "meteor": 0.48211646963074073,
        "nubia": {
            "semantic_relation": 4.58518,
            "contradiction": 0.37984,
            "irrelevancy": 33.60673,
            "logical_agreement": 66.01343,
            "grammar_ref": 5.27099,
            "grammar_hyp": 4.96687,
            "nubia_score": 0.90836
        },
        "bleurt": 0.50145,
        "bertscore": {
            "precision": 0.91856,
            "recall": 0.95598,
            "f1": 0.93376
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.43938,
        "nist": 2.570845176887281,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.69841,
            "fmeasure": 0.75973
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.52564,
            "fmeasure": 0.57556
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.55873,
            "fmeasure": 0.60779
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.55873,
            "fmeasure": 0.60779
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8181818181818182
        },
        "meteor": 0.39919801827160767,
        "nubia": {
            "semantic_relation": 4.94995,
            "contradiction": 0.40619,
            "irrelevancy": 0.65871,
            "logical_agreement": 98.93511,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.14744,
            "nubia_score": 0.82343
        },
        "bleurt": 0.43399,
        "bertscore": {
            "precision": 0.9537,
            "recall": 0.93128,
            "f1": 0.94236
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.3161,
        "nist": 4.216262548574169,
        "rouge1": {
            "precision": 0.71212,
            "recall": 0.79649,
            "fmeasure": 0.75184
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.54581,
            "fmeasure": 0.50855
        },
        "rougeL": {
            "precision": 0.59091,
            "recall": 0.67281,
            "fmeasure": 0.62911
        },
        "rougeLsum": {
            "precision": 0.59091,
            "recall": 0.67281,
            "fmeasure": 0.62911
        },
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "meteor": 0.4132145834932758,
        "nubia": {
            "semantic_relation": 4.328,
            "contradiction": 0.15791,
            "irrelevancy": 1.97533,
            "logical_agreement": 97.86676,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.59156,
            "nubia_score": 0.85865
        },
        "bleurt": 0.28062,
        "bertscore": {
            "precision": 0.9124,
            "recall": 0.92766,
            "f1": 0.91997
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.13978,
        "nist": 3.904780139256394,
        "rouge1": {
            "precision": 0.60326,
            "recall": 0.7964,
            "fmeasure": 0.67014
        },
        "rouge2": {
            "precision": 0.44388,
            "recall": 0.58961,
            "fmeasure": 0.49198
        },
        "rougeL": {
            "precision": 0.50662,
            "recall": 0.68938,
            "fmeasure": 0.5701
        },
        "rougeLsum": {
            "precision": 0.50662,
            "recall": 0.68938,
            "fmeasure": 0.5701
        },
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 1.0,
            "3": 0.8444444444444444
        },
        "meteor": 0.44712532969418833,
        "nubia": {
            "semantic_relation": 4.12731,
            "contradiction": 18.45971,
            "irrelevancy": 33.0409,
            "logical_agreement": 48.49939,
            "grammar_ref": 5.55931,
            "grammar_hyp": 4.8337,
            "nubia_score": 0.7173
        },
        "bleurt": 0.3417,
        "bertscore": {
            "precision": 0.90067,
            "recall": 0.93661,
            "f1": 0.91545
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.7095,
        "nist": 2.7978710291294635,
        "rouge1": {
            "precision": 0.82536,
            "recall": 0.70144,
            "fmeasure": 0.75498
        },
        "rouge2": {
            "precision": 0.54843,
            "recall": 0.46547,
            "fmeasure": 0.50129
        },
        "rougeL": {
            "precision": 0.62963,
            "recall": 0.54219,
            "fmeasure": 0.58055
        },
        "rougeLsum": {
            "precision": 0.62963,
            "recall": 0.54219,
            "fmeasure": 0.58055
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.058823529411764705,
            "3": 0.7777777777777778
        },
        "meteor": 0.37124310048963227,
        "nubia": {
            "semantic_relation": 3.97524,
            "contradiction": 2.49141,
            "irrelevancy": 4.50566,
            "logical_agreement": 93.00293,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.81366,
            "nubia_score": 0.62127
        },
        "bleurt": 0.19725,
        "bertscore": {
            "precision": 0.9571,
            "recall": 0.91759,
            "f1": 0.93682
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.839,
        "nist": 1.9767769323620341,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.53704,
            "fmeasure": 0.61275
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "meteor": 0.41910267807653556,
        "nubia": {
            "semantic_relation": 4.74089,
            "contradiction": 0.54392,
            "irrelevancy": 0.53393,
            "logical_agreement": 98.92214,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.75139,
            "nubia_score": 0.91626
        },
        "bleurt": 0.604,
        "bertscore": {
            "precision": 0.97642,
            "recall": 0.95148,
            "f1": 0.96379
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.14111,
        "nist": 2.6178057091995384,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.9375,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.57895,
            "recall": 0.73333,
            "fmeasure": 0.64706
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.8125,
            "fmeasure": 0.72222
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.8125,
            "fmeasure": 0.72222
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.9090909090909091
        },
        "meteor": 0.4589094242775072,
        "nubia": {
            "semantic_relation": 4.17073,
            "contradiction": 0.62945,
            "irrelevancy": 37.3827,
            "logical_agreement": 61.98784,
            "grammar_ref": 4.67419,
            "grammar_hyp": 4.09622,
            "nubia_score": 0.75322
        },
        "bleurt": 0.51345,
        "bertscore": {
            "precision": 0.89255,
            "recall": 0.97004,
            "f1": 0.92283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.0195,
        "nist": 2.9898332363522426,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "meteor": 0.5064321156600579,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        },
        "bleurt": 0.83294,
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.48395,
        "nist": 3.030594408918269,
        "rouge1": {
            "precision": 0.5493,
            "recall": 0.60689,
            "fmeasure": 0.56378
        },
        "rouge2": {
            "precision": 0.36012,
            "recall": 0.4209,
            "fmeasure": 0.38085
        },
        "rougeL": {
            "precision": 0.52708,
            "recall": 0.61285,
            "fmeasure": 0.55296
        },
        "rougeLsum": {
            "precision": 0.52708,
            "recall": 0.61285,
            "fmeasure": 0.55296
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.16666666666666666,
            "3": 1.0
        },
        "meteor": 0.3028482656863814,
        "nubia": {
            "semantic_relation": 3.65289,
            "contradiction": 8.10816,
            "irrelevancy": 60.18523,
            "logical_agreement": 31.70661,
            "grammar_ref": 4.6519,
            "grammar_hyp": 4.80077,
            "nubia_score": 0.53068
        },
        "bleurt": -0.09403,
        "bertscore": {
            "precision": 0.8696,
            "recall": 0.8954,
            "f1": 0.87762
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 73.44167,
        "nist": 5.326335765535058,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.8946,
            "fmeasure": 0.91676
        },
        "rouge2": {
            "precision": 0.90251,
            "recall": 0.85833,
            "fmeasure": 0.87787
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.87286,
            "fmeasure": 0.89237
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.87286,
            "fmeasure": 0.89237
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 1.0,
            "3": 0.9024390243902439
        },
        "meteor": 0.5309215488603597,
        "nubia": {
            "semantic_relation": 4.66474,
            "contradiction": 0.26942,
            "irrelevancy": 8.76731,
            "logical_agreement": 90.96328,
            "grammar_ref": 5.18336,
            "grammar_hyp": 5.10532,
            "nubia_score": 0.88518
        },
        "bleurt": 0.68538,
        "bertscore": {
            "precision": 0.9814,
            "recall": 0.97725,
            "f1": 0.97788
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.93226,
        "nist": 2.7405478231977827,
        "rouge1": {
            "precision": 0.8879,
            "recall": 0.73298,
            "fmeasure": 0.79866
        },
        "rouge2": {
            "precision": 0.67614,
            "recall": 0.56451,
            "fmeasure": 0.6131
        },
        "rougeL": {
            "precision": 0.83234,
            "recall": 0.70046,
            "fmeasure": 0.75764
        },
        "rougeLsum": {
            "precision": 0.83234,
            "recall": 0.70046,
            "fmeasure": 0.75764
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.06666666666666667,
            "3": 0.8484848484848485
        },
        "meteor": 0.3978964993706149,
        "nubia": {
            "semantic_relation": 4.21653,
            "contradiction": 0.31557,
            "irrelevancy": 6.98394,
            "logical_agreement": 92.70049,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.99731,
            "nubia_score": 0.73786
        },
        "bleurt": 0.23107,
        "bertscore": {
            "precision": 0.96709,
            "recall": 0.9151,
            "f1": 0.94009
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.32296,
        "nist": 4.713943055747063,
        "rouge1": {
            "precision": 0.72218,
            "recall": 0.72497,
            "fmeasure": 0.71054
        },
        "rouge2": {
            "precision": 0.47372,
            "recall": 0.48916,
            "fmeasure": 0.47345
        },
        "rougeL": {
            "precision": 0.59049,
            "recall": 0.5996,
            "fmeasure": 0.58475
        },
        "rougeLsum": {
            "precision": 0.59049,
            "recall": 0.5996,
            "fmeasure": 0.58475
        },
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.39285714285714285,
            "3": 0.7681159420289855
        },
        "meteor": 0.3623620981148542,
        "nubia": {
            "semantic_relation": 3.95893,
            "contradiction": 10.6177,
            "irrelevancy": 55.45089,
            "logical_agreement": 33.93141,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.58878,
            "nubia_score": 0.64673
        },
        "bleurt": 0.23193,
        "bertscore": {
            "precision": 0.9173,
            "recall": 0.91262,
            "f1": 0.91164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.33822,
        "nist": 3.6745013931424397,
        "rouge1": {
            "precision": 0.84211,
            "recall": 0.78966,
            "fmeasure": 0.8121
        },
        "rouge2": {
            "precision": 0.46296,
            "recall": 0.43155,
            "fmeasure": 0.44495
        },
        "rougeL": {
            "precision": 0.57895,
            "recall": 0.63508,
            "fmeasure": 0.60561
        },
        "rougeLsum": {
            "precision": 0.57895,
            "recall": 0.63508,
            "fmeasure": 0.60561
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "meteor": 0.400982817534587,
        "nubia": {
            "semantic_relation": 4.97924,
            "contradiction": 0.1422,
            "irrelevancy": 0.43018,
            "logical_agreement": 99.42761,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.00528,
            "nubia_score": 0.99403
        },
        "bleurt": 0.48516,
        "bertscore": {
            "precision": 0.94797,
            "recall": 0.92785,
            "f1": 0.9364
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.8037,
        "nist": 3.0878882661357028,
        "rouge1": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.7381,
            "fmeasure": 0.72222
        },
        "rougeL": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "rougeLsum": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "meteor": 0.96,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 2.51679,
            "irrelevancy": 0.90907,
            "logical_agreement": 96.57414,
            "grammar_ref": 5.94246,
            "grammar_hyp": 6.43289,
            "nubia_score": 0.86087
        },
        "bleurt": 0.74402,
        "bertscore": {
            "precision": 0.99641,
            "recall": 0.99641,
            "f1": 0.99641
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.11336,
        "nist": 2.1055161915432032,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "meteor": 0.4231469901582543,
        "nubia": {
            "semantic_relation": 4.01521,
            "contradiction": 10.23484,
            "irrelevancy": 37.69891,
            "logical_agreement": 52.06625,
            "grammar_ref": 7.84225,
            "grammar_hyp": 7.31486,
            "nubia_score": 0.66591
        },
        "bleurt": 0.18287,
        "bertscore": {
            "precision": 0.93887,
            "recall": 0.95113,
            "f1": 0.94496
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.76106,
        "nist": 4.742648209034681,
        "rouge1": {
            "precision": 0.78066,
            "recall": 0.63195,
            "fmeasure": 0.68845
        },
        "rouge2": {
            "precision": 0.51481,
            "recall": 0.4045,
            "fmeasure": 0.44328
        },
        "rougeL": {
            "precision": 0.55789,
            "recall": 0.44323,
            "fmeasure": 0.48697
        },
        "rougeLsum": {
            "precision": 0.55789,
            "recall": 0.44323,
            "fmeasure": 0.48697
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.7083333333333334
        },
        "meteor": 0.38660114649555016,
        "nubia": {
            "semantic_relation": 3.95754,
            "contradiction": 10.49942,
            "irrelevancy": 29.87367,
            "logical_agreement": 59.62691,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.67464,
            "nubia_score": 0.65796
        },
        "bleurt": 0.159,
        "bertscore": {
            "precision": 0.91,
            "recall": 0.90233,
            "f1": 0.90512
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 79.64774,
        "nist": 6.014689905344028,
        "rouge1": {
            "precision": 0.89615,
            "recall": 0.94447,
            "fmeasure": 0.91576
        },
        "rouge2": {
            "precision": 0.78146,
            "recall": 0.82089,
            "fmeasure": 0.79701
        },
        "rougeL": {
            "precision": 0.8806,
            "recall": 0.92673,
            "fmeasure": 0.89898
        },
        "rougeLsum": {
            "precision": 0.8806,
            "recall": 0.92673,
            "fmeasure": 0.89898
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.8461538461538461,
            "3": 0.9761904761904762
        },
        "meteor": 0.5500173635991447,
        "nubia": {
            "semantic_relation": 4.36485,
            "contradiction": 21.81439,
            "irrelevancy": 22.87428,
            "logical_agreement": 55.31133,
            "grammar_ref": 4.0718,
            "grammar_hyp": 4.05265,
            "nubia_score": 0.82995
        },
        "bleurt": 0.64002,
        "bertscore": {
            "precision": 0.97729,
            "recall": 0.98327,
            "f1": 0.98026
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.16506,
        "nist": 3.613571118078512,
        "rouge1": {
            "precision": 0.89744,
            "recall": 0.84455,
            "fmeasure": 0.86826
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.57778,
            "fmeasure": 0.59259
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.50481,
            "fmeasure": 0.51989
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.50481,
            "fmeasure": 0.51989
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9166666666666666
        },
        "meteor": 0.4329640618784028,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20449,
            "irrelevancy": 0.46284,
            "logical_agreement": 99.33267,
            "grammar_ref": 4.55634,
            "grammar_hyp": 5.236,
            "nubia_score": 0.89158
        },
        "bleurt": 0.45421,
        "bertscore": {
            "precision": 0.94536,
            "recall": 0.94073,
            "f1": 0.94304
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.19226,
        "nist": 3.221148605480614,
        "rouge1": {
            "precision": 0.62821,
            "recall": 0.67409,
            "fmeasure": 0.6487
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.49167,
            "fmeasure": 0.47348
        },
        "rougeL": {
            "precision": 0.59349,
            "recall": 0.64498,
            "fmeasure": 0.61653
        },
        "rougeLsum": {
            "precision": 0.59349,
            "recall": 0.64498,
            "fmeasure": 0.61653
        },
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.25,
            "3": 0.75
        },
        "meteor": 0.4094603223252393,
        "nubia": {
            "semantic_relation": 4.42216,
            "contradiction": 33.62708,
            "irrelevancy": 13.42816,
            "logical_agreement": 52.94476,
            "grammar_ref": 4.11451,
            "grammar_hyp": 4.43532,
            "nubia_score": 0.77822
        },
        "bleurt": 0.57403,
        "bertscore": {
            "precision": 0.92172,
            "recall": 0.93782,
            "f1": 0.92961
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.7768,
        "nist": 3.2724187706764623,
        "rouge1": {
            "precision": 0.6125,
            "recall": 0.55252,
            "fmeasure": 0.57842
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.23611,
            "fmeasure": 0.25833
        },
        "rougeL": {
            "precision": 0.51667,
            "recall": 0.46891,
            "fmeasure": 0.48946
        },
        "rougeLsum": {
            "precision": 0.51667,
            "recall": 0.46891,
            "fmeasure": 0.48946
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.5882352941176471
        },
        "meteor": 0.31906840705397527,
        "nubia": {
            "semantic_relation": 4.47097,
            "contradiction": 5.40685,
            "irrelevancy": 18.05171,
            "logical_agreement": 76.54144,
            "grammar_ref": 4.56502,
            "grammar_hyp": 5.22461,
            "nubia_score": 0.74656
        },
        "bleurt": 0.40246,
        "bertscore": {
            "precision": 0.91105,
            "recall": 0.89465,
            "f1": 0.90245
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 63.15552,
        "nist": 3.044416035899866,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.72115,
            "fmeasure": 0.735
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.69697,
            "fmeasure": 0.71146
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.72115,
            "fmeasure": 0.735
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.72115,
            "fmeasure": 0.735
        },
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "meteor": 0.3996028084735095,
        "nubia": {
            "semantic_relation": 4.86203,
            "contradiction": 11.34917,
            "irrelevancy": 2.63305,
            "logical_agreement": 86.01777,
            "grammar_ref": 3.96979,
            "grammar_hyp": 3.65881,
            "nubia_score": 0.8564
        },
        "bleurt": 0.75327,
        "bertscore": {
            "precision": 0.97303,
            "recall": 0.95251,
            "f1": 0.96123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.55909,
        "nist": 2.7754739341259422,
        "rouge1": {
            "precision": 0.82778,
            "recall": 0.65346,
            "fmeasure": 0.72932
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.31382,
            "fmeasure": 0.35714
        },
        "rougeL": {
            "precision": 0.57917,
            "recall": 0.45034,
            "fmeasure": 0.50489
        },
        "rougeLsum": {
            "precision": 0.57917,
            "recall": 0.45034,
            "fmeasure": 0.50489
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.8,
            "3": 0.56
        },
        "meteor": 0.30104810361156653,
        "nubia": {
            "semantic_relation": 4.26085,
            "contradiction": 0.35001,
            "irrelevancy": 0.57386,
            "logical_agreement": 99.07614,
            "grammar_ref": 4.18803,
            "grammar_hyp": 4.02544,
            "nubia_score": 0.83157
        },
        "bleurt": 0.18465,
        "bertscore": {
            "precision": 0.90863,
            "recall": 0.84928,
            "f1": 0.87279
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.51975,
        "nist": 1.579867819647426,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.9697,
            "fmeasure": 0.70608
        },
        "rouge2": {
            "precision": 0.5098,
            "recall": 0.93333,
            "fmeasure": 0.65907
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.9697,
            "fmeasure": 0.70608
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.9697,
            "fmeasure": 0.70608
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.875
        },
        "meteor": 0.3866372096002335,
        "nubia": {
            "semantic_relation": 3.27272,
            "contradiction": 5.15817,
            "irrelevancy": 94.40355,
            "logical_agreement": 0.43827,
            "grammar_ref": 4.055,
            "grammar_hyp": 3.98693,
            "nubia_score": 0.44665
        },
        "bleurt": -0.24321,
        "bertscore": {
            "precision": 0.82673,
            "recall": 0.95051,
            "f1": 0.88336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.71019,
        "nist": 3.545758942044469,
        "rouge1": {
            "precision": 0.86364,
            "recall": 0.70833,
            "fmeasure": 0.77592
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.48701,
            "fmeasure": 0.53571
        },
        "rougeL": {
            "precision": 0.86364,
            "recall": 0.70833,
            "fmeasure": 0.77592
        },
        "rougeLsum": {
            "precision": 0.86364,
            "recall": 0.70833,
            "fmeasure": 0.77592
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.9
        },
        "meteor": 0.5225641582077987,
        "nubia": {
            "semantic_relation": 4.61426,
            "contradiction": 0.44628,
            "irrelevancy": 0.61579,
            "logical_agreement": 98.93794,
            "grammar_ref": 5.25223,
            "grammar_hyp": 6.03672,
            "nubia_score": 0.78598
        },
        "bleurt": 0.61144,
        "bertscore": {
            "precision": 0.98285,
            "recall": 0.98285,
            "f1": 0.98285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.24933,
        "nist": 3.9809134810782925,
        "rouge1": {
            "precision": 0.75765,
            "recall": 0.65441,
            "fmeasure": 0.6944
        },
        "rouge2": {
            "precision": 0.49242,
            "recall": 0.40705,
            "fmeasure": 0.43981
        },
        "rougeL": {
            "precision": 0.58977,
            "recall": 0.51446,
            "fmeasure": 0.54072
        },
        "rougeLsum": {
            "precision": 0.58977,
            "recall": 0.51446,
            "fmeasure": 0.54072
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0,
            "3": 0.6666666666666666
        },
        "meteor": 0.3260922440980314,
        "nubia": {
            "semantic_relation": 3.47083,
            "contradiction": 50.13007,
            "irrelevancy": 2.73526,
            "logical_agreement": 47.13467,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.73921,
            "nubia_score": 0.55022
        },
        "bleurt": 0.12527,
        "bertscore": {
            "precision": 0.92436,
            "recall": 0.88535,
            "f1": 0.90139
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.63242,
        "nist": 2.807052310606123,
        "rouge1": {
            "precision": 0.51831,
            "recall": 0.78953,
            "fmeasure": 0.60534
        },
        "rouge2": {
            "precision": 0.29821,
            "recall": 0.47489,
            "fmeasure": 0.35074
        },
        "rougeL": {
            "precision": 0.43971,
            "recall": 0.70251,
            "fmeasure": 0.52322
        },
        "rougeLsum": {
            "precision": 0.43971,
            "recall": 0.70251,
            "fmeasure": 0.52322
        },
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.8666666666666667,
            "3": 0.7692307692307693
        },
        "meteor": 0.3838166458373927,
        "nubia": {
            "semantic_relation": 3.9845,
            "contradiction": 15.85962,
            "irrelevancy": 26.03606,
            "logical_agreement": 58.10432,
            "grammar_ref": 4.63208,
            "grammar_hyp": 4.08958,
            "nubia_score": 0.55332
        },
        "bleurt": 0.13169,
        "bertscore": {
            "precision": 0.85484,
            "recall": 0.92366,
            "f1": 0.88626
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 76.50871,
        "nist": 4.367687996987191,
        "rouge1": {
            "precision": 0.93182,
            "recall": 0.88889,
            "fmeasure": 0.90616
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.76768,
            "fmeasure": 0.77997
        },
        "rougeL": {
            "precision": 0.88636,
            "recall": 0.85,
            "fmeasure": 0.86435
        },
        "rougeLsum": {
            "precision": 0.88636,
            "recall": 0.85,
            "fmeasure": 0.86435
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.8461538461538461,
            "3": 0.8888888888888888
        },
        "meteor": 0.5104486361478292,
        "nubia": {
            "semantic_relation": 4.54528,
            "contradiction": 1.86458,
            "irrelevancy": 2.23629,
            "logical_agreement": 95.89913,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.6509,
            "nubia_score": 0.80656
        },
        "bleurt": 0.67577,
        "bertscore": {
            "precision": 0.99336,
            "recall": 0.97138,
            "f1": 0.98212
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 90.3602,
        "nist": 4.35896469898143,
        "rouge1": {
            "precision": 0.76667,
            "recall": 1.0,
            "fmeasure": 0.8671
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.79365,
            "fmeasure": 0.67778
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 1.0,
            "fmeasure": 0.8671
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 1.0,
            "fmeasure": 0.8671
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 1.0,
            "3": 1.0
        },
        "meteor": 0.5330273631654674,
        "nubia": {
            "semantic_relation": 4.66049,
            "contradiction": 0.15167,
            "irrelevancy": 97.75078,
            "logical_agreement": 2.09756,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.39823,
            "nubia_score": 0.81537
        },
        "bleurt": 0.45305,
        "bertscore": {
            "precision": 0.94724,
            "recall": 0.95307,
            "f1": 0.93621
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.39418,
        "nist": 0.5895371459264219,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.25877,
            "fmeasure": 0.341
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.15526,
            "fmeasure": 0.2046
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.15526,
            "fmeasure": 0.2046
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.25
        },
        "meteor": 0.12955465587044535,
        "nubia": {
            "semantic_relation": 3.77661,
            "contradiction": 0.10284,
            "irrelevancy": 5.54121,
            "logical_agreement": 94.35594,
            "grammar_ref": 4.46991,
            "grammar_hyp": 6.28314,
            "nubia_score": 0.40276
        },
        "bleurt": -0.3148,
        "bertscore": {
            "precision": 0.80376,
            "recall": 0.7727,
            "f1": 0.78792
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.26973,
        "nist": 4.259419386926153,
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.79133,
            "fmeasure": 0.80072
        },
        "rouge2": {
            "precision": 0.62963,
            "recall": 0.59694,
            "fmeasure": 0.60835
        },
        "rougeL": {
            "precision": 0.67778,
            "recall": 0.64592,
            "fmeasure": 0.65729
        },
        "rougeLsum": {
            "precision": 0.67778,
            "recall": 0.64592,
            "fmeasure": 0.65729
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6875,
            "3": 0.8695652173913043
        },
        "meteor": 0.4418119828315844,
        "nubia": {
            "semantic_relation": 4.12588,
            "contradiction": 4.01776,
            "irrelevancy": 62.4033,
            "logical_agreement": 33.57894,
            "grammar_ref": 4.8308,
            "grammar_hyp": 5.105,
            "nubia_score": 0.6334
        },
        "bleurt": 0.32619,
        "bertscore": {
            "precision": 0.9334,
            "recall": 0.94488,
            "f1": 0.93811
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.93459,
        "nist": 2.854679600009621,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.54924,
            "fmeasure": 0.54865
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33089
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.4072,
            "fmeasure": 0.4089
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.4072,
            "fmeasure": 0.4089
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.5555555555555556
        },
        "meteor": 0.35014478157011614,
        "nubia": {
            "semantic_relation": 3.7572,
            "contradiction": 0.09882,
            "irrelevancy": 99.76727,
            "logical_agreement": 0.13391,
            "grammar_ref": 4.84054,
            "grammar_hyp": 4.43163,
            "nubia_score": 0.64875
        },
        "bleurt": -0.17186,
        "bertscore": {
            "precision": 0.8786,
            "recall": 0.90383,
            "f1": 0.89103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.61639,
        "nist": 5.194776605143402,
        "rouge1": {
            "precision": 0.83056,
            "recall": 0.87817,
            "fmeasure": 0.85007
        },
        "rouge2": {
            "precision": 0.67344,
            "recall": 0.71365,
            "fmeasure": 0.68901
        },
        "rougeL": {
            "precision": 0.83056,
            "recall": 0.87817,
            "fmeasure": 0.85007
        },
        "rougeLsum": {
            "precision": 0.83056,
            "recall": 0.87817,
            "fmeasure": 0.85007
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.8666666666666667,
            "3": 0.875
        },
        "meteor": 0.48010785977248505,
        "nubia": {
            "semantic_relation": 3.61045,
            "contradiction": 49.8936,
            "irrelevancy": 0.71411,
            "logical_agreement": 49.3923,
            "grammar_ref": 4.13759,
            "grammar_hyp": 4.09135,
            "nubia_score": 0.60044
        },
        "bleurt": 0.5525,
        "bertscore": {
            "precision": 0.96901,
            "recall": 0.95399,
            "f1": 0.96143
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 70.16879,
        "nist": 3.0286497677077553,
        "rouge1": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.875,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "meteor": 0.5613051214200641,
        "nubia": {
            "semantic_relation": 4.89761,
            "contradiction": 0.83309,
            "irrelevancy": 31.2673,
            "logical_agreement": 67.89961,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.86831,
            "nubia_score": 0.98957
        },
        "bleurt": 0.76221,
        "bertscore": {
            "precision": 0.98524,
            "recall": 0.9921,
            "f1": 0.98866
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.1699250014423126,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        },
        "bleurt": 0.99428,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.45501,
        "nist": 3.1858607969540693,
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.77991,
            "fmeasure": 0.68111
        },
        "rouge2": {
            "precision": 0.42424,
            "recall": 0.51313,
            "fmeasure": 0.44779
        },
        "rougeL": {
            "precision": 0.48611,
            "recall": 0.63568,
            "fmeasure": 0.53278
        },
        "rougeLsum": {
            "precision": 0.48611,
            "recall": 0.63568,
            "fmeasure": 0.53278
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.8666666666666667
        },
        "meteor": 0.44546366525693487,
        "nubia": {
            "semantic_relation": 3.91656,
            "contradiction": 0.19629,
            "irrelevancy": 66.1774,
            "logical_agreement": 33.6263,
            "grammar_ref": 5.09196,
            "grammar_hyp": 4.66602,
            "nubia_score": 0.68568
        },
        "bleurt": -0.01792,
        "bertscore": {
            "precision": 0.89576,
            "recall": 0.94911,
            "f1": 0.92031
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.62935,
        "nist": 2.9138099235398776,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.54575,
            "fmeasure": 0.59627
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.32576,
            "fmeasure": 0.35653
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.38889,
            "fmeasure": 0.41806
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.38889,
            "fmeasure": 0.41806
        },
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.5
        },
        "meteor": 0.2948578160631639,
        "nubia": {
            "semantic_relation": 3.96539,
            "contradiction": 8.9816,
            "irrelevancy": 60.4,
            "logical_agreement": 30.61839,
            "grammar_ref": 4.69116,
            "grammar_hyp": 4.69614,
            "nubia_score": 0.62675
        },
        "bleurt": 0.14199,
        "bertscore": {
            "precision": 0.91275,
            "recall": 0.89815,
            "f1": 0.90153
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.3796,
        "nist": 1.8690357018548505,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.61111,
            "fmeasure": 0.51242
        },
        "rouge2": {
            "precision": 0.05882,
            "recall": 0.08283,
            "fmeasure": 0.06845
        },
        "rougeL": {
            "precision": 0.27778,
            "recall": 0.38194,
            "fmeasure": 0.32026
        },
        "rougeLsum": {
            "precision": 0.27778,
            "recall": 0.38194,
            "fmeasure": 0.32026
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6363636363636364
        },
        "meteor": 0.24252525559750784,
        "nubia": {
            "semantic_relation": 3.88328,
            "contradiction": 0.4889,
            "irrelevancy": 27.66648,
            "logical_agreement": 71.84462,
            "grammar_ref": 5.53377,
            "grammar_hyp": 5.07288,
            "nubia_score": 0.65837
        },
        "bleurt": 0.03264,
        "bertscore": {
            "precision": 0.83645,
            "recall": 0.85194,
            "f1": 0.83743
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.01961,
        "nist": 1.3416491745812238,
        "rouge1": {
            "precision": 0.35556,
            "recall": 0.44048,
            "fmeasure": 0.37928
        },
        "rouge2": {
            "precision": 0.11905,
            "recall": 0.14444,
            "fmeasure": 0.12529
        },
        "rougeL": {
            "precision": 0.22222,
            "recall": 0.2619,
            "fmeasure": 0.23265
        },
        "rougeLsum": {
            "precision": 0.22222,
            "recall": 0.2619,
            "fmeasure": 0.23265
        },
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.5
        },
        "meteor": 0.2522740252861911,
        "nubia": {
            "semantic_relation": 3.44356,
            "contradiction": 0.27882,
            "irrelevancy": 75.02426,
            "logical_agreement": 24.69693,
            "grammar_ref": 4.92688,
            "grammar_hyp": 3.93656,
            "nubia_score": 0.47021
        },
        "bleurt": -0.11254,
        "bertscore": {
            "precision": 0.72817,
            "recall": 0.78129,
            "f1": 0.7216
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 66.93676,
        "nist": 5.01178364865917,
        "rouge1": {
            "precision": 0.87121,
            "recall": 0.88384,
            "fmeasure": 0.8767
        },
        "rouge2": {
            "precision": 0.65606,
            "recall": 0.67424,
            "fmeasure": 0.66472
        },
        "rougeL": {
            "precision": 0.82955,
            "recall": 0.83965,
            "fmeasure": 0.83383
        },
        "rougeLsum": {
            "precision": 0.82955,
            "recall": 0.83965,
            "fmeasure": 0.83383
        },
        "local_recall": {
            "1": 0.2,
            "2": 1.0,
            "3": 0.8947368421052632
        },
        "meteor": 0.4574063926302342,
        "nubia": {
            "semantic_relation": 4.98412,
            "contradiction": 0.60296,
            "irrelevancy": 2.18068,
            "logical_agreement": 97.21636,
            "grammar_ref": 5.62679,
            "grammar_hyp": 5.40314,
            "nubia_score": 0.97414
        },
        "bleurt": 0.77727,
        "bertscore": {
            "precision": 0.97479,
            "recall": 0.98122,
            "f1": 0.97618
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.79138,
        "nist": 2.8409092703986056,
        "rouge1": {
            "precision": 0.77508,
            "recall": 0.63899,
            "fmeasure": 0.69885
        },
        "rouge2": {
            "precision": 0.56984,
            "recall": 0.46389,
            "fmeasure": 0.51036
        },
        "rougeL": {
            "precision": 0.73064,
            "recall": 0.60877,
            "fmeasure": 0.66298
        },
        "rougeLsum": {
            "precision": 0.73064,
            "recall": 0.60877,
            "fmeasure": 0.66298
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.3333333333333333,
            "3": 0.7333333333333333
        },
        "meteor": 0.3842606695609219,
        "nubia": {
            "semantic_relation": 3.90985,
            "contradiction": 1.30999,
            "irrelevancy": 33.72993,
            "logical_agreement": 64.96007,
            "grammar_ref": 4.66623,
            "grammar_hyp": 5.15579,
            "nubia_score": 0.62176
        },
        "bleurt": 0.10662,
        "bertscore": {
            "precision": 0.93275,
            "recall": 0.90244,
            "f1": 0.91285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.47794,
        "nist": 3.3044336075222436,
        "rouge1": {
            "precision": 0.70536,
            "recall": 0.60197,
            "fmeasure": 0.64583
        },
        "rouge2": {
            "precision": 0.45812,
            "recall": 0.38333,
            "fmeasure": 0.4147
        },
        "rougeL": {
            "precision": 0.70536,
            "recall": 0.60197,
            "fmeasure": 0.64583
        },
        "rougeLsum": {
            "precision": 0.70536,
            "recall": 0.60197,
            "fmeasure": 0.64583
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.6333333333333333
        },
        "meteor": 0.3144031182272963,
        "nubia": {
            "semantic_relation": 3.32594,
            "contradiction": 0.42997,
            "irrelevancy": 40.98502,
            "logical_agreement": 58.58501,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.99691,
            "nubia_score": 0.44372
        },
        "bleurt": -0.08838,
        "bertscore": {
            "precision": 0.90864,
            "recall": 0.86072,
            "f1": 0.88402
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.99111,
        "nist": 1.1227137604546689,
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.40179,
            "fmeasure": 0.34314
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855
        },
        "meteor": 0.2731132551770082,
        "nubia": {
            "semantic_relation": 3.78915,
            "contradiction": 2.88897,
            "irrelevancy": 55.44136,
            "logical_agreement": 41.66967,
            "grammar_ref": 4.73918,
            "grammar_hyp": 3.671,
            "nubia_score": 0.66998
        },
        "bleurt": 0.34221,
        "bertscore": {
            "precision": 0.82556,
            "recall": 0.86442,
            "f1": 0.84455
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.52709,
        "nist": 3.0523246202282612,
        "rouge1": {
            "precision": 0.69318,
            "recall": 0.75972,
            "fmeasure": 0.71483
        },
        "rouge2": {
            "precision": 0.36905,
            "recall": 0.45899,
            "fmeasure": 0.40384
        },
        "rougeL": {
            "precision": 0.69318,
            "recall": 0.75972,
            "fmeasure": 0.71483
        },
        "rougeLsum": {
            "precision": 0.69318,
            "recall": 0.75972,
            "fmeasure": 0.71483
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7647058823529411
        },
        "meteor": 0.4713442186150194,
        "nubia": {
            "semantic_relation": 4.36081,
            "contradiction": 4.74495,
            "irrelevancy": 76.49521,
            "logical_agreement": 18.75984,
            "grammar_ref": 4.99735,
            "grammar_hyp": 5.17563,
            "nubia_score": 0.69175
        },
        "bleurt": 0.34041,
        "bertscore": {
            "precision": 0.93099,
            "recall": 0.94239,
            "f1": 0.93586
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.22088,
        "nist": 3.1488583831319157,
        "rouge1": {
            "precision": 0.85,
            "recall": 0.70595,
            "fmeasure": 0.76674
        },
        "rouge2": {
            "precision": 0.57407,
            "recall": 0.47778,
            "fmeasure": 0.51866
        },
        "rougeL": {
            "precision": 0.81667,
            "recall": 0.68634,
            "fmeasure": 0.74204
        },
        "rougeLsum": {
            "precision": 0.81667,
            "recall": 0.68634,
            "fmeasure": 0.74204
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "meteor": 0.46148073561668723,
        "nubia": {
            "semantic_relation": 4.84998,
            "contradiction": 0.67933,
            "irrelevancy": 0.84759,
            "logical_agreement": 98.47307,
            "grammar_ref": 4.6711,
            "grammar_hyp": 4.45245,
            "nubia_score": 0.96441
        },
        "bleurt": 0.41018,
        "bertscore": {
            "precision": 0.97574,
            "recall": 0.95994,
            "f1": 0.96777
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 73.11104,
        "nist": 4.239321883025355,
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.84615,
            "fmeasure": 0.81481
        },
        "rouge2": {
            "precision": 0.61538,
            "recall": 0.75556,
            "fmeasure": 0.6771
        },
        "rougeL": {
            "precision": 0.69048,
            "recall": 0.83683,
            "fmeasure": 0.75556
        },
        "rougeLsum": {
            "precision": 0.69048,
            "recall": 0.83683,
            "fmeasure": 0.75556
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 0.5993181568480667,
        "nubia": {
            "semantic_relation": 4.83079,
            "contradiction": 0.64305,
            "irrelevancy": 37.43744,
            "logical_agreement": 61.91951,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.62903,
            "nubia_score": 0.87262
        },
        "bleurt": 0.20448,
        "bertscore": {
            "precision": 0.92894,
            "recall": 0.97065,
            "f1": 0.94923
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.898626692302749,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.371,
            "irrelevancy": 0.46802,
            "logical_agreement": 99.16099,
            "grammar_ref": 5.30755,
            "grammar_hyp": 5.2666,
            "nubia_score": 1.0
        },
        "bleurt": 0.90186,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.442,
        "nist": 2.582720211079266,
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.45238,
            "fmeasure": 0.49391
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.32168,
            "fmeasure": 0.35611
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.41071,
            "fmeasure": 0.45043
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.41071,
            "fmeasure": 0.45043
        },
        "local_recall": {
            "1": 0.45454545454545453,
            "2": 0.42857142857142855
        },
        "meteor": 0.273779082540772,
        "nubia": {
            "semantic_relation": 3.62348,
            "contradiction": 0.99749,
            "irrelevancy": 43.66901,
            "logical_agreement": 55.3335,
            "grammar_ref": 5.74657,
            "grammar_hyp": 4.91068,
            "nubia_score": 0.58699
        },
        "bleurt": 0.00783,
        "bertscore": {
            "precision": 0.9028,
            "recall": 0.86589,
            "f1": 0.88396
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.22589,
        "nist": 4.210838092738354,
        "rouge1": {
            "precision": 0.71154,
            "recall": 0.80324,
            "fmeasure": 0.72371
        },
        "rouge2": {
            "precision": 0.38194,
            "recall": 0.45825,
            "fmeasure": 0.39547
        },
        "rougeL": {
            "precision": 0.62179,
            "recall": 0.68907,
            "fmeasure": 0.6267
        },
        "rougeLsum": {
            "precision": 0.62179,
            "recall": 0.68907,
            "fmeasure": 0.6267
        },
        "local_recall": {
            "1": 0.38461538461538464,
            "2": 0.8,
            "3": 1.0
        },
        "meteor": 0.41984134501050907,
        "nubia": {
            "semantic_relation": 4.50058,
            "contradiction": 1.68684,
            "irrelevancy": 31.35377,
            "logical_agreement": 66.95939,
            "grammar_ref": 4.46901,
            "grammar_hyp": 4.38066,
            "nubia_score": 0.7794
        },
        "bleurt": 0.39029,
        "bertscore": {
            "precision": 0.91865,
            "recall": 0.946,
            "f1": 0.9316
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.26249,
        "nist": 3.065247778303368,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.66558,
            "fmeasure": 0.63386
        },
        "rouge2": {
            "precision": 0.34799,
            "recall": 0.33598,
            "fmeasure": 0.33951
        },
        "rougeL": {
            "precision": 0.57381,
            "recall": 0.54215,
            "fmeasure": 0.55386
        },
        "rougeLsum": {
            "precision": 0.57381,
            "recall": 0.54215,
            "fmeasure": 0.55386
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.7
        },
        "meteor": 0.31651414227280517,
        "nubia": {
            "semantic_relation": 4.74885,
            "contradiction": 7.31524,
            "irrelevancy": 8.04506,
            "logical_agreement": 84.6397,
            "grammar_ref": 4.12394,
            "grammar_hyp": 4.20461,
            "nubia_score": 0.88155
        },
        "bleurt": 0.33128,
        "bertscore": {
            "precision": 0.91406,
            "recall": 0.90211,
            "f1": 0.90621
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.29032,
        "nist": 4.440817935469431,
        "rouge1": {
            "precision": 0.88988,
            "recall": 0.83539,
            "fmeasure": 0.84671
        },
        "rouge2": {
            "precision": 0.79524,
            "recall": 0.76499,
            "fmeasure": 0.76217
        },
        "rougeL": {
            "precision": 0.84226,
            "recall": 0.80008,
            "fmeasure": 0.80616
        },
        "rougeLsum": {
            "precision": 0.84226,
            "recall": 0.80008,
            "fmeasure": 0.80616
        },
        "local_recall": {
            "1": 0.375,
            "2": 1.0,
            "3": 0.76
        },
        "meteor": 0.4132521690659114,
        "nubia": {
            "semantic_relation": 4.22699,
            "contradiction": 0.2516,
            "irrelevancy": 78.78971,
            "logical_agreement": 20.95869,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.60131,
            "nubia_score": 0.7928
        },
        "bleurt": 0.23003,
        "bertscore": {
            "precision": 0.97023,
            "recall": 0.93782,
            "f1": 0.95344
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 8,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.71418,
        "nist": 5.128477695578328,
        "rouge1": {
            "precision": 0.7361,
            "recall": 0.69166,
            "fmeasure": 0.70189
        },
        "rouge2": {
            "precision": 0.5846,
            "recall": 0.54716,
            "fmeasure": 0.55562
        },
        "rougeL": {
            "precision": 0.66231,
            "recall": 0.61808,
            "fmeasure": 0.62905
        },
        "rougeLsum": {
            "precision": 0.66231,
            "recall": 0.61808,
            "fmeasure": 0.62905
        },
        "local_recall": {
            "1": 0.34615384615384615,
            "2": 0.6216216216216216,
            "3": 0.726027397260274
        },
        "meteor": 0.3728636930294715,
        "nubia": {
            "semantic_relation": 3.64541,
            "contradiction": 26.96778,
            "irrelevancy": 36.28893,
            "logical_agreement": 36.74329,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.13532,
            "nubia_score": 0.56603
        },
        "bleurt": 0.07236,
        "bertscore": {
            "precision": 0.91538,
            "recall": 0.90049,
            "f1": 0.90578
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.4003,
        "nist": 3.976794210440776,
        "rouge1": {
            "precision": 0.82123,
            "recall": 0.76852,
            "fmeasure": 0.78179
        },
        "rouge2": {
            "precision": 0.61139,
            "recall": 0.57763,
            "fmeasure": 0.58355
        },
        "rougeL": {
            "precision": 0.7443,
            "recall": 0.70185,
            "fmeasure": 0.71036
        },
        "rougeLsum": {
            "precision": 0.7443,
            "recall": 0.70185,
            "fmeasure": 0.71036
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5,
            "3": 0.75
        },
        "meteor": 0.40825020990472727,
        "nubia": {
            "semantic_relation": 3.91551,
            "contradiction": 3.91905,
            "irrelevancy": 50.07298,
            "logical_agreement": 46.00796,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.35185,
            "nubia_score": 0.63813
        },
        "bleurt": 0.34266,
        "bertscore": {
            "precision": 0.93218,
            "recall": 0.93312,
            "f1": 0.92334
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.57983,
        "nist": 3.3261409136118623,
        "rouge1": {
            "precision": 0.73235,
            "recall": 0.9213,
            "fmeasure": 0.8154
        },
        "rouge2": {
            "precision": 0.44792,
            "recall": 0.58036,
            "fmeasure": 0.50525
        },
        "rougeL": {
            "precision": 0.62353,
            "recall": 0.78419,
            "fmeasure": 0.69415
        },
        "rougeLsum": {
            "precision": 0.62353,
            "recall": 0.78419,
            "fmeasure": 0.69415
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 0.8421052631578947
        },
        "meteor": 0.43481986477007606,
        "nubia": {
            "semantic_relation": 4.82396,
            "contradiction": 0.43446,
            "irrelevancy": 1.28298,
            "logical_agreement": 98.28255,
            "grammar_ref": 5.10267,
            "grammar_hyp": 4.72698,
            "nubia_score": 0.93
        },
        "bleurt": 0.55663,
        "bertscore": {
            "precision": 0.92893,
            "recall": 0.95347,
            "f1": 0.94103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.05511,
        "nist": 2.2803553387756272,
        "rouge1": {
            "precision": 0.65476,
            "recall": 0.60278,
            "fmeasure": 0.62264
        },
        "rouge2": {
            "precision": 0.30864,
            "recall": 0.28205,
            "fmeasure": 0.29217
        },
        "rougeL": {
            "precision": 0.40476,
            "recall": 0.3716,
            "fmeasure": 0.38431
        },
        "rougeLsum": {
            "precision": 0.40476,
            "recall": 0.3716,
            "fmeasure": 0.38431
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.09090909090909091,
            "3": 0.7142857142857143
        },
        "meteor": 0.2901862950580665,
        "nubia": {
            "semantic_relation": 2.94819,
            "contradiction": 98.93588,
            "irrelevancy": 0.92827,
            "logical_agreement": 0.13585,
            "grammar_ref": 3.4256,
            "grammar_hyp": 3.4291,
            "nubia_score": 0.34472
        },
        "bleurt": -0.13012,
        "bertscore": {
            "precision": 0.87026,
            "recall": 0.84885,
            "f1": 0.85942
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.90498,
        "nist": 2.4042262254365667,
        "rouge1": {
            "precision": 0.57895,
            "recall": 0.4697,
            "fmeasure": 0.51843
        },
        "rouge2": {
            "precision": 0.24074,
            "recall": 0.19255,
            "fmeasure": 0.21388
        },
        "rougeL": {
            "precision": 0.54386,
            "recall": 0.44192,
            "fmeasure": 0.48743
        },
        "rougeLsum": {
            "precision": 0.54386,
            "recall": 0.44192,
            "fmeasure": 0.48743
        },
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.42105263157894735
        },
        "meteor": 0.2857960696305719,
        "nubia": {
            "semantic_relation": 4.17783,
            "contradiction": 0.14886,
            "irrelevancy": 66.27355,
            "logical_agreement": 33.57759,
            "grammar_ref": 4.34096,
            "grammar_hyp": 4.66508,
            "nubia_score": 0.67247
        },
        "bleurt": 0.27402,
        "bertscore": {
            "precision": 0.93803,
            "recall": 0.89512,
            "f1": 0.91607
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.7224676484285957,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.81818,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.40157,
            "contradiction": 5.65972,
            "irrelevancy": 2.65283,
            "logical_agreement": 91.68745,
            "grammar_ref": 4.01628,
            "grammar_hyp": 3.81914,
            "nubia_score": 0.8297
        },
        "bleurt": 0.68577,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.47302,
        "nist": 4.474416099899872,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.56614,
            "fmeasure": 0.56899
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "meteor": 0.4748101853768951,
        "nubia": {
            "semantic_relation": 4.58246,
            "contradiction": 0.86231,
            "irrelevancy": 56.25508,
            "logical_agreement": 42.88262,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.26027,
            "nubia_score": 0.74168
        },
        "bleurt": 0.33863,
        "bertscore": {
            "precision": 0.96933,
            "recall": 0.95282,
            "f1": 0.95899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.0,
        "nist": 2.456435556800404,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 0.5277006683854432,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.14589,
            "irrelevancy": 0.6446,
            "logical_agreement": 98.20952,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.39193,
            "nubia_score": 1.0
        },
        "bleurt": 0.93658,
        "bertscore": {
            "precision": 0.986,
            "recall": 0.99497,
            "f1": 0.99047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.49269,
        "nist": 3.89145926838456,
        "rouge1": {
            "precision": 0.9375,
            "recall": 1.0,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.71429,
            "fmeasure": 0.68966
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.6,
            "fmeasure": 0.58065
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.6,
            "fmeasure": 0.58065
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 0.5178515092602387,
        "nubia": {
            "semantic_relation": 4.92199,
            "contradiction": 0.648,
            "irrelevancy": 14.49103,
            "logical_agreement": 84.86097,
            "grammar_ref": 4.08392,
            "grammar_hyp": 3.84603,
            "nubia_score": 0.96737
        },
        "bleurt": 0.65892,
        "bertscore": {
            "precision": 0.96781,
            "recall": 0.97397,
            "f1": 0.97088
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 7.65512,
        "nist": 2.303443174348202,
        "rouge1": {
            "precision": 0.58974,
            "recall": 0.74411,
            "fmeasure": 0.65657
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.25,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.875
        },
        "meteor": 0.25620429858829163,
        "nubia": {
            "semantic_relation": 4.69526,
            "contradiction": 0.22282,
            "irrelevancy": 22.60821,
            "logical_agreement": 77.16898,
            "grammar_ref": 6.26263,
            "grammar_hyp": 5.42762,
            "nubia_score": 0.83933
        },
        "bleurt": 0.43527,
        "bertscore": {
            "precision": 0.91961,
            "recall": 0.92511,
            "f1": 0.92236
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 89.48393,
        "nist": 5.281588763616596,
        "rouge1": {
            "precision": 0.85965,
            "recall": 0.95,
            "fmeasure": 0.90012
        },
        "rouge2": {
            "precision": 0.7963,
            "recall": 0.88538,
            "fmeasure": 0.83593
        },
        "rougeL": {
            "precision": 0.85965,
            "recall": 0.95,
            "fmeasure": 0.90012
        },
        "rougeLsum": {
            "precision": 0.85965,
            "recall": 0.95,
            "fmeasure": 0.90012
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 1.0
        },
        "meteor": 0.5740078469111655,
        "nubia": {
            "semantic_relation": 4.70409,
            "contradiction": 0.11754,
            "irrelevancy": 10.44754,
            "logical_agreement": 89.43493,
            "grammar_ref": 3.95052,
            "grammar_hyp": 3.86831,
            "nubia_score": 0.95745
        },
        "bleurt": 0.74204,
        "bertscore": {
            "precision": 0.97976,
            "recall": 0.9816,
            "f1": 0.96952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.7979,
        "nist": 4.078922368563326,
        "rouge1": {
            "precision": 0.80098,
            "recall": 0.72851,
            "fmeasure": 0.76296
        },
        "rouge2": {
            "precision": 0.59028,
            "recall": 0.57492,
            "fmeasure": 0.57761
        },
        "rougeL": {
            "precision": 0.61471,
            "recall": 0.64713,
            "fmeasure": 0.62356
        },
        "rougeLsum": {
            "precision": 0.61471,
            "recall": 0.64713,
            "fmeasure": 0.62356
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6363636363636364,
            "3": 0.8888888888888888
        },
        "meteor": 0.4614124890063244,
        "nubia": {
            "semantic_relation": 4.71483,
            "contradiction": 0.36623,
            "irrelevancy": 27.9019,
            "logical_agreement": 71.73187,
            "grammar_ref": 3.87403,
            "grammar_hyp": 3.71742,
            "nubia_score": 0.93284
        },
        "bleurt": 0.43489,
        "bertscore": {
            "precision": 0.96558,
            "recall": 0.95463,
            "f1": 0.95888
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.53787,
        "nist": 3.066860064202288,
        "rouge1": {
            "precision": 0.57971,
            "recall": 0.62802,
            "fmeasure": 0.60092
        },
        "rouge2": {
            "precision": 0.42424,
            "recall": 0.45989,
            "fmeasure": 0.43978
        },
        "rougeL": {
            "precision": 0.53623,
            "recall": 0.58052,
            "fmeasure": 0.55567
        },
        "rougeLsum": {
            "precision": 0.53623,
            "recall": 0.58052,
            "fmeasure": 0.55567
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "meteor": 0.3686982873840118,
        "nubia": {
            "semantic_relation": 3.508,
            "contradiction": 35.60772,
            "irrelevancy": 63.80925,
            "logical_agreement": 0.58303,
            "grammar_ref": 4.95426,
            "grammar_hyp": 4.39058,
            "nubia_score": 0.53332
        },
        "bleurt": -0.02751,
        "bertscore": {
            "precision": 0.87856,
            "recall": 0.89703,
            "f1": 0.88661
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.8037,
        "nist": 3.969023783328203,
        "rouge1": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.7381,
            "fmeasure": 0.72222
        },
        "rougeL": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "rougeLsum": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 0.5046339609688354,
        "nubia": {
            "semantic_relation": 4.23369,
            "contradiction": 0.79699,
            "irrelevancy": 35.69325,
            "logical_agreement": 63.50976,
            "grammar_ref": 7.10682,
            "grammar_hyp": 6.76014,
            "nubia_score": 0.73725
        },
        "bleurt": 0.69484,
        "bertscore": {
            "precision": 0.9703,
            "recall": 0.97351,
            "f1": 0.96978
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 4.423065265165703,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        },
        "bleurt": 0.94038,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.33655,
        "nist": 2.4825334452170633,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "rouge2": {
            "precision": 0.38462,
            "recall": 0.41667,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.5833333333333334
        },
        "meteor": 0.39678596194817073,
        "nubia": {
            "semantic_relation": 4.97599,
            "contradiction": 0.40183,
            "irrelevancy": 6.58471,
            "logical_agreement": 93.01346,
            "grammar_ref": 4.23153,
            "grammar_hyp": 4.06836,
            "nubia_score": 0.96508
        },
        "bleurt": 0.59716,
        "bertscore": {
            "precision": 0.91291,
            "recall": 0.92534,
            "f1": 0.91909
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.08439,
        "nist": 3.2414851729709646,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.74661,
            "fmeasure": 0.81931
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.58333,
            "fmeasure": 0.64412
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.50452,
            "fmeasure": 0.55586
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.50452,
            "fmeasure": 0.55586
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "meteor": 0.47058904521438194,
        "nubia": {
            "semantic_relation": 4.23015,
            "contradiction": 0.30962,
            "irrelevancy": 0.87818,
            "logical_agreement": 98.81219,
            "grammar_ref": 4.29821,
            "grammar_hyp": 4.71423,
            "nubia_score": 0.7174
        },
        "bleurt": 0.49887,
        "bertscore": {
            "precision": 0.96621,
            "recall": 0.95745,
            "f1": 0.96181
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.17703,
        "nist": 4.099350821725215,
        "rouge1": {
            "precision": 0.79192,
            "recall": 0.81818,
            "fmeasure": 0.79688
        },
        "rouge2": {
            "precision": 0.63704,
            "recall": 0.64444,
            "fmeasure": 0.63398
        },
        "rougeL": {
            "precision": 0.77109,
            "recall": 0.78956,
            "fmeasure": 0.77278
        },
        "rougeLsum": {
            "precision": 0.77109,
            "recall": 0.78956,
            "fmeasure": 0.77278
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7741935483870968
        },
        "meteor": 0.44181084054529174,
        "nubia": {
            "semantic_relation": 4.76946,
            "contradiction": 0.61152,
            "irrelevancy": 4.00373,
            "logical_agreement": 95.38475,
            "grammar_ref": 3.77014,
            "grammar_hyp": 3.92471,
            "nubia_score": 0.88735
        },
        "bleurt": 0.62006,
        "bertscore": {
            "precision": 0.96273,
            "recall": 0.96572,
            "f1": 0.96159
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 2.9143184224283365,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.90476,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.48227,
            "contradiction": 0.95878,
            "irrelevancy": 0.57826,
            "logical_agreement": 98.46295,
            "grammar_ref": 5.29735,
            "grammar_hyp": 5.33413,
            "nubia_score": 0.82891
        },
        "bleurt": 0.61495,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.09274,
        "nist": 4.960229422698499,
        "rouge1": {
            "precision": 0.81528,
            "recall": 0.75463,
            "fmeasure": 0.78222
        },
        "rouge2": {
            "precision": 0.60714,
            "recall": 0.5639,
            "fmeasure": 0.58362
        },
        "rougeL": {
            "precision": 0.7375,
            "recall": 0.68796,
            "fmeasure": 0.71064
        },
        "rougeLsum": {
            "precision": 0.7375,
            "recall": 0.68796,
            "fmeasure": 0.71064
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.14285714285714285,
            "3": 0.8095238095238095
        },
        "meteor": 0.47252127274418604,
        "nubia": {
            "semantic_relation": 4.63542,
            "contradiction": 0.24433,
            "irrelevancy": 0.63004,
            "logical_agreement": 99.12563,
            "grammar_ref": 4.56769,
            "grammar_hyp": 5.01346,
            "nubia_score": 0.85326
        },
        "bleurt": 0.39365,
        "bertscore": {
            "precision": 0.95242,
            "recall": 0.95944,
            "f1": 0.95587
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 73.69901,
        "nist": 5.028354446536456,
        "rouge1": {
            "precision": 0.86742,
            "recall": 0.88943,
            "fmeasure": 0.86034
        },
        "rouge2": {
            "precision": 0.78352,
            "recall": 0.83254,
            "fmeasure": 0.78887
        },
        "rougeL": {
            "precision": 0.81187,
            "recall": 0.85268,
            "fmeasure": 0.81615
        },
        "rougeLsum": {
            "precision": 0.81187,
            "recall": 0.85268,
            "fmeasure": 0.81615
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "meteor": 0.5393344873018939,
        "nubia": {
            "semantic_relation": 4.66633,
            "contradiction": 3.66429,
            "irrelevancy": 25.4803,
            "logical_agreement": 70.85541,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.46032,
            "nubia_score": 0.89382
        },
        "bleurt": 0.60281,
        "bertscore": {
            "precision": 0.97469,
            "recall": 0.97838,
            "f1": 0.97476
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.26304,
        "nist": 2.3924953092770256,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "local_recall": {
            "1": 0,
            "2": 0.5454545454545454
        },
        "meteor": 0.3326677810634414,
        "nubia": {
            "semantic_relation": 4.69027,
            "contradiction": 0.92902,
            "irrelevancy": 78.64123,
            "logical_agreement": 20.42976,
            "grammar_ref": 4.80739,
            "grammar_hyp": 5.11281,
            "nubia_score": 0.79617
        },
        "bleurt": 0.16371,
        "bertscore": {
            "precision": 0.86077,
            "recall": 0.82599,
            "f1": 0.84303
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.37185,
        "nist": 3.528728811956428,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.7255,
            "fmeasure": 0.70829
        },
        "rouge2": {
            "precision": 0.40374,
            "recall": 0.41026,
            "fmeasure": 0.39691
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.61916,
            "fmeasure": 0.60873
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.61916,
            "fmeasure": 0.60873
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.6521739130434783
        },
        "meteor": 0.39825920909182894,
        "nubia": {
            "semantic_relation": 4.31758,
            "contradiction": 0.27503,
            "irrelevancy": 73.00692,
            "logical_agreement": 26.71804,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.53157,
            "nubia_score": 0.7222
        },
        "bleurt": 0.10463,
        "bertscore": {
            "precision": 0.91768,
            "recall": 0.92536,
            "f1": 0.92123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.75068,
        "nist": 4.778415600773501,
        "rouge1": {
            "precision": 0.78891,
            "recall": 0.73123,
            "fmeasure": 0.75039
        },
        "rouge2": {
            "precision": 0.52511,
            "recall": 0.47927,
            "fmeasure": 0.49476
        },
        "rougeL": {
            "precision": 0.70834,
            "recall": 0.65303,
            "fmeasure": 0.67187
        },
        "rougeLsum": {
            "precision": 0.70834,
            "recall": 0.65303,
            "fmeasure": 0.67187
        },
        "local_recall": {
            "1": 0.7,
            "2": 0.3333333333333333,
            "3": 0.7631578947368421
        },
        "meteor": 0.409343554627657,
        "nubia": {
            "semantic_relation": 4.16987,
            "contradiction": 0.5322,
            "irrelevancy": 45.43873,
            "logical_agreement": 54.02907,
            "grammar_ref": 5.76985,
            "grammar_hyp": 5.40593,
            "nubia_score": 0.71881
        },
        "bleurt": -0.02267,
        "bertscore": {
            "precision": 0.92945,
            "recall": 0.91353,
            "f1": 0.92098
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.36788,
        "nist": 4.8063317635663445,
        "rouge1": {
            "precision": 0.80395,
            "recall": 0.74162,
            "fmeasure": 0.76656
        },
        "rouge2": {
            "precision": 0.5307,
            "recall": 0.50061,
            "fmeasure": 0.51222
        },
        "rougeL": {
            "precision": 0.66535,
            "recall": 0.63906,
            "fmeasure": 0.64808
        },
        "rougeLsum": {
            "precision": 0.66535,
            "recall": 0.63906,
            "fmeasure": 0.64808
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5833333333333334,
            "3": 0.7857142857142857
        },
        "meteor": 0.3802353842764793,
        "nubia": {
            "semantic_relation": 4.23705,
            "contradiction": 0.2535,
            "irrelevancy": 22.64468,
            "logical_agreement": 77.10182,
            "grammar_ref": 4.42501,
            "grammar_hyp": 4.33928,
            "nubia_score": 0.67846
        },
        "bleurt": 0.34085,
        "bertscore": {
            "precision": 0.94079,
            "recall": 0.9238,
            "f1": 0.93197
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 7.29135,
        "nist": 2.849806969738886,
        "rouge1": {
            "precision": 0.59491,
            "recall": 0.73311,
            "fmeasure": 0.65421
        },
        "rouge2": {
            "precision": 0.1719,
            "recall": 0.21484,
            "fmeasure": 0.19054
        },
        "rougeL": {
            "precision": 0.36343,
            "recall": 0.42485,
            "fmeasure": 0.38574
        },
        "rougeLsum": {
            "precision": 0.36343,
            "recall": 0.42485,
            "fmeasure": 0.38574
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.3333333333333333,
            "3": 0.7586206896551724
        },
        "meteor": 0.33456577349480787,
        "nubia": {
            "semantic_relation": 4.39938,
            "contradiction": 11.93965,
            "irrelevancy": 46.27059,
            "logical_agreement": 41.78976,
            "grammar_ref": 5.969,
            "grammar_hyp": 5.70064,
            "nubia_score": 0.76092
        },
        "bleurt": 0.11043,
        "bertscore": {
            "precision": 0.88882,
            "recall": 0.91479,
            "f1": 0.89987
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 8.91377,
        "nist": 1.3278154570790803,
        "rouge1": {
            "precision": 0.36364,
            "recall": 0.44444,
            "fmeasure": 0.39664
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.09091,
            "fmeasure": 0.09524
        },
        "rougeL": {
            "precision": 0.27273,
            "recall": 0.25,
            "fmeasure": 0.26087
        },
        "rougeLsum": {
            "precision": 0.27273,
            "recall": 0.25,
            "fmeasure": 0.26087
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "meteor": 0.17997203324051753,
        "nubia": {
            "semantic_relation": 3.3466,
            "contradiction": 0.0891,
            "irrelevancy": 99.72366,
            "logical_agreement": 0.18724,
            "grammar_ref": 5.08958,
            "grammar_hyp": 4.7413,
            "nubia_score": 0.51494
        },
        "bleurt": -0.50864,
        "bertscore": {
            "precision": 0.75725,
            "recall": 0.86237,
            "f1": 0.8064
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.00781,
        "nist": 2.066100685052549,
        "rouge1": {
            "precision": 0.47917,
            "recall": 0.61806,
            "fmeasure": 0.53382
        },
        "rouge2": {
            "precision": 0.26061,
            "recall": 0.38917,
            "fmeasure": 0.31042
        },
        "rougeL": {
            "precision": 0.47917,
            "recall": 0.61806,
            "fmeasure": 0.53382
        },
        "rougeLsum": {
            "precision": 0.47917,
            "recall": 0.61806,
            "fmeasure": 0.53382
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.875,
            "3": 0.2
        },
        "meteor": 0.2796373418434973,
        "nubia": {
            "semantic_relation": 3.49128,
            "contradiction": 9.04818,
            "irrelevancy": 61.4865,
            "logical_agreement": 29.46532,
            "grammar_ref": 4.27476,
            "grammar_hyp": 4.52626,
            "nubia_score": 0.48764
        },
        "bleurt": -0.03113,
        "bertscore": {
            "precision": 0.8727,
            "recall": 0.88817,
            "f1": 0.8802
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.58522,
        "nist": 2.955116912262305,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.67917,
            "fmeasure": 0.50871
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 1.0
        },
        "meteor": 0.5139078546685881,
        "nubia": {
            "semantic_relation": 2.89108,
            "contradiction": 0.54,
            "irrelevancy": 98.75045,
            "logical_agreement": 0.70956,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.79961,
            "nubia_score": 0.34265
        },
        "bleurt": -0.33255,
        "bertscore": {
            "precision": 0.89616,
            "recall": 0.94973,
            "f1": 0.92216
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 72.8596,
        "nist": 3.595388587594582,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.84615,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "local_recall": {
            "1": 0,
            "2": 0.6,
            "3": 1.0
        },
        "meteor": 0.529059933593805,
        "nubia": {
            "semantic_relation": 4.58319,
            "contradiction": 0.96556,
            "irrelevancy": 33.96022,
            "logical_agreement": 65.07421,
            "grammar_ref": 6.35753,
            "grammar_hyp": 7.06471,
            "nubia_score": 0.71304
        },
        "bleurt": 0.53575,
        "bertscore": {
            "precision": 0.97941,
            "recall": 0.99369,
            "f1": 0.97388
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.44004,
        "nist": 4.742010037910585,
        "rouge1": {
            "precision": 0.80208,
            "recall": 0.69341,
            "fmeasure": 0.72387
        },
        "rouge2": {
            "precision": 0.69519,
            "recall": 0.57527,
            "fmeasure": 0.60386
        },
        "rougeL": {
            "precision": 0.80208,
            "recall": 0.69341,
            "fmeasure": 0.72387
        },
        "rougeLsum": {
            "precision": 0.80208,
            "recall": 0.69341,
            "fmeasure": 0.72387
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.65,
            "3": 0.7777777777777778
        },
        "meteor": 0.4353924923343405,
        "nubia": {
            "semantic_relation": 3.71097,
            "contradiction": 29.71973,
            "irrelevancy": 34.63529,
            "logical_agreement": 35.64498,
            "grammar_ref": 4.43752,
            "grammar_hyp": 4.6216,
            "nubia_score": 0.59756
        },
        "bleurt": 0.12676,
        "bertscore": {
            "precision": 0.92908,
            "recall": 0.92573,
            "f1": 0.92635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.51001,
        "nist": 2.8102496994210826,
        "rouge1": {
            "precision": 0.6087,
            "recall": 0.6087,
            "fmeasure": 0.6087
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.41288,
            "fmeasure": 0.36683
        },
        "rougeL": {
            "precision": 0.52174,
            "recall": 0.52174,
            "fmeasure": 0.52174
        },
        "rougeLsum": {
            "precision": 0.52174,
            "recall": 0.52174,
            "fmeasure": 0.52174
        },
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "meteor": 0.412168042117757,
        "nubia": {
            "semantic_relation": 3.90139,
            "contradiction": 0.58571,
            "irrelevancy": 34.3426,
            "logical_agreement": 65.07169,
            "grammar_ref": 4.20692,
            "grammar_hyp": 4.17927,
            "nubia_score": 0.66046
        },
        "bleurt": 0.08891,
        "bertscore": {
            "precision": 0.88788,
            "recall": 0.93072,
            "f1": 0.906
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.98526,
        "nist": 3.8419234373175017,
        "rouge1": {
            "precision": 0.63073,
            "recall": 0.7915,
            "fmeasure": 0.69212
        },
        "rouge2": {
            "precision": 0.37698,
            "recall": 0.45084,
            "fmeasure": 0.40645
        },
        "rougeL": {
            "precision": 0.57517,
            "recall": 0.71236,
            "fmeasure": 0.62637
        },
        "rougeLsum": {
            "precision": 0.57517,
            "recall": 0.71236,
            "fmeasure": 0.62637
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.9032258064516129
        },
        "meteor": 0.45099819035793604,
        "nubia": {
            "semantic_relation": 4.12396,
            "contradiction": 0.83619,
            "irrelevancy": 64.62646,
            "logical_agreement": 34.53734,
            "grammar_ref": 5.15251,
            "grammar_hyp": 4.69159,
            "nubia_score": 0.69565
        },
        "bleurt": -0.01734,
        "bertscore": {
            "precision": 0.89815,
            "recall": 0.92027,
            "f1": 0.90883
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.03758,
        "nist": 2.666095248459418,
        "rouge1": {
            "precision": 0.64706,
            "recall": 0.65556,
            "fmeasure": 0.64637
        },
        "rouge2": {
            "precision": 0.52083,
            "recall": 0.51732,
            "fmeasure": 0.51345
        },
        "rougeL": {
            "precision": 0.64706,
            "recall": 0.65556,
            "fmeasure": 0.64637
        },
        "rougeLsum": {
            "precision": 0.64706,
            "recall": 0.65556,
            "fmeasure": 0.64637
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "meteor": 0.36974572391057337,
        "nubia": {
            "semantic_relation": 3.03875,
            "contradiction": 59.78455,
            "irrelevancy": 39.83489,
            "logical_agreement": 0.38056,
            "grammar_ref": 4.44297,
            "grammar_hyp": 4.99707,
            "nubia_score": 0.2492
        },
        "bleurt": -0.23044,
        "bertscore": {
            "precision": 0.83699,
            "recall": 0.91528,
            "f1": 0.87438
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 6,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.8932,
        "nist": 5.352346819149006,
        "rouge1": {
            "precision": 0.78562,
            "recall": 0.83154,
            "fmeasure": 0.805
        },
        "rouge2": {
            "precision": 0.60793,
            "recall": 0.64572,
            "fmeasure": 0.62459
        },
        "rougeL": {
            "precision": 0.67809,
            "recall": 0.71816,
            "fmeasure": 0.69581
        },
        "rougeLsum": {
            "precision": 0.67809,
            "recall": 0.71816,
            "fmeasure": 0.69581
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.55,
            "3": 0.8064516129032258
        },
        "meteor": 0.47405174559626817,
        "nubia": {
            "semantic_relation": 4.63547,
            "contradiction": 3.15607,
            "irrelevancy": 18.17316,
            "logical_agreement": 78.67077,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.47491,
            "nubia_score": 0.85713
        },
        "bleurt": 0.36786,
        "bertscore": {
            "precision": 0.94202,
            "recall": 0.94886,
            "f1": 0.94097
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.50341,
        "nist": 3.926592062147975,
        "rouge1": {
            "precision": 0.80392,
            "recall": 0.69758,
            "fmeasure": 0.74659
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.32222,
            "fmeasure": 0.34641
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57978,
            "fmeasure": 0.61988
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57978,
            "fmeasure": 0.61988
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7142857142857143
        },
        "meteor": 0.37423520854850306,
        "nubia": {
            "semantic_relation": 4.18498,
            "contradiction": 0.21419,
            "irrelevancy": 33.28813,
            "logical_agreement": 66.49768,
            "grammar_ref": 4.42639,
            "grammar_hyp": 4.43353,
            "nubia_score": 0.74514
        },
        "bleurt": 0.26882,
        "bertscore": {
            "precision": 0.93037,
            "recall": 0.92685,
            "f1": 0.92861
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.7457,
        "nist": 3.7193003013624066,
        "rouge1": {
            "precision": 0.73148,
            "recall": 0.7578,
            "fmeasure": 0.74328
        },
        "rouge2": {
            "precision": 0.53676,
            "recall": 0.54563,
            "fmeasure": 0.54026
        },
        "rougeL": {
            "precision": 0.62037,
            "recall": 0.6328,
            "fmeasure": 0.62563
        },
        "rougeLsum": {
            "precision": 0.62037,
            "recall": 0.6328,
            "fmeasure": 0.62563
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8095238095238095
        },
        "meteor": 0.46438136229144406,
        "nubia": {
            "semantic_relation": 4.30043,
            "contradiction": 14.14532,
            "irrelevancy": 12.22237,
            "logical_agreement": 73.63231,
            "grammar_ref": 5.29605,
            "grammar_hyp": 5.20192,
            "nubia_score": 0.74716
        },
        "bleurt": 0.15286,
        "bertscore": {
            "precision": 0.92271,
            "recall": 0.90303,
            "f1": 0.91186
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 5.61892,
        "nist": 1.1864756765647926,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.66111,
            "fmeasure": 0.44249
        },
        "rouge2": {
            "precision": 0.15,
            "recall": 0.31313,
            "fmeasure": 0.20245
        },
        "rougeL": {
            "precision": 0.31746,
            "recall": 0.63333,
            "fmeasure": 0.42229
        },
        "rougeLsum": {
            "precision": 0.31746,
            "recall": 0.63333,
            "fmeasure": 0.42229
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.625
        },
        "meteor": 0.2675203320174052,
        "nubia": {
            "semantic_relation": 3.42605,
            "contradiction": 0.11157,
            "irrelevancy": 99.74625,
            "logical_agreement": 0.14218,
            "grammar_ref": 4.40566,
            "grammar_hyp": 4.65515,
            "nubia_score": 0.37898
        },
        "bleurt": -0.28156,
        "bertscore": {
            "precision": 0.7929,
            "recall": 0.85023,
            "f1": 0.82057
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.41688,
        "nist": 3.969970516821268,
        "rouge1": {
            "precision": 0.63294,
            "recall": 0.57911,
            "fmeasure": 0.57866
        },
        "rouge2": {
            "precision": 0.29513,
            "recall": 0.28657,
            "fmeasure": 0.27728
        },
        "rougeL": {
            "precision": 0.44705,
            "recall": 0.43995,
            "fmeasure": 0.42619
        },
        "rougeLsum": {
            "precision": 0.44705,
            "recall": 0.43995,
            "fmeasure": 0.42619
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.47368421052631576,
            "3": 0.5925925925925926
        },
        "meteor": 0.2931950566300843,
        "nubia": {
            "semantic_relation": 3.50114,
            "contradiction": 7.31969,
            "irrelevancy": 82.01222,
            "logical_agreement": 10.66809,
            "grammar_ref": 4.54253,
            "grammar_hyp": 4.28088,
            "nubia_score": 0.48108
        },
        "bleurt": -0.20063,
        "bertscore": {
            "precision": 0.88223,
            "recall": 0.84904,
            "f1": 0.86222
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 4.098214829261011,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2797,
            "irrelevancy": 0.5863,
            "logical_agreement": 99.13399,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.67996,
            "nubia_score": 0.98883
        },
        "bleurt": 0.94053,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.07109,
        "nist": 1.7577114281254704,
        "rouge1": {
            "precision": 0.71795,
            "recall": 0.48077,
            "fmeasure": 0.56239
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.31132,
            "fmeasure": 0.38749
        },
        "rougeL": {
            "precision": 0.71795,
            "recall": 0.48077,
            "fmeasure": 0.56239
        },
        "rougeLsum": {
            "precision": 0.71795,
            "recall": 0.48077,
            "fmeasure": 0.56239
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5238095238095238
        },
        "meteor": 0.2851386040250059,
        "nubia": {
            "semantic_relation": 3.40048,
            "contradiction": 0.17057,
            "irrelevancy": 49.72166,
            "logical_agreement": 50.10778,
            "grammar_ref": 4.47266,
            "grammar_hyp": 3.87854,
            "nubia_score": 0.62479
        },
        "bleurt": -0.27287,
        "bertscore": {
            "precision": 0.87658,
            "recall": 0.8369,
            "f1": 0.85543
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.39223,
        "nist": 4.231814739926578,
        "rouge1": {
            "precision": 0.77792,
            "recall": 0.73413,
            "fmeasure": 0.75376
        },
        "rouge2": {
            "precision": 0.59429,
            "recall": 0.57052,
            "fmeasure": 0.58103
        },
        "rougeL": {
            "precision": 0.6961,
            "recall": 0.66044,
            "fmeasure": 0.67629
        },
        "rougeLsum": {
            "precision": 0.6961,
            "recall": 0.66044,
            "fmeasure": 0.67629
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.7391304347826086
        },
        "meteor": 0.39128451801232544,
        "nubia": {
            "semantic_relation": 3.66262,
            "contradiction": 42.05462,
            "irrelevancy": 4.57417,
            "logical_agreement": 53.3712,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.92484,
            "nubia_score": 0.66087
        },
        "bleurt": 0.18162,
        "bertscore": {
            "precision": 0.91721,
            "recall": 0.9232,
            "f1": 0.91979
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 71.35499,
        "nist": 2.6631425084871947,
        "rouge1": {
            "precision": 0.88095,
            "recall": 0.73968,
            "fmeasure": 0.79934
        },
        "rouge2": {
            "precision": 0.71795,
            "recall": 0.5873,
            "fmeasure": 0.64052
        },
        "rougeL": {
            "precision": 0.88095,
            "recall": 0.7303,
            "fmeasure": 0.79246
        },
        "rougeLsum": {
            "precision": 0.88095,
            "recall": 0.7303,
            "fmeasure": 0.79246
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "meteor": 0.46571815614664674,
        "nubia": {
            "semantic_relation": 4.32903,
            "contradiction": 0.19876,
            "irrelevancy": 0.44191,
            "logical_agreement": 99.35933,
            "grammar_ref": 2.70093,
            "grammar_hyp": 2.91333,
            "nubia_score": 0.89569
        },
        "bleurt": 0.50883,
        "bertscore": {
            "precision": 0.97898,
            "recall": 0.9747,
            "f1": 0.97683
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.61622,
        "nist": 4.077188313297396,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.75556,
            "fmeasure": 0.77576
        },
        "rouge2": {
            "precision": 0.61404,
            "recall": 0.58047,
            "fmeasure": 0.59566
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.69444,
            "fmeasure": 0.71212
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.69444,
            "fmeasure": 0.71212
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.8571428571428571
        },
        "meteor": 0.4669319701329494,
        "nubia": {
            "semantic_relation": 4.04853,
            "contradiction": 29.203,
            "irrelevancy": 37.94284,
            "logical_agreement": 32.85417,
            "grammar_ref": 4.75667,
            "grammar_hyp": 4.31521,
            "nubia_score": 0.71303
        },
        "bleurt": -0.05657,
        "bertscore": {
            "precision": 0.92866,
            "recall": 0.92074,
            "f1": 0.92468
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.37425,
        "nist": 4.186185062975116,
        "rouge1": {
            "precision": 0.8869,
            "recall": 0.87454,
            "fmeasure": 0.8788
        },
        "rouge2": {
            "precision": 0.7028,
            "recall": 0.70085,
            "fmeasure": 0.70012
        },
        "rougeL": {
            "precision": 0.84524,
            "recall": 0.837,
            "fmeasure": 0.83932
        },
        "rougeLsum": {
            "precision": 0.84524,
            "recall": 0.837,
            "fmeasure": 0.83932
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "meteor": 0.5268872887718299,
        "nubia": {
            "semantic_relation": 4.56147,
            "contradiction": 0.17796,
            "irrelevancy": 49.33775,
            "logical_agreement": 50.48429,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.72623,
            "nubia_score": 0.84833
        },
        "bleurt": 0.53956,
        "bertscore": {
            "precision": 0.96016,
            "recall": 0.96948,
            "f1": 0.9648
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.42014,
        "nist": 0.22125202633764687,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.32479,
            "fmeasure": 0.43636
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.07937,
            "fmeasure": 0.10741
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.29402,
            "fmeasure": 0.38788
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.29402,
            "fmeasure": 0.38788
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.25
        },
        "meteor": 0.14078298802960232,
        "nubia": {
            "semantic_relation": 2.77856,
            "contradiction": 5.43097,
            "irrelevancy": 30.9441,
            "logical_agreement": 63.62493,
            "grammar_ref": 4.61776,
            "grammar_hyp": 5.17462,
            "nubia_score": 0.22176
        },
        "bleurt": -0.86803,
        "bertscore": {
            "precision": 0.84326,
            "recall": 0.76332,
            "f1": 0.8013
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.28288,
        "nist": 2.5164012072813633,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.41429,
            "fmeasure": 0.45299
        },
        "rouge2": {
            "precision": 0.22727,
            "recall": 0.18407,
            "fmeasure": 0.20333
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.41429,
            "fmeasure": 0.45299
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.41429,
            "fmeasure": 0.45299
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.45454545454545453
        },
        "meteor": 0.25064092032410257,
        "nubia": {
            "semantic_relation": 4.16106,
            "contradiction": 20.58533,
            "irrelevancy": 54.35372,
            "logical_agreement": 25.06095,
            "grammar_ref": 4.95834,
            "grammar_hyp": 4.41135,
            "nubia_score": 0.70588
        },
        "bleurt": 0.24495,
        "bertscore": {
            "precision": 0.91641,
            "recall": 0.8909,
            "f1": 0.90347
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 5.29537,
        "nist": 1.6651977279244505,
        "rouge1": {
            "precision": 0.31579,
            "recall": 0.37267,
            "fmeasure": 0.33766
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.13287,
            "fmeasure": 0.11935
        },
        "rougeL": {
            "precision": 0.21053,
            "recall": 0.24845,
            "fmeasure": 0.22511
        },
        "rougeLsum": {
            "precision": 0.21053,
            "recall": 0.24845,
            "fmeasure": 0.22511
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "meteor": 0.24060628958301122,
        "nubia": {
            "semantic_relation": 3.7736,
            "contradiction": 0.08022,
            "irrelevancy": 98.01486,
            "logical_agreement": 1.90492,
            "grammar_ref": 4.57081,
            "grammar_hyp": 3.92836,
            "nubia_score": 0.6764
        },
        "bleurt": -0.14189,
        "bertscore": {
            "precision": 0.78617,
            "recall": 0.80669,
            "f1": 0.7963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.8037,
        "nist": 3.218725846082821,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.68452,
            "fmeasure": 0.69841
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 0.5312513743477362,
        "nubia": {
            "semantic_relation": 4.68121,
            "contradiction": 0.23407,
            "irrelevancy": 0.60193,
            "logical_agreement": 99.164,
            "grammar_ref": 5.1757,
            "grammar_hyp": 5.22369,
            "nubia_score": 0.89839
        },
        "bleurt": 0.58344,
        "bertscore": {
            "precision": 0.98124,
            "recall": 0.97997,
            "f1": 0.97952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 5,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 64.97769,
        "nist": 5.539622030356621,
        "rouge1": {
            "precision": 0.68601,
            "recall": 0.75194,
            "fmeasure": 0.71304
        },
        "rouge2": {
            "precision": 0.5051,
            "recall": 0.56538,
            "fmeasure": 0.53162
        },
        "rougeL": {
            "precision": 0.6249,
            "recall": 0.67282,
            "fmeasure": 0.64312
        },
        "rougeLsum": {
            "precision": 0.6249,
            "recall": 0.67282,
            "fmeasure": 0.64312
        },
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.7647058823529411,
            "3": 0.8857142857142857
        },
        "meteor": 0.51208971861226,
        "nubia": {
            "semantic_relation": 4.1495,
            "contradiction": 8.34694,
            "irrelevancy": 37.51106,
            "logical_agreement": 54.14199,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.54292,
            "nubia_score": 0.7649
        },
        "bleurt": 0.21561,
        "bertscore": {
            "precision": 0.92673,
            "recall": 0.93414,
            "f1": 0.92672
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.86216,
        "nist": 2.374501795988734,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.41667,
            "fmeasure": 0.45455
        },
        "rouge2": {
            "precision": 0.21053,
            "recall": 0.18496,
            "fmeasure": 0.19683
        },
        "rougeL": {
            "precision": 0.35,
            "recall": 0.30934,
            "fmeasure": 0.32828
        },
        "rougeLsum": {
            "precision": 0.35,
            "recall": 0.30934,
            "fmeasure": 0.32828
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.4117647058823529
        },
        "meteor": 0.1816744618288119,
        "nubia": {
            "semantic_relation": 3.5909,
            "contradiction": 0.17539,
            "irrelevancy": 94.7962,
            "logical_agreement": 5.0284,
            "grammar_ref": 3.8277,
            "grammar_hyp": 3.78187,
            "nubia_score": 0.59975
        },
        "bleurt": -0.07265,
        "bertscore": {
            "precision": 0.80051,
            "recall": 0.78056,
            "f1": 0.79041
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 69.64781,
        "nist": 4.887738352275971,
        "rouge1": {
            "precision": 0.85952,
            "recall": 0.88783,
            "fmeasure": 0.87104
        },
        "rouge2": {
            "precision": 0.73793,
            "recall": 0.76364,
            "fmeasure": 0.7481
        },
        "rougeL": {
            "precision": 0.85952,
            "recall": 0.88783,
            "fmeasure": 0.87104
        },
        "rougeLsum": {
            "precision": 0.85952,
            "recall": 0.88783,
            "fmeasure": 0.87104
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8823529411764706
        },
        "meteor": 0.5126984567608056,
        "nubia": {
            "semantic_relation": 4.00999,
            "contradiction": 47.75443,
            "irrelevancy": 10.49811,
            "logical_agreement": 41.74746,
            "grammar_ref": 3.98368,
            "grammar_hyp": 3.98429,
            "nubia_score": 0.69705
        },
        "bleurt": 0.67447,
        "bertscore": {
            "precision": 0.97622,
            "recall": 0.97692,
            "f1": 0.9765
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.49543,
        "nist": 3.6938620982275805,
        "rouge1": {
            "precision": 0.54669,
            "recall": 0.59213,
            "fmeasure": 0.5452
        },
        "rouge2": {
            "precision": 0.31875,
            "recall": 0.41162,
            "fmeasure": 0.35071
        },
        "rougeL": {
            "precision": 0.45191,
            "recall": 0.53628,
            "fmeasure": 0.46649
        },
        "rougeLsum": {
            "precision": 0.45191,
            "recall": 0.53628,
            "fmeasure": 0.46649
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.6,
            "3": 0.5652173913043478
        },
        "meteor": 0.3096485921296308,
        "nubia": {
            "semantic_relation": 3.78404,
            "contradiction": 28.913,
            "irrelevancy": 64.55666,
            "logical_agreement": 6.53035,
            "grammar_ref": 4.39403,
            "grammar_hyp": 3.89989,
            "nubia_score": 0.60348
        },
        "bleurt": 0.23235,
        "bertscore": {
            "precision": 0.86716,
            "recall": 0.90918,
            "f1": 0.88444
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.57065,
        "nist": 2.348432205485288,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.63312,
            "fmeasure": 0.71739
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.50305,
            "fmeasure": 0.57201
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.55443,
            "fmeasure": 0.62593
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.55443,
            "fmeasure": 0.62593
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "meteor": 0.3754545144609819,
        "nubia": {
            "semantic_relation": 4.11844,
            "contradiction": 15.99091,
            "irrelevancy": 2.10853,
            "logical_agreement": 81.90056,
            "grammar_ref": 5.07625,
            "grammar_hyp": 5.05735,
            "nubia_score": 0.61999
        },
        "bleurt": -0.12777,
        "bertscore": {
            "precision": 0.92002,
            "recall": 0.90355,
            "f1": 0.91171
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.36435,
        "nist": 2.4063899334068277,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.52632
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.6,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.6,
            "fmeasure": 0.57143
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "meteor": 0.42367222196762794,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24473,
            "irrelevancy": 0.41557,
            "logical_agreement": 99.3397,
            "grammar_ref": 4.16465,
            "grammar_hyp": 3.98993,
            "nubia_score": 0.99728
        },
        "bleurt": 0.65342,
        "bertscore": {
            "precision": 0.94626,
            "recall": 0.95409,
            "f1": 0.95016
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.60381,
        "nist": 3.9413755045926817,
        "rouge1": {
            "precision": 0.70175,
            "recall": 0.82502,
            "fmeasure": 0.75825
        },
        "rouge2": {
            "precision": 0.61261,
            "recall": 0.72361,
            "fmeasure": 0.66335
        },
        "rougeL": {
            "precision": 0.70175,
            "recall": 0.82502,
            "fmeasure": 0.75825
        },
        "rougeLsum": {
            "precision": 0.70175,
            "recall": 0.82502,
            "fmeasure": 0.75825
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.8148148148148148
        },
        "meteor": 0.48897055738408196,
        "nubia": {
            "semantic_relation": 3.74683,
            "contradiction": 0.17064,
            "irrelevancy": 49.5392,
            "logical_agreement": 50.29016,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.25845,
            "nubia_score": 0.66702
        },
        "bleurt": 0.23906,
        "bertscore": {
            "precision": 0.90364,
            "recall": 0.95649,
            "f1": 0.92841
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 4.73920135143642,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24144,
            "irrelevancy": 0.5072,
            "logical_agreement": 99.25136,
            "grammar_ref": 5.3705,
            "grammar_hyp": 5.23692,
            "nubia_score": 1.0
        },
        "bleurt": 0.75827,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 63.89431,
        "nist": 3.0784512384897154,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.70833,
            "fmeasure": 0.78186
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.52814,
            "fmeasure": 0.56534
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.49242,
            "fmeasure": 0.53922
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.49242,
            "fmeasure": 0.53922
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 1.0
        },
        "meteor": 0.5048336635894275,
        "nubia": {
            "semantic_relation": 3.81738,
            "contradiction": 1.10449,
            "irrelevancy": 39.76545,
            "logical_agreement": 59.13005,
            "grammar_ref": 4.87259,
            "grammar_hyp": 5.04235,
            "nubia_score": 0.52325
        },
        "bleurt": 0.18518,
        "bertscore": {
            "precision": 0.96369,
            "recall": 0.96393,
            "f1": 0.96381
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.13214,
        "nist": 2.6031352050710908,
        "rouge1": {
            "precision": 0.74673,
            "recall": 0.65556,
            "fmeasure": 0.67366
        },
        "rouge2": {
            "precision": 0.55682,
            "recall": 0.51823,
            "fmeasure": 0.51935
        },
        "rougeL": {
            "precision": 0.64951,
            "recall": 0.60714,
            "fmeasure": 0.60944
        },
        "rougeLsum": {
            "precision": 0.64951,
            "recall": 0.60714,
            "fmeasure": 0.60944
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.6333333333333333
        },
        "meteor": 0.35516726222655387,
        "nubia": {
            "semantic_relation": 4.22046,
            "contradiction": 2.2822,
            "irrelevancy": 44.22362,
            "logical_agreement": 53.49418,
            "grammar_ref": 4.16263,
            "grammar_hyp": 4.25864,
            "nubia_score": 0.65678
        },
        "bleurt": 0.09574,
        "bertscore": {
            "precision": 0.91764,
            "recall": 0.88035,
            "f1": 0.8979
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.4738,
        "nist": 2.16464204898994,
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.67194,
            "fmeasure": 0.76282
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.50649,
            "fmeasure": 0.58321
        },
        "rougeL": {
            "precision": 0.86275,
            "recall": 0.6469,
            "fmeasure": 0.73932
        },
        "rougeLsum": {
            "precision": 0.86275,
            "recall": 0.6469,
            "fmeasure": 0.73932
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6470588235294118
        },
        "meteor": 0.36965678671016855,
        "nubia": {
            "semantic_relation": 4.15957,
            "contradiction": 0.21322,
            "irrelevancy": 1.43833,
            "logical_agreement": 98.34845,
            "grammar_ref": 3.0511,
            "grammar_hyp": 2.99726,
            "nubia_score": 0.86765
        },
        "bleurt": 0.24605,
        "bertscore": {
            "precision": 0.94974,
            "recall": 0.91037,
            "f1": 0.92964
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.10725,
        "nist": 2.7109047337507373,
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "meteor": 0.5033950705050299,
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        },
        "bleurt": 0.22576,
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 7.68785,
        "nist": 0.9346258422306595,
        "rouge1": {
            "precision": 0.40741,
            "recall": 0.29048,
            "fmeasure": 0.33715
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.08625,
            "fmeasure": 0.10192
        },
        "rougeL": {
            "precision": 0.40741,
            "recall": 0.29048,
            "fmeasure": 0.33715
        },
        "rougeLsum": {
            "precision": 0.40741,
            "recall": 0.29048,
            "fmeasure": 0.33715
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.3333333333333333
        },
        "meteor": 0.20497750744036802,
        "nubia": {
            "semantic_relation": 2.67943,
            "contradiction": 70.69571,
            "irrelevancy": 25.72543,
            "logical_agreement": 3.57886,
            "grammar_ref": 4.72922,
            "grammar_hyp": 4.53765,
            "nubia_score": 0.23886
        },
        "bleurt": -0.08629,
        "bertscore": {
            "precision": 0.85281,
            "recall": 0.83308,
            "f1": 0.83958
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.61744,
        "nist": 2.033910253595537,
        "rouge1": {
            "precision": 0.39766,
            "recall": 0.84995,
            "fmeasure": 0.54179
        },
        "rouge2": {
            "precision": 0.2381,
            "recall": 0.51897,
            "fmeasure": 0.32641
        },
        "rougeL": {
            "precision": 0.32749,
            "recall": 0.69991,
            "fmeasure": 0.44617
        },
        "rougeLsum": {
            "precision": 0.32749,
            "recall": 0.69991,
            "fmeasure": 0.44617
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8333333333333334,
            "3": 1.0
        },
        "meteor": 0.37462113472359804,
        "nubia": {
            "semantic_relation": 3.59975,
            "contradiction": 21.88627,
            "irrelevancy": 48.94219,
            "logical_agreement": 29.17154,
            "grammar_ref": 4.65446,
            "grammar_hyp": 4.09437,
            "nubia_score": 0.09401
        },
        "bleurt": -0.3387,
        "bertscore": {
            "precision": 0.85237,
            "recall": 0.94262,
            "f1": 0.89417
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 70.76534,
        "nist": 3.9567393831281468,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.84211,
            "fmeasure": 0.86486
        },
        "rouge2": {
            "precision": 0.76471,
            "recall": 0.72222,
            "fmeasure": 0.74286
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.84211,
            "fmeasure": 0.86486
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.84211,
            "fmeasure": 0.86486
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8666666666666667
        },
        "meteor": 0.49899353704580235,
        "nubia": {
            "semantic_relation": 4.34284,
            "contradiction": 0.21763,
            "irrelevancy": 0.89196,
            "logical_agreement": 98.89041,
            "grammar_ref": 3.47563,
            "grammar_hyp": 3.70802,
            "nubia_score": 0.84306
        },
        "bleurt": 0.6042,
        "bertscore": {
            "precision": 0.94501,
            "recall": 0.93744,
            "f1": 0.94121
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.08888,
        "nist": 4.65590480278137,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.7453,
            "fmeasure": 0.80988
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.39683,
            "fmeasure": 0.42319
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.66154,
            "fmeasure": 0.70222
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.66154,
            "fmeasure": 0.70222
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.5714285714285714,
            "3": 1.0
        },
        "meteor": 0.3764911641629794,
        "nubia": {
            "semantic_relation": 4.44692,
            "contradiction": 0.10357,
            "irrelevancy": 66.39113,
            "logical_agreement": 33.5053,
            "grammar_ref": 5.94843,
            "grammar_hyp": 5.74742,
            "nubia_score": 0.81083
        },
        "bleurt": 0.38981,
        "bertscore": {
            "precision": 0.94397,
            "recall": 0.93146,
            "f1": 0.93664
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.89932,
        "nist": 2.594477333533169,
        "rouge1": {
            "precision": 0.57576,
            "recall": 0.80833,
            "fmeasure": 0.67236
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.44074,
            "fmeasure": 0.37892
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.59211,
            "fmeasure": 0.51348
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.59211,
            "fmeasure": 0.51348
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "meteor": 0.3872114700044454,
        "nubia": {
            "semantic_relation": 3.99346,
            "contradiction": 0.08194,
            "irrelevancy": 95.28526,
            "logical_agreement": 4.63279,
            "grammar_ref": 5.46955,
            "grammar_hyp": 4.43023,
            "nubia_score": 0.75652
        },
        "bleurt": 0.0886,
        "bertscore": {
            "precision": 0.85392,
            "recall": 0.89469,
            "f1": 0.87383
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 4.23331430181648,
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.88462,
            "fmeasure": 0.9
        },
        "rougeL": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 3.77055,
            "contradiction": 48.79365,
            "irrelevancy": 1.17603,
            "logical_agreement": 50.03032,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.40036,
            "nubia_score": 0.71443
        },
        "bleurt": 0.56405,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.09507,
        "nist": 2.472341254308068,
        "rouge1": {
            "precision": 0.90741,
            "recall": 0.53226,
            "fmeasure": 0.67092
        },
        "rouge2": {
            "precision": 0.41176,
            "recall": 0.2899,
            "fmeasure": 0.33861
        },
        "rougeL": {
            "precision": 0.46296,
            "recall": 0.33188,
            "fmeasure": 0.38516
        },
        "rougeLsum": {
            "precision": 0.46296,
            "recall": 0.33188,
            "fmeasure": 0.38516
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.4444444444444444
        },
        "meteor": 0.2806378762597664,
        "nubia": {
            "semantic_relation": 3.84256,
            "contradiction": 0.12386,
            "irrelevancy": 45.54447,
            "logical_agreement": 54.33167,
            "grammar_ref": 3.59602,
            "grammar_hyp": 3.50533,
            "nubia_score": 0.67361
        },
        "bleurt": -0.02103,
        "bertscore": {
            "precision": 0.94251,
            "recall": 0.89563,
            "f1": 0.91404
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.46849,
        "nist": 1.945124321596613,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.47619,
            "fmeasure": 0.45977
        },
        "rouge2": {
            "precision": 0.11905,
            "recall": 0.12821,
            "fmeasure": 0.12346
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.35714,
            "fmeasure": 0.34483
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.35714,
            "fmeasure": 0.34483
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.42857142857142855
        },
        "meteor": 0.2774030809556632,
        "nubia": {
            "semantic_relation": 3.06946,
            "contradiction": 1.16847,
            "irrelevancy": 98.50956,
            "logical_agreement": 0.32197,
            "grammar_ref": 3.90604,
            "grammar_hyp": 3.65676,
            "nubia_score": 0.4662
        },
        "bleurt": -0.17023,
        "bertscore": {
            "precision": 0.77803,
            "recall": 0.83209,
            "f1": 0.80261
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.35234,
        "nist": 2.038944894698677,
        "rouge1": {
            "precision": 0.62963,
            "recall": 0.48485,
            "fmeasure": 0.54762
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.21515,
            "fmeasure": 0.24756
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.38889,
            "fmeasure": 0.45635
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.38889,
            "fmeasure": 0.45635
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.5
        },
        "meteor": 0.24545494528992856,
        "nubia": {
            "semantic_relation": 3.91397,
            "contradiction": 0.94826,
            "irrelevancy": 45.28218,
            "logical_agreement": 53.76955,
            "grammar_ref": 4.53537,
            "grammar_hyp": 4.57978,
            "nubia_score": 0.61473
        },
        "bleurt": 0.05805,
        "bertscore": {
            "precision": 0.8988,
            "recall": 0.87691,
            "f1": 0.88772
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.303,
        "nist": 3.7062322616466656,
        "rouge1": {
            "precision": 0.6811,
            "recall": 0.66235,
            "fmeasure": 0.66834
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.45049,
            "fmeasure": 0.44498
        },
        "rougeL": {
            "precision": 0.65455,
            "recall": 0.64012,
            "fmeasure": 0.64414
        },
        "rougeLsum": {
            "precision": 0.65455,
            "recall": 0.64012,
            "fmeasure": 0.64414
        },
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.5,
            "3": 0.5833333333333334
        },
        "meteor": 0.3115835088537224,
        "nubia": {
            "semantic_relation": 3.80817,
            "contradiction": 16.74219,
            "irrelevancy": 20.17392,
            "logical_agreement": 63.08389,
            "grammar_ref": 4.46773,
            "grammar_hyp": 4.10602,
            "nubia_score": 0.64683
        },
        "bleurt": 0.17562,
        "bertscore": {
            "precision": 0.92028,
            "recall": 0.90461,
            "f1": 0.91131
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.20044,
        "nist": 2.522383722603699,
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.78314,
            "fmeasure": 0.76217
        },
        "rouge2": {
            "precision": 0.69167,
            "recall": 0.5,
            "fmeasure": 0.57926
        },
        "rougeL": {
            "precision": 0.82492,
            "recall": 0.61553,
            "fmeasure": 0.7037
        },
        "rougeLsum": {
            "precision": 0.82492,
            "recall": 0.61553,
            "fmeasure": 0.7037
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.631578947368421
        },
        "meteor": 0.3319159940420885,
        "nubia": {
            "semantic_relation": 3.99998,
            "contradiction": 0.21264,
            "irrelevancy": 16.70052,
            "logical_agreement": 83.08684,
            "grammar_ref": 4.70595,
            "grammar_hyp": 6.32903,
            "nubia_score": 0.50649
        },
        "bleurt": 0.26976,
        "bertscore": {
            "precision": 0.94682,
            "recall": 0.86477,
            "f1": 0.90391
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.30393,
        "nist": 2.489870649457386,
        "rouge1": {
            "precision": 0.77083,
            "recall": 0.72807,
            "fmeasure": 0.74762
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.5037,
            "fmeasure": 0.51717
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.53289,
            "fmeasure": 0.54643
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.53289,
            "fmeasure": 0.54643
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "meteor": 0.36462415670739146,
        "nubia": {
            "semantic_relation": 4.23324,
            "contradiction": 0.08035,
            "irrelevancy": 5.78534,
            "logical_agreement": 94.1343,
            "grammar_ref": 4.542,
            "grammar_hyp": 4.02563,
            "nubia_score": 0.83932
        },
        "bleurt": -0.13132,
        "bertscore": {
            "precision": 0.88689,
            "recall": 0.81338,
            "f1": 0.84795
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.07915,
        "nist": 4.266342600392025,
        "rouge1": {
            "precision": 0.7519,
            "recall": 0.78256,
            "fmeasure": 0.75753
        },
        "rouge2": {
            "precision": 0.50706,
            "recall": 0.52099,
            "fmeasure": 0.50679
        },
        "rougeL": {
            "precision": 0.57431,
            "recall": 0.57783,
            "fmeasure": 0.56856
        },
        "rougeLsum": {
            "precision": 0.57431,
            "recall": 0.57783,
            "fmeasure": 0.56856
        },
        "local_recall": {
            "1": 0.55,
            "2": 0.5555555555555556,
            "3": 1.0
        },
        "meteor": 0.40522645888403436,
        "nubia": {
            "semantic_relation": 3.86323,
            "contradiction": 16.94137,
            "irrelevancy": 65.8109,
            "logical_agreement": 17.24773,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.38339,
            "nubia_score": 0.57285
        },
        "bleurt": -0.19765,
        "bertscore": {
            "precision": 0.92299,
            "recall": 0.92348,
            "f1": 0.92073
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.82635,
        "nist": 4.185127290120417,
        "rouge1": {
            "precision": 0.78072,
            "recall": 0.66996,
            "fmeasure": 0.7118
        },
        "rouge2": {
            "precision": 0.4354,
            "recall": 0.39842,
            "fmeasure": 0.41458
        },
        "rougeL": {
            "precision": 0.71254,
            "recall": 0.60474,
            "fmeasure": 0.64513
        },
        "rougeLsum": {
            "precision": 0.71254,
            "recall": 0.60474,
            "fmeasure": 0.64513
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.4,
            "3": 0.7111111111111111
        },
        "meteor": 0.3673781413606543,
        "nubia": {
            "semantic_relation": 4.20349,
            "contradiction": 2.87974,
            "irrelevancy": 2.97099,
            "logical_agreement": 94.14927,
            "grammar_ref": 4.34153,
            "grammar_hyp": 5.50541,
            "nubia_score": 0.6805
        },
        "bleurt": 0.18974,
        "bertscore": {
            "precision": 0.92492,
            "recall": 0.8739,
            "f1": 0.89829
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.58845,
        "nist": 1.9859053794237111,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.64286,
            "fmeasure": 0.5625
        },
        "rouge2": {
            "precision": 0.35294,
            "recall": 0.46154,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.64286,
            "fmeasure": 0.5625
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.64286,
            "fmeasure": 0.5625
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "meteor": 0.3968712818925049,
        "nubia": {
            "semantic_relation": 3.81955,
            "contradiction": 0.11928,
            "irrelevancy": 99.77422,
            "logical_agreement": 0.1065,
            "grammar_ref": 5.0526,
            "grammar_hyp": 4.66197,
            "nubia_score": 0.64627
        },
        "bleurt": 0.0566,
        "bertscore": {
            "precision": 0.85901,
            "recall": 0.91709,
            "f1": 0.8871
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.32698,
        "nist": 2.7179411685442054,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.625,
            "fmeasure": 0.58824
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8888888888888888
        },
        "meteor": 0.44521293749779517,
        "nubia": {
            "semantic_relation": 4.54101,
            "contradiction": 0.21392,
            "irrelevancy": 91.79483,
            "logical_agreement": 7.99125,
            "grammar_ref": 3.99081,
            "grammar_hyp": 3.22431,
            "nubia_score": 0.95595
        },
        "bleurt": 0.36768,
        "bertscore": {
            "precision": 0.94011,
            "recall": 0.95642,
            "f1": 0.9482
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.78923,
        "nist": 1.0912281254206744,
        "rouge1": {
            "precision": 0.22727,
            "recall": 0.375,
            "fmeasure": 0.28173
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.13636,
            "recall": 0.22917,
            "fmeasure": 0.17028
        },
        "rougeLsum": {
            "precision": 0.13636,
            "recall": 0.22917,
            "fmeasure": 0.17028
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.4
        },
        "meteor": 0.21052631578947367,
        "nubia": {
            "semantic_relation": 3.12934,
            "contradiction": 0.85076,
            "irrelevancy": 43.74141,
            "logical_agreement": 55.40783,
            "grammar_ref": 7.18676,
            "grammar_hyp": 5.37497,
            "nubia_score": 0.52564
        },
        "bleurt": -0.2907,
        "bertscore": {
            "precision": 0.78816,
            "recall": 0.79837,
            "f1": 0.79324
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.28081,
        "nist": 3.7823328563833676,
        "rouge1": {
            "precision": 0.90196,
            "recall": 0.93856,
            "fmeasure": 0.91912
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.86905,
            "fmeasure": 0.85
        },
        "rougeL": {
            "precision": 0.90196,
            "recall": 0.93856,
            "fmeasure": 0.91912
        },
        "rougeLsum": {
            "precision": 0.90196,
            "recall": 0.93856,
            "fmeasure": 0.91912
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7
        },
        "meteor": 0.9804878048780489,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.1702,
            "irrelevancy": 1.29006,
            "logical_agreement": 98.53974,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.19652,
            "nubia_score": 1.0
        },
        "bleurt": 0.79797,
        "bertscore": {
            "precision": 0.98668,
            "recall": 0.99313,
            "f1": 0.9899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.60434,
        "nist": 2.806195618357017,
        "rouge1": {
            "precision": 0.58371,
            "recall": 0.65363,
            "fmeasure": 0.58698
        },
        "rouge2": {
            "precision": 0.35417,
            "recall": 0.35664,
            "fmeasure": 0.33837
        },
        "rougeL": {
            "precision": 0.52187,
            "recall": 0.51709,
            "fmeasure": 0.50355
        },
        "rougeLsum": {
            "precision": 0.52187,
            "recall": 0.51709,
            "fmeasure": 0.50355
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.1111111111111111,
            "3": 0.6470588235294118
        },
        "meteor": 0.3269420558597877,
        "nubia": {
            "semantic_relation": 3.68774,
            "contradiction": 48.8566,
            "irrelevancy": 45.3066,
            "logical_agreement": 5.8368,
            "grammar_ref": 4.30067,
            "grammar_hyp": 3.8251,
            "nubia_score": 0.56295
        },
        "bleurt": 0.03526,
        "bertscore": {
            "precision": 0.90183,
            "recall": 0.91749,
            "f1": 0.90407
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.99653,
        "nist": 2.825291559394867,
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.6,
            "fmeasure": 0.52174
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.875
        },
        "meteor": 0.35773193817564836,
        "nubia": {
            "semantic_relation": 4.90669,
            "contradiction": 0.67272,
            "irrelevancy": 73.50374,
            "logical_agreement": 25.82354,
            "grammar_ref": 3.90557,
            "grammar_hyp": 4.07226,
            "nubia_score": 0.94026
        },
        "bleurt": 0.32661,
        "bertscore": {
            "precision": 0.92613,
            "recall": 0.93682,
            "f1": 0.92172
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 70.97039,
        "nist": 3.8998572512287097,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.63333,
            "fmeasure": 0.7037
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.7777777777777778
        },
        "meteor": 0.5047034859011716,
        "nubia": {
            "semantic_relation": 4.54342,
            "contradiction": 0.48545,
            "irrelevancy": 0.54019,
            "logical_agreement": 98.97436,
            "grammar_ref": 4.98843,
            "grammar_hyp": 5.36395,
            "nubia_score": 0.7985
        },
        "bleurt": 0.49536,
        "bertscore": {
            "precision": 0.98271,
            "recall": 0.9644,
            "f1": 0.97347
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.52952,
        "nist": 2.934725242584268,
        "rouge1": {
            "precision": 0.55263,
            "recall": 0.55749,
            "fmeasure": 0.55285
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.45536,
            "fmeasure": 0.44796
        },
        "rougeL": {
            "precision": 0.42105,
            "recall": 0.44385,
            "fmeasure": 0.43089
        },
        "rougeLsum": {
            "precision": 0.42105,
            "recall": 0.44385,
            "fmeasure": 0.43089
        },
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.6
        },
        "meteor": 0.4227133677732795,
        "nubia": {
            "semantic_relation": 2.86344,
            "contradiction": 0.16547,
            "irrelevancy": 99.6184,
            "logical_agreement": 0.21613,
            "grammar_ref": 3.66593,
            "grammar_hyp": 3.32701,
            "nubia_score": 0.45479
        },
        "bleurt": -0.66153,
        "bertscore": {
            "precision": 0.8257,
            "recall": 0.87218,
            "f1": 0.8483
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 136,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.29601,
        "nist": 7.749731587574482,
        "rouge1": {
            "precision": 0.76302,
            "recall": 0.75979,
            "fmeasure": 0.75175
        },
        "rouge2": {
            "precision": 0.53791,
            "recall": 0.54089,
            "fmeasure": 0.53291
        },
        "rougeL": {
            "precision": 0.6633,
            "recall": 0.667,
            "fmeasure": 0.65648
        },
        "rougeLsum": {
            "precision": 0.6633,
            "recall": 0.667,
            "fmeasure": 0.65648
        },
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.461038961038961,
            "3": 0.8087927424982554
        },
        "meteor": 0.41800292500139896,
        "nubia": {
            "semantic_relation": 4.28849,
            "contradiction": 5.13073,
            "irrelevancy": 34.1138,
            "logical_agreement": 60.75547,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.49464,
            "nubia_score": 0.76447
        },
        "bleurt": 0.35278,
        "bertscore": {
            "precision": 0.92851,
            "recall": 0.93248,
            "f1": 0.92904
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.60402,
        "nist": 3.5213729290305062,
        "rouge1": {
            "precision": 0.78947,
            "recall": 0.88235,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.625,
            "fmeasure": 0.58824
        },
        "rougeL": {
            "precision": 0.78947,
            "recall": 0.88235,
            "fmeasure": 0.83333
        },
        "rougeLsum": {
            "precision": 0.78947,
            "recall": 0.88235,
            "fmeasure": 0.83333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9333333333333333
        },
        "meteor": 0.5506327646482522,
        "nubia": {
            "semantic_relation": 4.36063,
            "contradiction": 0.53554,
            "irrelevancy": 11.11377,
            "logical_agreement": 88.35068,
            "grammar_ref": 4.8802,
            "grammar_hyp": 5.47692,
            "nubia_score": 0.64995
        },
        "bleurt": 0.59899,
        "bertscore": {
            "precision": 0.96716,
            "recall": 0.97416,
            "f1": 0.97065
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 69.40338,
        "nist": 4.727702650785581,
        "rouge1": {
            "precision": 0.89474,
            "recall": 0.77273,
            "fmeasure": 0.82927
        },
        "rouge2": {
            "precision": 0.75926,
            "recall": 0.65079,
            "fmeasure": 0.70085
        },
        "rougeL": {
            "precision": 0.84211,
            "recall": 0.72727,
            "fmeasure": 0.78049
        },
        "rougeLsum": {
            "precision": 0.84211,
            "recall": 0.72727,
            "fmeasure": 0.78049
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.75,
            "3": 0.875
        },
        "meteor": 0.4491890044569018,
        "nubia": {
            "semantic_relation": 4.50449,
            "contradiction": 0.15168,
            "irrelevancy": 33.69445,
            "logical_agreement": 66.15387,
            "grammar_ref": 3.23206,
            "grammar_hyp": 3.09794,
            "nubia_score": 0.89359
        },
        "bleurt": 0.17071,
        "bertscore": {
            "precision": 0.96669,
            "recall": 0.9417,
            "f1": 0.95403
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.09554,
        "nist": 2.410643913622866,
        "rouge1": {
            "precision": 0.60417,
            "recall": 0.60062,
            "fmeasure": 0.55704
        },
        "rouge2": {
            "precision": 0.27172,
            "recall": 0.23557,
            "fmeasure": 0.23266
        },
        "rougeL": {
            "precision": 0.45635,
            "recall": 0.47844,
            "fmeasure": 0.43168
        },
        "rougeLsum": {
            "precision": 0.45635,
            "recall": 0.47844,
            "fmeasure": 0.43168
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.45,
            "3": 0.631578947368421
        },
        "meteor": 0.2782693364555548,
        "nubia": {
            "semantic_relation": 3.17214,
            "contradiction": 1.82023,
            "irrelevancy": 65.28659,
            "logical_agreement": 32.89318,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.24419,
            "nubia_score": 0.32564
        },
        "bleurt": -0.28022,
        "bertscore": {
            "precision": 0.8391,
            "recall": 0.85384,
            "f1": 0.84475
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.23101,
        "nist": 3.2179153444688247,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.6688,
            "fmeasure": 0.64973
        },
        "rouge2": {
            "precision": 0.51026,
            "recall": 0.3969,
            "fmeasure": 0.42341
        },
        "rougeL": {
            "precision": 0.38839,
            "recall": 0.35363,
            "fmeasure": 0.34867
        },
        "rougeLsum": {
            "precision": 0.38839,
            "recall": 0.35363,
            "fmeasure": 0.34867
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "meteor": 0.33876662859309853,
        "nubia": {
            "semantic_relation": 3.70201,
            "contradiction": 18.73072,
            "irrelevancy": 2.23433,
            "logical_agreement": 79.03494,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.41726,
            "nubia_score": 0.57374
        },
        "bleurt": 0.11487,
        "bertscore": {
            "precision": 0.9073,
            "recall": 0.90615,
            "f1": 0.90601
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.06545,
        "nist": 4.605331240149166,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.7619,
            "fmeasure": 0.82051
        },
        "rouge2": {
            "precision": 0.62745,
            "recall": 0.53333,
            "fmeasure": 0.57658
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57143,
            "fmeasure": 0.61538
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57143,
            "fmeasure": 0.61538
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5,
            "3": 0.9090909090909091
        },
        "meteor": 0.4414021895241935,
        "nubia": {
            "semantic_relation": 4.58261,
            "contradiction": 0.14043,
            "irrelevancy": 33.5481,
            "logical_agreement": 66.31147,
            "grammar_ref": 3.68983,
            "grammar_hyp": 3.73259,
            "nubia_score": 0.89855
        },
        "bleurt": 0.36077,
        "bertscore": {
            "precision": 0.96855,
            "recall": 0.94484,
            "f1": 0.95137
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 72.76817,
        "nist": 4.042812868077369,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.84615,
            "recall": 1.0,
            "fmeasure": 0.91667
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "meteor": 0.5352491092484717,
        "nubia": {
            "semantic_relation": 4.6266,
            "contradiction": 0.13422,
            "irrelevancy": 33.54124,
            "logical_agreement": 66.32454,
            "grammar_ref": 4.00353,
            "grammar_hyp": 3.8821,
            "nubia_score": 0.87392
        },
        "bleurt": 0.54376,
        "bertscore": {
            "precision": 0.95508,
            "recall": 0.9722,
            "f1": 0.96357
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.24222,
        "nist": 0.589314728948252,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.23214,
            "fmeasure": 0.30905
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.11396,
            "fmeasure": 0.15238
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.23214,
            "fmeasure": 0.30905
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.23214,
            "fmeasure": 0.30905
        },
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.4444444444444444
        },
        "meteor": 0.158521667309652,
        "nubia": {
            "semantic_relation": 2.93459,
            "contradiction": 2.21395,
            "irrelevancy": 43.47451,
            "logical_agreement": 54.31155,
            "grammar_ref": 3.10421,
            "grammar_hyp": 4.00757,
            "nubia_score": 0.31105
        },
        "bleurt": -0.14651,
        "bertscore": {
            "precision": 0.82188,
            "recall": 0.79473,
            "f1": 0.8021
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.7285,
        "nist": 2.15413541726763,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8
        },
        "meteor": 0.9142857142857143,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20505,
            "irrelevancy": 0.4305,
            "logical_agreement": 99.36445,
            "grammar_ref": 6.34893,
            "grammar_hyp": 6.41848,
            "nubia_score": 0.98459
        },
        "bleurt": 0.9017,
        "bertscore": {
            "precision": 0.99556,
            "recall": 0.99556,
            "f1": 0.99556
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.61369,
        "nist": 2.80787813729077,
        "rouge1": {
            "precision": 0.59091,
            "recall": 0.59325,
            "fmeasure": 0.59151
        },
        "rouge2": {
            "precision": 0.4127,
            "recall": 0.43333,
            "fmeasure": 0.42276
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.36508,
            "fmeasure": 0.364
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.36508,
            "fmeasure": 0.364
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.4666666666666667
        },
        "meteor": 0.3456977944124591,
        "nubia": {
            "semantic_relation": 3.36708,
            "contradiction": 0.64219,
            "irrelevancy": 98.61862,
            "logical_agreement": 0.7392,
            "grammar_ref": 6.02354,
            "grammar_hyp": 5.6144,
            "nubia_score": 0.4672
        },
        "bleurt": -0.37291,
        "bertscore": {
            "precision": 0.8649,
            "recall": 0.86958,
            "f1": 0.8636
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 86.68779,
        "nist": 3.0476314089081704,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.69841,
            "fmeasure": 0.77273
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "meteor": 0.5570133484098374,
        "nubia": {
            "semantic_relation": 4.22675,
            "contradiction": 0.58601,
            "irrelevancy": 0.55339,
            "logical_agreement": 98.8606,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.5844,
            "nubia_score": 0.77636
        },
        "bleurt": 0.30208,
        "bertscore": {
            "precision": 0.99092,
            "recall": 0.97079,
            "f1": 0.98075
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.52046,
        "nist": 1.639353622444082,
        "rouge1": {
            "precision": 0.31667,
            "recall": 0.65556,
            "fmeasure": 0.41905
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.35714,
            "fmeasure": 0.21445
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.55,
            "fmeasure": 0.35238
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.55,
            "fmeasure": 0.35238
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.125,
            "3": 0.7142857142857143
        },
        "meteor": 0.28264159975927516,
        "nubia": {
            "semantic_relation": 3.65266,
            "contradiction": 0.10274,
            "irrelevancy": 99.77721,
            "logical_agreement": 0.12006,
            "grammar_ref": 4.70243,
            "grammar_hyp": 4.97731,
            "nubia_score": 0.4418
        },
        "bleurt": -0.32316,
        "bertscore": {
            "precision": 0.83681,
            "recall": 0.92182,
            "f1": 0.85784
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.03107,
        "nist": 3.209206745560457,
        "rouge1": {
            "precision": 0.63715,
            "recall": 0.51136,
            "fmeasure": 0.55513
        },
        "rouge2": {
            "precision": 0.40882,
            "recall": 0.30142,
            "fmeasure": 0.33883
        },
        "rougeL": {
            "precision": 0.51736,
            "recall": 0.39646,
            "fmeasure": 0.43926
        },
        "rougeLsum": {
            "precision": 0.51736,
            "recall": 0.39646,
            "fmeasure": 0.43926
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5238095238095238
        },
        "meteor": 0.27213946909953185,
        "nubia": {
            "semantic_relation": 3.49841,
            "contradiction": 2.15158,
            "irrelevancy": 58.59035,
            "logical_agreement": 39.25807,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.88448,
            "nubia_score": 0.46532
        },
        "bleurt": -0.09628,
        "bertscore": {
            "precision": 0.9275,
            "recall": 0.88401,
            "f1": 0.90248
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.95922,
        "nist": 2.9947458617947103,
        "rouge1": {
            "precision": 0.48732,
            "recall": 0.67021,
            "fmeasure": 0.5515
        },
        "rouge2": {
            "precision": 0.2029,
            "recall": 0.3246,
            "fmeasure": 0.24497
        },
        "rougeL": {
            "precision": 0.38768,
            "recall": 0.52998,
            "fmeasure": 0.43757
        },
        "rougeLsum": {
            "precision": 0.38768,
            "recall": 0.52998,
            "fmeasure": 0.43757
        },
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.5,
            "3": 0.6551724137931034
        },
        "meteor": 0.32201433045674593,
        "nubia": {
            "semantic_relation": 3.73076,
            "contradiction": 14.76235,
            "irrelevancy": 54.23925,
            "logical_agreement": 30.99841,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.3628,
            "nubia_score": 0.5176
        },
        "bleurt": -0.02653,
        "bertscore": {
            "precision": 0.85329,
            "recall": 0.90085,
            "f1": 0.87599
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.17302,
        "nist": 0.08214800395174969,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.22222,
            "fmeasure": 0.32432
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.07692,
            "fmeasure": 0.11429
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.22222,
            "fmeasure": 0.32432
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.22222,
            "fmeasure": 0.32432
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.2777777777777778
        },
        "meteor": 0.14369365523023453,
        "nubia": {
            "semantic_relation": 1.97312,
            "contradiction": 4.40682,
            "irrelevancy": 28.38823,
            "logical_agreement": 67.20496,
            "grammar_ref": 4.95946,
            "grammar_hyp": 6.57943,
            "nubia_score": 0.08358
        },
        "bleurt": -0.42923,
        "bertscore": {
            "precision": 0.89541,
            "recall": 0.8342,
            "f1": 0.86372
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.09035,
        "nist": 2.2632580463790717,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.61579,
            "fmeasure": 0.5518
        },
        "rouge2": {
            "precision": 0.34783,
            "recall": 0.43275,
            "fmeasure": 0.3856
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.30789,
            "fmeasure": 0.2759
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.30789,
            "fmeasure": 0.2759
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714
        },
        "meteor": 0.32865005748181025,
        "nubia": {
            "semantic_relation": 3.71418,
            "contradiction": 35.59687,
            "irrelevancy": 63.21084,
            "logical_agreement": 1.19229,
            "grammar_ref": 4.38153,
            "grammar_hyp": 3.95371,
            "nubia_score": 0.62085
        },
        "bleurt": -0.01956,
        "bertscore": {
            "precision": 0.85918,
            "recall": 0.89729,
            "f1": 0.87782
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.13953,
        "nist": 1.353289509199005,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.41667,
            "fmeasure": 0.50794
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "meteor": 0.2969362339094229,
        "nubia": {
            "semantic_relation": 3.58413,
            "contradiction": 0.90915,
            "irrelevancy": 0.77982,
            "logical_agreement": 98.31103,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.04864,
            "nubia_score": 0.50694
        },
        "bleurt": 0.02674,
        "bertscore": {
            "precision": 0.95405,
            "recall": 0.92629,
            "f1": 0.93996
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 7.88878,
        "nist": 1.4566123344210267,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.50961,
            "fmeasure": 0.61275
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.26852,
            "fmeasure": 0.32639
        },
        "rougeL": {
            "precision": 0.58974,
            "recall": 0.36045,
            "fmeasure": 0.44702
        },
        "rougeLsum": {
            "precision": 0.58974,
            "recall": 0.36045,
            "fmeasure": 0.44702
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "meteor": 0.3210949354315316,
        "nubia": {
            "semantic_relation": 4.71014,
            "contradiction": 0.60368,
            "irrelevancy": 14.6522,
            "logical_agreement": 84.74413,
            "grammar_ref": 3.4928,
            "grammar_hyp": 4.9287,
            "nubia_score": 0.76401
        },
        "bleurt": 0.37141,
        "bertscore": {
            "precision": 0.94282,
            "recall": 0.88979,
            "f1": 0.9134
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.49941,
        "nist": 1.8984662032591466,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.72222,
            "fmeasure": 0.76389
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.21481,
            "fmeasure": 0.25714
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "meteor": 0.4273401256626268,
        "nubia": {
            "semantic_relation": 4.05895,
            "contradiction": 7.74436,
            "irrelevancy": 2.65955,
            "logical_agreement": 89.59608,
            "grammar_ref": 7.45181,
            "grammar_hyp": 7.82302,
            "nubia_score": 0.61237
        },
        "bleurt": -0.16317,
        "bertscore": {
            "precision": 0.92798,
            "recall": 0.9252,
            "f1": 0.92659
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.87732,
        "nist": 3.3516624552486545,
        "rouge1": {
            "precision": 0.68056,
            "recall": 0.68061,
            "fmeasure": 0.67998
        },
        "rouge2": {
            "precision": 0.24638,
            "recall": 0.24603,
            "fmeasure": 0.24597
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.39273,
            "fmeasure": 0.38332
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.39273,
            "fmeasure": 0.38332
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.631578947368421
        },
        "meteor": 0.28304001695526315,
        "nubia": {
            "semantic_relation": 3.78968,
            "contradiction": 0.11379,
            "irrelevancy": 99.1847,
            "logical_agreement": 0.70151,
            "grammar_ref": 4.82125,
            "grammar_hyp": 5.08343,
            "nubia_score": 0.56197
        },
        "bleurt": -0.18011,
        "bertscore": {
            "precision": 0.86979,
            "recall": 0.84475,
            "f1": 0.85709
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.40589,
        "nist": 4.349240093108124,
        "rouge1": {
            "precision": 0.67857,
            "recall": 0.64455,
            "fmeasure": 0.65821
        },
        "rouge2": {
            "precision": 0.44487,
            "recall": 0.40649,
            "fmeasure": 0.42262
        },
        "rougeL": {
            "precision": 0.61607,
            "recall": 0.57789,
            "fmeasure": 0.5937
        },
        "rougeLsum": {
            "precision": 0.61607,
            "recall": 0.57789,
            "fmeasure": 0.5937
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.7619047619047619,
            "3": 0.6363636363636364
        },
        "meteor": 0.3480034026344771,
        "nubia": {
            "semantic_relation": 4.39681,
            "contradiction": 24.78895,
            "irrelevancy": 33.99535,
            "logical_agreement": 41.2157,
            "grammar_ref": 4.68806,
            "grammar_hyp": 4.3705,
            "nubia_score": 0.78355
        },
        "bleurt": 0.28903,
        "bertscore": {
            "precision": 0.91993,
            "recall": 0.89668,
            "f1": 0.90708
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.41554,
        "nist": 3.674994290328183,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.92857,
            "fmeasure": 0.87808
        },
        "rouge2": {
            "precision": 0.53571,
            "recall": 0.60256,
            "fmeasure": 0.56695
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.48352,
            "fmeasure": 0.4569
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.48352,
            "fmeasure": 0.4569
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "meteor": 0.4541511217869309,
        "nubia": {
            "semantic_relation": 4.75444,
            "contradiction": 0.05513,
            "irrelevancy": 99.7134,
            "logical_agreement": 0.23147,
            "grammar_ref": 4.1674,
            "grammar_hyp": 4.41286,
            "nubia_score": 0.93642
        },
        "bleurt": 0.31482,
        "bertscore": {
            "precision": 0.91952,
            "recall": 0.94816,
            "f1": 0.93362
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 80.17494,
        "nist": 3.980352302429953,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "rouge2": {
            "precision": 0.84167,
            "recall": 0.85354,
            "fmeasure": 0.84585
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9375
        },
        "meteor": 0.5859552163896863,
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.82427,
            "irrelevancy": 0.91292,
            "logical_agreement": 98.26281,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.10466,
            "nubia_score": 0.9183
        },
        "bleurt": 0.80221,
        "bertscore": {
            "precision": 0.98723,
            "recall": 0.99228,
            "f1": 0.98974
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.44615,
        "nist": 2.5779441744668503,
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.65152,
            "fmeasure": 0.67544
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.35238,
            "fmeasure": 0.36415
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.53788,
            "fmeasure": 0.55702
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.53788,
            "fmeasure": 0.55702
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "meteor": 0.3836989904020544,
        "nubia": {
            "semantic_relation": 3.70951,
            "contradiction": 0.3203,
            "irrelevancy": 90.47188,
            "logical_agreement": 9.20782,
            "grammar_ref": 4.68733,
            "grammar_hyp": 4.85639,
            "nubia_score": 0.62707
        },
        "bleurt": 0.26802,
        "bertscore": {
            "precision": 0.93336,
            "recall": 0.93853,
            "f1": 0.93594
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.21167,
        "nist": 1.9303644234652384,
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.5,
            "fmeasure": 0.52174
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.18182,
            "fmeasure": 0.19048
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.41667,
            "fmeasure": 0.43478
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.41667,
            "fmeasure": 0.43478
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "meteor": 0.3173654597294904,
        "nubia": {
            "semantic_relation": 4.03933,
            "contradiction": 2.17831,
            "irrelevancy": 94.41695,
            "logical_agreement": 3.40474,
            "grammar_ref": 5.64121,
            "grammar_hyp": 6.03796,
            "nubia_score": 0.53205
        },
        "bleurt": -0.2411,
        "bertscore": {
            "precision": 0.86576,
            "recall": 0.87781,
            "f1": 0.87139
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.02048,
        "nist": 4.254336761374963,
        "rouge1": {
            "precision": 0.6886,
            "recall": 0.72313,
            "fmeasure": 0.70492
        },
        "rouge2": {
            "precision": 0.3836,
            "recall": 0.4071,
            "fmeasure": 0.39463
        },
        "rougeL": {
            "precision": 0.59064,
            "recall": 0.6093,
            "fmeasure": 0.59956
        },
        "rougeLsum": {
            "precision": 0.59064,
            "recall": 0.6093,
            "fmeasure": 0.59956
        },
        "local_recall": {
            "1": 0.375,
            "2": 0.6086956521739131,
            "3": 0.7058823529411765
        },
        "meteor": 0.3539104077895174,
        "nubia": {
            "semantic_relation": 4.61448,
            "contradiction": 0.63175,
            "irrelevancy": 18.34422,
            "logical_agreement": 81.02404,
            "grammar_ref": 4.61531,
            "grammar_hyp": 5.05675,
            "nubia_score": 0.78793
        },
        "bleurt": 0.27193,
        "bertscore": {
            "precision": 0.92306,
            "recall": 0.92387,
            "f1": 0.92302
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.67055,
        "nist": 1.699068263081717,
        "rouge1": {
            "precision": 0.71111,
            "recall": 0.43826,
            "fmeasure": 0.54211
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.19949,
            "fmeasure": 0.24951
        },
        "rougeL": {
            "precision": 0.51111,
            "recall": 0.31478,
            "fmeasure": 0.38947
        },
        "rougeLsum": {
            "precision": 0.51111,
            "recall": 0.31478,
            "fmeasure": 0.38947
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.45454545454545453,
            "3": 0.4444444444444444
        },
        "meteor": 0.24000574567708297,
        "nubia": {
            "semantic_relation": 3.15448,
            "contradiction": 10.26008,
            "irrelevancy": 50.37775,
            "logical_agreement": 39.36216,
            "grammar_ref": 3.96534,
            "grammar_hyp": 2.87196,
            "nubia_score": 0.52679
        },
        "bleurt": -0.18867,
        "bertscore": {
            "precision": 0.91886,
            "recall": 0.86071,
            "f1": 0.88884
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 4.3764992953429935,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        },
        "bleurt": 0.91462,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.69498,
        "nist": 1.8899750004807707,
        "rouge1": {
            "precision": 0.54902,
            "recall": 1.0,
            "fmeasure": 0.70716
        },
        "rouge2": {
            "precision": 0.47917,
            "recall": 0.92593,
            "fmeasure": 0.62957
        },
        "rougeL": {
            "precision": 0.54902,
            "recall": 1.0,
            "fmeasure": 0.70716
        },
        "rougeLsum": {
            "precision": 0.54902,
            "recall": 1.0,
            "fmeasure": 0.70716
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7142857142857143
        },
        "meteor": 0.4643988853040184,
        "nubia": {
            "semantic_relation": 3.9493,
            "contradiction": 0.07491,
            "irrelevancy": 99.5115,
            "logical_agreement": 0.4136,
            "grammar_ref": 3.90726,
            "grammar_hyp": 2.43816,
            "nubia_score": 0.77904
        },
        "bleurt": 0.17245,
        "bertscore": {
            "precision": 0.86245,
            "recall": 0.94076,
            "f1": 0.88439
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.46036,
        "nist": 2.625,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8571428571428571
        },
        "meteor": 0.9555555555555555,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.78492,
            "irrelevancy": 0.54406,
            "logical_agreement": 98.67101,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.3113,
            "nubia_score": 1.0
        },
        "bleurt": 0.90115,
        "bertscore": {
            "precision": 0.97522,
            "recall": 0.97522,
            "f1": 0.97522
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 15,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.81197,
        "nist": 6.81396144924507,
        "rouge1": {
            "precision": 0.81441,
            "recall": 0.79153,
            "fmeasure": 0.79277
        },
        "rouge2": {
            "precision": 0.66208,
            "recall": 0.61208,
            "fmeasure": 0.6232
        },
        "rougeL": {
            "precision": 0.73159,
            "recall": 0.71594,
            "fmeasure": 0.71527
        },
        "rougeLsum": {
            "precision": 0.73159,
            "recall": 0.71594,
            "fmeasure": 0.71527
        },
        "local_recall": {
            "1": 0.425531914893617,
            "2": 0.48148148148148145,
            "3": 0.832258064516129
        },
        "meteor": 0.44935451645642127,
        "nubia": {
            "semantic_relation": 4.35293,
            "contradiction": 15.06805,
            "irrelevancy": 28.58971,
            "logical_agreement": 56.34224,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.61829,
            "nubia_score": 0.77603
        },
        "bleurt": 0.34625,
        "bertscore": {
            "precision": 0.95629,
            "recall": 0.95347,
            "f1": 0.95204
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 2.4156844010247407,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.6374,
            "contradiction": 0.2158,
            "irrelevancy": 0.51722,
            "logical_agreement": 99.26698,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.20485,
            "nubia_score": 0.86208
        },
        "bleurt": 0.6432,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.07917,
        "nist": 3.3915861152071467,
        "rouge1": {
            "precision": 0.63148,
            "recall": 0.66389,
            "fmeasure": 0.64542
        },
        "rouge2": {
            "precision": 0.46296,
            "recall": 0.46296,
            "fmeasure": 0.46296
        },
        "rougeL": {
            "precision": 0.59444,
            "recall": 0.65,
            "fmeasure": 0.61667
        },
        "rougeLsum": {
            "precision": 0.59444,
            "recall": 0.65,
            "fmeasure": 0.61667
        },
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 0.7333333333333333
        },
        "meteor": 0.4457988467357869,
        "nubia": {
            "semantic_relation": 4.22324,
            "contradiction": 0.26323,
            "irrelevancy": 49.88984,
            "logical_agreement": 49.84694,
            "grammar_ref": 5.47595,
            "grammar_hyp": 5.94301,
            "nubia_score": 0.70829
        },
        "bleurt": 0.28826,
        "bertscore": {
            "precision": 0.93093,
            "recall": 0.93645,
            "f1": 0.93368
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.45308,
        "nist": 3.8026609793582464,
        "rouge1": {
            "precision": 0.64319,
            "recall": 0.52924,
            "fmeasure": 0.57707
        },
        "rouge2": {
            "precision": 0.37405,
            "recall": 0.29242,
            "fmeasure": 0.32759
        },
        "rougeL": {
            "precision": 0.55787,
            "recall": 0.47327,
            "fmeasure": 0.50891
        },
        "rougeLsum": {
            "precision": 0.55787,
            "recall": 0.47327,
            "fmeasure": 0.50891
        },
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "meteor": 0.31145031357030173,
        "nubia": {
            "semantic_relation": 3.94135,
            "contradiction": 0.18092,
            "irrelevancy": 15.22103,
            "logical_agreement": 84.59805,
            "grammar_ref": 4.73268,
            "grammar_hyp": 4.44194,
            "nubia_score": 0.6959
        },
        "bleurt": 0.19822,
        "bertscore": {
            "precision": 0.91419,
            "recall": 0.88601,
            "f1": 0.89635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.00461,
        "nist": 3.586498456513313,
        "rouge1": {
            "precision": 0.5259,
            "recall": 0.67407,
            "fmeasure": 0.57723
        },
        "rouge2": {
            "precision": 0.40278,
            "recall": 0.53885,
            "fmeasure": 0.44964
        },
        "rougeL": {
            "precision": 0.41437,
            "recall": 0.65705,
            "fmeasure": 0.50816
        },
        "rougeLsum": {
            "precision": 0.41437,
            "recall": 0.65705,
            "fmeasure": 0.50816
        },
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.2857142857142857,
            "3": 0.6875
        },
        "meteor": 0.39572245320013416,
        "nubia": {
            "semantic_relation": 3.71546,
            "contradiction": 9.64186,
            "irrelevancy": 71.06681,
            "logical_agreement": 19.29133,
            "grammar_ref": 3.56015,
            "grammar_hyp": 3.19306,
            "nubia_score": 0.69408
        },
        "bleurt": -0.11274,
        "bertscore": {
            "precision": 0.85988,
            "recall": 0.91184,
            "f1": 0.88051
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.96905,
        "nist": 0.09434734942811432,
        "rouge1": {
            "precision": 0.8658,
            "recall": 0.37542,
            "fmeasure": 0.51735
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.15328,
            "fmeasure": 0.21215
        },
        "rougeL": {
            "precision": 0.76623,
            "recall": 0.28779,
            "fmeasure": 0.40716
        },
        "rougeLsum": {
            "precision": 0.76623,
            "recall": 0.28779,
            "fmeasure": 0.40716
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.17647058823529413,
            "3": 0.42857142857142855
        },
        "meteor": 0.1947665322169363,
        "nubia": {
            "semantic_relation": 3.59397,
            "contradiction": 6.54106,
            "irrelevancy": 17.42735,
            "logical_agreement": 76.03159,
            "grammar_ref": 3.63495,
            "grammar_hyp": 5.36106,
            "nubia_score": 0.38075
        },
        "bleurt": -0.19802,
        "bertscore": {
            "precision": 0.91068,
            "recall": 0.8266,
            "f1": 0.85985
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.88302,
        "nist": 1.0700149676210042,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.34314,
            "fmeasure": 0.42912
        },
        "rouge2": {
            "precision": 0.13636,
            "recall": 0.07473,
            "fmeasure": 0.09586
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.22181,
            "fmeasure": 0.27682
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.22181,
            "fmeasure": 0.27682
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.35714285714285715
        },
        "meteor": 0.17425660014277192,
        "nubia": {
            "semantic_relation": 3.28106,
            "contradiction": 0.57871,
            "irrelevancy": 1.23391,
            "logical_agreement": 98.18738,
            "grammar_ref": 4.95035,
            "grammar_hyp": 5.09094,
            "nubia_score": 0.42367
        },
        "bleurt": -0.1731,
        "bertscore": {
            "precision": 0.88202,
            "recall": 0.82255,
            "f1": 0.84643
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.27291,
        "nist": 2.8793074668420173,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.69615,
            "fmeasure": 0.625
        },
        "rouge2": {
            "precision": 0.34615,
            "recall": 0.43056,
            "fmeasure": 0.38182
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.41923,
            "fmeasure": 0.38426
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.41923,
            "fmeasure": 0.38426
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.625
        },
        "meteor": 0.32816999680923126,
        "nubia": {
            "semantic_relation": 3.29158,
            "contradiction": 48.50204,
            "irrelevancy": 50.46171,
            "logical_agreement": 1.03625,
            "grammar_ref": 4.19915,
            "grammar_hyp": 5.22707,
            "nubia_score": 0.34404
        },
        "bleurt": -0.65819,
        "bertscore": {
            "precision": 0.90351,
            "recall": 0.9018,
            "f1": 0.90266
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.36028,
        "nist": 1.6363636363636365,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.71429,
            "fmeasure": 0.58824
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.33333,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.71429,
            "fmeasure": 0.58824
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.71429,
            "fmeasure": 0.58824
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7142857142857143
        },
        "meteor": 0.4486738411629312,
        "nubia": {
            "semantic_relation": 4.73359,
            "contradiction": 0.18527,
            "irrelevancy": 23.1462,
            "logical_agreement": 76.66854,
            "grammar_ref": 5.74517,
            "grammar_hyp": 5.65349,
            "nubia_score": 0.82641
        },
        "bleurt": 0.60044,
        "bertscore": {
            "precision": 0.88454,
            "recall": 0.93881,
            "f1": 0.91087
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.09926,
        "nist": 2.0931069271276543,
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.39732,
            "fmeasure": 0.45926
        },
        "rouge2": {
            "precision": 0.35,
            "recall": 0.24359,
            "fmeasure": 0.28696
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.39732,
            "fmeasure": 0.45926
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.39732,
            "fmeasure": 0.45926
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25
        },
        "meteor": 0.26797030717614817,
        "nubia": {
            "semantic_relation": 2.26185,
            "contradiction": 4.51287,
            "irrelevancy": 82.17776,
            "logical_agreement": 13.30937,
            "grammar_ref": 3.06207,
            "grammar_hyp": 2.63249,
            "nubia_score": 0.31368
        },
        "bleurt": 0.04976,
        "bertscore": {
            "precision": 0.9218,
            "recall": 0.88819,
            "f1": 0.90469
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.07266,
        "nist": 1.9792543971824617,
        "rouge1": {
            "precision": 0.43269,
            "recall": 0.46703,
            "fmeasure": 0.44675
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.24359,
            "fmeasure": 0.24667
        },
        "rougeL": {
            "precision": 0.39423,
            "recall": 0.42949,
            "fmeasure": 0.40876
        },
        "rougeLsum": {
            "precision": 0.39423,
            "recall": 0.42949,
            "fmeasure": 0.40876
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5238095238095238
        },
        "meteor": 0.28128735150774187,
        "nubia": {
            "semantic_relation": 3.96159,
            "contradiction": 0.21187,
            "irrelevancy": 4.17901,
            "logical_agreement": 95.60912,
            "grammar_ref": 5.01983,
            "grammar_hyp": 4.90884,
            "nubia_score": 0.64686
        },
        "bleurt": 0.19808,
        "bertscore": {
            "precision": 0.87178,
            "recall": 0.8799,
            "f1": 0.87582
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.91533,
        "nist": 4.139556526737576,
        "rouge1": {
            "precision": 0.59142,
            "recall": 0.53879,
            "fmeasure": 0.53788
        },
        "rouge2": {
            "precision": 0.36677,
            "recall": 0.25945,
            "fmeasure": 0.2866
        },
        "rougeL": {
            "precision": 0.41789,
            "recall": 0.36965,
            "fmeasure": 0.37707
        },
        "rougeLsum": {
            "precision": 0.41789,
            "recall": 0.36965,
            "fmeasure": 0.37707
        },
        "local_recall": {
            "1": 0.175,
            "2": 0.5555555555555556,
            "3": 0.5862068965517241
        },
        "meteor": 0.26270617452103834,
        "nubia": {
            "semantic_relation": 3.96432,
            "contradiction": 20.01537,
            "irrelevancy": 38.59055,
            "logical_agreement": 41.39408,
            "grammar_ref": 5.44243,
            "grammar_hyp": 5.14742,
            "nubia_score": 0.61956
        },
        "bleurt": -0.24857,
        "bertscore": {
            "precision": 0.88443,
            "recall": 0.86372,
            "f1": 0.87325
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 80.85403,
        "nist": 5.525116623382447,
        "rouge1": {
            "precision": 0.94697,
            "recall": 0.97101,
            "fmeasure": 0.9582
        },
        "rouge2": {
            "precision": 0.88889,
            "recall": 0.91188,
            "fmeasure": 0.89961
        },
        "rougeL": {
            "precision": 0.84091,
            "recall": 0.86087,
            "fmeasure": 0.85026
        },
        "rougeLsum": {
            "precision": 0.84091,
            "recall": 0.86087,
            "fmeasure": 0.85026
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "meteor": 0.5837723788674194,
        "nubia": {
            "semantic_relation": 4.68595,
            "contradiction": 0.31094,
            "irrelevancy": 0.61593,
            "logical_agreement": 99.07313,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.08413,
            "nubia_score": 0.93338
        },
        "bleurt": 0.64819,
        "bertscore": {
            "precision": 0.96775,
            "recall": 0.98476,
            "f1": 0.97509
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.12867,
        "nist": 4.348788601119048,
        "rouge1": {
            "precision": 0.78241,
            "recall": 0.73565,
            "fmeasure": 0.74998
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.51502,
            "fmeasure": 0.53651
        },
        "rougeL": {
            "precision": 0.68981,
            "recall": 0.6395,
            "fmeasure": 0.6564
        },
        "rougeLsum": {
            "precision": 0.68981,
            "recall": 0.6395,
            "fmeasure": 0.6564
        },
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.7272727272727273,
            "3": 0.9090909090909091
        },
        "meteor": 0.4036679891443808,
        "nubia": {
            "semantic_relation": 4.2271,
            "contradiction": 13.60758,
            "irrelevancy": 20.41262,
            "logical_agreement": 65.97979,
            "grammar_ref": 4.3679,
            "grammar_hyp": 4.20059,
            "nubia_score": 0.75106
        },
        "bleurt": 0.1611,
        "bertscore": {
            "precision": 0.9421,
            "recall": 0.9195,
            "f1": 0.92004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.94957,
        "nist": 2.7517889300225464,
        "rouge1": {
            "precision": 0.83009,
            "recall": 0.67951,
            "fmeasure": 0.73375
        },
        "rouge2": {
            "precision": 0.62564,
            "recall": 0.53946,
            "fmeasure": 0.5719
        },
        "rougeL": {
            "precision": 0.69913,
            "recall": 0.60794,
            "fmeasure": 0.64284
        },
        "rougeLsum": {
            "precision": 0.69913,
            "recall": 0.60794,
            "fmeasure": 0.64284
        },
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.6666666666666666,
            "3": 0.6538461538461539
        },
        "meteor": 0.3525246090804888,
        "nubia": {
            "semantic_relation": 4.39488,
            "contradiction": 1.56295,
            "irrelevancy": 1.08391,
            "logical_agreement": 97.35313,
            "grammar_ref": 4.54027,
            "grammar_hyp": 4.78165,
            "nubia_score": 0.7432
        },
        "bleurt": 0.33034,
        "bertscore": {
            "precision": 0.94787,
            "recall": 0.91315,
            "f1": 0.92336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.19461,
        "nist": 3.568940238412348,
        "rouge1": {
            "precision": 0.67277,
            "recall": 0.599,
            "fmeasure": 0.6287
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.37505,
            "fmeasure": 0.39144
        },
        "rougeL": {
            "precision": 0.6105,
            "recall": 0.54657,
            "fmeasure": 0.57224
        },
        "rougeLsum": {
            "precision": 0.6105,
            "recall": 0.54657,
            "fmeasure": 0.57224
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.6
        },
        "meteor": 0.3683451993179362,
        "nubia": {
            "semantic_relation": 4.38465,
            "contradiction": 0.13502,
            "irrelevancy": 0.68614,
            "logical_agreement": 99.17884,
            "grammar_ref": 4.13564,
            "grammar_hyp": 4.38247,
            "nubia_score": 0.77568
        },
        "bleurt": 0.3275,
        "bertscore": {
            "precision": 0.91235,
            "recall": 0.8952,
            "f1": 0.90364
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 73.48889,
        "nist": 3.5579098675041347,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "meteor": 0.9384615384615386,
        "nubia": {
            "semantic_relation": 4.61305,
            "contradiction": 1.00975,
            "irrelevancy": 33.27064,
            "logical_agreement": 65.71961,
            "grammar_ref": 4.85143,
            "grammar_hyp": 4.81815,
            "nubia_score": 0.82757
        },
        "bleurt": 0.54425,
        "bertscore": {
            "precision": 0.98143,
            "recall": 0.98247,
            "f1": 0.98195
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.03963,
        "nist": 3.260971674788868,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.69281,
            "fmeasure": 0.74242
        },
        "rouge2": {
            "precision": 0.54762,
            "recall": 0.48889,
            "fmeasure": 0.51648
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.39951,
            "fmeasure": 0.4207
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.39951,
            "fmeasure": 0.4207
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.6875
        },
        "meteor": 0.34087662005725766,
        "nubia": {
            "semantic_relation": 3.76055,
            "contradiction": 27.19549,
            "irrelevancy": 18.16386,
            "logical_agreement": 54.64065,
            "grammar_ref": 4.86284,
            "grammar_hyp": 5.32805,
            "nubia_score": 0.48698
        },
        "bleurt": 0.02176,
        "bertscore": {
            "precision": 0.88438,
            "recall": 0.88463,
            "f1": 0.8845
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 4,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.37656,
        "nist": 3.941280103098187,
        "rouge1": {
            "precision": 0.67765,
            "recall": 0.65346,
            "fmeasure": 0.65584
        },
        "rouge2": {
            "precision": 0.42061,
            "recall": 0.44186,
            "fmeasure": 0.42834
        },
        "rougeL": {
            "precision": 0.53835,
            "recall": 0.5168,
            "fmeasure": 0.52096
        },
        "rougeLsum": {
            "precision": 0.53835,
            "recall": 0.5168,
            "fmeasure": 0.52096
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.6363636363636364,
            "3": 0.5405405405405406
        },
        "meteor": 0.2851590283201091,
        "nubia": {
            "semantic_relation": 3.29798,
            "contradiction": 38.34047,
            "irrelevancy": 13.85739,
            "logical_agreement": 47.80214,
            "grammar_ref": 4.12218,
            "grammar_hyp": 3.76887,
            "nubia_score": 0.53677
        },
        "bleurt": 0.19709,
        "bertscore": {
            "precision": 0.88869,
            "recall": 0.88433,
            "f1": 0.88554
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.3756,
        "nist": 3.668906062536221,
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.85606,
            "fmeasure": 0.79556
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.71515,
            "fmeasure": 0.65876
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 0.85606,
            "fmeasure": 0.79556
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 0.85606,
            "fmeasure": 0.79556
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.875
        },
        "meteor": 0.4816573593726147,
        "nubia": {
            "semantic_relation": 4.87771,
            "contradiction": 0.18199,
            "irrelevancy": 3.59267,
            "logical_agreement": 96.22534,
            "grammar_ref": 6.27756,
            "grammar_hyp": 6.04685,
            "nubia_score": 0.9322
        },
        "bleurt": 0.50679,
        "bertscore": {
            "precision": 0.95426,
            "recall": 0.98003,
            "f1": 0.96697
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.33655,
        "nist": 2.402939370499758,
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.6,
            "fmeasure": 0.52174
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.54545,
            "fmeasure": 0.48
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.54545,
            "fmeasure": 0.48
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8
        },
        "meteor": 0.4170567296323968,
        "nubia": {
            "semantic_relation": 4.71731,
            "contradiction": 0.13972,
            "irrelevancy": 98.98056,
            "logical_agreement": 0.87973,
            "grammar_ref": 5.42176,
            "grammar_hyp": 4.3993,
            "nubia_score": 0.92645
        },
        "bleurt": 0.26429,
        "bertscore": {
            "precision": 0.9038,
            "recall": 0.94413,
            "f1": 0.92352
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.05803,
        "nist": 3.4905792013416606,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.7151,
            "fmeasure": 0.69091
        },
        "rouge2": {
            "precision": 0.51961,
            "recall": 0.54285,
            "fmeasure": 0.505
        },
        "rougeL": {
            "precision": 0.61667,
            "recall": 0.65966,
            "fmeasure": 0.60018
        },
        "rougeLsum": {
            "precision": 0.61667,
            "recall": 0.65966,
            "fmeasure": 0.60018
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.5,
            "3": 0.7333333333333333
        },
        "meteor": 0.41086207754075665,
        "nubia": {
            "semantic_relation": 3.82248,
            "contradiction": 0.49673,
            "irrelevancy": 50.09238,
            "logical_agreement": 49.41089,
            "grammar_ref": 4.07172,
            "grammar_hyp": 4.83576,
            "nubia_score": 0.53382
        },
        "bleurt": 0.16002,
        "bertscore": {
            "precision": 0.88631,
            "recall": 0.94158,
            "f1": 0.90543
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.60942,
        "nist": 2.460877066081187,
        "rouge1": {
            "precision": 0.86111,
            "recall": 0.66214,
            "fmeasure": 0.74575
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.56897
        },
        "rougeL": {
            "precision": 0.86111,
            "recall": 0.66214,
            "fmeasure": 0.74575
        },
        "rougeLsum": {
            "precision": 0.86111,
            "recall": 0.66214,
            "fmeasure": 0.74575
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.7
        },
        "meteor": 0.34961682015412276,
        "nubia": {
            "semantic_relation": 4.13175,
            "contradiction": 5.11621,
            "irrelevancy": 58.80018,
            "logical_agreement": 36.08361,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.77291,
            "nubia_score": 0.64306
        },
        "bleurt": 0.09037,
        "bertscore": {
            "precision": 0.96082,
            "recall": 0.91957,
            "f1": 0.93535
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 11.57612,
        "nist": 1.3483232314986586,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.58824,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.25,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.29412,
            "fmeasure": 0.35714
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.29412,
            "fmeasure": 0.35714
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "meteor": 0.27721408441957573,
        "nubia": {
            "semantic_relation": 3.17506,
            "contradiction": 99.75678,
            "irrelevancy": 0.13319,
            "logical_agreement": 0.11003,
            "grammar_ref": 4.71038,
            "grammar_hyp": 5.32732,
            "nubia_score": 0.28693
        },
        "bleurt": 0.07915,
        "bertscore": {
            "precision": 0.94512,
            "recall": 0.89177,
            "f1": 0.91767
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 7.14182,
        "nist": 1.1864028910312008,
        "rouge1": {
            "precision": 0.30769,
            "recall": 0.5,
            "fmeasure": 0.38095
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.14286,
            "fmeasure": 0.10526
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.5,
            "fmeasure": 0.38095
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.5,
            "fmeasure": 0.38095
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.42857142857142855
        },
        "meteor": 0.2681654242932354,
        "nubia": {
            "semantic_relation": 3.13846,
            "contradiction": 7.19067,
            "irrelevancy": 92.57575,
            "logical_agreement": 0.23357,
            "grammar_ref": 5.51883,
            "grammar_hyp": 4.36598,
            "nubia_score": 0.39111
        },
        "bleurt": 0.06147,
        "bertscore": {
            "precision": 0.81143,
            "recall": 0.84474,
            "f1": 0.82775
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.70233,
        "nist": 1.920911643007432,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.64133,
            "fmeasure": 0.62222
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.40741,
            "fmeasure": 0.39153
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.64133,
            "fmeasure": 0.62222
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.64133,
            "fmeasure": 0.62222
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "meteor": 0.49721225160341215,
        "nubia": {
            "semantic_relation": 4.45599,
            "contradiction": 0.07569,
            "irrelevancy": 5.00353,
            "logical_agreement": 94.92078,
            "grammar_ref": 3.44041,
            "grammar_hyp": 4.34642,
            "nubia_score": 0.80331
        },
        "bleurt": 0.3902,
        "bertscore": {
            "precision": 0.94738,
            "recall": 0.95744,
            "f1": 0.95238
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.14348,
        "nist": 2.731058148919434,
        "rouge1": {
            "precision": 0.46429,
            "recall": 0.41935,
            "fmeasure": 0.44068
        },
        "rouge2": {
            "precision": 0.25926,
            "recall": 0.23333,
            "fmeasure": 0.24561
        },
        "rougeL": {
            "precision": 0.46429,
            "recall": 0.41935,
            "fmeasure": 0.44068
        },
        "rougeLsum": {
            "precision": 0.46429,
            "recall": 0.41935,
            "fmeasure": 0.44068
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5714285714285714,
            "3": 0.4444444444444444
        },
        "meteor": 0.2682296725932508,
        "nubia": {
            "semantic_relation": 2.15022,
            "contradiction": 88.50655,
            "irrelevancy": 8.28597,
            "logical_agreement": 3.20748,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.82658,
            "nubia_score": 0.17367
        },
        "bleurt": -0.17695,
        "bertscore": {
            "precision": 0.90446,
            "recall": 0.89129,
            "f1": 0.89783
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.85338,
        "nist": 3.181947848412687,
        "rouge1": {
            "precision": 0.69565,
            "recall": 0.82807,
            "fmeasure": 0.756
        },
        "rouge2": {
            "precision": 0.43939,
            "recall": 0.52827,
            "fmeasure": 0.47967
        },
        "rougeL": {
            "precision": 0.65217,
            "recall": 0.77632,
            "fmeasure": 0.70875
        },
        "rougeLsum": {
            "precision": 0.65217,
            "recall": 0.77632,
            "fmeasure": 0.70875
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "meteor": 0.4536249368142578,
        "nubia": {
            "semantic_relation": 4.52912,
            "contradiction": 0.22539,
            "irrelevancy": 94.68934,
            "logical_agreement": 5.08527,
            "grammar_ref": 4.62058,
            "grammar_hyp": 4.04715,
            "nubia_score": 0.89601
        },
        "bleurt": 0.32697,
        "bertscore": {
            "precision": 0.89336,
            "recall": 0.93706,
            "f1": 0.91469
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 10,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 71.13795,
        "nist": 6.749819562764513,
        "rouge1": {
            "precision": 0.88808,
            "recall": 0.86321,
            "fmeasure": 0.87006
        },
        "rouge2": {
            "precision": 0.77716,
            "recall": 0.74469,
            "fmeasure": 0.75567
        },
        "rougeL": {
            "precision": 0.77828,
            "recall": 0.7637,
            "fmeasure": 0.76672
        },
        "rougeLsum": {
            "precision": 0.77828,
            "recall": 0.7637,
            "fmeasure": 0.76672
        },
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.5769230769230769,
            "3": 0.9174311926605505
        },
        "meteor": 0.5103703682637712,
        "nubia": {
            "semantic_relation": 4.52639,
            "contradiction": 16.8949,
            "irrelevancy": 16.64533,
            "logical_agreement": 66.45977,
            "grammar_ref": 4.86973,
            "grammar_hyp": 5.00159,
            "nubia_score": 0.8229
        },
        "bleurt": 0.5964,
        "bertscore": {
            "precision": 0.97202,
            "recall": 0.96882,
            "f1": 0.96927
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.18145,
        "nist": 4.629811199055004,
        "rouge1": {
            "precision": 0.9,
            "recall": 0.8303,
            "fmeasure": 0.86371
        },
        "rouge2": {
            "precision": 0.51709,
            "recall": 0.47857,
            "fmeasure": 0.49708
        },
        "rougeL": {
            "precision": 0.62857,
            "recall": 0.58182,
            "fmeasure": 0.60427
        },
        "rougeLsum": {
            "precision": 0.62857,
            "recall": 0.58182,
            "fmeasure": 0.60427
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8461538461538461
        },
        "meteor": 0.43726147937955784,
        "nubia": {
            "semantic_relation": 4.87926,
            "contradiction": 0.17703,
            "irrelevancy": 1.24876,
            "logical_agreement": 98.5742,
            "grammar_ref": 3.76682,
            "grammar_hyp": 4.25418,
            "nubia_score": 0.93787
        },
        "bleurt": 0.51494,
        "bertscore": {
            "precision": 0.93725,
            "recall": 0.94294,
            "f1": 0.94003
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 19.43406,
        "nist": 2.4929182263680483,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6363636363636364
        },
        "meteor": 0.38388402914845343,
        "nubia": {
            "semantic_relation": 4.25211,
            "contradiction": 0.57776,
            "irrelevancy": 0.52541,
            "logical_agreement": 98.89683,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.57554,
            "nubia_score": 0.83281
        },
        "bleurt": 0.5593,
        "bertscore": {
            "precision": 0.96843,
            "recall": 0.92985,
            "f1": 0.94874
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 77.76587,
        "nist": 4.977182700831409,
        "rouge1": {
            "precision": 0.95777,
            "recall": 0.97059,
            "fmeasure": 0.96392
        },
        "rouge2": {
            "precision": 0.89236,
            "recall": 0.90625,
            "fmeasure": 0.899
        },
        "rougeL": {
            "precision": 0.86953,
            "recall": 0.88235,
            "fmeasure": 0.87569
        },
        "rougeLsum": {
            "precision": 0.86953,
            "recall": 0.88235,
            "fmeasure": 0.87569
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 1.0
        },
        "meteor": 0.5572456018037968,
        "nubia": {
            "semantic_relation": 4.38435,
            "contradiction": 49.71468,
            "irrelevancy": 32.83018,
            "logical_agreement": 17.45513,
            "grammar_ref": 4.08754,
            "grammar_hyp": 3.88534,
            "nubia_score": 0.84061
        },
        "bleurt": 0.54233,
        "bertscore": {
            "precision": 0.98945,
            "recall": 0.98649,
            "f1": 0.98796
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 5.34141,
        "nist": 3.1283964985498263,
        "rouge1": {
            "precision": 0.54167,
            "recall": 0.51277,
            "fmeasure": 0.52555
        },
        "rouge2": {
            "precision": 0.16129,
            "recall": 0.16667,
            "fmeasure": 0.1635
        },
        "rougeL": {
            "precision": 0.29167,
            "recall": 0.29949,
            "fmeasure": 0.29476
        },
        "rougeLsum": {
            "precision": 0.29167,
            "recall": 0.29949,
            "fmeasure": 0.29476
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.6,
            "3": 0.3
        },
        "meteor": 0.22130904211231237,
        "nubia": {
            "semantic_relation": 2.6617,
            "contradiction": 4.50768,
            "irrelevancy": 39.93329,
            "logical_agreement": 55.55903,
            "grammar_ref": 5.53052,
            "grammar_hyp": 4.17408,
            "nubia_score": 0.46507
        },
        "bleurt": -0.44498,
        "bertscore": {
            "precision": 0.84918,
            "recall": 0.81233,
            "f1": 0.83035
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.74741,
        "nist": 1.9600748678329039,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.59028,
            "fmeasure": 0.54094
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.26786,
            "fmeasure": 0.24265
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.53472,
            "fmeasure": 0.4883
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.53472,
            "fmeasure": 0.4883
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666
        },
        "meteor": 0.2828732600984953,
        "nubia": {
            "semantic_relation": 3.98901,
            "contradiction": 0.5604,
            "irrelevancy": 0.6176,
            "logical_agreement": 98.82201,
            "grammar_ref": 6.12307,
            "grammar_hyp": 5.22852,
            "nubia_score": 0.71932
        },
        "bleurt": 0.23513,
        "bertscore": {
            "precision": 0.84623,
            "recall": 0.82543,
            "f1": 0.8357
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.33511,
        "nist": 3.0088906840841796,
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "meteor": 0.4630505936482093,
        "nubia": {
            "semantic_relation": 4.98921,
            "contradiction": 0.42473,
            "irrelevancy": 22.33974,
            "logical_agreement": 77.23553,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.79251,
            "nubia_score": 1.0
        },
        "bleurt": 0.7528,
        "bertscore": {
            "precision": 0.97213,
            "recall": 0.96481,
            "f1": 0.96846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 91.01199,
        "nist": 4.421895930448264,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.94444,
            "fmeasure": 0.97059
        },
        "rouge2": {
            "precision": 0.92857,
            "recall": 0.875,
            "fmeasure": 0.9
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.94444,
            "fmeasure": 0.97059
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.94444,
            "fmeasure": 0.97059
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "meteor": 0.6102183940437521,
        "nubia": {
            "semantic_relation": 4.92209,
            "contradiction": 0.44249,
            "irrelevancy": 13.73199,
            "logical_agreement": 85.82552,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.57626,
            "nubia_score": 0.97688
        },
        "bleurt": 0.88401,
        "bertscore": {
            "precision": 0.99792,
            "recall": 0.9941,
            "f1": 0.9947
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 3.9538,
        "nist": 1.2501570421932473,
        "rouge1": {
            "precision": 0.30769,
            "recall": 0.44444,
            "fmeasure": 0.36364
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.15385,
            "recall": 0.22222,
            "fmeasure": 0.18182
        },
        "rougeLsum": {
            "precision": 0.15385,
            "recall": 0.22222,
            "fmeasure": 0.18182
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.375
        },
        "meteor": 0.13533834586466165,
        "nubia": {
            "semantic_relation": 3.09008,
            "contradiction": 12.60533,
            "irrelevancy": 71.53211,
            "logical_agreement": 15.86255,
            "grammar_ref": 5.49813,
            "grammar_hyp": 6.27577,
            "nubia_score": 0.27784
        },
        "bleurt": -0.0014,
        "bertscore": {
            "precision": 0.83002,
            "recall": 0.83552,
            "f1": 0.83276
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.64971,
        "nist": 2.659005565642719,
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.75,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "meteor": 0.9051319272478866,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.4082,
            "irrelevancy": 0.76883,
            "logical_agreement": 98.82297,
            "grammar_ref": 4.6206,
            "grammar_hyp": 4.37368,
            "nubia_score": 0.96322
        },
        "bleurt": 0.74939,
        "bertscore": {
            "precision": 0.94619,
            "recall": 0.97387,
            "f1": 0.95983
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.07487,
        "nist": 4.0583463515289555,
        "rouge1": {
            "precision": 0.78175,
            "recall": 0.74229,
            "fmeasure": 0.74601
        },
        "rouge2": {
            "precision": 0.41608,
            "recall": 0.45826,
            "fmeasure": 0.43157
        },
        "rougeL": {
            "precision": 0.64484,
            "recall": 0.68747,
            "fmeasure": 0.65681
        },
        "rougeLsum": {
            "precision": 0.64484,
            "recall": 0.68747,
            "fmeasure": 0.65681
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5454545454545454,
            "3": 0.7777777777777778
        },
        "meteor": 0.4020641253984808,
        "nubia": {
            "semantic_relation": 4.0233,
            "contradiction": 0.28703,
            "irrelevancy": 47.17648,
            "logical_agreement": 52.53649,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.30843,
            "nubia_score": 0.70242
        },
        "bleurt": 0.14359,
        "bertscore": {
            "precision": 0.91588,
            "recall": 0.929,
            "f1": 0.91386
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.00962,
        "nist": 3.9767865386982915,
        "rouge1": {
            "precision": 0.92105,
            "recall": 0.875,
            "fmeasure": 0.89744
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.68421,
            "fmeasure": 0.7027
        },
        "rougeL": {
            "precision": 0.71053,
            "recall": 0.675,
            "fmeasure": 0.69231
        },
        "rougeLsum": {
            "precision": 0.71053,
            "recall": 0.675,
            "fmeasure": 0.69231
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.9375
        },
        "meteor": 0.47928551418313564,
        "nubia": {
            "semantic_relation": 4.87887,
            "contradiction": 0.22901,
            "irrelevancy": 0.47504,
            "logical_agreement": 99.29595,
            "grammar_ref": 4.55046,
            "grammar_hyp": 4.72911,
            "nubia_score": 0.91093
        },
        "bleurt": 0.3887,
        "bertscore": {
            "precision": 0.94263,
            "recall": 0.95072,
            "f1": 0.94666
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 73.56845,
        "nist": 4.45571393687282,
        "rouge1": {
            "precision": 0.86207,
            "recall": 0.96154,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.84,
            "fmeasure": 0.79245
        },
        "rougeL": {
            "precision": 0.86207,
            "recall": 0.96154,
            "fmeasure": 0.90909
        },
        "rougeLsum": {
            "precision": 0.86207,
            "recall": 0.96154,
            "fmeasure": 0.90909
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9583333333333334
        },
        "meteor": 0.5635960158276588,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2518,
            "irrelevancy": 0.51473,
            "logical_agreement": 99.23346,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.49816,
            "nubia_score": 0.97993
        },
        "bleurt": 0.73507,
        "bertscore": {
            "precision": 0.97906,
            "recall": 0.98697,
            "f1": 0.98233
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.02104,
        "nist": 2.6885172661100523,
        "rouge1": {
            "precision": 0.62963,
            "recall": 0.41818,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.3,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.27273,
            "fmeasure": 0.3
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.27273,
            "fmeasure": 0.3
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.5
        },
        "meteor": 0.22445564147891944,
        "nubia": {
            "semantic_relation": 3.60962,
            "contradiction": 0.27247,
            "irrelevancy": 5.21845,
            "logical_agreement": 94.50909,
            "grammar_ref": 4.59968,
            "grammar_hyp": 5.20491,
            "nubia_score": 0.50435
        },
        "bleurt": -0.66491,
        "bertscore": {
            "precision": 0.86031,
            "recall": 0.82154,
            "f1": 0.83698
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.10546,
        "nist": 2.32249814589546,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "meteor": 0.8569614896318238,
        "nubia": {
            "semantic_relation": 4.62868,
            "contradiction": 0.5038,
            "irrelevancy": 0.54324,
            "logical_agreement": 98.95296,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.03961,
            "nubia_score": 0.96227
        },
        "bleurt": 0.65075,
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.9307,
            "f1": 0.94796
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.07607,
        "nist": 1.8248488266296587,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.53846,
            "fmeasure": 0.58333
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.41667,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.53846,
            "fmeasure": 0.58333
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.53846,
            "fmeasure": 0.58333
        },
        "local_recall": {
            "1": 0,
            "2": 0.5
        },
        "meteor": 0.2905649719938529,
        "nubia": {
            "semantic_relation": 4.30186,
            "contradiction": 0.22784,
            "irrelevancy": 20.0262,
            "logical_agreement": 79.74595,
            "grammar_ref": 3.76485,
            "grammar_hyp": 3.24793,
            "nubia_score": 0.9399
        },
        "bleurt": 0.48767,
        "bertscore": {
            "precision": 0.92516,
            "recall": 0.91363,
            "f1": 0.91936
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 76.11606,
        "nist": 3.6961650890339652,
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.81481,
            "fmeasure": 0.77193
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 0.5715186082473627,
        "nubia": {
            "semantic_relation": 4.94183,
            "contradiction": 0.26546,
            "irrelevancy": 2.07729,
            "logical_agreement": 97.65725,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.255,
            "nubia_score": 0.96846
        },
        "bleurt": 0.74566,
        "bertscore": {
            "precision": 0.97599,
            "recall": 0.99403,
            "f1": 0.98493
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.55964,
        "nist": 2.232633837416351,
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.66667,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.375,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.66667,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.66667,
            "fmeasure": 0.6
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "meteor": 0.3635018352844103,
        "nubia": {
            "semantic_relation": 4.90464,
            "contradiction": 0.06314,
            "irrelevancy": 5.75705,
            "logical_agreement": 94.17981,
            "grammar_ref": 4.6877,
            "grammar_hyp": 4.53211,
            "nubia_score": 0.97448
        },
        "bleurt": 0.54093,
        "bertscore": {
            "precision": 0.89276,
            "recall": 0.92714,
            "f1": 0.90963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.52212,
        "nist": 2.7010257059136618,
        "rouge1": {
            "precision": 0.47708,
            "recall": 0.76751,
            "fmeasure": 0.58363
        },
        "rouge2": {
            "precision": 0.2538,
            "recall": 0.45238,
            "fmeasure": 0.32284
        },
        "rougeL": {
            "precision": 0.3375,
            "recall": 0.55791,
            "fmeasure": 0.41828
        },
        "rougeLsum": {
            "precision": 0.3375,
            "recall": 0.55791,
            "fmeasure": 0.41828
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.2857142857142857,
            "3": 0.7894736842105263
        },
        "meteor": 0.3761936736020568,
        "nubia": {
            "semantic_relation": 3.93948,
            "contradiction": 1.13805,
            "irrelevancy": 49.23197,
            "logical_agreement": 49.62998,
            "grammar_ref": 4.70186,
            "grammar_hyp": 4.44831,
            "nubia_score": 0.61035
        },
        "bleurt": 0.1071,
        "bertscore": {
            "precision": 0.88314,
            "recall": 0.9174,
            "f1": 0.89378
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.18055,
        "nist": 2.3350765829744575,
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.51242,
            "fmeasure": 0.55873
        },
        "rouge2": {
            "precision": 0.36111,
            "recall": 0.27976,
            "fmeasure": 0.31502
        },
        "rougeL": {
            "precision": 0.58974,
            "recall": 0.46928,
            "fmeasure": 0.52222
        },
        "rougeLsum": {
            "precision": 0.58974,
            "recall": 0.46928,
            "fmeasure": 0.52222
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.3333333333333333,
            "3": 0.7142857142857143
        },
        "meteor": 0.239567608611199,
        "nubia": {
            "semantic_relation": 3.58763,
            "contradiction": 0.28772,
            "irrelevancy": 3.80389,
            "logical_agreement": 95.9084,
            "grammar_ref": 4.68072,
            "grammar_hyp": 4.57186,
            "nubia_score": 0.57774
        },
        "bleurt": -0.19155,
        "bertscore": {
            "precision": 0.88295,
            "recall": 0.80556,
            "f1": 0.84248
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.52819,
        "nist": 2.987239107202013,
        "rouge1": {
            "precision": 0.48333,
            "recall": 0.57966,
            "fmeasure": 0.52703
        },
        "rouge2": {
            "precision": 0.26316,
            "recall": 0.32639,
            "fmeasure": 0.29132
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.49329,
            "fmeasure": 0.46108
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.49329,
            "fmeasure": 0.46108
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.7777777777777778
        },
        "meteor": 0.28428490613872626,
        "nubia": {
            "semantic_relation": 2.88104,
            "contradiction": 1.65553,
            "irrelevancy": 89.40814,
            "logical_agreement": 8.93633,
            "grammar_ref": 3.5564,
            "grammar_hyp": 3.26837,
            "nubia_score": 0.45181
        },
        "bleurt": -0.12888,
        "bertscore": {
            "precision": 0.86524,
            "recall": 0.882,
            "f1": 0.87354
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 68.94026,
        "nist": 3.0881978509745025,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "meteor": 0.81809314801268,
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        },
        "bleurt": 0.64449,
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.78113,
        "nist": 4.064451888091332,
        "rouge1": {
            "precision": 0.78333,
            "recall": 0.84551,
            "fmeasure": 0.80486
        },
        "rouge2": {
            "precision": 0.63492,
            "recall": 0.69292,
            "fmeasure": 0.65465
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.71997,
            "fmeasure": 0.67687
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.71997,
            "fmeasure": 0.67687
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.125,
            "3": 0.9473684210526315
        },
        "meteor": 0.4747333312051358,
        "nubia": {
            "semantic_relation": 3.88406,
            "contradiction": 0.50003,
            "irrelevancy": 0.77122,
            "logical_agreement": 98.72874,
            "grammar_ref": 4.25678,
            "grammar_hyp": 3.82554,
            "nubia_score": 0.70944
        },
        "bleurt": 0.3943,
        "bertscore": {
            "precision": 0.9576,
            "recall": 0.96379,
            "f1": 0.95957
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 19.7517,
        "nist": 2.3067182555743666,
        "rouge1": {
            "precision": 0.7619,
            "recall": 0.60349,
            "fmeasure": 0.67339
        },
        "rouge2": {
            "precision": 0.38462,
            "recall": 0.30637,
            "fmeasure": 0.341
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.40414,
            "fmeasure": 0.44691
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.40414,
            "fmeasure": 0.44691
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.5294117647058824
        },
        "meteor": 0.30264882027980994,
        "nubia": {
            "semantic_relation": 3.83394,
            "contradiction": 0.60898,
            "irrelevancy": 93.45529,
            "logical_agreement": 5.93573,
            "grammar_ref": 4.84215,
            "grammar_hyp": 4.96959,
            "nubia_score": 0.51892
        },
        "bleurt": 0.06538,
        "bertscore": {
            "precision": 0.89353,
            "recall": 0.88355,
            "f1": 0.88851
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 66.54378,
        "nist": 4.147342193035677,
        "rouge1": {
            "precision": 0.78431,
            "recall": 0.89356,
            "fmeasure": 0.83365
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.79327,
            "fmeasure": 0.73491
        },
        "rougeL": {
            "precision": 0.78431,
            "recall": 0.89356,
            "fmeasure": 0.83365
        },
        "rougeLsum": {
            "precision": 0.78431,
            "recall": 0.89356,
            "fmeasure": 0.83365
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9230769230769231
        },
        "meteor": 0.5209491366068684,
        "nubia": {
            "semantic_relation": 4.0274,
            "contradiction": 23.40857,
            "irrelevancy": 68.01334,
            "logical_agreement": 8.57809,
            "grammar_ref": 4.48877,
            "grammar_hyp": 3.7912,
            "nubia_score": 0.77131
        },
        "bleurt": 0.24465,
        "bertscore": {
            "precision": 0.96597,
            "recall": 0.96312,
            "f1": 0.94495
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.48988,
        "nist": 3.055195332240158,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.90794,
            "fmeasure": 0.67179
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.38828,
            "fmeasure": 0.2826
        },
        "rougeL": {
            "precision": 0.32,
            "recall": 0.55873,
            "fmeasure": 0.40684
        },
        "rougeLsum": {
            "precision": 0.32,
            "recall": 0.55873,
            "fmeasure": 0.40684
        },
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 1.0,
            "3": 0.9
        },
        "meteor": 0.3973633199424582,
        "nubia": {
            "semantic_relation": 3.86428,
            "contradiction": 18.73006,
            "irrelevancy": 23.92162,
            "logical_agreement": 57.34832,
            "grammar_ref": 4.11472,
            "grammar_hyp": 3.06319,
            "nubia_score": 0.38434
        },
        "bleurt": 0.06771,
        "bertscore": {
            "precision": 0.89285,
            "recall": 0.91133,
            "f1": 0.902
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.87554,
        "nist": 2.3196076273494395,
        "rouge1": {
            "precision": 0.4359,
            "recall": 0.81111,
            "fmeasure": 0.56568
        },
        "rouge2": {
            "precision": 0.30667,
            "recall": 0.59307,
            "fmeasure": 0.40313
        },
        "rougeL": {
            "precision": 0.39744,
            "recall": 0.73889,
            "fmeasure": 0.51562
        },
        "rougeLsum": {
            "precision": 0.39744,
            "recall": 0.73889,
            "fmeasure": 0.51562
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.9
        },
        "meteor": 0.4045332453263602,
        "nubia": {
            "semantic_relation": 4.04755,
            "contradiction": 0.14959,
            "irrelevancy": 98.64422,
            "logical_agreement": 1.20619,
            "grammar_ref": 5.20931,
            "grammar_hyp": 3.92692,
            "nubia_score": 0.50803
        },
        "bleurt": -0.17378,
        "bertscore": {
            "precision": 0.80138,
            "recall": 0.91484,
            "f1": 0.85436
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.67372,
        "nist": 3.008880366590873,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.64052,
            "fmeasure": 0.63213
        },
        "rouge2": {
            "precision": 0.17778,
            "recall": 0.17262,
            "fmeasure": 0.17501
        },
        "rougeL": {
            "precision": 0.39583,
            "recall": 0.40915,
            "fmeasure": 0.40209
        },
        "rougeLsum": {
            "precision": 0.39583,
            "recall": 0.40915,
            "fmeasure": 0.40209
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "meteor": 0.2930239820055068,
        "nubia": {
            "semantic_relation": 4.18444,
            "contradiction": 0.12622,
            "irrelevancy": 86.30408,
            "logical_agreement": 13.56969,
            "grammar_ref": 4.4151,
            "grammar_hyp": 4.9187,
            "nubia_score": 0.6564
        },
        "bleurt": -0.00995,
        "bertscore": {
            "precision": 0.89614,
            "recall": 0.8954,
            "f1": 0.88935
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.80384,
        "nist": 3.799326052930177,
        "rouge1": {
            "precision": 0.7669,
            "recall": 0.87593,
            "fmeasure": 0.81722
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.73729,
            "fmeasure": 0.68397
        },
        "rougeL": {
            "precision": 0.7669,
            "recall": 0.87593,
            "fmeasure": 0.81722
        },
        "rougeLsum": {
            "precision": 0.7669,
            "recall": 0.87593,
            "fmeasure": 0.81722
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.9473684210526315
        },
        "meteor": 0.44436352723802286,
        "nubia": {
            "semantic_relation": 4.75555,
            "contradiction": 0.29718,
            "irrelevancy": 18.33183,
            "logical_agreement": 81.37098,
            "grammar_ref": 6.17452,
            "grammar_hyp": 5.68355,
            "nubia_score": 0.91602
        },
        "bleurt": 0.42938,
        "bertscore": {
            "precision": 0.93239,
            "recall": 0.9434,
            "f1": 0.93647
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.273915542852983,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.78571,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90909
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90909
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.30531,
            "contradiction": 0.13077,
            "irrelevancy": 33.52146,
            "logical_agreement": 66.34777,
            "grammar_ref": 5.27628,
            "grammar_hyp": 5.33569,
            "nubia_score": 0.8039
        },
        "bleurt": 0.56444,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.03278,
        "nist": 3.382229517004531,
        "rouge1": {
            "precision": 0.81667,
            "recall": 0.68172,
            "fmeasure": 0.7425
        },
        "rouge2": {
            "precision": 0.50877,
            "recall": 0.42303,
            "fmeasure": 0.46157
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.50167,
            "fmeasure": 0.54601
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.50167,
            "fmeasure": 0.54601
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "meteor": 0.3698316367587973,
        "nubia": {
            "semantic_relation": 4.93661,
            "contradiction": 0.18099,
            "irrelevancy": 0.42925,
            "logical_agreement": 99.38975,
            "grammar_ref": 3.26294,
            "grammar_hyp": 3.06462,
            "nubia_score": 0.99331
        },
        "bleurt": 0.49916,
        "bertscore": {
            "precision": 0.93457,
            "recall": 0.90081,
            "f1": 0.91738
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.3219280948873626,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        },
        "bleurt": 0.97683,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.52877,
        "nist": 4.43821054894878,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.80484,
            "fmeasure": 0.81404
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.45098,
            "fmeasure": 0.45333
        },
        "rougeL": {
            "precision": 0.7381,
            "recall": 0.71652,
            "fmeasure": 0.72299
        },
        "rougeLsum": {
            "precision": 0.7381,
            "recall": 0.71652,
            "fmeasure": 0.72299
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "meteor": 0.4232367380520258,
        "nubia": {
            "semantic_relation": 4.51457,
            "contradiction": 0.3004,
            "irrelevancy": 33.57484,
            "logical_agreement": 66.12476,
            "grammar_ref": 5.3293,
            "grammar_hyp": 5.2395,
            "nubia_score": 0.80149
        },
        "bleurt": 0.37523,
        "bertscore": {
            "precision": 0.96232,
            "recall": 0.96656,
            "f1": 0.96443
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.84935,
        "nist": 2.425151750686625,
        "rouge1": {
            "precision": 0.49275,
            "recall": 0.53968,
            "fmeasure": 0.51515
        },
        "rouge2": {
            "precision": 0.25758,
            "recall": 0.28333,
            "fmeasure": 0.26984
        },
        "rougeL": {
            "precision": 0.34783,
            "recall": 0.34592,
            "fmeasure": 0.34499
        },
        "rougeLsum": {
            "precision": 0.34783,
            "recall": 0.34592,
            "fmeasure": 0.34499
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.7272727272727273
        },
        "meteor": 0.3372687801186905,
        "nubia": {
            "semantic_relation": 4.21181,
            "contradiction": 0.10203,
            "irrelevancy": 88.74054,
            "logical_agreement": 11.15743,
            "grammar_ref": 3.9898,
            "grammar_hyp": 4.09995,
            "nubia_score": 0.74846
        },
        "bleurt": 0.24883,
        "bertscore": {
            "precision": 0.90738,
            "recall": 0.89986,
            "f1": 0.90361
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.398,
        "nist": 1.7261486371803938,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.53846,
            "fmeasure": 0.63636
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2037,
            "fmeasure": 0.22353
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.38462,
            "fmeasure": 0.45455
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.38462,
            "fmeasure": 0.45455
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5714285714285714
        },
        "meteor": 0.26327612233306297,
        "nubia": {
            "semantic_relation": 4.07318,
            "contradiction": 14.05691,
            "irrelevancy": 69.08389,
            "logical_agreement": 16.85921,
            "grammar_ref": 5.35395,
            "grammar_hyp": 4.58629,
            "nubia_score": 0.64757
        },
        "bleurt": -0.28081,
        "bertscore": {
            "precision": 0.91468,
            "recall": 0.86531,
            "f1": 0.88931
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.83214,
        "nist": 3.5305098074966517,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.84615,
            "fmeasure": 0.88
        },
        "rouge2": {
            "precision": 0.60606,
            "recall": 0.5,
            "fmeasure": 0.54725
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.64957,
            "fmeasure": 0.70716
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.64957,
            "fmeasure": 0.70716
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 1.0
        },
        "meteor": 0.40901377787844384,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.25891,
            "irrelevancy": 0.47786,
            "logical_agreement": 99.26323,
            "grammar_ref": 4.20051,
            "grammar_hyp": 4.99607,
            "nubia_score": 0.93899
        },
        "bleurt": 0.51087,
        "bertscore": {
            "precision": 0.97028,
            "recall": 0.95031,
            "f1": 0.96019
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.6419,
        "nist": 1.3934338964335204,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "meteor": 0.4307001776843669,
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.30154,
            "irrelevancy": 0.49604,
            "logical_agreement": 99.20242,
            "grammar_ref": 5.72796,
            "grammar_hyp": 7.07513,
            "nubia_score": 0.79132
        },
        "bleurt": 0.82527,
        "bertscore": {
            "precision": 0.97397,
            "recall": 0.93815,
            "f1": 0.95573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 84.64817,
        "nist": 2.1126567718249225,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.74603,
            "fmeasure": 0.82828
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "meteor": 0.507208078598044,
        "nubia": {
            "semantic_relation": 3.69006,
            "contradiction": 0.31517,
            "irrelevancy": 0.57051,
            "logical_agreement": 99.11432,
            "grammar_ref": 6.37596,
            "grammar_hyp": 5.64518,
            "nubia_score": 0.75233
        },
        "bleurt": -0.15862,
        "bertscore": {
            "precision": 0.97931,
            "recall": 0.9326,
            "f1": 0.95538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.16764,
        "nist": 1.28275019220987,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.26667,
            "fmeasure": 0.2963
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.07143,
            "fmeasure": 0.08
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333
        },
        "meteor": 0.1511719100037575,
        "nubia": {
            "semantic_relation": 2.73321,
            "contradiction": 42.7709,
            "irrelevancy": 51.85838,
            "logical_agreement": 5.37072,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.24916,
            "nubia_score": 0.32813
        },
        "bleurt": -0.38979,
        "bertscore": {
            "precision": 0.79606,
            "recall": 0.79087,
            "f1": 0.79345
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.35579,
        "nist": 4.502060569538222,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.51453,
            "fmeasure": 0.52564
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.34226,
            "fmeasure": 0.34921
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.34226,
            "fmeasure": 0.34921
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "meteor": 0.4452980347402408,
        "nubia": {
            "semantic_relation": 4.76119,
            "contradiction": 0.26908,
            "irrelevancy": 33.53051,
            "logical_agreement": 66.20041,
            "grammar_ref": 4.41465,
            "grammar_hyp": 4.7223,
            "nubia_score": 0.88644
        },
        "bleurt": 0.29739,
        "bertscore": {
            "precision": 0.95538,
            "recall": 0.92773,
            "f1": 0.94135
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.56152,
        "nist": 1.3449057001279126,
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.60185,
            "fmeasure": 0.73256
        },
        "rouge2": {
            "precision": 0.57778,
            "recall": 0.38785,
            "fmeasure": 0.46394
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5303,
            "fmeasure": 0.62105
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5303,
            "fmeasure": 0.62105
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.6111111111111112
        },
        "meteor": 0.323138619971827,
        "nubia": {
            "semantic_relation": 3.91285,
            "contradiction": 0.24169,
            "irrelevancy": 33.32452,
            "logical_agreement": 66.43379,
            "grammar_ref": 3.86337,
            "grammar_hyp": 3.70233,
            "nubia_score": 0.71848
        },
        "bleurt": 0.14396,
        "bertscore": {
            "precision": 0.96725,
            "recall": 0.90083,
            "f1": 0.92997
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.87258,
        "nist": 3.2431015194769057,
        "rouge1": {
            "precision": 0.57895,
            "recall": 0.57407,
            "fmeasure": 0.57526
        },
        "rouge2": {
            "precision": 0.25926,
            "recall": 0.25957,
            "fmeasure": 0.25885
        },
        "rougeL": {
            "precision": 0.36842,
            "recall": 0.36532,
            "fmeasure": 0.36607
        },
        "rougeLsum": {
            "precision": 0.36842,
            "recall": 0.36532,
            "fmeasure": 0.36607
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.5625
        },
        "meteor": 0.309175028317315,
        "nubia": {
            "semantic_relation": 3.45827,
            "contradiction": 50.28156,
            "irrelevancy": 26.24956,
            "logical_agreement": 23.46888,
            "grammar_ref": 4.78465,
            "grammar_hyp": 5.67707,
            "nubia_score": 0.39648
        },
        "bleurt": -0.06075,
        "bertscore": {
            "precision": 0.87976,
            "recall": 0.86753,
            "f1": 0.87289
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.854285871987245,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32615,
            "irrelevancy": 0.47325,
            "logical_agreement": 99.2006,
            "grammar_ref": 5.00662,
            "grammar_hyp": 5.00662,
            "nubia_score": 1.0
        },
        "bleurt": 0.94692,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "total_length": 1764,
        "mean_pred_length": 28.0,
        "std_pred_length": 8.757762996245827,
        "median_pred_length": 27.0,
        "min_pred_length": 10,
        "max_pred_length": 46,
        "distinct-1": 0.4688208616780045,
        "vocab_size-1": 827,
        "unique-1": 659,
        "entropy-1": 8.347138552754208,
        "distinct-2": 0.9018224573780129,
        "vocab_size-2": 1534,
        "unique-2": 1458,
        "entropy-2": 10.446806402146564,
        "cond_entropy-2": 1.957842284655599,
        "distinct-3": 0.9774114774114774,
        "vocab_size-3": 1601,
        "unique-3": 1590,
        "entropy-3": 10.598283919527683,
        "cond_entropy-3": 0.15771857780804555,
        "total_length-nopunct": 1572,
        "mean_pred_length-nopunct": 24.952380952380953,
        "std_pred_length-nopunct": 7.505402438219899,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.5203562340966921,
        "vocab_size-1-nopunct": 818,
        "unique-1-nopunct": 657,
        "entropy-1-nopunct": 8.555571486596927,
        "distinct-2-nopunct": 0.9343936381709742,
        "vocab_size-2-nopunct": 1410,
        "unique-2-nopunct": 1350,
        "entropy-2-nopunct": 10.39822945370503,
        "cond_entropy-2-nopunct": 1.9036309185280582,
        "distinct-3-nopunct": 0.995850622406639,
        "vocab_size-3-nopunct": 1440,
        "unique-3-nopunct": 1435,
        "entropy-3-nopunct": 10.489031029549926,
        "cond_entropy-3-nopunct": 0.09713096804424864,
        "msttr-100": 0.73941,
        "msttr-100_nopunct": 0.77667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 85.50628,
        "nist": 11.442373861771022,
        "rouge1": {
            "precision": 0.88316,
            "recall": 0.89695,
            "fmeasure": 0.88713
        },
        "rouge2": {
            "precision": 0.7811,
            "recall": 0.78912,
            "fmeasure": 0.78128
        },
        "rougeL": {
            "precision": 0.87082,
            "recall": 0.89076,
            "fmeasure": 0.8777
        },
        "rougeLsum": {
            "precision": 0.87082,
            "recall": 0.89076,
            "fmeasure": 0.8777
        },
        "local_recall": {
            "1": 0.036734693877551024,
            "2": 0.18032786885245902,
            "3": 0.47368421052631576,
            "4": 0.6441717791411042,
            "5": 0.7784431137724551,
            "6": 0.8494623655913979,
            "7": 0.9036144578313253,
            "8": 0.9488372093023256,
            "9": 0.9310344827586207,
            "10": 0.9814814814814815
        },
        "meteor": 0.5565510946388789,
        "nubia": {
            "semantic_relation": 4.30249,
            "contradiction": 0.80626,
            "irrelevancy": 44.00871,
            "logical_agreement": 55.18503,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.4409,
            "nubia_score": 0.64817
        },
        "bleurt": 0.21203,
        "bertscore": {
            "precision": 0.96615,
            "recall": 0.97549,
            "f1": 0.9695
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.56457,
        "nist": 1.2456551980554023,
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.75,
            "fmeasure": 0.54545
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.54545,
            "fmeasure": 0.3871
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.5,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.5,
            "fmeasure": 0.36364
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5833333333333334
        },
        "meteor": 0.3550118368496461,
        "nubia": {
            "semantic_relation": 3.93084,
            "contradiction": 2.90635,
            "irrelevancy": 88.68982,
            "logical_agreement": 8.40384,
            "grammar_ref": 4.44512,
            "grammar_hyp": 4.16105,
            "nubia_score": 0.49902
        },
        "bleurt": -0.30699,
        "bertscore": {
            "precision": 0.85731,
            "recall": 0.91273,
            "f1": 0.88121
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "total_length": 2870,
        "mean_pred_length": 16.49425287356322,
        "std_pred_length": 7.1861513738745355,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.43902439024390244,
        "vocab_size-1": 1260,
        "unique-1": 983,
        "entropy-1": 8.537649133278203,
        "distinct-2": 0.8701780415430267,
        "vocab_size-2": 2346,
        "unique-2": 2213,
        "entropy-2": 10.971701519145066,
        "cond_entropy-2": 2.141612521683726,
        "distinct-3": 0.9702616970658208,
        "vocab_size-3": 2447,
        "unique-3": 2406,
        "entropy-3": 11.2198437607325,
        "cond_entropy-3": 0.26559202552581607,
        "total_length-nopunct": 2526,
        "mean_pred_length-nopunct": 14.517241379310345,
        "std_pred_length-nopunct": 6.299720973506277,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.49524940617577196,
        "vocab_size-1-nopunct": 1251,
        "unique-1-nopunct": 982,
        "entropy-1-nopunct": 8.856130207698245,
        "distinct-2-nopunct": 0.8830782312925171,
        "vocab_size-2-nopunct": 2077,
        "unique-2-nopunct": 1970,
        "entropy-2-nopunct": 10.810861078659766,
        "cond_entropy-2-nopunct": 2.095757617118593,
        "distinct-3-nopunct": 0.9807162534435262,
        "vocab_size-3-nopunct": 2136,
        "unique-3-nopunct": 2103,
        "entropy-3-nopunct": 11.046876295413645,
        "cond_entropy-3-nopunct": 0.25957504701622075,
        "msttr-100": 0.71857,
        "msttr-100_nopunct": 0.7628,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 70.94905,
        "nist": 10.282513393362654,
        "rouge1": {
            "precision": 0.87255,
            "recall": 0.80321,
            "fmeasure": 0.82288
        },
        "rouge2": {
            "precision": 0.73217,
            "recall": 0.67267,
            "fmeasure": 0.68795
        },
        "rougeL": {
            "precision": 0.83952,
            "recall": 0.77285,
            "fmeasure": 0.79132
        },
        "rougeLsum": {
            "precision": 0.83952,
            "recall": 0.77285,
            "fmeasure": 0.79132
        },
        "local_recall": {
            "1": 0.04302203567681007,
            "2": 0.14521452145214522,
            "3": 0.3915343915343915,
            "4": 0.532258064516129,
            "5": 0.6377708978328174,
            "6": 0.7731343283582089,
            "7": 0.8767932489451477
        },
        "meteor": 0.4739209441727924,
        "nubia": {
            "semantic_relation": 4.33611,
            "contradiction": 4.54415,
            "irrelevancy": 15.79715,
            "logical_agreement": 79.6587,
            "grammar_ref": 4.58509,
            "grammar_hyp": 5.03207,
            "nubia_score": 0.70296
        },
        "bleurt": 0.25894,
        "bertscore": {
            "precision": 0.95884,
            "recall": 0.94444,
            "f1": 0.94946
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "total_length": 1186,
        "mean_pred_length": 20.448275862068964,
        "std_pred_length": 8.990746993999275,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 54,
        "distinct-1": 0.5075885328836425,
        "vocab_size-1": 602,
        "unique-1": 489,
        "entropy-1": 8.029206718940571,
        "distinct-2": 0.9202127659574468,
        "vocab_size-2": 1038,
        "unique-2": 987,
        "entropy-2": 9.937832331207431,
        "cond_entropy-2": 1.7135132858682502,
        "distinct-3": 0.9850467289719627,
        "vocab_size-3": 1054,
        "unique-3": 1044,
        "entropy-3": 10.026741547691381,
        "cond_entropy-3": 0.09984351856710127,
        "total_length-nopunct": 1065,
        "mean_pred_length-nopunct": 18.362068965517242,
        "std_pred_length-nopunct": 7.973443585799891,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.5577464788732395,
        "vocab_size-1-nopunct": 594,
        "unique-1-nopunct": 487,
        "entropy-1-nopunct": 8.203631905697437,
        "distinct-2-nopunct": 0.9364448857994042,
        "vocab_size-2-nopunct": 943,
        "unique-2-nopunct": 900,
        "entropy-2-nopunct": 9.823366463516628,
        "cond_entropy-2-nopunct": 1.7149573725614125,
        "distinct-3-nopunct": 0.9926238145416227,
        "vocab_size-3-nopunct": 942,
        "unique-3-nopunct": 935,
        "entropy-3-nopunct": 9.875511906104386,
        "cond_entropy-3-nopunct": 0.060410908615624925,
        "msttr-100": 0.72909,
        "msttr-100_nopunct": 0.762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 67.85413,
        "nist": 9.333398300991902,
        "rouge1": {
            "precision": 0.85332,
            "recall": 0.78163,
            "fmeasure": 0.80793
        },
        "rouge2": {
            "precision": 0.72668,
            "recall": 0.66596,
            "fmeasure": 0.6861
        },
        "rougeL": {
            "precision": 0.83584,
            "recall": 0.77273,
            "fmeasure": 0.79513
        },
        "rougeLsum": {
            "precision": 0.83584,
            "recall": 0.77273,
            "fmeasure": 0.79513
        },
        "local_recall": {
            "1": 0.041031652989449004,
            "2": 0.15492957746478872,
            "3": 0.36363636363636365,
            "4": 0.5769230769230769,
            "5": 0.6368715083798883,
            "6": 0.7885304659498208,
            "7": 0.852112676056338
        },
        "meteor": 0.4550699353656598,
        "nubia": {
            "semantic_relation": 4.34696,
            "contradiction": 4.77652,
            "irrelevancy": 14.1091,
            "logical_agreement": 81.11438,
            "grammar_ref": 4.54049,
            "grammar_hyp": 4.71536,
            "nubia_score": 0.73799
        },
        "bleurt": 0.24646,
        "bertscore": {
            "precision": 0.95755,
            "recall": 0.94495,
            "f1": 0.94975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.38847,
        "nist": 2.2671377485203372,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.5098,
            "fmeasure": 0.5977
        },
        "rouge2": {
            "precision": 0.51515,
            "recall": 0.35417,
            "fmeasure": 0.41975
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.47059,
            "fmeasure": 0.55172
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.47059,
            "fmeasure": 0.55172
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "meteor": 0.31038359912941405,
        "nubia": {
            "semantic_relation": 4.13741,
            "contradiction": 12.10172,
            "irrelevancy": 13.26334,
            "logical_agreement": 74.63495,
            "grammar_ref": 3.28677,
            "grammar_hyp": 4.73107,
            "nubia_score": 0.58847
        },
        "bleurt": 0.38888,
        "bertscore": {
            "precision": 0.93961,
            "recall": 0.91915,
            "f1": 0.92927
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "total_length": 501,
        "mean_pred_length": 22.772727272727273,
        "std_pred_length": 9.467320914031392,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 41,
        "distinct-1": 0.5768463073852296,
        "vocab_size-1": 289,
        "unique-1": 240,
        "entropy-1": 7.3226385996604,
        "distinct-2": 0.9331941544885177,
        "vocab_size-2": 447,
        "unique-2": 428,
        "entropy-2": 8.736314700628682,
        "cond_entropy-2": 1.284459242195249,
        "distinct-3": 0.9934354485776805,
        "vocab_size-3": 454,
        "unique-3": 451,
        "entropy-3": 8.822921252213465,
        "cond_entropy-3": 0.09467324128357621,
        "total_length-nopunct": 448,
        "mean_pred_length-nopunct": 20.363636363636363,
        "std_pred_length-nopunct": 8.52027237371635,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.6361607142857143,
        "vocab_size-1-nopunct": 285,
        "unique-1-nopunct": 240,
        "entropy-1-nopunct": 7.46595659705266,
        "distinct-2-nopunct": 0.9342723004694836,
        "vocab_size-2-nopunct": 398,
        "unique-2-nopunct": 381,
        "entropy-2-nopunct": 8.569769097910097,
        "cond_entropy-2-nopunct": 1.1623237699874522,
        "distinct-3-nopunct": 0.9925742574257426,
        "vocab_size-3-nopunct": 401,
        "unique-3-nopunct": 398,
        "entropy-3-nopunct": 8.643359997603243,
        "cond_entropy-3-nopunct": 0.08009756179944771,
        "msttr-100": 0.716,
        "msttr-100_nopunct": 0.7625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 74.58766,
        "nist": 8.77179235060557,
        "rouge1": {
            "precision": 0.83449,
            "recall": 0.81778,
            "fmeasure": 0.81851
        },
        "rouge2": {
            "precision": 0.70252,
            "recall": 0.69423,
            "fmeasure": 0.69197
        },
        "rougeL": {
            "precision": 0.8135,
            "recall": 0.79808,
            "fmeasure": 0.7976
        },
        "rougeLsum": {
            "precision": 0.8135,
            "recall": 0.79808,
            "fmeasure": 0.7976
        },
        "local_recall": {
            "1": 0.04,
            "2": 0.1864406779661017,
            "3": 0.5,
            "4": 0.5306122448979592,
            "5": 0.7027027027027027,
            "6": 0.7676767676767676,
            "7": 0.9107142857142857
        },
        "meteor": 0.49099413875166237,
        "nubia": {
            "semantic_relation": 4.39078,
            "contradiction": 2.37517,
            "irrelevancy": 13.75744,
            "logical_agreement": 83.86738,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.63685,
            "nubia_score": 0.75587
        },
        "bleurt": 0.33316,
        "bertscore": {
            "precision": 0.96393,
            "recall": 0.95649,
            "f1": 0.95837
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.01969,
        "nist": 3.091588931265672,
        "rouge1": {
            "precision": 0.62778,
            "recall": 0.75029,
            "fmeasure": 0.66246
        },
        "rouge2": {
            "precision": 0.37279,
            "recall": 0.45926,
            "fmeasure": 0.38914
        },
        "rougeL": {
            "precision": 0.57917,
            "recall": 0.65552,
            "fmeasure": 0.59963
        },
        "rougeLsum": {
            "precision": 0.57917,
            "recall": 0.65552,
            "fmeasure": 0.59963
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.75,
            "3": 0.8
        },
        "meteor": 0.3735135136806336,
        "nubia": {
            "semantic_relation": 4.34886,
            "contradiction": 49.12644,
            "irrelevancy": 46.09654,
            "logical_agreement": 4.77702,
            "grammar_ref": 5.12311,
            "grammar_hyp": 4.61529,
            "nubia_score": 0.56172
        },
        "bleurt": 0.31546,
        "bertscore": {
            "precision": 0.89055,
            "recall": 0.93624,
            "f1": 0.91191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.28147,
        "nist": 3.1439774686768684,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.79545,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.60119,
            "fmeasure": 0.53431
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 0.49043387317825937,
        "nubia": {
            "semantic_relation": 2.68766,
            "contradiction": 26.50481,
            "irrelevancy": 71.49975,
            "logical_agreement": 1.99544,
            "grammar_ref": 3.66596,
            "grammar_hyp": 2.72658,
            "nubia_score": 0.46158
        },
        "bleurt": 0.07163,
        "bertscore": {
            "precision": 0.91675,
            "recall": 0.92378,
            "f1": 0.92025
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "total_length": 69,
        "mean_pred_length": 23.0,
        "std_pred_length": 10.614455552060438,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 38,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 57,
        "unique-1": 48,
        "entropy-1": 5.720772463993187,
        "distinct-2": 1.0,
        "vocab_size-2": 66,
        "unique-2": 66,
        "entropy-2": 6.044394119358462,
        "cond_entropy-2": 0.2503376550373066,
        "distinct-3": 1.0,
        "vocab_size-3": 63,
        "unique-3": 63,
        "entropy-3": 5.97727992349992,
        "cond_entropy-3": -0.06711419585853678,
        "total_length-nopunct": 61,
        "mean_pred_length-nopunct": 20.333333333333332,
        "std_pred_length-nopunct": 8.956685895029603,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.8688524590163934,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.656067050642171,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.85798099512757,
        "cond_entropy-2-nopunct": 0.1988796489812975,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 55,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.7813597135246555,
        "cond_entropy-3-nopunct": -0.0766212816029123,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 59.34357,
        "nist": 5.66750817224192,
        "rouge1": {
            "precision": 0.81463,
            "recall": 0.85732,
            "fmeasure": 0.83403
        },
        "rouge2": {
            "precision": 0.64492,
            "recall": 0.68608,
            "fmeasure": 0.66366
        },
        "rougeL": {
            "precision": 0.78396,
            "recall": 0.82906,
            "fmeasure": 0.80454
        },
        "rougeLsum": {
            "precision": 0.78396,
            "recall": 0.82906,
            "fmeasure": 0.80454
        },
        "local_recall": {
            "1": 0.10256410256410256,
            "2": 0.13333333333333333,
            "3": 0.75,
            "4": 0.7142857142857143,
            "5": 0.6666666666666666,
            "6": 0.8571428571428571,
            "7": 0.9642857142857143
        },
        "meteor": 0.4840790468335109,
        "nubia": {
            "semantic_relation": 4.76669,
            "contradiction": 0.52128,
            "irrelevancy": 26.65133,
            "logical_agreement": 72.82739,
            "grammar_ref": 4.54431,
            "grammar_hyp": 4.6352,
            "nubia_score": 0.85271
        },
        "bleurt": 0.36728,
        "bertscore": {
            "precision": 0.94421,
            "recall": 0.96771,
            "f1": 0.95285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 80.34284,
        "nist": 5.028743719105235,
        "rouge1": {
            "precision": 0.87719,
            "recall": 0.8631,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.75926,
            "recall": 0.74444,
            "fmeasure": 0.74854
        },
        "rougeL": {
            "precision": 0.85965,
            "recall": 0.84226,
            "fmeasure": 0.84762
        },
        "rougeLsum": {
            "precision": 0.85965,
            "recall": 0.84226,
            "fmeasure": 0.84762
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "meteor": 0.5279124806700477,
        "nubia": {
            "semantic_relation": 4.11695,
            "contradiction": 0.13544,
            "irrelevancy": 66.37733,
            "logical_agreement": 33.48722,
            "grammar_ref": 3.89472,
            "grammar_hyp": 3.50799,
            "nubia_score": 0.83639
        },
        "bleurt": 0.38427,
        "bertscore": {
            "precision": 0.98494,
            "recall": 0.97128,
            "f1": 0.97806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.09786,
        "nist": 3.1566687205209765,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.625,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "meteor": 0.4966539475018306,
        "nubia": {
            "semantic_relation": 4.87291,
            "contradiction": 1.46235,
            "irrelevancy": 0.76655,
            "logical_agreement": 97.7711,
            "grammar_ref": 5.69157,
            "grammar_hyp": 5.6695,
            "nubia_score": 0.87733
        },
        "bleurt": 0.63785,
        "bertscore": {
            "precision": 0.97269,
            "recall": 0.95234,
            "f1": 0.96241
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.8465578035643277,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.69325,
            "irrelevancy": 0.54497,
            "logical_agreement": 98.76179,
            "grammar_ref": 7.00423,
            "grammar_hyp": 7.45225,
            "nubia_score": 0.93405
        },
        "bleurt": 0.87565,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.84544,
        "nist": 2.690984218671936,
        "rouge1": {
            "precision": 0.62121,
            "recall": 0.63059,
            "fmeasure": 0.62579
        },
        "rouge2": {
            "precision": 0.46032,
            "recall": 0.46746,
            "fmeasure": 0.4638
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.48254,
            "fmeasure": 0.41232
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.48254,
            "fmeasure": 0.41232
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.6,
            "3": 0.6
        },
        "meteor": 0.2838672894251625,
        "nubia": {
            "semantic_relation": 3.62355,
            "contradiction": 64.04706,
            "irrelevancy": 33.81081,
            "logical_agreement": 2.14214,
            "grammar_ref": 3.44293,
            "grammar_hyp": 3.60062,
            "nubia_score": 0.5754
        },
        "bleurt": -0.05514,
        "bertscore": {
            "precision": 0.83841,
            "recall": 0.91503,
            "f1": 0.87295
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.76354,
        "nist": 2.515160478176624,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 0.4500312850536032,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.19258,
            "irrelevancy": 0.51944,
            "logical_agreement": 99.28798,
            "grammar_ref": 6.21263,
            "grammar_hyp": 6.02192,
            "nubia_score": 0.98116
        },
        "bleurt": 0.77197,
        "bertscore": {
            "precision": 0.95871,
            "recall": 0.98377,
            "f1": 0.97108
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 92.77192,
        "nist": 3.496977106830779,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.91667,
            "fmeasure": 0.82381
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.8,
            "fmeasure": 0.71154
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.91667,
            "fmeasure": 0.82381
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.91667,
            "fmeasure": 0.82381
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "meteor": 0.5991546711750068,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.35547,
            "irrelevancy": 0.81342,
            "logical_agreement": 98.83111,
            "grammar_ref": 7.77345,
            "grammar_hyp": 6.71465,
            "nubia_score": 1.0
        },
        "bleurt": 0.73619,
        "bertscore": {
            "precision": 0.97485,
            "recall": 0.99229,
            "f1": 0.98349
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 11.23785,
        "nist": 3.1883641763430943,
        "rouge1": {
            "precision": 0.47368,
            "recall": 0.43413,
            "fmeasure": 0.45299
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.10351,
            "fmeasure": 0.10716
        },
        "rougeL": {
            "precision": 0.26316,
            "recall": 0.24603,
            "fmeasure": 0.25427
        },
        "rougeLsum": {
            "precision": 0.26316,
            "recall": 0.24603,
            "fmeasure": 0.25427
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6
        },
        "meteor": 0.23825880165918054,
        "nubia": {
            "semantic_relation": 3.32901,
            "contradiction": 3.97177,
            "irrelevancy": 76.77485,
            "logical_agreement": 19.25338,
            "grammar_ref": 5.50536,
            "grammar_hyp": 4.80751,
            "nubia_score": 0.50497
        },
        "bleurt": -0.12829,
        "bertscore": {
            "precision": 0.84308,
            "recall": 0.85469,
            "f1": 0.84797
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.72798,
        "nist": 2.1036018135378924,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.78571,
            "fmeasure": 0.56
        },
        "rouge2": {
            "precision": 0.23529,
            "recall": 0.43636,
            "fmeasure": 0.2987
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.68254,
            "fmeasure": 0.48889
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.68254,
            "fmeasure": 0.48889
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 1.0
        },
        "meteor": 0.2950391483188965,
        "nubia": {
            "semantic_relation": 3.41006,
            "contradiction": 1.1944,
            "irrelevancy": 97.35513,
            "logical_agreement": 1.45047,
            "grammar_ref": 6.44614,
            "grammar_hyp": 4.59618,
            "nubia_score": 0.43407
        },
        "bleurt": -0.61512,
        "bertscore": {
            "precision": 0.85082,
            "recall": 0.89225,
            "f1": 0.85863
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.35559,
        "nist": 0.8767708530793096,
        "rouge1": {
            "precision": 0.84848,
            "recall": 0.48485,
            "fmeasure": 0.61581
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.29464,
            "fmeasure": 0.38627
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.34641,
            "fmeasure": 0.42365
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.34641,
            "fmeasure": 0.42365
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2222222222222222,
            "3": 0.6666666666666666
        },
        "meteor": 0.2588797201779407,
        "nubia": {
            "semantic_relation": 3.21833,
            "contradiction": 35.01195,
            "irrelevancy": 6.5715,
            "logical_agreement": 58.41655,
            "grammar_ref": 5.24053,
            "grammar_hyp": 5.66377,
            "nubia_score": 0.353
        },
        "bleurt": -0.5976,
        "bertscore": {
            "precision": 0.93001,
            "recall": 0.88378,
            "f1": 0.90403
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.70312,
        "nist": 2.60594593987377,
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.56667,
            "fmeasure": 0.65385
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.17857,
            "fmeasure": 0.20833
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.36667,
            "fmeasure": 0.42308
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.36667,
            "fmeasure": 0.42308
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.7777777777777778
        },
        "meteor": 0.3090763533680898,
        "nubia": {
            "semantic_relation": 3.89177,
            "contradiction": 11.47342,
            "irrelevancy": 37.4893,
            "logical_agreement": 51.03729,
            "grammar_ref": 5.62728,
            "grammar_hyp": 5.51366,
            "nubia_score": 0.54569
        },
        "bleurt": -0.65455,
        "bertscore": {
            "precision": 0.89895,
            "recall": 0.89091,
            "f1": 0.89491
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.50281,
        "nist": 2.8646054890616752,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.79259,
            "fmeasure": 0.74127
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "meteor": 0.48351570164972274,
        "nubia": {
            "semantic_relation": 4.6542,
            "contradiction": 0.23542,
            "irrelevancy": 4.26769,
            "logical_agreement": 95.49688,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.03878,
            "nubia_score": 0.87015
        },
        "bleurt": 0.68139,
        "bertscore": {
            "precision": 0.96145,
            "recall": 0.96696,
            "f1": 0.9642
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 2.8483609718589222,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21732,
            "irrelevancy": 0.45505,
            "logical_agreement": 99.32763,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.46881,
            "nubia_score": 0.9943
        },
        "bleurt": 0.96931,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 111,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.21619,
        "nist": 7.897464850329764,
        "rouge1": {
            "precision": 0.78637,
            "recall": 0.76007,
            "fmeasure": 0.76385
        },
        "rouge2": {
            "precision": 0.57463,
            "recall": 0.55708,
            "fmeasure": 0.55936
        },
        "rougeL": {
            "precision": 0.68268,
            "recall": 0.66207,
            "fmeasure": 0.66497
        },
        "rougeLsum": {
            "precision": 0.68268,
            "recall": 0.66207,
            "fmeasure": 0.66497
        },
        "local_recall": {
            "1": 0.19696969696969696,
            "2": 0.4444444444444444,
            "3": 0.7980845969672785
        },
        "meteor": 0.4172656760703917,
        "nubia": {
            "semantic_relation": 4.31975,
            "contradiction": 4.40849,
            "irrelevancy": 23.96609,
            "logical_agreement": 71.62542,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.46844,
            "nubia_score": 0.7827
        },
        "bleurt": 0.37034,
        "bertscore": {
            "precision": 0.93876,
            "recall": 0.93399,
            "f1": 0.9346
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.45818,
        "nist": 2.4599119706769588,
        "rouge1": {
            "precision": 0.95,
            "recall": 0.70602,
            "fmeasure": 0.80713
        },
        "rouge2": {
            "precision": 0.71667,
            "recall": 0.51913,
            "fmeasure": 0.59975
        },
        "rougeL": {
            "precision": 0.95,
            "recall": 0.70602,
            "fmeasure": 0.80713
        },
        "rougeLsum": {
            "precision": 0.95,
            "recall": 0.70602,
            "fmeasure": 0.80713
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6363636363636364
        },
        "meteor": 0.3742183355967774,
        "nubia": {
            "semantic_relation": 4.43313,
            "contradiction": 3.06996,
            "irrelevancy": 3.33086,
            "logical_agreement": 93.59918,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.31774,
            "nubia_score": 0.82835
        },
        "bleurt": 0.36408,
        "bertscore": {
            "precision": 0.94947,
            "recall": 0.92197,
            "f1": 0.93525
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 4.190572262757721,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rouge2": {
            "precision": 0.85,
            "recall": 0.81818,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.98748,
            "contradiction": 0.44405,
            "irrelevancy": 0.50174,
            "logical_agreement": 99.05421,
            "grammar_ref": 4.19853,
            "grammar_hyp": 3.68353,
            "nubia_score": 1.0
        },
        "bleurt": 0.83087,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "total_length": 712,
        "mean_pred_length": 23.733333333333334,
        "std_pred_length": 11.921782118831434,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 53,
        "distinct-1": 0.5280898876404494,
        "vocab_size-1": 376,
        "unique-1": 302,
        "entropy-1": 7.675808785688816,
        "distinct-2": 0.8988269794721407,
        "vocab_size-2": 613,
        "unique-2": 565,
        "entropy-2": 9.181936919539767,
        "cond_entropy-2": 1.3673771808402098,
        "distinct-3": 0.9647239263803681,
        "vocab_size-3": 629,
        "unique-3": 609,
        "entropy-3": 9.274702598239397,
        "cond_entropy-3": 0.103426307970486,
        "total_length-nopunct": 629,
        "mean_pred_length-nopunct": 20.966666666666665,
        "std_pred_length-nopunct": 9.741606073378705,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.5850556438791733,
        "vocab_size-1-nopunct": 368,
        "unique-1-nopunct": 300,
        "entropy-1-nopunct": 7.81467467197515,
        "distinct-2-nopunct": 0.9131886477462438,
        "vocab_size-2-nopunct": 547,
        "unique-2-nopunct": 508,
        "entropy-2-nopunct": 9.031097136929663,
        "cond_entropy-2-nopunct": 1.2799866195860345,
        "distinct-3-nopunct": 0.9753954305799648,
        "vocab_size-3-nopunct": 555,
        "unique-3-nopunct": 541,
        "entropy-3-nopunct": 9.103075703466633,
        "cond_entropy-3-nopunct": 0.08051890340126029,
        "msttr-100": 0.70571,
        "msttr-100_nopunct": 0.74833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 61.9662,
        "nist": 8.424270020892989,
        "rouge1": {
            "precision": 0.79095,
            "recall": 0.76563,
            "fmeasure": 0.76524
        },
        "rouge2": {
            "precision": 0.64326,
            "recall": 0.6029,
            "fmeasure": 0.61025
        },
        "rougeL": {
            "precision": 0.76455,
            "recall": 0.73626,
            "fmeasure": 0.73545
        },
        "rougeLsum": {
            "precision": 0.76455,
            "recall": 0.73626,
            "fmeasure": 0.73545
        },
        "local_recall": {
            "1": 0.05203619909502263,
            "2": 0.16049382716049382,
            "3": 0.4745762711864407,
            "4": 0.4782608695652174,
            "5": 0.6304347826086957,
            "6": 0.7467532467532467,
            "7": 0.8904109589041096
        },
        "meteor": 0.44850463298516063,
        "nubia": {
            "semantic_relation": 4.1195,
            "contradiction": 1.95374,
            "irrelevancy": 17.5674,
            "logical_agreement": 80.47886,
            "grammar_ref": 4.65355,
            "grammar_hyp": 4.94403,
            "nubia_score": 0.63459
        },
        "bleurt": 0.12083,
        "bertscore": {
            "precision": 0.94984,
            "recall": 0.94342,
            "f1": 0.94308
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.83034,
        "nist": 3.5319500393597303,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.89356,
            "fmeasure": 0.86061
        },
        "rouge2": {
            "precision": 0.51111,
            "recall": 0.55609,
            "fmeasure": 0.53149
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.80672,
            "fmeasure": 0.77576
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.80672,
            "fmeasure": 0.77576
        },
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.9285714285714286
        },
        "meteor": 0.46452714268937295,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.27225,
            "irrelevancy": 0.5759,
            "logical_agreement": 99.15185,
            "grammar_ref": 5.90677,
            "grammar_hyp": 5.78552,
            "nubia_score": 0.9572
        },
        "bleurt": 0.58308,
        "bertscore": {
            "precision": 0.95108,
            "recall": 0.98099,
            "f1": 0.9658
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "total_length": 210,
        "mean_pred_length": 23.333333333333332,
        "std_pred_length": 9.786612170602131,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 43,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 140,
        "unique-1": 115,
        "entropy-1": 6.652342806592707,
        "distinct-2": 0.9303482587064676,
        "vocab_size-2": 187,
        "unique-2": 181,
        "entropy-2": 7.462414144109816,
        "cond_entropy-2": 0.6919278894394327,
        "distinct-3": 0.9791666666666666,
        "vocab_size-3": 188,
        "unique-3": 186,
        "entropy-3": 7.535432422573643,
        "cond_entropy-3": 0.08186066348267933,
        "total_length-nopunct": 179,
        "mean_pred_length-nopunct": 19.88888888888889,
        "std_pred_length-nopunct": 7.519521918083837,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.7430167597765364,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.67786794203246,
        "distinct-2-nopunct": 0.9529411764705882,
        "vocab_size-2-nopunct": 162,
        "unique-2-nopunct": 159,
        "entropy-2-nopunct": 7.270264556994123,
        "cond_entropy-2-nopunct": 0.629182088591606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 161,
        "unique-3-nopunct": 161,
        "entropy-3-nopunct": 7.330916878114602,
        "cond_entropy-3-nopunct": 0.06842957212848805,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 62.36868,
        "nist": 7.05037813938521,
        "rouge1": {
            "precision": 0.81322,
            "recall": 0.77595,
            "fmeasure": 0.77623
        },
        "rouge2": {
            "precision": 0.67837,
            "recall": 0.60238,
            "fmeasure": 0.61829
        },
        "rougeL": {
            "precision": 0.74566,
            "recall": 0.69004,
            "fmeasure": 0.7035
        },
        "rougeLsum": {
            "precision": 0.74566,
            "recall": 0.69004,
            "fmeasure": 0.7035
        },
        "local_recall": {
            "1": 0.05925925925925926,
            "2": 0.22727272727272727,
            "3": 0.5,
            "4": 0.85,
            "5": 0.47058823529411764,
            "6": 0.68,
            "7": 0.9365079365079365
        },
        "meteor": 0.4376199349213115,
        "nubia": {
            "semantic_relation": 4.36469,
            "contradiction": 6.45663,
            "irrelevancy": 21.40687,
            "logical_agreement": 72.1365,
            "grammar_ref": 4.59683,
            "grammar_hyp": 5.23051,
            "nubia_score": 0.64592
        },
        "bleurt": 0.08232,
        "bertscore": {
            "precision": 0.9415,
            "recall": 0.93304,
            "f1": 0.93597
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "total_length": 1619,
        "mean_pred_length": 25.6984126984127,
        "std_pred_length": 8.911620593778542,
        "median_pred_length": 25.0,
        "min_pred_length": 6,
        "max_pred_length": 50,
        "distinct-1": 0.45460160592958615,
        "vocab_size-1": 736,
        "unique-1": 570,
        "entropy-1": 8.217591091283653,
        "distinct-2": 0.8926735218508998,
        "vocab_size-2": 1389,
        "unique-2": 1313,
        "entropy-2": 10.276429279449475,
        "cond_entropy-2": 1.9010728341145464,
        "distinct-3": 0.9665103817816477,
        "vocab_size-3": 1443,
        "unique-3": 1429,
        "entropy-3": 10.419094345628025,
        "cond_entropy-3": 0.15233920558070244,
        "total_length-nopunct": 1433,
        "mean_pred_length-nopunct": 22.746031746031747,
        "std_pred_length-nopunct": 7.760232883856683,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5066294487090021,
        "vocab_size-1-nopunct": 726,
        "unique-1-nopunct": 568,
        "entropy-1-nopunct": 8.417501485012753,
        "distinct-2-nopunct": 0.9284671532846716,
        "vocab_size-2-nopunct": 1272,
        "unique-2-nopunct": 1211,
        "entropy-2-nopunct": 10.2432679290037,
        "cond_entropy-2-nopunct": 1.8965887711114122,
        "distinct-3-nopunct": 0.9931140015302219,
        "vocab_size-3-nopunct": 1298,
        "unique-3-nopunct": 1290,
        "entropy-3-nopunct": 10.337693856168613,
        "cond_entropy-3-nopunct": 0.09943484007744009,
        "msttr-100": 0.7225,
        "msttr-100_nopunct": 0.76571,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 61.1708,
        "nist": 9.000632631503418,
        "rouge1": {
            "precision": 0.79704,
            "recall": 0.74977,
            "fmeasure": 0.75938
        },
        "rouge2": {
            "precision": 0.64466,
            "recall": 0.61654,
            "fmeasure": 0.61842
        },
        "rougeL": {
            "precision": 0.76322,
            "recall": 0.72707,
            "fmeasure": 0.73216
        },
        "rougeLsum": {
            "precision": 0.76322,
            "recall": 0.72707,
            "fmeasure": 0.73216
        },
        "local_recall": {
            "1": 0.05303760848601736,
            "2": 0.18633540372670807,
            "3": 0.3617021276595745,
            "4": 0.5074626865671642,
            "5": 0.6352941176470588,
            "6": 0.6952141057934509,
            "7": 0.8320754716981132
        },
        "meteor": 0.42670160454976547,
        "nubia": {
            "semantic_relation": 4.12034,
            "contradiction": 4.49483,
            "irrelevancy": 24.17492,
            "logical_agreement": 71.33025,
            "grammar_ref": 4.43738,
            "grammar_hyp": 4.74646,
            "nubia_score": 0.65135
        },
        "bleurt": 0.07167,
        "bertscore": {
            "precision": 0.93478,
            "recall": 0.93441,
            "f1": 0.93167
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 79.60516,
        "nist": 4.626515469406847,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9130434782608695
        },
        "meteor": 0.5010245744922759,
        "nubia": {
            "semantic_relation": 4.56353,
            "contradiction": 0.53355,
            "irrelevancy": 10.44428,
            "logical_agreement": 89.02217,
            "grammar_ref": 4.1188,
            "grammar_hyp": 4.34374,
            "nubia_score": 0.84935
        },
        "bleurt": 0.5274,
        "bertscore": {
            "precision": 0.99021,
            "recall": 0.94224,
            "f1": 0.96499
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.77284,
        "nist": 2.314359266249736,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.70588,
            "fmeasure": 0.73294
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.65625,
            "fmeasure": 0.67059
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.67647,
            "fmeasure": 0.69591
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.67647,
            "fmeasure": 0.69591
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.8571428571428571
        },
        "meteor": 0.5059278758912188,
        "nubia": {
            "semantic_relation": 4.24139,
            "contradiction": 0.64377,
            "irrelevancy": 1.38066,
            "logical_agreement": 97.97556,
            "grammar_ref": 5.6106,
            "grammar_hyp": 5.21979,
            "nubia_score": 0.72193
        },
        "bleurt": 0.32905,
        "bertscore": {
            "precision": 0.95483,
            "recall": 0.94864,
            "f1": 0.95173
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.6486,
        "nist": 3.0024827201111353,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.71795,
            "fmeasure": 0.60714
        },
        "rouge2": {
            "precision": 0.32143,
            "recall": 0.41667,
            "fmeasure": 0.36014
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.64103,
            "fmeasure": 0.53571
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.64103,
            "fmeasure": 0.53571
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.8333333333333334
        },
        "meteor": 0.3503660802970062,
        "nubia": {
            "semantic_relation": 3.70954,
            "contradiction": 0.8912,
            "irrelevancy": 89.11063,
            "logical_agreement": 9.99817,
            "grammar_ref": 4.60771,
            "grammar_hyp": 4.01814,
            "nubia_score": 0.58932
        },
        "bleurt": 0.35472,
        "bertscore": {
            "precision": 0.86985,
            "recall": 0.93226,
            "f1": 0.89905
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.20063,
        "nist": 2.777027705582418,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.83333,
            "fmeasure": 0.68182
        },
        "rouge2": {
            "precision": 0.37037,
            "recall": 0.59394,
            "fmeasure": 0.44762
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.72222,
            "fmeasure": 0.59848
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.72222,
            "fmeasure": 0.59848
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "meteor": 0.42919650333815856,
        "nubia": {
            "semantic_relation": 4.39354,
            "contradiction": 11.63095,
            "irrelevancy": 66.24717,
            "logical_agreement": 22.12188,
            "grammar_ref": 5.75818,
            "grammar_hyp": 5.38256,
            "nubia_score": 0.71298
        },
        "bleurt": 0.12296,
        "bertscore": {
            "precision": 0.86596,
            "recall": 0.94822,
            "f1": 0.90169
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.76769,
        "nist": 2.7222424602276996,
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.7321,
            "fmeasure": 0.79506
        },
        "rouge2": {
            "precision": 0.67407,
            "recall": 0.56914,
            "fmeasure": 0.61493
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.71236,
            "fmeasure": 0.7712
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.71236,
            "fmeasure": 0.7712
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6296296296296297
        },
        "meteor": 0.4077535145670116,
        "nubia": {
            "semantic_relation": 4.06877,
            "contradiction": 29.64925,
            "irrelevancy": 12.41306,
            "logical_agreement": 57.93769,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.35033,
            "nubia_score": 0.70251
        },
        "bleurt": 0.51177,
        "bertscore": {
            "precision": 0.95765,
            "recall": 0.92071,
            "f1": 0.93824
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.07844,
        "nist": 1.9007938616738882,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.56818,
            "fmeasure": 0.46923
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.2,
            "fmeasure": 0.16667
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.47273,
            "fmeasure": 0.39077
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.47273,
            "fmeasure": 0.39077
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5555555555555556
        },
        "meteor": 0.2603991343222217,
        "nubia": {
            "semantic_relation": 2.86619,
            "contradiction": 32.34067,
            "irrelevancy": 64.6447,
            "logical_agreement": 3.01463,
            "grammar_ref": 4.7527,
            "grammar_hyp": 4.95208,
            "nubia_score": 0.29799
        },
        "bleurt": -0.00594,
        "bertscore": {
            "precision": 0.87202,
            "recall": 0.91585,
            "f1": 0.8934
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.7138,
        "nist": 1.637390128310375,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.66026,
            "fmeasure": 0.68599
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.42063,
            "fmeasure": 0.44246
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.52564,
            "fmeasure": 0.55395
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.52564,
            "fmeasure": 0.55395
        },
        "local_recall": {
            "1": 0.05263157894736842,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 0.38044486355760443,
        "nubia": {
            "semantic_relation": 4.23567,
            "contradiction": 0.3575,
            "irrelevancy": 61.68704,
            "logical_agreement": 37.95546,
            "grammar_ref": 4.62626,
            "grammar_hyp": 4.09683,
            "nubia_score": 0.78234
        },
        "bleurt": -0.07235,
        "bertscore": {
            "precision": 0.94468,
            "recall": 0.92087,
            "f1": 0.92348
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 898,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.78669,
        "nist": 8.613247828419665,
        "rouge1": {
            "precision": 0.725,
            "recall": 0.72102,
            "fmeasure": 0.70738
        },
        "rouge2": {
            "precision": 0.53152,
            "recall": 0.52823,
            "fmeasure": 0.51747
        },
        "rougeL": {
            "precision": 0.68117,
            "recall": 0.67965,
            "fmeasure": 0.66576
        },
        "rougeLsum": {
            "precision": 0.68117,
            "recall": 0.67965,
            "fmeasure": 0.66576
        },
        "local_recall": {
            "1": 0.25458898643256184,
            "2": 0.5483297796730633,
            "3": 0.7516182726095801
        },
        "meteor": 0.40333960780082967,
        "nubia": {
            "semantic_relation": 4.08001,
            "contradiction": 9.80686,
            "irrelevancy": 32.79193,
            "logical_agreement": 57.40122,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.03357,
            "nubia_score": 0.70337
        },
        "bleurt": 0.31227,
        "bertscore": {
            "precision": 0.9279,
            "recall": 0.9266,
            "f1": 0.92555
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.79159,
        "nist": 2.373997727067532,
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.91667,
            "fmeasure": 0.84615
        },
        "rouge2": {
            "precision": 0.69231,
            "recall": 0.81818,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.91667,
            "fmeasure": 0.84615
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.91667,
            "fmeasure": 0.84615
        },
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "meteor": 0.9224832403808237,
        "nubia": {
            "semantic_relation": 4.6798,
            "contradiction": 0.2599,
            "irrelevancy": 33.6056,
            "logical_agreement": 66.13451,
            "grammar_ref": 4.85772,
            "grammar_hyp": 4.73633,
            "nubia_score": 0.82412
        },
        "bleurt": 0.69888,
        "bertscore": {
            "precision": 0.94838,
            "recall": 0.96136,
            "f1": 0.95483
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.43152,
        "nist": 4.102545171504303,
        "rouge1": {
            "precision": 0.81746,
            "recall": 0.75694,
            "fmeasure": 0.78059
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.45298,
            "fmeasure": 0.45206
        },
        "rougeL": {
            "precision": 0.72751,
            "recall": 0.68908,
            "fmeasure": 0.70331
        },
        "rougeLsum": {
            "precision": 0.72751,
            "recall": 0.68908,
            "fmeasure": 0.70331
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.5,
            "3": 1.0
        },
        "meteor": 0.4523305676269658,
        "nubia": {
            "semantic_relation": 4.15886,
            "contradiction": 14.8961,
            "irrelevancy": 19.5571,
            "logical_agreement": 65.54681,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.53052,
            "nubia_score": 0.67754
        },
        "bleurt": 0.20939,
        "bertscore": {
            "precision": 0.93434,
            "recall": 0.92432,
            "f1": 0.92731
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.70064,
        "nist": 1.648725165731062,
        "rouge1": {
            "precision": 0.51515,
            "recall": 0.46759,
            "fmeasure": 0.46667
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.37681,
            "fmeasure": 0.3569
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.46296,
            "fmeasure": 0.44828
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.46296,
            "fmeasure": 0.44828
        },
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.5
        },
        "meteor": 0.31534908772250136,
        "nubia": {
            "semantic_relation": 3.60885,
            "contradiction": 0.0845,
            "irrelevancy": 66.6596,
            "logical_agreement": 33.25589,
            "grammar_ref": 4.62828,
            "grammar_hyp": 4.59152,
            "nubia_score": 0.57655
        },
        "bleurt": -0.58921,
        "bertscore": {
            "precision": 0.86234,
            "recall": 0.81805,
            "f1": 0.81724
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.47872969366552,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.20451,
            "irrelevancy": 0.76191,
            "logical_agreement": 98.03358,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.01604,
            "nubia_score": 0.98068
        },
        "bleurt": 0.9148,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.06455,
        "nist": 2.2816637481137474,
        "rouge1": {
            "precision": 0.38462,
            "recall": 0.625,
            "fmeasure": 0.47619
        },
        "rouge2": {
            "precision": 0.20833,
            "recall": 0.35714,
            "fmeasure": 0.26316
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.625,
            "fmeasure": 0.47619
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.625,
            "fmeasure": 0.47619
        },
        "local_recall": {
            "1": 0.4,
            "2": 1.0
        },
        "meteor": 0.4161803129138124,
        "nubia": {
            "semantic_relation": 3.90685,
            "contradiction": 0.35936,
            "irrelevancy": 60.51959,
            "logical_agreement": 39.12106,
            "grammar_ref": 5.57872,
            "grammar_hyp": 4.71967,
            "nubia_score": 0.61031
        },
        "bleurt": 0.32237,
        "bertscore": {
            "precision": 0.86724,
            "recall": 0.921,
            "f1": 0.89331
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 82.65168,
        "nist": 3.2544789837508556,
        "rouge1": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 0.5690637876265101,
        "nubia": {
            "semantic_relation": 4.37248,
            "contradiction": 0.31688,
            "irrelevancy": 96.54524,
            "logical_agreement": 3.13788,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.47724,
            "nubia_score": 0.89041
        },
        "bleurt": 0.56358,
        "bertscore": {
            "precision": 0.94318,
            "recall": 0.98431,
            "f1": 0.9633
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.83437,
        "nist": 1.9786466670512837,
        "rouge1": {
            "precision": 0.46429,
            "recall": 0.59091,
            "fmeasure": 0.52
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.2,
            "fmeasure": 0.17391
        },
        "rougeL": {
            "precision": 0.39286,
            "recall": 0.5,
            "fmeasure": 0.44
        },
        "rougeLsum": {
            "precision": 0.39286,
            "recall": 0.5,
            "fmeasure": 0.44
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.42857142857142855
        },
        "meteor": 0.2799029712855335,
        "nubia": {
            "semantic_relation": 3.26188,
            "contradiction": 0.08346,
            "irrelevancy": 99.49145,
            "logical_agreement": 0.42509,
            "grammar_ref": 4.25346,
            "grammar_hyp": 4.4423,
            "nubia_score": 0.47293
        },
        "bleurt": -0.3169,
        "bertscore": {
            "precision": 0.85429,
            "recall": 0.87299,
            "f1": 0.86354
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 5.5387,
        "nist": 1.27219197607911,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.7,
            "fmeasure": 0.45161
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.22222,
            "fmeasure": 0.13793
        },
        "rougeL": {
            "precision": 0.2381,
            "recall": 0.5,
            "fmeasure": 0.32258
        },
        "rougeLsum": {
            "precision": 0.2381,
            "recall": 0.5,
            "fmeasure": 0.32258
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "meteor": 0.2855841800709355,
        "nubia": {
            "semantic_relation": 4.06587,
            "contradiction": 0.09218,
            "irrelevancy": 99.75043,
            "logical_agreement": 0.15739,
            "grammar_ref": 5.64952,
            "grammar_hyp": 3.79484,
            "nubia_score": 0.70887
        },
        "bleurt": -0.15682,
        "bertscore": {
            "precision": 0.8244,
            "recall": 0.89542,
            "f1": 0.85844
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.925938214656137,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.67194,
            "irrelevancy": 0.62656,
            "logical_agreement": 98.70151,
            "grammar_ref": 3.94537,
            "grammar_hyp": 3.94537,
            "nubia_score": 1.0
        },
        "bleurt": 0.92236,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.867976246918685,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        },
        "bleurt": 0.73788,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.82569,
        "nist": 2.6480557839832715,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.66138,
            "fmeasure": 0.70888
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.3635,
            "fmeasure": 0.4092
        },
        "rougeL": {
            "precision": 0.71795,
            "recall": 0.46667,
            "fmeasure": 0.56254
        },
        "rougeLsum": {
            "precision": 0.71795,
            "recall": 0.46667,
            "fmeasure": 0.56254
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "meteor": 0.28423318731906977,
        "nubia": {
            "semantic_relation": 3.01738,
            "contradiction": 0.11455,
            "irrelevancy": 99.18123,
            "logical_agreement": 0.70422,
            "grammar_ref": 3.09217,
            "grammar_hyp": 2.86454,
            "nubia_score": 0.54736
        },
        "bleurt": -0.225,
        "bertscore": {
            "precision": 0.90895,
            "recall": 0.86858,
            "f1": 0.8883
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.44147,
        "nist": 0.771320596681796,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.35294,
            "fmeasure": 0.44444
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.25,
            "fmeasure": 0.32
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.35294,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.35294,
            "fmeasure": 0.44444
        },
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "meteor": 0.22923407173743382,
        "nubia": {
            "semantic_relation": 2.57864,
            "contradiction": 86.37915,
            "irrelevancy": 2.79062,
            "logical_agreement": 10.83023,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.04631,
            "nubia_score": 0.25015
        },
        "bleurt": -0.13221,
        "bertscore": {
            "precision": 0.91732,
            "recall": 0.81471,
            "f1": 0.86297
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.64463,
        "nist": 3.3666239780332416,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.94118,
            "fmeasure": 0.86486
        },
        "rouge2": {
            "precision": 0.63158,
            "recall": 0.75,
            "fmeasure": 0.68571
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.70588,
            "fmeasure": 0.64865
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.70588,
            "fmeasure": 0.64865
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 0.5362202679757123,
        "nubia": {
            "semantic_relation": 4.31794,
            "contradiction": 0.03892,
            "irrelevancy": 99.33173,
            "logical_agreement": 0.62934,
            "grammar_ref": 3.64996,
            "grammar_hyp": 3.46731,
            "nubia_score": 0.90281
        },
        "bleurt": 0.49022,
        "bertscore": {
            "precision": 0.93912,
            "recall": 0.96856,
            "f1": 0.95361
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.52439,
        "nist": 3.2251537384960187,
        "rouge1": {
            "precision": 0.79487,
            "recall": 0.6197,
            "fmeasure": 0.69499
        },
        "rouge2": {
            "precision": 0.52083,
            "recall": 0.39363,
            "fmeasure": 0.44743
        },
        "rougeL": {
            "precision": 0.56838,
            "recall": 0.44091,
            "fmeasure": 0.49559
        },
        "rougeLsum": {
            "precision": 0.56838,
            "recall": 0.44091,
            "fmeasure": 0.49559
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.42105263157894735,
            "3": 1.0
        },
        "meteor": 0.32439871127995945,
        "nubia": {
            "semantic_relation": 4.20536,
            "contradiction": 6.24581,
            "irrelevancy": 62.4096,
            "logical_agreement": 31.34459,
            "grammar_ref": 5.11675,
            "grammar_hyp": 6.0727,
            "nubia_score": 0.52159
        },
        "bleurt": 0.26103,
        "bertscore": {
            "precision": 0.92396,
            "recall": 0.89611,
            "f1": 0.90981
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 78.25423,
        "nist": 4.341873690231146,
        "rouge1": {
            "precision": 0.88611,
            "recall": 0.95303,
            "fmeasure": 0.91745
        },
        "rouge2": {
            "precision": 0.76599,
            "recall": 0.83843,
            "fmeasure": 0.79916
        },
        "rougeL": {
            "precision": 0.85833,
            "recall": 0.93636,
            "fmeasure": 0.89439
        },
        "rougeLsum": {
            "precision": 0.85833,
            "recall": 0.93636,
            "fmeasure": 0.89439
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.75,
            "3": 1.0
        },
        "meteor": 0.604522287384506,
        "nubia": {
            "semantic_relation": 4.90416,
            "contradiction": 0.39393,
            "irrelevancy": 1.47349,
            "logical_agreement": 98.13257,
            "grammar_ref": 4.85767,
            "grammar_hyp": 4.88274,
            "nubia_score": 0.89675
        },
        "bleurt": 0.73815,
        "bertscore": {
            "precision": 0.96367,
            "recall": 0.97844,
            "f1": 0.97094
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.59538,
        "nist": 3.581684057515712,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.52632
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 0.4564994804682733,
        "nubia": {
            "semantic_relation": 4.98891,
            "contradiction": 1.56942,
            "irrelevancy": 3.30784,
            "logical_agreement": 95.12274,
            "grammar_ref": 5.6957,
            "grammar_hyp": 4.89203,
            "nubia_score": 0.93825
        },
        "bleurt": 0.14829,
        "bertscore": {
            "precision": 0.96201,
            "recall": 0.96953,
            "f1": 0.96576
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.38149,
        "nist": 2.301614579864853,
        "rouge1": {
            "precision": 0.63768,
            "recall": 0.97778,
            "fmeasure": 0.77193
        },
        "rouge2": {
            "precision": 0.48485,
            "recall": 0.7619,
            "fmeasure": 0.59259
        },
        "rougeL": {
            "precision": 0.47826,
            "recall": 0.85556,
            "fmeasure": 0.61203
        },
        "rougeLsum": {
            "precision": 0.47826,
            "recall": 0.85556,
            "fmeasure": 0.61203
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "meteor": 0.4727486553225701,
        "nubia": {
            "semantic_relation": 3.85239,
            "contradiction": 0.13822,
            "irrelevancy": 95.79575,
            "logical_agreement": 4.06604,
            "grammar_ref": 4.47457,
            "grammar_hyp": 4.45257,
            "nubia_score": 0.50496
        },
        "bleurt": -0.16264,
        "bertscore": {
            "precision": 0.8377,
            "recall": 0.94815,
            "f1": 0.88951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.68666,
        "nist": 1.9624267893289031,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.62714,
            "fmeasure": 0.69431
        },
        "rouge2": {
            "precision": 0.41176,
            "recall": 0.32828,
            "fmeasure": 0.36527
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.53755,
            "fmeasure": 0.59512
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.53755,
            "fmeasure": 0.59512
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.7777777777777778
        },
        "meteor": 0.3430254079588565,
        "nubia": {
            "semantic_relation": 4.76009,
            "contradiction": 0.53187,
            "irrelevancy": 0.55612,
            "logical_agreement": 98.91201,
            "grammar_ref": 3.13705,
            "grammar_hyp": 3.6113,
            "nubia_score": 0.9386
        },
        "bleurt": 0.37781,
        "bertscore": {
            "precision": 0.93826,
            "recall": 0.9206,
            "f1": 0.92934
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.02554,
        "nist": 2.548119821547004,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.55147,
            "fmeasure": 0.52437
        },
        "rouge2": {
            "precision": 0.21569,
            "recall": 0.23333,
            "fmeasure": 0.22412
        },
        "rougeL": {
            "precision": 0.42593,
            "recall": 0.45956,
            "fmeasure": 0.44202
        },
        "rougeLsum": {
            "precision": 0.42593,
            "recall": 0.45956,
            "fmeasure": 0.44202
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "meteor": 0.32158791089998645,
        "nubia": {
            "semantic_relation": 3.92135,
            "contradiction": 0.20053,
            "irrelevancy": 3.41692,
            "logical_agreement": 96.38255,
            "grammar_ref": 5.85115,
            "grammar_hyp": 4.45385,
            "nubia_score": 0.80961
        },
        "bleurt": 0.29457,
        "bertscore": {
            "precision": 0.88434,
            "recall": 0.862,
            "f1": 0.87303
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 62.96955,
        "nist": 5.209542327956269,
        "rouge1": {
            "precision": 0.9697,
            "recall": 0.86399,
            "fmeasure": 0.90848
        },
        "rouge2": {
            "precision": 0.74751,
            "recall": 0.66087,
            "fmeasure": 0.69726
        },
        "rougeL": {
            "precision": 0.74567,
            "recall": 0.67058,
            "fmeasure": 0.70187
        },
        "rougeLsum": {
            "precision": 0.74567,
            "recall": 0.67058,
            "fmeasure": 0.70187
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "meteor": 0.4845157203863295,
        "nubia": {
            "semantic_relation": 4.67104,
            "contradiction": 0.1851,
            "irrelevancy": 11.27801,
            "logical_agreement": 88.53689,
            "grammar_ref": 4.73012,
            "grammar_hyp": 4.84618,
            "nubia_score": 0.87002
        },
        "bleurt": 0.39629,
        "bertscore": {
            "precision": 0.96252,
            "recall": 0.94128,
            "f1": 0.95168
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.28575,
        "nist": 3.7620509457826294,
        "rouge1": {
            "precision": 0.87179,
            "recall": 0.96047,
            "fmeasure": 0.91269
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.90909,
            "fmeasure": 0.84585
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.95833,
            "fmeasure": 0.89833
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.95833,
            "fmeasure": 0.89833
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.9545454545454546
        },
        "meteor": 0.5213397838531207,
        "nubia": {
            "semantic_relation": 4.31398,
            "contradiction": 9.8189,
            "irrelevancy": 68.22413,
            "logical_agreement": 21.95698,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.40171,
            "nubia_score": 0.6652
        },
        "bleurt": -0.10223,
        "bertscore": {
            "precision": 0.899,
            "recall": 0.98232,
            "f1": 0.93726
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 48,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.91902,
        "nist": 7.385173818979528,
        "rouge1": {
            "precision": 0.82926,
            "recall": 0.81615,
            "fmeasure": 0.81782
        },
        "rouge2": {
            "precision": 0.66014,
            "recall": 0.65465,
            "fmeasure": 0.65356
        },
        "rougeL": {
            "precision": 0.7697,
            "recall": 0.76092,
            "fmeasure": 0.7608
        },
        "rougeLsum": {
            "precision": 0.7697,
            "recall": 0.76092,
            "fmeasure": 0.7608
        },
        "local_recall": {
            "1": 0.28378378378378377,
            "2": 0.6,
            "3": 0.8422090729783037
        },
        "meteor": 0.47156631811041944,
        "nubia": {
            "semantic_relation": 4.42641,
            "contradiction": 6.2657,
            "irrelevancy": 19.93116,
            "logical_agreement": 73.80313,
            "grammar_ref": 4.06325,
            "grammar_hyp": 4.02707,
            "nubia_score": 0.84931
        },
        "bleurt": 0.56291,
        "bertscore": {
            "precision": 0.95181,
            "recall": 0.95339,
            "f1": 0.95139
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.82727,
        "nist": 2.8043533630124777,
        "rouge1": {
            "precision": 0.93333,
            "recall": 1.0,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.81905,
            "fmeasure": 0.76863
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.81905,
            "fmeasure": 0.76863
        },
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.875
        },
        "meteor": 0.45626915779345323,
        "nubia": {
            "semantic_relation": 4.8136,
            "contradiction": 0.69691,
            "irrelevancy": 56.12808,
            "logical_agreement": 43.17501,
            "grammar_ref": 6.57473,
            "grammar_hyp": 4.94905,
            "nubia_score": 0.99874
        },
        "bleurt": 0.39135,
        "bertscore": {
            "precision": 0.95635,
            "recall": 0.92424,
            "f1": 0.94002
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 74.37506,
        "nist": 4.3098181812160545,
        "rouge1": {
            "precision": 0.98551,
            "recall": 0.84216,
            "fmeasure": 0.90108
        },
        "rouge2": {
            "precision": 0.89394,
            "recall": 0.77377,
            "fmeasure": 0.82276
        },
        "rougeL": {
            "precision": 0.89855,
            "recall": 0.78072,
            "fmeasure": 0.82914
        },
        "rougeLsum": {
            "precision": 0.89855,
            "recall": 0.78072,
            "fmeasure": 0.82914
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6,
            "3": 0.9142857142857143
        },
        "meteor": 0.49561421410074696,
        "nubia": {
            "semantic_relation": 4.41331,
            "contradiction": 5.39906,
            "irrelevancy": 2.6246,
            "logical_agreement": 91.97634,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.60775,
            "nubia_score": 0.74135
        },
        "bleurt": 0.48179,
        "bertscore": {
            "precision": 0.97313,
            "recall": 0.93297,
            "f1": 0.95216
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.34149,
        "nist": 3.863843347171064,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.76263,
            "fmeasure": 0.79444
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.3875,
            "fmeasure": 0.40972
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.60606,
            "fmeasure": 0.63333
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.60606,
            "fmeasure": 0.63333
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0
        },
        "meteor": 0.4061175367240061,
        "nubia": {
            "semantic_relation": 4.92896,
            "contradiction": 0.14445,
            "irrelevancy": 1.41189,
            "logical_agreement": 98.44366,
            "grammar_ref": 5.60099,
            "grammar_hyp": 5.83598,
            "nubia_score": 0.93034
        },
        "bleurt": 0.52954,
        "bertscore": {
            "precision": 0.92035,
            "recall": 0.92634,
            "f1": 0.91952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.14837,
        "nist": 3.2892956344219164,
        "rouge1": {
            "precision": 0.70641,
            "recall": 0.67446,
            "fmeasure": 0.68977
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.43761,
            "fmeasure": 0.44749
        },
        "rougeL": {
            "precision": 0.70641,
            "recall": 0.67446,
            "fmeasure": 0.68977
        },
        "rougeLsum": {
            "precision": 0.70641,
            "recall": 0.67446,
            "fmeasure": 0.68977
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.0,
            "3": 0.8235294117647058
        },
        "meteor": 0.3278564890786746,
        "nubia": {
            "semantic_relation": 4.12113,
            "contradiction": 25.2396,
            "irrelevancy": 52.41055,
            "logical_agreement": 22.34985,
            "grammar_ref": 3.80999,
            "grammar_hyp": 5.16183,
            "nubia_score": 0.56768
        },
        "bleurt": 0.23485,
        "bertscore": {
            "precision": 0.92409,
            "recall": 0.90918,
            "f1": 0.91606
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 85.22457,
        "nist": 4.373609831586596,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.92857,
            "recall": 0.86667,
            "fmeasure": 0.89655
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9230769230769231
        },
        "meteor": 0.5747920211718521,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.35488,
            "irrelevancy": 10.42506,
            "logical_agreement": 89.22006,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.15345,
            "nubia_score": 0.98846
        },
        "bleurt": 0.78906,
        "bertscore": {
            "precision": 0.99784,
            "recall": 0.98969,
            "f1": 0.99375
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.75909,
        "nist": 2.680879542526635,
        "rouge1": {
            "precision": 0.59744,
            "recall": 0.55807,
            "fmeasure": 0.5382
        },
        "rouge2": {
            "precision": 0.25397,
            "recall": 0.20455,
            "fmeasure": 0.21013
        },
        "rougeL": {
            "precision": 0.34666,
            "recall": 0.35433,
            "fmeasure": 0.32765
        },
        "rougeLsum": {
            "precision": 0.34666,
            "recall": 0.35433,
            "fmeasure": 0.32765
        },
        "local_recall": {
            "1": 0.6363636363636364,
            "2": 0.125,
            "3": 0.5294117647058824
        },
        "meteor": 0.22582193801757,
        "nubia": {
            "semantic_relation": 3.17573,
            "contradiction": 29.29642,
            "irrelevancy": 50.74936,
            "logical_agreement": 19.95422,
            "grammar_ref": 3.44707,
            "grammar_hyp": 3.6874,
            "nubia_score": 0.41596
        },
        "bleurt": -0.13196,
        "bertscore": {
            "precision": 0.87977,
            "recall": 0.85938,
            "f1": 0.86247
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.83129,
        "nist": 3.1390793980795575,
        "rouge1": {
            "precision": 0.74359,
            "recall": 1.0,
            "fmeasure": 0.85244
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.53704,
            "fmeasure": 0.45079
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.8963,
            "fmeasure": 0.76416
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.8963,
            "fmeasure": 0.76416
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "meteor": 0.4530966956609227,
        "nubia": {
            "semantic_relation": 4.29738,
            "contradiction": 0.30301,
            "irrelevancy": 95.63664,
            "logical_agreement": 4.06035,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.37425,
            "nubia_score": 0.60318
        },
        "bleurt": 0.18527,
        "bertscore": {
            "precision": 0.90801,
            "recall": 0.9263,
            "f1": 0.91707
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.8037,
        "nist": 3.0185957289397036,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.79365,
            "fmeasure": 0.76863
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 1.0
        },
        "meteor": 0.902035682675735,
        "nubia": {
            "semantic_relation": 4.91106,
            "contradiction": 0.27234,
            "irrelevancy": 35.38581,
            "logical_agreement": 64.34184,
            "grammar_ref": 4.01433,
            "grammar_hyp": 3.9396,
            "nubia_score": 0.96685
        },
        "bleurt": 0.6833,
        "bertscore": {
            "precision": 0.97989,
            "recall": 0.97368,
            "f1": 0.97222
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 5.43933,
        "nist": 0.8035382351244339,
        "rouge1": {
            "precision": 0.3125,
            "recall": 0.44192,
            "fmeasure": 0.36596
        },
        "rouge2": {
            "precision": 0.13333,
            "recall": 0.19394,
            "fmeasure": 0.15795
        },
        "rougeL": {
            "precision": 0.3125,
            "recall": 0.44192,
            "fmeasure": 0.36596
        },
        "rougeLsum": {
            "precision": 0.3125,
            "recall": 0.44192,
            "fmeasure": 0.36596
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "meteor": 0.22867618075149865,
        "nubia": {
            "semantic_relation": 2.65163,
            "contradiction": 1.47232,
            "irrelevancy": 88.45687,
            "logical_agreement": 10.07082,
            "grammar_ref": 4.79209,
            "grammar_hyp": 3.61885,
            "nubia_score": 0.37615
        },
        "bleurt": -0.57448,
        "bertscore": {
            "precision": 0.71951,
            "recall": 0.75855,
            "f1": 0.73851
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.56627,
        "nist": 3.8270775813000784,
        "rouge1": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.8,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "meteor": 0.44463865444394446,
        "nubia": {
            "semantic_relation": 4.60306,
            "contradiction": 3.38079,
            "irrelevancy": 59.36379,
            "logical_agreement": 37.25543,
            "grammar_ref": 5.78237,
            "grammar_hyp": 5.57301,
            "nubia_score": 0.82616
        },
        "bleurt": 0.11695,
        "bertscore": {
            "precision": 0.9178,
            "recall": 0.96872,
            "f1": 0.94258
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "nist": 3.1699250014423126,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.45873,
            "irrelevancy": 0.46812,
            "logical_agreement": 99.07315,
            "grammar_ref": 5.85687,
            "grammar_hyp": 5.85687,
            "nubia_score": 1.0
        },
        "bleurt": 0.95702,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.43314,
        "nist": 0.6720027070852478,
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.52963,
            "fmeasure": 0.62393
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.28105,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.52422
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.52422
        },
        "local_recall": {
            "1": 0,
            "2": 0.14285714285714285,
            "3": 0.6
        },
        "meteor": 0.29905304748723316,
        "nubia": {
            "semantic_relation": 3.97598,
            "contradiction": 0.24545,
            "irrelevancy": 3.51789,
            "logical_agreement": 96.23665,
            "grammar_ref": 3.74426,
            "grammar_hyp": 4.16414,
            "nubia_score": 0.7061
        },
        "bleurt": 0.29567,
        "bertscore": {
            "precision": 0.95289,
            "recall": 0.89204,
            "f1": 0.92146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.12203,
        "nist": 2.8610927314735184,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.41071,
            "fmeasure": 0.45055
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "meteor": 0.3707878006073302,
        "nubia": {
            "semantic_relation": 4.56442,
            "contradiction": 2.44907,
            "irrelevancy": 2.37459,
            "logical_agreement": 95.17634,
            "grammar_ref": 5.6187,
            "grammar_hyp": 6.50772,
            "nubia_score": 0.67533
        },
        "bleurt": 0.35902,
        "bertscore": {
            "precision": 0.95923,
            "recall": 0.93678,
            "f1": 0.94787
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.09287,
        "nist": 0.5717106617517091,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.38406,
            "fmeasure": 0.51034
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.15439,
            "fmeasure": 0.21019
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 0.34565,
            "fmeasure": 0.4593
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 0.34565,
            "fmeasure": 0.4593
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.47368421052631576
        },
        "meteor": 0.22297087980263663,
        "nubia": {
            "semantic_relation": 3.3625,
            "contradiction": 0.20994,
            "irrelevancy": 1.31793,
            "logical_agreement": 98.47213,
            "grammar_ref": 4.294,
            "grammar_hyp": 4.23691,
            "nubia_score": 0.45883
        },
        "bleurt": -0.19984,
        "bertscore": {
            "precision": 0.89304,
            "recall": 0.80847,
            "f1": 0.84856
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "total_length": 2955,
        "mean_pred_length": 17.801204819277107,
        "std_pred_length": 8.047464525886303,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.4416243654822335,
        "vocab_size-1": 1305,
        "unique-1": 1027,
        "entropy-1": 8.540098445299211,
        "distinct-2": 0.8615991394765149,
        "vocab_size-2": 2403,
        "unique-2": 2262,
        "entropy-2": 10.97772832869718,
        "cond_entropy-2": 2.1737335704604077,
        "distinct-3": 0.9664506290507053,
        "vocab_size-3": 2535,
        "unique-3": 2486,
        "entropy-3": 11.266230375732489,
        "cond_entropy-3": 0.30774929095180187,
        "total_length-nopunct": 2579,
        "mean_pred_length-nopunct": 15.536144578313253,
        "std_pred_length-nopunct": 6.872892067877064,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5025203567274137,
        "vocab_size-1-nopunct": 1296,
        "unique-1-nopunct": 1026,
        "entropy-1-nopunct": 8.87000060150455,
        "distinct-2-nopunct": 0.8781599668462495,
        "vocab_size-2-nopunct": 2119,
        "unique-2-nopunct": 2005,
        "entropy-2-nopunct": 10.823185609741103,
        "cond_entropy-2-nopunct": 2.0928979960297247,
        "distinct-3-nopunct": 0.9795282599020917,
        "vocab_size-3-nopunct": 2201,
        "unique-3-nopunct": 2165,
        "entropy-3-nopunct": 11.088882827965374,
        "cond_entropy-3-nopunct": 0.2892281156500035,
        "msttr-100": 0.7131,
        "msttr-100_nopunct": 0.7636,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 87.36616,
        "nist": 12.139339568706726,
        "rouge1": {
            "precision": 0.90691,
            "recall": 0.91348,
            "fmeasure": 0.90645
        },
        "rouge2": {
            "precision": 0.81631,
            "recall": 0.82651,
            "fmeasure": 0.8167
        },
        "rougeL": {
            "precision": 0.8951,
            "recall": 0.90296,
            "fmeasure": 0.89539
        },
        "rougeLsum": {
            "precision": 0.8951,
            "recall": 0.90296,
            "fmeasure": 0.89539
        },
        "local_recall": {
            "1": 0.032528339083292265,
            "2": 0.14874551971326164,
            "3": 0.3665480427046263,
            "4": 0.5793991416309013,
            "5": 0.728110599078341,
            "6": 0.821969696969697,
            "7": 0.8767605633802817,
            "8": 0.9292604501607717,
            "9": 0.9545454545454546,
            "10": 0.976897689768977
        },
        "meteor": 0.5520529679594758,
        "nubia": {
            "semantic_relation": 4.40372,
            "contradiction": 3.30868,
            "irrelevancy": 29.32611,
            "logical_agreement": 67.36521,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.83632,
            "nubia_score": 0.71045
        },
        "bleurt": 0.3544,
        "bertscore": {
            "precision": 0.97557,
            "recall": 0.97989,
            "f1": 0.97523
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.83565,
        "nist": 4.151511625195395,
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.91296,
            "fmeasure": 0.83651
        },
        "rouge2": {
            "precision": 0.61905,
            "recall": 0.70691,
            "fmeasure": 0.65965
        },
        "rougeL": {
            "precision": 0.75758,
            "recall": 0.86296,
            "fmeasure": 0.80635
        },
        "rougeLsum": {
            "precision": 0.75758,
            "recall": 0.86296,
            "fmeasure": 0.80635
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.9230769230769231
        },
        "meteor": 0.4845684868391792,
        "nubia": {
            "semantic_relation": 4.62027,
            "contradiction": 1.77682,
            "irrelevancy": 95.54526,
            "logical_agreement": 2.67791,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.6308,
            "nubia_score": 0.80452
        },
        "bleurt": 0.51839,
        "bertscore": {
            "precision": 0.96515,
            "recall": 0.97683,
            "f1": 0.97096
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "total_length": 1322,
        "mean_pred_length": 22.79310344827586,
        "std_pred_length": 9.011025087481972,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 49,
        "distinct-1": 0.4848714069591528,
        "vocab_size-1": 641,
        "unique-1": 515,
        "entropy-1": 8.061208103695657,
        "distinct-2": 0.8987341772151899,
        "vocab_size-2": 1136,
        "unique-2": 1084,
        "entropy-2": 9.999238067963459,
        "cond_entropy-2": 1.7626540859215454,
        "distinct-3": 0.9718076285240465,
        "vocab_size-3": 1172,
        "unique-3": 1159,
        "entropy-3": 10.144145213857222,
        "cond_entropy-3": 0.15955347711487794,
        "total_length-nopunct": 1160,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 7.788143065827252,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5448275862068965,
        "vocab_size-1-nopunct": 632,
        "unique-1-nopunct": 513,
        "entropy-1-nopunct": 8.273302418095351,
        "distinct-2-nopunct": 0.9319419237749547,
        "vocab_size-2-nopunct": 1027,
        "unique-2-nopunct": 983,
        "entropy-2-nopunct": 9.934018147407437,
        "cond_entropy-2-nopunct": 1.7487358967080502,
        "distinct-3-nopunct": 0.9913793103448276,
        "vocab_size-3-nopunct": 1035,
        "unique-3-nopunct": 1026,
        "entropy-3-nopunct": 10.01066461725975,
        "cond_entropy-3-nopunct": 0.08428022554907504,
        "msttr-100": 0.71769,
        "msttr-100_nopunct": 0.76636,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 84.77971,
        "nist": 11.040612739216606,
        "rouge1": {
            "precision": 0.8844,
            "recall": 0.90048,
            "fmeasure": 0.88926
        },
        "rouge2": {
            "precision": 0.78227,
            "recall": 0.80716,
            "fmeasure": 0.79098
        },
        "rougeL": {
            "precision": 0.87443,
            "recall": 0.8863,
            "fmeasure": 0.87699
        },
        "rougeLsum": {
            "precision": 0.87443,
            "recall": 0.8863,
            "fmeasure": 0.87699
        },
        "local_recall": {
            "1": 0.030851063829787233,
            "2": 0.1937984496124031,
            "3": 0.36423841059602646,
            "4": 0.5545454545454546,
            "5": 0.7703703703703704,
            "6": 0.8557692307692307,
            "7": 0.8859649122807017,
            "8": 0.8571428571428571,
            "9": 0.9477124183006536,
            "10": 0.9859154929577465
        },
        "meteor": 0.5377596306048043,
        "nubia": {
            "semantic_relation": 4.3213,
            "contradiction": 2.73346,
            "irrelevancy": 34.51441,
            "logical_agreement": 62.75214,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.60231,
            "nubia_score": 0.69019
        },
        "bleurt": 0.28165,
        "bertscore": {
            "precision": 0.9656,
            "recall": 0.97446,
            "f1": 0.9686
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "total_length": 756,
        "mean_pred_length": 23.625,
        "std_pred_length": 8.964339072123499,
        "median_pred_length": 21.5,
        "min_pred_length": 12,
        "max_pred_length": 42,
        "distinct-1": 0.5462962962962963,
        "vocab_size-1": 413,
        "unique-1": 338,
        "entropy-1": 7.69475871065088,
        "distinct-2": 0.9116022099447514,
        "vocab_size-2": 660,
        "unique-2": 625,
        "entropy-2": 9.277193456867685,
        "cond_entropy-2": 1.436470490399244,
        "distinct-3": 0.9783236994219653,
        "vocab_size-3": 677,
        "unique-3": 667,
        "entropy-3": 9.384404401766616,
        "cond_entropy-3": 0.11461683762559412,
        "total_length-nopunct": 660,
        "mean_pred_length-nopunct": 20.625,
        "std_pred_length-nopunct": 7.498958260985321,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.6136363636363636,
        "vocab_size-1-nopunct": 405,
        "unique-1-nopunct": 336,
        "entropy-1-nopunct": 7.882595559870566,
        "distinct-2-nopunct": 0.9299363057324841,
        "vocab_size-2-nopunct": 584,
        "unique-2-nopunct": 561,
        "entropy-2-nopunct": 9.113584786357157,
        "cond_entropy-2-nopunct": 1.288806627662485,
        "distinct-3-nopunct": 0.988255033557047,
        "vocab_size-3-nopunct": 589,
        "unique-3-nopunct": 583,
        "entropy-3-nopunct": 9.194411997807435,
        "cond_entropy-3-nopunct": 0.08886941078118606,
        "msttr-100": 0.71571,
        "msttr-100_nopunct": 0.76833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 87.42833,
        "nist": 10.364515229744173,
        "rouge1": {
            "precision": 0.89045,
            "recall": 0.91733,
            "fmeasure": 0.89999
        },
        "rouge2": {
            "precision": 0.79387,
            "recall": 0.82219,
            "fmeasure": 0.8037
        },
        "rougeL": {
            "precision": 0.87291,
            "recall": 0.89645,
            "fmeasure": 0.88044
        },
        "rougeLsum": {
            "precision": 0.87291,
            "recall": 0.89645,
            "fmeasure": 0.88044
        },
        "local_recall": {
            "1": 0.039014373716632446,
            "2": 0.2523364485981308,
            "3": 0.4084507042253521,
            "4": 0.71875,
            "5": 0.7272727272727273,
            "6": 0.8676470588235294,
            "7": 0.8939393939393939,
            "8": 0.9841269841269841,
            "9": 0.9761904761904762,
            "10": 0.9919354838709677
        },
        "meteor": 0.551863619192401,
        "nubia": {
            "semantic_relation": 4.46531,
            "contradiction": 1.7759,
            "irrelevancy": 37.73437,
            "logical_agreement": 60.48972,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.44002,
            "nubia_score": 0.71212
        },
        "bleurt": 0.31234,
        "bertscore": {
            "precision": 0.96705,
            "recall": 0.98117,
            "f1": 0.97107
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "total_length": 99,
        "mean_pred_length": 19.8,
        "std_pred_length": 8.908422980528034,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.7373737373737373,
        "vocab_size-1": 73,
        "unique-1": 60,
        "entropy-1": 5.919612554357491,
        "distinct-2": 0.9893617021276596,
        "vocab_size-2": 93,
        "unique-2": 92,
        "entropy-2": 6.533312255932943,
        "cond_entropy-2": 0.5139540401393542,
        "distinct-3": 1.0,
        "vocab_size-3": 89,
        "unique-3": 89,
        "entropy-3": 6.47573343096641,
        "cond_entropy-3": -0.056383510598879874,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 17.8,
        "std_pred_length-nopunct": 7.858753081755401,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7752808988764045,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.8829818859982765,
        "distinct-2-nopunct": 0.9880952380952381,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 82,
        "entropy-2-nopunct": 6.368507898969236,
        "cond_entropy-2-nopunct": 0.5208088430285941,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.303780748177105,
        "cond_entropy-3-nopunct": -0.06322021890545503,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 86.18705,
        "nist": 7.6090030025400655,
        "rouge1": {
            "precision": 0.92779,
            "recall": 0.92782,
            "fmeasure": 0.9274
        },
        "rouge2": {
            "precision": 0.8796,
            "recall": 0.87852,
            "fmeasure": 0.87862
        },
        "rougeL": {
            "precision": 0.92612,
            "recall": 0.92948,
            "fmeasure": 0.92724
        },
        "rougeLsum": {
            "precision": 0.92612,
            "recall": 0.92948,
            "fmeasure": 0.92724
        },
        "local_recall": {
            "1": 0.041666666666666664,
            "2": 0.19047619047619047,
            "3": 0.375,
            "4": 0.8,
            "5": 0.7142857142857143,
            "6": 1.0,
            "7": 1.0,
            "8": 1.0,
            "9": 0.875,
            "10": 1.0
        },
        "meteor": 0.6432135797317259,
        "nubia": {
            "semantic_relation": 4.54868,
            "contradiction": 0.25099,
            "irrelevancy": 38.72024,
            "logical_agreement": 61.02877,
            "grammar_ref": 5.04038,
            "grammar_hyp": 5.27,
            "nubia_score": 0.69129
        },
        "bleurt": 0.38779,
        "bertscore": {
            "precision": 0.98111,
            "recall": 0.99354,
            "f1": 0.98431
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.10823,
        "nist": 3.238703514944046,
        "rouge1": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.81818,
            "fmeasure": 0.78261
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "meteor": 0.5145692356432209,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21631,
            "irrelevancy": 9.48924,
            "logical_agreement": 90.29445,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.28863,
            "nubia_score": 1.0
        },
        "bleurt": 0.6871,
        "bertscore": {
            "precision": 0.96002,
            "recall": 0.96374,
            "f1": 0.96188
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 3,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 63.24584,
        "nist": 3.8940121266653542,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.80468,
            "fmeasure": 0.83692
        },
        "rouge2": {
            "precision": 0.75758,
            "recall": 0.71958,
            "fmeasure": 0.73348
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.80064,
            "fmeasure": 0.83365
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.80064,
            "fmeasure": 0.83365
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.7777777777777778
        },
        "meteor": 0.46934419041182657,
        "nubia": {
            "semantic_relation": 4.52162,
            "contradiction": 1.76832,
            "irrelevancy": 2.00981,
            "logical_agreement": 96.22187,
            "grammar_ref": 4.141,
            "grammar_hyp": 3.9393,
            "nubia_score": 0.8527
        },
        "bleurt": 0.71207,
        "bertscore": {
            "precision": 0.9479,
            "recall": 0.94117,
            "f1": 0.94409
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.48667,
        "nist": 3.709426882070707,
        "rouge1": {
            "precision": 0.64951,
            "recall": 0.68056,
            "fmeasure": 0.65589
        },
        "rouge2": {
            "precision": 0.43155,
            "recall": 0.47675,
            "fmeasure": 0.44577
        },
        "rougeL": {
            "precision": 0.59069,
            "recall": 0.6351,
            "fmeasure": 0.60461
        },
        "rougeLsum": {
            "precision": 0.59069,
            "recall": 0.6351,
            "fmeasure": 0.60461
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.25,
            "3": 0.5789473684210527
        },
        "meteor": 0.3563593908293042,
        "nubia": {
            "semantic_relation": 3.91333,
            "contradiction": 5.03053,
            "irrelevancy": 15.44082,
            "logical_agreement": 79.52865,
            "grammar_ref": 6.00658,
            "grammar_hyp": 5.1244,
            "nubia_score": 0.72044
        },
        "bleurt": 0.11624,
        "bertscore": {
            "precision": 0.90852,
            "recall": 0.90179,
            "f1": 0.90421
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.52207,
        "nist": 1.7289611191330565,
        "rouge1": {
            "precision": 0.475,
            "recall": 0.82955,
            "fmeasure": 0.60383
        },
        "rouge2": {
            "precision": 0.26316,
            "recall": 0.47727,
            "fmeasure": 0.33908
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.78409,
            "fmeasure": 0.57157
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.78409,
            "fmeasure": 0.57157
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.875
        },
        "meteor": 0.3776021738162498,
        "nubia": {
            "semantic_relation": 4.33948,
            "contradiction": 0.1935,
            "irrelevancy": 98.79473,
            "logical_agreement": 1.01178,
            "grammar_ref": 5.10481,
            "grammar_hyp": 4.20465,
            "nubia_score": 0.76306
        },
        "bleurt": 0.09496,
        "bertscore": {
            "precision": 0.85925,
            "recall": 0.92531,
            "f1": 0.89105
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "total_length": 723,
        "mean_pred_length": 25.821428571428573,
        "std_pred_length": 9.475734315414638,
        "median_pred_length": 23.5,
        "min_pred_length": 10,
        "max_pred_length": 51,
        "distinct-1": 0.5477178423236515,
        "vocab_size-1": 396,
        "unique-1": 324,
        "entropy-1": 7.748296172278456,
        "distinct-2": 0.9122302158273381,
        "vocab_size-2": 634,
        "unique-2": 595,
        "entropy-2": 9.232151685559144,
        "cond_entropy-2": 1.354747688705171,
        "distinct-3": 0.974512743628186,
        "vocab_size-3": 650,
        "unique-3": 638,
        "entropy-3": 9.324909611588168,
        "cond_entropy-3": 0.08989316140427073,
        "total_length-nopunct": 635,
        "mean_pred_length-nopunct": 22.678571428571427,
        "std_pred_length-nopunct": 7.478796558216012,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6125984251968504,
        "vocab_size-1-nopunct": 389,
        "unique-1-nopunct": 324,
        "entropy-1-nopunct": 7.88731491821761,
        "distinct-2-nopunct": 0.9456342668863262,
        "vocab_size-2-nopunct": 574,
        "unique-2-nopunct": 552,
        "entropy-2-nopunct": 9.114128591740332,
        "cond_entropy-2-nopunct": 1.268780799256556,
        "distinct-3-nopunct": 0.9948186528497409,
        "vocab_size-3-nopunct": 576,
        "unique-3-nopunct": 573,
        "entropy-3-nopunct": 9.16705684368871,
        "cond_entropy-3-nopunct": 0.055829590819595064,
        "msttr-100": 0.72286,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 85.82597,
        "nist": 10.190769086822822,
        "rouge1": {
            "precision": 0.91556,
            "recall": 0.91231,
            "fmeasure": 0.91142
        },
        "rouge2": {
            "precision": 0.83559,
            "recall": 0.84137,
            "fmeasure": 0.83407
        },
        "rougeL": {
            "precision": 0.90183,
            "recall": 0.91049,
            "fmeasure": 0.90218
        },
        "rougeLsum": {
            "precision": 0.90183,
            "recall": 0.91049,
            "fmeasure": 0.90218
        },
        "local_recall": {
            "1": 0.036608863198458574,
            "2": 0.16447368421052633,
            "3": 0.40789473684210525,
            "4": 0.6290322580645161,
            "5": 0.6935483870967742,
            "6": 0.9206349206349206,
            "7": 0.9382716049382716,
            "8": 1.0,
            "9": 0.9636363636363636,
            "10": 0.9883720930232558
        },
        "meteor": 0.5650643842437303,
        "nubia": {
            "semantic_relation": 4.37835,
            "contradiction": 2.56452,
            "irrelevancy": 30.36056,
            "logical_agreement": 67.07492,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.73545,
            "nubia_score": 0.6848
        },
        "bleurt": 0.26261,
        "bertscore": {
            "precision": 0.97852,
            "recall": 0.98215,
            "f1": 0.97835
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "total_length": 141,
        "mean_pred_length": 20.142857142857142,
        "std_pred_length": 5.986379097073418,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.7446808510638298,
        "vocab_size-1": 105,
        "unique-1": 93,
        "entropy-1": 6.369562522396734,
        "distinct-2": 0.9626865671641791,
        "vocab_size-2": 129,
        "unique-2": 126,
        "entropy-2": 6.976536951651809,
        "cond_entropy-2": 0.5314531367601838,
        "distinct-3": 1.0,
        "vocab_size-3": 127,
        "unique-3": 127,
        "entropy-3": 6.988684686772147,
        "cond_entropy-3": 0.001335653794708481,
        "total_length-nopunct": 125,
        "mean_pred_length-nopunct": 17.857142857142858,
        "std_pred_length-nopunct": 6.104531605491856,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 100,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.335432384506325,
        "distinct-2-nopunct": 0.9661016949152542,
        "vocab_size-2-nopunct": 114,
        "unique-2-nopunct": 112,
        "entropy-2-nopunct": 6.7978972866499685,
        "cond_entropy-2-nopunct": 0.4998586589325608,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 111,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.794415866350121,
        "cond_entropy-3-nopunct": 0.0018629070783547862,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 82.50422,
        "nist": 8.47406324550916,
        "rouge1": {
            "precision": 0.9142,
            "recall": 0.7827,
            "fmeasure": 0.81614
        },
        "rouge2": {
            "precision": 0.83209,
            "recall": 0.69386,
            "fmeasure": 0.72564
        },
        "rougeL": {
            "precision": 0.8982,
            "recall": 0.7784,
            "fmeasure": 0.80652
        },
        "rougeLsum": {
            "precision": 0.8982,
            "recall": 0.7784,
            "fmeasure": 0.80652
        },
        "local_recall": {
            "1": 0.01764705882352941,
            "2": 0.18181818181818182,
            "3": 0.5333333333333333,
            "4": 0.8333333333333334,
            "5": 0.75,
            "6": 0.5833333333333334,
            "7": 0.4,
            "8": 0.64,
            "9": 0.95,
            "10": 0.875
        },
        "meteor": 0.4941687551696723,
        "nubia": {
            "semantic_relation": 3.97632,
            "contradiction": 2.34453,
            "irrelevancy": 44.41284,
            "logical_agreement": 53.24263,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.83514,
            "nubia_score": 0.60545
        },
        "bleurt": 0.13131,
        "bertscore": {
            "precision": 0.978,
            "recall": 0.95186,
            "f1": 0.9598
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.10803,
        "nist": 2.9539212913716804,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.69048,
            "fmeasure": 0.61553
        },
        "rouge2": {
            "precision": 0.32353,
            "recall": 0.40934,
            "fmeasure": 0.36129
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.55238,
            "fmeasure": 0.49242
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.55238,
            "fmeasure": 0.49242
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.8181818181818182
        },
        "meteor": 0.4162256267504613,
        "nubia": {
            "semantic_relation": 4.46266,
            "contradiction": 0.20564,
            "irrelevancy": 54.15666,
            "logical_agreement": 45.6377,
            "grammar_ref": 5.03823,
            "grammar_hyp": 4.50255,
            "nubia_score": 0.85245
        },
        "bleurt": 0.16069,
        "bertscore": {
            "precision": 0.88674,
            "recall": 0.89838,
            "f1": 0.89252
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.01149,
        "nist": 4.512343274410415,
        "rouge1": {
            "precision": 0.9359,
            "recall": 0.90123,
            "fmeasure": 0.91824
        },
        "rouge2": {
            "precision": 0.84,
            "recall": 0.80769,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9359,
            "recall": 0.90123,
            "fmeasure": 0.91824
        },
        "rougeLsum": {
            "precision": 0.9359,
            "recall": 0.90123,
            "fmeasure": 0.91824
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.9523809523809523
        },
        "meteor": 0.5148951150872072,
        "nubia": {
            "semantic_relation": 4.23883,
            "contradiction": 0.09714,
            "irrelevancy": 3.32441,
            "logical_agreement": 96.57846,
            "grammar_ref": 4.19464,
            "grammar_hyp": 3.71909,
            "nubia_score": 0.80764
        },
        "bleurt": 0.30717,
        "bertscore": {
            "precision": 0.9413,
            "recall": 0.95132,
            "f1": 0.94628
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.11336,
        "nist": 2.1795698619043824,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.57937,
            "fmeasure": 0.53472
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.45833,
            "fmeasure": 0.41071
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.57937,
            "fmeasure": 0.53472
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.57937,
            "fmeasure": 0.53472
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666
        },
        "meteor": 0.4144683820350649,
        "nubia": {
            "semantic_relation": 3.54171,
            "contradiction": 0.14209,
            "irrelevancy": 77.4757,
            "logical_agreement": 22.38221,
            "grammar_ref": 4.8549,
            "grammar_hyp": 5.74514,
            "nubia_score": 0.46846
        },
        "bleurt": 0.31537,
        "bertscore": {
            "precision": 0.90942,
            "recall": 0.94271,
            "f1": 0.92577
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.60337,
        "nist": 3.196979798573185,
        "rouge1": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85568
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.85833,
            "fmeasure": 0.72741
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85568
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85568
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.9
        },
        "meteor": 0.5206924026304247,
        "nubia": {
            "semantic_relation": 4.17998,
            "contradiction": 0.61916,
            "irrelevancy": 93.24068,
            "logical_agreement": 6.14017,
            "grammar_ref": 4.75081,
            "grammar_hyp": 3.84954,
            "nubia_score": 0.77863
        },
        "bleurt": 0.40102,
        "bertscore": {
            "precision": 0.9344,
            "recall": 0.97921,
            "f1": 0.95628
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.11298,
        "nist": 1.7414895787249667,
        "rouge1": {
            "precision": 0.28571,
            "recall": 0.28356,
            "fmeasure": 0.28355
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.2619,
            "recall": 0.26395,
            "fmeasure": 0.26205
        },
        "rougeLsum": {
            "precision": 0.2619,
            "recall": 0.26395,
            "fmeasure": 0.26205
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "meteor": 0.1262438552331713,
        "nubia": {
            "semantic_relation": 1.90761,
            "contradiction": 6.01198,
            "irrelevancy": 64.89264,
            "logical_agreement": 29.09537,
            "grammar_ref": 4.12033,
            "grammar_hyp": 4.47646,
            "nubia_score": 0.1788
        },
        "bleurt": -0.04961,
        "bertscore": {
            "precision": 0.83065,
            "recall": 0.8101,
            "f1": 0.82025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 123,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.88177,
        "nist": 7.615680372993845,
        "rouge1": {
            "precision": 0.77281,
            "recall": 0.7585,
            "fmeasure": 0.75514
        },
        "rouge2": {
            "precision": 0.54485,
            "recall": 0.54162,
            "fmeasure": 0.53604
        },
        "rougeL": {
            "precision": 0.66791,
            "recall": 0.65864,
            "fmeasure": 0.65416
        },
        "rougeLsum": {
            "precision": 0.66791,
            "recall": 0.65864,
            "fmeasure": 0.65416
        },
        "local_recall": {
            "1": 0.2862190812720848,
            "2": 0.39464882943143814,
            "3": 0.7829099307159353
        },
        "meteor": 0.4073276433789189,
        "nubia": {
            "semantic_relation": 4.28741,
            "contradiction": 6.24679,
            "irrelevancy": 29.27203,
            "logical_agreement": 64.48118,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.69843,
            "nubia_score": 0.77378
        },
        "bleurt": 0.34361,
        "bertscore": {
            "precision": 0.92838,
            "recall": 0.92897,
            "f1": 0.92718
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 29,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 70.7828,
        "nist": 7.458731223138175,
        "rouge1": {
            "precision": 0.87617,
            "recall": 0.85858,
            "fmeasure": 0.86159
        },
        "rouge2": {
            "precision": 0.73484,
            "recall": 0.72177,
            "fmeasure": 0.72334
        },
        "rougeL": {
            "precision": 0.82533,
            "recall": 0.80836,
            "fmeasure": 0.81146
        },
        "rougeLsum": {
            "precision": 0.82533,
            "recall": 0.80836,
            "fmeasure": 0.81146
        },
        "local_recall": {
            "1": 0.225,
            "2": 0.5789473684210527,
            "3": 0.8816568047337278
        },
        "meteor": 0.48427338205156006,
        "nubia": {
            "semantic_relation": 4.40559,
            "contradiction": 5.16248,
            "irrelevancy": 17.64467,
            "logical_agreement": 77.19285,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.2223,
            "nubia_score": 0.83376
        },
        "bleurt": 0.59039,
        "bertscore": {
            "precision": 0.9636,
            "recall": 0.9567,
            "f1": 0.959
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1850,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.84915,
        "nist": 9.52487846234122,
        "rouge1": {
            "precision": 0.74696,
            "recall": 0.73726,
            "fmeasure": 0.72907
        },
        "rouge2": {
            "precision": 0.54175,
            "recall": 0.53802,
            "fmeasure": 0.53046
        },
        "rougeL": {
            "precision": 0.67254,
            "recall": 0.6679,
            "fmeasure": 0.65827
        },
        "rougeLsum": {
            "precision": 0.67254,
            "recall": 0.6679,
            "fmeasure": 0.65827
        },
        "local_recall": {
            "1": 0.24182156133828997,
            "2": 0.4940817105765559,
            "3": 0.78237445959428
        },
        "meteor": 0.40708143496409477,
        "nubia": {
            "semantic_relation": 4.18598,
            "contradiction": 6.72666,
            "irrelevancy": 33.33318,
            "logical_agreement": 59.94016,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.67144,
            "nubia_score": 0.73809
        },
        "bleurt": 0.31372,
        "bertscore": {
            "precision": 0.92768,
            "recall": 0.92667,
            "f1": 0.92545
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 112,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.17196,
        "nist": 7.664480155456171,
        "rouge1": {
            "precision": 0.76576,
            "recall": 0.74706,
            "fmeasure": 0.74554
        },
        "rouge2": {
            "precision": 0.5354,
            "recall": 0.51413,
            "fmeasure": 0.51725
        },
        "rougeL": {
            "precision": 0.6507,
            "recall": 0.64033,
            "fmeasure": 0.63614
        },
        "rougeLsum": {
            "precision": 0.6507,
            "recall": 0.64033,
            "fmeasure": 0.63614
        },
        "local_recall": {
            "1": 0.24629080118694363,
            "2": 0.4775641025641026,
            "3": 0.7961504811898513
        },
        "meteor": 0.3974863873050883,
        "nubia": {
            "semantic_relation": 4.21902,
            "contradiction": 4.14713,
            "irrelevancy": 25.44864,
            "logical_agreement": 70.40423,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.61197,
            "nubia_score": 0.76214
        },
        "bleurt": 0.30542,
        "bertscore": {
            "precision": 0.92858,
            "recall": 0.92807,
            "f1": 0.9271
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 91,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.03544,
        "nist": 7.421368543997385,
        "rouge1": {
            "precision": 0.75735,
            "recall": 0.7402,
            "fmeasure": 0.73842
        },
        "rouge2": {
            "precision": 0.54538,
            "recall": 0.53007,
            "fmeasure": 0.53126
        },
        "rougeL": {
            "precision": 0.65704,
            "recall": 0.64504,
            "fmeasure": 0.6429
        },
        "rougeLsum": {
            "precision": 0.65704,
            "recall": 0.64504,
            "fmeasure": 0.6429
        },
        "local_recall": {
            "1": 0.23873873873873874,
            "2": 0.43609022556390975,
            "3": 0.7752100840336135
        },
        "meteor": 0.40567357527988873,
        "nubia": {
            "semantic_relation": 4.13894,
            "contradiction": 7.38248,
            "irrelevancy": 29.89163,
            "logical_agreement": 62.72589,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.3425,
            "nubia_score": 0.73641
        },
        "bleurt": 0.27273,
        "bertscore": {
            "precision": 0.92738,
            "recall": 0.92358,
            "f1": 0.9243
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 2221,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.56057,
        "nist": 10.247026970436677,
        "rouge1": {
            "precision": 0.76953,
            "recall": 0.76242,
            "fmeasure": 0.7552
        },
        "rouge2": {
            "precision": 0.5383,
            "recall": 0.53313,
            "fmeasure": 0.52801
        },
        "rougeL": {
            "precision": 0.66157,
            "recall": 0.65826,
            "fmeasure": 0.65052
        },
        "rougeLsum": {
            "precision": 0.66157,
            "recall": 0.65826,
            "fmeasure": 0.65052
        },
        "local_recall": {
            "1": 0.22533632286995517,
            "2": 0.45879888268156427,
            "3": 0.8011424973011875
        },
        "meteor": 0.4101945734578029,
        "nubia": {
            "semantic_relation": 4.33573,
            "contradiction": 5.68402,
            "irrelevancy": 28.52033,
            "logical_agreement": 65.79565,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.74848,
            "nubia_score": 0.76383
        },
        "bleurt": 0.32151,
        "bertscore": {
            "precision": 0.93275,
            "recall": 0.93286,
            "f1": 0.93119
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 1369,
        "total_length": 130065,
        "mean_pred_length": 16.89155844155844,
        "std_pred_length": 6.864386270451366,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1687925268135163,
        "vocab_size-1": 21954,
        "unique-1": 15099,
        "entropy-1": 10.02577391646325,
        "distinct-2": 0.5449434070199812,
        "vocab_size-2": 66682,
        "unique-2": 55711,
        "entropy-2": 14.650842770291872,
        "cond_entropy-2": 4.249356003586507,
        "distinct-3": 0.7853922295382201,
        "vocab_size-3": 90057,
        "unique-3": 82114,
        "entropy-3": 15.99537268124052,
        "cond_entropy-3": 1.323096065497454,
        "total_length-nopunct": 112808,
        "mean_pred_length-nopunct": 14.65038961038961,
        "std_pred_length-nopunct": 5.909939336836451,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19444542940217005,
        "vocab_size-1-nopunct": 21935,
        "unique-1-nopunct": 15099,
        "entropy-1-nopunct": 10.60554986601293,
        "distinct-2-nopunct": 0.5920481790158694,
        "vocab_size-2-nopunct": 62229,
        "unique-2-nopunct": 53232,
        "entropy-2-nopunct": 14.664409896629463,
        "cond_entropy-2-nopunct": 4.232609227082032,
        "distinct-3-nopunct": 0.813844858738502,
        "vocab_size-3-nopunct": 79275,
        "unique-3-nopunct": 73192,
        "entropy-3-nopunct": 15.875666481593955,
        "cond_entropy-3-nopunct": 1.2841272269728776,
        "msttr-100": 0.71874,
        "msttr-100_nopunct": 0.77445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.29649,
        "nist": 9.931574024845435,
        "rouge1": {
            "precision": 0.76014,
            "recall": 0.75484,
            "fmeasure": 0.74722
        },
        "rouge2": {
            "precision": 0.52446,
            "recall": 0.52135,
            "fmeasure": 0.51552
        },
        "rougeL": {
            "precision": 0.63755,
            "recall": 0.63482,
            "fmeasure": 0.62723
        },
        "rougeLsum": {
            "precision": 0.63755,
            "recall": 0.63482,
            "fmeasure": 0.62723
        },
        "local_recall": {
            "1": 0.23294117647058823,
            "2": 0.4568775958954312,
            "3": 0.7967759463865242
        },
        "meteor": 0.4069869336135783,
        "nubia": {
            "semantic_relation": 4.25049,
            "contradiction": 7.41529,
            "irrelevancy": 30.41675,
            "logical_agreement": 62.16796,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.40566,
            "nubia_score": 0.74981
        },
        "bleurt": 0.28223,
        "bertscore": {
            "precision": 0.92913,
            "recall": 0.92886,
            "f1": 0.92741
        }
    },
    "totto_test": {
        "predictions_file": "mT5_xl/totto_test",
        "N": 7700,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.1577,
        "nist": 10.830125376872955,
        "rouge1": {
            "precision": 0.7503,
            "recall": 0.74241,
            "fmeasure": 0.73475
        },
        "rouge2": {
            "precision": 0.52447,
            "recall": 0.52047,
            "fmeasure": 0.51409
        },
        "rougeL": {
            "precision": 0.64906,
            "recall": 0.64557,
            "fmeasure": 0.63699
        },
        "rougeLsum": {
            "precision": 0.64906,
            "recall": 0.64557,
            "fmeasure": 0.63699
        },
        "local_recall": {
            "1": 0.23539665166808546,
            "2": 0.4727509778357236,
            "3": 0.7834250119307764
        },
        "meteor": 0.39939632628729227,
        "nubia": {
            "semantic_relation": 4.20095,
            "contradiction": 7.58801,
            "irrelevancy": 31.38651,
            "logical_agreement": 61.02548,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.60121,
            "nubia_score": 0.73568
        },
        "bleurt": 0.28478,
        "bertscore": {
            "precision": 0.9278,
            "recall": 0.92695,
            "f1": 0.92569
        }
    },
    "totto_challenge_test_scramble": {
        "predictions_file": "mT5_xl/totto_challenge_test_scramble",
        "N": 378
    },
    "wiki_auto_asset_turk_val": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_val",
        "N": 20000,
        "total_length": 415026,
        "mean_pred_length": 20.7513,
        "std_pred_length": 8.856875764624904,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 60,
        "distinct-1": 0.021781767889240675,
        "vocab_size-1": 9040,
        "unique-1": 12,
        "entropy-1": 9.787696053814443,
        "distinct-2": 0.07088394181648802,
        "vocab_size-2": 28001,
        "unique-2": 89,
        "entropy-2": 14.015253624563986,
        "cond_entropy-2": 3.9484765116984324,
        "distinct-3": 0.0925029197975607,
        "vocab_size-3": 34691,
        "unique-3": 163,
        "entropy-3": 14.888868520733938,
        "cond_entropy-3": 0.8933651927684547,
        "total_length-nopunct": 363166,
        "mean_pred_length-nopunct": 18.1583,
        "std_pred_length-nopunct": 7.690308258451023,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.024839880385278356,
        "vocab_size-1-nopunct": 9021,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 10.2455519859046,
        "distinct-2-nopunct": 0.07465191773077752,
        "vocab_size-2-nopunct": 25618,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 14.034034583019187,
        "cond_entropy-2-nopunct": 3.9585578489084434,
        "distinct-3-nopunct": 0.09492025770037689,
        "vocab_size-3-nopunct": 30675,
        "unique-3-nopunct": 134,
        "entropy-3-nopunct": 14.818541255296626,
        "cond_entropy-3-nopunct": 0.8275657650719107,
        "msttr-100": 0.26766,
        "msttr-100_nopunct": 0.25128,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_val.json",
        "bleu": 47.24856,
        "nist": 9.830163264127709,
        "rouge1": {
            "precision": 0.73563,
            "recall": 0.77737,
            "fmeasure": 0.74213
        },
        "rouge2": {
            "precision": 0.55676,
            "recall": 0.58618,
            "fmeasure": 0.56
        },
        "rougeL": {
            "precision": 0.69136,
            "recall": 0.72991,
            "fmeasure": 0.69732
        },
        "rougeLsum": {
            "precision": 0.69136,
            "recall": 0.72991,
            "fmeasure": 0.69732
        },
        "local_recall": {
            "1": 0.7649450610559922
        },
        "sari": 49.62554,
        "meteor": 0.4203734151263561,
        "nubia": {
            "semantic_relation": 4.46103,
            "contradiction": 2.17981,
            "irrelevancy": 27.26042,
            "logical_agreement": 70.55977,
            "grammar_ref": 4.53224,
            "grammar_hyp": 4.69192,
            "nubia_score": 0.73588
        },
        "bleurt": 0.35548,
        "bertscore": {
            "precision": 0.92344,
            "recall": 0.93587,
            "f1": 0.92894
        }
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7760,
        "mean_pred_length": 21.615598885793872,
        "std_pred_length": 9.403512744681423,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.35966494845360825,
        "vocab_size-1": 2791,
        "unique-1": 2028,
        "entropy-1": 9.188144884333632,
        "distinct-2": 0.8255641129577084,
        "vocab_size-2": 6110,
        "unique-2": 5637,
        "entropy-2": 12.224661288830381,
        "cond_entropy-2": 2.8001553479838672,
        "distinct-3": 0.9606645839250213,
        "vocab_size-3": 6765,
        "unique-3": 6634,
        "entropy-3": 12.64580267724211,
        "cond_entropy-3": 0.43695440762963217,
        "total_length-nopunct": 6820,
        "mean_pred_length-nopunct": 18.997214484679667,
        "std_pred_length-nopunct": 8.108765712326052,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.40747800586510263,
        "vocab_size-1-nopunct": 2779,
        "unique-1-nopunct": 2026,
        "entropy-1-nopunct": 9.554039108722176,
        "distinct-2-nopunct": 0.8562142083268843,
        "vocab_size-2-nopunct": 5532,
        "unique-2-nopunct": 5153,
        "entropy-2-nopunct": 12.171902248092573,
        "cond_entropy-2-nopunct": 2.7476322655498087,
        "distinct-3-nopunct": 0.9804981973123567,
        "vocab_size-3-nopunct": 5983,
        "unique-3-nopunct": 5890,
        "entropy-3-nopunct": 12.53167607520254,
        "cond_entropy-3-nopunct": 0.3825261721861503,
        "msttr-100": 0.72299,
        "msttr-100_nopunct": 0.76941,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 86.34939,
        "nist": 13.329512713282538,
        "rouge1": {
            "precision": 0.89874,
            "recall": 0.90638,
            "fmeasure": 0.89862
        },
        "rouge2": {
            "precision": 0.80532,
            "recall": 0.81573,
            "fmeasure": 0.80561
        },
        "rougeL": {
            "precision": 0.88654,
            "recall": 0.89608,
            "fmeasure": 0.88722
        },
        "rougeLsum": {
            "precision": 0.88654,
            "recall": 0.89608,
            "fmeasure": 0.88722
        },
        "local_recall": {
            "1": 0.03381109886071297,
            "2": 0.17452830188679244,
            "3": 0.40602409638554215,
            "4": 0.617737003058104,
            "5": 0.7465857359635811,
            "6": 0.8464788732394366,
            "7": 0.8838797814207651,
            "8": 0.9227985524728589,
            "9": 0.9513227513227513,
            "10": 0.9798449612403101
        },
        "sari": 48.74796,
        "meteor": 0.551356493160983,
        "nubia": {
            "semantic_relation": 4.36984,
            "contradiction": 2.52055,
            "irrelevancy": 33.99611,
            "logical_agreement": 63.48333,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.69195,
            "nubia_score": 0.69208
        },
        "bleurt": 0.30287,
        "bertscore": {
            "precision": 0.9719,
            "recall": 0.97818,
            "f1": 0.97285
        }
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7167,
        "mean_pred_length": 19.963788300835656,
        "std_pred_length": 9.29589858462179,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.3573322171061811,
        "vocab_size-1": 2561,
        "unique-1": 1869,
        "entropy-1": 9.113280774616257,
        "distinct-2": 0.832256169212691,
        "vocab_size-2": 5666,
        "unique-2": 5238,
        "entropy-2": 12.139825987465183,
        "cond_entropy-2": 2.7671722316842198,
        "distinct-3": 0.9615444254923244,
        "vocab_size-3": 6201,
        "unique-3": 6079,
        "entropy-3": 12.526257117156364,
        "cond_entropy-3": 0.4056865141794836,
        "total_length-nopunct": 6341,
        "mean_pred_length-nopunct": 17.662952646239553,
        "std_pred_length-nopunct": 8.092814184272115,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.40198706828575936,
        "vocab_size-1-nopunct": 2549,
        "unique-1-nopunct": 1868,
        "entropy-1-nopunct": 9.453751403450571,
        "distinct-2-nopunct": 0.8567368772985624,
        "vocab_size-2-nopunct": 5125,
        "unique-2-nopunct": 4772,
        "entropy-2-nopunct": 12.061882539880092,
        "cond_entropy-2-nopunct": 2.7488311245862627,
        "distinct-3-nopunct": 0.9779477147430198,
        "vocab_size-3-nopunct": 5499,
        "unique-3-nopunct": 5403,
        "entropy-3-nopunct": 12.407352949029834,
        "cond_entropy-3-nopunct": 0.3694223002622433,
        "msttr-100": 0.7269,
        "msttr-100_nopunct": 0.76762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 67.21602,
        "nist": 11.095537431856437,
        "rouge1": {
            "precision": 0.84507,
            "recall": 0.78787,
            "fmeasure": 0.80316
        },
        "rouge2": {
            "precision": 0.7046,
            "recall": 0.65558,
            "fmeasure": 0.66725
        },
        "rougeL": {
            "precision": 0.81486,
            "recall": 0.76168,
            "fmeasure": 0.77518
        },
        "rougeLsum": {
            "precision": 0.81486,
            "recall": 0.76168,
            "fmeasure": 0.77518
        },
        "local_recall": {
            "1": 0.04647707979626486,
            "2": 0.16219667943805874,
            "3": 0.4026258205689278,
            "4": 0.5404120443740095,
            "5": 0.6355140186915887,
            "6": 0.7518115942028986,
            "7": 0.8694158075601375
        },
        "sari": 48.17693,
        "meteor": 0.45786204822397686,
        "nubia": {
            "semantic_relation": 4.28957,
            "contradiction": 4.23798,
            "irrelevancy": 17.2489,
            "logical_agreement": 78.51313,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.90086,
            "nubia_score": 0.69691
        },
        "bleurt": 0.21354,
        "bertscore": {
            "precision": 0.95341,
            "recall": 0.94332,
            "f1": 0.94609
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "total_length": 6999,
        "mean_pred_length": 19.4958217270195,
        "std_pred_length": 10.384762746700865,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 77,
        "distinct-1": 0.34676382340334333,
        "vocab_size-1": 2427,
        "unique-1": 1754,
        "entropy-1": 9.002796118802296,
        "distinct-2": 0.8096385542168675,
        "vocab_size-2": 5376,
        "unique-2": 4889,
        "entropy-2": 12.028895312024684,
        "cond_entropy-2": 2.7630310932527435,
        "distinct-3": 0.9496895398821844,
        "vocab_size-3": 5965,
        "unique-3": 5811,
        "entropy-3": 12.439262754931162,
        "cond_entropy-3": 0.4285442505346882,
        "total_length-nopunct": 6174,
        "mean_pred_length-nopunct": 17.197771587743734,
        "std_pred_length-nopunct": 9.05614770143286,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 67,
        "distinct-1-nopunct": 0.39131843213475864,
        "vocab_size-1-nopunct": 2416,
        "unique-1-nopunct": 1752,
        "entropy-1-nopunct": 9.336567586239694,
        "distinct-2-nopunct": 0.8374892519346517,
        "vocab_size-2-nopunct": 4870,
        "unique-2-nopunct": 4449,
        "entropy-2-nopunct": 11.991937987590427,
        "cond_entropy-2-nopunct": 2.790491696328803,
        "distinct-3-nopunct": 0.9732404692082112,
        "vocab_size-3-nopunct": 5310,
        "unique-3-nopunct": 5190,
        "entropy-3-nopunct": 12.355905613590764,
        "cond_entropy-3-nopunct": 0.3887246678877843,
        "msttr-100": 0.71101,
        "msttr-100_nopunct": 0.75148,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "bleu": 29.36297,
        "nist": 6.971198722549733,
        "rouge1": {
            "precision": 0.57286,
            "recall": 0.57254,
            "fmeasure": 0.5521
        },
        "rouge2": {
            "precision": 0.33503,
            "recall": 0.34809,
            "fmeasure": 0.32637
        },
        "rougeL": {
            "precision": 0.50968,
            "recall": 0.52022,
            "fmeasure": 0.49509
        },
        "rougeLsum": {
            "precision": 0.50968,
            "recall": 0.52022,
            "fmeasure": 0.49509
        },
        "local_recall": {
            "1": 0.06144927536231884,
            "2": 0.13667582417582416,
            "3": 0.20984759671746775,
            "4": 0.2507082152974504,
            "5": 0.34130146082337315,
            "6": 0.3583743842364532,
            "7": 0.4817351598173516,
            "8": 0.558531746031746,
            "9": 0.6834532374100719
        },
        "sari": 41.58303,
        "meteor": 0.2879307325362799,
        "nubia": {
            "semantic_relation": 3.10651,
            "contradiction": 14.19534,
            "irrelevancy": 50.1858,
            "logical_agreement": 35.61886,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.14558,
            "nubia_score": 0.35983
        },
        "bleurt": -0.32984,
        "bertscore": {
            "precision": 0.87298,
            "recall": 0.88214,
            "f1": 0.87253
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "total_length": 6805,
        "mean_pred_length": 18.955431754874652,
        "std_pred_length": 9.642536754624485,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 60,
        "distinct-1": 0.36576047024246877,
        "vocab_size-1": 2489,
        "unique-1": 1854,
        "entropy-1": 9.094894605972616,
        "distinct-2": 0.8191126279863481,
        "vocab_size-2": 5280,
        "unique-2": 4820,
        "entropy-2": 12.018075979859395,
        "cond_entropy-2": 2.653276453723624,
        "distinct-3": 0.9513717759158863,
        "vocab_size-3": 5791,
        "unique-3": 5657,
        "entropy-3": 12.393014915114158,
        "cond_entropy-3": 0.3917219874479662,
        "total_length-nopunct": 5968,
        "mean_pred_length-nopunct": 16.623955431754876,
        "std_pred_length-nopunct": 8.23915409011,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4148793565683646,
        "vocab_size-1-nopunct": 2476,
        "unique-1-nopunct": 1852,
        "entropy-1-nopunct": 9.447399718671882,
        "distinct-2-nopunct": 0.8511321091103583,
        "vocab_size-2-nopunct": 4774,
        "unique-2-nopunct": 4389,
        "entropy-2-nopunct": 11.987026399597196,
        "cond_entropy-2-nopunct": 2.6795752977909366,
        "distinct-3-nopunct": 0.9767619047619047,
        "vocab_size-3-nopunct": 5128,
        "unique-3-nopunct": 5031,
        "entropy-3-nopunct": 12.306063543730142,
        "cond_entropy-3-nopunct": 0.34268041075835703,
        "msttr-100": 0.71588,
        "msttr-100_nopunct": 0.76424,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "bleu": 36.08801,
        "nist": 7.862998859261209,
        "rouge1": {
            "precision": 0.61912,
            "recall": 0.61327,
            "fmeasure": 0.59667
        },
        "rouge2": {
            "precision": 0.40088,
            "recall": 0.4023,
            "fmeasure": 0.38424
        },
        "rougeL": {
            "precision": 0.56516,
            "recall": 0.56954,
            "fmeasure": 0.54744
        },
        "rougeLsum": {
            "precision": 0.56516,
            "recall": 0.56954,
            "fmeasure": 0.54744
        },
        "local_recall": {
            "1": 0.0566183574879227,
            "2": 0.1401098901098901,
            "3": 0.19343493552168817,
            "4": 0.2847025495750708,
            "5": 0.3466135458167331,
            "6": 0.4211822660098522,
            "7": 0.5331050228310502,
            "8": 0.6349206349206349,
            "9": 0.7309352517985611
        },
        "sari": 43.14846,
        "meteor": 0.30815080800084743,
        "nubia": {
            "semantic_relation": 3.3539,
            "contradiction": 11.40804,
            "irrelevancy": 45.5561,
            "logical_agreement": 43.03586,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.47071,
            "nubia_score": 0.3821
        },
        "bleurt": -0.39554,
        "bertscore": {
            "precision": 0.87899,
            "recall": 0.89572,
            "f1": 0.88192
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "total_length": 6714,
        "mean_pred_length": 18.701949860724234,
        "std_pred_length": 9.500199182063437,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 63,
        "distinct-1": 0.38322907357759906,
        "vocab_size-1": 2573,
        "unique-1": 1982,
        "entropy-1": 9.167282897574006,
        "distinct-2": 0.8303697875688434,
        "vocab_size-2": 5277,
        "unique-2": 4833,
        "entropy-2": 12.050904956909786,
        "cond_entropy-2": 2.6005769871831603,
        "distinct-3": 0.9566377585056705,
        "vocab_size-3": 5736,
        "unique-3": 5614,
        "entropy-3": 12.390199750216489,
        "cond_entropy-3": 0.358390215519547,
        "total_length-nopunct": 5898,
        "mean_pred_length-nopunct": 16.428969359331475,
        "std_pred_length-nopunct": 8.15516971547482,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.4337063411325873,
        "vocab_size-1-nopunct": 2558,
        "unique-1-nopunct": 1980,
        "entropy-1-nopunct": 9.515447975611842,
        "distinct-2-nopunct": 0.8597219714749955,
        "vocab_size-2-nopunct": 4762,
        "unique-2-nopunct": 4388,
        "entropy-2-nopunct": 12.005589272123027,
        "cond_entropy-2-nopunct": 2.6318374152400428,
        "distinct-3-nopunct": 0.9808880308880309,
        "vocab_size-3-nopunct": 5081,
        "unique-3-nopunct": 4995,
        "entropy-3-nopunct": 12.2976564622022,
        "cond_entropy-3-nopunct": 0.31472756948591224,
        "msttr-100": 0.73463,
        "msttr-100_nopunct": 0.7731,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "bleu": 30.62867,
        "nist": 7.156716659718057,
        "rouge1": {
            "precision": 0.58174,
            "recall": 0.56973,
            "fmeasure": 0.55474
        },
        "rouge2": {
            "precision": 0.3588,
            "recall": 0.34772,
            "fmeasure": 0.33604
        },
        "rougeL": {
            "precision": 0.53545,
            "recall": 0.52912,
            "fmeasure": 0.5123
        },
        "rougeLsum": {
            "precision": 0.53545,
            "recall": 0.52912,
            "fmeasure": 0.5123
        },
        "local_recall": {
            "1": 0.05391304347826087,
            "2": 0.11950549450549451,
            "3": 0.21805392731535755,
            "4": 0.3073654390934844,
            "5": 0.3691899070385126,
            "6": 0.3768472906403941,
            "7": 0.4965753424657534,
            "8": 0.5357142857142857,
            "9": 0.6446043165467625
        },
        "sari": 43.05002,
        "meteor": 0.276437611938853,
        "nubia": {
            "semantic_relation": 3.14413,
            "contradiction": 13.06709,
            "irrelevancy": 41.3789,
            "logical_agreement": 45.55401,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.8222,
            "nubia_score": 0.32454
        },
        "bleurt": -0.62862,
        "bertscore": {
            "precision": 0.85663,
            "recall": 0.87669,
            "f1": 0.86208
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "total_length": 7298,
        "mean_pred_length": 20.328690807799443,
        "std_pred_length": 10.341416109216112,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 73,
        "distinct-1": 0.33173472184160047,
        "vocab_size-1": 2421,
        "unique-1": 1707,
        "entropy-1": 8.979804019296825,
        "distinct-2": 0.7916126242974492,
        "vocab_size-2": 5493,
        "unique-2": 4942,
        "entropy-2": 12.002478230491072,
        "cond_entropy-2": 2.788770767740055,
        "distinct-3": 0.9351063829787234,
        "vocab_size-3": 6153,
        "unique-3": 5945,
        "entropy-3": 12.440804098723452,
        "cond_entropy-3": 0.46390102274168005,
        "total_length-nopunct": 6379,
        "mean_pred_length-nopunct": 17.768802228412255,
        "std_pred_length-nopunct": 8.697294201100503,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 60,
        "distinct-1-nopunct": 0.3774886345822229,
        "vocab_size-1-nopunct": 2408,
        "unique-1-nopunct": 1706,
        "entropy-1-nopunct": 9.327815546264032,
        "distinct-2-nopunct": 0.8280730897009967,
        "vocab_size-2-nopunct": 4985,
        "unique-2-nopunct": 4508,
        "entropy-2-nopunct": 12.01640557927701,
        "cond_entropy-2-nopunct": 2.8265947448159894,
        "distinct-3-nopunct": 0.96537714184773,
        "vocab_size-3-nopunct": 5465,
        "unique-3-nopunct": 5301,
        "entropy-3-nopunct": 12.39221786827281,
        "cond_entropy-3-nopunct": 0.4006701487328117,
        "msttr-100": 0.69986,
        "msttr-100_nopunct": 0.73444,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "bleu": 42.8863,
        "nist": 8.515839614185694,
        "rouge1": {
            "precision": 0.65774,
            "recall": 0.67021,
            "fmeasure": 0.64257
        },
        "rouge2": {
            "precision": 0.45871,
            "recall": 0.47639,
            "fmeasure": 0.44721
        },
        "rougeL": {
            "precision": 0.60036,
            "recall": 0.6288,
            "fmeasure": 0.59262
        },
        "rougeLsum": {
            "precision": 0.60036,
            "recall": 0.6288,
            "fmeasure": 0.59262
        },
        "local_recall": {
            "1": 0.057971014492753624,
            "2": 0.1504120879120879,
            "3": 0.2321219226260258,
            "4": 0.3286118980169972,
            "5": 0.40239043824701193,
            "6": 0.479064039408867,
            "7": 0.5753424657534246,
            "8": 0.6785714285714286,
            "9": 0.8258992805755395
        },
        "sari": 42.80872,
        "meteor": 0.35020721188311954,
        "nubia": {
            "semantic_relation": 3.52749,
            "contradiction": 8.90348,
            "irrelevancy": 46.25697,
            "logical_agreement": 44.83956,
            "grammar_ref": 4.57404,
            "grammar_hyp": 4.90327,
            "nubia_score": 0.44664
        },
        "bleurt": -0.15311,
        "bertscore": {
            "precision": 0.89963,
            "recall": 0.91282,
            "f1": 0.90079
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "total_length": 7623,
        "mean_pred_length": 21.233983286908078,
        "std_pred_length": 10.008122801826211,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 67,
        "distinct-1": 0.3410730683457956,
        "vocab_size-1": 2600,
        "unique-1": 1849,
        "entropy-1": 9.08729903573289,
        "distinct-2": 0.8215859030837004,
        "vocab_size-2": 5968,
        "unique-2": 5466,
        "entropy-2": 12.188359898032646,
        "cond_entropy-2": 2.865045139602026,
        "distinct-3": 0.9603186097031137,
        "vocab_size-3": 6631,
        "unique-3": 6487,
        "entropy-3": 12.621837829302335,
        "cond_entropy-3": 0.44862663774625283,
        "total_length-nopunct": 6755,
        "mean_pred_length-nopunct": 18.81615598885794,
        "std_pred_length-nopunct": 8.938955198596748,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.38282753515914136,
        "vocab_size-1-nopunct": 2586,
        "unique-1-nopunct": 1844,
        "entropy-1-nopunct": 9.407991793423948,
        "distinct-2-nopunct": 0.8478736710444027,
        "vocab_size-2-nopunct": 5423,
        "unique-2-nopunct": 5002,
        "entropy-2-nopunct": 12.128332346039075,
        "cond_entropy-2-nopunct": 2.8454817664414316,
        "distinct-3-nopunct": 0.9778035448070234,
        "vocab_size-3-nopunct": 5903,
        "unique-3-nopunct": 5793,
        "entropy-3-nopunct": 12.510937703514738,
        "cond_entropy-3-nopunct": 0.4059447030102001,
        "msttr-100": 0.71592,
        "msttr-100_nopunct": 0.75418,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "bleu": 29.34904,
        "nist": 6.73609977575961,
        "rouge1": {
            "precision": 0.57787,
            "recall": 0.56004,
            "fmeasure": 0.54737
        },
        "rouge2": {
            "precision": 0.34032,
            "recall": 0.34336,
            "fmeasure": 0.32652
        },
        "rougeL": {
            "precision": 0.51594,
            "recall": 0.50928,
            "fmeasure": 0.49209
        },
        "rougeLsum": {
            "precision": 0.51594,
            "recall": 0.50928,
            "fmeasure": 0.49209
        },
        "local_recall": {
            "1": 0.06812393887945671,
            "2": 0.17369093231162197,
            "3": 0.2778993435448578,
            "4": 0.27099841521394613,
            "5": 0.3572170301142264,
            "6": 0.4891304347826087,
            "7": 0.6365024818633066
        },
        "sari": 40.95514,
        "meteor": 0.28423717548152405,
        "nubia": {
            "semantic_relation": 3.2113,
            "contradiction": 15.32649,
            "irrelevancy": 43.42832,
            "logical_agreement": 41.2452,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.05034,
            "nubia_score": 0.40849
        },
        "bleurt": -0.30383,
        "bertscore": {
            "precision": 0.8717,
            "recall": 0.87497,
            "f1": 0.86982
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "total_length": 7479,
        "mean_pred_length": 20.832869080779943,
        "std_pred_length": 10.588001321836748,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 66,
        "distinct-1": 0.3675625083567322,
        "vocab_size-1": 2749,
        "unique-1": 2047,
        "entropy-1": 9.24316511052058,
        "distinct-2": 0.8432584269662922,
        "vocab_size-2": 6004,
        "unique-2": 5558,
        "entropy-2": 12.262575818799831,
        "cond_entropy-2": 2.7775715225465993,
        "distinct-3": 0.9674604348469161,
        "vocab_size-3": 6541,
        "unique-3": 6417,
        "entropy-3": 12.620128538065888,
        "cond_entropy-3": 0.37109893932553006,
        "total_length-nopunct": 6636,
        "mean_pred_length-nopunct": 18.484679665738163,
        "std_pred_length-nopunct": 9.274169017750829,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.41229656419529837,
        "vocab_size-1-nopunct": 2736,
        "unique-1-nopunct": 2045,
        "entropy-1-nopunct": 9.575348460978647,
        "distinct-2-nopunct": 0.8669746694280708,
        "vocab_size-2-nopunct": 5442,
        "unique-2-nopunct": 5069,
        "entropy-2-nopunct": 12.183948952874292,
        "cond_entropy-2-nopunct": 2.737091538728449,
        "distinct-3-nopunct": 0.9815816154106117,
        "vocab_size-3-nopunct": 5809,
        "unique-3-nopunct": 5716,
        "entropy-3-nopunct": 12.491602104714964,
        "cond_entropy-3-nopunct": 0.3271547401851598,
        "msttr-100": 0.73689,
        "msttr-100_nopunct": 0.77621,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "bleu": 40.08471,
        "nist": 8.11256145710881,
        "rouge1": {
            "precision": 0.65295,
            "recall": 0.6305,
            "fmeasure": 0.62536
        },
        "rouge2": {
            "precision": 0.44265,
            "recall": 0.42862,
            "fmeasure": 0.42214
        },
        "rougeL": {
            "precision": 0.61135,
            "recall": 0.59009,
            "fmeasure": 0.58464
        },
        "rougeLsum": {
            "precision": 0.61135,
            "recall": 0.59009,
            "fmeasure": 0.58464
        },
        "local_recall": {
            "1": 0.05730050933786078,
            "2": 0.16475095785440613,
            "3": 0.2778993435448578,
            "4": 0.35340729001584786,
            "5": 0.470404984423676,
            "6": 0.5917874396135265,
            "7": 0.713631156930126
        },
        "sari": 42.55027,
        "meteor": 0.325590585217336,
        "nubia": {
            "semantic_relation": 3.61435,
            "contradiction": 11.83137,
            "irrelevancy": 37.62582,
            "logical_agreement": 50.54281,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.46162,
            "nubia_score": 0.4527
        },
        "bleurt": -0.35321,
        "bertscore": {
            "precision": 0.88544,
            "recall": 0.89514,
            "f1": 0.88707
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "total_length": 7430,
        "mean_pred_length": 20.696378830083564,
        "std_pred_length": 10.05858954605121,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.38640646029609693,
        "vocab_size-1": 2871,
        "unique-1": 2224,
        "entropy-1": 9.329601995086577,
        "distinct-2": 0.8411822938763965,
        "vocab_size-2": 5948,
        "unique-2": 5506,
        "entropy-2": 12.236894759066212,
        "cond_entropy-2": 2.6576411855826647,
        "distinct-3": 0.9597735399284862,
        "vocab_size-3": 6442,
        "unique-3": 6303,
        "entropy-3": 12.572663900636288,
        "cond_entropy-3": 0.347262394223578,
        "total_length-nopunct": 6562,
        "mean_pred_length-nopunct": 18.278551532033426,
        "std_pred_length-nopunct": 8.837459025336594,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.43538555318500455,
        "vocab_size-1-nopunct": 2857,
        "unique-1-nopunct": 2223,
        "entropy-1-nopunct": 9.688122175155083,
        "distinct-2-nopunct": 0.8702240851201032,
        "vocab_size-2-nopunct": 5398,
        "unique-2-nopunct": 5031,
        "entropy-2-nopunct": 12.191687160713537,
        "cond_entropy-2-nopunct": 2.627948037955652,
        "distinct-3-nopunct": 0.9787816563997263,
        "vocab_size-3-nopunct": 5720,
        "unique-3-nopunct": 5615,
        "entropy-3-nopunct": 12.467087829756421,
        "cond_entropy-3-nopunct": 0.2946685084274773,
        "msttr-100": 0.74122,
        "msttr-100_nopunct": 0.77985,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "bleu": 33.02696,
        "nist": 7.256032462362299,
        "rouge1": {
            "precision": 0.60927,
            "recall": 0.58402,
            "fmeasure": 0.57916
        },
        "rouge2": {
            "precision": 0.38562,
            "recall": 0.37101,
            "fmeasure": 0.36481
        },
        "rougeL": {
            "precision": 0.57278,
            "recall": 0.548,
            "fmeasure": 0.54317
        },
        "rougeLsum": {
            "precision": 0.57278,
            "recall": 0.548,
            "fmeasure": 0.54317
        },
        "local_recall": {
            "1": 0.055178268251273345,
            "2": 0.1392081736909323,
            "3": 0.26914660831509846,
            "4": 0.329635499207607,
            "5": 0.4091381100726895,
            "6": 0.5368357487922706,
            "7": 0.6571210385643376
        },
        "sari": 44.37596,
        "meteor": 0.2892277873207566,
        "nubia": {
            "semantic_relation": 3.42508,
            "contradiction": 14.09988,
            "irrelevancy": 35.83257,
            "logical_agreement": 50.06756,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.83174,
            "nubia_score": 0.39485
        },
        "bleurt": -0.60183,
        "bertscore": {
            "precision": 0.86218,
            "recall": 0.8802,
            "f1": 0.86807
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "mT5_xl/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "total_length": 7585,
        "mean_pred_length": 21.128133704735376,
        "std_pred_length": 11.205612631876074,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 95,
        "distinct-1": 0.32827949901120634,
        "vocab_size-1": 2490,
        "unique-1": 1727,
        "entropy-1": 9.03881048900429,
        "distinct-2": 0.7953224467201772,
        "vocab_size-2": 5747,
        "unique-2": 5192,
        "entropy-2": 12.075350567878568,
        "cond_entropy-2": 2.8096865978055825,
        "distinct-3": 0.9411679044706568,
        "vocab_size-3": 6463,
        "unique-3": 6273,
        "entropy-3": 12.527706221067344,
        "cond_entropy-3": 0.4717417724509786,
        "total_length-nopunct": 6710,
        "mean_pred_length-nopunct": 18.690807799442897,
        "std_pred_length-nopunct": 9.932457087965927,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 89,
        "distinct-1-nopunct": 0.3690014903129657,
        "vocab_size-1-nopunct": 2476,
        "unique-1-nopunct": 1725,
        "entropy-1-nopunct": 9.356000860697193,
        "distinct-2-nopunct": 0.8291607620847111,
        "vocab_size-2-nopunct": 5266,
        "unique-2-nopunct": 4789,
        "entropy-2-nopunct": 12.079053155458647,
        "cond_entropy-2-nopunct": 2.849647320791866,
        "distinct-3-nopunct": 0.9701268357810414,
        "vocab_size-3-nopunct": 5813,
        "unique-3-nopunct": 5673,
        "entropy-3-nopunct": 12.482100144718418,
        "cond_entropy-3-nopunct": 0.42672029569566633,
        "msttr-100": 0.71293,
        "msttr-100_nopunct": 0.74746,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "bleu": 44.29719,
        "nist": 8.381528874596373,
        "rouge1": {
            "precision": 0.68318,
            "recall": 0.65679,
            "fmeasure": 0.64496
        },
        "rouge2": {
            "precision": 0.48629,
            "recall": 0.47485,
            "fmeasure": 0.45989
        },
        "rougeL": {
            "precision": 0.62517,
            "recall": 0.61186,
            "fmeasure": 0.59462
        },
        "rougeLsum": {
            "precision": 0.62517,
            "recall": 0.61186,
            "fmeasure": 0.59462
        },
        "local_recall": {
            "1": 0.056451612903225805,
            "2": 0.16347381864623245,
            "3": 0.3150984682713348,
            "4": 0.38510301109350237,
            "5": 0.4953271028037383,
            "6": 0.5935990338164251,
            "7": 0.7392134402443681
        },
        "sari": 40.37558,
        "meteor": 0.34551737784611797,
        "nubia": {
            "semantic_relation": 3.70132,
            "contradiction": 10.76541,
            "irrelevancy": 37.36517,
            "logical_agreement": 51.86942,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.94466,
            "nubia_score": 0.50285
        },
        "bleurt": -0.09556,
        "bertscore": {
            "precision": 0.90518,
            "recall": 0.90519,
            "f1": 0.90173
        }
    }
}

{
    "submission_name": "mT5_base",
    "param_count": "-",
    "schema_guided_dialog_val": {
        "predictions_file": "mT5_base/schema_guided_dialog_val",
        "N": 10000,
        "total_length": 120665,
        "mean_pred_length": 12.0665,
        "std_pred_length": 7.074537281688464,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 61,
        "distinct-1": 0.033680023204740395,
        "vocab_size-1": 4064,
        "unique-1": 1722,
        "entropy-1": 8.055433157376076,
        "distinct-2": 0.12812542357565626,
        "vocab_size-2": 14179,
        "unique-2": 7344,
        "entropy-2": 11.296262644556553,
        "cond_entropy-2": 2.965931225868047,
        "distinct-3": 0.25148760741071874,
        "vocab_size-3": 25316,
        "unique-3": 15656,
        "entropy-3": 12.710744851726972,
        "cond_entropy-3": 1.4350685053459071,
        "total_length-nopunct": 106116,
        "mean_pred_length-nopunct": 10.6116,
        "std_pred_length-nopunct": 6.498780304026287,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.038146933544423084,
        "vocab_size-1-nopunct": 4048,
        "unique-1-nopunct": 1719,
        "entropy-1-nopunct": 8.283127004227985,
        "distinct-2-nopunct": 0.13958133921511506,
        "vocab_size-2-nopunct": 13416,
        "unique-2-nopunct": 7222,
        "entropy-2-nopunct": 11.180273032293508,
        "cond_entropy-2-nopunct": 3.0437422630770206,
        "distinct-3-nopunct": 0.27190181484620835,
        "vocab_size-3-nopunct": 23417,
        "unique-3-nopunct": 15034,
        "entropy-3-nopunct": 12.60412595306927,
        "cond_entropy-3-nopunct": 1.4590552275343551,
        "msttr-100": 0.69426,
        "msttr-100_nopunct": 0.72294,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_val.json",
        "local_recall": {
            "1": 0.6101737480467296
        },
        "rouge1": {
            "precision": 0.62876,
            "recall": 0.60626,
            "fmeasure": 0.6038
        },
        "rouge2": {
            "precision": 0.40998,
            "recall": 0.39644,
            "fmeasure": 0.39338
        },
        "rougeL": {
            "precision": 0.5709,
            "recall": 0.55061,
            "fmeasure": 0.54834
        },
        "rougeLsum": {
            "precision": 0.5709,
            "recall": 0.55061,
            "fmeasure": 0.54834
        },
        "nist": 7.539726804509134,
        "bleu": 35.79967,
        "nubia": {
            "semantic_relation": 3.86186,
            "contradiction": 4.27689,
            "irrelevancy": 17.8818,
            "logical_agreement": 77.84131,
            "grammar_ref": 4.88727,
            "grammar_hyp": 4.62526,
            "nubia_score": 0.71373
        },
        "bertscore": {
            "precision": 0.88531,
            "recall": 0.878,
            "f1": 0.88107
        },
        "meteor": 0.34345028092617397,
        "bleurt": 0.03409
    },
    "schema_guided_dialog_test": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 10000,
        "total_length": 127171,
        "mean_pred_length": 12.7171,
        "std_pred_length": 7.56424930776346,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 98,
        "distinct-1": 0.0327826312602716,
        "vocab_size-1": 4169,
        "unique-1": 1794,
        "entropy-1": 7.983113571423708,
        "distinct-2": 0.12974200100707514,
        "vocab_size-2": 15202,
        "unique-2": 8047,
        "entropy-2": 11.318979771760802,
        "cond_entropy-2": 3.0730467756779927,
        "distinct-3": 0.25760459821595194,
        "vocab_size-3": 27608,
        "unique-3": 17288,
        "entropy-3": 12.811981008218682,
        "cond_entropy-3": 1.5217799563041603,
        "total_length-nopunct": 111898,
        "mean_pred_length-nopunct": 11.1898,
        "std_pred_length-nopunct": 6.934246603633303,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 97,
        "distinct-1-nopunct": 0.03711415753632773,
        "vocab_size-1-nopunct": 4153,
        "unique-1-nopunct": 1792,
        "entropy-1-nopunct": 8.197275483401251,
        "distinct-2-nopunct": 0.14192623996545564,
        "vocab_size-2-nopunct": 14462,
        "unique-2-nopunct": 7988,
        "entropy-2-nopunct": 11.211034480235801,
        "cond_entropy-2-nopunct": 3.1650777219557416,
        "distinct-3-nopunct": 0.27887011305398085,
        "vocab_size-3-nopunct": 25629,
        "unique-3-nopunct": 16592,
        "entropy-3-nopunct": 12.711818069985428,
        "cond_entropy-3-nopunct": 1.5588740643304473,
        "msttr-100": 0.67764,
        "msttr-100_nopunct": 0.70447,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5613052867311845
        },
        "rouge1": {
            "precision": 0.58113,
            "recall": 0.55108,
            "fmeasure": 0.55372
        },
        "rouge2": {
            "precision": 0.35948,
            "recall": 0.34046,
            "fmeasure": 0.34174
        },
        "rougeL": {
            "precision": 0.52364,
            "recall": 0.49573,
            "fmeasure": 0.49861
        },
        "rougeLsum": {
            "precision": 0.52364,
            "recall": 0.49573,
            "fmeasure": 0.49861
        },
        "nist": 6.82239127328894,
        "bleu": 31.35552,
        "nubia": {
            "semantic_relation": 3.61494,
            "contradiction": 7.42742,
            "irrelevancy": 21.797,
            "logical_agreement": 70.77558,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.52454,
            "nubia_score": 0.64843
        },
        "bertscore": {
            "precision": 0.8746,
            "recall": 0.86514,
            "f1": 0.86935
        },
        "meteor": 0.31273876380156745,
        "bleurt": -0.07614
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 106,
        "total_length": 2246,
        "mean_pred_length": 21.18867924528302,
        "std_pred_length": 4.627875358204743,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 36,
        "distinct-1": 0.41718610863757793,
        "vocab_size-1": 937,
        "unique-1": 707,
        "entropy-1": 8.311784937729081,
        "distinct-2": 0.8411214953271028,
        "vocab_size-2": 1800,
        "unique-2": 1646,
        "entropy-2": 10.594705174287164,
        "cond_entropy-2": 2.093232428969279,
        "distinct-3": 0.95968534906588,
        "vocab_size-3": 1952,
        "unique-3": 1904,
        "entropy-3": 10.887005395373116,
        "cond_entropy-3": 0.2937196619036039,
        "total_length-nopunct": 2100,
        "mean_pred_length-nopunct": 19.81132075471698,
        "std_pred_length-nopunct": 4.558039150458935,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.44285714285714284,
        "vocab_size-1-nopunct": 930,
        "unique-1-nopunct": 703,
        "entropy-1-nopunct": 8.440817539237347,
        "distinct-2-nopunct": 0.8480441323971916,
        "vocab_size-2-nopunct": 1691,
        "unique-2-nopunct": 1547,
        "entropy-2-nopunct": 10.518045147929532,
        "cond_entropy-2-nopunct": 2.169022689601325,
        "distinct-3-nopunct": 0.9671610169491526,
        "vocab_size-3-nopunct": 1826,
        "unique-3-nopunct": 1783,
        "entropy-3-nopunct": 10.807617233423672,
        "cond_entropy-3-nopunct": 0.29288539702195093,
        "msttr-100": 0.72455,
        "msttr-100_nopunct": 0.74286,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3336405529953917
        },
        "rouge1": {
            "precision": 0.39154,
            "recall": 0.36104,
            "fmeasure": 0.36801
        },
        "rouge2": {
            "precision": 0.13226,
            "recall": 0.12152,
            "fmeasure": 0.12406
        },
        "rougeL": {
            "precision": 0.29852,
            "recall": 0.27357,
            "fmeasure": 0.27992
        },
        "rougeLsum": {
            "precision": 0.29852,
            "recall": 0.27357,
            "fmeasure": 0.27992
        },
        "nist": 3.124810111879621,
        "bleu": 7.52038,
        "nubia": {
            "semantic_relation": 2.67043,
            "contradiction": 31.30492,
            "irrelevancy": 58.94874,
            "logical_agreement": 9.74633,
            "grammar_ref": 3.66018,
            "grammar_hyp": 3.63483,
            "nubia_score": 0.35707
        },
        "bertscore": {
            "precision": 0.83021,
            "recall": 0.81508,
            "f1": 0.82228
        },
        "meteor": 0.16274991430526078,
        "bleurt": -0.36287
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 253,
        "total_length": 2182,
        "mean_pred_length": 8.624505928853756,
        "std_pred_length": 2.7543196854771135,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.4175068744271311,
        "vocab_size-1": 911,
        "unique-1": 615,
        "entropy-1": 8.357160529325233,
        "distinct-2": 0.7594608605495076,
        "vocab_size-2": 1465,
        "unique-2": 1202,
        "entropy-2": 10.276622747408034,
        "cond_entropy-2": 1.2310610591521913,
        "distinct-3": 0.8806682577565632,
        "vocab_size-3": 1476,
        "unique-3": 1322,
        "entropy-3": 10.446360798865461,
        "cond_entropy-3": 0.17100842840427546,
        "total_length-nopunct": 1744,
        "mean_pred_length-nopunct": 6.893280632411067,
        "std_pred_length-nopunct": 2.418733357696297,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5194954128440367,
        "vocab_size-1-nopunct": 906,
        "unique-1-nopunct": 615,
        "entropy-1-nopunct": 9.100604006220108,
        "distinct-2-nopunct": 0.7833668678739101,
        "vocab_size-2-nopunct": 1168,
        "unique-2-nopunct": 981,
        "entropy-2-nopunct": 9.970838023004964,
        "cond_entropy-2-nopunct": 0.9995307901251255,
        "distinct-3-nopunct": 0.8933764135702746,
        "vocab_size-3-nopunct": 1106,
        "unique-3-nopunct": 1008,
        "entropy-3-nopunct": 10.03513463150864,
        "cond_entropy-3-nopunct": 0.13162193667407637,
        "msttr-100": 0.76048,
        "msttr-100_nopunct": 0.88059,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.3856655290102389,
            "2": 0.7377963737796374,
            "3": 0.8532423208191127,
            "4": 0.9142857142857143,
            "5": 0.9090909090909091,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.34205,
            "recall": 0.33829,
            "fmeasure": 0.33807
        },
        "rouge2": {
            "precision": 0.19766,
            "recall": 0.1906,
            "fmeasure": 0.19244
        },
        "rougeL": {
            "precision": 0.34139,
            "recall": 0.33779,
            "fmeasure": 0.33751
        },
        "rougeLsum": {
            "precision": 0.34139,
            "recall": 0.33779,
            "fmeasure": 0.33751
        },
        "nist": 8.703408580879117,
        "bleu": 63.49906,
        "nubia": {
            "semantic_relation": 4.24007,
            "contradiction": 20.27373,
            "irrelevancy": 18.94303,
            "logical_agreement": 60.78324,
            "grammar_ref": 2.90527,
            "grammar_hyp": 2.91226,
            "nubia_score": 0.85636
        },
        "bertscore": {
            "precision": 0.9706,
            "recall": 0.96876,
            "f1": 0.96922
        },
        "meteor": 0.7725535828579563,
        "bleurt": 0.41993
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 106,
        "total_length": 2286,
        "mean_pred_length": 21.566037735849058,
        "std_pred_length": 4.358939779186678,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 37,
        "distinct-1": 0.39763779527559057,
        "vocab_size-1": 909,
        "unique-1": 676,
        "entropy-1": 8.208955074804955,
        "distinct-2": 0.813302752293578,
        "vocab_size-2": 1773,
        "unique-2": 1600,
        "entropy-2": 10.530154311307562,
        "cond_entropy-2": 2.137485392850517,
        "distinct-3": 0.9450337512054002,
        "vocab_size-3": 1960,
        "unique-3": 1883,
        "entropy-3": 10.888416290691866,
        "cond_entropy-3": 0.3643499753008582,
        "total_length-nopunct": 2132,
        "mean_pred_length-nopunct": 20.11320754716981,
        "std_pred_length-nopunct": 4.225530567818162,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.4226078799249531,
        "vocab_size-1-nopunct": 901,
        "unique-1-nopunct": 674,
        "entropy-1-nopunct": 8.31643002811105,
        "distinct-2-nopunct": 0.8188548864758144,
        "vocab_size-2-nopunct": 1659,
        "unique-2-nopunct": 1501,
        "entropy-2-nopunct": 10.438987104756844,
        "cond_entropy-2-nopunct": 2.2106756887411247,
        "distinct-3-nopunct": 0.9505208333333334,
        "vocab_size-3-nopunct": 1825,
        "unique-3-nopunct": 1756,
        "entropy-3-nopunct": 10.795287506559138,
        "cond_entropy-3-nopunct": 0.36656156639353465,
        "msttr-100": 0.71591,
        "msttr-100_nopunct": 0.73476,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.35269320843091334
        },
        "rouge1": {
            "precision": 0.40675,
            "recall": 0.3801,
            "fmeasure": 0.3864
        },
        "rouge2": {
            "precision": 0.15359,
            "recall": 0.14086,
            "fmeasure": 0.14398
        },
        "rougeL": {
            "precision": 0.30645,
            "recall": 0.28554,
            "fmeasure": 0.2905
        },
        "rougeLsum": {
            "precision": 0.30645,
            "recall": 0.28554,
            "fmeasure": 0.2905
        },
        "nist": 3.3302325104132713,
        "bleu": 9.41392,
        "nubia": {
            "semantic_relation": 2.6764,
            "contradiction": 23.06109,
            "irrelevancy": 68.17092,
            "logical_agreement": 8.76799,
            "grammar_ref": 3.68583,
            "grammar_hyp": 3.64404,
            "nubia_score": 0.36447
        },
        "bertscore": {
            "precision": 0.82512,
            "recall": 0.81307,
            "f1": 0.81879
        },
        "meteor": 0.17206225426205307,
        "bleurt": -0.41135
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5714285714285714,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.65,
            "recall": 0.8125,
            "fmeasure": 0.72222
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.53333,
            "fmeasure": 0.47059
        },
        "rougeL": {
            "precision": 0.55,
            "recall": 0.6875,
            "fmeasure": 0.61111
        },
        "rougeLsum": {
            "precision": 0.55,
            "recall": 0.6875,
            "fmeasure": 0.61111
        },
        "nist": 3.3386625928123093,
        "bleu": 22.27227,
        "nubia": {
            "semantic_relation": 4.13735,
            "contradiction": 0.09988,
            "irrelevancy": 53.92367,
            "logical_agreement": 45.97645,
            "grammar_ref": 3.92881,
            "grammar_hyp": 3.34745,
            "nubia_score": 0.84895
        },
        "bertscore": {
            "precision": 0.90304,
            "recall": 0.93472,
            "f1": 0.9186
        },
        "meteor": 0.3734836384767733,
        "bleurt": 0.28106
    },
    "web_nlg_en_challenge_test_numbers": {
        "predictions_file": "mT5_base/web_nlg_en_challenge_test_numbers",
        "N": 500,
        "total_length": 13126,
        "mean_pred_length": 26.252,
        "std_pred_length": 13.443678663223098,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 77,
        "distinct-1": 0.12890446442175835,
        "vocab_size-1": 1692,
        "unique-1": 768,
        "entropy-1": 8.044190337996605,
        "distinct-2": 0.4059876445430065,
        "vocab_size-2": 5126,
        "unique-2": 3346,
        "entropy-2": 11.346846745548573,
        "cond_entropy-2": 3.145353267370969,
        "distinct-3": 0.6474517565561603,
        "vocab_size-3": 7851,
        "unique-3": 6218,
        "entropy-3": 12.504208474834861,
        "cond_entropy-3": 1.2023518713081294,
        "total_length-nopunct": 11565,
        "mean_pred_length-nopunct": 23.13,
        "std_pred_length-nopunct": 12.120441411103805,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.14543882403804584,
        "vocab_size-1-nopunct": 1682,
        "unique-1-nopunct": 768,
        "entropy-1-nopunct": 8.337758491612497,
        "distinct-2-nopunct": 0.4271125169453231,
        "vocab_size-2-nopunct": 4726,
        "unique-2-nopunct": 3195,
        "entropy-2-nopunct": 11.258395873822566,
        "cond_entropy-2-nopunct": 3.050727727213048,
        "distinct-3-nopunct": 0.6635115948887838,
        "vocab_size-3-nopunct": 7010,
        "unique-3-nopunct": 5654,
        "entropy-3-nopunct": 12.352564263336811,
        "cond_entropy-3-nopunct": 1.1369197746982989,
        "msttr-100": 0.63672,
        "msttr-100_nopunct": 0.68113,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_numbers.json",
        "local_recall": {
            "1": 0.21722768137152415,
            "2": 0.52046783625731,
            "3": 0.7625022405449006,
            "4": 0.5555555555555556,
            "5": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.64724,
            "recall": 0.66162,
            "fmeasure": 0.6453
        },
        "rouge2": {
            "precision": 0.38555,
            "recall": 0.39736,
            "fmeasure": 0.38559
        },
        "rougeL": {
            "precision": 0.50348,
            "recall": 0.51844,
            "fmeasure": 0.50301
        },
        "rougeLsum": {
            "precision": 0.50348,
            "recall": 0.51844,
            "fmeasure": 0.50301
        },
        "nist": 7.118490189076549,
        "bleu": 35.73495,
        "nubia": {
            "semantic_relation": 3.67579,
            "contradiction": 33.84126,
            "irrelevancy": 14.72757,
            "logical_agreement": 51.43117,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.73821,
            "nubia_score": 0.5598
        },
        "bertscore": {
            "precision": 0.88483,
            "recall": 0.891,
            "f1": 0.88635
        },
        "meteor": 0.32896946211859746,
        "bleurt": -0.14321
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "nist": 1.925871591630247,
        "bleu": 11.73118,
        "nubia": {
            "semantic_relation": 3.50539,
            "contradiction": 38.90136,
            "irrelevancy": 25.93608,
            "logical_agreement": 35.16256,
            "grammar_ref": 2.53664,
            "grammar_hyp": 2.16706,
            "nubia_score": 0.70358
        },
        "bertscore": {
            "precision": 0.91411,
            "recall": 0.91671,
            "f1": 0.91541
        },
        "meteor": 0.33724045844385264,
        "bleurt": 0.12244
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 494,
        "total_length": 11371,
        "mean_pred_length": 23.018218623481783,
        "std_pred_length": 9.942429019228962,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 69,
        "distinct-1": 0.16181514378682613,
        "vocab_size-1": 1840,
        "unique-1": 690,
        "entropy-1": 8.638003289763914,
        "distinct-2": 0.38273420980049644,
        "vocab_size-2": 4163,
        "unique-2": 2206,
        "entropy-2": 11.269279116002695,
        "cond_entropy-2": 2.4125905463015167,
        "distinct-3": 0.5382837330251372,
        "vocab_size-3": 5589,
        "unique-3": 3591,
        "entropy-3": 12.010664294687807,
        "cond_entropy-3": 0.7585834163353654,
        "total_length-nopunct": 9271,
        "mean_pred_length-nopunct": 18.767206477732792,
        "std_pred_length-nopunct": 8.142236155082964,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.1977132995361881,
        "vocab_size-1-nopunct": 1833,
        "unique-1-nopunct": 690,
        "entropy-1-nopunct": 9.320703958948796,
        "distinct-2-nopunct": 0.4253161672553264,
        "vocab_size-2-nopunct": 3733,
        "unique-2-nopunct": 2117,
        "entropy-2-nopunct": 11.196650927158215,
        "cond_entropy-2-nopunct": 1.9373202062934463,
        "distinct-3-nopunct": 0.5764819509839431,
        "vocab_size-3-nopunct": 4775,
        "unique-3-nopunct": 3244,
        "entropy-3-nopunct": 11.813879965218165,
        "cond_entropy-3-nopunct": 0.6561013010332764,
        "msttr-100": 0.7069,
        "msttr-100_nopunct": 0.79717,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2745288248337029,
            "2": 0.640807962529274,
            "3": 0.8961950498707055,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.38992,
            "recall": 0.40427,
            "fmeasure": 0.39362
        },
        "rouge2": {
            "precision": 0.22392,
            "recall": 0.23646,
            "fmeasure": 0.22666
        },
        "rougeL": {
            "precision": 0.36448,
            "recall": 0.37898,
            "fmeasure": 0.36817
        },
        "rougeLsum": {
            "precision": 0.36448,
            "recall": 0.37898,
            "fmeasure": 0.36817
        },
        "nist": 8.894537691880293,
        "bleu": 49.10326,
        "nubia": {
            "semantic_relation": 3.96858,
            "contradiction": 18.93126,
            "irrelevancy": 22.29921,
            "logical_agreement": 58.76954,
            "grammar_ref": 2.60025,
            "grammar_hyp": 2.53989,
            "nubia_score": 0.82715
        },
        "bertscore": {
            "precision": 0.95364,
            "recall": 0.95154,
            "f1": 0.95181
        },
        "meteor": 0.643485110251454,
        "bleurt": 0.14983
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 354,
        "total_length": 9849,
        "mean_pred_length": 27.822033898305083,
        "std_pred_length": 9.912582333510523,
        "median_pred_length": 26.5,
        "min_pred_length": 6,
        "max_pred_length": 70,
        "distinct-1": 0.15686871763630825,
        "vocab_size-1": 1545,
        "unique-1": 608,
        "entropy-1": 8.448918752967614,
        "distinct-2": 0.3530279094260137,
        "vocab_size-2": 3352,
        "unique-2": 1778,
        "entropy-2": 10.875628569723693,
        "cond_entropy-2": 2.253013419745817,
        "distinct-3": 0.49195930423367246,
        "vocab_size-3": 4497,
        "unique-3": 2865,
        "entropy-3": 11.593222787877064,
        "cond_entropy-3": 0.733299071627758,
        "total_length-nopunct": 8175,
        "mean_pred_length-nopunct": 23.093220338983052,
        "std_pred_length-nopunct": 8.65469464203856,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.18813455657492353,
        "vocab_size-1-nopunct": 1538,
        "unique-1-nopunct": 608,
        "entropy-1-nopunct": 9.03397258344738,
        "distinct-2-nopunct": 0.39419511571410304,
        "vocab_size-2-nopunct": 3083,
        "unique-2-nopunct": 1754,
        "entropy-2-nopunct": 10.868081133881514,
        "cond_entropy-2-nopunct": 1.8842222373460662,
        "distinct-3-nopunct": 0.5283246283648051,
        "vocab_size-3-nopunct": 3945,
        "unique-3-nopunct": 2650,
        "entropy-3-nopunct": 11.428593258103541,
        "cond_entropy-3-nopunct": 0.5798593145529921,
        "msttr-100": 0.69898,
        "msttr-100_nopunct": 0.78556,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2968250986285929,
            "2": 0.6952076677316293,
            "3": 0.8948707079270878,
            "4": 0.972972972972973,
            "5": 0.9545454545454546,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.58505,
            "recall": 0.59224,
            "fmeasure": 0.5835
        },
        "rouge2": {
            "precision": 0.34136,
            "recall": 0.34843,
            "fmeasure": 0.33884
        },
        "rougeL": {
            "precision": 0.56193,
            "recall": 0.56904,
            "fmeasure": 0.56029
        },
        "rougeLsum": {
            "precision": 0.56193,
            "recall": 0.56904,
            "fmeasure": 0.56029
        },
        "nist": 8.859160055494847,
        "bleu": 52.63466,
        "nubia": {
            "semantic_relation": 3.96878,
            "contradiction": 19.14521,
            "irrelevancy": 21.34295,
            "logical_agreement": 59.51184,
            "grammar_ref": 2.54394,
            "grammar_hyp": 2.4893,
            "nubia_score": 0.83618
        },
        "bertscore": {
            "precision": 0.95494,
            "recall": 0.95259,
            "f1": 0.95312
        },
        "meteor": 0.6631281821365418,
        "bleurt": 0.16339
    },
    "common_gen_val": {
        "predictions_file": "mT5_base/common_gen_val",
        "N": 993,
        "total_length": 9197,
        "mean_pred_length": 9.261832829808661,
        "std_pred_length": 2.2613534665670985,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 17,
        "distinct-1": 0.12493204305751876,
        "vocab_size-1": 1149,
        "unique-1": 566,
        "entropy-1": 6.864052463370295,
        "distinct-2": 0.39541686981960017,
        "vocab_size-2": 3244,
        "unique-2": 2222,
        "entropy-2": 10.255538277762033,
        "cond_entropy-2": 3.2083695043423224,
        "distinct-3": 0.6497018444043822,
        "vocab_size-3": 4685,
        "unique-3": 3810,
        "entropy-3": 11.602788270727793,
        "cond_entropy-3": 1.4808715713632656,
        "total_length-nopunct": 8438,
        "mean_pred_length-nopunct": 8.497482376636455,
        "std_pred_length-nopunct": 2.0949860312756914,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.13593268547049064,
        "vocab_size-1-nopunct": 1147,
        "unique-1-nopunct": 566,
        "entropy-1-nopunct": 7.027495994636261,
        "distinct-2-nopunct": 0.3923438549361988,
        "vocab_size-2-nopunct": 2921,
        "unique-2-nopunct": 2031,
        "entropy-2-nopunct": 10.025992396047034,
        "cond_entropy-2-nopunct": 3.43288544046267,
        "distinct-3-nopunct": 0.6604153750774954,
        "vocab_size-3-nopunct": 4261,
        "unique-3-nopunct": 3508,
        "entropy-3-nopunct": 11.457116152338253,
        "cond_entropy-3-nopunct": 1.5770053232663572,
        "msttr-100": 0.54571,
        "msttr-100_nopunct": 0.57024,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/common_gen_val.json",
        "local_recall": {
            "1": 0.09098862642169729,
            "2": 0.27872340425531916,
            "3": 0.4619883040935672,
            "4": 0.7087992221682061,
            "5": 0.6652360515021459,
            "6": 0.7976190476190477,
            "7": 1.0,
            "8": 0.8
        },
        "rouge1": {
            "precision": 0.67653,
            "recall": 0.56908,
            "fmeasure": 0.60533
        },
        "rouge2": {
            "precision": 0.324,
            "recall": 0.26666,
            "fmeasure": 0.28425
        },
        "rougeL": {
            "precision": 0.58217,
            "recall": 0.49042,
            "fmeasure": 0.52114
        },
        "rougeLsum": {
            "precision": 0.58217,
            "recall": 0.49042,
            "fmeasure": 0.52114
        },
        "nist": 5.191907725183153,
        "bleu": 22.6278,
        "nubia": {
            "semantic_relation": 3.05661,
            "contradiction": 30.75414,
            "irrelevancy": 21.46612,
            "logical_agreement": 47.77974,
            "grammar_ref": 4.64808,
            "grammar_hyp": 4.97932,
            "nubia_score": 0.39806
        },
        "bertscore": {
            "precision": 0.88171,
            "recall": 0.86889,
            "f1": 0.87381
        },
        "meteor": 0.23353362285941978,
        "bleurt": -0.51215
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 106,
        "total_length": 2331,
        "mean_pred_length": 21.99056603773585,
        "std_pred_length": 4.651019938900941,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 36,
        "distinct-1": 0.4088374088374088,
        "vocab_size-1": 953,
        "unique-1": 712,
        "entropy-1": 8.274270597220326,
        "distinct-2": 0.8359550561797753,
        "vocab_size-2": 1860,
        "unique-2": 1715,
        "entropy-2": 10.61655861275872,
        "cond_entropy-2": 2.160517892912848,
        "distinct-3": 0.9655497876356772,
        "vocab_size-3": 2046,
        "unique-3": 1999,
        "entropy-3": 10.964890176543431,
        "cond_entropy-3": 0.34991113829890247,
        "total_length-nopunct": 2177,
        "mean_pred_length-nopunct": 20.537735849056602,
        "std_pred_length-nopunct": 4.489346988488913,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.43454294901240237,
        "vocab_size-1-nopunct": 946,
        "unique-1-nopunct": 711,
        "entropy-1-nopunct": 8.391969781704455,
        "distinct-2-nopunct": 0.8435538387252535,
        "vocab_size-2-nopunct": 1747,
        "unique-2-nopunct": 1614,
        "entropy-2-nopunct": 10.53731935157728,
        "cond_entropy-2-nopunct": 2.2290260521878165,
        "distinct-3-nopunct": 0.9720101781170484,
        "vocab_size-3-nopunct": 1910,
        "unique-3-nopunct": 1868,
        "entropy-3-nopunct": 10.878405841170729,
        "cond_entropy-3-nopunct": 0.3385297640370003,
        "msttr-100": 0.71609,
        "msttr-100_nopunct": 0.73619,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3160527512505684
        },
        "rouge1": {
            "precision": 0.38088,
            "recall": 0.3491,
            "fmeasure": 0.3586
        },
        "rouge2": {
            "precision": 0.12929,
            "recall": 0.11774,
            "fmeasure": 0.12127
        },
        "rougeL": {
            "precision": 0.28723,
            "recall": 0.26346,
            "fmeasure": 0.27066
        },
        "rougeLsum": {
            "precision": 0.28723,
            "recall": 0.26346,
            "fmeasure": 0.27066
        },
        "nist": 2.939011209032694,
        "bleu": 7.75689,
        "nubia": {
            "semantic_relation": 2.61708,
            "contradiction": 21.96612,
            "irrelevancy": 69.35527,
            "logical_agreement": 8.67861,
            "grammar_ref": 3.83852,
            "grammar_hyp": 3.71988,
            "nubia_score": 0.35188
        },
        "bertscore": {
            "precision": 0.82251,
            "recall": 0.80845,
            "f1": 0.8152
        },
        "meteor": 0.15135952662143312,
        "bleurt": -0.38941
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 460,
        "total_length": 11535,
        "mean_pred_length": 25.07608695652174,
        "std_pred_length": 9.113336733997112,
        "median_pred_length": 25.0,
        "min_pred_length": 6,
        "max_pred_length": 59,
        "distinct-1": 0.14512353706111833,
        "vocab_size-1": 1674,
        "unique-1": 543,
        "entropy-1": 8.511826460671164,
        "distinct-2": 0.3438374717832957,
        "vocab_size-2": 3808,
        "unique-2": 1841,
        "entropy-2": 11.10491584642624,
        "cond_entropy-2": 2.3956816547594406,
        "distinct-3": 0.48666980687706074,
        "vocab_size-3": 5166,
        "unique-3": 3020,
        "entropy-3": 11.894275851705121,
        "cond_entropy-3": 0.8062991426333821,
        "total_length-nopunct": 9379,
        "mean_pred_length-nopunct": 20.389130434782608,
        "std_pred_length-nopunct": 7.967780997647025,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.17773749866723532,
        "vocab_size-1-nopunct": 1667,
        "unique-1-nopunct": 542,
        "entropy-1-nopunct": 9.209642087152595,
        "distinct-2-nopunct": 0.39320551631348805,
        "vocab_size-2-nopunct": 3507,
        "unique-2-nopunct": 1831,
        "entropy-2-nopunct": 11.143289060246204,
        "cond_entropy-2-nopunct": 1.9836311793649823,
        "distinct-3-nopunct": 0.5362335973519329,
        "vocab_size-3-nopunct": 4536,
        "unique-3-nopunct": 2864,
        "entropy-3-nopunct": 11.752380502129878,
        "cond_entropy-3-nopunct": 0.6281514909339103,
        "msttr-100": 0.59496,
        "msttr-100_nopunct": 0.65538,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2827538247566064,
            "2": 0.6661106477620239,
            "3": 0.8844462215113954,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.35155,
            "recall": 0.35762,
            "fmeasure": 0.35093
        },
        "rouge2": {
            "precision": 0.16512,
            "recall": 0.16825,
            "fmeasure": 0.16242
        },
        "rougeL": {
            "precision": 0.34413,
            "recall": 0.35043,
            "fmeasure": 0.3435
        },
        "rougeLsum": {
            "precision": 0.34413,
            "recall": 0.35043,
            "fmeasure": 0.3435
        },
        "nist": 8.726186353554116,
        "bleu": 48.35291,
        "nubia": {
            "semantic_relation": 3.99703,
            "contradiction": 19.21572,
            "irrelevancy": 21.28816,
            "logical_agreement": 59.49612,
            "grammar_ref": 2.52111,
            "grammar_hyp": 2.47467,
            "nubia_score": 0.833
        },
        "bertscore": {
            "precision": 0.95432,
            "recall": 0.95099,
            "f1": 0.95196
        },
        "meteor": 0.6373053439331007,
        "bleurt": 0.16389
    },
    "cs_restaurants_challenge_test_scramble_parent": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 500,
        "total_length": 5231,
        "mean_pred_length": 10.462,
        "std_pred_length": 2.8447418160529083,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.07130567769069011,
        "vocab_size-1": 373,
        "unique-1": 144,
        "entropy-1": 6.464589090673322,
        "distinct-2": 0.18051151976326357,
        "vocab_size-2": 854,
        "unique-2": 424,
        "entropy-2": 8.066956993988793,
        "cond_entropy-2": 1.3501519329980454,
        "distinct-3": 0.28858425904041596,
        "vocab_size-3": 1221,
        "unique-3": 738,
        "entropy-3": 8.769865821162092,
        "cond_entropy-3": 0.8107953290974761,
        "total_length-nopunct": 4411,
        "mean_pred_length-nopunct": 8.822,
        "std_pred_length-nopunct": 2.7346509832152255,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.08365450011335299,
        "vocab_size-1-nopunct": 369,
        "unique-1-nopunct": 144,
        "entropy-1-nopunct": 6.634908349923528,
        "distinct-2-nopunct": 0.1756583993863462,
        "vocab_size-2-nopunct": 687,
        "unique-2-nopunct": 321,
        "entropy-2-nopunct": 7.86955327571961,
        "cond_entropy-2-nopunct": 1.4501934548669295,
        "distinct-3-nopunct": 0.2961008501905599,
        "vocab_size-3-nopunct": 1010,
        "unique-3-nopunct": 605,
        "entropy-3-nopunct": 8.611713072169776,
        "cond_entropy-3-nopunct": 0.9264508084218462,
        "msttr-100": 0.53577,
        "msttr-100_nopunct": 0.5625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4777544840437922
        },
        "rouge1": {
            "precision": 0.50364,
            "recall": 0.52239,
            "fmeasure": 0.49927
        },
        "rouge2": {
            "precision": 0.29827,
            "recall": 0.3117,
            "fmeasure": 0.29542
        },
        "rougeL": {
            "precision": 0.45646,
            "recall": 0.47308,
            "fmeasure": 0.45252
        },
        "rougeLsum": {
            "precision": 0.45646,
            "recall": 0.47308,
            "fmeasure": 0.45252
        },
        "nist": 4.102864846780687,
        "bleu": 19.21501,
        "nubia": {
            "semantic_relation": 3.18289,
            "contradiction": 28.38817,
            "irrelevancy": 31.00994,
            "logical_agreement": 40.60188,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.96079,
            "nubia_score": 0.45491
        },
        "bertscore": {
            "precision": 0.89139,
            "recall": 0.90296,
            "f1": 0.89683
        },
        "meteor": 0.24247896546488268,
        "bleurt": -0.19665
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 1075,
        "total_length": 22968,
        "mean_pred_length": 21.365581395348837,
        "std_pred_length": 11.379676968956254,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 70,
        "distinct-1": 0.11389759665621735,
        "vocab_size-1": 2616,
        "unique-1": 799,
        "entropy-1": 8.915167161328332,
        "distinct-2": 0.3013748686794866,
        "vocab_size-2": 6598,
        "unique-2": 3139,
        "entropy-2": 11.761547687160624,
        "cond_entropy-2": 2.591707398551993,
        "distinct-3": 0.449226630800269,
        "vocab_size-3": 9352,
        "unique-3": 5518,
        "entropy-3": 12.624583684132679,
        "cond_entropy-3": 0.8861280968013459,
        "total_length-nopunct": 18835,
        "mean_pred_length-nopunct": 17.52093023255814,
        "std_pred_length-nopunct": 9.571385604523588,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.1384656225112822,
        "vocab_size-1-nopunct": 2608,
        "unique-1-nopunct": 799,
        "entropy-1-nopunct": 9.639947916117842,
        "distinct-2-nopunct": 0.34121621621621623,
        "vocab_size-2-nopunct": 6060,
        "unique-2-nopunct": 3137,
        "entropy-2-nopunct": 11.75450824084554,
        "cond_entropy-2-nopunct": 2.191080083659154,
        "distinct-3-nopunct": 0.49014084507042255,
        "vocab_size-3-nopunct": 8178,
        "unique-3-nopunct": 5166,
        "entropy-3-nopunct": 12.465531430710417,
        "cond_entropy-3-nopunct": 0.7534156600578628,
        "msttr-100": 0.71659,
        "msttr-100_nopunct": 0.80564,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2942966881658091,
            "2": 0.6758572428271519,
            "3": 0.8962948815889993,
            "4": 0.948051948051948,
            "5": 0.9459459459459459,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.44486,
            "recall": 0.45169,
            "fmeasure": 0.44473
        },
        "rouge2": {
            "precision": 0.25753,
            "recall": 0.26336,
            "fmeasure": 0.25669
        },
        "rougeL": {
            "precision": 0.42598,
            "recall": 0.43285,
            "fmeasure": 0.42583
        },
        "rougeLsum": {
            "precision": 0.42598,
            "recall": 0.43285,
            "fmeasure": 0.42583
        },
        "nist": 9.485264785527292,
        "bleu": 52.0456,
        "nubia": {
            "semantic_relation": 4.03781,
            "contradiction": 18.97738,
            "irrelevancy": 21.26316,
            "logical_agreement": 59.75945,
            "grammar_ref": 2.64396,
            "grammar_hyp": 2.60064,
            "nubia_score": 0.83952
        },
        "bertscore": {
            "precision": 0.9582,
            "recall": 0.95609,
            "f1": 0.95648
        },
        "meteor": 0.6653874653306259,
        "bleurt": 0.21823
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 1654,
        "total_length": 40780,
        "mean_pred_length": 24.655380894800484,
        "std_pred_length": 12.539455677020397,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 85,
        "distinct-1": 0.044825895046591464,
        "vocab_size-1": 1828,
        "unique-1": 489,
        "entropy-1": 7.904776277984067,
        "distinct-2": 0.16073710576087513,
        "vocab_size-2": 6289,
        "unique-2": 2651,
        "entropy-2": 11.1070485272485,
        "cond_entropy-2": 3.0362864287292055,
        "distinct-3": 0.29707514944491886,
        "vocab_size-3": 11132,
        "unique-3": 6160,
        "entropy-3": 12.369930023500059,
        "cond_entropy-3": 1.3321923435925112,
        "total_length-nopunct": 36103,
        "mean_pred_length-nopunct": 21.827690447400244,
        "std_pred_length-nopunct": 11.30697026833617,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.05038362462953217,
        "vocab_size-1-nopunct": 1819,
        "unique-1-nopunct": 489,
        "entropy-1-nopunct": 8.18379967251119,
        "distinct-2-nopunct": 0.17271909199105925,
        "vocab_size-2-nopunct": 5950,
        "unique-2-nopunct": 2669,
        "entropy-2-nopunct": 11.019592702365383,
        "cond_entropy-2-nopunct": 2.983436874074401,
        "distinct-3-nopunct": 0.3142857142857143,
        "vocab_size-3-nopunct": 10307,
        "unique-3-nopunct": 5929,
        "entropy-3-nopunct": 12.255250500697223,
        "cond_entropy-3-nopunct": 1.2989799910404678,
        "msttr-100": 0.50386,
        "msttr-100_nopunct": 0.51884,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22994147630734377,
            "2": 0.5657118786857624,
            "3": 0.8161616161616162,
            "4": 0.8727272727272727,
            "5": 0.6551724137931034
        },
        "rouge1": {
            "precision": 0.70691,
            "recall": 0.71238,
            "fmeasure": 0.70126
        },
        "rouge2": {
            "precision": 0.45135,
            "recall": 0.45376,
            "fmeasure": 0.44679
        },
        "rougeL": {
            "precision": 0.56382,
            "recall": 0.56943,
            "fmeasure": 0.55952
        },
        "rougeLsum": {
            "precision": 0.56382,
            "recall": 0.56943,
            "fmeasure": 0.55952
        },
        "nist": 8.318526986794689,
        "bleu": 43.63007,
        "nubia": {
            "semantic_relation": 4.14593,
            "contradiction": 15.78093,
            "irrelevancy": 11.726,
            "logical_agreement": 72.49308,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.57114,
            "nubia_score": 0.70673
        },
        "bertscore": {
            "precision": 0.90504,
            "recall": 0.90633,
            "f1": 0.90434
        },
        "meteor": 0.3619718419995019,
        "bleurt": 0.05691
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 4,
        "total_length": 34,
        "mean_pred_length": 8.5,
        "std_pred_length": 2.29128784747792,
        "median_pred_length": 8.0,
        "min_pred_length": 6,
        "max_pred_length": 12,
        "distinct-1": 0.9117647058823529,
        "vocab_size-1": 31,
        "unique-1": 30,
        "entropy-1": 4.852168723603279,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": -0.18057224564182076,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.20645087746742646,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 6.5,
        "std_pred_length-nopunct": 2.0615528128088303,
        "median_pred_length-nopunct": 5.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.70043971814109,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.24100809950379512,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.2895066171949847,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.4666666666666667,
            "2": 0.3076923076923077,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.125,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "rougeLsum": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "nist": 3.881277652971979,
        "bleu": 55.99351,
        "nubia": {
            "semantic_relation": 4.16856,
            "contradiction": 32.18355,
            "irrelevancy": 15.85939,
            "logical_agreement": 51.95707,
            "grammar_ref": 3.0388,
            "grammar_hyp": 2.91246,
            "nubia_score": 0.81403
        },
        "bertscore": {
            "precision": 0.94713,
            "recall": 0.95097,
            "f1": 0.94852
        },
        "meteor": 0.7189097184664043,
        "bleurt": 0.32163
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 5049,
        "total_length": 37187,
        "mean_pred_length": 7.365220835809071,
        "std_pred_length": 2.705983656596231,
        "median_pred_length": 7.0,
        "min_pred_length": 1,
        "max_pred_length": 52,
        "distinct-1": 0.028881060585688546,
        "vocab_size-1": 1074,
        "unique-1": 449,
        "entropy-1": 6.690979793316871,
        "distinct-2": 0.10034849710622938,
        "vocab_size-2": 3225,
        "unique-2": 1597,
        "entropy-2": 8.951058332806861,
        "cond_entropy-2": 1.88375806595567,
        "distinct-3": 0.1696936138796604,
        "vocab_size-3": 4597,
        "unique-3": 2649,
        "entropy-3": 9.689629740982332,
        "cond_entropy-3": 0.7825339192541373,
        "total_length-nopunct": 31723,
        "mean_pred_length-nopunct": 6.2830263418498715,
        "std_pred_length-nopunct": 2.5003289685518792,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.03354033351196293,
        "vocab_size-1-nopunct": 1064,
        "unique-1-nopunct": 448,
        "entropy-1-nopunct": 6.8512001091679124,
        "distinct-2-nopunct": 0.10148459173727226,
        "vocab_size-2-nopunct": 2707,
        "unique-2-nopunct": 1384,
        "entropy-2-nopunct": 8.620855399562718,
        "cond_entropy-2-nopunct": 1.9754655456848154,
        "distinct-3-nopunct": 0.17008784096162738,
        "vocab_size-3-nopunct": 3679,
        "unique-3-nopunct": 2181,
        "entropy-3-nopunct": 9.27530902275749,
        "cond_entropy-3-nopunct": 0.7928923602258903,
        "msttr-100": 0.54916,
        "msttr-100_nopunct": 0.56782,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4583357732622826
        },
        "rouge1": {
            "precision": 0.51089,
            "recall": 0.47908,
            "fmeasure": 0.48201
        },
        "rouge2": {
            "precision": 0.29843,
            "recall": 0.279,
            "fmeasure": 0.28025
        },
        "rougeL": {
            "precision": 0.48516,
            "recall": 0.45369,
            "fmeasure": 0.45733
        },
        "rougeLsum": {
            "precision": 0.48516,
            "recall": 0.45369,
            "fmeasure": 0.45733
        },
        "nist": 4.608161489516046,
        "bleu": 25.38073,
        "nubia": {
            "semantic_relation": 3.13805,
            "contradiction": 8.62764,
            "irrelevancy": 23.16351,
            "logical_agreement": 68.20886,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.46607,
            "nubia_score": 0.58128
        },
        "bertscore": {
            "precision": 0.85944,
            "recall": 0.85016,
            "f1": 0.85419
        },
        "meteor": 0.2588259435885399,
        "bleurt": -0.10597
    },
    "web_nlg_ru_challenge_test_scramble_parent": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 500,
        "total_length": 10606,
        "mean_pred_length": 21.212,
        "std_pred_length": 12.055664892489338,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 70,
        "distinct-1": 0.18385819347539128,
        "vocab_size-1": 1950,
        "unique-1": 835,
        "entropy-1": 8.754766400756308,
        "distinct-2": 0.4282604393429646,
        "vocab_size-2": 4328,
        "unique-2": 2544,
        "entropy-2": 11.373442279822294,
        "cond_entropy-2": 2.3707399594550247,
        "distinct-3": 0.5864043306266916,
        "vocab_size-3": 5633,
        "unique-3": 3888,
        "entropy-3": 12.076020383050569,
        "cond_entropy-3": 0.7224338123036994,
        "total_length-nopunct": 8703,
        "mean_pred_length-nopunct": 17.406,
        "std_pred_length-nopunct": 10.024228848145876,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.22314144547857062,
        "vocab_size-1-nopunct": 1942,
        "unique-1-nopunct": 835,
        "entropy-1-nopunct": 9.442492149220755,
        "distinct-2-nopunct": 0.4701938315250518,
        "vocab_size-2-nopunct": 3857,
        "unique-2-nopunct": 2361,
        "entropy-2-nopunct": 11.325223888162256,
        "cond_entropy-2-nopunct": 1.9558351953744,
        "distinct-3-nopunct": 0.6222251071011294,
        "vocab_size-3-nopunct": 4793,
        "unique-3-nopunct": 3441,
        "entropy-3-nopunct": 11.881625516003663,
        "cond_entropy-3-nopunct": 0.594394473069491,
        "msttr-100": 0.62104,
        "msttr-100_nopunct": 0.6854,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.3006844850065189,
            "2": 0.6796969696969697,
            "3": 0.8951817413355875,
            "4": 0.9333333333333333,
            "5": 0.8,
            "6": 1.0
        },
        "rouge1": {
            "precision": 0.43302,
            "recall": 0.44271,
            "fmeasure": 0.43411
        },
        "rouge2": {
            "precision": 0.24335,
            "recall": 0.24994,
            "fmeasure": 0.24256
        },
        "rougeL": {
            "precision": 0.41457,
            "recall": 0.424,
            "fmeasure": 0.41543
        },
        "rougeLsum": {
            "precision": 0.41457,
            "recall": 0.424,
            "fmeasure": 0.41543
        },
        "nist": 9.152886192598514,
        "bleu": 52.14096,
        "nubia": {
            "semantic_relation": 4.03033,
            "contradiction": 19.63376,
            "irrelevancy": 21.12634,
            "logical_agreement": 59.2399,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.61494,
            "nubia_score": 0.83873
        },
        "bertscore": {
            "precision": 0.95843,
            "recall": 0.95607,
            "f1": 0.95655
        },
        "meteor": 0.6685025895081851,
        "bleurt": 0.22856
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.0,
            "3": 0.7222222222222222
        },
        "rouge1": {
            "precision": 0.43542,
            "recall": 0.71911,
            "fmeasure": 0.52248
        },
        "rouge2": {
            "precision": 0.26935,
            "recall": 0.49003,
            "fmeasure": 0.33048
        },
        "rougeL": {
            "precision": 0.41319,
            "recall": 0.69689,
            "fmeasure": 0.49655
        },
        "rougeLsum": {
            "precision": 0.41319,
            "recall": 0.69689,
            "fmeasure": 0.49655
        },
        "nist": 1.7241290256718935,
        "bleu": 14.71167,
        "nubia": {
            "semantic_relation": 3.52491,
            "contradiction": 30.03225,
            "irrelevancy": 59.22261,
            "logical_agreement": 10.74513,
            "grammar_ref": 5.41182,
            "grammar_hyp": 4.17065,
            "nubia_score": 0.3921
        },
        "bertscore": {
            "precision": 0.79932,
            "recall": 0.92781,
            "f1": 0.8453
        },
        "meteor": 0.3045986091244611,
        "bleurt": -0.00472
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 106,
        "total_length": 2265,
        "mean_pred_length": 21.367924528301888,
        "std_pred_length": 4.766877605677701,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 35,
        "distinct-1": 0.4052980132450331,
        "vocab_size-1": 918,
        "unique-1": 677,
        "entropy-1": 8.25964789825685,
        "distinct-2": 0.8314034275127373,
        "vocab_size-2": 1795,
        "unique-2": 1620,
        "entropy-2": 10.585373754206385,
        "cond_entropy-2": 2.137082530384149,
        "distinct-3": 0.9547004383828543,
        "vocab_size-3": 1960,
        "unique-3": 1891,
        "entropy-3": 10.902483728960222,
        "cond_entropy-3": 0.32636592702710737,
        "total_length-nopunct": 2088,
        "mean_pred_length-nopunct": 19.69811320754717,
        "std_pred_length-nopunct": 4.406619830074599,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.4363026819923372,
        "vocab_size-1-nopunct": 911,
        "unique-1-nopunct": 677,
        "entropy-1-nopunct": 8.393473132851453,
        "distinct-2-nopunct": 0.8365287588294652,
        "vocab_size-2-nopunct": 1658,
        "unique-2-nopunct": 1501,
        "entropy-2-nopunct": 10.472503118172092,
        "cond_entropy-2-nopunct": 2.1759989347264703,
        "distinct-3-nopunct": 0.9605543710021321,
        "vocab_size-3-nopunct": 1802,
        "unique-3-nopunct": 1743,
        "entropy-3-nopunct": 10.787994345711946,
        "cond_entropy-3-nopunct": 0.3209419427157026,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.7385,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3377635197066911
        },
        "rouge1": {
            "precision": 0.40275,
            "recall": 0.35939,
            "fmeasure": 0.37339
        },
        "rouge2": {
            "precision": 0.14331,
            "recall": 0.12616,
            "fmeasure": 0.13172
        },
        "rougeL": {
            "precision": 0.3053,
            "recall": 0.27025,
            "fmeasure": 0.28171
        },
        "rougeLsum": {
            "precision": 0.3053,
            "recall": 0.27025,
            "fmeasure": 0.28171
        },
        "nist": 3.1591835157566526,
        "bleu": 8.52975,
        "nubia": {
            "semantic_relation": 2.67147,
            "contradiction": 29.68963,
            "irrelevancy": 60.87281,
            "logical_agreement": 9.43757,
            "grammar_ref": 3.63886,
            "grammar_hyp": 3.66687,
            "nubia_score": 0.35151
        },
        "bertscore": {
            "precision": 0.8335,
            "recall": 0.81729,
            "f1": 0.82504
        },
        "meteor": 0.15609712431499356,
        "bleurt": -0.37974
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 2517,
        "total_length": 36684,
        "mean_pred_length": 14.574493444576877,
        "std_pred_length": 4.344212489395083,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 45,
        "distinct-1": 0.06684112964780285,
        "vocab_size-1": 2452,
        "unique-1": 1165,
        "entropy-1": 8.042865618585976,
        "distinct-2": 0.22632949922439782,
        "vocab_size-2": 7733,
        "unique-2": 4467,
        "entropy-2": 11.167816794972703,
        "cond_entropy-2": 2.8944514806659276,
        "distinct-3": 0.3834439178515008,
        "vocab_size-3": 12136,
        "unique-3": 8200,
        "entropy-3": 12.38265084540265,
        "cond_entropy-3": 1.2772259568625184,
        "total_length-nopunct": 32342,
        "mean_pred_length-nopunct": 12.84942391736194,
        "std_pred_length-nopunct": 3.8615249984609252,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.07538185640962217,
        "vocab_size-1-nopunct": 2438,
        "unique-1-nopunct": 1163,
        "entropy-1-nopunct": 8.250323457153328,
        "distinct-2-nopunct": 0.24036881810561608,
        "vocab_size-2-nopunct": 7169,
        "unique-2-nopunct": 4299,
        "entropy-2-nopunct": 11.031128159022975,
        "cond_entropy-2-nopunct": 2.9586341020573634,
        "distinct-3-nopunct": 0.4014940676724769,
        "vocab_size-3-nopunct": 10964,
        "unique-3-nopunct": 7595,
        "entropy-3-nopunct": 12.23307699252753,
        "cond_entropy-3-nopunct": 1.3000992302060685,
        "msttr-100": 0.68418,
        "msttr-100_nopunct": 0.71046,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5857995562361323
        },
        "rouge1": {
            "precision": 0.64001,
            "recall": 0.6124,
            "fmeasure": 0.61486
        },
        "rouge2": {
            "precision": 0.40869,
            "recall": 0.39014,
            "fmeasure": 0.39168
        },
        "rougeL": {
            "precision": 0.56037,
            "recall": 0.53712,
            "fmeasure": 0.53884
        },
        "rougeLsum": {
            "precision": 0.56037,
            "recall": 0.53712,
            "fmeasure": 0.53884
        },
        "nist": 6.870970222429393,
        "bleu": 33.04254,
        "nubia": {
            "semantic_relation": 4.01577,
            "contradiction": 6.3777,
            "irrelevancy": 21.81531,
            "logical_agreement": 71.80699,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.60813,
            "nubia_score": 0.7078
        },
        "bertscore": {
            "precision": 0.88629,
            "recall": 0.87731,
            "f1": 0.88136
        },
        "meteor": 0.32651022537590646,
        "bleurt": -0.04187
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 369,
        "total_length": 3865,
        "mean_pred_length": 10.474254742547425,
        "std_pred_length": 2.933779262138594,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.20620957309184992,
        "vocab_size-1": 797,
        "unique-1": 435,
        "entropy-1": 7.314655499841244,
        "distinct-2": 0.5054347826086957,
        "vocab_size-2": 1767,
        "unique-2": 1186,
        "entropy-2": 10.172981853659559,
        "cond_entropy-2": 2.443952884477898,
        "distinct-3": 0.7048289094979213,
        "vocab_size-3": 2204,
        "unique-3": 1743,
        "entropy-3": 10.827932560468604,
        "cond_entropy-3": 0.7541854837312283,
        "total_length-nopunct": 3369,
        "mean_pred_length-nopunct": 9.130081300813009,
        "std_pred_length-nopunct": 2.559723529257741,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.2341941228851291,
        "vocab_size-1-nopunct": 789,
        "unique-1-nopunct": 433,
        "entropy-1-nopunct": 7.5889568518381285,
        "distinct-2-nopunct": 0.48333333333333334,
        "vocab_size-2-nopunct": 1450,
        "unique-2-nopunct": 945,
        "entropy-2-nopunct": 9.859146037384303,
        "cond_entropy-2-nopunct": 2.5934082854469778,
        "distinct-3-nopunct": 0.6902318510072216,
        "vocab_size-3-nopunct": 1816,
        "unique-3-nopunct": 1416,
        "entropy-3-nopunct": 10.538454454146281,
        "cond_entropy-3-nopunct": 0.8241096408586421,
        "msttr-100": 0.60632,
        "msttr-100_nopunct": 0.65061,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2409957627118644,
            "2": 0.6247960848287113,
            "3": 0.8054448871181938,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.74283,
            "recall": 0.73438,
            "fmeasure": 0.73046
        },
        "rouge2": {
            "precision": 0.50234,
            "recall": 0.49505,
            "fmeasure": 0.492
        },
        "rougeL": {
            "precision": 0.65836,
            "recall": 0.64874,
            "fmeasure": 0.64551
        },
        "rougeLsum": {
            "precision": 0.65836,
            "recall": 0.64874,
            "fmeasure": 0.64551
        },
        "nist": 7.807203601400431,
        "bleu": 47.34337,
        "nubia": {
            "semantic_relation": 4.28138,
            "contradiction": 14.88692,
            "irrelevancy": 10.63481,
            "logical_agreement": 74.47826,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.26334,
            "nubia_score": 0.73053
        },
        "bertscore": {
            "precision": 0.92247,
            "recall": 0.92513,
            "f1": 0.92272
        },
        "meteor": 0.4091378586441632,
        "bleurt": 0.20047
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 106,
        "total_length": 2257,
        "mean_pred_length": 21.29245283018868,
        "std_pred_length": 4.444557793934518,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 35,
        "distinct-1": 0.3961010190518387,
        "vocab_size-1": 894,
        "unique-1": 655,
        "entropy-1": 8.187412918086313,
        "distinct-2": 0.8098558809855881,
        "vocab_size-2": 1742,
        "unique-2": 1585,
        "entropy-2": 10.476750479416772,
        "cond_entropy-2": 2.103300777061997,
        "distinct-3": 0.9427872860635697,
        "vocab_size-3": 1928,
        "unique-3": 1870,
        "entropy-3": 10.840436822736502,
        "cond_entropy-3": 0.364172510815328,
        "total_length-nopunct": 2111,
        "mean_pred_length-nopunct": 19.91509433962264,
        "std_pred_length-nopunct": 4.251787469901718,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.4197063003315964,
        "vocab_size-1-nopunct": 886,
        "unique-1-nopunct": 652,
        "entropy-1-nopunct": 8.295066006655624,
        "distinct-2-nopunct": 0.8154613466334164,
        "vocab_size-2-nopunct": 1635,
        "unique-2-nopunct": 1490,
        "entropy-2-nopunct": 10.391739100151653,
        "cond_entropy-2-nopunct": 2.185013568217958,
        "distinct-3-nopunct": 0.9494470774091627,
        "vocab_size-3-nopunct": 1803,
        "unique-3-nopunct": 1750,
        "entropy-3-nopunct": 10.757532153268427,
        "cond_entropy-3-nopunct": 0.37122945967273796,
        "msttr-100": 0.72409,
        "msttr-100_nopunct": 0.73667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.31047265987025024
        },
        "rouge1": {
            "precision": 0.37611,
            "recall": 0.34345,
            "fmeasure": 0.35257
        },
        "rouge2": {
            "precision": 0.1254,
            "recall": 0.11261,
            "fmeasure": 0.11584
        },
        "rougeL": {
            "precision": 0.30211,
            "recall": 0.27554,
            "fmeasure": 0.28284
        },
        "rougeLsum": {
            "precision": 0.30211,
            "recall": 0.27554,
            "fmeasure": 0.28284
        },
        "nist": 2.8603351346081527,
        "bleu": 7.28588,
        "nubia": {
            "semantic_relation": 2.49642,
            "contradiction": 23.06871,
            "irrelevancy": 65.62949,
            "logical_agreement": 11.3018,
            "grammar_ref": 3.80483,
            "grammar_hyp": 3.64639,
            "nubia_score": 0.3325
        },
        "bertscore": {
            "precision": 0.82169,
            "recall": 0.81006,
            "f1": 0.81553
        },
        "meteor": 0.1416317507976928,
        "bleurt": -0.3963
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 350,
        "total_length": 8750,
        "mean_pred_length": 25.0,
        "std_pred_length": 6.863984681967589,
        "median_pred_length": 24.0,
        "min_pred_length": 10,
        "max_pred_length": 56,
        "distinct-1": 0.1176,
        "vocab_size-1": 1029,
        "unique-1": 333,
        "entropy-1": 7.683991167702998,
        "distinct-2": 0.32821428571428574,
        "vocab_size-2": 2757,
        "unique-2": 1422,
        "entropy-2": 10.536676281400949,
        "cond_entropy-2": 2.703381892741309,
        "distinct-3": 0.5147826086956522,
        "vocab_size-3": 4144,
        "unique-3": 2725,
        "entropy-3": 11.522257111078082,
        "cond_entropy-3": 1.0413399695659291,
        "total_length-nopunct": 7743,
        "mean_pred_length-nopunct": 22.122857142857143,
        "std_pred_length-nopunct": 6.216962313555011,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.13173188686555598,
        "vocab_size-1-nopunct": 1020,
        "unique-1-nopunct": 333,
        "entropy-1-nopunct": 7.931602431564336,
        "distinct-2-nopunct": 0.34289192479372377,
        "vocab_size-2-nopunct": 2535,
        "unique-2-nopunct": 1386,
        "entropy-2-nopunct": 10.426415263625461,
        "cond_entropy-2-nopunct": 2.62739707998355,
        "distinct-3-nopunct": 0.530029816839415,
        "vocab_size-3-nopunct": 3733,
        "unique-3-nopunct": 2529,
        "entropy-3-nopunct": 11.380269251715893,
        "cond_entropy-3-nopunct": 0.9958101417311223,
        "msttr-100": 0.62379,
        "msttr-100_nopunct": 0.66623,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23630441220017767,
            "2": 0.5457953936797001,
            "3": 0.8271028037383178,
            "4": 0.3,
            "5": 0.6551724137931034
        },
        "rouge1": {
            "precision": 0.68156,
            "recall": 0.72193,
            "fmeasure": 0.69198
        },
        "rouge2": {
            "precision": 0.43357,
            "recall": 0.45741,
            "fmeasure": 0.43931
        },
        "rougeL": {
            "precision": 0.5389,
            "recall": 0.57084,
            "fmeasure": 0.54705
        },
        "rougeLsum": {
            "precision": 0.5389,
            "recall": 0.57084,
            "fmeasure": 0.54705
        },
        "nist": 7.504109740278841,
        "bleu": 40.05005,
        "nubia": {
            "semantic_relation": 4.13379,
            "contradiction": 16.39476,
            "irrelevancy": 14.55477,
            "logical_agreement": 69.05048,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.41912,
            "nubia_score": 0.69857
        },
        "bertscore": {
            "precision": 0.89811,
            "recall": 0.90319,
            "f1": 0.89896
        },
        "meteor": 0.36985383216388784,
        "bleurt": 0.03321
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 114,
        "total_length": 4814,
        "mean_pred_length": 42.228070175438596,
        "std_pred_length": 10.344110187639282,
        "median_pred_length": 42.0,
        "min_pred_length": 19,
        "max_pred_length": 93,
        "distinct-1": 0.15060240963855423,
        "vocab_size-1": 725,
        "unique-1": 251,
        "entropy-1": 7.521609371815348,
        "distinct-2": 0.3546808510638298,
        "vocab_size-2": 1667,
        "unique-2": 817,
        "entropy-2": 9.986527805874921,
        "cond_entropy-2": 2.379683685093952,
        "distinct-3": 0.5074138682948103,
        "vocab_size-3": 2327,
        "unique-3": 1419,
        "entropy-3": 10.750974545835447,
        "cond_entropy-3": 0.7885562652888568,
        "total_length-nopunct": 4280,
        "mean_pred_length-nopunct": 37.54385964912281,
        "std_pred_length-nopunct": 8.970849820759314,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 73,
        "distinct-1-nopunct": 0.1677570093457944,
        "vocab_size-1-nopunct": 718,
        "unique-1-nopunct": 249,
        "entropy-1-nopunct": 7.739488243440881,
        "distinct-2-nopunct": 0.3732597215554489,
        "vocab_size-2-nopunct": 1555,
        "unique-2-nopunct": 793,
        "entropy-2-nopunct": 9.941199727132913,
        "cond_entropy-2-nopunct": 2.2645875008175844,
        "distinct-3-nopunct": 0.5261599210266535,
        "vocab_size-3-nopunct": 2132,
        "unique-3-nopunct": 1336,
        "entropy-3-nopunct": 10.637349197751984,
        "cond_entropy-3-nopunct": 0.711531583663764,
        "msttr-100": 0.60188,
        "msttr-100_nopunct": 0.645,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.210079275198188,
            "2": 0.6012544802867383,
            "3": 0.7794486215538847
        },
        "rouge1": {
            "precision": 0.70187,
            "recall": 0.65623,
            "fmeasure": 0.67163
        },
        "rouge2": {
            "precision": 0.41222,
            "recall": 0.381,
            "fmeasure": 0.39203
        },
        "rougeL": {
            "precision": 0.49978,
            "recall": 0.47293,
            "fmeasure": 0.48088
        },
        "rougeLsum": {
            "precision": 0.49978,
            "recall": 0.47293,
            "fmeasure": 0.48088
        },
        "nist": 7.504036597368873,
        "bleu": 41.75463,
        "nubia": {
            "semantic_relation": 3.82746,
            "contradiction": 17.45422,
            "irrelevancy": 11.81853,
            "logical_agreement": 70.72725,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.11839,
            "nubia_score": 0.64683
        },
        "bertscore": {
            "precision": 0.89547,
            "recall": 0.88428,
            "f1": 0.88859
        },
        "meteor": 0.32928640764235995,
        "bleurt": -0.09526
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 305,
        "total_length": 9718,
        "mean_pred_length": 31.862295081967215,
        "std_pred_length": 7.659177799781406,
        "median_pred_length": 31.0,
        "min_pred_length": 16,
        "max_pred_length": 62,
        "distinct-1": 0.11710228442066269,
        "vocab_size-1": 1138,
        "unique-1": 394,
        "entropy-1": 7.7035991241226895,
        "distinct-2": 0.3324126208435143,
        "vocab_size-2": 3129,
        "unique-2": 1666,
        "entropy-2": 10.650032304161636,
        "cond_entropy-2": 2.82898975779158,
        "distinct-3": 0.5253623188405797,
        "vocab_size-3": 4785,
        "unique-3": 3208,
        "entropy-3": 11.71804677374939,
        "cond_entropy-3": 1.1101163858107967,
        "total_length-nopunct": 8583,
        "mean_pred_length-nopunct": 28.140983606557377,
        "std_pred_length-nopunct": 7.125327189477568,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.1315390888966562,
        "vocab_size-1-nopunct": 1129,
        "unique-1-nopunct": 393,
        "entropy-1-nopunct": 7.963135793976539,
        "distinct-2-nopunct": 0.3569702826769751,
        "vocab_size-2-nopunct": 2955,
        "unique-2-nopunct": 1676,
        "entropy-2-nopunct": 10.602104088583788,
        "cond_entropy-2-nopunct": 2.750410480094982,
        "distinct-3-nopunct": 0.5507337263263514,
        "vocab_size-3-nopunct": 4391,
        "unique-3-nopunct": 3060,
        "entropy-3-nopunct": 11.613618771717153,
        "cond_entropy-3-nopunct": 1.0506245441689686,
        "msttr-100": 0.60959,
        "msttr-100_nopunct": 0.65588,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.21684387241186345,
            "2": 0.5767841011743451,
            "3": 0.8106420184861354
        },
        "rouge1": {
            "precision": 0.67232,
            "recall": 0.69622,
            "fmeasure": 0.67518
        },
        "rouge2": {
            "precision": 0.40586,
            "recall": 0.4211,
            "fmeasure": 0.40798
        },
        "rougeL": {
            "precision": 0.50479,
            "recall": 0.52455,
            "fmeasure": 0.5074
        },
        "rougeLsum": {
            "precision": 0.50479,
            "recall": 0.52455,
            "fmeasure": 0.5074
        },
        "nist": 7.618408368324953,
        "bleu": 40.18218,
        "nubia": {
            "semantic_relation": 4.00374,
            "contradiction": 19.97976,
            "irrelevancy": 13.06313,
            "logical_agreement": 66.9571,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.26185,
            "nubia_score": 0.6578
        },
        "bertscore": {
            "precision": 0.89013,
            "recall": 0.89363,
            "f1": 0.89041
        },
        "meteor": 0.35096023213973393,
        "bleurt": -0.03517
    },
    "schema_guided_dialog_challenge_test_backtranslation_parent": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6281,
        "mean_pred_length": 12.562,
        "std_pred_length": 7.434121064389522,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 49,
        "distinct-1": 0.1504537494029613,
        "vocab_size-1": 945,
        "unique-1": 545,
        "entropy-1": 7.690544230522189,
        "distinct-2": 0.4267427780660785,
        "vocab_size-2": 2467,
        "unique-2": 1688,
        "entropy-2": 10.280638274936445,
        "cond_entropy-2": 2.3334777715125536,
        "distinct-3": 0.6146563150918387,
        "vocab_size-3": 3246,
        "unique-3": 2560,
        "entropy-3": 11.054561309782766,
        "cond_entropy-3": 0.7911071508705518,
        "total_length-nopunct": 5493,
        "mean_pred_length-nopunct": 10.986,
        "std_pred_length-nopunct": 6.803955026306391,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.16985253959584926,
        "vocab_size-1-nopunct": 933,
        "unique-1-nopunct": 542,
        "entropy-1-nopunct": 7.876935692688774,
        "distinct-2-nopunct": 0.4438213498898458,
        "vocab_size-2-nopunct": 2216,
        "unique-2-nopunct": 1558,
        "entropy-2-nopunct": 10.11477016024412,
        "cond_entropy-2-nopunct": 2.3700366011539202,
        "distinct-3-nopunct": 0.6321762349799733,
        "vocab_size-3-nopunct": 2841,
        "unique-3-nopunct": 2294,
        "entropy-3-nopunct": 10.859907402446257,
        "cond_entropy-3-nopunct": 0.7771729820077625,
        "msttr-100": 0.66968,
        "msttr-100_nopunct": 0.70222,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5810459940652819
        },
        "rouge1": {
            "precision": 0.59004,
            "recall": 0.56915,
            "fmeasure": 0.56647
        },
        "rouge2": {
            "precision": 0.37851,
            "recall": 0.36542,
            "fmeasure": 0.36349
        },
        "rougeL": {
            "precision": 0.53511,
            "recall": 0.51686,
            "fmeasure": 0.51457
        },
        "rougeLsum": {
            "precision": 0.53511,
            "recall": 0.51686,
            "fmeasure": 0.51457
        },
        "nist": 6.161107242040539,
        "bleu": 33.70791,
        "nubia": {
            "semantic_relation": 3.67389,
            "contradiction": 5.88916,
            "irrelevancy": 21.29014,
            "logical_agreement": 72.8207,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.44341,
            "nubia_score": 0.67385
        },
        "bertscore": {
            "precision": 0.87868,
            "recall": 0.87162,
            "f1": 0.87459
        },
        "meteor": 0.32523328280313,
        "bleurt": -0.02893
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 79,
        "total_length": 3650,
        "mean_pred_length": 46.20253164556962,
        "std_pred_length": 13.29926213508126,
        "median_pred_length": 46.0,
        "min_pred_length": 21,
        "max_pred_length": 96,
        "distinct-1": 0.16,
        "vocab_size-1": 584,
        "unique-1": 234,
        "entropy-1": 7.388083645056388,
        "distinct-2": 0.3528423410809297,
        "vocab_size-2": 1260,
        "unique-2": 649,
        "entropy-2": 9.63696453167955,
        "cond_entropy-2": 2.1765511762896064,
        "distinct-3": 0.47623138602520043,
        "vocab_size-3": 1663,
        "unique-3": 1015,
        "entropy-3": 10.247358776984683,
        "cond_entropy-3": 0.6296194968433773,
        "total_length-nopunct": 3251,
        "mean_pred_length-nopunct": 41.151898734177216,
        "std_pred_length-nopunct": 12.022224785782033,
        "median_pred_length-nopunct": 40.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.17779144878498923,
        "vocab_size-1-nopunct": 578,
        "unique-1-nopunct": 232,
        "entropy-1-nopunct": 7.586149312661331,
        "distinct-2-nopunct": 0.37105926860025223,
        "vocab_size-2-nopunct": 1177,
        "unique-2-nopunct": 630,
        "entropy-2-nopunct": 9.583286348040316,
        "cond_entropy-2-nopunct": 2.049564508138921,
        "distinct-3-nopunct": 0.4943420627222761,
        "vocab_size-3-nopunct": 1529,
        "unique-3-nopunct": 968,
        "entropy-3-nopunct": 10.129362052290926,
        "cond_entropy-3-nopunct": 0.5571052360007661,
        "msttr-100": 0.61583,
        "msttr-100_nopunct": 0.65531,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23179271708683474,
            "2": 0.4715984147952444,
            "3": 0.769010863350486
        },
        "rouge1": {
            "precision": 0.7249,
            "recall": 0.62849,
            "fmeasure": 0.66506
        },
        "rouge2": {
            "precision": 0.43968,
            "recall": 0.37872,
            "fmeasure": 0.40206
        },
        "rougeL": {
            "precision": 0.49716,
            "recall": 0.43385,
            "fmeasure": 0.45752
        },
        "rougeLsum": {
            "precision": 0.49716,
            "recall": 0.43385,
            "fmeasure": 0.45752
        },
        "nist": 7.163093932576768,
        "bleu": 43.24083,
        "nubia": {
            "semantic_relation": 3.71676,
            "contradiction": 11.12545,
            "irrelevancy": 8.57442,
            "logical_agreement": 80.30014,
            "grammar_ref": 3.96506,
            "grammar_hyp": 3.91066,
            "nubia_score": 0.64501
        },
        "bertscore": {
            "precision": 0.89785,
            "recall": 0.87688,
            "f1": 0.88588
        },
        "meteor": 0.3197835770164398,
        "bleurt": -0.14274
    },
    "schema_guided_dialog_challenge_test_bfp02_parent": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6404,
        "mean_pred_length": 12.808,
        "std_pred_length": 7.577013659747487,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 44,
        "distinct-1": 0.14678326046221113,
        "vocab_size-1": 940,
        "unique-1": 513,
        "entropy-1": 7.758806021112132,
        "distinct-2": 0.43089430894308944,
        "vocab_size-2": 2544,
        "unique-2": 1692,
        "entropy-2": 10.4227075004728,
        "cond_entropy-2": 2.423769630288494,
        "distinct-3": 0.6278682457438934,
        "vocab_size-3": 3393,
        "unique-3": 2644,
        "entropy-3": 11.235963868851513,
        "cond_entropy-3": 0.8427012849440427,
        "total_length-nopunct": 5641,
        "mean_pred_length-nopunct": 11.282,
        "std_pred_length-nopunct": 6.979575631798828,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.1643325651480234,
        "vocab_size-1-nopunct": 927,
        "unique-1-nopunct": 509,
        "entropy-1-nopunct": 7.932149247531137,
        "distinct-2-nopunct": 0.44524411593075275,
        "vocab_size-2-nopunct": 2289,
        "unique-2-nopunct": 1556,
        "entropy-2-nopunct": 10.259705941076177,
        "cond_entropy-2-nopunct": 2.4585297535293296,
        "distinct-3-nopunct": 0.6444109412018092,
        "vocab_size-3-nopunct": 2992,
        "unique-3-nopunct": 2379,
        "entropy-3-nopunct": 11.056252727933598,
        "cond_entropy-3-nopunct": 0.8424701381235754,
        "msttr-100": 0.68547,
        "msttr-100_nopunct": 0.71214,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5663238626459822
        },
        "rouge1": {
            "precision": 0.5946,
            "recall": 0.55657,
            "fmeasure": 0.56352
        },
        "rouge2": {
            "precision": 0.37903,
            "recall": 0.35528,
            "fmeasure": 0.35886
        },
        "rougeL": {
            "precision": 0.54183,
            "recall": 0.50663,
            "fmeasure": 0.51343
        },
        "rougeLsum": {
            "precision": 0.54183,
            "recall": 0.50663,
            "fmeasure": 0.51343
        },
        "nist": 6.2001716370198405,
        "bleu": 32.53762,
        "nubia": {
            "semantic_relation": 3.64445,
            "contradiction": 6.24789,
            "irrelevancy": 20.68029,
            "logical_agreement": 73.07182,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.61945,
            "nubia_score": 0.65112
        },
        "bertscore": {
            "precision": 0.87846,
            "recall": 0.86391,
            "f1": 0.87065
        },
        "meteor": 0.31715518395526116,
        "bleurt": -0.06914
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 297,
        "total_length": 2974,
        "mean_pred_length": 10.013468013468014,
        "std_pred_length": 2.665369714878281,
        "median_pred_length": 9.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.22562205783456624,
        "vocab_size-1": 671,
        "unique-1": 361,
        "entropy-1": 7.210284651257273,
        "distinct-2": 0.5345536047814718,
        "vocab_size-2": 1431,
        "unique-2": 976,
        "entropy-2": 9.93279736866399,
        "cond_entropy-2": 2.291334081813863,
        "distinct-3": 0.730672268907563,
        "vocab_size-3": 1739,
        "unique-3": 1391,
        "entropy-3": 10.517419147264327,
        "cond_entropy-3": 0.6677703493280636,
        "total_length-nopunct": 2601,
        "mean_pred_length-nopunct": 8.757575757575758,
        "std_pred_length-nopunct": 2.3998775603907068,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.2552864282968089,
        "vocab_size-1-nopunct": 664,
        "unique-1-nopunct": 359,
        "entropy-1-nopunct": 7.4920653070396215,
        "distinct-2-nopunct": 0.515625,
        "vocab_size-2-nopunct": 1188,
        "unique-2-nopunct": 791,
        "entropy-2-nopunct": 9.636877968450895,
        "cond_entropy-2-nopunct": 2.4547491964094474,
        "distinct-3-nopunct": 0.7204783258594918,
        "vocab_size-3-nopunct": 1446,
        "unique-3-nopunct": 1145,
        "entropy-3-nopunct": 10.242851010348682,
        "cond_entropy-3-nopunct": 0.741012708759043,
        "msttr-100": 0.60724,
        "msttr-100_nopunct": 0.65462,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2359781121751026,
            "2": 0.6507772020725389,
            "3": 0.826677994902294,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.76911,
            "recall": 0.75486,
            "fmeasure": 0.75399
        },
        "rouge2": {
            "precision": 0.53677,
            "recall": 0.52363,
            "fmeasure": 0.52333
        },
        "rougeL": {
            "precision": 0.68835,
            "recall": 0.67266,
            "fmeasure": 0.67231
        },
        "rougeLsum": {
            "precision": 0.68835,
            "recall": 0.67266,
            "fmeasure": 0.67231
        },
        "nist": 8.113981855567026,
        "bleu": 52.1869,
        "nubia": {
            "semantic_relation": 4.41157,
            "contradiction": 13.03737,
            "irrelevancy": 7.68528,
            "logical_agreement": 79.27736,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.25092,
            "nubia_score": 0.7707
        },
        "bertscore": {
            "precision": 0.93327,
            "recall": 0.93539,
            "f1": 0.93328
        },
        "meteor": 0.43014045848723625,
        "bleurt": 0.28387
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.1,
            "3": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.49333,
            "recall": 0.4746,
            "fmeasure": 0.47881
        },
        "rouge2": {
            "precision": 0.21528,
            "recall": 0.20995,
            "fmeasure": 0.21026
        },
        "rougeL": {
            "precision": 0.42333,
            "recall": 0.44901,
            "fmeasure": 0.43382
        },
        "rougeLsum": {
            "precision": 0.42333,
            "recall": 0.44901,
            "fmeasure": 0.43382
        },
        "nist": 2.249130934027304,
        "bleu": 12.19359,
        "nubia": {
            "semantic_relation": 3.23553,
            "contradiction": 2.03333,
            "irrelevancy": 67.19944,
            "logical_agreement": 30.76724,
            "grammar_ref": 5.71002,
            "grammar_hyp": 4.81315,
            "nubia_score": 0.48836
        },
        "bertscore": {
            "precision": 0.80871,
            "recall": 0.8563,
            "f1": 0.82057
        },
        "meteor": 0.24200393009574994,
        "bleurt": -0.0073
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 72,
        "total_length": 891,
        "mean_pred_length": 12.375,
        "std_pred_length": 3.2121189787013393,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.3221099887766554,
        "vocab_size-1": 287,
        "unique-1": 178,
        "entropy-1": 6.593209786701892,
        "distinct-2": 0.6605616605616605,
        "vocab_size-2": 541,
        "unique-2": 410,
        "entropy-2": 8.728561778509086,
        "cond_entropy-2": 1.8747934716646282,
        "distinct-3": 0.8005354752342704,
        "vocab_size-3": 598,
        "unique-3": 508,
        "entropy-3": 9.069749812317376,
        "cond_entropy-3": 0.41125411967896186,
        "total_length-nopunct": 768,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.3658854166666667,
        "vocab_size-1-nopunct": 281,
        "unique-1-nopunct": 177,
        "entropy-1-nopunct": 6.71377443325763,
        "distinct-2-nopunct": 0.6436781609195402,
        "vocab_size-2-nopunct": 448,
        "unique-2-nopunct": 334,
        "entropy-2-nopunct": 8.432044282638762,
        "cond_entropy-2-nopunct": 1.9508422093401385,
        "distinct-3-nopunct": 0.7884615384615384,
        "vocab_size-3-nopunct": 492,
        "unique-3-nopunct": 414,
        "entropy-3-nopunct": 8.777837060230686,
        "cond_entropy-3-nopunct": 0.42757139273461975,
        "msttr-100": 0.60625,
        "msttr-100_nopunct": 0.64,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.25821596244131456,
            "2": 0.5287356321839081,
            "3": 0.729483282674772
        },
        "rouge1": {
            "precision": 0.63442,
            "recall": 0.64991,
            "fmeasure": 0.63337
        },
        "rouge2": {
            "precision": 0.36035,
            "recall": 0.37717,
            "fmeasure": 0.36275
        },
        "rougeL": {
            "precision": 0.53466,
            "recall": 0.55003,
            "fmeasure": 0.53497
        },
        "rougeLsum": {
            "precision": 0.53466,
            "recall": 0.55003,
            "fmeasure": 0.53497
        },
        "nist": 5.430771259872023,
        "bleu": 30.62445,
        "nubia": {
            "semantic_relation": 3.74431,
            "contradiction": 22.51636,
            "irrelevancy": 22.80164,
            "logical_agreement": 54.68201,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.31461,
            "nubia_score": 0.56486
        },
        "bertscore": {
            "precision": 0.87793,
            "recall": 0.8828,
            "f1": 0.87917
        },
        "meteor": 0.3398254307257362,
        "bleurt": -0.14357
    },
    "schema_guided_dialog_challenge_test_bfp05_parent": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6154,
        "mean_pred_length": 12.308,
        "std_pred_length": 7.255696796311159,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 42,
        "distinct-1": 0.15290867728306792,
        "vocab_size-1": 941,
        "unique-1": 529,
        "entropy-1": 7.688099526827733,
        "distinct-2": 0.4395118500176866,
        "vocab_size-2": 2485,
        "unique-2": 1712,
        "entropy-2": 10.317745207137829,
        "cond_entropy-2": 2.380690295173489,
        "distinct-3": 0.6274738067520372,
        "vocab_size-3": 3234,
        "unique-3": 2560,
        "entropy-3": 11.082729076840147,
        "cond_entropy-3": 0.7879877239846698,
        "total_length-nopunct": 5425,
        "mean_pred_length-nopunct": 10.85,
        "std_pred_length-nopunct": 6.689058229676282,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.17142857142857143,
        "vocab_size-1-nopunct": 930,
        "unique-1-nopunct": 526,
        "entropy-1-nopunct": 7.864131542366209,
        "distinct-2-nopunct": 0.44954314720812183,
        "vocab_size-2-nopunct": 2214,
        "unique-2-nopunct": 1551,
        "entropy-2-nopunct": 10.138816262547598,
        "cond_entropy-2-nopunct": 2.40683758568034,
        "distinct-3-nopunct": 0.6381920903954802,
        "vocab_size-3-nopunct": 2824,
        "unique-3-nopunct": 2267,
        "entropy-3-nopunct": 10.887504573574711,
        "cond_entropy-3-nopunct": 0.7832508349827362,
        "msttr-100": 0.67787,
        "msttr-100_nopunct": 0.70796,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5732869182850862
        },
        "rouge1": {
            "precision": 0.59525,
            "recall": 0.56401,
            "fmeasure": 0.56856
        },
        "rouge2": {
            "precision": 0.37357,
            "recall": 0.34935,
            "fmeasure": 0.35404
        },
        "rougeL": {
            "precision": 0.54005,
            "recall": 0.50933,
            "fmeasure": 0.5148
        },
        "rougeLsum": {
            "precision": 0.54005,
            "recall": 0.50933,
            "fmeasure": 0.5148
        },
        "nist": 6.108680735738482,
        "bleu": 33.14959,
        "nubia": {
            "semantic_relation": 3.62659,
            "contradiction": 6.9936,
            "irrelevancy": 20.47204,
            "logical_agreement": 72.53436,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.54362,
            "nubia_score": 0.65013
        },
        "bertscore": {
            "precision": 0.878,
            "recall": 0.86899,
            "f1": 0.87304
        },
        "meteor": 0.3185990664537251,
        "bleurt": -0.04324
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 19,
        "total_length": 326,
        "mean_pred_length": 17.157894736842106,
        "std_pred_length": 11.070411763818845,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 45,
        "distinct-1": 0.40797546012269936,
        "vocab_size-1": 133,
        "unique-1": 80,
        "entropy-1": 6.278196835207978,
        "distinct-2": 0.6840390879478827,
        "vocab_size-2": 210,
        "unique-2": 157,
        "entropy-2": 7.442212588236432,
        "cond_entropy-2": 1.0012526924967537,
        "distinct-3": 0.8090277777777778,
        "vocab_size-3": 233,
        "unique-3": 190,
        "entropy-3": 7.747186786296966,
        "cond_entropy-3": 0.2909746230990936,
        "total_length-nopunct": 267,
        "mean_pred_length-nopunct": 14.052631578947368,
        "std_pred_length-nopunct": 9.467249276546273,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.4794007490636704,
        "vocab_size-1-nopunct": 128,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.398465755073174,
        "distinct-2-nopunct": 0.7258064516129032,
        "vocab_size-2-nopunct": 180,
        "unique-2-nopunct": 140,
        "entropy-2-nopunct": 7.238611544328307,
        "cond_entropy-2-nopunct": 0.8492604878873067,
        "distinct-3-nopunct": 0.8253275109170306,
        "vocab_size-3-nopunct": 189,
        "unique-3-nopunct": 159,
        "entropy-3-nopunct": 7.4451477577147305,
        "cond_entropy-3-nopunct": 0.24407381406378484,
        "msttr-100": 0.57,
        "msttr-100_nopunct": 0.65,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.3067484662576687,
            "2": 0.5520833333333334,
            "3": 0.782608695652174
        },
        "rouge1": {
            "precision": 0.30225,
            "recall": 0.34127,
            "fmeasure": 0.31224
        },
        "rouge2": {
            "precision": 0.19246,
            "recall": 0.22281,
            "fmeasure": 0.19296
        },
        "rougeL": {
            "precision": 0.27893,
            "recall": 0.32038,
            "fmeasure": 0.28997
        },
        "rougeLsum": {
            "precision": 0.27893,
            "recall": 0.32038,
            "fmeasure": 0.28997
        },
        "nist": 5.86565052745929,
        "bleu": 42.34179,
        "nubia": {
            "semantic_relation": 3.74068,
            "contradiction": 32.88581,
            "irrelevancy": 20.01814,
            "logical_agreement": 47.09605,
            "grammar_ref": 2.97301,
            "grammar_hyp": 2.96796,
            "nubia_score": 0.72909
        },
        "bertscore": {
            "precision": 0.9515,
            "recall": 0.94362,
            "f1": 0.94678
        },
        "meteor": 0.6283235494354458,
        "bleurt": 0.12453
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 1295,
        "total_length": 38868,
        "mean_pred_length": 30.013899613899614,
        "std_pred_length": 11.45876440565074,
        "median_pred_length": 29.0,
        "min_pred_length": 8,
        "max_pred_length": 96,
        "distinct-1": 0.04332612946382628,
        "vocab_size-1": 1684,
        "unique-1": 472,
        "entropy-1": 7.844098282343245,
        "distinct-2": 0.15234343810715142,
        "vocab_size-2": 5724,
        "unique-2": 2369,
        "entropy-2": 10.978094408911739,
        "cond_entropy-2": 3.004447041574183,
        "distinct-3": 0.2833948949776724,
        "vocab_size-3": 10281,
        "unique-3": 5552,
        "entropy-3": 12.25725950327317,
        "cond_entropy-3": 1.3342950700590444,
        "total_length-nopunct": 34479,
        "mean_pred_length-nopunct": 26.624710424710425,
        "std_pred_length-nopunct": 10.34320731965955,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.048580295252182486,
        "vocab_size-1-nopunct": 1675,
        "unique-1-nopunct": 472,
        "entropy-1-nopunct": 8.10548786119037,
        "distinct-2-nopunct": 0.16661644165863065,
        "vocab_size-2-nopunct": 5529,
        "unique-2-nopunct": 2453,
        "entropy-2-nopunct": 10.931450426001136,
        "cond_entropy-2-nopunct": 2.945126190185224,
        "distinct-3-nopunct": 0.3039919721534071,
        "vocab_size-3-nopunct": 9694,
        "unique-3-nopunct": 5480,
        "entropy-3-nopunct": 12.174492024572176,
        "cond_entropy-3-nopunct": 1.287600935121922,
        "msttr-100": 0.61884,
        "msttr-100_nopunct": 0.65794,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22400544032641959,
            "2": 0.5443482330915048,
            "3": 0.8042405732409257,
            "4": 0.5882352941176471,
            "5": 0.6551724137931034
        },
        "rouge1": {
            "precision": 0.68349,
            "recall": 0.69425,
            "fmeasure": 0.68013
        },
        "rouge2": {
            "precision": 0.42213,
            "recall": 0.42793,
            "fmeasure": 0.41933
        },
        "rougeL": {
            "precision": 0.52109,
            "recall": 0.53219,
            "fmeasure": 0.51953
        },
        "rougeLsum": {
            "precision": 0.52109,
            "recall": 0.53219,
            "fmeasure": 0.51953
        },
        "nist": 7.98494823180966,
        "bleu": 41.32829,
        "nubia": {
            "semantic_relation": 4.02882,
            "contradiction": 17.30642,
            "irrelevancy": 12.91609,
            "logical_agreement": 69.77749,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.34874,
            "nubia_score": 0.67799
        },
        "bertscore": {
            "precision": 0.8951,
            "recall": 0.89566,
            "f1": 0.8939
        },
        "meteor": 0.3477566653883049,
        "bleurt": -0.02563
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 106,
        "total_length": 2248,
        "mean_pred_length": 21.20754716981132,
        "std_pred_length": 4.343107706431168,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 34,
        "distinct-1": 0.4096975088967972,
        "vocab_size-1": 921,
        "unique-1": 671,
        "entropy-1": 8.291399188294431,
        "distinct-2": 0.8370681605975724,
        "vocab_size-2": 1793,
        "unique-2": 1619,
        "entropy-2": 10.599097798284182,
        "cond_entropy-2": 2.1154489871138487,
        "distinct-3": 0.9666011787819253,
        "vocab_size-3": 1968,
        "unique-3": 1914,
        "entropy-3": 10.91790971298078,
        "cond_entropy-3": 0.33150768652468227,
        "total_length-nopunct": 2096,
        "mean_pred_length-nopunct": 19.77358490566038,
        "std_pred_length-nopunct": 4.200815327124289,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.43559160305343514,
        "vocab_size-1-nopunct": 913,
        "unique-1-nopunct": 669,
        "entropy-1-nopunct": 8.411650217214019,
        "distinct-2-nopunct": 0.8402010050251256,
        "vocab_size-2-nopunct": 1672,
        "unique-2-nopunct": 1518,
        "entropy-2-nopunct": 10.494596658806438,
        "cond_entropy-2-nopunct": 2.183394283502009,
        "distinct-3-nopunct": 0.9686836518046709,
        "vocab_size-3-nopunct": 1825,
        "unique-3-nopunct": 1777,
        "entropy-3-nopunct": 10.811502218558655,
        "cond_entropy-3-nopunct": 0.33447590285476875,
        "msttr-100": 0.72773,
        "msttr-100_nopunct": 0.7475,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2897806812879141
        },
        "rouge1": {
            "precision": 0.33645,
            "recall": 0.31261,
            "fmeasure": 0.31843
        },
        "rouge2": {
            "precision": 0.09718,
            "recall": 0.09067,
            "fmeasure": 0.09191
        },
        "rougeL": {
            "precision": 0.23964,
            "recall": 0.22516,
            "fmeasure": 0.228
        },
        "rougeLsum": {
            "precision": 0.23964,
            "recall": 0.22516,
            "fmeasure": 0.228
        },
        "nist": 2.6844897085508888,
        "bleu": 5.25687,
        "nubia": {
            "semantic_relation": 2.49515,
            "contradiction": 24.41554,
            "irrelevancy": 67.42843,
            "logical_agreement": 8.15603,
            "grammar_ref": 3.75874,
            "grammar_hyp": 3.77219,
            "nubia_score": 0.31798
        },
        "bertscore": {
            "precision": 0.81385,
            "recall": 0.79878,
            "f1": 0.80597
        },
        "meteor": 0.13413613971181965,
        "bleurt": -0.48112
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 106,
        "total_length": 2232,
        "mean_pred_length": 21.056603773584907,
        "std_pred_length": 4.742084146295993,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.4018817204301075,
        "vocab_size-1": 897,
        "unique-1": 655,
        "entropy-1": 8.218550879953876,
        "distinct-2": 0.8254938852304797,
        "vocab_size-2": 1755,
        "unique-2": 1591,
        "entropy-2": 10.537197621736633,
        "cond_entropy-2": 2.128068612711229,
        "distinct-3": 0.9564356435643564,
        "vocab_size-3": 1932,
        "unique-3": 1874,
        "entropy-3": 10.874989266751541,
        "cond_entropy-3": 0.3493081898334352,
        "total_length-nopunct": 2072,
        "mean_pred_length-nopunct": 19.547169811320753,
        "std_pred_length-nopunct": 4.551864796114612,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.42905405405405406,
        "vocab_size-1-nopunct": 889,
        "unique-1-nopunct": 653,
        "entropy-1-nopunct": 8.348859753030718,
        "distinct-2-nopunct": 0.8331637843336724,
        "vocab_size-2-nopunct": 1638,
        "unique-2-nopunct": 1492,
        "entropy-2-nopunct": 10.444890503164373,
        "cond_entropy-2-nopunct": 2.195476958829425,
        "distinct-3-nopunct": 0.960752688172043,
        "vocab_size-3-nopunct": 1787,
        "unique-3-nopunct": 1737,
        "entropy-3-nopunct": 10.768802636913987,
        "cond_entropy-3-nopunct": 0.34380874151089463,
        "msttr-100": 0.71409,
        "msttr-100_nopunct": 0.7405,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2907834101382488
        },
        "rouge1": {
            "precision": 0.35572,
            "recall": 0.31562,
            "fmeasure": 0.3263
        },
        "rouge2": {
            "precision": 0.10662,
            "recall": 0.09255,
            "fmeasure": 0.09617
        },
        "rougeL": {
            "precision": 0.26973,
            "recall": 0.23826,
            "fmeasure": 0.24643
        },
        "rougeLsum": {
            "precision": 0.26973,
            "recall": 0.23826,
            "fmeasure": 0.24643
        },
        "nist": 2.7290204325324017,
        "bleu": 5.33986,
        "nubia": {
            "semantic_relation": 2.39697,
            "contradiction": 30.17476,
            "irrelevancy": 62.52982,
            "logical_agreement": 7.29542,
            "grammar_ref": 3.78639,
            "grammar_hyp": 3.72696,
            "nubia_score": 0.2911
        },
        "bertscore": {
            "precision": 0.81334,
            "recall": 0.79912,
            "f1": 0.80585
        },
        "meteor": 0.13226255929330183,
        "bleurt": -0.46287
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 106,
        "total_length": 2168,
        "mean_pred_length": 20.452830188679247,
        "std_pred_length": 4.328780549604682,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.40267527675276754,
        "vocab_size-1": 873,
        "unique-1": 658,
        "entropy-1": 8.113012131349457,
        "distinct-2": 0.8098933074684772,
        "vocab_size-2": 1670,
        "unique-2": 1506,
        "entropy-2": 10.435977140487086,
        "cond_entropy-2": 2.129739472899689,
        "distinct-3": 0.9468302658486708,
        "vocab_size-3": 1852,
        "unique-3": 1785,
        "entropy-3": 10.803742768702076,
        "cond_entropy-3": 0.3862080459282244,
        "total_length-nopunct": 2030,
        "mean_pred_length-nopunct": 19.150943396226417,
        "std_pred_length-nopunct": 4.136337941081912,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.42758620689655175,
        "vocab_size-1-nopunct": 868,
        "unique-1-nopunct": 656,
        "entropy-1-nopunct": 8.234887994886105,
        "distinct-2-nopunct": 0.8097713097713097,
        "vocab_size-2-nopunct": 1558,
        "unique-2-nopunct": 1408,
        "entropy-2-nopunct": 10.329970022271242,
        "cond_entropy-2-nopunct": 2.207882940553675,
        "distinct-3-nopunct": 0.9499449944994499,
        "vocab_size-3-nopunct": 1727,
        "unique-3-nopunct": 1667,
        "entropy-3-nopunct": 10.708126547172832,
        "cond_entropy-3-nopunct": 0.39848769625164493,
        "msttr-100": 0.70524,
        "msttr-100_nopunct": 0.724,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2704225352112676
        },
        "rouge1": {
            "precision": 0.33611,
            "recall": 0.30372,
            "fmeasure": 0.31117
        },
        "rouge2": {
            "precision": 0.10768,
            "recall": 0.09347,
            "fmeasure": 0.09752
        },
        "rougeL": {
            "precision": 0.25752,
            "recall": 0.23398,
            "fmeasure": 0.23881
        },
        "rougeLsum": {
            "precision": 0.25752,
            "recall": 0.23398,
            "fmeasure": 0.23881
        },
        "nist": 2.4978936042264377,
        "bleu": 5.45925,
        "nubia": {
            "semantic_relation": 2.23451,
            "contradiction": 36.08867,
            "irrelevancy": 54.75554,
            "logical_agreement": 9.1558,
            "grammar_ref": 3.81724,
            "grammar_hyp": 3.753,
            "nubia_score": 0.26851
        },
        "bertscore": {
            "precision": 0.81256,
            "recall": 0.79454,
            "f1": 0.80317
        },
        "meteor": 0.13018372207404977,
        "bleurt": -0.50048
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 106,
        "total_length": 2287,
        "mean_pred_length": 21.57547169811321,
        "std_pred_length": 7.1387173326067055,
        "median_pred_length": 20.5,
        "min_pred_length": 5,
        "max_pred_length": 68,
        "distinct-1": 0.39965019676432006,
        "vocab_size-1": 914,
        "unique-1": 669,
        "entropy-1": 8.20464410133418,
        "distinct-2": 0.8042182485098579,
        "vocab_size-2": 1754,
        "unique-2": 1566,
        "entropy-2": 10.507163936160504,
        "cond_entropy-2": 2.119130410717423,
        "distinct-3": 0.9368674698795181,
        "vocab_size-3": 1944,
        "unique-3": 1854,
        "entropy-3": 10.871047829121228,
        "cond_entropy-3": 0.3754445529978561,
        "total_length-nopunct": 2128,
        "mean_pred_length-nopunct": 20.07547169811321,
        "std_pred_length-nopunct": 6.481756856540687,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.4257518796992481,
        "vocab_size-1-nopunct": 906,
        "unique-1-nopunct": 666,
        "entropy-1-nopunct": 8.328816990199455,
        "distinct-2-nopunct": 0.8086053412462908,
        "vocab_size-2-nopunct": 1635,
        "unique-2-nopunct": 1466,
        "entropy-2-nopunct": 10.408857639907184,
        "cond_entropy-2-nopunct": 2.181718923580104,
        "distinct-3-nopunct": 0.9436325678496869,
        "vocab_size-3-nopunct": 1808,
        "unique-3-nopunct": 1732,
        "entropy-3-nopunct": 10.773576651100228,
        "cond_entropy-3-nopunct": 0.3823993446756204,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.72667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.26215953307393
        },
        "rouge1": {
            "precision": 0.3044,
            "recall": 0.29037,
            "fmeasure": 0.28986
        },
        "rouge2": {
            "precision": 0.08673,
            "recall": 0.07706,
            "fmeasure": 0.0799
        },
        "rougeL": {
            "precision": 0.23457,
            "recall": 0.22262,
            "fmeasure": 0.22308
        },
        "rougeLsum": {
            "precision": 0.23457,
            "recall": 0.22262,
            "fmeasure": 0.22308
        },
        "nist": 2.286923628517236,
        "bleu": 4.76204,
        "nubia": {
            "semantic_relation": 2.09317,
            "contradiction": 34.89597,
            "irrelevancy": 61.88819,
            "logical_agreement": 3.21585,
            "grammar_ref": 3.93729,
            "grammar_hyp": 3.78721,
            "nubia_score": 0.25693
        },
        "bertscore": {
            "precision": 0.80284,
            "recall": 0.79071,
            "f1": 0.79649
        },
        "meteor": 0.12136313269766273,
        "bleurt": -0.53179
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.4642857142857143
        },
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.4362,
            "fmeasure": 0.51918
        },
        "rouge2": {
            "precision": 0.37037,
            "recall": 0.2493,
            "fmeasure": 0.29746
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.33815,
            "fmeasure": 0.40303
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.33815,
            "fmeasure": 0.40303
        },
        "nist": 2.9042847393791016,
        "bleu": 33.58478,
        "nubia": {
            "semantic_relation": 2.59093,
            "contradiction": 52.49176,
            "irrelevancy": 35.86763,
            "logical_agreement": 11.64062,
            "grammar_ref": 4.14314,
            "grammar_hyp": 3.81738,
            "nubia_score": 0.24969
        },
        "bertscore": {
            "precision": 0.93523,
            "recall": 0.85538,
            "f1": 0.89353
        },
        "meteor": 0.25975130110185995,
        "bleurt": -0.46615
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_base/e2e_nlg_test",
        "N": 5,
        "total_length": 44,
        "mean_pred_length": 8.8,
        "std_pred_length": 0.7483314773547883,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 10,
        "distinct-1": 0.4318181818181818,
        "vocab_size-1": 19,
        "unique-1": 5,
        "entropy-1": 4.073210744553411,
        "distinct-2": 0.5641025641025641,
        "vocab_size-2": 22,
        "unique-2": 9,
        "entropy-2": 4.3361829878711236,
        "cond_entropy-2": 0.14300977911213772,
        "distinct-3": 0.6470588235294118,
        "vocab_size-3": 22,
        "unique-3": 12,
        "entropy-3": 4.337175341123076,
        "cond_entropy-3": -0.05808974519533622,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 7.8,
        "std_pred_length-nopunct": 0.7483314773547882,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.46153846153846156,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 4.019143808983936,
        "distinct-2-nopunct": 0.5882352941176471,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 4.1973257087065035,
        "cond_entropy-2-nopunct": 0.16572320993515824,
        "distinct-3-nopunct": 0.6896551724137931,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 4.211260736432281,
        "cond_entropy-3-nopunct": -0.0655202081171303,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.65397,
            "recall": 0.48477,
            "fmeasure": 0.50424
        },
        "rouge2": {
            "precision": 0.37381,
            "recall": 0.21818,
            "fmeasure": 0.24768
        },
        "rougeL": {
            "precision": 0.60675,
            "recall": 0.45271,
            "fmeasure": 0.46606
        },
        "rougeLsum": {
            "precision": 0.60675,
            "recall": 0.45271,
            "fmeasure": 0.46606
        },
        "nist": 1.1584778190719272,
        "bleu": 12.15204,
        "nubia": {
            "semantic_relation": 2.89259,
            "contradiction": 18.10595,
            "irrelevancy": 42.12701,
            "logical_agreement": 39.76705,
            "grammar_ref": 5.06674,
            "grammar_hyp": 5.71656,
            "nubia_score": 0.31537
        },
        "bertscore": {
            "precision": 0.89285,
            "recall": 0.82928,
            "f1": 0.85844
        },
        "meteor": 0.22250577795179702,
        "bleurt": -0.39693
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_base/e2e_nlg_test",
        "N": 120,
        "total_length": 1481,
        "mean_pred_length": 12.341666666666667,
        "std_pred_length": 5.065398690023213,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.05739365293720459,
        "vocab_size-1": 85,
        "unique-1": 4,
        "entropy-1": 5.250833984157013,
        "distinct-2": 0.09551800146950772,
        "vocab_size-2": 130,
        "unique-2": 9,
        "entropy-2": 6.260780555859201,
        "cond_entropy-2": 0.8399599655745971,
        "distinct-3": 0.13295729250604352,
        "vocab_size-3": 165,
        "unique-3": 26,
        "entropy-3": 6.697264000564664,
        "cond_entropy-3": 0.5412316661264892,
        "total_length-nopunct": 1333,
        "mean_pred_length-nopunct": 11.108333333333333,
        "std_pred_length-nopunct": 4.670467202420856,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.06301575393848462,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 5.312993025551713,
        "distinct-2-nopunct": 0.09810387469084914,
        "vocab_size-2-nopunct": 119,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 6.040889144428922,
        "cond_entropy-2-nopunct": 0.8973726049243589,
        "distinct-3-nopunct": 0.13998170173833485,
        "vocab_size-3-nopunct": 153,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 6.516320390523065,
        "cond_entropy-3-nopunct": 0.5827033717178441,
        "msttr-100": 0.26786,
        "msttr-100_nopunct": 0.25615,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6102598267821452
        },
        "rouge1": {
            "precision": 0.76143,
            "recall": 0.63777,
            "fmeasure": 0.66286
        },
        "rouge2": {
            "precision": 0.50036,
            "recall": 0.41592,
            "fmeasure": 0.43077
        },
        "rougeL": {
            "precision": 0.62134,
            "recall": 0.5206,
            "fmeasure": 0.53969
        },
        "rougeLsum": {
            "precision": 0.62134,
            "recall": 0.5206,
            "fmeasure": 0.53969
        },
        "nist": 4.384839683542606,
        "bleu": 27.73333,
        "nubia": {
            "semantic_relation": 4.14547,
            "contradiction": 1.47941,
            "irrelevancy": 21.62315,
            "logical_agreement": 76.89744,
            "grammar_ref": 5.42765,
            "grammar_hyp": 5.02086,
            "nubia_score": 0.74442
        },
        "bertscore": {
            "precision": 0.92032,
            "recall": 0.88591,
            "f1": 0.90193
        },
        "meteor": 0.3155251789080837,
        "bleurt": 0.04041
    },
    "cs_restaurants_val": {
        "predictions_file": "mT5_base/cs_restaurants_val",
        "N": 781,
        "total_length": 8215,
        "mean_pred_length": 10.518565941101153,
        "std_pred_length": 3.0406930257159615,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.0332318928788801,
        "vocab_size-1": 273,
        "unique-1": 80,
        "entropy-1": 6.116346655286214,
        "distinct-2": 0.0878396556362658,
        "vocab_size-2": 653,
        "unique-2": 249,
        "entropy-2": 7.570150690382749,
        "cond_entropy-2": 1.2320264641713423,
        "distinct-3": 0.15421614309334136,
        "vocab_size-3": 1026,
        "unique-3": 441,
        "entropy-3": 8.335991351241567,
        "cond_entropy-3": 0.8420459452594081,
        "total_length-nopunct": 6908,
        "mean_pred_length-nopunct": 8.845070422535212,
        "std_pred_length-nopunct": 2.6749306885193374,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.03894035900405327,
        "vocab_size-1-nopunct": 269,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.240805841588683,
        "distinct-2-nopunct": 0.08992981883466623,
        "vocab_size-2-nopunct": 551,
        "unique-2-nopunct": 206,
        "entropy-2-nopunct": 7.434424310090635,
        "cond_entropy-2-nopunct": 1.33481860316784,
        "distinct-3-nopunct": 0.16778900112233447,
        "vocab_size-3-nopunct": 897,
        "unique-3-nopunct": 395,
        "entropy-3-nopunct": 8.284510835139631,
        "cond_entropy-3-nopunct": 0.8987775938304666,
        "msttr-100": 0.49159,
        "msttr-100_nopunct": 0.51725,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_val.json",
        "local_recall": {
            "1": 0.43757396449704145
        },
        "rouge1": {
            "precision": 0.49855,
            "recall": 0.49446,
            "fmeasure": 0.48095
        },
        "rouge2": {
            "precision": 0.29942,
            "recall": 0.30009,
            "fmeasure": 0.28833
        },
        "rougeL": {
            "precision": 0.45673,
            "recall": 0.45564,
            "fmeasure": 0.44182
        },
        "rougeLsum": {
            "precision": 0.45673,
            "recall": 0.45564,
            "fmeasure": 0.44182
        },
        "nist": 3.7012721548064076,
        "bleu": 17.14237,
        "nubia": {
            "semantic_relation": 3.20692,
            "contradiction": 27.94705,
            "irrelevancy": 27.65886,
            "logical_agreement": 44.39409,
            "grammar_ref": 6.54085,
            "grammar_hyp": 6.51156,
            "nubia_score": 0.42849
        },
        "bertscore": {
            "precision": 0.89872,
            "recall": 0.89841,
            "f1": 0.89835
        },
        "meteor": 0.23021203881609334,
        "bleurt": -0.14083
    },
    "cs_restaurants_test": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 842,
        "total_length": 8745,
        "mean_pred_length": 10.385985748218527,
        "std_pred_length": 2.776631923014176,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.05317324185248713,
        "vocab_size-1": 465,
        "unique-1": 169,
        "entropy-1": 6.468612220709368,
        "distinct-2": 0.14070606098949767,
        "vocab_size-2": 1112,
        "unique-2": 524,
        "entropy-2": 8.129013915196074,
        "cond_entropy-2": 1.4062068020911596,
        "distinct-3": 0.2329698343010905,
        "vocab_size-3": 1645,
        "unique-3": 957,
        "entropy-3": 8.879890246095867,
        "cond_entropy-3": 0.8845674791974677,
        "total_length-nopunct": 7348,
        "mean_pred_length-nopunct": 8.726840855106888,
        "std_pred_length-nopunct": 2.6446677848101396,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.06273816004354926,
        "vocab_size-1-nopunct": 461,
        "unique-1-nopunct": 169,
        "entropy-1-nopunct": 6.6482788415738785,
        "distinct-2-nopunct": 0.13403012603750383,
        "vocab_size-2-nopunct": 872,
        "unique-2-nopunct": 398,
        "entropy-2-nopunct": 7.914796874795928,
        "cond_entropy-2-nopunct": 1.5172937735075644,
        "distinct-3-nopunct": 0.2376412429378531,
        "vocab_size-3-nopunct": 1346,
        "unique-3-nopunct": 790,
        "entropy-3-nopunct": 8.719350225129336,
        "cond_entropy-3-nopunct": 1.0234882396963338,
        "msttr-100": 0.53391,
        "msttr-100_nopunct": 0.55548,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4688279301745636
        },
        "rouge1": {
            "precision": 0.49921,
            "recall": 0.51528,
            "fmeasure": 0.49375
        },
        "rouge2": {
            "precision": 0.29269,
            "recall": 0.30492,
            "fmeasure": 0.28977
        },
        "rougeL": {
            "precision": 0.45239,
            "recall": 0.46605,
            "fmeasure": 0.44725
        },
        "rougeLsum": {
            "precision": 0.45239,
            "recall": 0.46605,
            "fmeasure": 0.44725
        },
        "nist": 4.171084804027315,
        "bleu": 19.25341,
        "nubia": {
            "semantic_relation": 3.17081,
            "contradiction": 27.50749,
            "irrelevancy": 32.80407,
            "logical_agreement": 39.68843,
            "grammar_ref": 6.8707,
            "grammar_hyp": 6.99172,
            "nubia_score": 0.44946
        },
        "bertscore": {
            "precision": 0.89061,
            "recall": 0.90247,
            "f1": 0.89622
        },
        "meteor": 0.2379364333339289,
        "bleurt": -0.19502
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 4,
        "total_length": 86,
        "mean_pred_length": 21.5,
        "std_pred_length": 7.794228634059948,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 34,
        "distinct-1": 0.5813953488372093,
        "vocab_size-1": 50,
        "unique-1": 25,
        "entropy-1": 5.442204400247555,
        "distinct-2": 0.7804878048780488,
        "vocab_size-2": 64,
        "unique-2": 46,
        "entropy-2": 5.918527614374178,
        "cond_entropy-2": 0.3982304265038647,
        "distinct-3": 0.8717948717948718,
        "vocab_size-3": 68,
        "unique-3": 58,
        "entropy-3": 6.028991962451996,
        "cond_entropy-3": 0.09451688091083163,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 18.25,
        "std_pred_length-nopunct": 7.1545440106270926,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6438356164383562,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 5.429416682108416,
        "distinct-2-nopunct": 0.7971014492753623,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.702727355328889,
        "cond_entropy-2-nopunct": 0.25942127477245525,
        "distinct-3-nopunct": 0.8923076923076924,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.806983197643842,
        "cond_entropy-3-nopunct": 0.09845874086567001,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.3235294117647059,
            "2": 0.7692307692307693,
            "3": 0.6538461538461539
        },
        "rouge1": {
            "precision": 0.40909,
            "recall": 0.55909,
            "fmeasure": 0.46212
        },
        "rouge2": {
            "precision": 0.11667,
            "recall": 0.13472,
            "fmeasure": 0.12485
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.51364,
            "fmeasure": 0.41667
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.51364,
            "fmeasure": 0.41667
        },
        "nist": 3.336413695636789,
        "bleu": 23.99553,
        "nubia": {
            "semantic_relation": 3.31909,
            "contradiction": 35.83705,
            "irrelevancy": 22.01326,
            "logical_agreement": 42.14968,
            "grammar_ref": 2.93748,
            "grammar_hyp": 2.78947,
            "nubia_score": 0.5959
        },
        "bertscore": {
            "precision": 0.923,
            "recall": 0.9391,
            "f1": 0.93097
        },
        "meteor": 0.5132386827358055,
        "bleurt": -0.00732
    },
    "schema_guided_dialog_challenge_test_nopunc_parent": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6671,
        "mean_pred_length": 13.342,
        "std_pred_length": 7.426239694488726,
        "median_pred_length": 12.0,
        "min_pred_length": 1,
        "max_pred_length": 47,
        "distinct-1": 0.15380002998051268,
        "vocab_size-1": 1026,
        "unique-1": 592,
        "entropy-1": 7.8185912444652175,
        "distinct-2": 0.4508183438664722,
        "vocab_size-2": 2782,
        "unique-2": 1941,
        "entropy-2": 10.535490741032264,
        "cond_entropy-2": 2.487673334107458,
        "distinct-3": 0.6498589562764457,
        "vocab_size-3": 3686,
        "unique-3": 2965,
        "entropy-3": 11.348931629730611,
        "cond_entropy-3": 0.8276936977815782,
        "total_length-nopunct": 5864,
        "mean_pred_length-nopunct": 11.728,
        "std_pred_length-nopunct": 6.765945314588347,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.1730900409276944,
        "vocab_size-1-nopunct": 1015,
        "unique-1-nopunct": 591,
        "entropy-1-nopunct": 8.00260095040518,
        "distinct-2-nopunct": 0.46551081282624907,
        "vocab_size-2-nopunct": 2497,
        "unique-2-nopunct": 1774,
        "entropy-2-nopunct": 10.37656801211118,
        "cond_entropy-2-nopunct": 2.4979997962425124,
        "distinct-3-nopunct": 0.6685162351006987,
        "vocab_size-3-nopunct": 3253,
        "unique-3-nopunct": 2671,
        "entropy-3-nopunct": 11.171231704311461,
        "cond_entropy-3-nopunct": 0.8234305292873472,
        "msttr-100": 0.6897,
        "msttr-100_nopunct": 0.71759,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5670681405708629
        },
        "rouge1": {
            "precision": 0.59813,
            "recall": 0.55489,
            "fmeasure": 0.56398
        },
        "rouge2": {
            "precision": 0.37382,
            "recall": 0.34297,
            "fmeasure": 0.34969
        },
        "rougeL": {
            "precision": 0.53293,
            "recall": 0.49294,
            "fmeasure": 0.50179
        },
        "rougeLsum": {
            "precision": 0.53293,
            "recall": 0.49294,
            "fmeasure": 0.50179
        },
        "nist": 6.268956261933764,
        "bleu": 32.3598,
        "nubia": {
            "semantic_relation": 3.62089,
            "contradiction": 8.41043,
            "irrelevancy": 20.13668,
            "logical_agreement": 71.45289,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.53031,
            "nubia_score": 0.64679
        },
        "bertscore": {
            "precision": 0.87935,
            "recall": 0.86673,
            "f1": 0.87253
        },
        "meteor": 0.31809800746755723,
        "bleurt": -0.05044
    },
    "cs_restaurants_challenge_test_scramble": {
        "predictions_file": "mT5_base/cs_restaurants_challenge_test_scramble",
        "N": 500,
        "total_length": 5537,
        "mean_pred_length": 11.074,
        "std_pred_length": 3.8931380658795036,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 30,
        "distinct-1": 0.1269640599602673,
        "vocab_size-1": 703,
        "unique-1": 314,
        "entropy-1": 7.430029911067417,
        "distinct-2": 0.3915028786976375,
        "vocab_size-2": 1972,
        "unique-2": 1295,
        "entropy-2": 9.873642812401354,
        "cond_entropy-2": 2.210655819977967,
        "distinct-3": 0.6105355962089486,
        "vocab_size-3": 2770,
        "unique-3": 2215,
        "entropy-3": 10.793956326386493,
        "cond_entropy-3": 0.9984733166814558,
        "total_length-nopunct": 4762,
        "mean_pred_length-nopunct": 9.524,
        "std_pred_length-nopunct": 3.501060410789851,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.14657706845863083,
        "vocab_size-1-nopunct": 698,
        "unique-1-nopunct": 313,
        "entropy-1-nopunct": 7.697451689279229,
        "distinct-2-nopunct": 0.40638198029094325,
        "vocab_size-2-nopunct": 1732,
        "unique-2-nopunct": 1165,
        "entropy-2-nopunct": 9.714461732175186,
        "cond_entropy-2-nopunct": 2.225398641395592,
        "distinct-3-nopunct": 0.6393834706351316,
        "vocab_size-3-nopunct": 2406,
        "unique-3-nopunct": 1961,
        "entropy-3-nopunct": 10.64929292255304,
        "cond_entropy-3-nopunct": 1.058762838657335,
        "msttr-100": 0.65418,
        "msttr-100_nopunct": 0.69872,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.3978569764733287
        },
        "rouge1": {
            "precision": 0.39183,
            "recall": 0.43044,
            "fmeasure": 0.39368
        },
        "rouge2": {
            "precision": 0.20581,
            "recall": 0.22844,
            "fmeasure": 0.20677
        },
        "rougeL": {
            "precision": 0.34415,
            "recall": 0.37834,
            "fmeasure": 0.34621
        },
        "rougeLsum": {
            "precision": 0.34415,
            "recall": 0.37834,
            "fmeasure": 0.34621
        },
        "nist": 3.1206193402656464,
        "bleu": 12.16771,
        "nubia": {
            "semantic_relation": 2.81969,
            "contradiction": 29.91394,
            "irrelevancy": 34.10002,
            "logical_agreement": 35.98604,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.70082,
            "nubia_score": 0.38493
        },
        "bertscore": {
            "precision": 0.87412,
            "recall": 0.88187,
            "f1": 0.87766
        },
        "meteor": 0.197216178613564,
        "bleurt": -0.33161
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 339,
        "total_length": 3414,
        "mean_pred_length": 10.070796460176991,
        "std_pred_length": 4.036814686975193,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 25,
        "distinct-1": 0.3397773872290568,
        "vocab_size-1": 1160,
        "unique-1": 699,
        "entropy-1": 8.496821152522255,
        "distinct-2": 0.6773983739837398,
        "vocab_size-2": 2083,
        "unique-2": 1598,
        "entropy-2": 10.659573713537704,
        "cond_entropy-2": 1.5901234583853294,
        "distinct-3": 0.827485380116959,
        "vocab_size-3": 2264,
        "unique-3": 1929,
        "entropy-3": 11.016525804828957,
        "cond_entropy-3": 0.3653738016822111,
        "total_length-nopunct": 2749,
        "mean_pred_length-nopunct": 8.109144542772862,
        "std_pred_length-nopunct": 3.5336401263469397,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.42015278283012003,
        "vocab_size-1-nopunct": 1155,
        "unique-1-nopunct": 699,
        "entropy-1-nopunct": 9.214085091851606,
        "distinct-2-nopunct": 0.7087136929460581,
        "vocab_size-2-nopunct": 1708,
        "unique-2-nopunct": 1343,
        "entropy-2-nopunct": 10.411593577357944,
        "cond_entropy-2-nopunct": 1.3200368459130625,
        "distinct-3-nopunct": 0.8440366972477065,
        "vocab_size-3-nopunct": 1748,
        "unique-3-nopunct": 1517,
        "entropy-3-nopunct": 10.652796584118706,
        "cond_entropy-3-nopunct": 0.3111089557577835,
        "msttr-100": 0.65176,
        "msttr-100_nopunct": 0.72852,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.34226447709593777,
            "2": 0.6881233000906618,
            "3": 0.883248730964467,
            "4": 0.9166666666666666,
            "5": 0.9333333333333333,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.29215,
            "recall": 0.29081,
            "fmeasure": 0.28967
        },
        "rouge2": {
            "precision": 0.14752,
            "recall": 0.14225,
            "fmeasure": 0.14362
        },
        "rougeL": {
            "precision": 0.29166,
            "recall": 0.29045,
            "fmeasure": 0.28925
        },
        "rougeLsum": {
            "precision": 0.29166,
            "recall": 0.29045,
            "fmeasure": 0.28925
        },
        "nist": 8.877544449621642,
        "bleu": 59.20698,
        "nubia": {
            "semantic_relation": 4.19535,
            "contradiction": 20.1042,
            "irrelevancy": 19.75117,
            "logical_agreement": 60.14463,
            "grammar_ref": 2.83259,
            "grammar_hyp": 2.82934,
            "nubia_score": 0.85146
        },
        "bertscore": {
            "precision": 0.96841,
            "recall": 0.96625,
            "f1": 0.96673
        },
        "meteor": 0.7447060906876474,
        "bleurt": 0.37847
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 1328,
        "total_length": 25209,
        "mean_pred_length": 18.982680722891565,
        "std_pred_length": 4.966044465467651,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 47,
        "distinct-1": 0.0787417192272601,
        "vocab_size-1": 1985,
        "unique-1": 955,
        "entropy-1": 7.960284307281082,
        "distinct-2": 0.24831455969180521,
        "vocab_size-2": 5930,
        "unique-2": 3458,
        "entropy-2": 10.902961045409285,
        "cond_entropy-2": 2.7653661258538422,
        "distinct-3": 0.40983461180330777,
        "vocab_size-3": 9243,
        "unique-3": 6252,
        "entropy-3": 12.12828587576103,
        "cond_entropy-3": 1.2881000822319404,
        "total_length-nopunct": 22315,
        "mean_pred_length-nopunct": 16.803463855421686,
        "std_pred_length-nopunct": 4.433384445348704,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.08837105086264845,
        "vocab_size-1-nopunct": 1972,
        "unique-1-nopunct": 953,
        "entropy-1-nopunct": 8.170443031126409,
        "distinct-2-nopunct": 0.26564063467861054,
        "vocab_size-2-nopunct": 5575,
        "unique-2-nopunct": 3334,
        "entropy-2-nopunct": 10.83207487220234,
        "cond_entropy-2-nopunct": 2.804097984707734,
        "distinct-3-nopunct": 0.43394882750902897,
        "vocab_size-3-nopunct": 8531,
        "unique-3-nopunct": 5905,
        "entropy-3-nopunct": 12.054233849478136,
        "cond_entropy-3-nopunct": 1.3093173444891888,
        "msttr-100": 0.68476,
        "msttr-100_nopunct": 0.70955,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5942286652078774
        },
        "rouge1": {
            "precision": 0.64366,
            "recall": 0.61735,
            "fmeasure": 0.61805
        },
        "rouge2": {
            "precision": 0.41353,
            "recall": 0.39749,
            "fmeasure": 0.3972
        },
        "rougeL": {
            "precision": 0.54573,
            "recall": 0.52216,
            "fmeasure": 0.52376
        },
        "rougeLsum": {
            "precision": 0.54573,
            "recall": 0.52216,
            "fmeasure": 0.52376
        },
        "nist": 6.676112416191206,
        "bleu": 31.48578,
        "nubia": {
            "semantic_relation": 4.15176,
            "contradiction": 6.10355,
            "irrelevancy": 19.89072,
            "logical_agreement": 74.00574,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.66055,
            "nubia_score": 0.71982
        },
        "bertscore": {
            "precision": 0.89006,
            "recall": 0.87896,
            "f1": 0.88406
        },
        "meteor": 0.3273022529740671,
        "bleurt": -0.06997
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 316,
        "total_length": 6780,
        "mean_pred_length": 21.455696202531644,
        "std_pred_length": 8.10617434367073,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 63,
        "distinct-1": 0.23067846607669618,
        "vocab_size-1": 1564,
        "unique-1": 745,
        "entropy-1": 8.58005545537479,
        "distinct-2": 0.5037128712871287,
        "vocab_size-2": 3256,
        "unique-2": 2085,
        "entropy-2": 11.059084881423225,
        "cond_entropy-2": 2.244739423683342,
        "distinct-3": 0.6610279765777488,
        "vocab_size-3": 4064,
        "unique-3": 2998,
        "entropy-3": 11.699125805940492,
        "cond_entropy-3": 0.6510547384325688,
        "total_length-nopunct": 5541,
        "mean_pred_length-nopunct": 17.53481012658228,
        "std_pred_length-nopunct": 6.86502258485217,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.28117668290922215,
        "vocab_size-1-nopunct": 1558,
        "unique-1-nopunct": 744,
        "entropy-1-nopunct": 9.245130620044153,
        "distinct-2-nopunct": 0.5525358851674641,
        "vocab_size-2-nopunct": 2887,
        "unique-2-nopunct": 1933,
        "entropy-2-nopunct": 11.008760543932292,
        "cond_entropy-2-nopunct": 1.8233121661837204,
        "distinct-3-nopunct": 0.6989203503768588,
        "vocab_size-3-nopunct": 3431,
        "unique-3-nopunct": 2629,
        "entropy-3-nopunct": 11.489136880603535,
        "cond_entropy-3-nopunct": 0.5041743198863482,
        "msttr-100": 0.61254,
        "msttr-100_nopunct": 0.68109,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.28983130271790064,
            "2": 0.6816208393632417,
            "3": 0.8802816901408451,
            "4": 0.9473684210526315,
            "5": 0.9545454545454546,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.39073,
            "recall": 0.40123,
            "fmeasure": 0.39296
        },
        "rouge2": {
            "precision": 0.20501,
            "recall": 0.21063,
            "fmeasure": 0.20513
        },
        "rougeL": {
            "precision": 0.37897,
            "recall": 0.39017,
            "fmeasure": 0.38149
        },
        "rougeLsum": {
            "precision": 0.37897,
            "recall": 0.39017,
            "fmeasure": 0.38149
        },
        "nist": 8.625659796811329,
        "bleu": 48.47719,
        "nubia": {
            "semantic_relation": 4.02085,
            "contradiction": 18.41851,
            "irrelevancy": 21.43288,
            "logical_agreement": 60.14861,
            "grammar_ref": 2.6064,
            "grammar_hyp": 2.54991,
            "nubia_score": 0.83031
        },
        "bertscore": {
            "precision": 0.95484,
            "recall": 0.95377,
            "f1": 0.95352
        },
        "meteor": 0.6520557512313966,
        "bleurt": 0.16704
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 217,
        "total_length": 5470,
        "mean_pred_length": 25.207373271889402,
        "std_pred_length": 7.064439474004024,
        "median_pred_length": 25.0,
        "min_pred_length": 10,
        "max_pred_length": 43,
        "distinct-1": 0.2570383912248629,
        "vocab_size-1": 1406,
        "unique-1": 686,
        "entropy-1": 8.569868941720353,
        "distinct-2": 0.5383590329335618,
        "vocab_size-2": 2828,
        "unique-2": 1811,
        "entropy-2": 10.970820025337085,
        "cond_entropy-2": 2.2014870276546703,
        "distinct-3": 0.6953931691818904,
        "vocab_size-3": 3502,
        "unique-3": 2604,
        "entropy-3": 11.542887497872922,
        "cond_entropy-3": 0.5826805927871465,
        "total_length-nopunct": 4490,
        "mean_pred_length-nopunct": 20.691244239631338,
        "std_pred_length-nopunct": 6.125535193040401,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.31135857461024496,
        "vocab_size-1-nopunct": 1398,
        "unique-1-nopunct": 685,
        "entropy-1-nopunct": 9.21849980599709,
        "distinct-2-nopunct": 0.5876433419143459,
        "vocab_size-2-nopunct": 2511,
        "unique-2-nopunct": 1693,
        "entropy-2-nopunct": 10.904344081619756,
        "cond_entropy-2-nopunct": 1.7384266365946504,
        "distinct-3-nopunct": 0.7300295857988166,
        "vocab_size-3-nopunct": 2961,
        "unique-3-nopunct": 2293,
        "entropy-3-nopunct": 11.326135884135018,
        "cond_entropy-3-nopunct": 0.43986261214195144,
        "msttr-100": 0.62037,
        "msttr-100_nopunct": 0.68705,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2668711656441718,
            "2": 0.6578778135048231,
            "3": 0.8958180484225972,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.51493,
            "recall": 0.53548,
            "fmeasure": 0.52099
        },
        "rouge2": {
            "precision": 0.29047,
            "recall": 0.30566,
            "fmeasure": 0.29264
        },
        "rougeL": {
            "precision": 0.49118,
            "recall": 0.51217,
            "fmeasure": 0.49719
        },
        "rougeLsum": {
            "precision": 0.49118,
            "recall": 0.51217,
            "fmeasure": 0.49719
        },
        "nist": 8.349770913938508,
        "bleu": 46.88589,
        "nubia": {
            "semantic_relation": 3.9734,
            "contradiction": 18.4277,
            "irrelevancy": 21.99437,
            "logical_agreement": 59.57793,
            "grammar_ref": 2.56565,
            "grammar_hyp": 2.46146,
            "nubia_score": 0.82329
        },
        "bertscore": {
            "precision": 0.95004,
            "recall": 0.94814,
            "f1": 0.94821
        },
        "meteor": 0.6253241438894982,
        "bleurt": 0.12497
    },
    "web_nlg_ru_val": {
        "predictions_file": "mT5_base/web_nlg_ru_val",
        "N": 790,
        "total_length": 15738,
        "mean_pred_length": 19.921518987341774,
        "std_pred_length": 10.1008292789779,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 56,
        "distinct-1": 0.09118058203075359,
        "vocab_size-1": 1435,
        "unique-1": 482,
        "entropy-1": 8.205481649627155,
        "distinct-2": 0.2348809205244849,
        "vocab_size-2": 3511,
        "unique-2": 1598,
        "entropy-2": 10.67469175402645,
        "cond_entropy-2": 2.2295369530222695,
        "distinct-3": 0.35238027970052266,
        "vocab_size-3": 4989,
        "unique-3": 2728,
        "entropy-3": 11.496234948375006,
        "cond_entropy-3": 0.855444519260605,
        "total_length-nopunct": 12772,
        "mean_pred_length-nopunct": 16.167088607594938,
        "std_pred_length-nopunct": 8.653523779494414,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.1118853742561854,
        "vocab_size-1-nopunct": 1429,
        "unique-1-nopunct": 482,
        "entropy-1-nopunct": 8.835693677929758,
        "distinct-2-nopunct": 0.271323652144884,
        "vocab_size-2-nopunct": 3251,
        "unique-2-nopunct": 1629,
        "entropy-2-nopunct": 10.669330048289304,
        "cond_entropy-2-nopunct": 1.8995927637442103,
        "distinct-3-nopunct": 0.3972480343102216,
        "vocab_size-3-nopunct": 4446,
        "unique-3-nopunct": 2651,
        "entropy-3-nopunct": 11.358394954106545,
        "cond_entropy-3-nopunct": 0.7243623625715272,
        "msttr-100": 0.47089,
        "msttr-100_nopunct": 0.49811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_val.json",
        "local_recall": {
            "1": 0.24683143219264891,
            "2": 0.6375475856541776,
            "3": 0.8425176286236615,
            "4": 0.8181818181818182,
            "5": 0.8076923076923077,
            "6": 1.0,
            "7": 0.75,
            "8": 0,
            "9": 1.0
        },
        "rouge1": {
            "precision": 0.32598,
            "recall": 0.33691,
            "fmeasure": 0.329
        },
        "rouge2": {
            "precision": 0.12541,
            "recall": 0.13357,
            "fmeasure": 0.12728
        },
        "rougeL": {
            "precision": 0.31161,
            "recall": 0.32266,
            "fmeasure": 0.3147
        },
        "rougeLsum": {
            "precision": 0.31161,
            "recall": 0.32266,
            "fmeasure": 0.3147
        },
        "nist": 7.887608866182779,
        "bleu": 44.25999,
        "nubia": {
            "semantic_relation": 3.93591,
            "contradiction": 22.53903,
            "irrelevancy": 21.06954,
            "logical_agreement": 56.39143,
            "grammar_ref": 2.60252,
            "grammar_hyp": 2.57192,
            "nubia_score": 0.8058
        },
        "bertscore": {
            "precision": 0.95129,
            "recall": 0.94919,
            "f1": 0.94943
        },
        "meteor": 0.6024524211397355,
        "bleurt": 0.17469
    },
    "schema_guided_dialog_challenge_test_scramble_parent": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6695,
        "mean_pred_length": 13.39,
        "std_pred_length": 8.364323044933164,
        "median_pred_length": 11.5,
        "min_pred_length": 3,
        "max_pred_length": 85,
        "distinct-1": 0.1439880507841673,
        "vocab_size-1": 964,
        "unique-1": 534,
        "entropy-1": 7.6935476179051125,
        "distinct-2": 0.4235673930589185,
        "vocab_size-2": 2624,
        "unique-2": 1738,
        "entropy-2": 10.432757129872277,
        "cond_entropy-2": 2.5121703759291902,
        "distinct-3": 0.6180860403863038,
        "vocab_size-3": 3520,
        "unique-3": 2702,
        "entropy-3": 11.268789307456123,
        "cond_entropy-3": 0.8678537021107332,
        "total_length-nopunct": 5896,
        "mean_pred_length-nopunct": 11.792,
        "std_pred_length-nopunct": 7.587142808725825,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.16163500678426052,
        "vocab_size-1-nopunct": 953,
        "unique-1-nopunct": 532,
        "entropy-1-nopunct": 7.868618213276766,
        "distinct-2-nopunct": 0.44125277983691624,
        "vocab_size-2-nopunct": 2381,
        "unique-2-nopunct": 1632,
        "entropy-2-nopunct": 10.277851730339497,
        "cond_entropy-2-nopunct": 2.5455997901676737,
        "distinct-3-nopunct": 0.6305147058823529,
        "vocab_size-3-nopunct": 3087,
        "unique-3-nopunct": 2416,
        "entropy-3-nopunct": 11.06925886547238,
        "cond_entropy-3-nopunct": 0.8509736053185113,
        "msttr-100": 0.66955,
        "msttr-100_nopunct": 0.69397,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5610049905351919
        },
        "rouge1": {
            "precision": 0.57036,
            "recall": 0.54395,
            "fmeasure": 0.54611
        },
        "rouge2": {
            "precision": 0.34484,
            "recall": 0.32808,
            "fmeasure": 0.32902
        },
        "rougeL": {
            "precision": 0.51363,
            "recall": 0.48827,
            "fmeasure": 0.49093
        },
        "rougeLsum": {
            "precision": 0.51363,
            "recall": 0.48827,
            "fmeasure": 0.49093
        },
        "nist": 5.962018726540769,
        "bleu": 30.63706,
        "nubia": {
            "semantic_relation": 3.51447,
            "contradiction": 7.75503,
            "irrelevancy": 24.00828,
            "logical_agreement": 68.23669,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.50089,
            "nubia_score": 0.62458
        },
        "bertscore": {
            "precision": 0.86976,
            "recall": 0.86243,
            "f1": 0.86566
        },
        "meteor": 0.30778831457104533,
        "bleurt": -0.12447
    },
    "xsum_challenge_test_backtranslation_parent": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 500,
        "total_length": 10760,
        "mean_pred_length": 21.52,
        "std_pred_length": 5.002959124358303,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 68,
        "distinct-1": 0.2552973977695167,
        "vocab_size-1": 2747,
        "unique-1": 1723,
        "entropy-1": 8.904476171439331,
        "distinct-2": 0.691812865497076,
        "vocab_size-2": 7098,
        "unique-2": 6024,
        "entropy-2": 12.210045176912454,
        "cond_entropy-2": 3.0873979529059574,
        "distinct-3": 0.8967213114754098,
        "vocab_size-3": 8752,
        "unique-3": 8195,
        "entropy-3": 12.97057395615257,
        "cond_entropy-3": 0.7708366342876811,
        "total_length-nopunct": 10007,
        "mean_pred_length-nopunct": 20.014,
        "std_pred_length-nopunct": 4.7148493083024405,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.27350854401918656,
        "vocab_size-1-nopunct": 2737,
        "unique-1-nopunct": 1722,
        "entropy-1-nopunct": 9.073772932474187,
        "distinct-2-nopunct": 0.7001157042179447,
        "vocab_size-2-nopunct": 6656,
        "unique-2-nopunct": 5673,
        "entropy-2-nopunct": 12.136015780615452,
        "cond_entropy-2-nopunct": 3.1829686256034977,
        "distinct-3-nopunct": 0.9069612523592762,
        "vocab_size-3-nopunct": 8169,
        "unique-3-nopunct": 7677,
        "entropy-3-nopunct": 12.89747951503346,
        "cond_entropy-3-nopunct": 0.7797247828407173,
        "msttr-100": 0.71645,
        "msttr-100_nopunct": 0.7324,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.33306378247245527
        },
        "rouge1": {
            "precision": 0.37938,
            "recall": 0.35696,
            "fmeasure": 0.3601
        },
        "rouge2": {
            "precision": 0.13601,
            "recall": 0.12773,
            "fmeasure": 0.12881
        },
        "rougeL": {
            "precision": 0.29127,
            "recall": 0.27462,
            "fmeasure": 0.27663
        },
        "rougeLsum": {
            "precision": 0.29127,
            "recall": 0.27462,
            "fmeasure": 0.27663
        },
        "nist": 3.4054293301687775,
        "bleu": 8.75635,
        "nubia": {
            "semantic_relation": 2.61483,
            "contradiction": 25.30754,
            "irrelevancy": 65.78542,
            "logical_agreement": 8.90704,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.7123,
            "nubia_score": 0.35347
        },
        "bertscore": {
            "precision": 0.82356,
            "recall": 0.81244,
            "f1": 0.81767
        },
        "meteor": 0.15700798766971708,
        "bleurt": -0.40283
    },
    "schema_guided_dialog_challenge_test_backtranslation": {
        "predictions_file": "mT5_base/schema_guided_dialog_challenge_test_backtranslation",
        "N": 500,
        "total_length": 6554,
        "mean_pred_length": 13.108,
        "std_pred_length": 7.692095683232235,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 48,
        "distinct-1": 0.16158071406774488,
        "vocab_size-1": 1059,
        "unique-1": 605,
        "entropy-1": 7.865857380666254,
        "distinct-2": 0.5272547076313181,
        "vocab_size-2": 3192,
        "unique-2": 2301,
        "entropy-2": 10.940892541209593,
        "cond_entropy-2": 2.819562738327728,
        "distinct-3": 0.7646741087504502,
        "vocab_size-3": 4247,
        "unique-3": 3605,
        "entropy-3": 11.77878245689511,
        "cond_entropy-3": 0.8561665749971779,
        "total_length-nopunct": 5719,
        "mean_pred_length-nopunct": 11.438,
        "std_pred_length-nopunct": 7.0155652658926915,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.18289910823570554,
        "vocab_size-1-nopunct": 1046,
        "unique-1-nopunct": 602,
        "entropy-1-nopunct": 8.08132961562927,
        "distinct-2-nopunct": 0.5470396627706458,
        "vocab_size-2-nopunct": 2855,
        "unique-2-nopunct": 2117,
        "entropy-2-nopunct": 10.773134353548132,
        "cond_entropy-2-nopunct": 2.8283822403324126,
        "distinct-3-nopunct": 0.7792372881355932,
        "vocab_size-3-nopunct": 3678,
        "unique-3-nopunct": 3183,
        "entropy-3-nopunct": 11.57096385300608,
        "cond_entropy-3-nopunct": 0.8300297236303112,
        "msttr-100": 0.68554,
        "msttr-100_nopunct": 0.7193,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_backtranslation.json",
        "local_recall": {
            "1": 0.5140949554896143
        },
        "rouge1": {
            "precision": 0.49139,
            "recall": 0.48252,
            "fmeasure": 0.4744
        },
        "rouge2": {
            "precision": 0.27479,
            "recall": 0.2641,
            "fmeasure": 0.26127
        },
        "rougeL": {
            "precision": 0.43276,
            "recall": 0.42396,
            "fmeasure": 0.41728
        },
        "rougeLsum": {
            "precision": 0.43276,
            "recall": 0.42396,
            "fmeasure": 0.41728
        },
        "nist": 5.18804019374737,
        "bleu": 26.14275,
        "nubia": {
            "semantic_relation": 3.35811,
            "contradiction": 7.87589,
            "irrelevancy": 26.84496,
            "logical_agreement": 65.27915,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.6911,
            "nubia_score": 0.57262
        },
        "bertscore": {
            "precision": 0.84865,
            "recall": 0.84645,
            "f1": 0.84697
        },
        "meteor": 0.28390972240470724,
        "bleurt": -0.22114
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 143,
        "total_length": 4593,
        "mean_pred_length": 32.11888111888112,
        "std_pred_length": 10.80629802799198,
        "median_pred_length": 28.0,
        "min_pred_length": 14,
        "max_pred_length": 70,
        "distinct-1": 0.24646200740256913,
        "vocab_size-1": 1132,
        "unique-1": 509,
        "entropy-1": 8.394969417973456,
        "distinct-2": 0.49842696629213484,
        "vocab_size-2": 2218,
        "unique-2": 1293,
        "entropy-2": 10.643983805963956,
        "cond_entropy-2": 2.106608211136672,
        "distinct-3": 0.6264221035523566,
        "vocab_size-3": 2698,
        "unique-3": 1851,
        "entropy-3": 11.106466124059207,
        "cond_entropy-3": 0.47450912250672483,
        "total_length-nopunct": 3736,
        "mean_pred_length-nopunct": 26.125874125874127,
        "std_pred_length-nopunct": 8.539392170494242,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.3013918629550321,
        "vocab_size-1-nopunct": 1126,
        "unique-1-nopunct": 509,
        "entropy-1-nopunct": 9.039106591999948,
        "distinct-2-nopunct": 0.5402170887837462,
        "vocab_size-2-nopunct": 1941,
        "unique-2-nopunct": 1187,
        "entropy-2-nopunct": 10.544969395123397,
        "cond_entropy-2-nopunct": 1.543262201920206,
        "distinct-3-nopunct": 0.6628985507246377,
        "vocab_size-3-nopunct": 2287,
        "unique-3-nopunct": 1647,
        "entropy-3-nopunct": 10.910379201910768,
        "cond_entropy-3-nopunct": 0.37905543464591673,
        "msttr-100": 0.62333,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2874854707477722,
            "2": 0.6816632583503749,
            "3": 0.889413988657845
        },
        "rouge1": {
            "precision": 0.55361,
            "recall": 0.56168,
            "fmeasure": 0.55022
        },
        "rouge2": {
            "precision": 0.36354,
            "recall": 0.38088,
            "fmeasure": 0.36408
        },
        "rougeL": {
            "precision": 0.51782,
            "recall": 0.52465,
            "fmeasure": 0.51422
        },
        "rougeLsum": {
            "precision": 0.51782,
            "recall": 0.52465,
            "fmeasure": 0.51422
        },
        "nist": 8.693934267322549,
        "bleu": 52.8598,
        "nubia": {
            "semantic_relation": 3.92936,
            "contradiction": 20.26753,
            "irrelevancy": 21.42382,
            "logical_agreement": 58.30865,
            "grammar_ref": 2.5384,
            "grammar_hyp": 2.49772,
            "nubia_score": 0.83253
        },
        "bertscore": {
            "precision": 0.95349,
            "recall": 0.94999,
            "f1": 0.95141
        },
        "meteor": 0.6555022611083468,
        "bleurt": 0.13307
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 469,
        "total_length": 10597,
        "mean_pred_length": 22.594882729211086,
        "std_pred_length": 8.549745032738715,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 98,
        "distinct-1": 0.10993677455883741,
        "vocab_size-1": 1165,
        "unique-1": 576,
        "entropy-1": 7.710030009958217,
        "distinct-2": 0.2914691943127962,
        "vocab_size-2": 2952,
        "unique-2": 1745,
        "entropy-2": 10.168358837916493,
        "cond_entropy-2": 2.3332080247019205,
        "distinct-3": 0.4558442902992028,
        "vocab_size-3": 4403,
        "unique-3": 3053,
        "entropy-3": 11.243377974090777,
        "cond_entropy-3": 1.1140991368501623,
        "total_length-nopunct": 9518,
        "mean_pred_length-nopunct": 20.294243070362473,
        "std_pred_length-nopunct": 7.752486973726804,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 97,
        "distinct-1-nopunct": 0.12145408699306577,
        "vocab_size-1-nopunct": 1156,
        "unique-1-nopunct": 575,
        "entropy-1-nopunct": 7.85703388824273,
        "distinct-2-nopunct": 0.3058901536081335,
        "vocab_size-2-nopunct": 2768,
        "unique-2-nopunct": 1675,
        "entropy-2-nopunct": 10.101622297198729,
        "cond_entropy-2-nopunct": 2.3412241599828723,
        "distinct-3-nopunct": 0.47645687645687645,
        "vocab_size-3-nopunct": 4088,
        "unique-3-nopunct": 2896,
        "entropy-3-nopunct": 11.181518049823271,
        "cond_entropy-3-nopunct": 1.118133024712282,
        "msttr-100": 0.6699,
        "msttr-100_nopunct": 0.68695,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6370584829183555
        },
        "rouge1": {
            "precision": 0.64819,
            "recall": 0.6555,
            "fmeasure": 0.63983
        },
        "rouge2": {
            "precision": 0.41867,
            "recall": 0.42269,
            "fmeasure": 0.41291
        },
        "rougeL": {
            "precision": 0.55397,
            "recall": 0.56025,
            "fmeasure": 0.5469
        },
        "rougeLsum": {
            "precision": 0.55397,
            "recall": 0.56025,
            "fmeasure": 0.5469
        },
        "nist": 6.251786513770776,
        "bleu": 32.51942,
        "nubia": {
            "semantic_relation": 4.24402,
            "contradiction": 7.22983,
            "irrelevancy": 19.2368,
            "logical_agreement": 73.53337,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.67747,
            "nubia_score": 0.7302
        },
        "bertscore": {
            "precision": 0.88828,
            "recall": 0.88676,
            "f1": 0.88711
        },
        "meteor": 0.3421707946268506,
        "bleurt": -0.04974
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 115,
        "total_length": 2100,
        "mean_pred_length": 18.26086956521739,
        "std_pred_length": 6.0721559190065175,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 52,
        "distinct-1": 0.24714285714285714,
        "vocab_size-1": 519,
        "unique-1": 249,
        "entropy-1": 7.299453759311211,
        "distinct-2": 0.5425692695214106,
        "vocab_size-2": 1077,
        "unique-2": 727,
        "entropy-2": 9.582683079819413,
        "cond_entropy-2": 2.092876919815347,
        "distinct-3": 0.6962566844919786,
        "vocab_size-3": 1302,
        "unique-3": 1007,
        "entropy-3": 10.086648217485678,
        "cond_entropy-3": 0.5525017132930529,
        "total_length-nopunct": 1836,
        "mean_pred_length-nopunct": 15.965217391304348,
        "std_pred_length-nopunct": 5.31434553176606,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.28050108932461876,
        "vocab_size-1-nopunct": 515,
        "unique-1-nopunct": 249,
        "entropy-1-nopunct": 7.561848887714883,
        "distinct-2-nopunct": 0.5351539802440441,
        "vocab_size-2-nopunct": 921,
        "unique-2-nopunct": 621,
        "entropy-2-nopunct": 9.339653890448428,
        "cond_entropy-2-nopunct": 1.9078038285651282,
        "distinct-3-nopunct": 0.6811955168119551,
        "vocab_size-3-nopunct": 1094,
        "unique-3-nopunct": 834,
        "entropy-3-nopunct": 9.819946075891368,
        "cond_entropy-3-nopunct": 0.5351806421218334,
        "msttr-100": 0.6381,
        "msttr-100_nopunct": 0.685,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23684210526315788,
            "2": 0.5733333333333334,
            "3": 0.8605371900826446
        },
        "rouge1": {
            "precision": 0.73548,
            "recall": 0.74616,
            "fmeasure": 0.73083
        },
        "rouge2": {
            "precision": 0.48361,
            "recall": 0.4921,
            "fmeasure": 0.48143
        },
        "rougeL": {
            "precision": 0.61094,
            "recall": 0.62422,
            "fmeasure": 0.60952
        },
        "rougeLsum": {
            "precision": 0.61094,
            "recall": 0.62422,
            "fmeasure": 0.60952
        },
        "nist": 7.707489556934958,
        "bleu": 49.45806,
        "nubia": {
            "semantic_relation": 4.42142,
            "contradiction": 11.00767,
            "irrelevancy": 6.76099,
            "logical_agreement": 82.23134,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.66377,
            "nubia_score": 0.77511
        },
        "bertscore": {
            "precision": 0.91664,
            "recall": 0.92243,
            "f1": 0.91828
        },
        "meteor": 0.41127509575362964,
        "bleurt": 0.16756
    },
    "xsum_challenge_test_bfp_02_parent": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 500,
        "total_length": 10601,
        "mean_pred_length": 21.202,
        "std_pred_length": 4.56609198330476,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 36,
        "distinct-1": 0.2562022450712197,
        "vocab_size-1": 2716,
        "unique-1": 1740,
        "entropy-1": 8.888551629280405,
        "distinct-2": 0.684981684981685,
        "vocab_size-2": 6919,
        "unique-2": 5890,
        "entropy-2": 12.154366844543679,
        "cond_entropy-2": 3.0449653438965036,
        "distinct-3": 0.8862618477241954,
        "vocab_size-3": 8509,
        "unique-3": 7945,
        "entropy-3": 12.910781305980526,
        "cond_entropy-3": 0.7651411809725449,
        "total_length-nopunct": 9868,
        "mean_pred_length-nopunct": 19.736,
        "std_pred_length-nopunct": 4.375648980437074,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.2741183623834617,
        "vocab_size-1-nopunct": 2705,
        "unique-1-nopunct": 1737,
        "entropy-1-nopunct": 9.056464555256184,
        "distinct-2-nopunct": 0.6923569598633647,
        "vocab_size-2-nopunct": 6486,
        "unique-2-nopunct": 5543,
        "entropy-2-nopunct": 12.07401661521866,
        "cond_entropy-2-nopunct": 3.137166999850512,
        "distinct-3-nopunct": 0.8945647271087055,
        "vocab_size-3-nopunct": 7933,
        "unique-3-nopunct": 7429,
        "entropy-3-nopunct": 12.82923220482246,
        "cond_entropy-3-nopunct": 0.7733724451273717,
        "msttr-100": 0.71519,
        "msttr-100_nopunct": 0.7348,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3195324881141046
        },
        "rouge1": {
            "precision": 0.37955,
            "recall": 0.35074,
            "fmeasure": 0.35751
        },
        "rouge2": {
            "precision": 0.13291,
            "recall": 0.12064,
            "fmeasure": 0.12364
        },
        "rougeL": {
            "precision": 0.29106,
            "recall": 0.26883,
            "fmeasure": 0.27403
        },
        "rougeLsum": {
            "precision": 0.29106,
            "recall": 0.26883,
            "fmeasure": 0.27403
        },
        "nist": 3.2865575596458565,
        "bleu": 7.59708,
        "nubia": {
            "semantic_relation": 2.59638,
            "contradiction": 26.90824,
            "irrelevancy": 62.43816,
            "logical_agreement": 10.6536,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.6718,
            "nubia_score": 0.34706
        },
        "bertscore": {
            "precision": 0.82598,
            "recall": 0.8104,
            "f1": 0.81783
        },
        "meteor": 0.15284549431371805,
        "bleurt": -0.39596
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 518,
        "total_length": 15063,
        "mean_pred_length": 29.07915057915058,
        "std_pred_length": 13.09054853910049,
        "median_pred_length": 27.0,
        "min_pred_length": 5,
        "max_pred_length": 85,
        "distinct-1": 0.05536745668193587,
        "vocab_size-1": 834,
        "unique-1": 230,
        "entropy-1": 7.576402651125124,
        "distinct-2": 0.15393606050189068,
        "vocab_size-2": 2239,
        "unique-2": 881,
        "entropy-2": 9.90117748016528,
        "cond_entropy-2": 2.194254235503798,
        "distinct-3": 0.23939545162900122,
        "vocab_size-3": 3358,
        "unique-3": 1653,
        "entropy-3": 10.643797310210267,
        "cond_entropy-3": 0.7873483363803558,
        "total_length-nopunct": 13395,
        "mean_pred_length-nopunct": 25.85907335907336,
        "std_pred_length-nopunct": 11.74000127893381,
        "median_pred_length-nopunct": 24.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.06173945502053005,
        "vocab_size-1-nopunct": 827,
        "unique-1-nopunct": 230,
        "entropy-1-nopunct": 7.81066260477228,
        "distinct-2-nopunct": 0.16191659548031373,
        "vocab_size-2-nopunct": 2085,
        "unique-2-nopunct": 861,
        "entropy-2-nopunct": 9.793911712023789,
        "cond_entropy-2-nopunct": 2.067613656992265,
        "distinct-3-nopunct": 0.25042479164980985,
        "vocab_size-3-nopunct": 3095,
        "unique-3-nopunct": 1581,
        "entropy-3-nopunct": 10.508779230432959,
        "cond_entropy-3-nopunct": 0.7440696736518468,
        "msttr-100": 0.6414,
        "msttr-100_nopunct": 0.68624,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.25468230351829163,
            "2": 0.660889659156557,
            "3": 0.9182623606744784,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.82052,
            "recall": 0.78969,
            "fmeasure": 0.79958
        },
        "rouge2": {
            "precision": 0.59336,
            "recall": 0.57152,
            "fmeasure": 0.57795
        },
        "rougeL": {
            "precision": 0.65896,
            "recall": 0.63932,
            "fmeasure": 0.64452
        },
        "rougeLsum": {
            "precision": 0.65896,
            "recall": 0.63932,
            "fmeasure": 0.64452
        },
        "nist": 9.200149310766518,
        "bleu": 59.64832,
        "nubia": {
            "semantic_relation": 4.62793,
            "contradiction": 4.55358,
            "irrelevancy": 4.53713,
            "logical_agreement": 90.90929,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.1566,
            "nubia_score": 0.87069
        },
        "bertscore": {
            "precision": 0.9456,
            "recall": 0.93754,
            "f1": 0.94046
        },
        "meteor": 0.42067617387155015,
        "bleurt": 0.32377
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 1177,
        "total_length": 28814,
        "mean_pred_length": 24.48088360237893,
        "std_pred_length": 12.282286527590857,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 96,
        "distinct-1": 0.045394599847296456,
        "vocab_size-1": 1308,
        "unique-1": 369,
        "entropy-1": 7.454579559534603,
        "distinct-2": 0.1680717878206752,
        "vocab_size-2": 4645,
        "unique-2": 2065,
        "entropy-2": 10.660117976191314,
        "cond_entropy-2": 3.0618280259280404,
        "distinct-3": 0.32286470143613,
        "vocab_size-3": 8543,
        "unique-3": 4895,
        "entropy-3": 12.043820858116689,
        "cond_entropy-3": 1.4544753776011963,
        "total_length-nopunct": 25449,
        "mean_pred_length-nopunct": 21.621920135938826,
        "std_pred_length-nopunct": 11.059841646590488,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.0510432629965814,
        "vocab_size-1-nopunct": 1299,
        "unique-1-nopunct": 368,
        "entropy-1-nopunct": 7.675036862995914,
        "distinct-2-nopunct": 0.18214403427818063,
        "vocab_size-2-nopunct": 4421,
        "unique-2-nopunct": 2073,
        "entropy-2-nopunct": 10.57711058805389,
        "cond_entropy-2-nopunct": 3.0586949353325714,
        "distinct-3-nopunct": 0.3436241610738255,
        "vocab_size-3-nopunct": 7936,
        "unique-3-nopunct": 4709,
        "entropy-3-nopunct": 11.941605025418509,
        "cond_entropy-3-nopunct": 1.4302920187521417,
        "msttr-100": 0.59372,
        "msttr-100_nopunct": 0.63315,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2140247705604562,
            "2": 0.4979386165826844,
            "3": 0.741626002812009,
            "4": 0.3,
            "5": 0.6551724137931034
        },
        "rouge1": {
            "precision": 0.64034,
            "recall": 0.66622,
            "fmeasure": 0.6432
        },
        "rouge2": {
            "precision": 0.36981,
            "recall": 0.38579,
            "fmeasure": 0.37127
        },
        "rougeL": {
            "precision": 0.50255,
            "recall": 0.5237,
            "fmeasure": 0.50459
        },
        "rougeLsum": {
            "precision": 0.50255,
            "recall": 0.5237,
            "fmeasure": 0.50459
        },
        "nist": 6.6185319803213645,
        "bleu": 30.74201,
        "nubia": {
            "semantic_relation": 3.86177,
            "contradiction": 22.07663,
            "irrelevancy": 15.73802,
            "logical_agreement": 62.18535,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.69097,
            "nubia_score": 0.61443
        },
        "bertscore": {
            "precision": 0.88108,
            "recall": 0.88684,
            "f1": 0.88244
        },
        "meteor": 0.317561624253898,
        "bleurt": -0.10724
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 56,
        "total_length": 664,
        "mean_pred_length": 11.857142857142858,
        "std_pred_length": 5.779979521183975,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.2816265060240964,
        "vocab_size-1": 187,
        "unique-1": 115,
        "entropy-1": 6.05078221133965,
        "distinct-2": 0.5509868421052632,
        "vocab_size-2": 335,
        "unique-2": 235,
        "entropy-2": 7.897335977883256,
        "cond_entropy-2": 1.6154954828712234,
        "distinct-3": 0.6865942028985508,
        "vocab_size-3": 379,
        "unique-3": 296,
        "entropy-3": 8.271293941303847,
        "cond_entropy-3": 0.4204415821530793,
        "total_length-nopunct": 583,
        "mean_pred_length-nopunct": 10.410714285714286,
        "std_pred_length-nopunct": 5.354493392450487,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.31732418524871353,
        "vocab_size-1-nopunct": 185,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.160262942394105,
        "distinct-2-nopunct": 0.5483870967741935,
        "vocab_size-2-nopunct": 289,
        "unique-2-nopunct": 205,
        "entropy-2-nopunct": 7.663307163686255,
        "cond_entropy-2-nopunct": 1.66303795421177,
        "distinct-3-nopunct": 0.6878980891719745,
        "vocab_size-3-nopunct": 324,
        "unique-3-nopunct": 255,
        "entropy-3-nopunct": 8.0347585923213,
        "cond_entropy-3-nopunct": 0.4044446178808555,
        "msttr-100": 0.56,
        "msttr-100_nopunct": 0.608,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19653179190751446,
            "2": 0.5833333333333334,
            "3": 0.8152173913043478
        },
        "rouge1": {
            "precision": 0.74828,
            "recall": 0.72581,
            "fmeasure": 0.72666
        },
        "rouge2": {
            "precision": 0.48975,
            "recall": 0.47962,
            "fmeasure": 0.47733
        },
        "rougeL": {
            "precision": 0.62247,
            "recall": 0.60383,
            "fmeasure": 0.60418
        },
        "rougeLsum": {
            "precision": 0.62247,
            "recall": 0.60383,
            "fmeasure": 0.60418
        },
        "nist": 6.054088300866928,
        "bleu": 39.41734,
        "nubia": {
            "semantic_relation": 4.34433,
            "contradiction": 4.23647,
            "irrelevancy": 8.31278,
            "logical_agreement": 87.45075,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.33112,
            "nubia_score": 0.75264
        },
        "bertscore": {
            "precision": 0.92231,
            "recall": 0.92345,
            "f1": 0.92172
        },
        "meteor": 0.38261885825170866,
        "bleurt": 0.15464
    },
    "web_nlg_ru_test": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 1102,
        "total_length": 23414,
        "mean_pred_length": 21.24682395644283,
        "std_pred_length": 11.382831018681673,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 70,
        "distinct-1": 0.11339369607926882,
        "vocab_size-1": 2655,
        "unique-1": 825,
        "entropy-1": 8.921238468884411,
        "distinct-2": 0.3004661168877734,
        "vocab_size-2": 6704,
        "unique-2": 3215,
        "entropy-2": 11.772034871163571,
        "cond_entropy-2": 2.594234720825897,
        "distinct-3": 0.44846770391324847,
        "vocab_size-3": 9512,
        "unique-3": 5631,
        "entropy-3": 12.643163568659498,
        "cond_entropy-3": 0.8933470777449644,
        "total_length-nopunct": 19201,
        "mean_pred_length-nopunct": 17.423774954627948,
        "std_pred_length-nopunct": 9.578839783274262,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.13785740326024687,
        "vocab_size-1-nopunct": 2647,
        "unique-1-nopunct": 825,
        "entropy-1-nopunct": 9.643938046960493,
        "distinct-2-nopunct": 0.3402397922537157,
        "vocab_size-2-nopunct": 6158,
        "unique-2-nopunct": 3207,
        "entropy-2-nopunct": 11.765661342653683,
        "cond_entropy-2-nopunct": 2.1982156605793897,
        "distinct-3-nopunct": 0.48926281108430897,
        "vocab_size-3-nopunct": 8316,
        "unique-3-nopunct": 5266,
        "entropy-3-nopunct": 12.483821968151226,
        "cond_entropy-3-nopunct": 0.7617493357531941,
        "msttr-100": 0.71325,
        "msttr-100_nopunct": 0.8062,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.29469702376704016,
            "2": 0.6737305628182193,
            "3": 0.8932636685948872,
            "4": 0.948051948051948,
            "5": 0.9459459459459459,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.44126,
            "recall": 0.44914,
            "fmeasure": 0.4415
        },
        "rouge2": {
            "precision": 0.25542,
            "recall": 0.26169,
            "fmeasure": 0.25463
        },
        "rougeL": {
            "precision": 0.42228,
            "recall": 0.43024,
            "fmeasure": 0.42251
        },
        "rougeLsum": {
            "precision": 0.42228,
            "recall": 0.43024,
            "fmeasure": 0.42251
        },
        "nist": 9.465501420113611,
        "bleu": 51.82818,
        "nubia": {
            "semantic_relation": 4.03055,
            "contradiction": 19.32632,
            "irrelevancy": 21.2248,
            "logical_agreement": 59.44888,
            "grammar_ref": 2.65213,
            "grammar_hyp": 2.60879,
            "nubia_score": 0.83664
        },
        "bertscore": {
            "precision": 0.95792,
            "recall": 0.9558,
            "f1": 0.9562
        },
        "meteor": 0.6645442107297311,
        "bleurt": 0.21617
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 28,
        "total_length": 292,
        "mean_pred_length": 10.428571428571429,
        "std_pred_length": 3.499271061118826,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.3698630136986301,
        "vocab_size-1": 108,
        "unique-1": 67,
        "entropy-1": 5.638935812054454,
        "distinct-2": 0.6856060606060606,
        "vocab_size-2": 181,
        "unique-2": 141,
        "entropy-2": 7.2175231216090685,
        "cond_entropy-2": 1.3338957074619815,
        "distinct-3": 0.826271186440678,
        "vocab_size-3": 195,
        "unique-3": 167,
        "entropy-3": 7.476819161604119,
        "cond_entropy-3": 0.3330142621765153,
        "total_length-nopunct": 257,
        "mean_pred_length-nopunct": 9.178571428571429,
        "std_pred_length-nopunct": 2.8915340889837533,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.4046692607003891,
        "vocab_size-1-nopunct": 104,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.686643750694403,
        "distinct-2-nopunct": 0.6550218340611353,
        "vocab_size-2-nopunct": 150,
        "unique-2-nopunct": 113,
        "entropy-2-nopunct": 6.924186076727188,
        "cond_entropy-2-nopunct": 1.4504748035722808,
        "distinct-3-nopunct": 0.8109452736318408,
        "vocab_size-3-nopunct": 163,
        "unique-3-nopunct": 138,
        "entropy-3-nopunct": 7.204412698587809,
        "cond_entropy-3-nopunct": 0.3554935015721747,
        "msttr-100": 0.545,
        "msttr-100_nopunct": 0.545,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.14965986394557823,
            "2": 0.6170212765957447,
            "3": 0.8962962962962963,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.82811,
            "recall": 0.786,
            "fmeasure": 0.80073
        },
        "rouge2": {
            "precision": 0.62776,
            "recall": 0.58741,
            "fmeasure": 0.60184
        },
        "rougeL": {
            "precision": 0.72506,
            "recall": 0.67755,
            "fmeasure": 0.69563
        },
        "rougeLsum": {
            "precision": 0.72506,
            "recall": 0.67755,
            "fmeasure": 0.69563
        },
        "nist": 6.914050361510056,
        "bleu": 61.39488,
        "nubia": {
            "semantic_relation": 4.27715,
            "contradiction": 21.09942,
            "irrelevancy": 3.1674,
            "logical_agreement": 75.73317,
            "grammar_ref": 4.67502,
            "grammar_hyp": 4.89953,
            "nubia_score": 0.7266
        },
        "bertscore": {
            "precision": 0.94507,
            "recall": 0.93438,
            "f1": 0.93874
        },
        "meteor": 0.4336292841717867,
        "bleurt": 0.35338
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7492,
        "mean_pred_length": 20.86908077994429,
        "std_pred_length": 9.90411506674438,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 90,
        "distinct-1": 0.35811532301121196,
        "vocab_size-1": 2683,
        "unique-1": 1949,
        "entropy-1": 9.162590524770721,
        "distinct-2": 0.8264404878732651,
        "vocab_size-2": 5895,
        "unique-2": 5446,
        "entropy-2": 12.17190860097906,
        "cond_entropy-2": 2.7610947300767554,
        "distinct-3": 0.9523176852671981,
        "vocab_size-3": 6451,
        "unique-3": 6319,
        "entropy-3": 12.557696604334403,
        "cond_entropy-3": 0.4057635451704732,
        "total_length-nopunct": 6640,
        "mean_pred_length-nopunct": 18.4958217270195,
        "std_pred_length-nopunct": 8.6732296697454,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.4022590361445783,
        "vocab_size-1-nopunct": 2671,
        "unique-1-nopunct": 1948,
        "entropy-1-nopunct": 9.508022386708033,
        "distinct-2-nopunct": 0.853844929151409,
        "vocab_size-2-nopunct": 5363,
        "unique-2-nopunct": 4997,
        "entropy-2-nopunct": 12.115390542732557,
        "cond_entropy-2-nopunct": 2.7412498519307693,
        "distinct-3-nopunct": 0.971968929415738,
        "vocab_size-3-nopunct": 5756,
        "unique-3-nopunct": 5656,
        "entropy-3-nopunct": 12.459634595557144,
        "cond_entropy-3-nopunct": 0.3666512106596183,
        "msttr-100": 0.72824,
        "msttr-100_nopunct": 0.76773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.044142614601018676,
            "2": 0.17752234993614305,
            "3": 0.4201312910284464,
            "4": 0.5673534072900158,
            "5": 0.6895119418483905,
            "6": 0.7916666666666666,
            "7": 0.8896525391370752
        },
        "rouge1": {
            "precision": 0.8481,
            "recall": 0.81238,
            "fmeasure": 0.82056
        },
        "rouge2": {
            "precision": 0.7122,
            "recall": 0.68341,
            "fmeasure": 0.68846
        },
        "rougeL": {
            "precision": 0.82098,
            "recall": 0.78829,
            "fmeasure": 0.79468
        },
        "rougeLsum": {
            "precision": 0.82098,
            "recall": 0.78829,
            "fmeasure": 0.79468
        },
        "nist": 11.210690329278748,
        "bleu": 68.27395,
        "nubia": {
            "semantic_relation": 4.36759,
            "contradiction": 4.15557,
            "irrelevancy": 17.5334,
            "logical_agreement": 78.31103,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.93126,
            "nubia_score": 0.71107
        },
        "bertscore": {
            "precision": 0.95374,
            "recall": 0.94932,
            "f1": 0.94939
        },
        "meteor": 0.47285419726840644,
        "bleurt": 0.23223
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7492,
        "mean_pred_length": 20.86908077994429,
        "std_pred_length": 9.90411506674438,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 90,
        "distinct-1": 0.35811532301121196,
        "vocab_size-1": 2683,
        "unique-1": 1949,
        "entropy-1": 9.162590524770721,
        "distinct-2": 0.8264404878732651,
        "vocab_size-2": 5895,
        "unique-2": 5446,
        "entropy-2": 12.17190860097906,
        "cond_entropy-2": 2.7610947300767554,
        "distinct-3": 0.9523176852671981,
        "vocab_size-3": 6451,
        "unique-3": 6319,
        "entropy-3": 12.557696604334403,
        "cond_entropy-3": 0.4057635451704732,
        "total_length-nopunct": 6640,
        "mean_pred_length-nopunct": 18.4958217270195,
        "std_pred_length-nopunct": 8.6732296697454,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.4022590361445783,
        "vocab_size-1-nopunct": 2671,
        "unique-1-nopunct": 1948,
        "entropy-1-nopunct": 9.508022386708033,
        "distinct-2-nopunct": 0.853844929151409,
        "vocab_size-2-nopunct": 5363,
        "unique-2-nopunct": 4997,
        "entropy-2-nopunct": 12.115390542732557,
        "cond_entropy-2-nopunct": 2.7412498519307693,
        "distinct-3-nopunct": 0.971968929415738,
        "vocab_size-3-nopunct": 5756,
        "unique-3-nopunct": 5656,
        "entropy-3-nopunct": 12.459634595557144,
        "cond_entropy-3-nopunct": 0.3666512106596183,
        "msttr-100": 0.72824,
        "msttr-100_nopunct": 0.76773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.044142614601018676,
            "2": 0.17752234993614305,
            "3": 0.4201312910284464,
            "4": 0.5673534072900158,
            "5": 0.6895119418483905,
            "6": 0.7916666666666666,
            "7": 0.8896525391370752
        },
        "rouge1": {
            "precision": 0.8481,
            "recall": 0.81238,
            "fmeasure": 0.82056
        },
        "rouge2": {
            "precision": 0.7122,
            "recall": 0.68341,
            "fmeasure": 0.68846
        },
        "rougeL": {
            "precision": 0.82098,
            "recall": 0.78829,
            "fmeasure": 0.79468
        },
        "rougeLsum": {
            "precision": 0.82098,
            "recall": 0.78829,
            "fmeasure": 0.79468
        },
        "nist": 11.210690329278748,
        "bleu": 68.27395,
        "nubia": {
            "semantic_relation": 4.36759,
            "contradiction": 4.15557,
            "irrelevancy": 17.5334,
            "logical_agreement": 78.31103,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.93126,
            "nubia_score": 0.71107
        },
        "bertscore": {
            "precision": 0.95374,
            "recall": 0.94932,
            "f1": 0.94939
        },
        "meteor": 0.47285419726840644,
        "bleurt": 0.23223
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 149,
        "total_length": 1192,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.006711409395973154,
        "vocab_size-1": 8,
        "unique-1": 0,
        "entropy-1": 3.0,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 7,
        "unique-2": 0,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 6,
        "unique-3": 0,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 894,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 0.006711409395973154,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": 0.08,
        "msttr-100_nopunct": 0.06,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.1742627345844504
        },
        "rouge1": {
            "precision": 0.2528,
            "recall": 0.33731,
            "fmeasure": 0.28305
        },
        "rouge2": {
            "precision": 0.10906,
            "recall": 0.1587,
            "fmeasure": 0.12582
        },
        "rougeL": {
            "precision": 0.21775,
            "recall": 0.2935,
            "fmeasure": 0.2446
        },
        "rougeLsum": {
            "precision": 0.21775,
            "recall": 0.2935,
            "fmeasure": 0.2446
        },
        "nist": 0.7981222518005632,
        "bleu": 0.57781,
        "nubia": {
            "semantic_relation": 1.58616,
            "contradiction": 51.55783,
            "irrelevancy": 44.13536,
            "logical_agreement": 4.30681,
            "grammar_ref": 6.81129,
            "grammar_hyp": 7.63725,
            "nubia_score": 0.08272
        },
        "bertscore": {
            "precision": 0.82092,
            "recall": 0.86881,
            "f1": 0.84411
        },
        "meteor": 0.0899761224919898,
        "bleurt": -0.71859
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 609,
        "total_length": 6650,
        "mean_pred_length": 10.919540229885058,
        "std_pred_length": 2.7198285078461395,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.06451127819548873,
        "vocab_size-1": 429,
        "unique-1": 170,
        "entropy-1": 6.338501612339992,
        "distinct-2": 0.16470782982949841,
        "vocab_size-2": 995,
        "unique-2": 495,
        "entropy-2": 8.13940261856336,
        "cond_entropy-2": 1.5027459849492586,
        "distinct-3": 0.26712076583210603,
        "vocab_size-3": 1451,
        "unique-3": 876,
        "entropy-3": 8.9656836686512,
        "cond_entropy-3": 1.010952525872534,
        "total_length-nopunct": 5698,
        "mean_pred_length-nopunct": 9.35632183908046,
        "std_pred_length-nopunct": 2.4839974407358327,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.07476307476307477,
        "vocab_size-1-nopunct": 426,
        "unique-1-nopunct": 170,
        "entropy-1-nopunct": 6.5257110362319946,
        "distinct-2-nopunct": 0.15189624680683828,
        "vocab_size-2-nopunct": 773,
        "unique-2-nopunct": 377,
        "entropy-2-nopunct": 7.842401723389873,
        "cond_entropy-2-nopunct": 1.6725196878301432,
        "distinct-3-nopunct": 0.26183035714285713,
        "vocab_size-3-nopunct": 1173,
        "unique-3-nopunct": 712,
        "entropy-3-nopunct": 8.714758624143206,
        "cond_entropy-3-nopunct": 1.1860261020596872,
        "msttr-100": 0.51439,
        "msttr-100_nopunct": 0.53679,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.5263625066571986
        },
        "rouge1": {
            "precision": 0.56355,
            "recall": 0.57194,
            "fmeasure": 0.55351
        },
        "rouge2": {
            "precision": 0.33863,
            "recall": 0.34769,
            "fmeasure": 0.33366
        },
        "rougeL": {
            "precision": 0.5125,
            "recall": 0.51932,
            "fmeasure": 0.50341
        },
        "rougeLsum": {
            "precision": 0.5125,
            "recall": 0.51932,
            "fmeasure": 0.50341
        },
        "nist": 4.540355778095908,
        "bleu": 22.00492,
        "nubia": {
            "semantic_relation": 3.59887,
            "contradiction": 20.83313,
            "irrelevancy": 31.41297,
            "logical_agreement": 47.7539,
            "grammar_ref": 6.96179,
            "grammar_hyp": 6.89204,
            "nubia_score": 0.55008
        },
        "bertscore": {
            "precision": 0.90625,
            "recall": 0.91163,
            "f1": 0.9087
        },
        "meteor": 0.2672731388998854,
        "bleurt": -0.0623
    },
    "xsum_challenge_test_bfp_05_parent": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 500,
        "total_length": 10745,
        "mean_pred_length": 21.49,
        "std_pred_length": 5.213242752836281,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 68,
        "distinct-1": 0.259004187994416,
        "vocab_size-1": 2783,
        "unique-1": 1777,
        "entropy-1": 8.903256954575546,
        "distinct-2": 0.6914592484138604,
        "vocab_size-2": 7084,
        "unique-2": 6068,
        "entropy-2": 12.178932952288138,
        "cond_entropy-2": 3.0581626104235142,
        "distinct-3": 0.893689071318625,
        "vocab_size-3": 8709,
        "unique-3": 8190,
        "entropy-3": 12.947403362488899,
        "cond_entropy-3": 0.7779912615453675,
        "total_length-nopunct": 10016,
        "mean_pred_length-nopunct": 20.032,
        "std_pred_length-nopunct": 4.892338500144895,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.27675718849840253,
        "vocab_size-1-nopunct": 2772,
        "unique-1-nopunct": 1775,
        "entropy-1-nopunct": 9.069971821373805,
        "distinct-2-nopunct": 0.6988230348886086,
        "vocab_size-2-nopunct": 6650,
        "unique-2-nopunct": 5713,
        "entropy-2-nopunct": 12.102490034000496,
        "cond_entropy-2-nopunct": 3.1510446304868,
        "distinct-3-nopunct": 0.9030612244897959,
        "vocab_size-3-nopunct": 8142,
        "unique-3-nopunct": 7683,
        "entropy-3-nopunct": 12.872375182155503,
        "cond_entropy-3-nopunct": 0.7889156455014881,
        "msttr-100": 0.71206,
        "msttr-100_nopunct": 0.7307,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.31780167264038234
        },
        "rouge1": {
            "precision": 0.37107,
            "recall": 0.34593,
            "fmeasure": 0.35163
        },
        "rouge2": {
            "precision": 0.12543,
            "recall": 0.11659,
            "fmeasure": 0.11854
        },
        "rougeL": {
            "precision": 0.28654,
            "recall": 0.26715,
            "fmeasure": 0.27166
        },
        "rougeLsum": {
            "precision": 0.28654,
            "recall": 0.26715,
            "fmeasure": 0.27166
        },
        "nist": 3.252767513024902,
        "bleu": 7.67489,
        "nubia": {
            "semantic_relation": 2.52722,
            "contradiction": 28.09395,
            "irrelevancy": 63.54319,
            "logical_agreement": 8.36286,
            "grammar_ref": 3.79385,
            "grammar_hyp": 3.6992,
            "nubia_score": 0.33559
        },
        "bertscore": {
            "precision": 0.82143,
            "recall": 0.80881,
            "f1": 0.81482
        },
        "meteor": 0.1507285133362478,
        "bleurt": -0.41215
    },
    "xsum_challenge_test_nopunc_parent": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 500,
        "total_length": 10690,
        "mean_pred_length": 21.38,
        "std_pred_length": 5.111125120753747,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 68,
        "distinct-1": 0.2606173994387278,
        "vocab_size-1": 2786,
        "unique-1": 1733,
        "entropy-1": 8.933599704484527,
        "distinct-2": 0.6982335623159961,
        "vocab_size-2": 7115,
        "unique-2": 6084,
        "entropy-2": 12.225379122764835,
        "cond_entropy-2": 3.0712398851512757,
        "distinct-3": 0.899484004127967,
        "vocab_size-3": 8716,
        "unique-3": 8216,
        "entropy-3": 12.960398500041574,
        "cond_entropy-3": 0.7486274730784962,
        "total_length-nopunct": 9947,
        "mean_pred_length-nopunct": 19.894,
        "std_pred_length-nopunct": 4.743286202623662,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.278978586508495,
        "vocab_size-1-nopunct": 2775,
        "unique-1-nopunct": 1731,
        "entropy-1-nopunct": 9.102358104850135,
        "distinct-2-nopunct": 0.704244733777919,
        "vocab_size-2-nopunct": 6653,
        "unique-2-nopunct": 5704,
        "entropy-2-nopunct": 12.140847967208213,
        "cond_entropy-2-nopunct": 3.1595788962203724,
        "distinct-3-nopunct": 0.9077903207779144,
        "vocab_size-3-nopunct": 8122,
        "unique-3-nopunct": 7678,
        "entropy-3-nopunct": 12.879850092166711,
        "cond_entropy-3-nopunct": 0.7611604137006717,
        "msttr-100": 0.71642,
        "msttr-100_nopunct": 0.73808,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3249296906388108
        },
        "rouge1": {
            "precision": 0.37447,
            "recall": 0.35114,
            "fmeasure": 0.35468
        },
        "rouge2": {
            "precision": 0.13037,
            "recall": 0.12212,
            "fmeasure": 0.12318
        },
        "rougeL": {
            "precision": 0.2871,
            "recall": 0.26908,
            "fmeasure": 0.27177
        },
        "rougeLsum": {
            "precision": 0.2871,
            "recall": 0.26908,
            "fmeasure": 0.27177
        },
        "nist": 3.3501648104639306,
        "bleu": 8.10559,
        "nubia": {
            "semantic_relation": 2.57645,
            "contradiction": 25.32258,
            "irrelevancy": 64.93657,
            "logical_agreement": 9.74086,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.69772,
            "nubia_score": 0.34378
        },
        "bertscore": {
            "precision": 0.82187,
            "recall": 0.80906,
            "f1": 0.81511
        },
        "meteor": 0.15409648722409933,
        "bleurt": -0.41076
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.23529411764705882
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.25389,
            "fmeasure": 0.31878
        },
        "rouge2": {
            "precision": 0.2381,
            "recall": 0.13228,
            "fmeasure": 0.16762
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.23587,
            "fmeasure": 0.29314
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.23587,
            "fmeasure": 0.29314
        },
        "nist": 0.4503506019270825,
        "bleu": 5.73311,
        "nubia": {
            "semantic_relation": 3.0694,
            "contradiction": 94.60027,
            "irrelevancy": 2.16757,
            "logical_agreement": 3.23217,
            "grammar_ref": 4.39709,
            "grammar_hyp": 3.54401,
            "nubia_score": 0.35884
        },
        "bertscore": {
            "precision": 0.89782,
            "recall": 0.81588,
            "f1": 0.8549
        },
        "meteor": 0.17424614595917218,
        "bleurt": -0.12415
    },
    "common_gen_test": {
        "predictions_file": "mT5_base/common_gen_test",
        "N": 1497
    },
    "common_gen_challenge_test_scramble": {
        "predictions_file": "mT5_base/common_gen_challenge_test_scramble",
        "N": 500
    },
    "dart_val": {
        "predictions_file": "mT5_base/dart_val",
        "N": 2768
    },
    "dart_test": {
        "predictions_file": "mT5_base/dart_test",
        "N": 6959
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.15351,
            "recall": 0.4823,
            "fmeasure": 0.23246
        },
        "rouge2": {
            "precision": 0.02667,
            "recall": 0.10741,
            "fmeasure": 0.04271
        },
        "rougeL": {
            "precision": 0.11404,
            "recall": 0.37112,
            "fmeasure": 0.17379
        },
        "rougeLsum": {
            "precision": 0.11404,
            "recall": 0.37112,
            "fmeasure": 0.17379
        },
        "nist": 0.6716643055393374,
        "bleu": 5.3923,
        "nubia": {
            "semantic_relation": 2.61994,
            "contradiction": 0.97828,
            "irrelevancy": 55.35685,
            "logical_agreement": 43.66487,
            "grammar_ref": 4.75948,
            "grammar_hyp": 3.47631,
            "nubia_score": 0.07284
        },
        "bertscore": {
            "precision": 0.71311,
            "recall": 0.8141,
            "f1": 0.76013
        },
        "meteor": 0.14635251999187568,
        "bleurt": -1.15033
    },
    "schema_guided_dialog_challenge_test_bfp02": {
        "predictions_file": "mT5_base/schema_guided_dialog_challenge_test_bfp02",
        "N": 500,
        "total_length": 6570,
        "mean_pred_length": 13.14,
        "std_pred_length": 8.154532482000425,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 46,
        "distinct-1": 0.16270928462709286,
        "vocab_size-1": 1069,
        "unique-1": 602,
        "entropy-1": 7.945383800648952,
        "distinct-2": 0.5255354200988468,
        "vocab_size-2": 3190,
        "unique-2": 2297,
        "entropy-2": 10.95622827539052,
        "cond_entropy-2": 2.7762060419940635,
        "distinct-3": 0.7605026929982047,
        "vocab_size-3": 4236,
        "unique-3": 3592,
        "entropy-3": 11.783831992090857,
        "cond_entropy-3": 0.844624168736516,
        "total_length-nopunct": 5803,
        "mean_pred_length-nopunct": 11.606,
        "std_pred_length-nopunct": 7.577517007569168,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.18197484059968982,
        "vocab_size-1-nopunct": 1056,
        "unique-1-nopunct": 599,
        "entropy-1-nopunct": 8.131589076929913,
        "distinct-2-nopunct": 0.5423345276258722,
        "vocab_size-2-nopunct": 2876,
        "unique-2-nopunct": 2130,
        "entropy-2-nopunct": 10.797507037382243,
        "cond_entropy-2-nopunct": 2.786895576772154,
        "distinct-3-nopunct": 0.7703996669442131,
        "vocab_size-3-nopunct": 3701,
        "unique-3-nopunct": 3183,
        "entropy-3-nopunct": 11.586606215072067,
        "cond_entropy-3-nopunct": 0.8245266847549017,
        "msttr-100": 0.70138,
        "msttr-100_nopunct": 0.72621,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp02.json",
        "local_recall": {
            "1": 0.5056649816977514
        },
        "rouge1": {
            "precision": 0.52151,
            "recall": 0.49274,
            "fmeasure": 0.49164
        },
        "rouge2": {
            "precision": 0.2987,
            "recall": 0.27832,
            "fmeasure": 0.27781
        },
        "rougeL": {
            "precision": 0.45765,
            "recall": 0.42968,
            "fmeasure": 0.4302
        },
        "rougeLsum": {
            "precision": 0.45765,
            "recall": 0.42968,
            "fmeasure": 0.4302
        },
        "nist": 5.373781538576437,
        "bleu": 26.02164,
        "nubia": {
            "semantic_relation": 3.3762,
            "contradiction": 8.0838,
            "irrelevancy": 26.93837,
            "logical_agreement": 64.97784,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.84864,
            "nubia_score": 0.55327
        },
        "bertscore": {
            "precision": 0.85382,
            "recall": 0.84496,
            "f1": 0.84875
        },
        "meteor": 0.2818654444968996,
        "bleurt": -0.24047
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 56,
        "total_length": 1913,
        "mean_pred_length": 34.160714285714285,
        "std_pred_length": 8.329759012365342,
        "median_pred_length": 33.0,
        "min_pred_length": 18,
        "max_pred_length": 67,
        "distinct-1": 0.3324621014113957,
        "vocab_size-1": 636,
        "unique-1": 352,
        "entropy-1": 7.930993141996248,
        "distinct-2": 0.624663435648896,
        "vocab_size-2": 1160,
        "unique-2": 812,
        "entropy-2": 9.827329438483162,
        "cond_entropy-2": 1.771553205122128,
        "distinct-3": 0.7579122709605774,
        "vocab_size-3": 1365,
        "unique-3": 1080,
        "entropy-3": 10.228350962904207,
        "cond_entropy-3": 0.40497093733075296,
        "total_length-nopunct": 1608,
        "mean_pred_length-nopunct": 28.714285714285715,
        "std_pred_length-nopunct": 7.050112171636212,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.39116915422885573,
        "vocab_size-1-nopunct": 629,
        "unique-1-nopunct": 351,
        "entropy-1-nopunct": 8.378133157750867,
        "distinct-2-nopunct": 0.6662371134020618,
        "vocab_size-2-nopunct": 1034,
        "unique-2-nopunct": 745,
        "entropy-2-nopunct": 9.732272838198536,
        "cond_entropy-2-nopunct": 1.3845307839854286,
        "distinct-3-nopunct": 0.7867647058823529,
        "vocab_size-3-nopunct": 1177,
        "unique-3-nopunct": 955,
        "entropy-3-nopunct": 10.038200943820074,
        "cond_entropy-3-nopunct": 0.31884466826662694,
        "msttr-100": 0.62211,
        "msttr-100_nopunct": 0.66875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.26078971533516987,
            "2": 0.6391096979332274,
            "3": 0.9188712522045855
        },
        "rouge1": {
            "precision": 0.78816,
            "recall": 0.79883,
            "fmeasure": 0.7877
        },
        "rouge2": {
            "precision": 0.5834,
            "recall": 0.59971,
            "fmeasure": 0.58306
        },
        "rougeL": {
            "precision": 0.70585,
            "recall": 0.7149,
            "fmeasure": 0.7043
        },
        "rougeLsum": {
            "precision": 0.70585,
            "recall": 0.7149,
            "fmeasure": 0.7043
        },
        "nist": 8.481817872439233,
        "bleu": 55.42173,
        "nubia": {
            "semantic_relation": 3.77178,
            "contradiction": 19.00545,
            "irrelevancy": 23.99275,
            "logical_agreement": 57.0018,
            "grammar_ref": 2.50981,
            "grammar_hyp": 2.50686,
            "nubia_score": 0.83686
        },
        "bertscore": {
            "precision": 0.95295,
            "recall": 0.94939,
            "f1": 0.95067
        },
        "meteor": 0.6510607509632951,
        "bleurt": 0.12158
    },
    "schema_guided_dialog_challenge_test_bfp05": {
        "predictions_file": "mT5_base/schema_guided_dialog_challenge_test_bfp05",
        "N": 500,
        "total_length": 6410,
        "mean_pred_length": 12.82,
        "std_pred_length": 8.033903160979724,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 49,
        "distinct-1": 0.16380655226209048,
        "vocab_size-1": 1050,
        "unique-1": 601,
        "entropy-1": 7.8731874255498875,
        "distinct-2": 0.5270727580372251,
        "vocab_size-2": 3115,
        "unique-2": 2294,
        "entropy-2": 10.888851239670467,
        "cond_entropy-2": 2.7768791536766413,
        "distinct-3": 0.7650646950092421,
        "vocab_size-3": 4139,
        "unique-3": 3576,
        "entropy-3": 11.7268853085796,
        "cond_entropy-3": 0.8480172956576543,
        "total_length-nopunct": 5635,
        "mean_pred_length-nopunct": 11.27,
        "std_pred_length-nopunct": 7.343643509866203,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.18438331854480922,
        "vocab_size-1-nopunct": 1039,
        "unique-1-nopunct": 599,
        "entropy-1-nopunct": 8.077531301054895,
        "distinct-2-nopunct": 0.5444985394352483,
        "vocab_size-2-nopunct": 2796,
        "unique-2-nopunct": 2102,
        "entropy-2-nopunct": 10.731767622226478,
        "cond_entropy-2-nopunct": 2.7822619685356687,
        "distinct-3-nopunct": 0.7793832219107182,
        "vocab_size-3-nopunct": 3614,
        "unique-3-nopunct": 3164,
        "entropy-3-nopunct": 11.539669366565551,
        "cond_entropy-3-nopunct": 0.8314286148030946,
        "msttr-100": 0.69297,
        "msttr-100_nopunct": 0.72482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp05.json",
        "local_recall": {
            "1": 0.510993037742763
        },
        "rouge1": {
            "precision": 0.51153,
            "recall": 0.49246,
            "fmeasure": 0.48733
        },
        "rouge2": {
            "precision": 0.29436,
            "recall": 0.27944,
            "fmeasure": 0.27781
        },
        "rougeL": {
            "precision": 0.45686,
            "recall": 0.43851,
            "fmeasure": 0.43483
        },
        "rougeLsum": {
            "precision": 0.45686,
            "recall": 0.43851,
            "fmeasure": 0.43483
        },
        "nist": 5.256457769774703,
        "bleu": 26.61187,
        "nubia": {
            "semantic_relation": 3.37932,
            "contradiction": 7.63276,
            "irrelevancy": 28.53233,
            "logical_agreement": 63.83491,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.82087,
            "nubia_score": 0.55671
        },
        "bertscore": {
            "precision": 0.85125,
            "recall": 0.84731,
            "f1": 0.8487
        },
        "meteor": 0.28604410932356794,
        "bleurt": -0.2561
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 19,
        "total_length": 738,
        "mean_pred_length": 38.8421052631579,
        "std_pred_length": 8.125743094082223,
        "median_pred_length": 38.0,
        "min_pred_length": 24,
        "max_pred_length": 52,
        "distinct-1": 0.2899728997289973,
        "vocab_size-1": 214,
        "unique-1": 92,
        "entropy-1": 6.752870455482376,
        "distinct-2": 0.48400556328233657,
        "vocab_size-2": 348,
        "unique-2": 185,
        "entropy-2": 8.063683035985866,
        "cond_entropy-2": 1.2334957095943124,
        "distinct-3": 0.5757142857142857,
        "vocab_size-3": 403,
        "unique-3": 244,
        "entropy-3": 8.386969257994963,
        "cond_entropy-3": 0.32560275668851163,
        "total_length-nopunct": 639,
        "mean_pred_length-nopunct": 33.63157894736842,
        "std_pred_length-nopunct": 7.357134212634338,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.3302034428794992,
        "vocab_size-1-nopunct": 211,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.947109739429694,
        "distinct-2-nopunct": 0.5048387096774194,
        "vocab_size-2-nopunct": 313,
        "unique-2-nopunct": 171,
        "entropy-2-nopunct": 7.957589651171209,
        "cond_entropy-2-nopunct": 1.02871256938351,
        "distinct-3-nopunct": 0.5973377703826955,
        "vocab_size-3-nopunct": 359,
        "unique-3-nopunct": 228,
        "entropy-3-nopunct": 8.22430643835172,
        "cond_entropy-3-nopunct": 0.2748674180188167,
        "msttr-100": 0.59571,
        "msttr-100_nopunct": 0.615,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.39661016949152544,
            "2": 0.7218045112781954,
            "3": 0.9455445544554455
        },
        "rouge1": {
            "precision": 0.91992,
            "recall": 0.93721,
            "fmeasure": 0.92504
        },
        "rouge2": {
            "precision": 0.6652,
            "recall": 0.6891,
            "fmeasure": 0.67033
        },
        "rougeL": {
            "precision": 0.85468,
            "recall": 0.86937,
            "fmeasure": 0.85863
        },
        "rougeLsum": {
            "precision": 0.85468,
            "recall": 0.86937,
            "fmeasure": 0.85863
        },
        "nist": 7.793707149097352,
        "bleu": 62.66394,
        "nubia": {
            "semantic_relation": 3.75775,
            "contradiction": 21.00487,
            "irrelevancy": 22.7482,
            "logical_agreement": 56.24693,
            "grammar_ref": 2.51721,
            "grammar_hyp": 2.52949,
            "nubia_score": 0.86114
        },
        "bertscore": {
            "precision": 0.96003,
            "recall": 0.95695,
            "f1": 0.95835
        },
        "meteor": 0.7368821400035965,
        "bleurt": 0.16497
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 12,
        "total_length": 506,
        "mean_pred_length": 42.166666666666664,
        "std_pred_length": 7.592027982620249,
        "median_pred_length": 43.5,
        "min_pred_length": 30,
        "max_pred_length": 53,
        "distinct-1": 0.32608695652173914,
        "vocab_size-1": 165,
        "unique-1": 67,
        "entropy-1": 6.5241251588422084,
        "distinct-2": 0.5526315789473685,
        "vocab_size-2": 273,
        "unique-2": 154,
        "entropy-2": 7.777721203036208,
        "cond_entropy-2": 1.1858456207707588,
        "distinct-3": 0.6721991701244814,
        "vocab_size-3": 324,
        "unique-3": 217,
        "entropy-3": 8.154467687997272,
        "cond_entropy-3": 0.37930659108420284,
        "total_length-nopunct": 438,
        "mean_pred_length-nopunct": 36.5,
        "std_pred_length-nopunct": 6.751543033509698,
        "median_pred_length-nopunct": 39.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.3698630136986301,
        "vocab_size-1-nopunct": 162,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.6867625385084075,
        "distinct-2-nopunct": 0.5821596244131455,
        "vocab_size-2-nopunct": 248,
        "unique-2-nopunct": 142,
        "entropy-2-nopunct": 7.714534040676986,
        "cond_entropy-2-nopunct": 1.0467896580514964,
        "distinct-3-nopunct": 0.6932367149758454,
        "vocab_size-3-nopunct": 287,
        "unique-3-nopunct": 194,
        "entropy-3-nopunct": 8.009979583044768,
        "cond_entropy-3-nopunct": 0.3066946835606548,
        "msttr-100": 0.624,
        "msttr-100_nopunct": 0.625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.4264705882352941,
            "2": 0.6149425287356322,
            "3": 0.8924050632911392
        },
        "rouge1": {
            "precision": 0.93634,
            "recall": 0.87632,
            "fmeasure": 0.89492
        },
        "rouge2": {
            "precision": 0.52903,
            "recall": 0.51065,
            "fmeasure": 0.51199
        },
        "rougeL": {
            "precision": 0.85995,
            "recall": 0.80387,
            "fmeasure": 0.81842
        },
        "rougeLsum": {
            "precision": 0.85995,
            "recall": 0.80387,
            "fmeasure": 0.81842
        },
        "nist": 7.238621173682913,
        "bleu": 56.09177,
        "nubia": {
            "semantic_relation": 3.5097,
            "contradiction": 25.13016,
            "irrelevancy": 25.75873,
            "logical_agreement": 49.11111,
            "grammar_ref": 2.55511,
            "grammar_hyp": 2.51766,
            "nubia_score": 0.83562
        },
        "bertscore": {
            "precision": 0.95746,
            "recall": 0.94971,
            "f1": 0.9528
        },
        "meteor": 0.6953724769928993,
        "bleurt": 0.08702
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 22,
        "total_length": 211,
        "mean_pred_length": 9.590909090909092,
        "std_pred_length": 1.6964961460474113,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 11,
        "distinct-1": 0.09004739336492891,
        "vocab_size-1": 19,
        "unique-1": 0,
        "entropy-1": 4.099667637841016,
        "distinct-2": 0.12698412698412698,
        "vocab_size-2": 24,
        "unique-2": 0,
        "entropy-2": 4.456807221898623,
        "cond_entropy-2": 0.25959460262393474,
        "distinct-3": 0.1317365269461078,
        "vocab_size-3": 22,
        "unique-3": 0,
        "entropy-3": 4.323076151922691,
        "cond_entropy-3": -0.13530890450825644,
        "total_length-nopunct": 161,
        "mean_pred_length-nopunct": 7.318181818181818,
        "std_pred_length-nopunct": 1.2572106078126664,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.10559006211180125,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.030242196095184,
        "distinct-2-nopunct": 0.12949640287769784,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.041523032414441,
        "cond_entropy-2-nopunct": -0.020656158939462207,
        "distinct-3-nopunct": 0.13675213675213677,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 3.8621702423518176,
        "cond_entropy-3-nopunct": -0.18687309716682415,
        "msttr-100": 0.19,
        "msttr-100_nopunct": 0.17,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.22857142857142856
        },
        "rouge1": {
            "precision": 0.33345,
            "recall": 0.33771,
            "fmeasure": 0.33162
        },
        "rouge2": {
            "precision": 0.20076,
            "recall": 0.19662,
            "fmeasure": 0.19668
        },
        "rougeL": {
            "precision": 0.31632,
            "recall": 0.31831,
            "fmeasure": 0.31348
        },
        "rougeLsum": {
            "precision": 0.31632,
            "recall": 0.31831,
            "fmeasure": 0.31348
        },
        "nist": 1.8144261924821563,
        "bleu": 17.19383,
        "nubia": {
            "semantic_relation": 2.16866,
            "contradiction": 45.57115,
            "irrelevancy": 25.85777,
            "logical_agreement": 28.57108,
            "grammar_ref": 6.09546,
            "grammar_hyp": 6.09318,
            "nubia_score": 0.28935
        },
        "bertscore": {
            "precision": 0.88286,
            "recall": 0.88349,
            "f1": 0.8831
        },
        "meteor": 0.1324226078515793,
        "bleurt": -0.3746
    },
    "schema_guided_dialog_challenge_test_nopunc": {
        "predictions_file": "mT5_base/schema_guided_dialog_challenge_test_nopunc",
        "N": 500,
        "total_length": 6424,
        "mean_pred_length": 12.848,
        "std_pred_length": 7.8514263672278055,
        "median_pred_length": 11.0,
        "min_pred_length": 1,
        "max_pred_length": 43,
        "distinct-1": 0.1727895392278954,
        "vocab_size-1": 1110,
        "unique-1": 644,
        "entropy-1": 8.06779931017173,
        "distinct-2": 0.5405131667792032,
        "vocab_size-2": 3202,
        "unique-2": 2368,
        "entropy-2": 10.952756179094445,
        "cond_entropy-2": 2.834858588817043,
        "distinct-3": 0.778289716181349,
        "vocab_size-3": 4223,
        "unique-3": 3646,
        "entropy-3": 11.778824880800606,
        "cond_entropy-3": 0.8663989423928798,
        "total_length-nopunct": 5788,
        "mean_pred_length-nopunct": 11.576,
        "std_pred_length-nopunct": 7.189174083300529,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.18970283344851416,
        "vocab_size-1-nopunct": 1098,
        "unique-1-nopunct": 644,
        "entropy-1-nopunct": 8.178067957180634,
        "distinct-2-nopunct": 0.55767776096823,
        "vocab_size-2-nopunct": 2949,
        "unique-2-nopunct": 2234,
        "entropy-2-nopunct": 10.828380384264548,
        "cond_entropy-2-nopunct": 2.7867256548985324,
        "distinct-3-nopunct": 0.7908141962421712,
        "vocab_size-3-nopunct": 3788,
        "unique-3-nopunct": 3311,
        "entropy-3-nopunct": 11.629260715630073,
        "cond_entropy-3-nopunct": 0.8332548765643046,
        "msttr-100": 0.72219,
        "msttr-100_nopunct": 0.74105,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_nopunc.json",
        "local_recall": {
            "1": 0.5048671836330638
        },
        "rouge1": {
            "precision": 0.53471,
            "recall": 0.48483,
            "fmeasure": 0.49471
        },
        "rouge2": {
            "precision": 0.30444,
            "recall": 0.27505,
            "fmeasure": 0.28027
        },
        "rougeL": {
            "precision": 0.46138,
            "recall": 0.41761,
            "fmeasure": 0.42651
        },
        "rougeLsum": {
            "precision": 0.46138,
            "recall": 0.41761,
            "fmeasure": 0.42651
        },
        "nist": 5.465684086425271,
        "bleu": 25.13065,
        "nubia": {
            "semantic_relation": 3.42207,
            "contradiction": 7.96401,
            "irrelevancy": 25.58395,
            "logical_agreement": 66.45203,
            "grammar_ref": 4.79983,
            "grammar_hyp": 5.11647,
            "nubia_score": 0.54712
        },
        "bertscore": {
            "precision": 0.85377,
            "recall": 0.83794,
            "f1": 0.84524
        },
        "meteor": 0.2820220571718664,
        "bleurt": -0.25917
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 453,
        "total_length": 5478,
        "mean_pred_length": 12.092715231788079,
        "std_pred_length": 4.685260802394754,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.16757940854326397,
        "vocab_size-1": 918,
        "unique-1": 470,
        "entropy-1": 7.346938752588935,
        "distinct-2": 0.43402985074626865,
        "vocab_size-2": 2181,
        "unique-2": 1387,
        "entropy-2": 10.301278425504574,
        "cond_entropy-2": 2.615914534369427,
        "distinct-3": 0.6327646544181977,
        "vocab_size-3": 2893,
        "unique-3": 2178,
        "entropy-3": 11.105520645287967,
        "cond_entropy-3": 0.9026800362635535,
        "total_length-nopunct": 4784,
        "mean_pred_length-nopunct": 10.560706401766005,
        "std_pred_length-nopunct": 4.129146006332865,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.19000836120401338,
        "vocab_size-1-nopunct": 909,
        "unique-1-nopunct": 467,
        "entropy-1-nopunct": 7.608473145196654,
        "distinct-2-nopunct": 0.41884091433848997,
        "vocab_size-2-nopunct": 1814,
        "unique-2-nopunct": 1138,
        "entropy-2-nopunct": 10.009689717787303,
        "cond_entropy-2-nopunct": 2.681428070145337,
        "distinct-3-nopunct": 0.6224858174316658,
        "vocab_size-3-nopunct": 2414,
        "unique-3-nopunct": 1804,
        "entropy-3-nopunct": 10.835968319004316,
        "cond_entropy-3-nopunct": 0.9469001896035569,
        "msttr-100": 0.52074,
        "msttr-100_nopunct": 0.54702,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23038461538461538,
            "2": 0.595088161209068,
            "3": 0.7985513807152558,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.72523,
            "recall": 0.725,
            "fmeasure": 0.71666
        },
        "rouge2": {
            "precision": 0.47927,
            "recall": 0.47701,
            "fmeasure": 0.47156
        },
        "rougeL": {
            "precision": 0.62731,
            "recall": 0.62436,
            "fmeasure": 0.61772
        },
        "rougeLsum": {
            "precision": 0.62731,
            "recall": 0.62436,
            "fmeasure": 0.61772
        },
        "nist": 7.6457908694425685,
        "bleu": 43.43092,
        "nubia": {
            "semantic_relation": 4.2434,
            "contradiction": 15.31193,
            "irrelevancy": 10.67613,
            "logical_agreement": 74.01194,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.17266,
            "nubia_score": 0.72008
        },
        "bertscore": {
            "precision": 0.91584,
            "recall": 0.91896,
            "f1": 0.91617
        },
        "meteor": 0.3926625258738929,
        "bleurt": 0.14375
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 1099,
        "total_length": 23348,
        "mean_pred_length": 21.24476797088262,
        "std_pred_length": 11.385748375687077,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 70,
        "distinct-1": 0.11328593455542231,
        "vocab_size-1": 2645,
        "unique-1": 820,
        "entropy-1": 8.92038870227279,
        "distinct-2": 0.30010337543260374,
        "vocab_size-2": 6677,
        "unique-2": 3192,
        "entropy-2": 11.768111988624186,
        "cond_entropy-2": 2.5911377102084665,
        "distinct-3": 0.4481323877068558,
        "vocab_size-3": 9478,
        "unique-3": 5604,
        "entropy-3": 12.638688793061874,
        "cond_entropy-3": 0.8928624445239022,
        "total_length-nopunct": 19154,
        "mean_pred_length-nopunct": 17.428571428571427,
        "std_pred_length-nopunct": 9.585359194105393,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.1376735929831889,
        "vocab_size-1-nopunct": 2637,
        "unique-1-nopunct": 820,
        "entropy-1-nopunct": 9.640761147991823,
        "distinct-2-nopunct": 0.3397950706175575,
        "vocab_size-2-nopunct": 6135,
        "unique-2-nopunct": 3187,
        "entropy-2-nopunct": 11.761426123138154,
        "cond_entropy-2-nopunct": 2.1973582034167896,
        "distinct-3-nopunct": 0.4887355508374617,
        "vocab_size-3-nopunct": 8287,
        "unique-3-nopunct": 5242,
        "entropy-3-nopunct": 12.478658487902345,
        "cond_entropy-3-nopunct": 0.7609842457596024,
        "msttr-100": 0.6312,
        "msttr-100_nopunct": 0.69063,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2951910691283813,
            "2": 0.6734665747760166,
            "3": 0.8930782217220034,
            "4": 0.948051948051948,
            "5": 0.9459459459459459,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.44246,
            "recall": 0.45036,
            "fmeasure": 0.44271
        },
        "rouge2": {
            "precision": 0.25611,
            "recall": 0.2624,
            "fmeasure": 0.25533
        },
        "rougeL": {
            "precision": 0.42343,
            "recall": 0.43141,
            "fmeasure": 0.42366
        },
        "rougeLsum": {
            "precision": 0.42343,
            "recall": 0.43141,
            "fmeasure": 0.42366
        },
        "nist": 9.456678676130855,
        "bleu": 51.76758,
        "nubia": {
            "semantic_relation": 4.03039,
            "contradiction": 19.33504,
            "irrelevancy": 21.21904,
            "logical_agreement": 59.44592,
            "grammar_ref": 2.65247,
            "grammar_hyp": 2.60908,
            "nubia_score": 0.83659
        },
        "bertscore": {
            "precision": 0.95788,
            "recall": 0.95576,
            "f1": 0.95616
        },
        "meteor": 0.6642693015261293,
        "bleurt": 0.21599
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 414,
        "total_length": 8759,
        "mean_pred_length": 21.157004830917874,
        "std_pred_length": 7.734232001443361,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 52,
        "distinct-1": 0.13334855577120677,
        "vocab_size-1": 1168,
        "unique-1": 445,
        "entropy-1": 7.737029670187069,
        "distinct-2": 0.3639304973037747,
        "vocab_size-2": 3037,
        "unique-2": 1700,
        "entropy-2": 10.647867684821383,
        "cond_entropy-2": 2.7312171421729365,
        "distinct-3": 0.5544067582902534,
        "vocab_size-3": 4397,
        "unique-3": 3045,
        "entropy-3": 11.617912397404957,
        "cond_entropy-3": 1.0409434305234024,
        "total_length-nopunct": 7701,
        "mean_pred_length-nopunct": 18.60144927536232,
        "std_pred_length-nopunct": 6.857634261030187,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.1504999350733671,
        "vocab_size-1-nopunct": 1159,
        "unique-1-nopunct": 443,
        "entropy-1-nopunct": 8.01027929370786,
        "distinct-2-nopunct": 0.3734046932894195,
        "vocab_size-2-nopunct": 2721,
        "unique-2-nopunct": 1594,
        "entropy-2-nopunct": 10.485707776755813,
        "cond_entropy-2-nopunct": 2.6395821110903253,
        "distinct-3-nopunct": 0.5605994471118871,
        "vocab_size-3-nopunct": 3853,
        "unique-3-nopunct": 2721,
        "entropy-3-nopunct": 11.422079150223167,
        "cond_entropy-3-nopunct": 0.9992047100590183,
        "msttr-100": 0.5054,
        "msttr-100_nopunct": 0.52494,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2296106848536516,
            "2": 0.544952285283777,
            "3": 0.8206369426751592,
            "4": 0.7272727272727273,
            "5": 0.5
        },
        "rouge1": {
            "precision": 0.69588,
            "recall": 0.71909,
            "fmeasure": 0.69808
        },
        "rouge2": {
            "precision": 0.45014,
            "recall": 0.46547,
            "fmeasure": 0.45126
        },
        "rougeL": {
            "precision": 0.5662,
            "recall": 0.58745,
            "fmeasure": 0.569
        },
        "rougeLsum": {
            "precision": 0.5662,
            "recall": 0.58745,
            "fmeasure": 0.569
        },
        "nist": 7.78797874523527,
        "bleu": 41.57095,
        "nubia": {
            "semantic_relation": 4.22541,
            "contradiction": 15.10562,
            "irrelevancy": 12.0783,
            "logical_agreement": 72.81608,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.60644,
            "nubia_score": 0.72227
        },
        "bertscore": {
            "precision": 0.90397,
            "recall": 0.90882,
            "f1": 0.90492
        },
        "meteor": 0.370974354721395,
        "bleurt": 0.06686
    },
    "totto_val": {
        "predictions_file": "mT5_base/totto_val",
        "N": 7700,
        "total_length": 122852,
        "mean_pred_length": 15.954805194805195,
        "std_pred_length": 6.743792453090665,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 96,
        "distinct-1": 0.17528408165923226,
        "vocab_size-1": 21534,
        "unique-1": 14806,
        "entropy-1": 10.103004011891668,
        "distinct-2": 0.5455137557315548,
        "vocab_size-2": 62817,
        "unique-2": 52525,
        "entropy-2": 14.57638960255026,
        "cond_entropy-2": 4.0639704390984654,
        "distinct-3": 0.7735733164575811,
        "vocab_size-3": 83122,
        "unique-3": 75643,
        "entropy-3": 15.836602330836328,
        "cond_entropy-3": 1.2240138711277129,
        "total_length-nopunct": 106671,
        "mean_pred_length-nopunct": 13.853376623376624,
        "std_pred_length-nopunct": 5.713636709012082,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.2016761819051101,
        "vocab_size-1-nopunct": 21513,
        "unique-1-nopunct": 14803,
        "entropy-1-nopunct": 10.681465029845386,
        "distinct-2-nopunct": 0.5917187863111416,
        "vocab_size-2-nopunct": 58563,
        "unique-2-nopunct": 50050,
        "entropy-2-nopunct": 14.581765703783375,
        "cond_entropy-2-nopunct": 4.065185459472198,
        "distinct-3-nopunct": 0.8002651444599052,
        "vocab_size-3-nopunct": 73041,
        "unique-3-nopunct": 67327,
        "entropy-3-nopunct": 15.704412118642841,
        "cond_entropy-3-nopunct": 1.1966796074729011,
        "msttr-100": 0.72296,
        "msttr-100_nopunct": 0.77686,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_val.json",
        "local_recall": {
            "1": 0.21183378500451672,
            "2": 0.4343325425921932,
            "3": 0.7561742704274061
        },
        "rouge1": {
            "precision": 0.7567,
            "recall": 0.71552,
            "fmeasure": 0.72357
        },
        "rouge2": {
            "precision": 0.52779,
            "recall": 0.50064,
            "fmeasure": 0.50543
        },
        "rougeL": {
            "precision": 0.65768,
            "recall": 0.62372,
            "fmeasure": 0.62966
        },
        "rougeLsum": {
            "precision": 0.65768,
            "recall": 0.62372,
            "fmeasure": 0.62966
        },
        "nist": 10.536265497245804,
        "bleu": 45.2201,
        "nubia": {
            "semantic_relation": 4.13382,
            "contradiction": 9.85994,
            "irrelevancy": 29.31388,
            "logical_agreement": 60.82618,
            "grammar_ref": 4.66172,
            "grammar_hyp": 4.67896,
            "nubia_score": 0.70938
        },
        "bertscore": {
            "precision": 0.92697,
            "recall": 0.91983,
            "f1": 0.92178
        },
        "meteor": 0.38576048202090046,
        "bleurt": 0.25772
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 382,
        "total_length": 10599,
        "mean_pred_length": 27.74607329842932,
        "std_pred_length": 8.05257090583996,
        "median_pred_length": 27.0,
        "min_pred_length": 10,
        "max_pred_length": 61,
        "distinct-1": 0.10585904330597226,
        "vocab_size-1": 1122,
        "unique-1": 332,
        "entropy-1": 7.738369990958738,
        "distinct-2": 0.30008808847998436,
        "vocab_size-2": 3066,
        "unique-2": 1515,
        "entropy-2": 10.615728987600724,
        "cond_entropy-2": 2.7386917581670867,
        "distinct-3": 0.4741230299949161,
        "vocab_size-3": 4663,
        "unique-3": 2935,
        "entropy-3": 11.61201799714732,
        "cond_entropy-3": 1.0448837325067033,
        "total_length-nopunct": 9385,
        "mean_pred_length-nopunct": 24.56806282722513,
        "std_pred_length-nopunct": 7.294789499292264,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.11859350026638253,
        "vocab_size-1-nopunct": 1113,
        "unique-1-nopunct": 332,
        "entropy-1-nopunct": 8.001040250417136,
        "distinct-2-nopunct": 0.3180051094079751,
        "vocab_size-2-nopunct": 2863,
        "unique-2-nopunct": 1493,
        "entropy-2-nopunct": 10.538133295202918,
        "cond_entropy-2-nopunct": 2.656569168520872,
        "distinct-3-nopunct": 0.49321424428720567,
        "vocab_size-3-nopunct": 4252,
        "unique-3-nopunct": 2771,
        "entropy-3-nopunct": 11.487103071049587,
        "cond_entropy-3-nopunct": 0.9890996653558404,
        "msttr-100": 0.48524,
        "msttr-100_nopunct": 0.50194,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22680925142999253,
            "2": 0.5607638888888888,
            "3": 0.8293419633225458,
            "4": 0.3333333333333333,
            "5": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.69033,
            "recall": 0.72072,
            "fmeasure": 0.69715
        },
        "rouge2": {
            "precision": 0.43662,
            "recall": 0.4551,
            "fmeasure": 0.44042
        },
        "rougeL": {
            "precision": 0.54061,
            "recall": 0.56583,
            "fmeasure": 0.54633
        },
        "rougeLsum": {
            "precision": 0.54061,
            "recall": 0.56583,
            "fmeasure": 0.54633
        },
        "nist": 7.8199476238859935,
        "bleu": 42.48773,
        "nubia": {
            "semantic_relation": 4.15703,
            "contradiction": 15.72055,
            "irrelevancy": 13.30649,
            "logical_agreement": 70.97296,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.31044,
            "nubia_score": 0.71147
        },
        "bertscore": {
            "precision": 0.89993,
            "recall": 0.90342,
            "f1": 0.90026
        },
        "meteor": 0.3694412732026102,
        "bleurt": 0.03951
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 3,
        "total_length": 66,
        "mean_pred_length": 22.0,
        "std_pred_length": 10.23067283548187,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 35,
        "distinct-1": 0.6060606060606061,
        "vocab_size-1": 40,
        "unique-1": 31,
        "entropy-1": 4.887747203788195,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 56,
        "unique-2": 50,
        "entropy-2": 5.743075359973515,
        "cond_entropy-2": 0.8151684854981915,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 56,
        "unique-3": 52,
        "entropy-3": 5.773557262275183,
        "cond_entropy-3": 0.0088587971446598,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 6.548960901462833,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7872340425531915,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.054380872862172,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.260456902679035,
        "cond_entropy-2-nopunct": 0.14927202837246573,
        "distinct-3-nopunct": 0.9512195121951219,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.259991029008325,
        "cond_entropy-3-nopunct": -0.024564370081596287,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.10810810810810811,
            "2": 0.8333333333333334,
            "3": 0.9285714285714286
        },
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "nist": 5.8859372972242605,
        "bleu": 71.25103,
        "nubia": {
            "semantic_relation": 4.09186,
            "contradiction": 16.13008,
            "irrelevancy": 23.3372,
            "logical_agreement": 60.53272,
            "grammar_ref": 2.52713,
            "grammar_hyp": 2.50343,
            "nubia_score": 0.85502
        },
        "bertscore": {
            "precision": 0.9698,
            "recall": 0.96815,
            "f1": 0.96829
        },
        "meteor": 0.7595847878975788,
        "bleurt": 0.2831
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 986,
        "total_length": 20628,
        "mean_pred_length": 20.920892494929006,
        "std_pred_length": 11.737486522796267,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 70,
        "distinct-1": 0.12090362613922824,
        "vocab_size-1": 2494,
        "unique-1": 831,
        "entropy-1": 8.883458316749355,
        "distinct-2": 0.31330821708583645,
        "vocab_size-2": 6154,
        "unique-2": 3071,
        "entropy-2": 11.67387602373385,
        "cond_entropy-2": 2.531519865952224,
        "distinct-3": 0.4614065180102916,
        "vocab_size-3": 8608,
        "unique-3": 5245,
        "entropy-3": 12.501122028272876,
        "cond_entropy-3": 0.8510698392972154,
        "total_length-nopunct": 16892,
        "mean_pred_length-nopunct": 17.13184584178499,
        "std_pred_length-nopunct": 9.828801286359509,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.1471702581103481,
        "vocab_size-1-nopunct": 2486,
        "unique-1-nopunct": 831,
        "entropy-1-nopunct": 9.603319151311142,
        "distinct-2-nopunct": 0.352822834150635,
        "vocab_size-2-nopunct": 5612,
        "unique-2-nopunct": 3009,
        "entropy-2-nopunct": 11.65209486374208,
        "cond_entropy-2-nopunct": 2.1268105311858316,
        "distinct-3-nopunct": 0.5000670241286863,
        "vocab_size-3-nopunct": 7461,
        "unique-3-nopunct": 4817,
        "entropy-3-nopunct": 12.327994069196526,
        "cond_entropy-3-nopunct": 0.7206454808969897,
        "msttr-100": 0.63126,
        "msttr-100_nopunct": 0.6925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.298324478953821,
            "2": 0.6754946253310484,
            "3": 0.8934149430139299,
            "4": 0.948051948051948,
            "5": 0.9459459459459459,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.47506,
            "recall": 0.48271,
            "fmeasure": 0.47491
        },
        "rouge2": {
            "precision": 0.27688,
            "recall": 0.28308,
            "fmeasure": 0.2757
        },
        "rougeL": {
            "precision": 0.45449,
            "recall": 0.46224,
            "fmeasure": 0.45433
        },
        "rougeLsum": {
            "precision": 0.45449,
            "recall": 0.46224,
            "fmeasure": 0.45433
        },
        "nist": 9.43209288815645,
        "bleu": 52.6232,
        "nubia": {
            "semantic_relation": 4.03341,
            "contradiction": 19.42125,
            "irrelevancy": 21.35318,
            "logical_agreement": 59.22557,
            "grammar_ref": 2.66553,
            "grammar_hyp": 2.62541,
            "nubia_score": 0.837
        },
        "bertscore": {
            "precision": 0.95839,
            "recall": 0.95665,
            "f1": 0.95686
        },
        "meteor": 0.6716334039517484,
        "bleurt": 0.22347
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.2727272727272727
        },
        "rouge1": {
            "precision": 0.59821,
            "recall": 0.39649,
            "fmeasure": 0.46753
        },
        "rouge2": {
            "precision": 0.18205,
            "recall": 0.10728,
            "fmeasure": 0.13203
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.32719,
            "fmeasure": 0.38766
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.32719,
            "fmeasure": 0.38766
        },
        "nist": 0.3345832138725121,
        "bleu": 2.43058,
        "nubia": {
            "semantic_relation": 3.28937,
            "contradiction": 48.45787,
            "irrelevancy": 48.39957,
            "logical_agreement": 3.14256,
            "grammar_ref": 3.96887,
            "grammar_hyp": 4.71027,
            "nubia_score": 0.32201
        },
        "bertscore": {
            "precision": 0.85164,
            "recall": 0.79434,
            "f1": 0.82095
        },
        "meteor": 0.19606836013390744,
        "bleurt": -0.27161
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 16,
        "total_length": 248,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.9039432764659772,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.22580645161290322,
        "vocab_size-1": 56,
        "unique-1": 33,
        "entropy-1": 4.796448334256855,
        "distinct-2": 0.33620689655172414,
        "vocab_size-2": 78,
        "unique-2": 50,
        "entropy-2": 5.457326745072308,
        "cond_entropy-2": 0.6027920643416724,
        "distinct-3": 0.42592592592592593,
        "vocab_size-3": 92,
        "unique-3": 66,
        "entropy-3": 5.828274005611433,
        "cond_entropy-3": 0.37259874292742545,
        "total_length-nopunct": 214,
        "mean_pred_length-nopunct": 13.375,
        "std_pred_length-nopunct": 1.8328597873268975,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.24766355140186916,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.705791146312401,
        "distinct-2-nopunct": 0.35353535353535354,
        "vocab_size-2-nopunct": 70,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.359603236713171,
        "cond_entropy-2-nopunct": 0.6927500233015352,
        "distinct-3-nopunct": 0.46153846153846156,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.74711726110076,
        "cond_entropy-3-nopunct": 0.36254122991941756,
        "msttr-100": 0.345,
        "msttr-100_nopunct": 0.355,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4089068825910931
        },
        "rouge1": {
            "precision": 0.55932,
            "recall": 0.47257,
            "fmeasure": 0.50107
        },
        "rouge2": {
            "precision": 0.33742,
            "recall": 0.28821,
            "fmeasure": 0.30225
        },
        "rougeL": {
            "precision": 0.48169,
            "recall": 0.41579,
            "fmeasure": 0.43601
        },
        "rougeLsum": {
            "precision": 0.48169,
            "recall": 0.41579,
            "fmeasure": 0.43601
        },
        "nist": 2.9318608212628297,
        "bleu": 18.5869,
        "nubia": {
            "semantic_relation": 3.35281,
            "contradiction": 29.65975,
            "irrelevancy": 22.58727,
            "logical_agreement": 47.75298,
            "grammar_ref": 5.92126,
            "grammar_hyp": 6.12292,
            "nubia_score": 0.49514
        },
        "bertscore": {
            "precision": 0.91648,
            "recall": 0.89999,
            "f1": 0.90796
        },
        "meteor": 0.2159096383462418,
        "bleurt": -0.033
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "rouge1": {
            "precision": 0.28571,
            "recall": 0.26667,
            "fmeasure": 0.27586
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.07143,
            "fmeasure": 0.07407
        },
        "rougeL": {
            "precision": 0.21429,
            "recall": 0.2,
            "fmeasure": 0.2069
        },
        "rougeLsum": {
            "precision": 0.21429,
            "recall": 0.2,
            "fmeasure": 0.2069
        },
        "nist": 1.0600905711694244,
        "bleu": 5.85516,
        "nubia": {
            "semantic_relation": 2.48306,
            "contradiction": 0.21333,
            "irrelevancy": 95.8174,
            "logical_agreement": 3.96927,
            "grammar_ref": 5.48676,
            "grammar_hyp": 5.85039,
            "nubia_score": 0.21353
        },
        "bertscore": {
            "precision": 0.77277,
            "recall": 0.78441,
            "f1": 0.77855
        },
        "meteor": 0.11564440949896566,
        "bleurt": -0.17104
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 335,
        "total_length": 8367,
        "mean_pred_length": 24.976119402985073,
        "std_pred_length": 4.5449033141527515,
        "median_pred_length": 24.0,
        "min_pred_length": 16,
        "max_pred_length": 43,
        "distinct-1": 0.1033823353651249,
        "vocab_size-1": 865,
        "unique-1": 426,
        "entropy-1": 7.3765228729424965,
        "distinct-2": 0.2711653386454183,
        "vocab_size-2": 2178,
        "unique-2": 1277,
        "entropy-2": 9.7025884227516,
        "cond_entropy-2": 2.2345033242251264,
        "distinct-3": 0.42938807327530204,
        "vocab_size-3": 3305,
        "unique-3": 2249,
        "entropy-3": 10.780306986731073,
        "cond_entropy-3": 1.0493266273192132,
        "total_length-nopunct": 7662,
        "mean_pred_length-nopunct": 22.871641791044777,
        "std_pred_length-nopunct": 3.9585466189465186,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.11132863482119551,
        "vocab_size-1-nopunct": 853,
        "unique-1-nopunct": 424,
        "entropy-1-nopunct": 7.418833385021374,
        "distinct-2-nopunct": 0.2818343114507984,
        "vocab_size-2-nopunct": 2065,
        "unique-2-nopunct": 1219,
        "entropy-2-nopunct": 9.658646753851968,
        "cond_entropy-2-nopunct": 2.246021863182848,
        "distinct-3-nopunct": 0.44579519450800914,
        "vocab_size-3-nopunct": 3117,
        "unique-3-nopunct": 2168,
        "entropy-3-nopunct": 10.68706065210324,
        "cond_entropy-3-nopunct": 1.054836422852348,
        "msttr-100": 0.63928,
        "msttr-100_nopunct": 0.64237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6696815286624204
        },
        "rouge1": {
            "precision": 0.76098,
            "recall": 0.68751,
            "fmeasure": 0.71435
        },
        "rouge2": {
            "precision": 0.53621,
            "recall": 0.48568,
            "fmeasure": 0.50391
        },
        "rougeL": {
            "precision": 0.6534,
            "recall": 0.59033,
            "fmeasure": 0.61334
        },
        "rougeLsum": {
            "precision": 0.6534,
            "recall": 0.59033,
            "fmeasure": 0.61334
        },
        "nist": 6.966412121459259,
        "bleu": 39.74885,
        "nubia": {
            "semantic_relation": 4.49712,
            "contradiction": 0.71318,
            "irrelevancy": 7.16696,
            "logical_agreement": 92.11986,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.40765,
            "nubia_score": 0.81918
        },
        "bertscore": {
            "precision": 0.91376,
            "recall": 0.89601,
            "f1": 0.90451
        },
        "meteor": 0.3779001358449607,
        "bleurt": 0.06638
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 125,
        "total_length": 4053,
        "mean_pred_length": 32.424,
        "std_pred_length": 14.40347957960159,
        "median_pred_length": 30.0,
        "min_pred_length": 9,
        "max_pred_length": 96,
        "distinct-1": 0.11917098445595854,
        "vocab_size-1": 483,
        "unique-1": 137,
        "entropy-1": 6.902363124611603,
        "distinct-2": 0.31924643584521384,
        "vocab_size-2": 1254,
        "unique-2": 586,
        "entropy-2": 9.476203948187568,
        "cond_entropy-2": 2.491155680050627,
        "distinct-3": 0.49986852484880356,
        "vocab_size-3": 1901,
        "unique-3": 1166,
        "entropy-3": 10.410804276077398,
        "cond_entropy-3": 0.9680881751711533,
        "total_length-nopunct": 3581,
        "mean_pred_length-nopunct": 28.648,
        "std_pred_length-nopunct": 12.705435687138005,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.1329237643116448,
        "vocab_size-1-nopunct": 476,
        "unique-1-nopunct": 137,
        "entropy-1-nopunct": 7.038715747638892,
        "distinct-2-nopunct": 0.33564814814814814,
        "vocab_size-2-nopunct": 1160,
        "unique-2-nopunct": 564,
        "entropy-2-nopunct": 9.386993020355291,
        "cond_entropy-2-nopunct": 2.439406527248878,
        "distinct-3-nopunct": 0.516061242870009,
        "vocab_size-3-nopunct": 1719,
        "unique-3-nopunct": 1082,
        "entropy-3-nopunct": 10.268995813710891,
        "cond_entropy-3-nopunct": 0.9054901034074283,
        "msttr-100": 0.4745,
        "msttr-100_nopunct": 0.49743,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1905071521456437,
            "2": 0.4332084893882647,
            "3": 0.7113095238095238
        },
        "rouge1": {
            "precision": 0.59666,
            "recall": 0.62063,
            "fmeasure": 0.59564
        },
        "rouge2": {
            "precision": 0.3288,
            "recall": 0.34332,
            "fmeasure": 0.32757
        },
        "rougeL": {
            "precision": 0.4436,
            "recall": 0.46816,
            "fmeasure": 0.44505
        },
        "rougeLsum": {
            "precision": 0.4436,
            "recall": 0.46816,
            "fmeasure": 0.44505
        },
        "nist": 5.528346951803033,
        "bleu": 27.02822,
        "nubia": {
            "semantic_relation": 3.586,
            "contradiction": 24.55458,
            "irrelevancy": 16.26635,
            "logical_agreement": 59.17907,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.39562,
            "nubia_score": 0.54208
        },
        "bertscore": {
            "precision": 0.86421,
            "recall": 0.86602,
            "f1": 0.86332
        },
        "meteor": 0.29088360831920296,
        "bleurt": -0.2726
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_base/e2e_nlg_test",
        "N": 389,
        "total_length": 6012,
        "mean_pred_length": 15.455012853470437,
        "std_pred_length": 3.90058420413031,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.01746506986027944,
        "vocab_size-1": 105,
        "unique-1": 5,
        "entropy-1": 5.520772106694047,
        "distinct-2": 0.03681308909834608,
        "vocab_size-2": 207,
        "unique-2": 28,
        "entropy-2": 6.622466443594142,
        "cond_entropy-2": 0.9507804666952228,
        "distinct-3": 0.0588460068781047,
        "vocab_size-3": 308,
        "unique-3": 64,
        "entropy-3": 7.2282187489205,
        "cond_entropy-3": 0.631975802401237,
        "total_length-nopunct": 5416,
        "mean_pred_length-nopunct": 13.922879177377892,
        "std_pred_length-nopunct": 3.5074970661721907,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.019017725258493354,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 5.607178963784578,
        "distinct-2-nopunct": 0.03839267953053511,
        "vocab_size-2-nopunct": 193,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 6.538444206519337,
        "cond_entropy-2-nopunct": 0.9931361054098684,
        "distinct-3-nopunct": 0.06382061233290211,
        "vocab_size-3-nopunct": 296,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 7.210572414930741,
        "cond_entropy-3-nopunct": 0.6662891318126473,
        "msttr-100": 0.2405,
        "msttr-100_nopunct": 0.23889,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6615709871523825
        },
        "rouge1": {
            "precision": 0.80447,
            "recall": 0.67671,
            "fmeasure": 0.72008
        },
        "rouge2": {
            "precision": 0.52924,
            "recall": 0.44233,
            "fmeasure": 0.47145
        },
        "rougeL": {
            "precision": 0.6416,
            "recall": 0.53451,
            "fmeasure": 0.57127
        },
        "rougeLsum": {
            "precision": 0.6416,
            "recall": 0.53451,
            "fmeasure": 0.57127
        },
        "nist": 4.9240361005691,
        "bleu": 32.75016,
        "nubia": {
            "semantic_relation": 4.35437,
            "contradiction": 0.90843,
            "irrelevancy": 8.10463,
            "logical_agreement": 90.98695,
            "grammar_ref": 5.31197,
            "grammar_hyp": 4.97374,
            "nubia_score": 0.80088
        },
        "bertscore": {
            "precision": 0.93433,
            "recall": 0.90556,
            "f1": 0.91933
        },
        "meteor": 0.3529097810530993,
        "bleurt": 0.22444
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 251,
        "total_length": 8725,
        "mean_pred_length": 34.7609561752988,
        "std_pred_length": 9.116697471722318,
        "median_pred_length": 34.0,
        "min_pred_length": 17,
        "max_pred_length": 65,
        "distinct-1": 0.10830945558739255,
        "vocab_size-1": 945,
        "unique-1": 272,
        "entropy-1": 7.682880383922027,
        "distinct-2": 0.29242388482416803,
        "vocab_size-2": 2478,
        "unique-2": 1164,
        "entropy-2": 10.367348207191283,
        "cond_entropy-2": 2.5760372673657996,
        "distinct-3": 0.4460659126839353,
        "vocab_size-3": 3668,
        "unique-3": 2213,
        "entropy-3": 11.245723751595495,
        "cond_entropy-3": 0.9145163781033664,
        "total_length-nopunct": 7731,
        "mean_pred_length-nopunct": 30.800796812749002,
        "std_pred_length-nopunct": 8.344676438490435,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.12120036217824344,
        "vocab_size-1-nopunct": 937,
        "unique-1-nopunct": 269,
        "entropy-1-nopunct": 7.935378751634841,
        "distinct-2-nopunct": 0.31163101604278076,
        "vocab_size-2-nopunct": 2331,
        "unique-2-nopunct": 1167,
        "entropy-2-nopunct": 10.306321875258778,
        "cond_entropy-2-nopunct": 2.45987540559457,
        "distinct-3-nopunct": 0.4675612117858625,
        "vocab_size-3-nopunct": 3380,
        "unique-3-nopunct": 2133,
        "entropy-3-nopunct": 11.135824489229003,
        "cond_entropy-3-nopunct": 0.8598482449491657,
        "msttr-100": 0.48103,
        "msttr-100_nopunct": 0.49039,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23580927667855983,
            "2": 0.6127962085308057,
            "3": 0.8367231638418079
        },
        "rouge1": {
            "precision": 0.70102,
            "recall": 0.70504,
            "fmeasure": 0.69405
        },
        "rouge2": {
            "precision": 0.43538,
            "recall": 0.43581,
            "fmeasure": 0.42996
        },
        "rougeL": {
            "precision": 0.51508,
            "recall": 0.52317,
            "fmeasure": 0.5121
        },
        "rougeLsum": {
            "precision": 0.51508,
            "recall": 0.52317,
            "fmeasure": 0.5121
        },
        "nist": 7.894721338393926,
        "bleu": 44.92469,
        "nubia": {
            "semantic_relation": 4.05054,
            "contradiction": 16.94023,
            "irrelevancy": 11.58341,
            "logical_agreement": 71.47636,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.21976,
            "nubia_score": 0.67538
        },
        "bertscore": {
            "precision": 0.89828,
            "recall": 0.89849,
            "f1": 0.89692
        },
        "meteor": 0.36303761713594024,
        "bleurt": -0.008
    },
    "schema_guided_dialog_challenge_test_scramble": {
        "predictions_file": "mT5_base/schema_guided_dialog_challenge_test_scramble",
        "N": 500,
        "total_length": 6882,
        "mean_pred_length": 13.764,
        "std_pred_length": 7.8920405472856,
        "median_pred_length": 12.0,
        "min_pred_length": 0,
        "max_pred_length": 54,
        "distinct-1": 0.15707643126997967,
        "vocab_size-1": 1081,
        "unique-1": 606,
        "entropy-1": 7.881571680856226,
        "distinct-2": 0.5099483001723327,
        "vocab_size-2": 3255,
        "unique-2": 2333,
        "entropy-2": 10.95684694718004,
        "cond_entropy-2": 2.8509071561281107,
        "distinct-3": 0.7501699524133243,
        "vocab_size-3": 4414,
        "unique-3": 3723,
        "entropy-3": 11.820306135286753,
        "cond_entropy-3": 0.8720160929071812,
        "total_length-nopunct": 6052,
        "mean_pred_length-nopunct": 12.104,
        "std_pred_length-nopunct": 7.223654476786662,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.17647058823529413,
        "vocab_size-1-nopunct": 1068,
        "unique-1-nopunct": 602,
        "entropy-1-nopunct": 8.075668231240499,
        "distinct-2-nopunct": 0.5287232126778318,
        "vocab_size-2-nopunct": 2936,
        "unique-2-nopunct": 2161,
        "entropy-2-nopunct": 10.80522312028244,
        "cond_entropy-2-nopunct": 2.84654242860583,
        "distinct-3-nopunct": 0.7613771270280966,
        "vocab_size-3-nopunct": 3848,
        "unique-3-nopunct": 3300,
        "entropy-3-nopunct": 11.617514196946505,
        "cond_entropy-3-nopunct": 0.8403669667067571,
        "msttr-100": 0.68721,
        "msttr-100_nopunct": 0.71733,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.504388229220444
        },
        "rouge1": {
            "precision": 0.49276,
            "recall": 0.48132,
            "fmeasure": 0.47452
        },
        "rouge2": {
            "precision": 0.26002,
            "recall": 0.25461,
            "fmeasure": 0.25017
        },
        "rougeL": {
            "precision": 0.42326,
            "recall": 0.41282,
            "fmeasure": 0.40711
        },
        "rougeLsum": {
            "precision": 0.42326,
            "recall": 0.41282,
            "fmeasure": 0.40711
        },
        "nist": 5.174748375204948,
        "bleu": 23.6022,
        "nubia": {
            "semantic_relation": 3.27034,
            "contradiction": 10.28065,
            "irrelevancy": 27.95309,
            "logical_agreement": 61.56626,
            "grammar_ref": 4.76906,
            "grammar_hyp": 4.64151,
            "nubia_score": 0.54854
        },
        "bertscore": {
            "precision": 0.84342,
            "recall": 0.84106,
            "f1": 0.84122
        },
        "meteor": 0.2732776615731898,
        "bleurt": -0.29091
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 158,
        "total_length": 6063,
        "mean_pred_length": 38.37341772151899,
        "std_pred_length": 10.78998843115673,
        "median_pred_length": 37.0,
        "min_pred_length": 17,
        "max_pred_length": 85,
        "distinct-1": 0.13409203364670955,
        "vocab_size-1": 813,
        "unique-1": 242,
        "entropy-1": 7.5841698797848816,
        "distinct-2": 0.3353090601185436,
        "vocab_size-2": 1980,
        "unique-2": 1004,
        "entropy-2": 10.129953505949377,
        "cond_entropy-2": 2.4539865103753535,
        "distinct-3": 0.4879067339481469,
        "vocab_size-3": 2804,
        "unique-3": 1788,
        "entropy-3": 10.920191466263246,
        "cond_entropy-3": 0.8232953805132123,
        "total_length-nopunct": 5438,
        "mean_pred_length-nopunct": 34.41772151898734,
        "std_pred_length-nopunct": 9.743037234628618,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.1478484737035675,
        "vocab_size-1-nopunct": 804,
        "unique-1-nopunct": 240,
        "entropy-1-nopunct": 7.772721166245589,
        "distinct-2-nopunct": 0.3503787878787879,
        "vocab_size-2-nopunct": 1850,
        "unique-2-nopunct": 982,
        "entropy-2-nopunct": 10.062349028394024,
        "cond_entropy-2-nopunct": 2.3698592272029004,
        "distinct-3-nopunct": 0.5029285435376806,
        "vocab_size-3-nopunct": 2576,
        "unique-3-nopunct": 1696,
        "entropy-3-nopunct": 10.804401882742718,
        "cond_entropy-3-nopunct": 0.7696639352800432,
        "msttr-100": 0.519,
        "msttr-100_nopunct": 0.52074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22866127583108714,
            "2": 0.4854202401372213,
            "3": 0.8017761989342806
        },
        "rouge1": {
            "precision": 0.68574,
            "recall": 0.6601,
            "fmeasure": 0.66595
        },
        "rouge2": {
            "precision": 0.4092,
            "recall": 0.3922,
            "fmeasure": 0.39615
        },
        "rougeL": {
            "precision": 0.49069,
            "recall": 0.47308,
            "fmeasure": 0.47605
        },
        "rougeLsum": {
            "precision": 0.49069,
            "recall": 0.47308,
            "fmeasure": 0.47605
        },
        "nist": 7.527199641220138,
        "bleu": 41.40418,
        "nubia": {
            "semantic_relation": 3.82413,
            "contradiction": 19.40646,
            "irrelevancy": 11.69623,
            "logical_agreement": 68.89731,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.18975,
            "nubia_score": 0.64398
        },
        "bertscore": {
            "precision": 0.88993,
            "recall": 0.88437,
            "f1": 0.88588
        },
        "meteor": 0.3320687611126419,
        "bleurt": -0.12691
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 1510,
        "total_length": 36020,
        "mean_pred_length": 23.85430463576159,
        "std_pred_length": 12.713030990554522,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 94,
        "distinct-1": 0.04747362576346474,
        "vocab_size-1": 1710,
        "unique-1": 487,
        "entropy-1": 7.8830411026598535,
        "distinct-2": 0.16302521008403362,
        "vocab_size-2": 5626,
        "unique-2": 2402,
        "entropy-2": 10.99923669390662,
        "cond_entropy-2": 2.9444466897519463,
        "distinct-3": 0.2920606060606061,
        "vocab_size-3": 9638,
        "unique-3": 5315,
        "entropy-3": 12.172615110181017,
        "cond_entropy-3": 1.245384404269698,
        "total_length-nopunct": 31920,
        "mean_pred_length-nopunct": 21.13907284768212,
        "std_pred_length-nopunct": 11.435473873720648,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 83,
        "distinct-1-nopunct": 0.053289473684210525,
        "vocab_size-1-nopunct": 1701,
        "unique-1-nopunct": 487,
        "entropy-1-nopunct": 8.156499947373845,
        "distinct-2-nopunct": 0.17231173955935547,
        "vocab_size-2-nopunct": 5240,
        "unique-2-nopunct": 2347,
        "entropy-2-nopunct": 10.89336427999861,
        "cond_entropy-2-nopunct": 2.8876605308623606,
        "distinct-3-nopunct": 0.3047750865051903,
        "vocab_size-3-nopunct": 8808,
        "unique-3-nopunct": 5005,
        "entropy-3-nopunct": 12.037733121139294,
        "cond_entropy-3-nopunct": 1.210399745786051,
        "msttr-100": 0.49386,
        "msttr-100_nopunct": 0.50473,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23626530031312268,
            "2": 0.583864118895966,
            "3": 0.8356974747153489,
            "4": 0.9215686274509803,
            "5": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.71998,
            "recall": 0.7255,
            "fmeasure": 0.71464
        },
        "rouge2": {
            "precision": 0.46884,
            "recall": 0.47039,
            "fmeasure": 0.46385
        },
        "rougeL": {
            "precision": 0.58106,
            "recall": 0.58726,
            "fmeasure": 0.57717
        },
        "rougeLsum": {
            "precision": 0.58106,
            "recall": 0.58726,
            "fmeasure": 0.57717
        },
        "nist": 8.509841386724835,
        "bleu": 46.08827,
        "nubia": {
            "semantic_relation": 4.22744,
            "contradiction": 14.69504,
            "irrelevancy": 9.73455,
            "logical_agreement": 75.57041,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.5815,
            "nubia_score": 0.73128
        },
        "bertscore": {
            "precision": 0.91085,
            "recall": 0.91191,
            "f1": 0.91008
        },
        "meteor": 0.3748052449779152,
        "bleurt": 0.10549
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 80,
        "total_length": 3411,
        "mean_pred_length": 42.6375,
        "std_pred_length": 11.352580929022263,
        "median_pred_length": 42.0,
        "min_pred_length": 19,
        "max_pred_length": 93,
        "distinct-1": 0.1902667839343301,
        "vocab_size-1": 649,
        "unique-1": 290,
        "entropy-1": 7.316231802855823,
        "distinct-2": 0.43800660462323626,
        "vocab_size-2": 1459,
        "unique-2": 865,
        "entropy-2": 9.831737663703649,
        "cond_entropy-2": 2.437798739372649,
        "distinct-3": 0.6185788988003691,
        "vocab_size-3": 2011,
        "unique-3": 1421,
        "entropy-3": 10.631874885882901,
        "cond_entropy-3": 0.8238440302336895,
        "total_length-nopunct": 3037,
        "mean_pred_length-nopunct": 37.9625,
        "std_pred_length-nopunct": 9.901317778457573,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 73,
        "distinct-1-nopunct": 0.21139282186368127,
        "vocab_size-1-nopunct": 642,
        "unique-1-nopunct": 288,
        "entropy-1-nopunct": 7.498664670729088,
        "distinct-2-nopunct": 0.4589110585052418,
        "vocab_size-2-nopunct": 1357,
        "unique-2-nopunct": 826,
        "entropy-2-nopunct": 9.790014890859728,
        "cond_entropy-2-nopunct": 2.356532280898094,
        "distinct-3-nopunct": 0.6371220020855057,
        "vocab_size-3-nopunct": 1833,
        "unique-3-nopunct": 1321,
        "entropy-3-nopunct": 10.51850841240103,
        "cond_entropy-3-nopunct": 0.7436092728558492,
        "msttr-100": 0.51029,
        "msttr-100_nopunct": 0.53333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.20409711684370258,
            "2": 0.514745308310992,
            "3": 0.7226720647773279
        },
        "rouge1": {
            "precision": 0.65472,
            "recall": 0.61786,
            "fmeasure": 0.62824
        },
        "rouge2": {
            "precision": 0.35616,
            "recall": 0.32921,
            "fmeasure": 0.33796
        },
        "rougeL": {
            "precision": 0.46268,
            "recall": 0.44171,
            "fmeasure": 0.44667
        },
        "rougeLsum": {
            "precision": 0.46268,
            "recall": 0.44171,
            "fmeasure": 0.44667
        },
        "nist": 6.860137943266808,
        "bleu": 35.03109,
        "nubia": {
            "semantic_relation": 3.52705,
            "contradiction": 23.27026,
            "irrelevancy": 15.26412,
            "logical_agreement": 61.46562,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.12473,
            "nubia_score": 0.5716
        },
        "bertscore": {
            "precision": 0.87751,
            "recall": 0.86678,
            "f1": 0.87086
        },
        "meteor": 0.2950608478499521,
        "bleurt": -0.21187
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 41,
        "total_length": 1798,
        "mean_pred_length": 43.853658536585364,
        "std_pred_length": 13.9223648390879,
        "median_pred_length": 43.0,
        "min_pred_length": 21,
        "max_pred_length": 96,
        "distinct-1": 0.2374860956618465,
        "vocab_size-1": 427,
        "unique-1": 207,
        "entropy-1": 7.033757781499452,
        "distinct-2": 0.4906089926010245,
        "vocab_size-2": 862,
        "unique-2": 533,
        "entropy-2": 9.209140006142672,
        "cond_entropy-2": 2.110274821601347,
        "distinct-3": 0.6363636363636364,
        "vocab_size-3": 1092,
        "unique-3": 776,
        "entropy-3": 9.799928709865677,
        "cond_entropy-3": 0.6082985141615599,
        "total_length-nopunct": 1608,
        "mean_pred_length-nopunct": 39.21951219512195,
        "std_pred_length-nopunct": 12.53971679596561,
        "median_pred_length-nopunct": 38.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.26181592039800994,
        "vocab_size-1-nopunct": 421,
        "unique-1-nopunct": 205,
        "entropy-1-nopunct": 7.173794294469708,
        "distinct-2-nopunct": 0.5098915124441609,
        "vocab_size-2-nopunct": 799,
        "unique-2-nopunct": 503,
        "entropy-2-nopunct": 9.151525827033383,
        "cond_entropy-2-nopunct": 2.0379664030816373,
        "distinct-3-nopunct": 0.6553079947575361,
        "vocab_size-3-nopunct": 1000,
        "unique-3-nopunct": 729,
        "entropy-3-nopunct": 9.687272039279998,
        "cond_entropy-3-nopunct": 0.5495048560166331,
        "msttr-100": 0.51412,
        "msttr-100_nopunct": 0.53187,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18580060422960726,
            "2": 0.39285714285714285,
            "3": 0.6935123042505593
        },
        "rouge1": {
            "precision": 0.65355,
            "recall": 0.57848,
            "fmeasure": 0.60235
        },
        "rouge2": {
            "precision": 0.36467,
            "recall": 0.31962,
            "fmeasure": 0.33442
        },
        "rougeL": {
            "precision": 0.46538,
            "recall": 0.4089,
            "fmeasure": 0.42683
        },
        "rougeLsum": {
            "precision": 0.46538,
            "recall": 0.4089,
            "fmeasure": 0.42683
        },
        "nist": 6.349772935843114,
        "bleu": 35.70515,
        "nubia": {
            "semantic_relation": 3.48756,
            "contradiction": 19.4111,
            "irrelevancy": 12.96925,
            "logical_agreement": 67.61965,
            "grammar_ref": 3.92594,
            "grammar_hyp": 3.95449,
            "nubia_score": 0.55381
        },
        "bertscore": {
            "precision": 0.87293,
            "recall": 0.85587,
            "f1": 0.86249
        },
        "meteor": 0.2824341249169649,
        "bleurt": -0.21544
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 269,
        "total_length": 8813,
        "mean_pred_length": 32.762081784386616,
        "std_pred_length": 10.7095436079559,
        "median_pred_length": 32.0,
        "min_pred_length": 10,
        "max_pred_length": 96,
        "distinct-1": 0.10110064677181436,
        "vocab_size-1": 891,
        "unique-1": 335,
        "entropy-1": 7.288475664921152,
        "distinct-2": 0.301498127340824,
        "vocab_size-2": 2576,
        "unique-2": 1396,
        "entropy-2": 10.22735043921929,
        "cond_entropy-2": 2.842124824959118,
        "distinct-3": 0.496797583081571,
        "vocab_size-3": 4111,
        "unique-3": 2719,
        "entropy-3": 11.419378954189243,
        "cond_entropy-3": 1.2347157152906207,
        "total_length-nopunct": 7764,
        "mean_pred_length-nopunct": 28.86245353159851,
        "std_pred_length-nopunct": 9.824086699639892,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.1137300360638846,
        "vocab_size-1-nopunct": 883,
        "unique-1-nopunct": 333,
        "entropy-1-nopunct": 7.493495940672186,
        "distinct-2-nopunct": 0.32341561040693795,
        "vocab_size-2-nopunct": 2424,
        "unique-2-nopunct": 1372,
        "entropy-2-nopunct": 10.170229423178139,
        "cond_entropy-2-nopunct": 2.781987763229079,
        "distinct-3-nopunct": 0.5249100470523111,
        "vocab_size-3-nopunct": 3793,
        "unique-3-nopunct": 2604,
        "entropy-3-nopunct": 11.324356292496487,
        "cond_entropy-3-nopunct": 1.1890038122789708,
        "msttr-100": 0.52932,
        "msttr-100_nopunct": 0.5474,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18566775244299674,
            "2": 0.422759758108851,
            "3": 0.6882773220428685,
            "4": 0.25,
            "5": 0.5
        },
        "rouge1": {
            "precision": 0.58231,
            "recall": 0.59611,
            "fmeasure": 0.5771
        },
        "rouge2": {
            "precision": 0.2962,
            "recall": 0.30908,
            "fmeasure": 0.29564
        },
        "rougeL": {
            "precision": 0.41118,
            "recall": 0.42228,
            "fmeasure": 0.40723
        },
        "rougeLsum": {
            "precision": 0.41118,
            "recall": 0.42228,
            "fmeasure": 0.40723
        },
        "nist": 5.882887130070522,
        "bleu": 25.27002,
        "nubia": {
            "semantic_relation": 3.42821,
            "contradiction": 25.95339,
            "irrelevancy": 25.01456,
            "logical_agreement": 49.03205,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.43145,
            "nubia_score": 0.49243
        },
        "bertscore": {
            "precision": 0.85344,
            "recall": 0.85627,
            "f1": 0.85306
        },
        "meteor": 0.27696970208684374,
        "bleurt": -0.36895
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 1322,
        "total_length": 30537,
        "mean_pred_length": 23.099092284417548,
        "std_pred_length": 12.498533012578772,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 96,
        "distinct-1": 0.051249304122867344,
        "vocab_size-1": 1565,
        "unique-1": 482,
        "entropy-1": 7.723351360324862,
        "distinct-2": 0.17535512579154544,
        "vocab_size-2": 5123,
        "unique-2": 2298,
        "entropy-2": 10.882818142312999,
        "cond_entropy-2": 2.9899984571213256,
        "distinct-3": 0.315670598358011,
        "vocab_size-3": 8805,
        "unique-3": 4924,
        "entropy-3": 12.126830636259767,
        "cond_entropy-3": 1.314029041694627,
        "total_length-nopunct": 27042,
        "mean_pred_length-nopunct": 20.4553706505295,
        "std_pred_length-nopunct": 11.268953335610515,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.05754012277198432,
        "vocab_size-1-nopunct": 1556,
        "unique-1-nopunct": 482,
        "entropy-1-nopunct": 7.976019531953268,
        "distinct-2-nopunct": 0.18573094867807155,
        "vocab_size-2-nopunct": 4777,
        "unique-2-nopunct": 2208,
        "entropy-2-nopunct": 10.78512302934256,
        "cond_entropy-2-nopunct": 2.9678888344261773,
        "distinct-3-nopunct": 0.33207639970489383,
        "vocab_size-3-nopunct": 8102,
        "unique-3-nopunct": 4674,
        "entropy-3-nopunct": 12.008744520639635,
        "cond_entropy-3-nopunct": 1.2916146168427323,
        "msttr-100": 0.5022,
        "msttr-100_nopunct": 0.51989,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2249216964361297,
            "2": 0.5404075895994378,
            "3": 0.793509219007645,
            "4": 0.9215686274509803,
            "5": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.6964,
            "recall": 0.70922,
            "fmeasure": 0.694
        },
        "rouge2": {
            "precision": 0.4442,
            "recall": 0.45132,
            "fmeasure": 0.44158
        },
        "rougeL": {
            "precision": 0.56689,
            "recall": 0.5782,
            "fmeasure": 0.56488
        },
        "rougeLsum": {
            "precision": 0.56689,
            "recall": 0.5782,
            "fmeasure": 0.56488
        },
        "nist": 7.7305220461308926,
        "bleu": 40.04927,
        "nubia": {
            "semantic_relation": 4.09835,
            "contradiction": 17.05704,
            "irrelevancy": 12.41398,
            "logical_agreement": 70.52898,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.64364,
            "nubia_score": 0.69048
        },
        "bertscore": {
            "precision": 0.90196,
            "recall": 0.90469,
            "f1": 0.90196
        },
        "meteor": 0.3511882734694528,
        "bleurt": 0.05301
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 457,
        "total_length": 14296,
        "mean_pred_length": 31.282275711159738,
        "std_pred_length": 11.812038738242551,
        "median_pred_length": 30.0,
        "min_pred_length": 8,
        "max_pred_length": 85,
        "distinct-1": 0.08463905987688863,
        "vocab_size-1": 1210,
        "unique-1": 460,
        "entropy-1": 7.685665840465522,
        "distinct-2": 0.2404798034540068,
        "vocab_size-2": 3328,
        "unique-2": 1723,
        "entropy-2": 10.436609540564227,
        "cond_entropy-2": 2.631276045579911,
        "distinct-3": 0.38103422507846363,
        "vocab_size-3": 5099,
        "unique-3": 3232,
        "entropy-3": 11.393669018124385,
        "cond_entropy-3": 1.0077309665656264,
        "total_length-nopunct": 12642,
        "mean_pred_length-nopunct": 27.663019693654267,
        "std_pred_length-nopunct": 10.617901673967257,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.09500079101408004,
        "vocab_size-1-nopunct": 1201,
        "unique-1-nopunct": 458,
        "entropy-1-nopunct": 7.939953124700377,
        "distinct-2-nopunct": 0.25400082068116536,
        "vocab_size-2-nopunct": 3095,
        "unique-2-nopunct": 1679,
        "entropy-2-nopunct": 10.346436622277725,
        "cond_entropy-2-nopunct": 2.50882637411224,
        "distinct-3-nopunct": 0.39512278308321963,
        "vocab_size-3-nopunct": 4634,
        "unique-3-nopunct": 3015,
        "entropy-3-nopunct": 11.260513738368532,
        "cond_entropy-3-nopunct": 0.9533599235560007,
        "msttr-100": 0.4838,
        "msttr-100_nopunct": 0.49016,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2297008547008547,
            "2": 0.5889377749842866,
            "3": 0.8366352711919455,
            "4": 0.25,
            "5": 0.5
        },
        "rouge1": {
            "precision": 0.70713,
            "recall": 0.69641,
            "fmeasure": 0.69338
        },
        "rouge2": {
            "precision": 0.4385,
            "recall": 0.43061,
            "fmeasure": 0.42927
        },
        "rougeL": {
            "precision": 0.52205,
            "recall": 0.51635,
            "fmeasure": 0.51271
        },
        "rougeLsum": {
            "precision": 0.52205,
            "recall": 0.51635,
            "fmeasure": 0.51271
        },
        "nist": 8.189579470877009,
        "bleu": 46.09813,
        "nubia": {
            "semantic_relation": 4.13042,
            "contradiction": 14.48922,
            "irrelevancy": 10.97769,
            "logical_agreement": 74.53309,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.31343,
            "nubia_score": 0.70871
        },
        "bertscore": {
            "precision": 0.90278,
            "recall": 0.90007,
            "f1": 0.89999
        },
        "meteor": 0.3651274208204452,
        "bleurt": -0.02196
    },
    "xsum_val": {
        "predictions_file": "mT5_base/xsum_val",
        "N": 1117,
        "total_length": 24145,
        "mean_pred_length": 21.615935541629366,
        "std_pred_length": 4.789969782460388,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 91,
        "distinct-1": 0.18716090287844275,
        "vocab_size-1": 4519,
        "unique-1": 2543,
        "entropy-1": 9.126954856480637,
        "distinct-2": 0.6063053673788431,
        "vocab_size-2": 13962,
        "unique-2": 11356,
        "entropy-2": 12.935958623242604,
        "cond_entropy-2": 3.5831746093765746,
        "distinct-3": 0.8464698096846333,
        "vocab_size-3": 18547,
        "unique-3": 17070,
        "entropy-3": 13.950482842623687,
        "cond_entropy-3": 1.0186268542631693,
        "total_length-nopunct": 22494,
        "mean_pred_length-nopunct": 20.137869292748434,
        "std_pred_length-nopunct": 4.568857263642487,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.20032008535609497,
        "vocab_size-1-nopunct": 4506,
        "unique-1-nopunct": 2542,
        "entropy-1-nopunct": 9.30295962573814,
        "distinct-2-nopunct": 0.6165504981989989,
        "vocab_size-2-nopunct": 13180,
        "unique-2-nopunct": 10811,
        "entropy-2-nopunct": 12.869240352151367,
        "cond_entropy-2-nopunct": 3.687592921229649,
        "distinct-3-nopunct": 0.8583415597235933,
        "vocab_size-3-nopunct": 17390,
        "unique-3-nopunct": 16072,
        "entropy-3-nopunct": 13.89022007655781,
        "cond_entropy-3-nopunct": 1.0365436123288212,
        "msttr-100": 0.7149,
        "msttr-100_nopunct": 0.73397,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_val.json",
        "local_recall": {
            "1": 0.3270238525478858
        },
        "rouge1": {
            "precision": 0.37141,
            "recall": 0.35138,
            "fmeasure": 0.3543
        },
        "rouge2": {
            "precision": 0.12723,
            "recall": 0.11995,
            "fmeasure": 0.12087
        },
        "rougeL": {
            "precision": 0.28496,
            "recall": 0.2695,
            "fmeasure": 0.27173
        },
        "rougeLsum": {
            "precision": 0.28496,
            "recall": 0.2695,
            "fmeasure": 0.27173
        },
        "nist": 3.436605426211766,
        "bleu": 8.0376,
        "nubia": {
            "semantic_relation": 2.56338,
            "contradiction": 28.81343,
            "irrelevancy": 62.67507,
            "logical_agreement": 8.51151,
            "grammar_ref": 3.8151,
            "grammar_hyp": 3.74336,
            "nubia_score": 0.3414
        },
        "bertscore": {
            "precision": 0.82258,
            "recall": 0.81238,
            "f1": 0.81716
        },
        "meteor": 0.1561065633702751,
        "bleurt": -0.39369
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 116,
        "total_length": 2786,
        "mean_pred_length": 24.017241379310345,
        "std_pred_length": 7.161899621128136,
        "median_pred_length": 24.0,
        "min_pred_length": 9,
        "max_pred_length": 47,
        "distinct-1": 0.2455132806891601,
        "vocab_size-1": 684,
        "unique-1": 311,
        "entropy-1": 7.811415461759626,
        "distinct-2": 0.4902621722846442,
        "vocab_size-2": 1309,
        "unique-2": 777,
        "entropy-2": 9.815657518364743,
        "cond_entropy-2": 1.8269105784508322,
        "distinct-3": 0.6237274862960063,
        "vocab_size-3": 1593,
        "unique-3": 1080,
        "entropy-3": 10.343280621591838,
        "cond_entropy-3": 0.5267709338033116,
        "total_length-nopunct": 2309,
        "mean_pred_length-nopunct": 19.905172413793103,
        "std_pred_length-nopunct": 6.605873103007059,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.29363360762234736,
        "vocab_size-1-nopunct": 678,
        "unique-1-nopunct": 310,
        "entropy-1-nopunct": 8.271501947502179,
        "distinct-2-nopunct": 0.523483812129503,
        "vocab_size-2-nopunct": 1148,
        "unique-2-nopunct": 709,
        "entropy-2-nopunct": 9.687840741622422,
        "cond_entropy-2-nopunct": 1.4418615564783686,
        "distinct-3-nopunct": 0.6504573904670198,
        "vocab_size-3-nopunct": 1351,
        "unique-3-nopunct": 952,
        "entropy-3-nopunct": 10.127585081766844,
        "cond_entropy-3-nopunct": 0.4596788666700831,
        "msttr-100": 0.57667,
        "msttr-100_nopunct": 0.63957,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2697072072072072,
            "2": 0.660377358490566,
            "3": 0.8921095008051529
        },
        "rouge1": {
            "precision": 0.15393,
            "recall": 0.16379,
            "fmeasure": 0.15757
        },
        "rouge2": {
            "precision": 0.07295,
            "recall": 0.07984,
            "fmeasure": 0.07553
        },
        "rougeL": {
            "precision": 0.14846,
            "recall": 0.15817,
            "fmeasure": 0.15204
        },
        "rougeLsum": {
            "precision": 0.14846,
            "recall": 0.15817,
            "fmeasure": 0.15204
        },
        "nist": 7.771865116534989,
        "bleu": 45.88733,
        "nubia": {
            "semantic_relation": 4.00628,
            "contradiction": 18.51942,
            "irrelevancy": 20.13358,
            "logical_agreement": 61.347,
            "grammar_ref": 2.53819,
            "grammar_hyp": 2.46756,
            "nubia_score": 0.83361
        },
        "bertscore": {
            "precision": 0.95386,
            "recall": 0.94856,
            "f1": 0.95052
        },
        "meteor": 0.6111839283297974,
        "bleurt": 0.15418
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 642,
        "total_length": 11879,
        "mean_pred_length": 18.503115264797508,
        "std_pred_length": 12.035933593213045,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 70,
        "distinct-1": 0.15733647613435475,
        "vocab_size-1": 1869,
        "unique-1": 713,
        "entropy-1": 8.73694320779869,
        "distinct-2": 0.37296431431876836,
        "vocab_size-2": 4191,
        "unique-2": 2249,
        "entropy-2": 11.283361552290174,
        "cond_entropy-2": 2.258257282411488,
        "distinct-3": 0.52033978291647,
        "vocab_size-3": 5513,
        "unique-3": 3537,
        "entropy-3": 11.95587722546571,
        "cond_entropy-3": 0.6912920885876804,
        "total_length-nopunct": 9822,
        "mean_pred_length-nopunct": 15.299065420560748,
        "std_pred_length-nopunct": 10.059525285558859,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.18957442476074118,
        "vocab_size-1-nopunct": 1862,
        "unique-1-nopunct": 713,
        "entropy-1-nopunct": 9.363055603089478,
        "distinct-2-nopunct": 0.4016339869281046,
        "vocab_size-2-nopunct": 3687,
        "unique-2-nopunct": 2067,
        "entropy-2-nopunct": 11.168036310953829,
        "cond_entropy-2-nopunct": 1.8887200742244048,
        "distinct-3-nopunct": 0.546849379245725,
        "vocab_size-3-nopunct": 4669,
        "unique-3-nopunct": 3110,
        "entropy-3-nopunct": 11.7459209152532,
        "cond_entropy-3-nopunct": 0.6331308349312925,
        "msttr-100": 0.61805,
        "msttr-100_nopunct": 0.67367,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.30728632165371644,
            "2": 0.6811989100817438,
            "3": 0.9009797060881736,
            "4": 0.9473684210526315,
            "5": 0.9393939393939394,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.50553,
            "recall": 0.51471,
            "fmeasure": 0.5064
        },
        "rouge2": {
            "precision": 0.32012,
            "recall": 0.32863,
            "fmeasure": 0.32071
        },
        "rougeL": {
            "precision": 0.47827,
            "recall": 0.48742,
            "fmeasure": 0.47912
        },
        "rougeLsum": {
            "precision": 0.47827,
            "recall": 0.48742,
            "fmeasure": 0.47912
        },
        "nist": 9.327860754133008,
        "bleu": 55.22014,
        "nubia": {
            "semantic_relation": 4.05458,
            "contradiction": 19.40556,
            "irrelevancy": 21.17941,
            "logical_agreement": 59.41503,
            "grammar_ref": 2.74601,
            "grammar_hyp": 2.70489,
            "nubia_score": 0.83925
        },
        "bertscore": {
            "precision": 0.96049,
            "recall": 0.95924,
            "f1": 0.95923
        },
        "meteor": 0.6904749751245274,
        "bleurt": 0.25364
    },
    "web_nlg_ru_challenge_test_scramble": {
        "predictions_file": "mT5_base/web_nlg_ru_challenge_test_scramble",
        "N": 500,
        "total_length": 11178,
        "mean_pred_length": 22.356,
        "std_pred_length": 13.025254853552772,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.20459831812488818,
        "vocab_size-1": 2287,
        "unique-1": 1089,
        "entropy-1": 8.926932258217242,
        "distinct-2": 0.5221015171380409,
        "vocab_size-2": 5575,
        "unique-2": 3796,
        "entropy-2": 11.812044351196754,
        "cond_entropy-2": 2.6489973480022173,
        "distinct-3": 0.7300058950677932,
        "vocab_size-3": 7430,
        "unique-3": 6044,
        "entropy-3": 12.591343990915515,
        "cond_entropy-3": 0.783012222013945,
        "total_length-nopunct": 9179,
        "mean_pred_length-nopunct": 18.358,
        "std_pred_length-nopunct": 10.884017456803347,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.24817518248175183,
        "vocab_size-1-nopunct": 2278,
        "unique-1-nopunct": 1088,
        "entropy-1-nopunct": 9.637547030003821,
        "distinct-2-nopunct": 0.5830164765525983,
        "vocab_size-2-nopunct": 5060,
        "unique-2-nopunct": 3707,
        "entropy-2-nopunct": 11.781060390836352,
        "cond_entropy-2-nopunct": 2.205335162620886,
        "distinct-3-nopunct": 0.7654970045237804,
        "vocab_size-3-nopunct": 6261,
        "unique-3-nopunct": 5298,
        "entropy-3-nopunct": 12.372937467864087,
        "cond_entropy-3-nopunct": 0.6141386672469525,
        "msttr-100": 0.63748,
        "msttr-100_nopunct": 0.70659,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.2790091264667536,
            "2": 0.6066666666666667,
            "3": 0.8233305156382079,
            "4": 0.8222222222222222,
            "5": 0.8,
            "6": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.40265,
            "recall": 0.42495,
            "fmeasure": 0.40779
        },
        "rouge2": {
            "precision": 0.21295,
            "recall": 0.22813,
            "fmeasure": 0.21488
        },
        "rougeL": {
            "precision": 0.38309,
            "recall": 0.40471,
            "fmeasure": 0.38791
        },
        "rougeLsum": {
            "precision": 0.38309,
            "recall": 0.40471,
            "fmeasure": 0.38791
        },
        "nist": 7.797958855325105,
        "bleu": 41.19875,
        "nubia": {
            "semantic_relation": 3.90691,
            "contradiction": 22.09991,
            "irrelevancy": 22.54804,
            "logical_agreement": 55.35204,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.57214,
            "nubia_score": 0.78782
        },
        "bertscore": {
            "precision": 0.94786,
            "recall": 0.94676,
            "f1": 0.94661
        },
        "meteor": 0.5980682318215984,
        "bleurt": 0.13893
    },
    "mlsum_de_val": {
        "predictions_file": "mT5_base/mlsum_de_val",
        "N": 11392,
        "total_length": 308481,
        "mean_pred_length": 27.078739466292134,
        "std_pred_length": 11.173202176015208,
        "median_pred_length": 25.0,
        "min_pred_length": 7,
        "max_pred_length": 86,
        "distinct-1": 0.11825039467584714,
        "vocab_size-1": 36478,
        "unique-1": 21815,
        "entropy-1": 10.561857526582608,
        "distinct-2": 0.5352268175529892,
        "vocab_size-2": 159010,
        "unique-2": 128290,
        "entropy-2": 16.04481534370026,
        "cond_entropy-2": 5.242207266381116,
        "distinct-3": 0.8534146315852109,
        "vocab_size-3": 243818,
        "unique-3": 224600,
        "entropy-3": 17.66882655172216,
        "cond_entropy-3": 1.601007093664922,
        "total_length-nopunct": 273808,
        "mean_pred_length-nopunct": 24.035112359550563,
        "std_pred_length-nopunct": 9.850631089049264,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 78,
        "distinct-1-nopunct": 0.13317361070531175,
        "vocab_size-1-nopunct": 36464,
        "unique-1-nopunct": 21812,
        "entropy-1-nopunct": 11.114246498907166,
        "distinct-2-nopunct": 0.5951885555758796,
        "vocab_size-2-nopunct": 156187,
        "unique-2-nopunct": 129141,
        "entropy-2-nopunct": 16.294813038148025,
        "cond_entropy-2-nopunct": 5.278612601259394,
        "distinct-3-nopunct": 0.887648193001466,
        "vocab_size-3-nopunct": 222821,
        "unique-3-nopunct": 208611,
        "entropy-3-nopunct": 17.603952015092876,
        "cond_entropy-3-nopunct": 1.341434515544634,
        "msttr-100": 0.77637,
        "msttr-100_nopunct": 0.82596,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_val.json",
        "local_recall": {
            "1": 0.46741049927757267
        },
        "rouge1": {
            "precision": 0.45046,
            "recall": 0.45513,
            "fmeasure": 0.44268
        },
        "rouge2": {
            "precision": 0.33813,
            "recall": 0.34316,
            "fmeasure": 0.33647
        },
        "rougeL": {
            "precision": 0.41301,
            "recall": 0.41685,
            "fmeasure": 0.40692
        },
        "rougeLsum": {
            "precision": 0.41301,
            "recall": 0.41685,
            "fmeasure": 0.40692
        },
        "nist": 7.297474398210466,
        "bleu": 37.18461,
        "nubia": {
            "semantic_relation": 2.74282,
            "contradiction": 23.60508,
            "irrelevancy": 41.32796,
            "logical_agreement": 35.06696,
            "grammar_ref": 5.04919,
            "grammar_hyp": 4.97976,
            "nubia_score": 0.40185
        },
        "bertscore": {
            "precision": 0.89128,
            "recall": 0.89314,
            "f1": 0.89203
        },
        "meteor": 0.4277377983881437,
        "bleurt": -0.24649
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 34,
        "total_length": 357,
        "mean_pred_length": 10.5,
        "std_pred_length": 2.692582403567252,
        "median_pred_length": 9.5,
        "min_pred_length": 6,
        "max_pred_length": 15,
        "distinct-1": 0.1792717086834734,
        "vocab_size-1": 64,
        "unique-1": 16,
        "entropy-1": 5.236784288610634,
        "distinct-2": 0.33126934984520123,
        "vocab_size-2": 107,
        "unique-2": 43,
        "entropy-2": 6.189716071289768,
        "cond_entropy-2": 0.7587773757494513,
        "distinct-3": 0.43944636678200694,
        "vocab_size-3": 127,
        "unique-3": 60,
        "entropy-3": 6.599718850396776,
        "cond_entropy-3": 0.38923624717807204,
        "total_length-nopunct": 310,
        "mean_pred_length-nopunct": 9.117647058823529,
        "std_pred_length-nopunct": 2.272142107744467,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.2,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 5.254607920480535,
        "distinct-2-nopunct": 0.34057971014492755,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 6.024004745752176,
        "cond_entropy-2-nopunct": 0.7900412810943953,
        "distinct-3-nopunct": 0.45454545454545453,
        "vocab_size-3-nopunct": 110,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 6.418706408433112,
        "cond_entropy-3-nopunct": 0.38766601481676755,
        "msttr-100": 0.4,
        "msttr-100_nopunct": 0.41667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.37910447761194027
        },
        "rouge1": {
            "precision": 0.51855,
            "recall": 0.46756,
            "fmeasure": 0.47949
        },
        "rouge2": {
            "precision": 0.32524,
            "recall": 0.29396,
            "fmeasure": 0.30011
        },
        "rougeL": {
            "precision": 0.47474,
            "recall": 0.42212,
            "fmeasure": 0.43628
        },
        "rougeLsum": {
            "precision": 0.47474,
            "recall": 0.42212,
            "fmeasure": 0.43628
        },
        "nist": 2.8342407500053297,
        "bleu": 16.86021,
        "nubia": {
            "semantic_relation": 3.23591,
            "contradiction": 27.05363,
            "irrelevancy": 18.51903,
            "logical_agreement": 54.42734,
            "grammar_ref": 6.46033,
            "grammar_hyp": 6.6801,
            "nubia_score": 0.4278
        },
        "bertscore": {
            "precision": 0.91173,
            "recall": 0.90752,
            "f1": 0.9094
        },
        "meteor": 0.2110801005908908,
        "bleurt": -0.20883
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 12,
        "total_length": 87,
        "mean_pred_length": 7.25,
        "std_pred_length": 1.963203164898291,
        "median_pred_length": 6.5,
        "min_pred_length": 5,
        "max_pred_length": 10,
        "distinct-1": 0.3563218390804598,
        "vocab_size-1": 31,
        "unique-1": 13,
        "entropy-1": 4.545565122350952,
        "distinct-2": 0.5333333333333333,
        "vocab_size-2": 40,
        "unique-2": 23,
        "entropy-2": 5.096379317070696,
        "cond_entropy-2": 0.2808007343640026,
        "distinct-3": 0.5714285714285714,
        "vocab_size-3": 36,
        "unique-3": 22,
        "entropy-3": 4.964366629402694,
        "cond_entropy-3": -0.06725875946522128,
        "total_length-nopunct": 71,
        "mean_pred_length-nopunct": 5.916666666666667,
        "std_pred_length-nopunct": 1.552328000849763,
        "median_pred_length-nopunct": 5.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.4084507042253521,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.543375732382814,
        "distinct-2-nopunct": 0.5084745762711864,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.684875413761868,
        "cond_entropy-2-nopunct": 0.29008750580507814,
        "distinct-3-nopunct": 0.5531914893617021,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.5003574682386,
        "cond_entropy-3-nopunct": -0.10231716631320778,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.25609756097560976
        },
        "rouge1": {
            "precision": 0.4626,
            "recall": 0.36754,
            "fmeasure": 0.40511
        },
        "rouge2": {
            "precision": 0.25821,
            "recall": 0.20184,
            "fmeasure": 0.22321
        },
        "rougeL": {
            "precision": 0.4626,
            "recall": 0.36754,
            "fmeasure": 0.40511
        },
        "rougeLsum": {
            "precision": 0.4626,
            "recall": 0.36754,
            "fmeasure": 0.40511
        },
        "nist": 1.6272173146214437,
        "bleu": 12.24482,
        "nubia": {
            "semantic_relation": 2.53261,
            "contradiction": 32.90608,
            "irrelevancy": 29.53716,
            "logical_agreement": 37.55675,
            "grammar_ref": 6.83527,
            "grammar_hyp": 7.72351,
            "nubia_score": 0.19049
        },
        "bertscore": {
            "precision": 0.88185,
            "recall": 0.87933,
            "f1": 0.88051
        },
        "meteor": 0.13302082845147503,
        "bleurt": -0.27722
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 183,
        "total_length": 1490,
        "mean_pred_length": 8.142076502732241,
        "std_pred_length": 0.95901250135433,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 11,
        "distinct-1": 0.02953020134228188,
        "vocab_size-1": 44,
        "unique-1": 13,
        "entropy-1": 3.845438229244147,
        "distinct-2": 0.046671767406273906,
        "vocab_size-2": 61,
        "unique-2": 23,
        "entropy-2": 3.9985807215079183,
        "cond_entropy-2": 0.03832414050501533,
        "distinct-3": 0.050711743772241996,
        "vocab_size-3": 57,
        "unique-3": 22,
        "entropy-3": 3.827043749731181,
        "cond_entropy-3": -0.17292453057405627,
        "total_length-nopunct": 1126,
        "mean_pred_length-nopunct": 6.1530054644808745,
        "std_pred_length-nopunct": 0.730730030188523,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.037300177619893425,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7038775958022776,
        "distinct-2-nopunct": 0.04772004241781548,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 3.5627215321911945,
        "cond_entropy-2-nopunct": -0.13829912596413632,
        "distinct-3-nopunct": 0.05394736842105263,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.3280578257164684,
        "cond_entropy-3-nopunct": -0.24995493377739603,
        "msttr-100": 0.19071,
        "msttr-100_nopunct": 0.19364,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.19042871385842472
        },
        "rouge1": {
            "precision": 0.27625,
            "recall": 0.33934,
            "fmeasure": 0.29689
        },
        "rouge2": {
            "precision": 0.12986,
            "recall": 0.16609,
            "fmeasure": 0.14073
        },
        "rougeL": {
            "precision": 0.24565,
            "recall": 0.30134,
            "fmeasure": 0.2634
        },
        "rougeLsum": {
            "precision": 0.24565,
            "recall": 0.30134,
            "fmeasure": 0.2634
        },
        "nist": 1.1445194252326005,
        "bleu": 5.33739,
        "nubia": {
            "semantic_relation": 1.71825,
            "contradiction": 49.61505,
            "irrelevancy": 40.9808,
            "logical_agreement": 9.40415,
            "grammar_ref": 6.72681,
            "grammar_hyp": 7.45728,
            "nubia_score": 0.11463
        },
        "bertscore": {
            "precision": 0.83236,
            "recall": 0.87126,
            "f1": 0.85119
        },
        "meteor": 0.10033196904142389,
        "bleurt": -0.64829
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 267,
        "total_length": 2606,
        "mean_pred_length": 9.760299625468164,
        "std_pred_length": 2.851282106009908,
        "median_pred_length": 8.0,
        "min_pred_length": 6,
        "max_pred_length": 18,
        "distinct-1": 0.11588641596316193,
        "vocab_size-1": 302,
        "unique-1": 148,
        "entropy-1": 5.841038743539757,
        "distinct-2": 0.2599401453612655,
        "vocab_size-2": 608,
        "unique-2": 355,
        "entropy-2": 7.599341830141698,
        "cond_entropy-2": 1.4542702841672996,
        "distinct-3": 0.36631274131274133,
        "vocab_size-3": 759,
        "unique-3": 531,
        "entropy-3": 8.231739294668698,
        "cond_entropy-3": 0.9807682324363537,
        "total_length-nopunct": 2261,
        "mean_pred_length-nopunct": 8.46816479400749,
        "std_pred_length-nopunct": 2.5502290421841507,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.13224237063246352,
        "vocab_size-1-nopunct": 299,
        "unique-1-nopunct": 148,
        "entropy-1-nopunct": 5.968497924948696,
        "distinct-2-nopunct": 0.21865596790371114,
        "vocab_size-2-nopunct": 436,
        "unique-2-nopunct": 249,
        "entropy-2-nopunct": 7.0399648901687994,
        "cond_entropy-2-nopunct": 1.6179603915608167,
        "distinct-3-nopunct": 0.3254198031268095,
        "vocab_size-3-nopunct": 562,
        "unique-3-nopunct": 391,
        "entropy-3-nopunct": 7.698944906501117,
        "cond_entropy-3-nopunct": 1.1488330357896244,
        "msttr-100": 0.44115,
        "msttr-100_nopunct": 0.45864,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.598605577689243
        },
        "rouge1": {
            "precision": 0.575,
            "recall": 0.63135,
            "fmeasure": 0.58761
        },
        "rouge2": {
            "precision": 0.34564,
            "recall": 0.38443,
            "fmeasure": 0.35458
        },
        "rougeL": {
            "precision": 0.51957,
            "recall": 0.56612,
            "fmeasure": 0.52949
        },
        "rougeLsum": {
            "precision": 0.51957,
            "recall": 0.56612,
            "fmeasure": 0.52949
        },
        "nist": 4.056309473236822,
        "bleu": 21.25521,
        "nubia": {
            "semantic_relation": 3.61989,
            "contradiction": 21.36275,
            "irrelevancy": 33.94291,
            "logical_agreement": 44.69435,
            "grammar_ref": 7.44295,
            "grammar_hyp": 7.1497,
            "nubia_score": 0.57189
        },
        "bertscore": {
            "precision": 0.90615,
            "recall": 0.9193,
            "f1": 0.91245
        },
        "meteor": 0.30003267859524363,
        "bleurt": 0.00467
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 297,
        "total_length": 3338,
        "mean_pred_length": 11.239057239057239,
        "std_pred_length": 1.9932773682449116,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 19,
        "distinct-1": 0.06860395446375075,
        "vocab_size-1": 229,
        "unique-1": 99,
        "entropy-1": 6.122972896176052,
        "distinct-2": 0.15291022689904638,
        "vocab_size-2": 465,
        "unique-2": 225,
        "entropy-2": 7.388846132363287,
        "cond_entropy-2": 1.0054847933834647,
        "distinct-3": 0.24161807580174927,
        "vocab_size-3": 663,
        "unique-3": 340,
        "entropy-3": 8.062410331676793,
        "cond_entropy-3": 0.7148663027256318,
        "total_length-nopunct": 2819,
        "mean_pred_length-nopunct": 9.491582491582491,
        "std_pred_length-nopunct": 1.9018234703976622,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.08017027314650585,
        "vocab_size-1-nopunct": 226,
        "unique-1-nopunct": 99,
        "entropy-1-nopunct": 6.299041852932963,
        "distinct-2-nopunct": 0.1522601110229976,
        "vocab_size-2-nopunct": 384,
        "unique-2-nopunct": 162,
        "entropy-2-nopunct": 7.281252606346224,
        "cond_entropy-2-nopunct": 1.1174194663194876,
        "distinct-3-nopunct": 0.24943820224719102,
        "vocab_size-3-nopunct": 555,
        "unique-3-nopunct": 272,
        "entropy-3-nopunct": 7.928914496418628,
        "cond_entropy-3-nopunct": 0.8240686246927273,
        "msttr-100": 0.49848,
        "msttr-100_nopunct": 0.52429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.49111352919840406
        },
        "rouge1": {
            "precision": 0.52075,
            "recall": 0.52843,
            "fmeasure": 0.51414
        },
        "rouge2": {
            "precision": 0.31667,
            "recall": 0.32612,
            "fmeasure": 0.31419
        },
        "rougeL": {
            "precision": 0.48235,
            "recall": 0.49069,
            "fmeasure": 0.47709
        },
        "rougeLsum": {
            "precision": 0.48235,
            "recall": 0.49069,
            "fmeasure": 0.47709
        },
        "nist": 4.035619789170873,
        "bleu": 20.75908,
        "nubia": {
            "semantic_relation": 3.60373,
            "contradiction": 22.65292,
            "irrelevancy": 31.73452,
            "logical_agreement": 45.61256,
            "grammar_ref": 6.65825,
            "grammar_hyp": 6.74326,
            "nubia_score": 0.52984
        },
        "bertscore": {
            "precision": 0.90035,
            "recall": 0.90567,
            "f1": 0.90281
        },
        "meteor": 0.2513500744148854,
        "bleurt": -0.13738
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 86,
        "total_length": 1179,
        "mean_pred_length": 13.709302325581396,
        "std_pred_length": 2.5374693448475596,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.1475826972010178,
        "vocab_size-1": 174,
        "unique-1": 75,
        "entropy-1": 5.853544691852826,
        "distinct-2": 0.29551692589204026,
        "vocab_size-2": 323,
        "unique-2": 192,
        "entropy-2": 7.13738420263937,
        "cond_entropy-2": 1.1178486284023876,
        "distinct-3": 0.41211519364448856,
        "vocab_size-3": 415,
        "unique-3": 286,
        "entropy-3": 7.643047100811445,
        "cond_entropy-3": 0.5130450032441246,
        "total_length-nopunct": 1027,
        "mean_pred_length-nopunct": 11.94186046511628,
        "std_pred_length-nopunct": 2.3642425954832675,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.1665043816942551,
        "vocab_size-1-nopunct": 171,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 5.9210089217367585,
        "distinct-2-nopunct": 0.2975557917109458,
        "vocab_size-2-nopunct": 280,
        "unique-2-nopunct": 158,
        "entropy-2-nopunct": 7.022595574688413,
        "cond_entropy-2-nopunct": 1.1954745900568255,
        "distinct-3-nopunct": 0.43391812865497076,
        "vocab_size-3-nopunct": 371,
        "unique-3-nopunct": 252,
        "entropy-3-nopunct": 7.613417940285267,
        "cond_entropy-3-nopunct": 0.5785126107119194,
        "msttr-100": 0.46909,
        "msttr-100_nopunct": 0.481,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.43498098859315587
        },
        "rouge1": {
            "precision": 0.65026,
            "recall": 0.48579,
            "fmeasure": 0.54583
        },
        "rouge2": {
            "precision": 0.38313,
            "recall": 0.28005,
            "fmeasure": 0.3174
        },
        "rougeL": {
            "precision": 0.57161,
            "recall": 0.42458,
            "fmeasure": 0.47851
        },
        "rougeLsum": {
            "precision": 0.57161,
            "recall": 0.42458,
            "fmeasure": 0.47851
        },
        "nist": 3.462777401158459,
        "bleu": 18.49132,
        "nubia": {
            "semantic_relation": 3.31712,
            "contradiction": 18.02477,
            "irrelevancy": 16.92261,
            "logical_agreement": 65.05261,
            "grammar_ref": 6.22337,
            "grammar_hyp": 6.43639,
            "nubia_score": 0.49244
        },
        "bertscore": {
            "precision": 0.92861,
            "recall": 0.9051,
            "f1": 0.91658
        },
        "meteor": 0.22686207058969982,
        "bleurt": -0.05942
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_base/cs_restaurants_test",
        "N": 9,
        "total_length": 132,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.4166666666666667,
        "vocab_size-1": 55,
        "unique-1": 31,
        "entropy-1": 5.252685193819797,
        "distinct-2": 0.6016260162601627,
        "vocab_size-2": 74,
        "unique-2": 50,
        "entropy-2": 5.914768730145867,
        "cond_entropy-2": 0.5612384576014143,
        "distinct-3": 0.7105263157894737,
        "vocab_size-3": 81,
        "unique-3": 64,
        "entropy-3": 6.103998927061233,
        "cond_entropy-3": 0.16852906974257817,
        "total_length-nopunct": 115,
        "mean_pred_length-nopunct": 12.777777777777779,
        "std_pred_length-nopunct": 2.57240820062005,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.4608695652173913,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.245696545221583,
        "distinct-2-nopunct": 0.6320754716981132,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.795815833107083,
        "cond_entropy-2-nopunct": 0.5764259018201185,
        "distinct-3-nopunct": 0.7628865979381443,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 6.015077213803625,
        "cond_entropy-3-nopunct": 0.18605829944568267,
        "msttr-100": 0.52,
        "msttr-100_nopunct": 0.51,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.48148148148148145
        },
        "rouge1": {
            "precision": 0.63065,
            "recall": 0.49713,
            "fmeasure": 0.54161
        },
        "rouge2": {
            "precision": 0.37692,
            "recall": 0.30736,
            "fmeasure": 0.32833
        },
        "rougeL": {
            "precision": 0.5354,
            "recall": 0.42962,
            "fmeasure": 0.46279
        },
        "rougeLsum": {
            "precision": 0.5354,
            "recall": 0.42962,
            "fmeasure": 0.46279
        },
        "nist": 3.2673891427125867,
        "bleu": 23.65177,
        "nubia": {
            "semantic_relation": 3.6988,
            "contradiction": 11.09501,
            "irrelevancy": 19.80985,
            "logical_agreement": 69.09514,
            "grammar_ref": 6.01604,
            "grammar_hyp": 6.34395,
            "nubia_score": 0.56188
        },
        "bertscore": {
            "precision": 0.92938,
            "recall": 0.90727,
            "f1": 0.9181
        },
        "meteor": 0.25658835619370457,
        "bleurt": -0.10072
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 214,
        "total_length": 6058,
        "mean_pred_length": 28.30841121495327,
        "std_pred_length": 9.493639006614462,
        "median_pred_length": 26.0,
        "min_pred_length": 14,
        "max_pred_length": 70,
        "distinct-1": 0.2444701221525256,
        "vocab_size-1": 1481,
        "unique-1": 719,
        "entropy-1": 8.571829897796711,
        "distinct-2": 0.5078713210130048,
        "vocab_size-2": 2968,
        "unique-2": 1815,
        "entropy-2": 11.016580083216136,
        "cond_entropy-2": 2.272088513175395,
        "distinct-3": 0.6516873889875666,
        "vocab_size-3": 3669,
        "unique-3": 2607,
        "entropy-3": 11.5637651391819,
        "cond_entropy-3": 0.5594895106436586,
        "total_length-nopunct": 4895,
        "mean_pred_length-nopunct": 22.873831775700936,
        "std_pred_length-nopunct": 7.598448396072407,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.30112359550561796,
        "vocab_size-1-nopunct": 1474,
        "unique-1-nopunct": 718,
        "entropy-1-nopunct": 9.298696242679389,
        "distinct-2-nopunct": 0.5601367229224524,
        "vocab_size-2-nopunct": 2622,
        "unique-2-nopunct": 1696,
        "entropy-2-nopunct": 10.943184502766794,
        "cond_entropy-2-nopunct": 1.691835895152826,
        "distinct-3-nopunct": 0.6897246474143721,
        "vocab_size-3-nopunct": 3081,
        "unique-3-nopunct": 2292,
        "entropy-3-nopunct": 11.353397486411593,
        "cond_entropy-3-nopunct": 0.4277983733007085,
        "msttr-100": 0.69883,
        "msttr-100_nopunct": 0.79729,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2871203599550056,
            "2": 0.6880530973451328,
            "3": 0.8967032967032967
        },
        "rouge1": {
            "precision": 0.44143,
            "recall": 0.44915,
            "fmeasure": 0.4402
        },
        "rouge2": {
            "precision": 0.26176,
            "recall": 0.26817,
            "fmeasure": 0.25995
        },
        "rougeL": {
            "precision": 0.41428,
            "recall": 0.42186,
            "fmeasure": 0.41317
        },
        "rougeLsum": {
            "precision": 0.41428,
            "recall": 0.42186,
            "fmeasure": 0.41317
        },
        "nist": 8.807395233885792,
        "bleu": 51.58307,
        "nubia": {
            "semantic_relation": 3.96396,
            "contradiction": 19.1613,
            "irrelevancy": 21.44165,
            "logical_agreement": 59.39705,
            "grammar_ref": 2.5317,
            "grammar_hyp": 2.47712,
            "nubia_score": 0.8347
        },
        "bertscore": {
            "precision": 0.95372,
            "recall": 0.95115,
            "f1": 0.95189
        },
        "meteor": 0.6558025203277565,
        "bleurt": 0.13208
    },
    "xsum_test": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 1166,
        "total_length": 24925,
        "mean_pred_length": 21.376500857632934,
        "std_pred_length": 4.8408386465895425,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 68,
        "distinct-1": 0.18784353059177533,
        "vocab_size-1": 4682,
        "unique-1": 2689,
        "entropy-1": 9.15963004910856,
        "distinct-2": 0.6069699903194579,
        "vocab_size-2": 14421,
        "unique-2": 11779,
        "entropy-2": 12.955970158914045,
        "cond_entropy-2": 3.564126419614148,
        "distinct-3": 0.8445093613065994,
        "vocab_size-3": 19080,
        "unique-3": 17518,
        "entropy-3": 13.987631379875403,
        "cond_entropy-3": 1.0396377092114202,
        "total_length-nopunct": 23201,
        "mean_pred_length-nopunct": 19.89794168096055,
        "std_pred_length-nopunct": 4.591256424715443,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.20132752898581957,
        "vocab_size-1-nopunct": 4671,
        "unique-1-nopunct": 2687,
        "entropy-1-nopunct": 9.347208766917866,
        "distinct-2-nopunct": 0.6167460857726345,
        "vocab_size-2-nopunct": 13590,
        "unique-2-nopunct": 11181,
        "entropy-2-nopunct": 12.893481104118088,
        "cond_entropy-2-nopunct": 3.674847845385777,
        "distinct-3-nopunct": 0.8563419425942786,
        "vocab_size-3-nopunct": 17871,
        "unique-3-nopunct": 16487,
        "entropy-3-nopunct": 13.926139060843612,
        "cond_entropy-3-nopunct": 1.0527020850508042,
        "msttr-100": 0.71775,
        "msttr-100_nopunct": 0.73612,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.32116788321167883
        },
        "rouge1": {
            "precision": 0.37577,
            "recall": 0.34888,
            "fmeasure": 0.35446
        },
        "rouge2": {
            "precision": 0.13141,
            "recall": 0.12092,
            "fmeasure": 0.12313
        },
        "rougeL": {
            "precision": 0.28783,
            "recall": 0.26727,
            "fmeasure": 0.27145
        },
        "rougeLsum": {
            "precision": 0.28783,
            "recall": 0.26727,
            "fmeasure": 0.27145
        },
        "nist": 3.433475273564139,
        "bleu": 7.94054,
        "nubia": {
            "semantic_relation": 2.56744,
            "contradiction": 27.42794,
            "irrelevancy": 63.40709,
            "logical_agreement": 9.16498,
            "grammar_ref": 3.76542,
            "grammar_hyp": 3.70531,
            "nubia_score": 0.34039
        },
        "bertscore": {
            "precision": 0.82305,
            "recall": 0.80983,
            "f1": 0.8161
        },
        "meteor": 0.15287028143083134,
        "bleurt": -0.40955
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.23076923076923078
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.26667,
            "fmeasure": 0.2963
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.16667,
            "recall": 0.13333,
            "fmeasure": 0.14815
        },
        "rougeLsum": {
            "precision": 0.16667,
            "recall": 0.13333,
            "fmeasure": 0.14815
        },
        "nist": 1.154475172988883,
        "bleu": 3.6673,
        "nubia": {
            "semantic_relation": 0.39452,
            "contradiction": 22.90225,
            "irrelevancy": 76.35087,
            "logical_agreement": 0.74687,
            "grammar_ref": 5.57252,
            "grammar_hyp": 5.02466,
            "nubia_score": 0.06408
        },
        "bertscore": {
            "precision": 0.70641,
            "recall": 0.714,
            "f1": 0.71019
        },
        "meteor": 0.058224163027656484,
        "bleurt": -1.15916
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 214,
        "total_length": 4702,
        "mean_pred_length": 21.97196261682243,
        "std_pred_length": 6.40744010284136,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 42,
        "distinct-1": 0.27264993619736283,
        "vocab_size-1": 1282,
        "unique-1": 640,
        "entropy-1": 8.52837732496392,
        "distinct-2": 0.5668449197860963,
        "vocab_size-2": 2544,
        "unique-2": 1675,
        "entropy-2": 10.83192100054972,
        "cond_entropy-2": 2.077995021698607,
        "distinct-3": 0.7257838090781469,
        "vocab_size-3": 3102,
        "unique-3": 2371,
        "entropy-3": 11.39114848532235,
        "cond_entropy-3": 0.5677037402190545,
        "total_length-nopunct": 3897,
        "mean_pred_length-nopunct": 18.210280373831775,
        "std_pred_length-nopunct": 5.769537058145631,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.32717474980754424,
        "vocab_size-1-nopunct": 1275,
        "unique-1-nopunct": 640,
        "entropy-1-nopunct": 9.103896357052415,
        "distinct-2-nopunct": 0.6046701058919359,
        "vocab_size-2-nopunct": 2227,
        "unique-2-nopunct": 1520,
        "entropy-2-nopunct": 10.726812780500929,
        "cond_entropy-2-nopunct": 1.6778635751276212,
        "distinct-3-nopunct": 0.7474776592678005,
        "vocab_size-3-nopunct": 2593,
        "unique-3-nopunct": 2037,
        "entropy-3-nopunct": 11.146592919286393,
        "cond_entropy-3-nopunct": 0.44220691306096205,
        "msttr-100": 0.69745,
        "msttr-100_nopunct": 0.78342,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.29146656815663097,
            "2": 0.6846095526914329,
            "3": 0.911660777385159,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.44626,
            "recall": 0.47425,
            "fmeasure": 0.45655
        },
        "rouge2": {
            "precision": 0.23247,
            "recall": 0.25613,
            "fmeasure": 0.24005
        },
        "rougeL": {
            "precision": 0.42827,
            "recall": 0.45671,
            "fmeasure": 0.43872
        },
        "rougeLsum": {
            "precision": 0.42827,
            "recall": 0.45671,
            "fmeasure": 0.43872
        },
        "nist": 8.232262448511026,
        "bleu": 46.6472,
        "nubia": {
            "semantic_relation": 4.00039,
            "contradiction": 18.57724,
            "irrelevancy": 21.89748,
            "logical_agreement": 59.52528,
            "grammar_ref": 2.61878,
            "grammar_hyp": 2.50008,
            "nubia_score": 0.82854
        },
        "bertscore": {
            "precision": 0.95199,
            "recall": 0.95302,
            "f1": 0.95164
        },
        "meteor": 0.648101309728443,
        "bleurt": 0.14379
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 200,
        "total_length": 3141,
        "mean_pred_length": 15.705,
        "std_pred_length": 6.6036334695378125,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 63,
        "distinct-1": 0.3349251830627189,
        "vocab_size-1": 1052,
        "unique-1": 636,
        "entropy-1": 8.422582686198535,
        "distinct-2": 0.6524991499489969,
        "vocab_size-2": 1919,
        "unique-2": 1421,
        "entropy-2": 10.546626119485211,
        "cond_entropy-2": 1.8099084010007989,
        "distinct-3": 0.8026267785479752,
        "vocab_size-3": 2200,
        "unique-3": 1846,
        "entropy-3": 10.95139761638523,
        "cond_entropy-3": 0.4153932120339862,
        "total_length-nopunct": 2594,
        "mean_pred_length-nopunct": 12.97,
        "std_pred_length-nopunct": 5.515351303407608,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.40323824209714726,
        "vocab_size-1-nopunct": 1046,
        "unique-1-nopunct": 635,
        "entropy-1-nopunct": 8.980796352206012,
        "distinct-2-nopunct": 0.6812865497076024,
        "vocab_size-2-nopunct": 1631,
        "unique-2-nopunct": 1243,
        "entropy-2-nopunct": 10.353982459853745,
        "cond_entropy-2-nopunct": 1.4442012569292415,
        "distinct-3-nopunct": 0.817228805834093,
        "vocab_size-3-nopunct": 1793,
        "unique-3-nopunct": 1525,
        "entropy-3-nopunct": 10.668287462951737,
        "cond_entropy-3-nopunct": 0.3474043659542628,
        "msttr-100": 0.72742,
        "msttr-100_nopunct": 0.8048,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.26930596285434993,
            "2": 0.6229838709677419,
            "3": 0.8985695708712613,
            "4": 0.95,
            "5": 0.9615384615384616,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.38235,
            "recall": 0.39248,
            "fmeasure": 0.38497
        },
        "rouge2": {
            "precision": 0.20517,
            "recall": 0.21051,
            "fmeasure": 0.20622
        },
        "rougeL": {
            "precision": 0.37003,
            "recall": 0.38064,
            "fmeasure": 0.37286
        },
        "rougeLsum": {
            "precision": 0.37003,
            "recall": 0.38064,
            "fmeasure": 0.37286
        },
        "nist": 8.464551603740343,
        "bleu": 52.74451,
        "nubia": {
            "semantic_relation": 4.04318,
            "contradiction": 18.00872,
            "irrelevancy": 22.5942,
            "logical_agreement": 59.39708,
            "grammar_ref": 2.7039,
            "grammar_hyp": 2.66217,
            "nubia_score": 0.8301
        },
        "bertscore": {
            "precision": 0.95951,
            "recall": 0.95786,
            "f1": 0.95766
        },
        "meteor": 0.6888905349566034,
        "bleurt": 0.2235
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.71282,
            "fmeasure": 0.71515
        },
        "rouge2": {
            "precision": 0.48485,
            "recall": 0.55556,
            "fmeasure": 0.49469
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.77949,
            "fmeasure": 0.6902
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.77949,
            "fmeasure": 0.6902
        },
        "nist": 3.3937721354508072,
        "bleu": 56.62604,
        "nubia": {
            "semantic_relation": 3.14256,
            "contradiction": 76.90859,
            "irrelevancy": 22.46443,
            "logical_agreement": 0.62698,
            "grammar_ref": 6.66832,
            "grammar_hyp": 6.45382,
            "nubia_score": 0.30303
        },
        "bertscore": {
            "precision": 0.96582,
            "recall": 0.95587,
            "f1": 0.96082
        },
        "meteor": 0.4079121296326939,
        "bleurt": 0.27059
    },
    "xsum_challenge_test_backtranslation": {
        "predictions_file": "mT5_base/xsum_challenge_test_backtranslation",
        "N": 500,
        "total_length": 11729,
        "mean_pred_length": 23.458,
        "std_pred_length": 5.14511768572887,
        "median_pred_length": 23.0,
        "min_pred_length": 3,
        "max_pred_length": 44,
        "distinct-1": 0.26404638076562365,
        "vocab_size-1": 3097,
        "unique-1": 1982,
        "entropy-1": 9.10979253222722,
        "distinct-2": 0.7367530501380355,
        "vocab_size-2": 8273,
        "unique-2": 7187,
        "entropy-2": 12.539160386674821,
        "cond_entropy-2": 3.227347623356137,
        "distinct-3": 0.9361543480287072,
        "vocab_size-3": 10044,
        "unique-3": 9620,
        "entropy-3": 13.224581226222643,
        "cond_entropy-3": 0.6979866709414158,
        "total_length-nopunct": 10946,
        "mean_pred_length-nopunct": 21.892,
        "std_pred_length-nopunct": 4.991626588598149,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.28192947195322493,
        "vocab_size-1-nopunct": 3086,
        "unique-1-nopunct": 1979,
        "entropy-1-nopunct": 9.278719758637054,
        "distinct-2-nopunct": 0.7437296572850852,
        "vocab_size-2-nopunct": 7769,
        "unique-2-nopunct": 6788,
        "entropy-2-nopunct": 12.455256887302466,
        "cond_entropy-2-nopunct": 3.288149330108332,
        "distinct-3-nopunct": 0.9413834707420068,
        "vocab_size-3-nopunct": 9363,
        "unique-3-nopunct": 8989,
        "entropy-3-nopunct": 13.134735686647437,
        "cond_entropy-3-nopunct": 0.7004097520198264,
        "msttr-100": 0.73368,
        "msttr-100_nopunct": 0.7511,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_backtranslation.json",
        "local_recall": {
            "1": 0.27726675427069647
        },
        "rouge1": {
            "precision": 0.29137,
            "recall": 0.30035,
            "fmeasure": 0.2887
        },
        "rouge2": {
            "precision": 0.07098,
            "recall": 0.07336,
            "fmeasure": 0.07041
        },
        "rougeL": {
            "precision": 0.21492,
            "recall": 0.22202,
            "fmeasure": 0.21309
        },
        "rougeLsum": {
            "precision": 0.21492,
            "recall": 0.22202,
            "fmeasure": 0.21309
        },
        "nist": 2.4550344843226273,
        "bleu": 4.45743,
        "nubia": {
            "semantic_relation": 1.98955,
            "contradiction": 32.04377,
            "irrelevancy": 64.34392,
            "logical_agreement": 3.61231,
            "grammar_ref": 3.78538,
            "grammar_hyp": 4.19996,
            "nubia_score": 0.2182
        },
        "bertscore": {
            "precision": 0.79311,
            "recall": 0.79072,
            "f1": 0.79163
        },
        "meteor": 0.1245655991640809,
        "bleurt": -0.61431
    },
    "xsum_challenge_test_bfp_02": {
        "predictions_file": "mT5_base/xsum_challenge_test_bfp_02",
        "N": 500,
        "total_length": 11908,
        "mean_pred_length": 23.816,
        "std_pred_length": 5.9905044862682475,
        "median_pred_length": 23.0,
        "min_pred_length": 7,
        "max_pred_length": 61,
        "distinct-1": 0.26444407121263014,
        "vocab_size-1": 3149,
        "unique-1": 2021,
        "entropy-1": 9.136730709691484,
        "distinct-2": 0.7369389901823282,
        "vocab_size-2": 8407,
        "unique-2": 7361,
        "entropy-2": 12.552334787223485,
        "cond_entropy-2": 3.218849181038583,
        "distinct-3": 0.9372937293729373,
        "vocab_size-3": 10224,
        "unique-3": 9824,
        "entropy-3": 13.248168017632777,
        "cond_entropy-3": 0.7005893246922402,
        "total_length-nopunct": 11150,
        "mean_pred_length-nopunct": 22.3,
        "std_pred_length-nopunct": 5.716467440648988,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 57,
        "distinct-1-nopunct": 0.2813452914798206,
        "vocab_size-1-nopunct": 3137,
        "unique-1-nopunct": 2020,
        "entropy-1-nopunct": 9.292230463058567,
        "distinct-2-nopunct": 0.7452582159624414,
        "vocab_size-2-nopunct": 7937,
        "unique-2-nopunct": 6990,
        "entropy-2-nopunct": 12.47669965989674,
        "cond_entropy-2-nopunct": 3.285657541854542,
        "distinct-3-nopunct": 0.9429556650246306,
        "vocab_size-3-nopunct": 9571,
        "unique-3-nopunct": 9226,
        "entropy-3-nopunct": 13.161745170571365,
        "cond_entropy-3-nopunct": 0.6986965175626042,
        "msttr-100": 0.7395,
        "msttr-100_nopunct": 0.75748,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_02.json",
        "local_recall": {
            "1": 0.285162440570523
        },
        "rouge1": {
            "precision": 0.30121,
            "recall": 0.30915,
            "fmeasure": 0.29849
        },
        "rouge2": {
            "precision": 0.08142,
            "recall": 0.08353,
            "fmeasure": 0.08041
        },
        "rougeL": {
            "precision": 0.22217,
            "recall": 0.22797,
            "fmeasure": 0.22004
        },
        "rougeLsum": {
            "precision": 0.22217,
            "recall": 0.22797,
            "fmeasure": 0.22004
        },
        "nist": 2.503337541407995,
        "bleu": 4.69207,
        "nubia": {
            "semantic_relation": 2.12722,
            "contradiction": 30.66802,
            "irrelevancy": 63.68587,
            "logical_agreement": 5.6461,
            "grammar_ref": 3.74155,
            "grammar_hyp": 4.39717,
            "nubia_score": 0.22289
        },
        "bertscore": {
            "precision": 0.79688,
            "recall": 0.79768,
            "f1": 0.797
        },
        "meteor": 0.1271945464424019,
        "bleurt": -0.65083
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "mT5_base/totto_test",
        "N": 17,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07894736842105263,
            "2": 0.40625,
            "3": 0.7719298245614035
        },
        "rouge1": {
            "precision": 0.6791,
            "recall": 0.6309,
            "fmeasure": 0.63793
        },
        "rouge2": {
            "precision": 0.44083,
            "recall": 0.39978,
            "fmeasure": 0.41205
        },
        "rougeL": {
            "precision": 0.58724,
            "recall": 0.54748,
            "fmeasure": 0.55257
        },
        "rougeLsum": {
            "precision": 0.58724,
            "recall": 0.54748,
            "fmeasure": 0.55257
        },
        "nist": 5.625646825416738,
        "bleu": 48.63111,
        "nubia": {
            "semantic_relation": 3.98059,
            "contradiction": 8.13218,
            "irrelevancy": 16.6605,
            "logical_agreement": 75.20733,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.31426,
            "nubia_score": 0.66269
        },
        "bertscore": {
            "precision": 0.90684,
            "recall": 0.89179,
            "f1": 0.89813
        },
        "meteor": 0.3691324015237983,
        "bleurt": 0.17842
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.75,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.78431,
            "recall": 0.56667,
            "fmeasure": 0.65637
        },
        "rouge2": {
            "precision": 0.60417,
            "recall": 0.42836,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.45098,
            "recall": 0.33,
            "fmeasure": 0.38009
        },
        "rougeLsum": {
            "precision": 0.45098,
            "recall": 0.33,
            "fmeasure": 0.38009
        },
        "nist": 4.28711670621203,
        "bleu": 52.08534,
        "nubia": {
            "semantic_relation": 2.951,
            "contradiction": 0.97029,
            "irrelevancy": 66.19719,
            "logical_agreement": 32.83253,
            "grammar_ref": 4.19943,
            "grammar_hyp": 3.90675,
            "nubia_score": 0.39827
        },
        "bertscore": {
            "precision": 0.93302,
            "recall": 0.87344,
            "f1": 0.90225
        },
        "meteor": 0.36006280941729085,
        "bleurt": -0.49801
    },
    "xsum_challenge_test_bfp_05": {
        "predictions_file": "mT5_base/xsum_challenge_test_bfp_05",
        "N": 500,
        "total_length": 12027,
        "mean_pred_length": 24.054,
        "std_pred_length": 5.244719630256703,
        "median_pred_length": 24.0,
        "min_pred_length": 12,
        "max_pred_length": 47,
        "distinct-1": 0.2755466866217677,
        "vocab_size-1": 3314,
        "unique-1": 2153,
        "entropy-1": 9.22185595816838,
        "distinct-2": 0.7485902663312224,
        "vocab_size-2": 8629,
        "unique-2": 7591,
        "entropy-2": 12.607740503456462,
        "cond_entropy-2": 3.187790586170126,
        "distinct-3": 0.9381518091956108,
        "vocab_size-3": 10345,
        "unique-3": 9964,
        "entropy-3": 13.262898663323956,
        "cond_entropy-3": 0.6611579561851827,
        "total_length-nopunct": 11251,
        "mean_pred_length-nopunct": 22.502,
        "std_pred_length-nopunct": 5.01936211086628,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.29357390454181853,
        "vocab_size-1-nopunct": 3303,
        "unique-1-nopunct": 2152,
        "entropy-1-nopunct": 9.3853441314265,
        "distinct-2-nopunct": 0.7557436517533253,
        "vocab_size-2-nopunct": 8125,
        "unique-2-nopunct": 7190,
        "entropy-2-nopunct": 12.527011781897352,
        "cond_entropy-2-nopunct": 3.246388768624585,
        "distinct-3-nopunct": 0.9445907716320359,
        "vocab_size-3-nopunct": 9683,
        "unique-3-nopunct": 9360,
        "entropy-3-nopunct": 13.178187556752302,
        "cond_entropy-3-nopunct": 0.6676832869929047,
        "msttr-100": 0.74483,
        "msttr-100_nopunct": 0.76527,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_05.json",
        "local_recall": {
            "1": 0.2730983671843887
        },
        "rouge1": {
            "precision": 0.2846,
            "recall": 0.29605,
            "fmeasure": 0.284
        },
        "rouge2": {
            "precision": 0.0741,
            "recall": 0.07682,
            "fmeasure": 0.07352
        },
        "rougeL": {
            "precision": 0.21431,
            "recall": 0.22281,
            "fmeasure": 0.21366
        },
        "rougeLsum": {
            "precision": 0.21431,
            "recall": 0.22281,
            "fmeasure": 0.21366
        },
        "nist": 2.4150692764656685,
        "bleu": 4.43403,
        "nubia": {
            "semantic_relation": 1.93543,
            "contradiction": 37.83554,
            "irrelevancy": 57.03934,
            "logical_agreement": 5.12512,
            "grammar_ref": 3.79385,
            "grammar_hyp": 4.62269,
            "nubia_score": 0.19295
        },
        "bertscore": {
            "precision": 0.79099,
            "recall": 0.79326,
            "f1": 0.79189
        },
        "meteor": 0.12409225325150398,
        "bleurt": -0.74066
    },
    "xsum_challenge_test_nopunc": {
        "predictions_file": "mT5_base/xsum_challenge_test_nopunc",
        "N": 500,
        "total_length": 11847,
        "mean_pred_length": 23.694,
        "std_pred_length": 5.282836737965693,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.2636110407698151,
        "vocab_size-1": 3123,
        "unique-1": 1948,
        "entropy-1": 9.156206848385798,
        "distinct-2": 0.7387855820921829,
        "vocab_size-2": 8383,
        "unique-2": 7309,
        "entropy-2": 12.561395022582367,
        "cond_entropy-2": 3.2046005907168733,
        "distinct-3": 0.9362035585876279,
        "vocab_size-3": 10155,
        "unique-3": 9751,
        "entropy-3": 13.239532900425065,
        "cond_entropy-3": 0.683455615247303,
        "total_length-nopunct": 11064,
        "mean_pred_length-nopunct": 22.128,
        "std_pred_length-nopunct": 5.0071564784815745,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.2813629790310918,
        "vocab_size-1-nopunct": 3113,
        "unique-1-nopunct": 1947,
        "entropy-1-nopunct": 9.32235483129207,
        "distinct-2-nopunct": 0.7464028776978417,
        "vocab_size-2-nopunct": 7885,
        "unique-2-nopunct": 6909,
        "entropy-2-nopunct": 12.481986535318944,
        "cond_entropy-2-nopunct": 3.2633003228861623,
        "distinct-3-nopunct": 0.9427662957074722,
        "vocab_size-3-nopunct": 9488,
        "unique-3-nopunct": 9137,
        "entropy-3-nopunct": 13.153365885454495,
        "cond_entropy-3-nopunct": 0.6841883614203268,
        "msttr-100": 0.73898,
        "msttr-100_nopunct": 0.758,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_nopunc.json",
        "local_recall": {
            "1": 0.31257533145841704
        },
        "rouge1": {
            "precision": 0.3211,
            "recall": 0.3346,
            "fmeasure": 0.32037
        },
        "rouge2": {
            "precision": 0.09817,
            "recall": 0.10132,
            "fmeasure": 0.09733
        },
        "rougeL": {
            "precision": 0.23829,
            "recall": 0.24814,
            "fmeasure": 0.23752
        },
        "rougeLsum": {
            "precision": 0.23829,
            "recall": 0.24814,
            "fmeasure": 0.23752
        },
        "nist": 2.8640178382927037,
        "bleu": 6.13389,
        "nubia": {
            "semantic_relation": 2.32488,
            "contradiction": 27.579,
            "irrelevancy": 66.88933,
            "logical_agreement": 5.53167,
            "grammar_ref": 3.78318,
            "grammar_hyp": 4.1164,
            "nubia_score": 0.27982
        },
        "bertscore": {
            "precision": 0.80798,
            "recall": 0.8052,
            "f1": 0.80629
        },
        "meteor": 0.14397967847664458,
        "bleurt": -0.51958
    },
    "xsum_challenge_test_covid": {
        "predictions_file": "mT5_base/xsum_challenge_test_covid",
        "N": 401,
        "total_length": 10408,
        "mean_pred_length": 25.955112219451372,
        "std_pred_length": 6.292772250240098,
        "median_pred_length": 25.0,
        "min_pred_length": 11,
        "max_pred_length": 65,
        "distinct-1": 0.2023443504996157,
        "vocab_size-1": 2106,
        "unique-1": 1235,
        "entropy-1": 8.595648811531396,
        "distinct-2": 0.6450484660737483,
        "vocab_size-2": 6455,
        "unique-2": 5369,
        "entropy-2": 12.00029217250819,
        "cond_entropy-2": 3.253794896374076,
        "distinct-3": 0.8767437018530085,
        "vocab_size-3": 8422,
        "unique-3": 7840,
        "entropy-3": 12.8823387024684,
        "cond_entropy-3": 0.8860715279506873,
        "total_length-nopunct": 9710,
        "mean_pred_length-nopunct": 24.214463840399002,
        "std_pred_length-nopunct": 6.080416237418583,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.21585993820803295,
        "vocab_size-1-nopunct": 2096,
        "unique-1-nopunct": 1234,
        "entropy-1-nopunct": 8.716851776927601,
        "distinct-2-nopunct": 0.6583951015146632,
        "vocab_size-2-nopunct": 6129,
        "unique-2-nopunct": 5158,
        "entropy-2-nopunct": 11.932979901993916,
        "cond_entropy-2-nopunct": 3.2909757677513363,
        "distinct-3-nopunct": 0.888414907947912,
        "vocab_size-3-nopunct": 7914,
        "unique-3-nopunct": 7417,
        "entropy-3-nopunct": 12.809393094163411,
        "cond_entropy-3-nopunct": 0.8767607588843446,
        "msttr-100": 0.72913,
        "msttr-100_nopunct": 0.74619,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_covid.json",
        "local_recall": {
            "1": 0.25540605478135514
        },
        "rouge1": {
            "precision": 0.25636,
            "recall": 0.27575,
            "fmeasure": 0.25769
        },
        "rouge2": {
            "precision": 0.06121,
            "recall": 0.066,
            "fmeasure": 0.0617
        },
        "rougeL": {
            "precision": 0.18868,
            "recall": 0.20496,
            "fmeasure": 0.19017
        },
        "rougeLsum": {
            "precision": 0.18868,
            "recall": 0.20496,
            "fmeasure": 0.19017
        },
        "nist": 2.0322359817412754,
        "bleu": 3.87748,
        "nubia": {
            "semantic_relation": 1.78435,
            "contradiction": 29.26895,
            "irrelevancy": 65.69931,
            "logical_agreement": 5.03174,
            "grammar_ref": 4.04957,
            "grammar_hyp": 4.33647,
            "nubia_score": 0.18856
        },
        "bertscore": {
            "precision": 0.77788,
            "recall": 0.77743,
            "f1": 0.77739
        },
        "meteor": 0.11433492510330255,
        "bleurt": -0.6933
    },
    "e2e_nlg_val": {
        "predictions_file": "mT5_base/e2e_nlg_val",
        "N": 4299,
        "total_length": 103485,
        "mean_pred_length": 24.07187718073971,
        "std_pred_length": 7.157367611822331,
        "median_pred_length": 25.0,
        "min_pred_length": 5,
        "max_pred_length": 41,
        "distinct-1": 0.0012465574720974054,
        "vocab_size-1": 129,
        "unique-1": 5,
        "entropy-1": 5.632572407086899,
        "distinct-2": 0.003911842397112496,
        "vocab_size-2": 388,
        "unique-2": 56,
        "entropy-2": 7.005787415223847,
        "cond_entropy-2": 1.2827405675116899,
        "distinct-3": 0.007904138606974613,
        "vocab_size-3": 750,
        "unique-3": 138,
        "entropy-3": 7.845271525255817,
        "cond_entropy-3": 0.8650848281458162,
        "total_length-nopunct": 94103,
        "mean_pred_length-nopunct": 21.889509188183297,
        "std_pred_length-nopunct": 6.60444063966954,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.0013495850291701647,
        "vocab_size-1-nopunct": 127,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 5.681052440329002,
        "distinct-2-nopunct": 0.0042537080753641265,
        "vocab_size-2-nopunct": 382,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 6.9703039977809755,
        "cond_entropy-2-nopunct": 1.327161137825095,
        "distinct-3-nopunct": 0.008911759546225367,
        "vocab_size-3-nopunct": 762,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.867232432194427,
        "cond_entropy-3-nopunct": 0.8893935872244841,
        "msttr-100": 0.26679,
        "msttr-100_nopunct": 0.2584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_val.json",
        "local_recall": {
            "1": 0.7250025904051394
        },
        "rouge1": {
            "precision": 0.75739,
            "recall": 0.73958,
            "fmeasure": 0.73884
        },
        "rouge2": {
            "precision": 0.47341,
            "recall": 0.46222,
            "fmeasure": 0.46172
        },
        "rougeL": {
            "precision": 0.55892,
            "recall": 0.54473,
            "fmeasure": 0.54461
        },
        "rougeLsum": {
            "precision": 0.55892,
            "recall": 0.54473,
            "fmeasure": 0.54461
        },
        "nist": 5.386015450672416,
        "bleu": 34.65702,
        "nubia": {
            "semantic_relation": 4.47021,
            "contradiction": 1.96981,
            "irrelevancy": 10.80689,
            "logical_agreement": 87.2233,
            "grammar_ref": 4.85661,
            "grammar_hyp": 4.33754,
            "nubia_score": 0.85234
        },
        "bertscore": {
            "precision": 0.92203,
            "recall": 0.91123,
            "f1": 0.91634
        },
        "meteor": 0.3806515120013559,
        "bleurt": 0.3213
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_base/e2e_nlg_test",
        "N": 737,
        "total_length": 14064,
        "mean_pred_length": 19.082767978290367,
        "std_pred_length": 3.6565495137406927,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 31,
        "distinct-1": 0.00739476678043231,
        "vocab_size-1": 104,
        "unique-1": 1,
        "entropy-1": 5.575835917585019,
        "distinct-2": 0.020259623321077513,
        "vocab_size-2": 270,
        "unique-2": 16,
        "entropy-2": 6.886518200291166,
        "cond_entropy-2": 1.195125036255361,
        "distinct-3": 0.03907863383637808,
        "vocab_size-3": 492,
        "unique-3": 60,
        "entropy-3": 7.617696880255693,
        "cond_entropy-3": 0.7457664809136596,
        "total_length-nopunct": 12776,
        "mean_pred_length-nopunct": 17.335142469470828,
        "std_pred_length-nopunct": 3.3680234310060215,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.007983719474013776,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 1,
        "entropy-1-nopunct": 5.637335429355388,
        "distinct-2-nopunct": 0.021845668244870838,
        "vocab_size-2-nopunct": 263,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 6.841064859645786,
        "cond_entropy-2-nopunct": 1.2404455676478572,
        "distinct-3-nopunct": 0.04344363829410724,
        "vocab_size-3-nopunct": 491,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 7.623716869651146,
        "cond_entropy-3-nopunct": 0.7713235995129185,
        "msttr-100": 0.24514,
        "msttr-100_nopunct": 0.24291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6932171276998863
        },
        "rouge1": {
            "precision": 0.78464,
            "recall": 0.70034,
            "fmeasure": 0.72802
        },
        "rouge2": {
            "precision": 0.503,
            "recall": 0.44926,
            "fmeasure": 0.46669
        },
        "rougeL": {
            "precision": 0.61136,
            "recall": 0.54729,
            "fmeasure": 0.56839
        },
        "rougeLsum": {
            "precision": 0.61136,
            "recall": 0.54729,
            "fmeasure": 0.56839
        },
        "nist": 5.208341039149947,
        "bleu": 33.81144,
        "nubia": {
            "semantic_relation": 4.35965,
            "contradiction": 1.73728,
            "irrelevancy": 12.90076,
            "logical_agreement": 85.36196,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.65808,
            "nubia_score": 0.79823
        },
        "bertscore": {
            "precision": 0.93074,
            "recall": 0.90732,
            "f1": 0.91849
        },
        "meteor": 0.36544012010875127,
        "bleurt": 0.26444
    },
    "e2e_nlg_test": {
        "predictions_file": "mT5_base/e2e_nlg_test",
        "N": 4693,
        "total_length": 112350,
        "mean_pred_length": 23.939910505007457,
        "std_pred_length": 6.824690618452274,
        "median_pred_length": 24.0,
        "min_pred_length": 7,
        "max_pred_length": 45,
        "distinct-1": 0.0011838006230529595,
        "vocab_size-1": 133,
        "unique-1": 4,
        "entropy-1": 5.734934397487359,
        "distinct-2": 0.004012744178269876,
        "vocab_size-2": 432,
        "unique-2": 37,
        "entropy-2": 7.216524195999863,
        "cond_entropy-2": 1.3879340753539766,
        "distinct-3": 0.009177965114020435,
        "vocab_size-3": 945,
        "unique-3": 104,
        "entropy-3": 8.116525416235307,
        "cond_entropy-3": 0.9133072395127505,
        "total_length-nopunct": 102710,
        "mean_pred_length-nopunct": 21.885787342851057,
        "std_pred_length-nopunct": 6.364099681760142,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.0012754356927270956,
        "vocab_size-1-nopunct": 131,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 5.794106451979912,
        "distinct-2-nopunct": 0.004356387157329851,
        "vocab_size-2-nopunct": 427,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 7.215388773105096,
        "cond_entropy-2-nopunct": 1.461101935730916,
        "distinct-3-nopunct": 0.010254596888260255,
        "vocab_size-3-nopunct": 957,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 8.17121015108136,
        "cond_entropy-3-nopunct": 0.951572908016033,
        "msttr-100": 0.27541,
        "msttr-100_nopunct": 0.26835,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7128539485921206
        },
        "rouge1": {
            "precision": 0.7925,
            "recall": 0.7185,
            "fmeasure": 0.74312
        },
        "rouge2": {
            "precision": 0.4897,
            "recall": 0.44325,
            "fmeasure": 0.45846
        },
        "rougeL": {
            "precision": 0.56781,
            "recall": 0.51426,
            "fmeasure": 0.53194
        },
        "rougeLsum": {
            "precision": 0.56781,
            "recall": 0.51426,
            "fmeasure": 0.53194
        },
        "nist": 5.491361624743675,
        "bleu": 32.91521,
        "nubia": {
            "semantic_relation": 4.43809,
            "contradiction": 1.87624,
            "irrelevancy": 11.52984,
            "logical_agreement": 86.59392,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.44909,
            "nubia_score": 0.83045
        },
        "bertscore": {
            "precision": 0.92759,
            "recall": 0.90779,
            "f1": 0.91729
        },
        "meteor": 0.3692678619777901,
        "bleurt": 0.27263
    },
    "e2e_nlg_challenge_test_scramble": {
        "predictions_file": "mT5_base/e2e_nlg_challenge_test_scramble",
        "N": 500,
        "total_length": 12332,
        "mean_pred_length": 24.664,
        "std_pred_length": 6.940252444976336,
        "median_pred_length": 24.0,
        "min_pred_length": 9,
        "max_pred_length": 50,
        "distinct-1": 0.029273434965942265,
        "vocab_size-1": 361,
        "unique-1": 131,
        "entropy-1": 6.30302455094378,
        "distinct-2": 0.15196078431372548,
        "vocab_size-2": 1798,
        "unique-2": 983,
        "entropy-2": 8.875469147999649,
        "cond_entropy-2": 2.4752071052859455,
        "distinct-3": 0.33348040945993646,
        "vocab_size-3": 3779,
        "unique-3": 2574,
        "entropy-3": 10.490483712012134,
        "cond_entropy-3": 1.6115005935827886,
        "total_length-nopunct": 11132,
        "mean_pred_length-nopunct": 22.264,
        "std_pred_length-nopunct": 6.255741682646431,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.0319798778296802,
        "vocab_size-1-nopunct": 356,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.3795978570450185,
        "distinct-2-nopunct": 0.16995861550037622,
        "vocab_size-2-nopunct": 1807,
        "unique-2-nopunct": 1056,
        "entropy-2-nopunct": 8.860185574229279,
        "cond_entropy-2-nopunct": 2.5125117078895847,
        "distinct-3-nopunct": 0.35728385313857086,
        "vocab_size-3-nopunct": 3620,
        "unique-3-nopunct": 2501,
        "entropy-3-nopunct": 10.493517425745235,
        "cond_entropy-3-nopunct": 1.6090567275422822,
        "msttr-100": 0.53902,
        "msttr-100_nopunct": 0.55225,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.645215288756626
        },
        "rouge1": {
            "precision": 0.7063,
            "recall": 0.6525,
            "fmeasure": 0.66757
        },
        "rouge2": {
            "precision": 0.38414,
            "recall": 0.35387,
            "fmeasure": 0.36215
        },
        "rougeL": {
            "precision": 0.47409,
            "recall": 0.4378,
            "fmeasure": 0.44786
        },
        "rougeLsum": {
            "precision": 0.47409,
            "recall": 0.4378,
            "fmeasure": 0.44786
        },
        "nist": 4.679372791093412,
        "bleu": 23.95596,
        "nubia": {
            "semantic_relation": 4.07978,
            "contradiction": 6.66375,
            "irrelevancy": 27.10614,
            "logical_agreement": 66.23011,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.8072,
            "nubia_score": 0.68315
        },
        "bertscore": {
            "precision": 0.9,
            "recall": 0.89218,
            "f1": 0.89576
        },
        "meteor": 0.32909498616544713,
        "bleurt": 0.01416
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.53061,
            "recall": 0.67857,
            "fmeasure": 0.59432
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.32281,
            "fmeasure": 0.28117
        },
        "rougeL": {
            "precision": 0.33673,
            "recall": 0.43095,
            "fmeasure": 0.37729
        },
        "rougeLsum": {
            "precision": 0.33673,
            "recall": 0.43095,
            "fmeasure": 0.37729
        },
        "nist": 3.3366826976918174,
        "bleu": 21.39038,
        "nubia": {
            "semantic_relation": 3.3602,
            "contradiction": 90.10699,
            "irrelevancy": 7.36867,
            "logical_agreement": 2.52434,
            "grammar_ref": 3.72412,
            "grammar_hyp": 2.98587,
            "nubia_score": 0.59684
        },
        "bertscore": {
            "precision": 0.89553,
            "recall": 0.87885,
            "f1": 0.88571
        },
        "meteor": 0.29357289116453184,
        "bleurt": 0.03818
    },
    "web_nlg_en_val": {
        "predictions_file": "mT5_base/web_nlg_en_val",
        "N": 1667,
        "total_length": 35943,
        "mean_pred_length": 21.56148770245951,
        "std_pred_length": 10.959226595740386,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 68,
        "distinct-1": 0.09490025874300977,
        "vocab_size-1": 3411,
        "unique-1": 1059,
        "entropy-1": 8.668275454175404,
        "distinct-2": 0.2852141440074688,
        "vocab_size-2": 9776,
        "unique-2": 4697,
        "entropy-2": 11.983669974148317,
        "cond_entropy-2": 3.0809003415339755,
        "distinct-3": 0.45588641172682387,
        "vocab_size-3": 14866,
        "unique-3": 8991,
        "entropy-3": 13.125057027226392,
        "cond_entropy-3": 1.1931608355527572,
        "total_length-nopunct": 31761,
        "mean_pred_length-nopunct": 19.052789442111578,
        "std_pred_length-nopunct": 9.834727670036814,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.10708101130317056,
        "vocab_size-1-nopunct": 3401,
        "unique-1-nopunct": 1057,
        "entropy-1-nopunct": 9.05767508998048,
        "distinct-2-nopunct": 0.3000598125872267,
        "vocab_size-2-nopunct": 9030,
        "unique-2-nopunct": 4531,
        "entropy-2-nopunct": 11.900742061164415,
        "cond_entropy-2-nopunct": 2.987781558120293,
        "distinct-3-nopunct": 0.47268441974179476,
        "vocab_size-3-nopunct": 13437,
        "unique-3-nopunct": 8398,
        "entropy-3-nopunct": 12.995387110611684,
        "cond_entropy-3-nopunct": 1.1468640621913302,
        "msttr-100": 0.5385,
        "msttr-100_nopunct": 0.5664,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_val.json",
        "local_recall": {
            "1": 0.31335231530046453,
            "2": 0.7450191570881226,
            "3": 0.9484551072337332,
            "4": 0.9574468085106383,
            "5": 1.0,
            "6": 0.75,
            "7": 1.0,
            "8": 1.0
        },
        "rouge1": {
            "precision": 0.84719,
            "recall": 0.82672,
            "fmeasure": 0.83194
        },
        "rouge2": {
            "precision": 0.64645,
            "recall": 0.63102,
            "fmeasure": 0.63481
        },
        "rougeL": {
            "precision": 0.71844,
            "recall": 0.70327,
            "fmeasure": 0.7065
        },
        "rougeLsum": {
            "precision": 0.71844,
            "recall": 0.70327,
            "fmeasure": 0.7065
        },
        "nist": 11.79096480532081,
        "bleu": 66.23693,
        "nubia": {
            "semantic_relation": 4.75896,
            "contradiction": 2.88254,
            "irrelevancy": 3.35424,
            "logical_agreement": 93.76322,
            "grammar_ref": 4.59465,
            "grammar_hyp": 4.4953,
            "nubia_score": 0.90283
        },
        "bertscore": {
            "precision": 0.95892,
            "recall": 0.95486,
            "f1": 0.95613
        },
        "meteor": 0.46631201760678426,
        "bleurt": 0.46082
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.23076923076923078,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.66791,
            "recall": 0.68871,
            "fmeasure": 0.67269
        },
        "rouge2": {
            "precision": 0.40201,
            "recall": 0.39919,
            "fmeasure": 0.39664
        },
        "rougeL": {
            "precision": 0.52214,
            "recall": 0.5403,
            "fmeasure": 0.52674
        },
        "rougeLsum": {
            "precision": 0.52214,
            "recall": 0.5403,
            "fmeasure": 0.52674
        },
        "nist": 3.961436052794682,
        "bleu": 25.10948,
        "nubia": {
            "semantic_relation": 4.04567,
            "contradiction": 1.04736,
            "irrelevancy": 38.43415,
            "logical_agreement": 60.51849,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.20924,
            "nubia_score": 0.71013
        },
        "bertscore": {
            "precision": 0.89721,
            "recall": 0.89365,
            "f1": 0.89166
        },
        "meteor": 0.30257073516116606,
        "bleurt": 0.18241
    },
    "web_nlg_en_test": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 1779,
        "total_length": 44833,
        "mean_pred_length": 25.20123664980326,
        "std_pred_length": 12.833914573597145,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 96,
        "distinct-1": 0.041531907300426024,
        "vocab_size-1": 1862,
        "unique-1": 494,
        "entropy-1": 7.88253243026545,
        "distinct-2": 0.15136804942630186,
        "vocab_size-2": 6517,
        "unique-2": 2699,
        "entropy-2": 11.115363363976059,
        "cond_entropy-2": 3.0726439349967545,
        "distinct-3": 0.28533010296789824,
        "vocab_size-3": 11777,
        "unique-3": 6406,
        "entropy-3": 12.42379184250358,
        "cond_entropy-3": 1.3761840346586536,
        "total_length-nopunct": 39684,
        "mean_pred_length-nopunct": 22.30691399662732,
        "std_pred_length-nopunct": 11.543218030279547,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.04669388166515472,
        "vocab_size-1-nopunct": 1853,
        "unique-1-nopunct": 494,
        "entropy-1-nopunct": 8.157205503729157,
        "distinct-2-nopunct": 0.1633557578155916,
        "vocab_size-2-nopunct": 6192,
        "unique-2-nopunct": 2724,
        "entropy-2-nopunct": 11.037370095902718,
        "cond_entropy-2-nopunct": 3.0259449368032,
        "distinct-3-nopunct": 0.30302275369539944,
        "vocab_size-3-nopunct": 10947,
        "unique-3-nopunct": 6187,
        "entropy-3-nopunct": 12.3164814966182,
        "cond_entropy-3-nopunct": 1.3408570570911018,
        "msttr-100": 0.62027,
        "msttr-100_nopunct": 0.66018,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2264616443857938,
            "2": 0.5554044867437118,
            "3": 0.8071282051282052,
            "4": 0.8727272727272727,
            "5": 0.6551724137931034
        },
        "rouge1": {
            "precision": 0.69916,
            "recall": 0.70593,
            "fmeasure": 0.69384
        },
        "rouge2": {
            "precision": 0.44274,
            "recall": 0.446,
            "fmeasure": 0.43842
        },
        "rougeL": {
            "precision": 0.55537,
            "recall": 0.56231,
            "fmeasure": 0.55148
        },
        "rougeLsum": {
            "precision": 0.55537,
            "recall": 0.56231,
            "fmeasure": 0.55148
        },
        "nist": 8.153709321358281,
        "bleu": 42.16549,
        "nubia": {
            "semantic_relation": 4.10659,
            "contradiction": 16.3974,
            "irrelevancy": 12.04502,
            "logical_agreement": 71.55758,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.55881,
            "nubia_score": 0.69516
        },
        "bertscore": {
            "precision": 0.90217,
            "recall": 0.9035,
            "f1": 0.90145
        },
        "meteor": 0.3558045891965796,
        "bleurt": 0.03375
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 32,
        "total_length": 1222,
        "mean_pred_length": 38.1875,
        "std_pred_length": 6.825675332888315,
        "median_pred_length": 38.5,
        "min_pred_length": 24,
        "max_pred_length": 49,
        "distinct-1": 0.2937806873977087,
        "vocab_size-1": 359,
        "unique-1": 178,
        "entropy-1": 7.2833915824007205,
        "distinct-2": 0.5218487394957984,
        "vocab_size-2": 621,
        "unique-2": 363,
        "entropy-2": 8.87522532136606,
        "cond_entropy-2": 1.4984876815957775,
        "distinct-3": 0.6442141623488774,
        "vocab_size-3": 746,
        "unique-3": 507,
        "entropy-3": 9.28757092506077,
        "cond_entropy-3": 0.409689990550835,
        "total_length-nopunct": 1046,
        "mean_pred_length-nopunct": 32.6875,
        "std_pred_length-nopunct": 6.191917614923506,
        "median_pred_length-nopunct": 32.5,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.33747609942638623,
        "vocab_size-1-nopunct": 353,
        "unique-1-nopunct": 175,
        "entropy-1-nopunct": 7.572883765929628,
        "distinct-2-nopunct": 0.5542406311637081,
        "vocab_size-2-nopunct": 562,
        "unique-2-nopunct": 343,
        "entropy-2-nopunct": 8.793863664913346,
        "cond_entropy-2-nopunct": 1.2357387852217199,
        "distinct-3-nopunct": 0.659877800407332,
        "vocab_size-3-nopunct": 648,
        "unique-3-nopunct": 453,
        "entropy-3-nopunct": 9.095019003022154,
        "cond_entropy-3-nopunct": 0.3101367520714916,
        "msttr-100": 0.6775,
        "msttr-100_nopunct": 0.728,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.31896551724137934,
            "2": 0.7203579418344519,
            "3": 0.9169329073482428
        },
        "rouge1": {
            "precision": 0.80897,
            "recall": 0.84382,
            "fmeasure": 0.81719
        },
        "rouge2": {
            "precision": 0.55903,
            "recall": 0.60781,
            "fmeasure": 0.5715
        },
        "rougeL": {
            "precision": 0.76953,
            "recall": 0.80285,
            "fmeasure": 0.77706
        },
        "rougeLsum": {
            "precision": 0.76953,
            "recall": 0.80285,
            "fmeasure": 0.77706
        },
        "nist": 7.992596158196351,
        "bleu": 58.42962,
        "nubia": {
            "semantic_relation": 3.79611,
            "contradiction": 19.72676,
            "irrelevancy": 24.44206,
            "logical_agreement": 55.83119,
            "grammar_ref": 2.45871,
            "grammar_hyp": 2.46578,
            "nubia_score": 0.86131
        },
        "bertscore": {
            "precision": 0.95843,
            "recall": 0.95386,
            "f1": 0.95596
        },
        "meteor": 0.6954091175200672,
        "bleurt": 0.23879
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 254,
        "total_length": 2194,
        "mean_pred_length": 8.637795275590552,
        "std_pred_length": 2.7570076536314523,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.4179580674567001,
        "vocab_size-1": 917,
        "unique-1": 618,
        "entropy-1": 8.368471675447697,
        "distinct-2": 0.7603092783505154,
        "vocab_size-2": 1475,
        "unique-2": 1212,
        "entropy-2": 10.286577555924485,
        "cond_entropy-2": 1.229712389671546,
        "distinct-3": 0.8813760379596679,
        "vocab_size-3": 1486,
        "unique-3": 1332,
        "entropy-3": 10.456511665555558,
        "cond_entropy-3": 0.16916999094692178,
        "total_length-nopunct": 1755,
        "mean_pred_length-nopunct": 6.909448818897638,
        "std_pred_length-nopunct": 2.42762750164653,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5196581196581197,
        "vocab_size-1-nopunct": 912,
        "unique-1-nopunct": 618,
        "entropy-1-nopunct": 9.11105244246167,
        "distinct-2-nopunct": 0.7848101265822784,
        "vocab_size-2-nopunct": 1178,
        "unique-2-nopunct": 991,
        "entropy-2-nopunct": 9.98428738204425,
        "cond_entropy-2-nopunct": 0.9999834892975175,
        "distinct-3-nopunct": 0.8941459502806736,
        "vocab_size-3-nopunct": 1115,
        "unique-3-nopunct": 1017,
        "entropy-3-nopunct": 10.047307275074356,
        "cond_entropy-3-nopunct": 0.1295422268795131,
        "msttr-100": 0.76095,
        "msttr-100_nopunct": 0.88235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.3858695652173913,
            "2": 0.7364771151178918,
            "3": 0.8532423208191127,
            "4": 0.9142857142857143,
            "5": 0.9090909090909091,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.3407,
            "recall": 0.33695,
            "fmeasure": 0.33674
        },
        "rouge2": {
            "precision": 0.19688,
            "recall": 0.18985,
            "fmeasure": 0.19168
        },
        "rougeL": {
            "precision": 0.34005,
            "recall": 0.33646,
            "fmeasure": 0.33618
        },
        "rougeLsum": {
            "precision": 0.34005,
            "recall": 0.33646,
            "fmeasure": 0.33618
        },
        "nist": 8.690208473409514,
        "bleu": 63.3066,
        "nubia": {
            "semantic_relation": 4.23718,
            "contradiction": 20.34707,
            "irrelevancy": 18.97056,
            "logical_agreement": 60.68237,
            "grammar_ref": 2.90382,
            "grammar_hyp": 2.90932,
            "nubia_score": 0.85576
        },
        "bertscore": {
            "precision": 0.97038,
            "recall": 0.96856,
            "f1": 0.96901
        },
        "meteor": 0.7708778239544977,
        "bleurt": 0.41876
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 159,
        "total_length": 4888,
        "mean_pred_length": 30.742138364779873,
        "std_pred_length": 6.947434109828962,
        "median_pred_length": 30.0,
        "min_pred_length": 16,
        "max_pred_length": 67,
        "distinct-1": 0.2614566284779051,
        "vocab_size-1": 1278,
        "unique-1": 628,
        "entropy-1": 8.43585663741507,
        "distinct-2": 0.5415521251850286,
        "vocab_size-2": 2561,
        "unique-2": 1646,
        "entropy-2": 10.816151718941063,
        "cond_entropy-2": 2.223867079446516,
        "distinct-3": 0.6967177242888403,
        "vocab_size-3": 3184,
        "unique-3": 2365,
        "entropy-3": 11.398943120583922,
        "cond_entropy-3": 0.5960025041736219,
        "total_length-nopunct": 3993,
        "mean_pred_length-nopunct": 25.11320754716981,
        "std_pred_length-nopunct": 6.428103716073436,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.3183070373153018,
        "vocab_size-1-nopunct": 1271,
        "unique-1-nopunct": 626,
        "entropy-1-nopunct": 9.107782420653065,
        "distinct-2-nopunct": 0.5972874282733438,
        "vocab_size-2-nopunct": 2290,
        "unique-2-nopunct": 1542,
        "entropy-2-nopunct": 10.79035208030479,
        "cond_entropy-2-nopunct": 1.7229426579604143,
        "distinct-3-nopunct": 0.7387755102040816,
        "vocab_size-3-nopunct": 2715,
        "unique-3-nopunct": 2112,
        "entropy-3-nopunct": 11.203298662061233,
        "cond_entropy-3-nopunct": 0.42584573718660484,
        "msttr-100": 0.70604,
        "msttr-100_nopunct": 0.79872,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2664067576348278,
            "2": 0.6527331189710611,
            "3": 0.8726003490401396
        },
        "rouge1": {
            "precision": 0.51498,
            "recall": 0.51496,
            "fmeasure": 0.51263
        },
        "rouge2": {
            "precision": 0.29931,
            "recall": 0.29905,
            "fmeasure": 0.2955
        },
        "rougeL": {
            "precision": 0.47615,
            "recall": 0.47544,
            "fmeasure": 0.47309
        },
        "rougeLsum": {
            "precision": 0.47615,
            "recall": 0.47544,
            "fmeasure": 0.47309
        },
        "nist": 8.57603805594847,
        "bleu": 47.96292,
        "nubia": {
            "semantic_relation": 3.92818,
            "contradiction": 20.15504,
            "irrelevancy": 21.1332,
            "logical_agreement": 58.71176,
            "grammar_ref": 2.45758,
            "grammar_hyp": 2.43439,
            "nubia_score": 0.81898
        },
        "bertscore": {
            "precision": 0.95007,
            "recall": 0.94466,
            "f1": 0.9468
        },
        "meteor": 0.6139305202028893,
        "bleurt": 0.1083
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_base/web_nlg_ru_test",
        "N": 29,
        "total_length": 1209,
        "mean_pred_length": 41.689655172413794,
        "std_pred_length": 8.19210489677193,
        "median_pred_length": 40.0,
        "min_pred_length": 30,
        "max_pred_length": 59,
        "distinct-1": 0.2762613730355666,
        "vocab_size-1": 334,
        "unique-1": 155,
        "entropy-1": 7.124259481596155,
        "distinct-2": 0.4957627118644068,
        "vocab_size-2": 585,
        "unique-2": 335,
        "entropy-2": 8.739621317999587,
        "cond_entropy-2": 1.5319879277730992,
        "distinct-3": 0.6055603822762815,
        "vocab_size-3": 697,
        "unique-3": 449,
        "entropy-3": 9.16813280325731,
        "cond_entropy-3": 0.43597570773605504,
        "total_length-nopunct": 1021,
        "mean_pred_length-nopunct": 35.206896551724135,
        "std_pred_length-nopunct": 7.640090766498324,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.32125367286973555,
        "vocab_size-1-nopunct": 328,
        "unique-1-nopunct": 153,
        "entropy-1-nopunct": 7.428740756813523,
        "distinct-2-nopunct": 0.532258064516129,
        "vocab_size-2-nopunct": 528,
        "unique-2-nopunct": 316,
        "entropy-2-nopunct": 8.675588358498295,
        "cond_entropy-2-nopunct": 1.2723359325333352,
        "distinct-3-nopunct": 0.6344755970924195,
        "vocab_size-3-nopunct": 611,
        "unique-3-nopunct": 415,
        "entropy-3-nopunct": 8.997040049452565,
        "cond_entropy-3-nopunct": 0.32807189098038025,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.725,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.3409090909090909,
            "2": 0.6188235294117647,
            "3": 0.8885630498533724
        },
        "rouge1": {
            "precision": 0.88017,
            "recall": 0.84066,
            "fmeasure": 0.84303
        },
        "rouge2": {
            "precision": 0.66144,
            "recall": 0.65014,
            "fmeasure": 0.6346
        },
        "rougeL": {
            "precision": 0.83898,
            "recall": 0.8011,
            "fmeasure": 0.8018
        },
        "rougeLsum": {
            "precision": 0.83898,
            "recall": 0.8011,
            "fmeasure": 0.8018
        },
        "nist": 7.759395866218818,
        "bleu": 54.9625,
        "nubia": {
            "semantic_relation": 3.6678,
            "contradiction": 21.23261,
            "irrelevancy": 21.91292,
            "logical_agreement": 56.85447,
            "grammar_ref": 2.50557,
            "grammar_hyp": 2.49629,
            "nubia_score": 0.85812
        },
        "bertscore": {
            "precision": 0.95491,
            "recall": 0.94774,
            "f1": 0.95098
        },
        "meteor": 0.6703765568383064,
        "bleurt": 0.11232
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 256,
        "total_length": 7691,
        "mean_pred_length": 30.04296875,
        "std_pred_length": 8.22594203945806,
        "median_pred_length": 30.0,
        "min_pred_length": 13,
        "max_pred_length": 56,
        "distinct-1": 0.07385255493433884,
        "vocab_size-1": 568,
        "unique-1": 234,
        "entropy-1": 6.9681778766238835,
        "distinct-2": 0.2121049092131809,
        "vocab_size-2": 1577,
        "unique-2": 776,
        "entropy-2": 9.25623312377547,
        "cond_entropy-2": 2.2231460084110513,
        "distinct-3": 0.3680178297813066,
        "vocab_size-3": 2642,
        "unique-3": 1640,
        "entropy-3": 10.396876180856761,
        "cond_entropy-3": 1.1731416980423004,
        "total_length-nopunct": 7013,
        "mean_pred_length-nopunct": 27.39453125,
        "std_pred_length-nopunct": 7.358868040858828,
        "median_pred_length-nopunct": 26.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.0799942963068587,
        "vocab_size-1-nopunct": 561,
        "unique-1-nopunct": 234,
        "entropy-1-nopunct": 7.018299947386146,
        "distinct-2-nopunct": 0.22184401361550984,
        "vocab_size-2-nopunct": 1499,
        "unique-2-nopunct": 743,
        "entropy-2-nopunct": 9.219979137591965,
        "cond_entropy-2-nopunct": 2.2556113341435586,
        "distinct-3-nopunct": 0.3825565297646516,
        "vocab_size-3-nopunct": 2487,
        "unique-3-nopunct": 1557,
        "entropy-3-nopunct": 10.344592962481897,
        "cond_entropy-3-nopunct": 1.1743449722377555,
        "msttr-100": 0.615,
        "msttr-100_nopunct": 0.61771,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6228122218926134
        },
        "rouge1": {
            "precision": 0.69374,
            "recall": 0.63626,
            "fmeasure": 0.65053
        },
        "rouge2": {
            "precision": 0.45047,
            "recall": 0.41355,
            "fmeasure": 0.42206
        },
        "rougeL": {
            "precision": 0.5812,
            "recall": 0.53207,
            "fmeasure": 0.54435
        },
        "rougeLsum": {
            "precision": 0.5812,
            "recall": 0.53207,
            "fmeasure": 0.54435
        },
        "nist": 6.1644314914959235,
        "bleu": 33.96581,
        "nubia": {
            "semantic_relation": 3.95107,
            "contradiction": 4.60103,
            "irrelevancy": 27.31696,
            "logical_agreement": 68.08201,
            "grammar_ref": 4.19274,
            "grammar_hyp": 4.05936,
            "nubia_score": 0.65775
        },
        "bertscore": {
            "precision": 0.90035,
            "recall": 0.88509,
            "f1": 0.89226
        },
        "meteor": 0.33770758787336724,
        "bleurt": -0.07579
    },
    "e2e_nlg_challenge_test_scramble_parent": {
        "predictions_file": "mT5_base/e2e_nlg_test",
        "N": 500,
        "total_length": 11872,
        "mean_pred_length": 23.744,
        "std_pred_length": 6.939918155136989,
        "median_pred_length": 23.0,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.009855121293800539,
        "vocab_size-1": 117,
        "unique-1": 9,
        "entropy-1": 5.736463811874515,
        "distinct-2": 0.02998593035525853,
        "vocab_size-2": 341,
        "unique-2": 55,
        "entropy-2": 7.200907794334962,
        "cond_entropy-2": 1.3694852614489659,
        "distinct-3": 0.06015452538631347,
        "vocab_size-3": 654,
        "unique-3": 137,
        "entropy-3": 8.072709554619141,
        "cond_entropy-3": 0.8839965186873586,
        "total_length-nopunct": 10839,
        "mean_pred_length-nopunct": 21.678,
        "std_pred_length-nopunct": 6.4756710849146755,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.010609834855613986,
        "vocab_size-1-nopunct": 115,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 5.794449649591438,
        "distinct-2-nopunct": 0.03230486507399168,
        "vocab_size-2-nopunct": 334,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 7.197134446766105,
        "cond_entropy-2-nopunct": 1.44041212906697,
        "distinct-3-nopunct": 0.0667750787681675,
        "vocab_size-3-nopunct": 657,
        "unique-3-nopunct": 135,
        "entropy-3-nopunct": 8.12067361040591,
        "cond_entropy-3-nopunct": 0.917000988666229,
        "msttr-100": 0.47059,
        "msttr-100_nopunct": 0.48213,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.713568306519111
        },
        "rouge1": {
            "precision": 0.79734,
            "recall": 0.71506,
            "fmeasure": 0.74409
        },
        "rouge2": {
            "precision": 0.48589,
            "recall": 0.43462,
            "fmeasure": 0.45249
        },
        "rougeL": {
            "precision": 0.56814,
            "recall": 0.50801,
            "fmeasure": 0.52915
        },
        "rougeLsum": {
            "precision": 0.56814,
            "recall": 0.50801,
            "fmeasure": 0.52915
        },
        "nist": 5.443781565557182,
        "bleu": 32.26544,
        "nubia": {
            "semantic_relation": 4.43314,
            "contradiction": 2.06803,
            "irrelevancy": 11.06257,
            "logical_agreement": 86.8694,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.46222,
            "nubia_score": 0.82803
        },
        "bertscore": {
            "precision": 0.92777,
            "recall": 0.90671,
            "f1": 0.91685
        },
        "meteor": 0.3678071063555279,
        "bleurt": 0.26013
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_base/e2e_nlg_test",
        "N": 1187,
        "total_length": 25878,
        "mean_pred_length": 21.801179443976412,
        "std_pred_length": 3.885587647159185,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 36,
        "distinct-1": 0.003980214854316408,
        "vocab_size-1": 103,
        "unique-1": 2,
        "entropy-1": 5.47300060636181,
        "distinct-2": 0.012717184399173787,
        "vocab_size-2": 314,
        "unique-2": 37,
        "entropy-2": 6.74277053628817,
        "cond_entropy-2": 1.1757693006343681,
        "distinct-3": 0.025740299523485364,
        "vocab_size-3": 605,
        "unique-3": 90,
        "entropy-3": 7.501158011017096,
        "cond_entropy-3": 0.7627869017454038,
        "total_length-nopunct": 23598,
        "mean_pred_length-nopunct": 19.880370682392588,
        "std_pred_length-nopunct": 3.525214583190618,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.0042800237308246464,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 5.528324613491818,
        "distinct-2-nopunct": 0.013564767301771452,
        "vocab_size-2-nopunct": 304,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 6.736174318140645,
        "cond_entropy-2-nopunct": 1.2424890351973181,
        "distinct-3-nopunct": 0.028505465510742557,
        "vocab_size-3-nopunct": 605,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 7.535928125653132,
        "cond_entropy-3-nopunct": 0.797955245242467,
        "msttr-100": 0.25818,
        "msttr-100_nopunct": 0.25145,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7165957805196446
        },
        "rouge1": {
            "precision": 0.79138,
            "recall": 0.7212,
            "fmeasure": 0.74394
        },
        "rouge2": {
            "precision": 0.46867,
            "recall": 0.42731,
            "fmeasure": 0.4405
        },
        "rougeL": {
            "precision": 0.5664,
            "recall": 0.51589,
            "fmeasure": 0.5323
        },
        "rougeLsum": {
            "precision": 0.5664,
            "recall": 0.51589,
            "fmeasure": 0.5323
        },
        "nist": 5.146983990125854,
        "bleu": 31.65178,
        "nubia": {
            "semantic_relation": 4.43199,
            "contradiction": 1.40777,
            "irrelevancy": 7.20161,
            "logical_agreement": 91.39062,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.47661,
            "nubia_score": 0.83607
        },
        "bertscore": {
            "precision": 0.92855,
            "recall": 0.90628,
            "f1": 0.917
        },
        "meteor": 0.36690170429489655,
        "bleurt": 0.26622
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_base/e2e_nlg_test",
        "N": 1406,
        "total_length": 37114,
        "mean_pred_length": 26.396870554765293,
        "std_pred_length": 4.401647356690528,
        "median_pred_length": 26.0,
        "min_pred_length": 15,
        "max_pred_length": 40,
        "distinct-1": 0.002694401034649997,
        "vocab_size-1": 100,
        "unique-1": 4,
        "entropy-1": 5.587289022595877,
        "distinct-2": 0.009241626526268623,
        "vocab_size-2": 330,
        "unique-2": 43,
        "entropy-2": 6.9970822276786215,
        "cond_entropy-2": 1.3325505269340758,
        "distinct-3": 0.019503235962917614,
        "vocab_size-3": 669,
        "unique-3": 111,
        "entropy-3": 7.802517344360929,
        "cond_entropy-3": 0.8189674108479696,
        "total_length-nopunct": 33977,
        "mean_pred_length-nopunct": 24.165718349928877,
        "std_pred_length-nopunct": 4.150304417742577,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.00288430408805957,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 5.623665278363426,
        "distinct-2-nopunct": 0.010131712259371834,
        "vocab_size-2-nopunct": 330,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 6.98040222970007,
        "cond_entropy-2-nopunct": 1.391758321946724,
        "distinct-3-nopunct": 0.021755174073479867,
        "vocab_size-3-nopunct": 678,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 7.8286086179366965,
        "cond_entropy-3-nopunct": 0.8504385985161849,
        "msttr-100": 0.2852,
        "msttr-100_nopunct": 0.27997,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7109571979707767
        },
        "rouge1": {
            "precision": 0.79278,
            "recall": 0.72002,
            "fmeasure": 0.74557
        },
        "rouge2": {
            "precision": 0.48139,
            "recall": 0.43684,
            "fmeasure": 0.45233
        },
        "rougeL": {
            "precision": 0.544,
            "recall": 0.4954,
            "fmeasure": 0.5123
        },
        "rougeLsum": {
            "precision": 0.544,
            "recall": 0.4954,
            "fmeasure": 0.5123
        },
        "nist": 5.187429981727047,
        "bleu": 31.49345,
        "nubia": {
            "semantic_relation": 4.49115,
            "contradiction": 1.89841,
            "irrelevancy": 12.01899,
            "logical_agreement": 86.0826,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.33812,
            "nubia_score": 0.84283
        },
        "bertscore": {
            "precision": 0.92571,
            "recall": 0.90842,
            "f1": 0.91675
        },
        "meteor": 0.3682059345995405,
        "bleurt": 0.28823
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "mT5_base/e2e_nlg_test",
        "N": 774,
        "total_length": 25345,
        "mean_pred_length": 32.74547803617571,
        "std_pred_length": 3.9350113312627406,
        "median_pred_length": 32.0,
        "min_pred_length": 19,
        "max_pred_length": 45,
        "distinct-1": 0.0036693627934503846,
        "vocab_size-1": 93,
        "unique-1": 3,
        "entropy-1": 5.693378929879978,
        "distinct-2": 0.01102926213829311,
        "vocab_size-2": 271,
        "unique-2": 24,
        "entropy-2": 7.042135278796437,
        "cond_entropy-2": 1.2868392928081893,
        "distinct-3": 0.021473294953145355,
        "vocab_size-3": 511,
        "unique-3": 70,
        "entropy-3": 7.848615478948726,
        "cond_entropy-3": 0.8121363197779601,
        "total_length-nopunct": 23345,
        "mean_pred_length-nopunct": 30.161498708010335,
        "std_pred_length-nopunct": 3.584133255135306,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.0038980509745127436,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 5.726569813854229,
        "distinct-2-nopunct": 0.012050861725222631,
        "vocab_size-2-nopunct": 272,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 7.052876339558874,
        "cond_entropy-2-nopunct": 1.351362619702129,
        "distinct-3-nopunct": 0.024040005505344773,
        "vocab_size-3-nopunct": 524,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 7.903465273195081,
        "cond_entropy-3-nopunct": 0.8391257423531626,
        "msttr-100": 0.31455,
        "msttr-100_nopunct": 0.30644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7425590386138152
        },
        "rouge1": {
            "precision": 0.80027,
            "recall": 0.75908,
            "fmeasure": 0.77383
        },
        "rouge2": {
            "precision": 0.49996,
            "recall": 0.47386,
            "fmeasure": 0.48318
        },
        "rougeL": {
            "precision": 0.52914,
            "recall": 0.5036,
            "fmeasure": 0.51257
        },
        "rougeLsum": {
            "precision": 0.52914,
            "recall": 0.5036,
            "fmeasure": 0.51257
        },
        "nist": 5.631033553813905,
        "bleu": 35.73342,
        "nubia": {
            "semantic_relation": 4.53061,
            "contradiction": 2.87698,
            "irrelevancy": 14.59669,
            "logical_agreement": 82.52632,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.08114,
            "nubia_score": 0.86205
        },
        "bertscore": {
            "precision": 0.92497,
            "recall": 0.91376,
            "f1": 0.91919
        },
        "meteor": 0.3825556864302106,
        "bleurt": 0.32501
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "mT5_base/e2e_nlg_test",
        "N": 73,
        "total_length": 2344,
        "mean_pred_length": 32.10958904109589,
        "std_pred_length": 3.5017085608044836,
        "median_pred_length": 31.0,
        "min_pred_length": 24,
        "max_pred_length": 41,
        "distinct-1": 0.036262798634812285,
        "vocab_size-1": 85,
        "unique-1": 5,
        "entropy-1": 5.615755145133675,
        "distinct-2": 0.09247027741083223,
        "vocab_size-2": 210,
        "unique-2": 35,
        "entropy-2": 6.893279479899221,
        "cond_entropy-2": 1.2203538497109236,
        "distinct-3": 0.15878070973612374,
        "vocab_size-3": 349,
        "unique-3": 95,
        "entropy-3": 7.617551840845542,
        "cond_entropy-3": 0.7299291860353697,
        "total_length-nopunct": 2162,
        "mean_pred_length-nopunct": 29.616438356164384,
        "std_pred_length-nopunct": 3.470541929914682,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.03839037927844589,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 5.622330813382611,
        "distinct-2-nopunct": 0.10052656773575874,
        "vocab_size-2-nopunct": 210,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 6.875243306927434,
        "cond_entropy-2-nopunct": 1.2820471646978784,
        "distinct-3-nopunct": 0.17410714285714285,
        "vocab_size-3-nopunct": 351,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 7.636433835947663,
        "cond_entropy-3-nopunct": 0.7573305484484696,
        "msttr-100": 0.37652,
        "msttr-100_nopunct": 0.36143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7515243902439024
        },
        "rouge1": {
            "precision": 0.79383,
            "recall": 0.76772,
            "fmeasure": 0.77693
        },
        "rouge2": {
            "precision": 0.51942,
            "recall": 0.50023,
            "fmeasure": 0.50702
        },
        "rougeL": {
            "precision": 0.5294,
            "recall": 0.51258,
            "fmeasure": 0.51835
        },
        "rougeLsum": {
            "precision": 0.5294,
            "recall": 0.51258,
            "fmeasure": 0.51835
        },
        "nist": 5.433063003024565,
        "bleu": 37.17468,
        "nubia": {
            "semantic_relation": 4.34974,
            "contradiction": 4.60301,
            "irrelevancy": 25.99777,
            "logical_agreement": 69.39922,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.11299,
            "nubia_score": 0.8241
        },
        "bertscore": {
            "precision": 0.92131,
            "recall": 0.91436,
            "f1": 0.91772
        },
        "meteor": 0.3854489699709458,
        "bleurt": 0.28471
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "mT5_base/e2e_nlg_test",
        "N": 2,
        "total_length": 68,
        "mean_pred_length": 34.0,
        "std_pred_length": 0.0,
        "median_pred_length": 34.0,
        "min_pred_length": 34,
        "max_pred_length": 34,
        "distinct-1": 0.4264705882352941,
        "vocab_size-1": 29,
        "unique-1": 0,
        "entropy-1": 4.793345194191515,
        "distinct-2": 0.5,
        "vocab_size-2": 33,
        "unique-2": 0,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.22965855083538686,
        "distinct-3": 0.5,
        "vocab_size-3": 32,
        "unique-3": 0,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.04439411935845341,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 32.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 32,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.4375,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.75,
        "distinct-2-nopunct": 0.5,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.21226082651590766,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.04730571477835684,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7714285714285715
        },
        "rouge1": {
            "precision": 0.98438,
            "recall": 0.78885,
            "fmeasure": 0.87529
        },
        "rouge2": {
            "precision": 0.80645,
            "recall": 0.64272,
            "fmeasure": 0.71487
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.65414,
            "fmeasure": 0.72432
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.65414,
            "fmeasure": 0.72432
        },
        "nist": 4.457698346652484,
        "bleu": 54.70067,
        "nubia": {
            "semantic_relation": 4.79476,
            "contradiction": 0.1978,
            "irrelevancy": 0.42681,
            "logical_agreement": 99.37539,
            "grammar_ref": 4.16331,
            "grammar_hyp": 4.255,
            "nubia_score": 0.8781
        },
        "bertscore": {
            "precision": 0.96491,
            "recall": 0.93829,
            "f1": 0.95142
        },
        "meteor": 0.4418113472536837,
        "bleurt": 0.39829
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 213,
        "total_length": 7714,
        "mean_pred_length": 36.21596244131455,
        "std_pred_length": 8.406923629888471,
        "median_pred_length": 35.0,
        "min_pred_length": 17,
        "max_pred_length": 65,
        "distinct-1": 0.12833808659579984,
        "vocab_size-1": 990,
        "unique-1": 309,
        "entropy-1": 7.719827122634277,
        "distinct-2": 0.3419544060791894,
        "vocab_size-2": 2565,
        "unique-2": 1312,
        "entropy-2": 10.477065968546148,
        "cond_entropy-2": 2.6543594608578696,
        "distinct-3": 0.5113885839736553,
        "vocab_size-3": 3727,
        "unique-3": 2388,
        "entropy-3": 11.383267416343392,
        "cond_entropy-3": 0.9399616523540337,
        "total_length-nopunct": 6907,
        "mean_pred_length-nopunct": 32.42723004694836,
        "std_pred_length-nopunct": 7.7022410206709075,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.14202982481540466,
        "vocab_size-1-nopunct": 981,
        "unique-1-nopunct": 307,
        "entropy-1-nopunct": 7.934529392786826,
        "distinct-2-nopunct": 0.3576337018225276,
        "vocab_size-2-nopunct": 2394,
        "unique-2-nopunct": 1274,
        "entropy-2-nopunct": 10.415552900477175,
        "cond_entropy-2-nopunct": 2.5701312508365377,
        "distinct-3-nopunct": 0.5278506403332819,
        "vocab_size-3-nopunct": 3421,
        "unique-3-nopunct": 2266,
        "entropy-3-nopunct": 11.267961449371557,
        "cond_entropy-3-nopunct": 0.8839681863001713,
        "msttr-100": 0.61818,
        "msttr-100_nopunct": 0.65435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.21767764298093586,
            "2": 0.5125535823637477,
            "3": 0.8034015566445661
        },
        "rouge1": {
            "precision": 0.68239,
            "recall": 0.6644,
            "fmeasure": 0.66701
        },
        "rouge2": {
            "precision": 0.40427,
            "recall": 0.39116,
            "fmeasure": 0.39352
        },
        "rougeL": {
            "precision": 0.4929,
            "recall": 0.48016,
            "fmeasure": 0.48124
        },
        "rougeLsum": {
            "precision": 0.4929,
            "recall": 0.48016,
            "fmeasure": 0.48124
        },
        "nist": 7.786207261097186,
        "bleu": 41.17678,
        "nubia": {
            "semantic_relation": 3.90206,
            "contradiction": 19.49019,
            "irrelevancy": 13.05915,
            "logical_agreement": 67.45066,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.18645,
            "nubia_score": 0.65272
        },
        "bertscore": {
            "precision": 0.89107,
            "recall": 0.88775,
            "f1": 0.88819
        },
        "meteor": 0.3368043935497493,
        "bleurt": -0.09664
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 349,
        "total_length": 6322,
        "mean_pred_length": 18.11461318051576,
        "std_pred_length": 5.188541340305144,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 52,
        "distinct-1": 0.16118316988294842,
        "vocab_size-1": 1019,
        "unique-1": 441,
        "entropy-1": 7.6270218213320025,
        "distinct-2": 0.40415201741168594,
        "vocab_size-2": 2414,
        "unique-2": 1421,
        "entropy-2": 10.43624083565578,
        "cond_entropy-2": 2.603978666900235,
        "distinct-3": 0.5874822190611664,
        "vocab_size-3": 3304,
        "unique-3": 2349,
        "entropy-3": 11.276019895417974,
        "cond_entropy-3": 0.9198644991567803,
        "total_length-nopunct": 5551,
        "mean_pred_length-nopunct": 15.9054441260745,
        "std_pred_length-nopunct": 4.568447805016999,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.18194919834264098,
        "vocab_size-1-nopunct": 1010,
        "unique-1-nopunct": 437,
        "entropy-1-nopunct": 7.907270779133156,
        "distinct-2-nopunct": 0.40561322568242986,
        "vocab_size-2-nopunct": 2110,
        "unique-2-nopunct": 1283,
        "entropy-2-nopunct": 10.23384117807536,
        "cond_entropy-2-nopunct": 2.5071785225149137,
        "distinct-3-nopunct": 0.58788378322687,
        "vocab_size-3-nopunct": 2853,
        "unique-3-nopunct": 2043,
        "entropy-3-nopunct": 11.059232436757117,
        "cond_entropy-3-nopunct": 0.8912284962575957,
        "msttr-100": 0.62698,
        "msttr-100_nopunct": 0.67582,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2345679012345679,
            "2": 0.5336927223719676,
            "3": 0.8229665071770335,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.69762,
            "recall": 0.7274,
            "fmeasure": 0.70346
        },
        "rouge2": {
            "precision": 0.45527,
            "recall": 0.47439,
            "fmeasure": 0.45825
        },
        "rougeL": {
            "precision": 0.57665,
            "recall": 0.60381,
            "fmeasure": 0.58222
        },
        "rougeLsum": {
            "precision": 0.57665,
            "recall": 0.60381,
            "fmeasure": 0.58222
        },
        "nist": 7.658818251400436,
        "bleu": 42.72282,
        "nubia": {
            "semantic_relation": 4.28863,
            "contradiction": 13.82694,
            "irrelevancy": 10.37,
            "logical_agreement": 75.80305,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.73136,
            "nubia_score": 0.74005
        },
        "bertscore": {
            "precision": 0.90525,
            "recall": 0.91149,
            "f1": 0.90695
        },
        "meteor": 0.384239722656581,
        "bleurt": 0.07994
    },
    "mlsum_de_test": {
        "predictions_file": "mT5_base/mlsum_de_test",
        "N": 10695,
        "total_length": 290384,
        "mean_pred_length": 27.15137914913511,
        "std_pred_length": 11.083312859932725,
        "median_pred_length": 26.0,
        "min_pred_length": 6,
        "max_pred_length": 90,
        "distinct-1": 0.12299920105790953,
        "vocab_size-1": 35717,
        "unique-1": 21429,
        "entropy-1": 10.565396389530354,
        "distinct-2": 0.5462960645574191,
        "vocab_size-2": 152793,
        "unique-2": 124148,
        "entropy-2": 16.016333490341292,
        "cond_entropy-2": 5.21358638650216,
        "distinct-3": 0.8615470977047816,
        "vocab_size-3": 231751,
        "unique-3": 214848,
        "entropy-3": 17.60321716672174,
        "cond_entropy-3": 1.5632783492185283,
        "total_length-nopunct": 257782,
        "mean_pred_length-nopunct": 24.103038803179057,
        "std_pred_length-nopunct": 9.780166414473785,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.13850074869463344,
        "vocab_size-1-nopunct": 35703,
        "unique-1-nopunct": 21428,
        "entropy-1-nopunct": 11.115826930230794,
        "distinct-2-nopunct": 0.606013266582216,
        "vocab_size-2-nopunct": 149738,
        "unique-2-nopunct": 124569,
        "entropy-2-nopunct": 16.26305439447733,
        "cond_entropy-2-nopunct": 5.243522740554366,
        "distinct-3-nopunct": 0.8955506108497749,
        "vocab_size-3-nopunct": 211701,
        "unique-3-nopunct": 199339,
        "entropy-3-nopunct": 17.537644296526498,
        "cond_entropy-3-nopunct": 1.3077681741874967,
        "msttr-100": 0.77647,
        "msttr-100_nopunct": 0.82692,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "local_recall": {
            "1": 0.48091641852998607
        },
        "rouge1": {
            "precision": 0.46436,
            "recall": 0.46776,
            "fmeasure": 0.45628
        },
        "rouge2": {
            "precision": 0.35364,
            "recall": 0.35926,
            "fmeasure": 0.35232
        },
        "rougeL": {
            "precision": 0.42715,
            "recall": 0.43004,
            "fmeasure": 0.42082
        },
        "rougeLsum": {
            "precision": 0.42715,
            "recall": 0.43004,
            "fmeasure": 0.42082
        },
        "nist": 7.5689846219996015,
        "bleu": 39.03444,
        "nubia": {
            "semantic_relation": 2.78211,
            "contradiction": 23.62743,
            "irrelevancy": 40.04108,
            "logical_agreement": 36.33149,
            "grammar_ref": 5.03454,
            "grammar_hyp": 4.97748,
            "nubia_score": 0.41381
        },
        "bertscore": {
            "precision": 0.89385,
            "recall": 0.89541,
            "f1": 0.89444
        },
        "meteor": 0.4419044633393923,
        "bleurt": -0.22639
    },
    "mlsum_de_challenge_test_covid": {
        "predictions_file": "mT5_base/mlsum_de_challenge_test_covid",
        "N": 5058,
        "total_length": 150935,
        "mean_pred_length": 29.840846184262553,
        "std_pred_length": 9.513958041910671,
        "median_pred_length": 30.0,
        "min_pred_length": 0,
        "max_pred_length": 90,
        "distinct-1": 0.10869579620366383,
        "vocab_size-1": 16406,
        "unique-1": 10143,
        "entropy-1": 9.468010677600663,
        "distinct-2": 0.44184181302184017,
        "vocab_size-2": 64455,
        "unique-2": 53470,
        "entropy-2": 13.476244721432318,
        "cond_entropy-2": 3.91330097742208,
        "distinct-3": 0.6560953266913315,
        "vocab_size-3": 92392,
        "unique-3": 86817,
        "entropy-3": 14.465281299958173,
        "cond_entropy-3": 0.9820860629119742,
        "total_length-nopunct": 132720,
        "mean_pred_length-nopunct": 26.23962040332147,
        "std_pred_length-nopunct": 8.25938219487625,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 78,
        "distinct-1-nopunct": 0.12350813743218807,
        "vocab_size-1-nopunct": 16392,
        "unique-1-nopunct": 10139,
        "entropy-1-nopunct": 9.936860636083157,
        "distinct-2-nopunct": 0.49502205024165186,
        "vocab_size-2-nopunct": 63196,
        "unique-2-nopunct": 53716,
        "entropy-2-nopunct": 13.661251991546767,
        "cond_entropy-2-nopunct": 3.8068424542487436,
        "distinct-3-nopunct": 0.6882697421007129,
        "vocab_size-3-nopunct": 84386,
        "unique-3-nopunct": 80631,
        "entropy-3-nopunct": 14.412657317779164,
        "cond_entropy-3-nopunct": 0.7632030187540388,
        "msttr-100": 0.73486,
        "msttr-100_nopunct": 0.77824,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_challenge_test_covid.json",
        "local_recall": {
            "1": 0.37842175853653176
        },
        "rouge1": {
            "precision": 0.26803,
            "recall": 0.37014,
            "fmeasure": 0.30147
        },
        "rouge2": {
            "precision": 0.18107,
            "recall": 0.25204,
            "fmeasure": 0.20515
        },
        "rougeL": {
            "precision": 0.24409,
            "recall": 0.33752,
            "fmeasure": 0.27502
        },
        "rougeLsum": {
            "precision": 0.24409,
            "recall": 0.33752,
            "fmeasure": 0.27502
        },
        "nist": 3.8292782459921058,
        "bleu": 19.42147,
        "nubia": {
            "semantic_relation": 1.8866,
            "contradiction": 24.56593,
            "irrelevancy": 59.27272,
            "logical_agreement": 16.14159,
            "grammar_ref": 5.17358,
            "grammar_hyp": 4.97626,
            "nubia_score": 0.22184
        },
        "bertscore": {
            "precision": 0.85659,
            "recall": 0.87502,
            "f1": 0.8654
        },
        "meteor": 0.32249954953426135,
        "bleurt": -0.54766
    },
    "web_nlg_en_challenge_test_scramble": {
        "predictions_file": "mT5_base/web_nlg_en_challenge_test_scramble",
        "N": 500,
        "total_length": 12788,
        "mean_pred_length": 25.576,
        "std_pred_length": 13.35425864658911,
        "median_pred_length": 25.0,
        "min_pred_length": 6,
        "max_pred_length": 86,
        "distinct-1": 0.12636847044103847,
        "vocab_size-1": 1616,
        "unique-1": 723,
        "entropy-1": 8.032898681167438,
        "distinct-2": 0.408447265625,
        "vocab_size-2": 5019,
        "unique-2": 3204,
        "entropy-2": 11.3510205277303,
        "cond_entropy-2": 3.1591071850196526,
        "distinct-3": 0.6532914828639295,
        "vocab_size-3": 7701,
        "unique-3": 6012,
        "entropy-3": 12.49889727641682,
        "cond_entropy-3": 1.1919115818073527,
        "total_length-nopunct": 11318,
        "mean_pred_length-nopunct": 22.636,
        "std_pred_length-nopunct": 12.002145808146143,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.14189786181304118,
        "vocab_size-1-nopunct": 1606,
        "unique-1-nopunct": 721,
        "entropy-1-nopunct": 8.310968059813725,
        "distinct-2-nopunct": 0.427158439637641,
        "vocab_size-2-nopunct": 4621,
        "unique-2-nopunct": 3065,
        "entropy-2-nopunct": 11.248053505513088,
        "cond_entropy-2-nopunct": 3.0665589658566277,
        "distinct-3-nopunct": 0.667086644698585,
        "vocab_size-3-nopunct": 6883,
        "unique-3-nopunct": 5492,
        "entropy-3-nopunct": 12.340746749463937,
        "cond_entropy-3-nopunct": 1.1287312579152364,
        "msttr-100": 0.54787,
        "msttr-100_nopunct": 0.56531,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.21031824471239374,
            "2": 0.5256192738378012,
            "3": 0.7645848915482424,
            "4": 0.2,
            "5": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.64621,
            "recall": 0.6656,
            "fmeasure": 0.64581
        },
        "rouge2": {
            "precision": 0.37933,
            "recall": 0.38993,
            "fmeasure": 0.37826
        },
        "rougeL": {
            "precision": 0.50016,
            "recall": 0.51493,
            "fmeasure": 0.49924
        },
        "rougeLsum": {
            "precision": 0.50016,
            "recall": 0.51493,
            "fmeasure": 0.49924
        },
        "nist": 7.14493516108524,
        "bleu": 34.83469,
        "nubia": {
            "semantic_relation": 3.85569,
            "contradiction": 24.67225,
            "irrelevancy": 14.24335,
            "logical_agreement": 61.0844,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.80503,
            "nubia_score": 0.60623
        },
        "bertscore": {
            "precision": 0.88398,
            "recall": 0.88944,
            "f1": 0.88513
        },
        "meteor": 0.32744273829403386,
        "bleurt": -0.11272
    },
    "mlsum_es_val": {
        "predictions_file": "mT5_base/mlsum_es_val",
        "N": 9977,
        "total_length": 225862,
        "mean_pred_length": 22.638268016437806,
        "std_pred_length": 8.663520131192554,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 94,
        "distinct-1": 0.115809653682337,
        "vocab_size-1": 26157,
        "unique-1": 14512,
        "entropy-1": 10.02999303833144,
        "distinct-2": 0.49210922481876923,
        "vocab_size-2": 106239,
        "unique-2": 83017,
        "entropy-2": 15.274549463953608,
        "cond_entropy-2": 5.4157601421506145,
        "distinct-3": 0.8178264079103289,
        "vocab_size-3": 168397,
        "unique-3": 152721,
        "entropy-3": 17.079267305634655,
        "cond_entropy-3": 1.8485227008783442,
        "total_length-nopunct": 213731,
        "mean_pred_length-nopunct": 21.422371454344994,
        "std_pred_length-nopunct": 7.867297485127524,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 85,
        "distinct-1-nopunct": 0.12228455394865509,
        "vocab_size-1-nopunct": 26136,
        "unique-1-nopunct": 14511,
        "entropy-1-nopunct": 10.194395635598449,
        "distinct-2-nopunct": 0.515356753732442,
        "vocab_size-2-nopunct": 105006,
        "unique-2-nopunct": 83321,
        "entropy-2-nopunct": 15.355252374111725,
        "cond_entropy-2-nopunct": 5.342242873780062,
        "distinct-3-nopunct": 0.835228123048659,
        "vocab_size-3-nopunct": 161848,
        "unique-3-nopunct": 148028,
        "entropy-3-nopunct": 17.057833533639705,
        "cond_entropy-3-nopunct": 1.7401410164059623,
        "msttr-100": 0.7096,
        "msttr-100_nopunct": 0.723,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_val.json",
        "local_recall": {
            "1": 0.2847753535415485
        },
        "rouge1": {
            "precision": 0.31651,
            "recall": 0.30534,
            "fmeasure": 0.29909
        },
        "rouge2": {
            "precision": 0.12671,
            "recall": 0.12303,
            "fmeasure": 0.12017
        },
        "rougeL": {
            "precision": 0.25407,
            "recall": 0.24595,
            "fmeasure": 0.24059
        },
        "rougeLsum": {
            "precision": 0.25407,
            "recall": 0.24595,
            "fmeasure": 0.24059
        },
        "nist": 3.1382143328409087,
        "bleu": 9.73871,
        "nubia": {
            "semantic_relation": 1.74395,
            "contradiction": 27.98136,
            "irrelevancy": 60.26322,
            "logical_agreement": 11.75541,
            "grammar_ref": 5.2776,
            "grammar_hyp": 5.20474,
            "nubia_score": 0.19489
        },
        "bertscore": {
            "precision": 0.84205,
            "recall": 0.84136,
            "f1": 0.84148
        },
        "meteor": 0.21970758447289462,
        "bleurt": -0.41772
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.59375
        },
        "rouge1": {
            "precision": 0.74802,
            "recall": 0.65503,
            "fmeasure": 0.69122
        },
        "rouge2": {
            "precision": 0.54206,
            "recall": 0.50529,
            "fmeasure": 0.51874
        },
        "rougeL": {
            "precision": 0.74802,
            "recall": 0.65503,
            "fmeasure": 0.69122
        },
        "rougeLsum": {
            "precision": 0.74802,
            "recall": 0.65503,
            "fmeasure": 0.69122
        },
        "nist": 2.00940035551084,
        "bleu": 24.18369,
        "nubia": {
            "semantic_relation": 3.63052,
            "contradiction": 14.94947,
            "irrelevancy": 24.00342,
            "logical_agreement": 61.04711,
            "grammar_ref": 5.04645,
            "grammar_hyp": 5.19326,
            "nubia_score": 0.49667
        },
        "bertscore": {
            "precision": 0.94062,
            "recall": 0.91889,
            "f1": 0.92955
        },
        "meteor": 0.3099462397862758,
        "bleurt": 0.18289
    },
    "mlsum_es_test": {
        "predictions_file": "mT5_base/mlsum_es_test",
        "N": 13366,
        "total_length": 301167,
        "mean_pred_length": 22.532320814005686,
        "std_pred_length": 8.3585283432711,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 98,
        "distinct-1": 0.10317531469251279,
        "vocab_size-1": 31073,
        "unique-1": 16796,
        "entropy-1": 10.077897834782675,
        "distinct-2": 0.46221521120496456,
        "vocab_size-2": 133026,
        "unique-2": 102711,
        "entropy-2": 15.446776189691898,
        "cond_entropy-2": 5.540865604325063,
        "distinct-3": 0.7924900249603731,
        "vocab_size-3": 217487,
        "unique-3": 195730,
        "entropy-3": 17.37171603327546,
        "cond_entropy-3": 1.9697520056401703,
        "total_length-nopunct": 284858,
        "mean_pred_length-nopunct": 21.31213526859195,
        "std_pred_length-nopunct": 7.553330623365311,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 89,
        "distinct-1-nopunct": 0.10901923063421073,
        "vocab_size-1-nopunct": 31055,
        "unique-1-nopunct": 16795,
        "entropy-1-nopunct": 10.249261042162253,
        "distinct-2-nopunct": 0.48605483771160846,
        "vocab_size-2-nopunct": 131960,
        "unique-2-nopunct": 103731,
        "entropy-2-nopunct": 15.542435750534874,
        "cond_entropy-2-nopunct": 5.4759915555280525,
        "distinct-3-nopunct": 0.811983294979971,
        "vocab_size-3-nopunct": 209594,
        "unique-3-nopunct": 190431,
        "entropy-3-nopunct": 17.36153136427542,
        "cond_entropy-3-nopunct": 1.856637536290874,
        "msttr-100": 0.70915,
        "msttr-100_nopunct": 0.72233,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "local_recall": {
            "1": 0.28070042850988897
        },
        "rouge1": {
            "precision": 0.3185,
            "recall": 0.30406,
            "fmeasure": 0.29946
        },
        "rouge2": {
            "precision": 0.12629,
            "recall": 0.12086,
            "fmeasure": 0.119
        },
        "rougeL": {
            "precision": 0.25535,
            "recall": 0.24443,
            "fmeasure": 0.24052
        },
        "rougeLsum": {
            "precision": 0.25535,
            "recall": 0.24443,
            "fmeasure": 0.24052
        },
        "nist": 3.1301187211084507,
        "bleu": 9.32485,
        "nubia": {
            "semantic_relation": 1.73355,
            "contradiction": 28.63937,
            "irrelevancy": 60.13776,
            "logical_agreement": 11.22287,
            "grammar_ref": 5.26998,
            "grammar_hyp": 5.21837,
            "nubia_score": 0.19303
        },
        "bertscore": {
            "precision": 0.84225,
            "recall": 0.84054,
            "f1": 0.84118
        },
        "meteor": 0.21726211197454662,
        "bleurt": -0.42398
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 46,
        "total_length": 1436,
        "mean_pred_length": 31.217391304347824,
        "std_pred_length": 7.070800469654303,
        "median_pred_length": 31.0,
        "min_pred_length": 18,
        "max_pred_length": 48,
        "distinct-1": 0.13997214484679665,
        "vocab_size-1": 201,
        "unique-1": 71,
        "entropy-1": 6.43596823487271,
        "distinct-2": 0.3762589928057554,
        "vocab_size-2": 523,
        "unique-2": 263,
        "entropy-2": 8.383312184131348,
        "cond_entropy-2": 1.889580607143401,
        "distinct-3": 0.5595238095238095,
        "vocab_size-3": 752,
        "unique-3": 494,
        "entropy-3": 9.194163549548573,
        "cond_entropy-3": 0.83114605737874,
        "total_length-nopunct": 1325,
        "mean_pred_length-nopunct": 28.804347826086957,
        "std_pred_length-nopunct": 6.43907759130476,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.1479245283018868,
        "vocab_size-1-nopunct": 196,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.424502103965644,
        "distinct-2-nopunct": 0.382329945269742,
        "vocab_size-2-nopunct": 489,
        "unique-2-nopunct": 245,
        "entropy-2-nopunct": 8.306152021404127,
        "cond_entropy-2-nopunct": 1.916095860059335,
        "distinct-3-nopunct": 0.570154095701541,
        "vocab_size-3-nopunct": 703,
        "unique-3-nopunct": 468,
        "entropy-3-nopunct": 9.106547686949185,
        "cond_entropy-3-nopunct": 0.8275324695029646,
        "msttr-100": 0.57714,
        "msttr-100_nopunct": 0.56769,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6366639141205616
        },
        "rouge1": {
            "precision": 0.6448,
            "recall": 0.65296,
            "fmeasure": 0.63493
        },
        "rouge2": {
            "precision": 0.40876,
            "recall": 0.41862,
            "fmeasure": 0.40456
        },
        "rougeL": {
            "precision": 0.52507,
            "recall": 0.53418,
            "fmeasure": 0.51829
        },
        "rougeLsum": {
            "precision": 0.52507,
            "recall": 0.53418,
            "fmeasure": 0.51829
        },
        "nist": 5.249278535534669,
        "bleu": 35.81585,
        "nubia": {
            "semantic_relation": 3.82057,
            "contradiction": 37.98906,
            "irrelevancy": 27.76797,
            "logical_agreement": 34.24297,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.32253,
            "nubia_score": 0.58161
        },
        "bertscore": {
            "precision": 0.88529,
            "recall": 0.88871,
            "f1": 0.88662
        },
        "meteor": 0.32201703676645754,
        "bleurt": -0.16486
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 1397,
        "total_length": 28445,
        "mean_pred_length": 20.36148890479599,
        "std_pred_length": 7.167114916245989,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 54,
        "distinct-1": 0.059799613288802955,
        "vocab_size-1": 1701,
        "unique-1": 803,
        "entropy-1": 7.3138380403440815,
        "distinct-2": 0.18371044069801834,
        "vocab_size-2": 4969,
        "unique-2": 2904,
        "entropy-2": 9.947111731987885,
        "cond_entropy-2": 2.518211463729158,
        "distinct-3": 0.3300456122568321,
        "vocab_size-3": 8466,
        "unique-3": 5774,
        "entropy-3": 11.379159951746384,
        "cond_entropy-3": 1.4650988352501975,
        "total_length-nopunct": 25813,
        "mean_pred_length-nopunct": 18.477451682176092,
        "std_pred_length-nopunct": 6.701880617698192,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.06543214659280208,
        "vocab_size-1-nopunct": 1689,
        "unique-1-nopunct": 801,
        "entropy-1-nopunct": 7.38035244054433,
        "distinct-2-nopunct": 0.19556847968545216,
        "vocab_size-2-nopunct": 4775,
        "unique-2-nopunct": 2857,
        "entropy-2-nopunct": 9.895332660128195,
        "cond_entropy-2-nopunct": 2.6046162004345446,
        "distinct-3-nopunct": 0.3475824319040792,
        "vocab_size-3-nopunct": 8001,
        "unique-3-nopunct": 5538,
        "entropy-3-nopunct": 11.330880992327709,
        "cond_entropy-3-nopunct": 1.4978324091875048,
        "msttr-100": 0.6012,
        "msttr-100_nopunct": 0.60845,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6388369255795039
        },
        "rouge1": {
            "precision": 0.66206,
            "recall": 0.65206,
            "fmeasure": 0.64441
        },
        "rouge2": {
            "precision": 0.44301,
            "recall": 0.43493,
            "fmeasure": 0.43023
        },
        "rougeL": {
            "precision": 0.57492,
            "recall": 0.56631,
            "fmeasure": 0.55973
        },
        "rougeLsum": {
            "precision": 0.57492,
            "recall": 0.56631,
            "fmeasure": 0.55973
        },
        "nist": 6.636681717743768,
        "bleu": 35.63292,
        "nubia": {
            "semantic_relation": 4.0978,
            "contradiction": 5.01614,
            "irrelevancy": 23.5014,
            "logical_agreement": 71.48245,
            "grammar_ref": 4.97201,
            "grammar_hyp": 4.86973,
            "nubia_score": 0.69133
        },
        "bertscore": {
            "precision": 0.88506,
            "recall": 0.87965,
            "f1": 0.88191
        },
        "meteor": 0.34227985416161505,
        "bleurt": -0.05447
    },
    "mlsum_es_challenge_test_covid": {
        "predictions_file": "mT5_base/mlsum_es_challenge_test_covid",
        "N": 1938,
        "total_length": 45134,
        "mean_pred_length": 23.288957688338492,
        "std_pred_length": 8.198900719644897,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 89,
        "distinct-1": 0.18702087118358665,
        "vocab_size-1": 8441,
        "unique-1": 5185,
        "entropy-1": 9.539123576019053,
        "distinct-2": 0.6267478470228725,
        "vocab_size-2": 27073,
        "unique-2": 22543,
        "entropy-2": 13.891183562008615,
        "cond_entropy-2": 4.479662447280302,
        "distinct-3": 0.9058122061176014,
        "vocab_size-3": 37372,
        "unique-3": 35281,
        "entropy-3": 15.07636608273671,
        "cond_entropy-3": 1.1996578493181198,
        "total_length-nopunct": 42838,
        "mean_pred_length-nopunct": 22.104231166150672,
        "std_pred_length-nopunct": 7.46539817556508,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.19674121107427983,
        "vocab_size-1-nopunct": 8428,
        "unique-1-nopunct": 5182,
        "entropy-1-nopunct": 9.647869718354093,
        "distinct-2-nopunct": 0.6488997555012225,
        "vocab_size-2-nopunct": 26540,
        "unique-2-nopunct": 22362,
        "entropy-2-nopunct": 13.912989836211052,
        "cond_entropy-2-nopunct": 4.402228964572354,
        "distinct-3-nopunct": 0.9149940968122786,
        "vocab_size-3-nopunct": 35650,
        "unique-3-nopunct": 33863,
        "entropy-3-nopunct": 15.018340184760566,
        "cond_entropy-3-nopunct": 1.1156571698342577,
        "msttr-100": 0.72508,
        "msttr-100_nopunct": 0.73107,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_challenge_test_covid.json",
        "local_recall": {
            "1": 0.2220161834120027
        },
        "rouge1": {
            "precision": 0.26534,
            "recall": 0.24197,
            "fmeasure": 0.24213
        },
        "rouge2": {
            "precision": 0.06471,
            "recall": 0.06015,
            "fmeasure": 0.05962
        },
        "rougeL": {
            "precision": 0.19581,
            "recall": 0.1787,
            "fmeasure": 0.17849
        },
        "rougeLsum": {
            "precision": 0.19581,
            "recall": 0.1787,
            "fmeasure": 0.17849
        },
        "nist": 1.9634892182250518,
        "bleu": 3.73542,
        "nubia": {
            "semantic_relation": 1.35524,
            "contradiction": 31.83321,
            "irrelevancy": 60.05771,
            "logical_agreement": 8.10908,
            "grammar_ref": 5.23427,
            "grammar_hyp": 5.2911,
            "nubia_score": 0.1436
        },
        "bertscore": {
            "precision": 0.83336,
            "recall": 0.82951,
            "f1": 0.83126
        },
        "meteor": 0.15877473786767657,
        "bleurt": -0.5004
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 983,
        "total_length": 5180,
        "mean_pred_length": 5.269582909460834,
        "std_pred_length": 1.42409169674049,
        "median_pred_length": 5.0,
        "min_pred_length": 4,
        "max_pred_length": 12,
        "distinct-1": 0.010038610038610039,
        "vocab_size-1": 52,
        "unique-1": 11,
        "entropy-1": 3.4406896142709797,
        "distinct-2": 0.02049082678103407,
        "vocab_size-2": 86,
        "unique-2": 24,
        "entropy-2": 4.00006115931564,
        "cond_entropy-2": 0.5282447743708244,
        "distinct-3": 0.03142501555693839,
        "vocab_size-3": 101,
        "unique-3": 29,
        "entropy-3": 4.614340320950242,
        "cond_entropy-3": 0.5339509175957131,
        "total_length-nopunct": 4222,
        "mean_pred_length-nopunct": 4.295015259409969,
        "std_pred_length-nopunct": 1.1439813643254044,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.011605873993368073,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.1440000573066045,
        "distinct-2-nopunct": 0.020994133991972832,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 3.6584644736557426,
        "cond_entropy-2-nopunct": 0.3935082591754324,
        "distinct-3-nopunct": 0.030585106382978722,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 3.9263622092470545,
        "cond_entropy-3-nopunct": 0.46654078857602155,
        "msttr-100": 0.16412,
        "msttr-100_nopunct": 0.14976,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4921858274459431
        },
        "rouge1": {
            "precision": 0.54848,
            "recall": 0.50939,
            "fmeasure": 0.52023
        },
        "rouge2": {
            "precision": 0.36859,
            "recall": 0.33765,
            "fmeasure": 0.34659
        },
        "rougeL": {
            "precision": 0.54772,
            "recall": 0.50878,
            "fmeasure": 0.51955
        },
        "rougeLsum": {
            "precision": 0.54772,
            "recall": 0.50878,
            "fmeasure": 0.51955
        },
        "nist": 2.683937666447204,
        "bleu": 29.22694,
        "nubia": {
            "semantic_relation": 3.1364,
            "contradiction": 2.0416,
            "irrelevancy": 22.59626,
            "logical_agreement": 75.36214,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.5232,
            "nubia_score": 0.60335
        },
        "bertscore": {
            "precision": 0.86147,
            "recall": 0.85324,
            "f1": 0.8569
        },
        "meteor": 0.26995930630219056,
        "bleurt": 0.14402
    },
    "wiki_lingua_spanish_es_val": {
        "predictions_file": "mT5_base/wiki_lingua_spanish_es_val",
        "N": 11316,
        "total_length": 348895,
        "mean_pred_length": 30.832007776599504,
        "std_pred_length": 24.455855524959627,
        "median_pred_length": 23.0,
        "min_pred_length": 2,
        "max_pred_length": 188,
        "distinct-1": 0.027802060791928804,
        "vocab_size-1": 9700,
        "unique-1": 3018,
        "entropy-1": 8.391040349891265,
        "distinct-2": 0.15555173751921772,
        "vocab_size-2": 52511,
        "unique-2": 29406,
        "entropy-2": 13.076477753366529,
        "cond_entropy-2": 4.508673652357807,
        "distinct-3": 0.3686259244842351,
        "vocab_size-3": 120269,
        "unique-3": 85777,
        "entropy-3": 15.255609279455673,
        "cond_entropy-3": 2.204470503484959,
        "total_length-nopunct": 287726,
        "mean_pred_length-nopunct": 25.426475786496994,
        "std_pred_length-nopunct": 20.653733084773734,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 126,
        "distinct-1-nopunct": 0.0336431188005255,
        "vocab_size-1-nopunct": 9680,
        "unique-1-nopunct": 3014,
        "entropy-1-nopunct": 9.316008351271167,
        "distinct-2-nopunct": 0.24899515576442327,
        "vocab_size-2-nopunct": 68825,
        "unique-2-nopunct": 45273,
        "entropy-2-nopunct": 13.801267534411968,
        "cond_entropy-2-nopunct": 4.616419383986753,
        "distinct-3-nopunct": 0.4775781031920271,
        "vocab_size-3-nopunct": 126605,
        "unique-3-nopunct": 98227,
        "entropy-3-nopunct": 15.79254308221206,
        "cond_entropy-3-nopunct": 2.054612879421201,
        "msttr-100": 0.41191,
        "msttr-100_nopunct": 0.47127,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_val.json",
        "local_recall": {
            "1": 0.2272711459920544
        },
        "rouge1": {
            "precision": 0.41479,
            "recall": 0.28427,
            "fmeasure": 0.31067
        },
        "rouge2": {
            "precision": 0.14329,
            "recall": 0.09761,
            "fmeasure": 0.10678
        },
        "rougeL": {
            "precision": 0.35414,
            "recall": 0.24505,
            "fmeasure": 0.26627
        },
        "rougeLsum": {
            "precision": 0.35414,
            "recall": 0.24505,
            "fmeasure": 0.26627
        },
        "nist": 2.9407861429986055,
        "bleu": 7.62822,
        "sari": 67.06077,
        "nubia": {
            "semantic_relation": 2.87198,
            "contradiction": 16.77944,
            "irrelevancy": 35.25368,
            "logical_agreement": 47.96687,
            "grammar_ref": 3.95671,
            "grammar_hyp": 3.45848,
            "nubia_score": 0.39734
        },
        "bertscore": {
            "precision": 0.85909,
            "recall": 0.81449,
            "f1": 0.83549
        },
        "meteor": 0.13512529432507908,
        "bleurt": -0.42882
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 1027,
        "total_length": 10505,
        "mean_pred_length": 10.228821811100293,
        "std_pred_length": 4.409561496832099,
        "median_pred_length": 9.0,
        "min_pred_length": 1,
        "max_pred_length": 28,
        "distinct-1": 0.10775821037601142,
        "vocab_size-1": 1132,
        "unique-1": 609,
        "entropy-1": 7.257855220444775,
        "distinct-2": 0.2879299430259548,
        "vocab_size-2": 2729,
        "unique-2": 1670,
        "entropy-2": 9.981183297339689,
        "cond_entropy-2": 2.3499394989480695,
        "distinct-3": 0.4566966398485566,
        "vocab_size-3": 3860,
        "unique-3": 2685,
        "entropy-3": 11.03503478987223,
        "cond_entropy-3": 1.1242678582742553,
        "total_length-nopunct": 9035,
        "mean_pred_length-nopunct": 8.79746835443038,
        "std_pred_length-nopunct": 4.133350880482977,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.12440509131156613,
        "vocab_size-1-nopunct": 1124,
        "unique-1-nopunct": 609,
        "entropy-1-nopunct": 7.543386568872163,
        "distinct-2-nopunct": 0.2978271728271728,
        "vocab_size-2-nopunct": 2385,
        "unique-2-nopunct": 1463,
        "entropy-2-nopunct": 9.815542419063586,
        "cond_entropy-2-nopunct": 2.541764740248574,
        "distinct-3-nopunct": 0.4722222222222222,
        "vocab_size-3-nopunct": 3298,
        "unique-3-nopunct": 2345,
        "entropy-3-nopunct": 10.817353560651775,
        "cond_entropy-3-nopunct": 1.1751235126145407,
        "msttr-100": 0.61076,
        "msttr-100_nopunct": 0.64811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6170823217832708
        },
        "rouge1": {
            "precision": 0.67827,
            "recall": 0.6478,
            "fmeasure": 0.65156
        },
        "rouge2": {
            "precision": 0.47568,
            "recall": 0.45369,
            "fmeasure": 0.45454
        },
        "rougeL": {
            "precision": 0.62538,
            "recall": 0.59648,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.62538,
            "recall": 0.59648,
            "fmeasure": 0.6
        },
        "nist": 7.30085179631235,
        "bleu": 44.48379,
        "nubia": {
            "semantic_relation": 4.02509,
            "contradiction": 8.21402,
            "irrelevancy": 15.85182,
            "logical_agreement": 75.93416,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.74943,
            "nubia_score": 0.73561
        },
        "bertscore": {
            "precision": 0.90621,
            "recall": 0.89624,
            "f1": 0.90084
        },
        "meteor": 0.3693798155229147,
        "bleurt": 0.21081
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 958,
        "total_length": 20355,
        "mean_pred_length": 21.247390396659707,
        "std_pred_length": 7.488360381730561,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 98,
        "distinct-1": 0.08012773274379759,
        "vocab_size-1": 1631,
        "unique-1": 765,
        "entropy-1": 7.582302647295013,
        "distinct-2": 0.22560189720059803,
        "vocab_size-2": 4376,
        "unique-2": 2505,
        "entropy-2": 10.238470659837832,
        "cond_entropy-2": 2.5188083347200876,
        "distinct-3": 0.36948858397960843,
        "vocab_size-3": 6813,
        "unique-3": 4481,
        "entropy-3": 11.500194819443818,
        "cond_entropy-3": 1.3376472303626468,
        "total_length-nopunct": 17895,
        "mean_pred_length-nopunct": 18.67954070981211,
        "std_pred_length-nopunct": 6.857985227141522,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 97,
        "distinct-1-nopunct": 0.09047219893825091,
        "vocab_size-1-nopunct": 1619,
        "unique-1-nopunct": 764,
        "entropy-1-nopunct": 7.805969932587362,
        "distinct-2-nopunct": 0.24337249808112416,
        "vocab_size-2-nopunct": 4122,
        "unique-2-nopunct": 2439,
        "entropy-2-nopunct": 10.225787549756333,
        "cond_entropy-2-nopunct": 2.5660632969251367,
        "distinct-3-nopunct": 0.397709493710495,
        "vocab_size-3-nopunct": 6355,
        "unique-3-nopunct": 4280,
        "entropy-3-nopunct": 11.524313999480567,
        "cond_entropy-3-nopunct": 1.3933601971121177,
        "msttr-100": 0.64113,
        "msttr-100_nopunct": 0.66652,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5984698214791726
        },
        "rouge1": {
            "precision": 0.64969,
            "recall": 0.61273,
            "fmeasure": 0.61899
        },
        "rouge2": {
            "precision": 0.40971,
            "recall": 0.38484,
            "fmeasure": 0.38935
        },
        "rougeL": {
            "precision": 0.56582,
            "recall": 0.53286,
            "fmeasure": 0.53872
        },
        "rougeLsum": {
            "precision": 0.56582,
            "recall": 0.53286,
            "fmeasure": 0.53872
        },
        "nist": 6.494141863461169,
        "bleu": 31.36234,
        "nubia": {
            "semantic_relation": 4.27858,
            "contradiction": 6.31811,
            "irrelevancy": 17.66813,
            "logical_agreement": 76.01376,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.77337,
            "nubia_score": 0.73111
        },
        "bertscore": {
            "precision": 0.88723,
            "recall": 0.87806,
            "f1": 0.88221
        },
        "meteor": 0.33534779781082297,
        "bleurt": -0.0871
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 72,
        "total_length": 2304,
        "mean_pred_length": 32.0,
        "std_pred_length": 7.779960011322538,
        "median_pred_length": 32.0,
        "min_pred_length": 12,
        "max_pred_length": 56,
        "distinct-1": 0.1701388888888889,
        "vocab_size-1": 392,
        "unique-1": 214,
        "entropy-1": 6.871498719446997,
        "distinct-2": 0.37231182795698925,
        "vocab_size-2": 831,
        "unique-2": 548,
        "entropy-2": 8.639902481332443,
        "cond_entropy-2": 1.7138328501530127,
        "distinct-3": 0.5189814814814815,
        "vocab_size-3": 1121,
        "unique-3": 842,
        "entropy-3": 9.338720837798823,
        "cond_entropy-3": 0.6949713821394234,
        "total_length-nopunct": 2054,
        "mean_pred_length-nopunct": 28.52777777777778,
        "std_pred_length-nopunct": 7.245635127099744,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.18743914313534565,
        "vocab_size-1-nopunct": 385,
        "unique-1-nopunct": 213,
        "entropy-1-nopunct": 6.923440683523073,
        "distinct-2-nopunct": 0.39354187689202824,
        "vocab_size-2-nopunct": 780,
        "unique-2-nopunct": 518,
        "entropy-2-nopunct": 8.601880808365847,
        "cond_entropy-2-nopunct": 1.6919797281215871,
        "distinct-3-nopunct": 0.5413612565445026,
        "vocab_size-3-nopunct": 1034,
        "unique-3-nopunct": 789,
        "entropy-3-nopunct": 9.272431123388868,
        "cond_entropy-3-nopunct": 0.7019167033117379,
        "msttr-100": 0.62174,
        "msttr-100_nopunct": 0.6145,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6326530612244898
        },
        "rouge1": {
            "precision": 0.66722,
            "recall": 0.61176,
            "fmeasure": 0.63233
        },
        "rouge2": {
            "precision": 0.42186,
            "recall": 0.38877,
            "fmeasure": 0.40048
        },
        "rougeL": {
            "precision": 0.52594,
            "recall": 0.48265,
            "fmeasure": 0.49843
        },
        "rougeLsum": {
            "precision": 0.52594,
            "recall": 0.48265,
            "fmeasure": 0.49843
        },
        "nist": 5.838228598437417,
        "bleu": 34.63023,
        "nubia": {
            "semantic_relation": 4.19806,
            "contradiction": 0.92907,
            "irrelevancy": 15.82382,
            "logical_agreement": 83.2471,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.06886,
            "nubia_score": 0.74864
        },
        "bertscore": {
            "precision": 0.89913,
            "recall": 0.88453,
            "f1": 0.89155
        },
        "meteor": 0.3430084907660233,
        "bleurt": -0.05149
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 1024,
        "total_length": 9802,
        "mean_pred_length": 9.572265625,
        "std_pred_length": 5.8144026072713055,
        "median_pred_length": 6.0,
        "min_pred_length": 3,
        "max_pred_length": 35,
        "distinct-1": 0.07263823709447052,
        "vocab_size-1": 712,
        "unique-1": 403,
        "entropy-1": 6.065076260900612,
        "distinct-2": 0.19457735247208932,
        "vocab_size-2": 1708,
        "unique-2": 1060,
        "entropy-2": 8.281265726378725,
        "cond_entropy-2": 1.913485534866381,
        "distinct-3": 0.3153211245808615,
        "vocab_size-3": 2445,
        "unique-3": 1695,
        "entropy-3": 9.219382240499261,
        "cond_entropy-3": 0.9045881240705793,
        "total_length-nopunct": 8303,
        "mean_pred_length-nopunct": 8.1083984375,
        "std_pred_length-nopunct": 5.089911108383678,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.0847886306154402,
        "vocab_size-1-nopunct": 704,
        "unique-1-nopunct": 402,
        "entropy-1-nopunct": 6.275981810885376,
        "distinct-2-nopunct": 0.2121170490451985,
        "vocab_size-2-nopunct": 1544,
        "unique-2-nopunct": 965,
        "entropy-2-nopunct": 8.189702476933116,
        "cond_entropy-2-nopunct": 2.0633912964544616,
        "distinct-3-nopunct": 0.3542765787370104,
        "vocab_size-3-nopunct": 2216,
        "unique-3-nopunct": 1588,
        "entropy-3-nopunct": 9.18104006735991,
        "cond_entropy-3-nopunct": 0.9664765574149153,
        "msttr-100": 0.45286,
        "msttr-100_nopunct": 0.47892,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.41300296020173227
        },
        "rouge1": {
            "precision": 0.42326,
            "recall": 0.38639,
            "fmeasure": 0.39484
        },
        "rouge2": {
            "precision": 0.20481,
            "recall": 0.18974,
            "fmeasure": 0.19248
        },
        "rougeL": {
            "precision": 0.38246,
            "recall": 0.34768,
            "fmeasure": 0.35577
        },
        "rougeLsum": {
            "precision": 0.38246,
            "recall": 0.34768,
            "fmeasure": 0.35577
        },
        "nist": 4.259809237725077,
        "bleu": 23.01681,
        "nubia": {
            "semantic_relation": 2.49015,
            "contradiction": 10.21945,
            "irrelevancy": 27.65043,
            "logical_agreement": 62.13012,
            "grammar_ref": 5.2128,
            "grammar_hyp": 4.95221,
            "nubia_score": 0.42396
        },
        "bertscore": {
            "precision": 0.8518,
            "recall": 0.83741,
            "f1": 0.84418
        },
        "meteor": 0.23741729067447334,
        "bleurt": -0.5719
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "mT5_base/wiki_lingua_spanish_es_test",
        "N": 22632,
        "total_length": 691242,
        "mean_pred_length": 30.54268292682927,
        "std_pred_length": 24.09786842544183,
        "median_pred_length": 23.0,
        "min_pred_length": 1,
        "max_pred_length": 160,
        "distinct-1": 0.01860274693956675,
        "vocab_size-1": 12859,
        "unique-1": 3872,
        "entropy-1": 8.452440633130355,
        "distinct-2": 0.12322130988169486,
        "vocab_size-2": 82387,
        "unique-2": 44782,
        "entropy-2": 13.326034215936584,
        "cond_entropy-2": 4.6925560571309655,
        "distinct-3": 0.32406576054986225,
        "vocab_size-3": 209340,
        "unique-3": 144117,
        "entropy-3": 15.787813393773915,
        "cond_entropy-3": 2.4822634309038345,
        "total_length-nopunct": 570292,
        "mean_pred_length-nopunct": 25.198480028278542,
        "std_pred_length-nopunct": 20.358898074574917,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 128,
        "distinct-1-nopunct": 0.02250601446276644,
        "vocab_size-1-nopunct": 12835,
        "unique-1-nopunct": 3872,
        "entropy-1-nopunct": 9.3815463216165,
        "distinct-2-nopunct": 0.2083595050980163,
        "vocab_size-2-nopunct": 114111,
        "unique-2-nopunct": 72364,
        "entropy-2-nopunct": 14.159485798706564,
        "cond_entropy-2-nopunct": 4.910230876509229,
        "distinct-3-nopunct": 0.435733345522904,
        "vocab_size-3-nopunct": 228777,
        "unique-3-nopunct": 172560,
        "entropy-3-nopunct": 16.458254746397415,
        "cond_entropy-3-nopunct": 2.36437392466307,
        "msttr-100": 0.4136,
        "msttr-100_nopunct": 0.47305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "local_recall": {
            "1": 0.22457918508253882
        },
        "rouge1": {
            "precision": 0.41524,
            "recall": 0.28147,
            "fmeasure": 0.30867
        },
        "rouge2": {
            "precision": 0.14411,
            "recall": 0.09648,
            "fmeasure": 0.10612
        },
        "rougeL": {
            "precision": 0.35367,
            "recall": 0.242,
            "fmeasure": 0.26384
        },
        "rougeLsum": {
            "precision": 0.35367,
            "recall": 0.242,
            "fmeasure": 0.26384
        },
        "nist": 2.8758384026012807,
        "bleu": 7.45038,
        "sari": 67.00953,
        "nubia": {
            "semantic_relation": 2.85804,
            "contradiction": 16.92875,
            "irrelevancy": 34.78736,
            "logical_agreement": 48.28389,
            "grammar_ref": 3.9494,
            "grammar_hyp": 3.4685,
            "nubia_score": 0.39372
        },
        "bertscore": {
            "precision": 0.859,
            "recall": 0.81329,
            "f1": 0.83482
        },
        "meteor": 0.1337035739839359,
        "bleurt": -0.43661
    },
    "wiki_lingua_russian_ru_val": {
        "predictions_file": "mT5_base/wiki_lingua_russian_ru_val",
        "N": 5288,
        "total_length": 138415,
        "mean_pred_length": 26.17530257186082,
        "std_pred_length": 19.921586518187812,
        "median_pred_length": 21.0,
        "min_pred_length": 1,
        "max_pred_length": 146,
        "distinct-1": 0.04263988729545208,
        "vocab_size-1": 5902,
        "unique-1": 1837,
        "entropy-1": 8.20730740521277,
        "distinct-2": 0.19011169785242663,
        "vocab_size-2": 25309,
        "unique-2": 13458,
        "entropy-2": 12.534210878921009,
        "cond_entropy-2": 4.113407199028487,
        "distinct-3": 0.4052565707133917,
        "vocab_size-3": 51808,
        "unique-3": 36026,
        "entropy-3": 14.361205295328988,
        "cond_entropy-3": 1.856161131397246,
        "total_length-nopunct": 114122,
        "mean_pred_length-nopunct": 21.581316187594553,
        "std_pred_length-nopunct": 17.02382771049645,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 112,
        "distinct-1-nopunct": 0.05155009551182068,
        "vocab_size-1-nopunct": 5883,
        "unique-1-nopunct": 1833,
        "entropy-1-nopunct": 9.094212770430053,
        "distinct-2-nopunct": 0.284354441545077,
        "vocab_size-2-nopunct": 30948,
        "unique-2-nopunct": 19714,
        "entropy-2-nopunct": 13.07722328716782,
        "cond_entropy-2-nopunct": 4.1307859674592144,
        "distinct-3-nopunct": 0.5123515210043458,
        "vocab_size-3-nopunct": 53054,
        "unique-3-nopunct": 40359,
        "entropy-3-nopunct": 14.759710282939665,
        "cond_entropy-3-nopunct": 1.749479500777801,
        "msttr-100": 0.43454,
        "msttr-100_nopunct": 0.49939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_val.json",
        "local_recall": {
            "1": 0.1922001438923626
        },
        "rouge1": {
            "precision": 0.39127,
            "recall": 0.23976,
            "fmeasure": 0.27344
        },
        "rouge2": {
            "precision": 0.12524,
            "recall": 0.07564,
            "fmeasure": 0.0869
        },
        "rougeL": {
            "precision": 0.33319,
            "recall": 0.20592,
            "fmeasure": 0.23364
        },
        "rougeLsum": {
            "precision": 0.33319,
            "recall": 0.20592,
            "fmeasure": 0.23364
        },
        "nist": 1.742896925348519,
        "bleu": 5.72814,
        "sari": 67.662,
        "nubia": {
            "semantic_relation": 2.66413,
            "contradiction": 18.64915,
            "irrelevancy": 35.47159,
            "logical_agreement": 45.87926,
            "grammar_ref": 3.95099,
            "grammar_hyp": 3.55275,
            "nubia_score": 0.37419
        },
        "bertscore": {
            "precision": 0.85036,
            "recall": 0.80338,
            "f1": 0.82553
        },
        "meteor": 0.11615928883433516,
        "bleurt": -0.4954
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "mT5_base/wiki_lingua_russian_ru_test",
        "N": 10580,
        "total_length": 275422,
        "mean_pred_length": 26.032325141776937,
        "std_pred_length": 19.78555387728043,
        "median_pred_length": 21.0,
        "min_pred_length": 1,
        "max_pred_length": 148,
        "distinct-1": 0.028476301820479118,
        "vocab_size-1": 7843,
        "unique-1": 2238,
        "entropy-1": 8.293975141846484,
        "distinct-2": 0.14856404950876373,
        "vocab_size-2": 39346,
        "unique-2": 20107,
        "entropy-2": 12.793361718830818,
        "cond_entropy-2": 4.281417604216587,
        "distinct-3": 0.35021218187467307,
        "vocab_size-3": 89046,
        "unique-3": 59495,
        "entropy-3": 14.887967138146449,
        "cond_entropy-3": 2.1235323021995214,
        "total_length-nopunct": 227038,
        "mean_pred_length-nopunct": 21.459168241965973,
        "std_pred_length-nopunct": 16.836204577141995,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 124,
        "distinct-1-nopunct": 0.03446119151860041,
        "vocab_size-1-nopunct": 7824,
        "unique-1-nopunct": 2237,
        "entropy-1-nopunct": 9.196022897839075,
        "distinct-2-nopunct": 0.23515661092118637,
        "vocab_size-2-nopunct": 50902,
        "unique-2-nopunct": 31258,
        "entropy-2-nopunct": 13.439952248477386,
        "cond_entropy-2-nopunct": 4.39777260061069,
        "distinct-3-nopunct": 0.46029317479745874,
        "vocab_size-3-nopunct": 94767,
        "unique-3-nopunct": 69743,
        "entropy-3-nopunct": 15.420502611675884,
        "cond_entropy-3-nopunct": 2.052898360728537,
        "msttr-100": 0.43347,
        "msttr-100_nopunct": 0.497,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "local_recall": {
            "1": 0.19286084234704218
        },
        "rouge1": {
            "precision": 0.39049,
            "recall": 0.24111,
            "fmeasure": 0.27278
        },
        "rouge2": {
            "precision": 0.12532,
            "recall": 0.07641,
            "fmeasure": 0.08648
        },
        "rougeL": {
            "precision": 0.333,
            "recall": 0.20699,
            "fmeasure": 0.23306
        },
        "rougeLsum": {
            "precision": 0.333,
            "recall": 0.20699,
            "fmeasure": 0.23306
        },
        "nist": 1.822245890973893,
        "bleu": 5.89027,
        "sari": 67.60209,
        "nubia": {
            "semantic_relation": 2.66549,
            "contradiction": 18.67222,
            "irrelevancy": 35.00298,
            "logical_agreement": 46.3248,
            "grammar_ref": 3.95647,
            "grammar_hyp": 3.55764,
            "nubia_score": 0.36971
        },
        "bertscore": {
            "precision": 0.85075,
            "recall": 0.80364,
            "f1": 0.82584
        },
        "meteor": 0.11633343863387022,
        "bleurt": -0.49745
    },
    "wiki_lingua_turkish_tr_val": {
        "predictions_file": "mT5_base/wiki_lingua_turkish_tr_val",
        "N": 449,
        "total_length": 15227,
        "mean_pred_length": 33.91314031180401,
        "std_pred_length": 17.948181566430616,
        "median_pred_length": 31.0,
        "min_pred_length": 4,
        "max_pred_length": 107,
        "distinct-1": 0.15242661062586196,
        "vocab_size-1": 2321,
        "unique-1": 1106,
        "entropy-1": 8.176992117855663,
        "distinct-2": 0.49343618892948976,
        "vocab_size-2": 7292,
        "unique-2": 5140,
        "entropy-2": 11.898861726002206,
        "cond_entropy-2": 3.5627383529732906,
        "distinct-3": 0.7419219764114733,
        "vocab_size-3": 10631,
        "unique-3": 8823,
        "entropy-3": 13.03986405532852,
        "cond_entropy-3": 1.154299129566759,
        "total_length-nopunct": 12821,
        "mean_pred_length-nopunct": 28.55456570155902,
        "std_pred_length-nopunct": 15.637522199351649,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 97,
        "distinct-1-nopunct": 0.18017315342017004,
        "vocab_size-1-nopunct": 2310,
        "unique-1-nopunct": 1105,
        "entropy-1-nopunct": 8.878174675544319,
        "distinct-2-nopunct": 0.5909311348205626,
        "vocab_size-2-nopunct": 7311,
        "unique-2-nopunct": 5522,
        "entropy-2-nopunct": 12.200141613286837,
        "cond_entropy-2-nopunct": 3.41123197161278,
        "distinct-3-nopunct": 0.827811792334144,
        "vocab_size-3-nopunct": 9870,
        "unique-3-nopunct": 8604,
        "entropy-3-nopunct": 13.096000038764865,
        "cond_entropy-3-nopunct": 0.9160116792487341,
        "msttr-100": 0.58079,
        "msttr-100_nopunct": 0.6518,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_val.json",
        "local_recall": {
            "1": 0.28959235209235207
        },
        "rouge1": {
            "precision": 0.36119,
            "recall": 0.31837,
            "fmeasure": 0.31438
        },
        "rouge2": {
            "precision": 0.14491,
            "recall": 0.13611,
            "fmeasure": 0.13184
        },
        "rougeL": {
            "precision": 0.2952,
            "recall": 0.26358,
            "fmeasure": 0.25884
        },
        "rougeLsum": {
            "precision": 0.2952,
            "recall": 0.26358,
            "fmeasure": 0.25884
        },
        "nist": 3.3683772866136605,
        "bleu": 14.53953,
        "sari": 68.11222,
        "nubia": {
            "semantic_relation": 2.38448,
            "contradiction": 26.63823,
            "irrelevancy": 49.20646,
            "logical_agreement": 24.15531,
            "grammar_ref": 3.85457,
            "grammar_hyp": 3.85423,
            "nubia_score": 0.28914
        },
        "bertscore": {
            "precision": 0.83756,
            "recall": 0.82479,
            "f1": 0.83058
        },
        "meteor": 0.15642439956518403,
        "bleurt": -0.533
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.95238,
            "recall": 0.33542,
            "fmeasure": 0.4953
        },
        "rouge2": {
            "precision": 0.36111,
            "recall": 0.11374,
            "fmeasure": 0.1728
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.23363,
            "fmeasure": 0.34551
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.23363,
            "fmeasure": 0.34551
        },
        "nist": 0.09756476838793274,
        "bleu": 6.73087,
        "nubia": {
            "semantic_relation": 3.39689,
            "contradiction": 5.06003,
            "irrelevancy": 31.89654,
            "logical_agreement": 63.04343,
            "grammar_ref": 4.80653,
            "grammar_hyp": 6.22872,
            "nubia_score": 0.28087
        },
        "bertscore": {
            "precision": 0.94464,
            "recall": 0.8045,
            "f1": 0.86277
        },
        "meteor": 0.21038745623977342,
        "bleurt": -0.24992
    },
    "web_nlg_en_challenge_test_scramble_parent": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 500,
        "total_length": 12475,
        "mean_pred_length": 24.95,
        "std_pred_length": 13.032401927503617,
        "median_pred_length": 24.0,
        "min_pred_length": 6,
        "max_pred_length": 93,
        "distinct-1": 0.10324649298597194,
        "vocab_size-1": 1288,
        "unique-1": 426,
        "entropy-1": 7.806319896487727,
        "distinct-2": 0.3040501043841336,
        "vocab_size-2": 3641,
        "unique-2": 1892,
        "entropy-2": 10.825952567453598,
        "cond_entropy-2": 2.8606253136528434,
        "distinct-3": 0.4841830065359477,
        "vocab_size-3": 5556,
        "unique-3": 3608,
        "entropy-3": 11.868166419722003,
        "cond_entropy-3": 1.0993788128253428,
        "total_length-nopunct": 11036,
        "mean_pred_length-nopunct": 22.072,
        "std_pred_length-nopunct": 11.740818370113729,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.11589343965204785,
        "vocab_size-1-nopunct": 1279,
        "unique-1-nopunct": 426,
        "entropy-1-nopunct": 8.074760570697586,
        "distinct-2-nopunct": 0.3204252088078967,
        "vocab_size-2-nopunct": 3376,
        "unique-2-nopunct": 1836,
        "entropy-2-nopunct": 10.733096212342303,
        "cond_entropy-2-nopunct": 2.7951034383021414,
        "distinct-3-nopunct": 0.5011956954962137,
        "vocab_size-3-nopunct": 5030,
        "unique-3-nopunct": 3369,
        "entropy-3-nopunct": 11.7323087902886,
        "cond_entropy-3-nopunct": 1.0488071824501883,
        "msttr-100": 0.51161,
        "msttr-100_nopunct": 0.51855,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2192132832575608,
            "2": 0.5676959619952494,
            "3": 0.8057217651458489,
            "4": 0.4,
            "5": 0.6111111111111112
        },
        "rouge1": {
            "precision": 0.70486,
            "recall": 0.70695,
            "fmeasure": 0.69729
        },
        "rouge2": {
            "precision": 0.45001,
            "recall": 0.44827,
            "fmeasure": 0.44331
        },
        "rougeL": {
            "precision": 0.56006,
            "recall": 0.5623,
            "fmeasure": 0.55423
        },
        "rougeLsum": {
            "precision": 0.56006,
            "recall": 0.5623,
            "fmeasure": 0.55423
        },
        "nist": 8.008834124887194,
        "bleu": 41.92972,
        "nubia": {
            "semantic_relation": 4.14117,
            "contradiction": 15.00774,
            "irrelevancy": 11.58043,
            "logical_agreement": 73.41183,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.59964,
            "nubia_score": 0.70074
        },
        "bertscore": {
            "precision": 0.90362,
            "recall": 0.90456,
            "f1": 0.90271
        },
        "meteor": 0.3540857837478062,
        "bleurt": 0.04098
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "mT5_base/wiki_lingua_turkish_tr_test",
        "N": 900,
        "total_length": 32312,
        "mean_pred_length": 35.90222222222222,
        "std_pred_length": 18.737644686434358,
        "median_pred_length": 33.0,
        "min_pred_length": 4,
        "max_pred_length": 115,
        "distinct-1": 0.1051931171081951,
        "vocab_size-1": 3399,
        "unique-1": 1411,
        "entropy-1": 8.27463375082287,
        "distinct-2": 0.38810008913790905,
        "vocab_size-2": 12191,
        "unique-2": 7708,
        "entropy-2": 12.27631405588925,
        "cond_entropy-2": 3.851087572688669,
        "distinct-3": 0.6362742527530152,
        "vocab_size-3": 19414,
        "unique-3": 14879,
        "entropy-3": 13.696935701063298,
        "cond_entropy-3": 1.4310467328491958,
        "total_length-nopunct": 27182,
        "mean_pred_length-nopunct": 30.202222222222222,
        "std_pred_length-nopunct": 16.210257231338833,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 101,
        "distinct-1-nopunct": 0.12453093959237731,
        "vocab_size-1-nopunct": 3385,
        "unique-1-nopunct": 1410,
        "entropy-1-nopunct": 8.995996181230929,
        "distinct-2-nopunct": 0.48242142911498365,
        "vocab_size-2-nopunct": 12679,
        "unique-2-nopunct": 8681,
        "entropy-2-nopunct": 12.703535849837504,
        "cond_entropy-2-nopunct": 3.7904535259621914,
        "distinct-3-nopunct": 0.7324481916318651,
        "vocab_size-3-nopunct": 18591,
        "unique-3-nopunct": 14974,
        "entropy-3-nopunct": 13.883234363265899,
        "cond_entropy-3-nopunct": 1.1994997574383766,
        "msttr-100": 0.57991,
        "msttr-100_nopunct": 0.65151,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "local_recall": {
            "1": 0.30491270807957777
        },
        "rouge1": {
            "precision": 0.36024,
            "recall": 0.32783,
            "fmeasure": 0.32042
        },
        "rouge2": {
            "precision": 0.14443,
            "recall": 0.1335,
            "fmeasure": 0.13061
        },
        "rougeL": {
            "precision": 0.29141,
            "recall": 0.26667,
            "fmeasure": 0.25988
        },
        "rougeLsum": {
            "precision": 0.29141,
            "recall": 0.26667,
            "fmeasure": 0.25988
        },
        "nist": 3.6238464631468457,
        "bleu": 14.86094,
        "sari": 67.39995,
        "nubia": {
            "semantic_relation": 2.41066,
            "contradiction": 25.83091,
            "irrelevancy": 49.51657,
            "logical_agreement": 24.65252,
            "grammar_ref": 3.87672,
            "grammar_hyp": 3.84118,
            "nubia_score": 0.28759
        },
        "bertscore": {
            "precision": 0.83716,
            "recall": 0.82824,
            "f1": 0.83215
        },
        "meteor": 0.163090682144569,
        "bleurt": -0.5126
    },
    "web_nlg_en_challenge_test_numbers_parent": {
        "predictions_file": "mT5_base/web_nlg_en_test",
        "N": 500,
        "total_length": 12779,
        "mean_pred_length": 25.558,
        "std_pred_length": 12.745926251159624,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 93,
        "distinct-1": 0.10235542687221222,
        "vocab_size-1": 1308,
        "unique-1": 455,
        "entropy-1": 7.812637363285168,
        "distinct-2": 0.2994543529603388,
        "vocab_size-2": 3677,
        "unique-2": 1908,
        "entropy-2": 10.818600533606155,
        "cond_entropy-2": 2.8519666972112776,
        "distinct-3": 0.47610153663299093,
        "vocab_size-3": 5608,
        "unique-3": 3623,
        "entropy-3": 11.851525047930917,
        "cond_entropy-3": 1.0922736437511396,
        "total_length-nopunct": 11353,
        "mean_pred_length-nopunct": 22.706,
        "std_pred_length-nopunct": 11.47743717037911,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 73,
        "distinct-1-nopunct": 0.11441909627411256,
        "vocab_size-1-nopunct": 1299,
        "unique-1-nopunct": 455,
        "entropy-1-nopunct": 8.057190188294708,
        "distinct-2-nopunct": 0.31088178383856996,
        "vocab_size-2-nopunct": 3374,
        "unique-2-nopunct": 1796,
        "entropy-2-nopunct": 10.712442326966144,
        "cond_entropy-2-nopunct": 2.7882219807222453,
        "distinct-3-nopunct": 0.49212788563701343,
        "vocab_size-3-nopunct": 5095,
        "unique-3-nopunct": 3389,
        "entropy-3-nopunct": 11.71878637234091,
        "cond_entropy-3-nopunct": 1.0547439848908884,
        "msttr-100": 0.6237,
        "msttr-100_nopunct": 0.66044,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23269914279740747,
            "2": 0.566219470244238,
            "3": 0.8110772539881699,
            "4": 0.5555555555555556,
            "5": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.70579,
            "recall": 0.71111,
            "fmeasure": 0.69928
        },
        "rouge2": {
            "precision": 0.44793,
            "recall": 0.44965,
            "fmeasure": 0.44259
        },
        "rougeL": {
            "precision": 0.5558,
            "recall": 0.56163,
            "fmeasure": 0.55123
        },
        "rougeLsum": {
            "precision": 0.5558,
            "recall": 0.56163,
            "fmeasure": 0.55123
        },
        "nist": 8.032228859945732,
        "bleu": 42.89658,
        "nubia": {
            "semantic_relation": 4.09619,
            "contradiction": 17.41834,
            "irrelevancy": 12.52365,
            "logical_agreement": 70.05801,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.5006,
            "nubia_score": 0.6902
        },
        "bertscore": {
            "precision": 0.90333,
            "recall": 0.90394,
            "f1": 0.90206
        },
        "meteor": 0.35809913898290696,
        "bleurt": 0.0188
    },
    "wiki_lingua_vietnamese_vi_val": {
        "predictions_file": "mT5_base/wiki_lingua_vietnamese_vi_val",
        "N": 1957,
        "total_length": 55109,
        "mean_pred_length": 28.159938681655596,
        "std_pred_length": 18.001063660059977,
        "median_pred_length": 24.0,
        "min_pred_length": 3,
        "max_pred_length": 127,
        "distinct-1": 0.06655900125206408,
        "vocab_size-1": 3668,
        "unique-1": 1222,
        "entropy-1": 8.167737730894062,
        "distinct-2": 0.24655704394942807,
        "vocab_size-2": 13105,
        "unique-2": 6794,
        "entropy-2": 12.098136840738043,
        "cond_entropy-2": 3.7304206588771285,
        "distinct-3": 0.4562750268580916,
        "vocab_size-3": 23359,
        "unique-3": 15710,
        "entropy-3": 13.598845787374715,
        "cond_entropy-3": 1.524993413342008,
        "total_length-nopunct": 45678,
        "mean_pred_length-nopunct": 23.340827797649464,
        "std_pred_length-nopunct": 15.603867094341982,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 108,
        "distinct-1-nopunct": 0.08001663820657647,
        "vocab_size-1-nopunct": 3655,
        "unique-1-nopunct": 1220,
        "entropy-1-nopunct": 9.006608237571442,
        "distinct-2-nopunct": 0.3383499919946936,
        "vocab_size-2-nopunct": 14793,
        "unique-2-nopunct": 9060,
        "entropy-2-nopunct": 12.541842031051537,
        "cond_entropy-2-nopunct": 3.657027852243634,
        "distinct-3-nopunct": 0.5588545158509721,
        "vocab_size-3-nopunct": 23340,
        "unique-3-nopunct": 17243,
        "entropy-3-nopunct": 13.85334053425989,
        "cond_entropy-3-nopunct": 1.3562726812541042,
        "msttr-100": 0.44948,
        "msttr-100_nopunct": 0.51182,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_val.json",
        "local_recall": {
            "1": 0.18727690477167358
        },
        "rouge1": {
            "precision": 0.328,
            "recall": 0.22819,
            "fmeasure": 0.2488
        },
        "rouge2": {
            "precision": 0.09543,
            "recall": 0.06798,
            "fmeasure": 0.07294
        },
        "rougeL": {
            "precision": 0.27413,
            "recall": 0.19258,
            "fmeasure": 0.20867
        },
        "rougeLsum": {
            "precision": 0.27413,
            "recall": 0.19258,
            "fmeasure": 0.20867
        },
        "nist": 2.0904510239969247,
        "bleu": 5.99215,
        "sari": 65.66163,
        "nubia": {
            "semantic_relation": 2.53846,
            "contradiction": 19.4531,
            "irrelevancy": 38.49057,
            "logical_agreement": 42.05632,
            "grammar_ref": 3.90718,
            "grammar_hyp": 3.39234,
            "nubia_score": 0.33935
        },
        "bertscore": {
            "precision": 0.83902,
            "recall": 0.80109,
            "f1": 0.81901
        },
        "meteor": 0.11646967274391619,
        "bleurt": -0.50452
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 1246,
        "total_length": 18425,
        "mean_pred_length": 14.787319422150883,
        "std_pred_length": 5.005826432465101,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 37,
        "distinct-1": 0.09888738127544097,
        "vocab_size-1": 1822,
        "unique-1": 862,
        "entropy-1": 7.824139036703857,
        "distinct-2": 0.26666278595960186,
        "vocab_size-2": 4581,
        "unique-2": 2675,
        "entropy-2": 10.386833841779055,
        "cond_entropy-2": 2.3508032253237783,
        "distinct-3": 0.413544216406201,
        "vocab_size-3": 6589,
        "unique-3": 4421,
        "entropy-3": 11.524270160412799,
        "cond_entropy-3": 1.1984165766999295,
        "total_length-nopunct": 16499,
        "mean_pred_length-nopunct": 13.241573033707866,
        "std_pred_length-nopunct": 4.542141407849786,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.10952178919934541,
        "vocab_size-1-nopunct": 1807,
        "unique-1-nopunct": 860,
        "entropy-1-nopunct": 7.976891205558109,
        "distinct-2-nopunct": 0.2727987936799318,
        "vocab_size-2-nopunct": 4161,
        "unique-2-nopunct": 2499,
        "entropy-2-nopunct": 10.22222108391726,
        "cond_entropy-2-nopunct": 2.4061871608448206,
        "distinct-3-nopunct": 0.42393089169700865,
        "vocab_size-3-nopunct": 5938,
        "unique-3-nopunct": 4061,
        "entropy-3-nopunct": 11.364642953755883,
        "cond_entropy-3-nopunct": 1.2446064248940634,
        "msttr-100": 0.655,
        "msttr-100_nopunct": 0.67451,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6354253669013245
        },
        "rouge1": {
            "precision": 0.7063,
            "recall": 0.66441,
            "fmeasure": 0.67305
        },
        "rouge2": {
            "precision": 0.49674,
            "recall": 0.46592,
            "fmeasure": 0.47177
        },
        "rougeL": {
            "precision": 0.62163,
            "recall": 0.58469,
            "fmeasure": 0.59272
        },
        "rougeLsum": {
            "precision": 0.62163,
            "recall": 0.58469,
            "fmeasure": 0.59272
        },
        "nist": 7.291843278265927,
        "bleu": 38.58405,
        "nubia": {
            "semantic_relation": 4.32221,
            "contradiction": 6.81019,
            "irrelevancy": 20.07483,
            "logical_agreement": 73.11498,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.763,
            "nubia_score": 0.7796
        },
        "bertscore": {
            "precision": 0.90355,
            "recall": 0.88979,
            "f1": 0.89618
        },
        "meteor": 0.36680557666995023,
        "bleurt": -0.00558
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 500,
        "total_length": 4149,
        "mean_pred_length": 8.298,
        "std_pred_length": 1.4273037518342058,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 12,
        "distinct-1": 0.015184381778741865,
        "vocab_size-1": 63,
        "unique-1": 9,
        "entropy-1": 4.606670788469379,
        "distinct-2": 0.0457659632776103,
        "vocab_size-2": 167,
        "unique-2": 38,
        "entropy-2": 5.806648799926797,
        "cond_entropy-2": 0.9923718401374488,
        "distinct-3": 0.08447126071768815,
        "vocab_size-3": 266,
        "unique-3": 84,
        "entropy-3": 6.3145651849401485,
        "cond_entropy-3": 0.6109264319671571,
        "total_length-nopunct": 3652,
        "mean_pred_length-nopunct": 7.304,
        "std_pred_length-nopunct": 1.4239325826737728,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.016976998904709748,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 4.632883263891786,
        "distinct-2-nopunct": 0.04663705583756345,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.494491164400947,
        "cond_entropy-2-nopunct": 1.045653352036408,
        "distinct-3-nopunct": 0.08408748114630468,
        "vocab_size-3-nopunct": 223,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 5.948674551322247,
        "cond_entropy-3-nopunct": 0.6758719269072757,
        "msttr-100": 0.2961,
        "msttr-100_nopunct": 0.30222,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5181842314839394
        },
        "rouge1": {
            "precision": 0.55934,
            "recall": 0.52968,
            "fmeasure": 0.53613
        },
        "rouge2": {
            "precision": 0.32298,
            "recall": 0.30222,
            "fmeasure": 0.30704
        },
        "rougeL": {
            "precision": 0.53726,
            "recall": 0.5101,
            "fmeasure": 0.51572
        },
        "rougeLsum": {
            "precision": 0.53726,
            "recall": 0.5101,
            "fmeasure": 0.51572
        },
        "nist": 3.5627316290753437,
        "bleu": 27.2371,
        "nubia": {
            "semantic_relation": 3.66774,
            "contradiction": 6.53586,
            "irrelevancy": 19.22028,
            "logical_agreement": 74.24386,
            "grammar_ref": 4.43492,
            "grammar_hyp": 3.83992,
            "nubia_score": 0.72595
        },
        "bertscore": {
            "precision": 0.88837,
            "recall": 0.88341,
            "f1": 0.88558
        },
        "meteor": 0.28698442413951514,
        "bleurt": 0.09779
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 2078,
        "total_length": 21058,
        "mean_pred_length": 10.133782483156882,
        "std_pred_length": 5.4431530870628935,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 52,
        "distinct-1": 0.020277329281033336,
        "vocab_size-1": 427,
        "unique-1": 118,
        "entropy-1": 6.11192030335316,
        "distinct-2": 0.08888303477344574,
        "vocab_size-2": 1687,
        "unique-2": 669,
        "entropy-2": 8.62226765533478,
        "cond_entropy-2": 2.205979252613889,
        "distinct-3": 0.1824636137735179,
        "vocab_size-3": 3084,
        "unique-3": 1621,
        "entropy-3": 9.794092011969129,
        "cond_entropy-3": 1.2548750790142467,
        "total_length-nopunct": 18285,
        "mean_pred_length-nopunct": 8.799326275264677,
        "std_pred_length-nopunct": 4.9079750394501716,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.023079026524473613,
        "vocab_size-1-nopunct": 422,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.280631768615942,
        "distinct-2-nopunct": 0.09779724810267168,
        "vocab_size-2-nopunct": 1585,
        "unique-2-nopunct": 715,
        "entropy-2-nopunct": 8.343692867737268,
        "cond_entropy-2-nopunct": 2.2710317020048767,
        "distinct-3-nopunct": 0.19290920670865472,
        "vocab_size-3-nopunct": 2726,
        "unique-3-nopunct": 1527,
        "entropy-3-nopunct": 9.496330970901873,
        "cond_entropy-3-nopunct": 1.2774063348212197,
        "msttr-100": 0.491,
        "msttr-100_nopunct": 0.51159,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4192062917162519
        },
        "rouge1": {
            "precision": 0.47941,
            "recall": 0.42873,
            "fmeasure": 0.43729
        },
        "rouge2": {
            "precision": 0.24296,
            "recall": 0.22047,
            "fmeasure": 0.2219
        },
        "rougeL": {
            "precision": 0.44002,
            "recall": 0.39518,
            "fmeasure": 0.40256
        },
        "rougeLsum": {
            "precision": 0.44002,
            "recall": 0.39518,
            "fmeasure": 0.40256
        },
        "nist": 3.564780098518408,
        "bleu": 17.12959,
        "nubia": {
            "semantic_relation": 3.07337,
            "contradiction": 13.42496,
            "irrelevancy": 23.61847,
            "logical_agreement": 62.95657,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.32902,
            "nubia_score": 0.52588
        },
        "bertscore": {
            "precision": 0.84856,
            "recall": 0.83352,
            "f1": 0.84019
        },
        "meteor": 0.2295856690968344,
        "bleurt": -0.27595
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "mT5_base/schema_guided_dialog_test",
        "N": 715,
        "total_length": 6948,
        "mean_pred_length": 9.717482517482518,
        "std_pred_length": 3.2211997653073365,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 25,
        "distinct-1": 0.013097294185377088,
        "vocab_size-1": 91,
        "unique-1": 20,
        "entropy-1": 4.203171021316269,
        "distinct-2": 0.0333707684902936,
        "vocab_size-2": 208,
        "unique-2": 70,
        "entropy-2": 5.02065933156274,
        "cond_entropy-2": 0.7135824053996997,
        "distinct-3": 0.050743022834360274,
        "vocab_size-3": 280,
        "unique-3": 112,
        "entropy-3": 5.270964000448197,
        "cond_entropy-3": 0.23094013561228013,
        "total_length-nopunct": 6140,
        "mean_pred_length-nopunct": 8.587412587412587,
        "std_pred_length-nopunct": 2.82280590289803,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.014332247557003257,
        "vocab_size-1-nopunct": 88,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.081549965268669,
        "distinct-2-nopunct": 0.0352073732718894,
        "vocab_size-2-nopunct": 191,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 4.785344532487552,
        "cond_entropy-2-nopunct": 0.6475714516611089,
        "distinct-3-nopunct": 0.054140127388535034,
        "vocab_size-3-nopunct": 255,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 5.038001701215948,
        "cond_entropy-3-nopunct": 0.1701238685154681,
        "msttr-100": 0.22014,
        "msttr-100_nopunct": 0.20754,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5847837789341468
        },
        "rouge1": {
            "precision": 0.54674,
            "recall": 0.59232,
            "fmeasure": 0.55691
        },
        "rouge2": {
            "precision": 0.2897,
            "recall": 0.30544,
            "fmeasure": 0.29023
        },
        "rougeL": {
            "precision": 0.45237,
            "recall": 0.48596,
            "fmeasure": 0.45872
        },
        "rougeLsum": {
            "precision": 0.45237,
            "recall": 0.48596,
            "fmeasure": 0.45872
        },
        "nist": 2.8852832850249066,
        "bleu": 24.98689,
        "nubia": {
            "semantic_relation": 3.70782,
            "contradiction": 0.82389,
            "irrelevancy": 23.16731,
            "logical_agreement": 76.0088,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.26037,
            "nubia_score": 0.77541
        },
        "bertscore": {
            "precision": 0.85571,
            "recall": 0.86516,
            "f1": 0.85988
        },
        "meteor": 0.2940007264276495,
        "bleurt": 0.22502
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 106,
        "total_length": 2309,
        "mean_pred_length": 21.78301886792453,
        "std_pred_length": 4.414822197708515,
        "median_pred_length": 22.0,
        "min_pred_length": 7,
        "max_pred_length": 34,
        "distinct-1": 0.40233867475097446,
        "vocab_size-1": 929,
        "unique-1": 683,
        "entropy-1": 8.32341196300179,
        "distinct-2": 0.8356786200635498,
        "vocab_size-2": 1841,
        "unique-2": 1672,
        "entropy-2": 10.638246529603835,
        "cond_entropy-2": 2.128226452331983,
        "distinct-3": 0.9647114926084883,
        "vocab_size-3": 2023,
        "unique-3": 1969,
        "entropy-3": 10.950155441543668,
        "cond_entropy-3": 0.31357928318850714,
        "total_length-nopunct": 2135,
        "mean_pred_length-nopunct": 20.141509433962263,
        "std_pred_length-nopunct": 4.133249165608739,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.4309133489461358,
        "vocab_size-1-nopunct": 920,
        "unique-1-nopunct": 681,
        "entropy-1-nopunct": 8.450485364663429,
        "distinct-2-nopunct": 0.8472153770330212,
        "vocab_size-2-nopunct": 1719,
        "unique-2-nopunct": 1572,
        "entropy-2-nopunct": 10.555884087564161,
        "cond_entropy-2-nopunct": 2.1869460896505517,
        "distinct-3-nopunct": 0.9729589183567343,
        "vocab_size-3-nopunct": 1871,
        "unique-3-nopunct": 1827,
        "entropy-3-nopunct": 10.850966082711318,
        "cond_entropy-3-nopunct": 0.29606797179289523,
        "msttr-100": 0.72478,
        "msttr-100_nopunct": 0.7481,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.40395337050177393
        },
        "rouge1": {
            "precision": 0.42168,
            "recall": 0.42769,
            "fmeasure": 0.41462
        },
        "rouge2": {
            "precision": 0.18794,
            "recall": 0.19207,
            "fmeasure": 0.1854
        },
        "rougeL": {
            "precision": 0.33682,
            "recall": 0.34271,
            "fmeasure": 0.33169
        },
        "rougeLsum": {
            "precision": 0.33682,
            "recall": 0.34271,
            "fmeasure": 0.33169
        },
        "nist": 3.688427361283483,
        "bleu": 14.19265,
        "nubia": {
            "semantic_relation": 3.00103,
            "contradiction": 17.28689,
            "irrelevancy": 67.94557,
            "logical_agreement": 14.76754,
            "grammar_ref": 3.74062,
            "grammar_hyp": 3.68524,
            "nubia_score": 0.44043
        },
        "bertscore": {
            "precision": 0.84024,
            "recall": 0.83503,
            "f1": 0.83725
        },
        "meteor": 0.19686909147307005,
        "bleurt": -0.29277
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.11905,
            "recall": 0.59028,
            "fmeasure": 0.19804
        },
        "rouge2": {
            "precision": 0.04819,
            "recall": 0.25098,
            "fmeasure": 0.08082
        },
        "rougeL": {
            "precision": 0.10714,
            "recall": 0.53125,
            "fmeasure": 0.17824
        },
        "rougeLsum": {
            "precision": 0.10714,
            "recall": 0.53125,
            "fmeasure": 0.17824
        },
        "nist": 0.3263438716344561,
        "bleu": 1.76974,
        "nubia": {
            "semantic_relation": 4.04269,
            "contradiction": 2.95759,
            "irrelevancy": 6.56768,
            "logical_agreement": 90.47473,
            "grammar_ref": 4.60656,
            "grammar_hyp": 0.96077,
            "nubia_score": 0.40907
        },
        "bertscore": {
            "precision": 0.69543,
            "recall": 0.85343,
            "f1": 0.76637
        },
        "meteor": 0.16159679096063995,
        "bleurt": -0.05889
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "mT5_base/xsum_test",
        "N": 106,
        "total_length": 2296,
        "mean_pred_length": 21.660377358490567,
        "std_pred_length": 4.580283406517075,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 38,
        "distinct-1": 0.3902439024390244,
        "vocab_size-1": 896,
        "unique-1": 657,
        "entropy-1": 8.228955779266556,
        "distinct-2": 0.8223744292237443,
        "vocab_size-2": 1801,
        "unique-2": 1622,
        "entropy-2": 10.583168583668419,
        "cond_entropy-2": 2.1706745639646243,
        "distinct-3": 0.960172744721689,
        "vocab_size-3": 2001,
        "unique-3": 1940,
        "entropy-3": 10.929701053166042,
        "cond_entropy-3": 0.3558493536138663,
        "total_length-nopunct": 2132,
        "mean_pred_length-nopunct": 20.11320754716981,
        "std_pred_length-nopunct": 4.4368116095695305,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.4169793621013133,
        "vocab_size-1-nopunct": 889,
        "unique-1-nopunct": 656,
        "entropy-1-nopunct": 8.357505909540167,
        "distinct-2-nopunct": 0.8297137216189536,
        "vocab_size-2-nopunct": 1681,
        "unique-2-nopunct": 1518,
        "entropy-2-nopunct": 10.493666552532071,
        "cond_entropy-2-nopunct": 2.2282414839415297,
        "distinct-3-nopunct": 0.9682291666666667,
        "vocab_size-3-nopunct": 1859,
        "unique-3-nopunct": 1807,
        "entropy-3-nopunct": 10.83859923338,
        "cond_entropy-3-nopunct": 0.3496959095374081,
        "msttr-100": 0.71773,
        "msttr-100_nopunct": 0.74571,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3699668403600189
        },
        "rouge1": {
            "precision": 0.42111,
            "recall": 0.3946,
            "fmeasure": 0.39967
        },
        "rouge2": {
            "precision": 0.17551,
            "recall": 0.16541,
            "fmeasure": 0.16663
        },
        "rougeL": {
            "precision": 0.32822,
            "recall": 0.30885,
            "fmeasure": 0.31235
        },
        "rougeLsum": {
            "precision": 0.32822,
            "recall": 0.30885,
            "fmeasure": 0.31235
        },
        "nist": 3.497752921416247,
        "bleu": 10.83331,
        "nubia": {
            "semantic_relation": 2.88926,
            "contradiction": 29.75501,
            "irrelevancy": 59.95318,
            "logical_agreement": 10.29182,
            "grammar_ref": 3.75111,
            "grammar_hyp": 3.72176,
            "nubia_score": 0.41187
        },
        "bertscore": {
            "precision": 0.83773,
            "recall": 0.82602,
            "f1": 0.83151
        },
        "meteor": 0.18769037841900382,
        "bleurt": -0.29635
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7867,
        "mean_pred_length": 21.91364902506964,
        "std_pred_length": 9.115220843732748,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.3683742214312953,
        "vocab_size-1": 2898,
        "unique-1": 2115,
        "entropy-1": 9.25569495775647,
        "distinct-2": 0.8329781566329248,
        "vocab_size-2": 6254,
        "unique-2": 5782,
        "entropy-2": 12.273958823776688,
        "cond_entropy-2": 2.780509633542581,
        "distinct-3": 0.9630717582878724,
        "vocab_size-3": 6885,
        "unique-3": 6757,
        "entropy-3": 12.675655854825958,
        "cond_entropy-3": 0.41767670933395173,
        "total_length-nopunct": 6935,
        "mean_pred_length-nopunct": 19.317548746518106,
        "std_pred_length-nopunct": 8.003446235936336,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4161499639509733,
        "vocab_size-1-nopunct": 2886,
        "unique-1-nopunct": 2112,
        "entropy-1-nopunct": 9.622147464008012,
        "distinct-2-nopunct": 0.8622262773722628,
        "vocab_size-2-nopunct": 5670,
        "unique-2-nopunct": 5286,
        "entropy-2-nopunct": 12.21947682942681,
        "cond_entropy-2-nopunct": 2.725804687530003,
        "distinct-3-nopunct": 0.982628277304166,
        "vocab_size-3-nopunct": 6109,
        "unique-3-nopunct": 6018,
        "entropy-3-nopunct": 12.564821181777965,
        "cond_entropy-3-nopunct": 0.3653786532626024,
        "msttr-100": 0.72846,
        "msttr-100_nopunct": 0.77101,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03252480705622933,
            "2": 0.18396226415094338,
            "3": 0.42168674698795183,
            "4": 0.6253822629969419,
            "5": 0.7496206373292867,
            "6": 0.8816901408450705,
            "7": 0.9330601092896175,
            "8": 0.9517490952955368,
            "9": 0.9608465608465608,
            "10": 0.9868217054263566
        },
        "rouge1": {
            "precision": 0.90089,
            "recall": 0.92456,
            "fmeasure": 0.90926
        },
        "rouge2": {
            "precision": 0.80979,
            "recall": 0.84003,
            "fmeasure": 0.82018
        },
        "rougeL": {
            "precision": 0.89107,
            "recall": 0.91565,
            "fmeasure": 0.89985
        },
        "rougeLsum": {
            "precision": 0.89107,
            "recall": 0.91565,
            "fmeasure": 0.89985
        },
        "nist": 13.468596381208068,
        "bleu": 87.8592,
        "nubia": {
            "semantic_relation": 4.43317,
            "contradiction": 2.39277,
            "irrelevancy": 33.77215,
            "logical_agreement": 63.83507,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.69498,
            "nubia_score": 0.70724
        },
        "bertscore": {
            "precision": 0.97415,
            "recall": 0.98213,
            "f1": 0.9761
        },
        "meteor": 0.5658096710191454,
        "bleurt": 0.32233
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7867,
        "mean_pred_length": 21.91364902506964,
        "std_pred_length": 9.115220843732748,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.3683742214312953,
        "vocab_size-1": 2898,
        "unique-1": 2115,
        "entropy-1": 9.25569495775647,
        "distinct-2": 0.8329781566329248,
        "vocab_size-2": 6254,
        "unique-2": 5782,
        "entropy-2": 12.273958823776688,
        "cond_entropy-2": 2.780509633542581,
        "distinct-3": 0.9630717582878724,
        "vocab_size-3": 6885,
        "unique-3": 6757,
        "entropy-3": 12.675655854825958,
        "cond_entropy-3": 0.41767670933395173,
        "total_length-nopunct": 6935,
        "mean_pred_length-nopunct": 19.317548746518106,
        "std_pred_length-nopunct": 8.003446235936336,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4161499639509733,
        "vocab_size-1-nopunct": 2886,
        "unique-1-nopunct": 2112,
        "entropy-1-nopunct": 9.622147464008012,
        "distinct-2-nopunct": 0.8622262773722628,
        "vocab_size-2-nopunct": 5670,
        "unique-2-nopunct": 5286,
        "entropy-2-nopunct": 12.21947682942681,
        "cond_entropy-2-nopunct": 2.725804687530003,
        "distinct-3-nopunct": 0.982628277304166,
        "vocab_size-3-nopunct": 6109,
        "unique-3-nopunct": 6018,
        "entropy-3-nopunct": 12.564821181777965,
        "cond_entropy-3-nopunct": 0.3653786532626024,
        "msttr-100": 0.72846,
        "msttr-100_nopunct": 0.77101,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03252480705622933,
            "2": 0.18396226415094338,
            "3": 0.42168674698795183,
            "4": 0.6253822629969419,
            "5": 0.7496206373292867,
            "6": 0.8816901408450705,
            "7": 0.9330601092896175,
            "8": 0.9517490952955368,
            "9": 0.9608465608465608,
            "10": 0.9868217054263566
        },
        "rouge1": {
            "precision": 0.90089,
            "recall": 0.92456,
            "fmeasure": 0.90926
        },
        "rouge2": {
            "precision": 0.80979,
            "recall": 0.84003,
            "fmeasure": 0.82018
        },
        "rougeL": {
            "precision": 0.89107,
            "recall": 0.91565,
            "fmeasure": 0.89985
        },
        "rougeLsum": {
            "precision": 0.89107,
            "recall": 0.91565,
            "fmeasure": 0.89985
        },
        "nist": 13.468596381208068,
        "bleu": 87.8592,
        "nubia": {
            "semantic_relation": 4.43317,
            "contradiction": 2.39277,
            "irrelevancy": 33.77215,
            "logical_agreement": 63.83507,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.69498,
            "nubia_score": 0.70724
        },
        "bertscore": {
            "precision": 0.97415,
            "recall": 0.98213,
            "f1": 0.9761
        },
        "meteor": 0.5658096710191454,
        "bleurt": 0.32233
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7867,
        "mean_pred_length": 21.91364902506964,
        "std_pred_length": 9.115220843732748,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.3683742214312953,
        "vocab_size-1": 2898,
        "unique-1": 2115,
        "entropy-1": 9.25569495775647,
        "distinct-2": 0.8329781566329248,
        "vocab_size-2": 6254,
        "unique-2": 5782,
        "entropy-2": 12.273958823776688,
        "cond_entropy-2": 2.780509633542581,
        "distinct-3": 0.9630717582878724,
        "vocab_size-3": 6885,
        "unique-3": 6757,
        "entropy-3": 12.675655854825958,
        "cond_entropy-3": 0.41767670933395173,
        "total_length-nopunct": 6935,
        "mean_pred_length-nopunct": 19.317548746518106,
        "std_pred_length-nopunct": 8.003446235936336,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4161499639509733,
        "vocab_size-1-nopunct": 2886,
        "unique-1-nopunct": 2112,
        "entropy-1-nopunct": 9.622147464008012,
        "distinct-2-nopunct": 0.8622262773722628,
        "vocab_size-2-nopunct": 5670,
        "unique-2-nopunct": 5286,
        "entropy-2-nopunct": 12.21947682942681,
        "cond_entropy-2-nopunct": 2.725804687530003,
        "distinct-3-nopunct": 0.982628277304166,
        "vocab_size-3-nopunct": 6109,
        "unique-3-nopunct": 6018,
        "entropy-3-nopunct": 12.564821181777965,
        "cond_entropy-3-nopunct": 0.3653786532626024,
        "msttr-100": 0.72846,
        "msttr-100_nopunct": 0.77101,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03252480705622933,
            "2": 0.18396226415094338,
            "3": 0.42168674698795183,
            "4": 0.6253822629969419,
            "5": 0.7496206373292867,
            "6": 0.8816901408450705,
            "7": 0.9330601092896175,
            "8": 0.9517490952955368,
            "9": 0.9608465608465608,
            "10": 0.9868217054263566
        },
        "rouge1": {
            "precision": 0.90089,
            "recall": 0.92456,
            "fmeasure": 0.90926
        },
        "rouge2": {
            "precision": 0.80979,
            "recall": 0.84003,
            "fmeasure": 0.82018
        },
        "rougeL": {
            "precision": 0.89107,
            "recall": 0.91565,
            "fmeasure": 0.89985
        },
        "rougeLsum": {
            "precision": 0.89107,
            "recall": 0.91565,
            "fmeasure": 0.89985
        },
        "nist": 13.468596381208068,
        "bleu": 87.8592,
        "nubia": {
            "semantic_relation": 4.43317,
            "contradiction": 2.39277,
            "irrelevancy": 33.77215,
            "logical_agreement": 63.83507,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.69498,
            "nubia_score": 0.70724
        },
        "bertscore": {
            "precision": 0.97415,
            "recall": 0.98213,
            "f1": 0.9761
        },
        "meteor": 0.5658096710191454,
        "bleurt": 0.32233
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7867,
        "mean_pred_length": 21.91364902506964,
        "std_pred_length": 9.115220843732748,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.3683742214312953,
        "vocab_size-1": 2898,
        "unique-1": 2115,
        "entropy-1": 9.25569495775647,
        "distinct-2": 0.8329781566329248,
        "vocab_size-2": 6254,
        "unique-2": 5782,
        "entropy-2": 12.273958823776688,
        "cond_entropy-2": 2.780509633542581,
        "distinct-3": 0.9630717582878724,
        "vocab_size-3": 6885,
        "unique-3": 6757,
        "entropy-3": 12.675655854825958,
        "cond_entropy-3": 0.41767670933395173,
        "total_length-nopunct": 6935,
        "mean_pred_length-nopunct": 19.317548746518106,
        "std_pred_length-nopunct": 8.003446235936336,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4161499639509733,
        "vocab_size-1-nopunct": 2886,
        "unique-1-nopunct": 2112,
        "entropy-1-nopunct": 9.622147464008012,
        "distinct-2-nopunct": 0.8622262773722628,
        "vocab_size-2-nopunct": 5670,
        "unique-2-nopunct": 5286,
        "entropy-2-nopunct": 12.21947682942681,
        "cond_entropy-2-nopunct": 2.725804687530003,
        "distinct-3-nopunct": 0.982628277304166,
        "vocab_size-3-nopunct": 6109,
        "unique-3-nopunct": 6018,
        "entropy-3-nopunct": 12.564821181777965,
        "cond_entropy-3-nopunct": 0.3653786532626024,
        "msttr-100": 0.72846,
        "msttr-100_nopunct": 0.77101,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03252480705622933,
            "2": 0.18396226415094338,
            "3": 0.42168674698795183,
            "4": 0.6253822629969419,
            "5": 0.7496206373292867,
            "6": 0.8816901408450705,
            "7": 0.9330601092896175,
            "8": 0.9517490952955368,
            "9": 0.9608465608465608,
            "10": 0.9868217054263566
        },
        "rouge1": {
            "precision": 0.90089,
            "recall": 0.92456,
            "fmeasure": 0.90926
        },
        "rouge2": {
            "precision": 0.80979,
            "recall": 0.84003,
            "fmeasure": 0.82018
        },
        "rougeL": {
            "precision": 0.89107,
            "recall": 0.91565,
            "fmeasure": 0.89985
        },
        "rougeLsum": {
            "precision": 0.89107,
            "recall": 0.91565,
            "fmeasure": 0.89985
        },
        "nist": 13.468596381208068,
        "bleu": 87.8592,
        "nubia": {
            "semantic_relation": 4.43317,
            "contradiction": 2.39277,
            "irrelevancy": 33.77215,
            "logical_agreement": 63.83507,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.69498,
            "nubia_score": 0.70724
        },
        "bertscore": {
            "precision": 0.97415,
            "recall": 0.98213,
            "f1": 0.9761
        },
        "meteor": 0.5658096710191454,
        "bleurt": 0.32233
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7492,
        "mean_pred_length": 20.86908077994429,
        "std_pred_length": 9.90411506674438,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 90,
        "distinct-1": 0.35811532301121196,
        "vocab_size-1": 2683,
        "unique-1": 1949,
        "entropy-1": 9.162590524770721,
        "distinct-2": 0.8264404878732651,
        "vocab_size-2": 5895,
        "unique-2": 5446,
        "entropy-2": 12.17190860097906,
        "cond_entropy-2": 2.7610947300767554,
        "distinct-3": 0.9523176852671981,
        "vocab_size-3": 6451,
        "unique-3": 6319,
        "entropy-3": 12.557696604334403,
        "cond_entropy-3": 0.4057635451704732,
        "total_length-nopunct": 6640,
        "mean_pred_length-nopunct": 18.4958217270195,
        "std_pred_length-nopunct": 8.6732296697454,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.4022590361445783,
        "vocab_size-1-nopunct": 2671,
        "unique-1-nopunct": 1948,
        "entropy-1-nopunct": 9.508022386708033,
        "distinct-2-nopunct": 0.853844929151409,
        "vocab_size-2-nopunct": 5363,
        "unique-2-nopunct": 4997,
        "entropy-2-nopunct": 12.115390542732557,
        "cond_entropy-2-nopunct": 2.7412498519307693,
        "distinct-3-nopunct": 0.971968929415738,
        "vocab_size-3-nopunct": 5756,
        "unique-3-nopunct": 5656,
        "entropy-3-nopunct": 12.459634595557144,
        "cond_entropy-3-nopunct": 0.3666512106596183,
        "msttr-100": 0.72824,
        "msttr-100_nopunct": 0.76773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.044142614601018676,
            "2": 0.17752234993614305,
            "3": 0.4201312910284464,
            "4": 0.5673534072900158,
            "5": 0.6895119418483905,
            "6": 0.7916666666666666,
            "7": 0.8896525391370752
        },
        "rouge1": {
            "precision": 0.8481,
            "recall": 0.81238,
            "fmeasure": 0.82056
        },
        "rouge2": {
            "precision": 0.7122,
            "recall": 0.68341,
            "fmeasure": 0.68846
        },
        "rougeL": {
            "precision": 0.82098,
            "recall": 0.78829,
            "fmeasure": 0.79468
        },
        "rougeLsum": {
            "precision": 0.82098,
            "recall": 0.78829,
            "fmeasure": 0.79468
        },
        "nist": 11.210690329278748,
        "bleu": 68.27395,
        "nubia": {
            "semantic_relation": 4.36759,
            "contradiction": 4.15557,
            "irrelevancy": 17.5334,
            "logical_agreement": 78.31103,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.93126,
            "nubia_score": 0.71107
        },
        "bertscore": {
            "precision": 0.95374,
            "recall": 0.94932,
            "f1": 0.94939
        },
        "meteor": 0.47285419726840644,
        "bleurt": 0.23223
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7492,
        "mean_pred_length": 20.86908077994429,
        "std_pred_length": 9.90411506674438,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 90,
        "distinct-1": 0.35811532301121196,
        "vocab_size-1": 2683,
        "unique-1": 1949,
        "entropy-1": 9.162590524770721,
        "distinct-2": 0.8264404878732651,
        "vocab_size-2": 5895,
        "unique-2": 5446,
        "entropy-2": 12.17190860097906,
        "cond_entropy-2": 2.7610947300767554,
        "distinct-3": 0.9523176852671981,
        "vocab_size-3": 6451,
        "unique-3": 6319,
        "entropy-3": 12.557696604334403,
        "cond_entropy-3": 0.4057635451704732,
        "total_length-nopunct": 6640,
        "mean_pred_length-nopunct": 18.4958217270195,
        "std_pred_length-nopunct": 8.6732296697454,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.4022590361445783,
        "vocab_size-1-nopunct": 2671,
        "unique-1-nopunct": 1948,
        "entropy-1-nopunct": 9.508022386708033,
        "distinct-2-nopunct": 0.853844929151409,
        "vocab_size-2-nopunct": 5363,
        "unique-2-nopunct": 4997,
        "entropy-2-nopunct": 12.115390542732557,
        "cond_entropy-2-nopunct": 2.7412498519307693,
        "distinct-3-nopunct": 0.971968929415738,
        "vocab_size-3-nopunct": 5756,
        "unique-3-nopunct": 5656,
        "entropy-3-nopunct": 12.459634595557144,
        "cond_entropy-3-nopunct": 0.3666512106596183,
        "msttr-100": 0.72824,
        "msttr-100_nopunct": 0.76773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.044142614601018676,
            "2": 0.17752234993614305,
            "3": 0.4201312910284464,
            "4": 0.5673534072900158,
            "5": 0.6895119418483905,
            "6": 0.7916666666666666,
            "7": 0.8896525391370752
        },
        "rouge1": {
            "precision": 0.8481,
            "recall": 0.81238,
            "fmeasure": 0.82056
        },
        "rouge2": {
            "precision": 0.7122,
            "recall": 0.68341,
            "fmeasure": 0.68846
        },
        "rougeL": {
            "precision": 0.82098,
            "recall": 0.78829,
            "fmeasure": 0.79468
        },
        "rougeLsum": {
            "precision": 0.82098,
            "recall": 0.78829,
            "fmeasure": 0.79468
        },
        "nist": 11.210690329278748,
        "bleu": 68.27395,
        "nubia": {
            "semantic_relation": 4.36759,
            "contradiction": 4.15557,
            "irrelevancy": 17.5334,
            "logical_agreement": 78.31103,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.93126,
            "nubia_score": 0.71107
        },
        "bertscore": {
            "precision": 0.95374,
            "recall": 0.94932,
            "f1": 0.94939
        },
        "meteor": 0.47285419726840644,
        "bleurt": 0.23223
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "mT5_base/totto_test",
        "N": 54,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2122905027932961,
            "2": 0.38285714285714284,
            "3": 0.7370967741935484
        },
        "rouge1": {
            "precision": 0.775,
            "recall": 0.7212,
            "fmeasure": 0.73173
        },
        "rouge2": {
            "precision": 0.54261,
            "recall": 0.51218,
            "fmeasure": 0.51674
        },
        "rougeL": {
            "precision": 0.69136,
            "recall": 0.64324,
            "fmeasure": 0.6516
        },
        "rougeLsum": {
            "precision": 0.69136,
            "recall": 0.64324,
            "fmeasure": 0.6516
        },
        "nist": 6.828336917762835,
        "bleu": 44.59873,
        "nubia": {
            "semantic_relation": 4.09266,
            "contradiction": 15.5895,
            "irrelevancy": 21.59968,
            "logical_agreement": 62.81082,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.65619,
            "nubia_score": 0.70157
        },
        "bertscore": {
            "precision": 0.93278,
            "recall": 0.92788,
            "f1": 0.92857
        },
        "meteor": 0.38471895441197584,
        "bleurt": 0.26025
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "mT5_base/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "total_length": 110223,
        "mean_pred_length": 28.139647689558334,
        "std_pred_length": 18.007122897215933,
        "median_pred_length": 24.0,
        "min_pred_length": 3,
        "max_pred_length": 140,
        "distinct-1": 0.046269834789472254,
        "vocab_size-1": 5100,
        "unique-1": 1550,
        "entropy-1": 8.282537267809797,
        "distinct-2": 0.20022388200101593,
        "vocab_size-2": 21285,
        "unique-2": 10653,
        "entropy-2": 12.475141800113873,
        "cond_entropy-2": 3.9881010299145805,
        "distinct-3": 0.4070554454091748,
        "vocab_size-3": 41678,
        "unique-3": 27231,
        "entropy-3": 14.23269174168309,
        "cond_entropy-3": 1.7764978729661267,
        "total_length-nopunct": 91253,
        "mean_pred_length-nopunct": 23.2966556037784,
        "std_pred_length-nopunct": 15.544177912874144,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 125,
        "distinct-1-nopunct": 0.05570227828126199,
        "vocab_size-1-nopunct": 5083,
        "unique-1-nopunct": 1550,
        "entropy-1-nopunct": 9.148785695373384,
        "distinct-2-nopunct": 0.28896445910048546,
        "vocab_size-2-nopunct": 25237,
        "unique-2-nopunct": 14906,
        "entropy-2-nopunct": 13.043022870060927,
        "cond_entropy-2-nopunct": 4.016592547165546,
        "distinct-3-nopunct": 0.5192222395377551,
        "vocab_size-3-nopunct": 43313,
        "unique-3-nopunct": 31293,
        "entropy-3-nopunct": 14.62448053422621,
        "cond_entropy-3-nopunct": 1.6249675090839117,
        "msttr-100": 0.45186,
        "msttr-100_nopunct": 0.51593,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "local_recall": {
            "1": 0.19712437696575794
        },
        "rouge1": {
            "precision": 0.33399,
            "recall": 0.23674,
            "fmeasure": 0.25649
        },
        "rouge2": {
            "precision": 0.10059,
            "recall": 0.07192,
            "fmeasure": 0.07737
        },
        "rougeL": {
            "precision": 0.2784,
            "recall": 0.19943,
            "fmeasure": 0.21471
        },
        "rougeLsum": {
            "precision": 0.2784,
            "recall": 0.19943,
            "fmeasure": 0.21471
        },
        "nist": 2.2486314611304046,
        "bleu": 6.4438,
        "sari": 65.6837,
        "nubia": {
            "semantic_relation": 2.56315,
            "contradiction": 20.36715,
            "irrelevancy": 37.35011,
            "logical_agreement": 42.28274,
            "grammar_ref": 3.92068,
            "grammar_hyp": 3.41292,
            "nubia_score": 0.33978
        },
        "bertscore": {
            "precision": 0.83977,
            "recall": 0.80299,
            "f1": 0.82033
        },
        "meteor": 0.12008086750401634,
        "bleurt": -0.51016
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8513513513513513
        },
        "rouge1": {
            "precision": 0.92059,
            "recall": 0.89012,
            "fmeasure": 0.9
        },
        "rouge2": {
            "precision": 0.80976,
            "recall": 0.80556,
            "fmeasure": 0.80556
        },
        "rougeL": {
            "precision": 0.8549,
            "recall": 0.82594,
            "fmeasure": 0.8359
        },
        "rougeLsum": {
            "precision": 0.8549,
            "recall": 0.82594,
            "fmeasure": 0.8359
        },
        "nist": 5.071736098299283,
        "bleu": 69.20426,
        "nubia": {
            "semantic_relation": 4.7328,
            "contradiction": 0.39639,
            "irrelevancy": 1.45616,
            "logical_agreement": 98.14745,
            "grammar_ref": 5.92578,
            "grammar_hyp": 6.28676,
            "nubia_score": 0.87598
        },
        "bertscore": {
            "precision": 0.97637,
            "recall": 0.97013,
            "f1": 0.97314
        },
        "meteor": 0.5000307858181545,
        "bleurt": 0.77222
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.675,
            "fmeasure": 0.63429
        },
        "rouge2": {
            "precision": 0.32143,
            "recall": 0.38304,
            "fmeasure": 0.3386
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.575,
            "fmeasure": 0.52
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.575,
            "fmeasure": 0.52
        },
        "nist": 3.9292679310066085,
        "bleu": 28.64285,
        "nubia": {
            "semantic_relation": 3.42841,
            "contradiction": 67.23133,
            "irrelevancy": 11.18777,
            "logical_agreement": 21.58089,
            "grammar_ref": 5.69136,
            "grammar_hyp": 4.90097,
            "nubia_score": 0.45889
        },
        "bertscore": {
            "precision": 0.91113,
            "recall": 0.96029,
            "f1": 0.93506
        },
        "meteor": 0.41404948945667935,
        "bleurt": 0.28362
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "mT5_base/totto_test",
        "N": 71,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25139664804469275,
            "2": 0.6,
            "3": 0.751004016064257
        },
        "rouge1": {
            "precision": 0.73799,
            "recall": 0.73361,
            "fmeasure": 0.71403
        },
        "rouge2": {
            "precision": 0.55005,
            "recall": 0.56441,
            "fmeasure": 0.5384
        },
        "rougeL": {
            "precision": 0.69232,
            "recall": 0.69852,
            "fmeasure": 0.67439
        },
        "rougeLsum": {
            "precision": 0.69232,
            "recall": 0.69852,
            "fmeasure": 0.67439
        },
        "nist": 6.76122478362263,
        "bleu": 50.38754,
        "nubia": {
            "semantic_relation": 4.03376,
            "contradiction": 11.90303,
            "irrelevancy": 39.40653,
            "logical_agreement": 48.69045,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.21035,
            "nubia_score": 0.66476
        },
        "bertscore": {
            "precision": 0.93698,
            "recall": 0.9302,
            "f1": 0.93166
        },
        "meteor": 0.40085159068786663,
        "bleurt": 0.32451
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "mT5_base/totto_test",
        "N": 62,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1569767441860465,
            "2": 0.4067796610169492,
            "3": 0.7973760932944607
        },
        "rouge1": {
            "precision": 0.77503,
            "recall": 0.74409,
            "fmeasure": 0.74991
        },
        "rouge2": {
            "precision": 0.55268,
            "recall": 0.52502,
            "fmeasure": 0.53173
        },
        "rougeL": {
            "precision": 0.68184,
            "recall": 0.65189,
            "fmeasure": 0.65825
        },
        "rougeLsum": {
            "precision": 0.68184,
            "recall": 0.65189,
            "fmeasure": 0.65825
        },
        "nist": 7.331216546642364,
        "bleu": 49.39795,
        "nubia": {
            "semantic_relation": 4.2895,
            "contradiction": 5.45581,
            "irrelevancy": 31.59406,
            "logical_agreement": 62.95013,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.55377,
            "nubia_score": 0.76484
        },
        "bertscore": {
            "precision": 0.93137,
            "recall": 0.9255,
            "f1": 0.92673
        },
        "meteor": 0.40531792334855676,
        "bleurt": 0.29056
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.05263157894736842,
            "2": 0.2727272727272727
        },
        "rouge1": {
            "precision": 0.52941,
            "recall": 0.23182,
            "fmeasure": 0.31649
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.053,
            "fmeasure": 0.07302
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.19848,
            "fmeasure": 0.27394
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.19848,
            "fmeasure": 0.27394
        },
        "nist": 0.06094760529048976,
        "bleu": 4.16038,
        "nubia": {
            "semantic_relation": 2.40138,
            "contradiction": 91.70948,
            "irrelevancy": 2.09819,
            "logical_agreement": 6.19233,
            "grammar_ref": 4.34131,
            "grammar_hyp": 5.35671,
            "nubia_score": 0.13849
        },
        "bertscore": {
            "precision": 0.9028,
            "recall": 0.83643,
            "f1": 0.85961
        },
        "meteor": 0.1313822048652219,
        "bleurt": -0.1542
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.2857142857142857
        },
        "rouge1": {
            "precision": 0.2,
            "recall": 0.21267,
            "fmeasure": 0.20536
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.2,
            "recall": 0.21267,
            "fmeasure": 0.20536
        },
        "rougeLsum": {
            "precision": 0.2,
            "recall": 0.21267,
            "fmeasure": 0.20536
        },
        "nist": 0.953845820409259,
        "bleu": 3.45859,
        "nubia": {
            "semantic_relation": 1.00568,
            "contradiction": 13.56988,
            "irrelevancy": 85.27418,
            "logical_agreement": 1.15594,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.56858,
            "nubia_score": 0.09515
        },
        "bertscore": {
            "precision": 0.6743,
            "recall": 0.67224,
            "f1": 0.67327
        },
        "meteor": 0.10104728975907513,
        "bleurt": -0.49268
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.85348,
            "fmeasure": 0.81363
        },
        "rouge2": {
            "precision": 0.59524,
            "recall": 0.65598,
            "fmeasure": 0.62393
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.85348,
            "fmeasure": 0.81363
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.85348,
            "fmeasure": 0.81363
        },
        "nist": 3.512201038453565,
        "bleu": 56.64313,
        "nubia": {
            "semantic_relation": 2.05726,
            "contradiction": 85.31143,
            "irrelevancy": 14.12787,
            "logical_agreement": 0.5607,
            "grammar_ref": 4.48671,
            "grammar_hyp": 3.99022,
            "nubia_score": 0.2129
        },
        "bertscore": {
            "precision": 0.91907,
            "recall": 0.95335,
            "f1": 0.93589
        },
        "meteor": 0.4398027655070263,
        "bleurt": 0.11111
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.29412,
            "fmeasure": 0.35714
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.25,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.29412,
            "fmeasure": 0.35714
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.29412,
            "fmeasure": 0.35714
        },
        "nist": 0.8768600701346063,
        "bleu": 18.51604,
        "nubia": {
            "semantic_relation": 2.35408,
            "contradiction": 12.75157,
            "irrelevancy": 85.33699,
            "logical_agreement": 1.91145,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.57034,
            "nubia_score": 0.16146
        },
        "bertscore": {
            "precision": 0.86295,
            "recall": 0.7723,
            "f1": 0.81511
        },
        "meteor": 0.194296409135584,
        "bleurt": -0.22243
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5714285714285714,
            "3": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.3871,
            "fmeasure": 0.43636
        },
        "rouge2": {
            "precision": 0.21739,
            "recall": 0.16667,
            "fmeasure": 0.18868
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.35484,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.35484,
            "fmeasure": 0.4
        },
        "nist": 3.2200284517077997,
        "bleu": 15.02086,
        "nubia": {
            "semantic_relation": 2.06646,
            "contradiction": 61.01435,
            "irrelevancy": 25.16239,
            "logical_agreement": 13.82326,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.64625,
            "nubia_score": 0.16097
        },
        "bertscore": {
            "precision": 0.92051,
            "recall": 0.88204,
            "f1": 0.90087
        },
        "meteor": 0.25665832586274206,
        "bleurt": -0.05648
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "mT5_base/totto_test",
        "N": 44,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2357142857142857,
            "2": 0.6025641025641025,
            "3": 0.7632850241545893
        },
        "rouge1": {
            "precision": 0.79833,
            "recall": 0.732,
            "fmeasure": 0.75406
        },
        "rouge2": {
            "precision": 0.56825,
            "recall": 0.53239,
            "fmeasure": 0.54243
        },
        "rougeL": {
            "precision": 0.69926,
            "recall": 0.6537,
            "fmeasure": 0.66578
        },
        "rougeLsum": {
            "precision": 0.69926,
            "recall": 0.6537,
            "fmeasure": 0.66578
        },
        "nist": 7.036268675771635,
        "bleu": 51.70529,
        "nubia": {
            "semantic_relation": 4.38407,
            "contradiction": 5.48516,
            "irrelevancy": 27.8866,
            "logical_agreement": 66.62824,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.71335,
            "nubia_score": 0.76094
        },
        "bertscore": {
            "precision": 0.93973,
            "recall": 0.93099,
            "f1": 0.93355
        },
        "meteor": 0.4172860813800694,
        "bleurt": 0.34255
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.25
        },
        "rouge1": {
            "precision": 0.36364,
            "recall": 0.33333,
            "fmeasure": 0.34783
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.27273,
            "recall": 0.25,
            "fmeasure": 0.26087
        },
        "rougeLsum": {
            "precision": 0.27273,
            "recall": 0.25,
            "fmeasure": 0.26087
        },
        "nist": 1.038381856959982,
        "bleu": 4.40631,
        "nubia": {
            "semantic_relation": 2.6618,
            "contradiction": 3.54847,
            "irrelevancy": 96.33084,
            "logical_agreement": 0.1207,
            "grammar_ref": 3.85254,
            "grammar_hyp": 4.96938,
            "nubia_score": 0.20348
        },
        "bertscore": {
            "precision": 0.84674,
            "recall": 0.85479,
            "f1": 0.85075
        },
        "meteor": 0.22156436966446735,
        "bleurt": -0.7014
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.65,
            "2": 0.36363636363636365,
            "3": 0.5625
        },
        "rouge1": {
            "precision": 0.68869,
            "recall": 0.6112,
            "fmeasure": 0.63239
        },
        "rouge2": {
            "precision": 0.38816,
            "recall": 0.42375,
            "fmeasure": 0.38867
        },
        "rougeL": {
            "precision": 0.49606,
            "recall": 0.51262,
            "fmeasure": 0.4808
        },
        "rougeLsum": {
            "precision": 0.49606,
            "recall": 0.51262,
            "fmeasure": 0.4808
        },
        "nist": 4.428074980012873,
        "bleu": 29.97792,
        "nubia": {
            "semantic_relation": 4.06327,
            "contradiction": 0.2309,
            "irrelevancy": 76.94774,
            "logical_agreement": 22.82136,
            "grammar_ref": 4.07664,
            "grammar_hyp": 3.5907,
            "nubia_score": 0.71672
        },
        "bertscore": {
            "precision": 0.92007,
            "recall": 0.90846,
            "f1": 0.90704
        },
        "meteor": 0.31881523269647655,
        "bleurt": -0.03618
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "mT5_base/totto_test",
        "N": 35,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14893617021276595,
            "2": 0.5309734513274337,
            "3": 0.743073047858942
        },
        "rouge1": {
            "precision": 0.77389,
            "recall": 0.73716,
            "fmeasure": 0.74252
        },
        "rouge2": {
            "precision": 0.54621,
            "recall": 0.52885,
            "fmeasure": 0.52754
        },
        "rougeL": {
            "precision": 0.68179,
            "recall": 0.65862,
            "fmeasure": 0.65716
        },
        "rougeLsum": {
            "precision": 0.68179,
            "recall": 0.65862,
            "fmeasure": 0.65716
        },
        "nist": 6.6810776203326485,
        "bleu": 47.45227,
        "nubia": {
            "semantic_relation": 4.11004,
            "contradiction": 9.63546,
            "irrelevancy": 24.97334,
            "logical_agreement": 65.3912,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.57255,
            "nubia_score": 0.6915
        },
        "bertscore": {
            "precision": 0.93409,
            "recall": 0.92497,
            "f1": 0.92788
        },
        "meteor": 0.40428043302188393,
        "bleurt": 0.25059
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "mT5_base/totto_test",
        "N": 42,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22413793103448276,
            "2": 0.49056603773584906,
            "3": 0.7662921348314606
        },
        "rouge1": {
            "precision": 0.7856,
            "recall": 0.7314,
            "fmeasure": 0.75058
        },
        "rouge2": {
            "precision": 0.54485,
            "recall": 0.51441,
            "fmeasure": 0.52406
        },
        "rougeL": {
            "precision": 0.6729,
            "recall": 0.63071,
            "fmeasure": 0.64424
        },
        "rougeLsum": {
            "precision": 0.6729,
            "recall": 0.63071,
            "fmeasure": 0.64424
        },
        "nist": 6.879887898563247,
        "bleu": 44.22807,
        "nubia": {
            "semantic_relation": 4.22574,
            "contradiction": 8.63113,
            "irrelevancy": 29.35882,
            "logical_agreement": 62.01004,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.65933,
            "nubia_score": 0.73612
        },
        "bertscore": {
            "precision": 0.93754,
            "recall": 0.9253,
            "f1": 0.92957
        },
        "meteor": 0.40445115273214144,
        "bleurt": 0.27361
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "mT5_base/totto_test",
        "N": 15,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.29545454545454547,
            "3": 0.7643312101910829
        },
        "rouge1": {
            "precision": 0.81306,
            "recall": 0.70671,
            "fmeasure": 0.74572
        },
        "rouge2": {
            "precision": 0.51502,
            "recall": 0.4697,
            "fmeasure": 0.48538
        },
        "rougeL": {
            "precision": 0.66086,
            "recall": 0.58678,
            "fmeasure": 0.61365
        },
        "rougeLsum": {
            "precision": 0.66086,
            "recall": 0.58678,
            "fmeasure": 0.61365
        },
        "nist": 5.1173813606422955,
        "bleu": 39.38118,
        "nubia": {
            "semantic_relation": 4.18813,
            "contradiction": 10.77852,
            "irrelevancy": 47.28772,
            "logical_agreement": 41.93376,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.80833,
            "nubia_score": 0.67823
        },
        "bertscore": {
            "precision": 0.92559,
            "recall": 0.91645,
            "f1": 0.92042
        },
        "meteor": 0.368819300063914,
        "bleurt": 0.26255
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7083333333333334
        },
        "rouge1": {
            "precision": 0.73547,
            "recall": 0.69791,
            "fmeasure": 0.71289
        },
        "rouge2": {
            "precision": 0.461,
            "recall": 0.44678,
            "fmeasure": 0.452
        },
        "rougeL": {
            "precision": 0.53803,
            "recall": 0.5123,
            "fmeasure": 0.52255
        },
        "rougeLsum": {
            "precision": 0.53803,
            "recall": 0.5123,
            "fmeasure": 0.52255
        },
        "nist": 4.678738818916925,
        "bleu": 33.20217,
        "nubia": {
            "semantic_relation": 4.58619,
            "contradiction": 0.541,
            "irrelevancy": 54.83542,
            "logical_agreement": 44.62358,
            "grammar_ref": 4.6156,
            "grammar_hyp": 5.09484,
            "nubia_score": 0.78808
        },
        "bertscore": {
            "precision": 0.90868,
            "recall": 0.89829,
            "f1": 0.90259
        },
        "meteor": 0.34826515208586095,
        "bleurt": 0.17796
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "mT5_base/totto_test",
        "N": 18,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.3103448275862069,
            "3": 0.782608695652174
        },
        "rouge1": {
            "precision": 0.77932,
            "recall": 0.73395,
            "fmeasure": 0.74648
        },
        "rouge2": {
            "precision": 0.53149,
            "recall": 0.51456,
            "fmeasure": 0.51168
        },
        "rougeL": {
            "precision": 0.68336,
            "recall": 0.66565,
            "fmeasure": 0.66284
        },
        "rougeLsum": {
            "precision": 0.68336,
            "recall": 0.66565,
            "fmeasure": 0.66284
        },
        "nist": 5.951843578006963,
        "bleu": 45.16013,
        "nubia": {
            "semantic_relation": 4.27659,
            "contradiction": 1.06988,
            "irrelevancy": 32.32564,
            "logical_agreement": 66.60448,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.80543,
            "nubia_score": 0.73335
        },
        "bertscore": {
            "precision": 0.93243,
            "recall": 0.9274,
            "f1": 0.92854
        },
        "meteor": 0.4047350996933735,
        "bleurt": 0.29976
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "mT5_base/totto_test",
        "N": 10,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11864406779661017,
            "2": 0.15384615384615385,
            "3": 0.5686274509803921
        },
        "rouge1": {
            "precision": 0.68019,
            "recall": 0.5819,
            "fmeasure": 0.59009
        },
        "rouge2": {
            "precision": 0.38829,
            "recall": 0.34535,
            "fmeasure": 0.33361
        },
        "rougeL": {
            "precision": 0.54736,
            "recall": 0.48012,
            "fmeasure": 0.48067
        },
        "rougeLsum": {
            "precision": 0.54736,
            "recall": 0.48012,
            "fmeasure": 0.48067
        },
        "nist": 3.167454495484528,
        "bleu": 16.98566,
        "nubia": {
            "semantic_relation": 3.87154,
            "contradiction": 12.18116,
            "irrelevancy": 46.85297,
            "logical_agreement": 40.96587,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.76397,
            "nubia_score": 0.59484
        },
        "bertscore": {
            "precision": 0.89849,
            "recall": 0.87717,
            "f1": 0.88486
        },
        "meteor": 0.27361843054270035,
        "bleurt": 0.10484
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "mT5_base/totto_test",
        "N": 18,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27941176470588236,
            "2": 0.6619718309859155,
            "3": 0.7043010752688172
        },
        "rouge1": {
            "precision": 0.65943,
            "recall": 0.71501,
            "fmeasure": 0.67966
        },
        "rouge2": {
            "precision": 0.37801,
            "recall": 0.416,
            "fmeasure": 0.39165
        },
        "rougeL": {
            "precision": 0.53774,
            "recall": 0.58632,
            "fmeasure": 0.55624
        },
        "rougeLsum": {
            "precision": 0.53774,
            "recall": 0.58632,
            "fmeasure": 0.55624
        },
        "nist": 5.409980494085417,
        "bleu": 32.21581,
        "nubia": {
            "semantic_relation": 3.9481,
            "contradiction": 11.67041,
            "irrelevancy": 51.37031,
            "logical_agreement": 36.95927,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.33939,
            "nubia_score": 0.67222
        },
        "bertscore": {
            "precision": 0.89712,
            "recall": 0.91187,
            "f1": 0.90263
        },
        "meteor": 0.36957702550317456,
        "bleurt": 0.04982
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "mT5_base/totto_test",
        "N": 15,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.46153846153846156,
            "3": 0.7760416666666666
        },
        "rouge1": {
            "precision": 0.80481,
            "recall": 0.72401,
            "fmeasure": 0.75384
        },
        "rouge2": {
            "precision": 0.57181,
            "recall": 0.51419,
            "fmeasure": 0.5343
        },
        "rougeL": {
            "precision": 0.72732,
            "recall": 0.66115,
            "fmeasure": 0.6829
        },
        "rougeLsum": {
            "precision": 0.72732,
            "recall": 0.66115,
            "fmeasure": 0.6829
        },
        "nist": 5.816330159861485,
        "bleu": 47.59373,
        "nubia": {
            "semantic_relation": 4.22902,
            "contradiction": 3.41552,
            "irrelevancy": 36.85315,
            "logical_agreement": 59.73133,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.55293,
            "nubia_score": 0.72014
        },
        "bertscore": {
            "precision": 0.94063,
            "recall": 0.92776,
            "f1": 0.93139
        },
        "meteor": 0.3943071796491577,
        "bleurt": 0.34839
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "mT5_base/totto_test",
        "N": 28,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14102564102564102,
            "2": 0.4266666666666667,
            "3": 0.7134502923976608
        },
        "rouge1": {
            "precision": 0.77921,
            "recall": 0.68611,
            "fmeasure": 0.71699
        },
        "rouge2": {
            "precision": 0.5278,
            "recall": 0.48027,
            "fmeasure": 0.495
        },
        "rougeL": {
            "precision": 0.68406,
            "recall": 0.62532,
            "fmeasure": 0.64109
        },
        "rougeLsum": {
            "precision": 0.68406,
            "recall": 0.62532,
            "fmeasure": 0.64109
        },
        "nist": 5.8212757059905815,
        "bleu": 41.51941,
        "nubia": {
            "semantic_relation": 3.98353,
            "contradiction": 11.18923,
            "irrelevancy": 29.2363,
            "logical_agreement": 59.57446,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.63657,
            "nubia_score": 0.65728
        },
        "bertscore": {
            "precision": 0.92505,
            "recall": 0.91518,
            "f1": 0.91675
        },
        "meteor": 0.36764003613300256,
        "bleurt": 0.22536
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "mT5_base/totto_test",
        "N": 47,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10619469026548672,
            "2": 0.4470588235294118,
            "3": 0.7270833333333333
        },
        "rouge1": {
            "precision": 0.76905,
            "recall": 0.67655,
            "fmeasure": 0.71306
        },
        "rouge2": {
            "precision": 0.50228,
            "recall": 0.44359,
            "fmeasure": 0.46631
        },
        "rougeL": {
            "precision": 0.65939,
            "recall": 0.58774,
            "fmeasure": 0.61539
        },
        "rougeLsum": {
            "precision": 0.65939,
            "recall": 0.58774,
            "fmeasure": 0.61539
        },
        "nist": 5.929440668049828,
        "bleu": 37.12488,
        "nubia": {
            "semantic_relation": 4.19406,
            "contradiction": 12.36722,
            "irrelevancy": 27.05844,
            "logical_agreement": 60.57433,
            "grammar_ref": 4.69178,
            "grammar_hyp": 5.07951,
            "nubia_score": 0.68404
        },
        "bertscore": {
            "precision": 0.92917,
            "recall": 0.91336,
            "f1": 0.91992
        },
        "meteor": 0.35672258155730313,
        "bleurt": 0.26678
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "mT5_base/totto_test",
        "N": 48,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21637426900584794,
            "2": 0.532051282051282,
            "3": 0.667953667953668
        },
        "rouge1": {
            "precision": 0.74439,
            "recall": 0.65443,
            "fmeasure": 0.68479
        },
        "rouge2": {
            "precision": 0.4744,
            "recall": 0.42008,
            "fmeasure": 0.438
        },
        "rougeL": {
            "precision": 0.61317,
            "recall": 0.54789,
            "fmeasure": 0.56921
        },
        "rougeLsum": {
            "precision": 0.61317,
            "recall": 0.54789,
            "fmeasure": 0.56921
        },
        "nist": 6.064277038560135,
        "bleu": 33.4463,
        "nubia": {
            "semantic_relation": 3.89764,
            "contradiction": 17.19599,
            "irrelevancy": 28.72871,
            "logical_agreement": 54.0753,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.72664,
            "nubia_score": 0.64844
        },
        "bertscore": {
            "precision": 0.91406,
            "recall": 0.89592,
            "f1": 0.90255
        },
        "meteor": 0.335923606122123,
        "bleurt": 0.1365
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "mT5_base/totto_test",
        "N": 46,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20909090909090908,
            "2": 0.31386861313868614,
            "3": 0.7213438735177866
        },
        "rouge1": {
            "precision": 0.76674,
            "recall": 0.69397,
            "fmeasure": 0.71482
        },
        "rouge2": {
            "precision": 0.53082,
            "recall": 0.48901,
            "fmeasure": 0.49808
        },
        "rougeL": {
            "precision": 0.67376,
            "recall": 0.61219,
            "fmeasure": 0.6286
        },
        "rougeLsum": {
            "precision": 0.67376,
            "recall": 0.61219,
            "fmeasure": 0.6286
        },
        "nist": 6.059817045274016,
        "bleu": 42.34697,
        "nubia": {
            "semantic_relation": 4.11723,
            "contradiction": 16.39693,
            "irrelevancy": 31.16508,
            "logical_agreement": 52.43799,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.85198,
            "nubia_score": 0.68543
        },
        "bertscore": {
            "precision": 0.92348,
            "recall": 0.91192,
            "f1": 0.91586
        },
        "meteor": 0.3664931326768892,
        "bleurt": 0.27887
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.45,
            "fmeasure": 0.5625
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.31579,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.45,
            "fmeasure": 0.5625
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.45,
            "fmeasure": 0.5625
        },
        "nist": 2.143626447431683,
        "bleu": 43.66835,
        "nubia": {
            "semantic_relation": 3.56794,
            "contradiction": 3.4121,
            "irrelevancy": 38.27416,
            "logical_agreement": 58.31375,
            "grammar_ref": 4.8547,
            "grammar_hyp": 4.87233,
            "nubia_score": 0.47951
        },
        "bertscore": {
            "precision": 0.91628,
            "recall": 0.85766,
            "f1": 0.87645
        },
        "meteor": 0.22078953266809714,
        "bleurt": -0.29093
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "mT5_base/totto_test",
        "N": 20,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.5370370370370371,
            "3": 0.8755555555555555
        },
        "rouge1": {
            "precision": 0.82954,
            "recall": 0.83174,
            "fmeasure": 0.82727
        },
        "rouge2": {
            "precision": 0.68428,
            "recall": 0.68599,
            "fmeasure": 0.68271
        },
        "rougeL": {
            "precision": 0.72657,
            "recall": 0.73266,
            "fmeasure": 0.72708
        },
        "rougeLsum": {
            "precision": 0.72657,
            "recall": 0.73266,
            "fmeasure": 0.72708
        },
        "nist": 6.597937608647184,
        "bleu": 59.5892,
        "nubia": {
            "semantic_relation": 4.49957,
            "contradiction": 8.25606,
            "irrelevancy": 19.3745,
            "logical_agreement": 72.36944,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.60856,
            "nubia_score": 0.82836
        },
        "bertscore": {
            "precision": 0.94805,
            "recall": 0.95245,
            "f1": 0.95004
        },
        "meteor": 0.45508668142058184,
        "bleurt": 0.47705
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "mT5_base/totto_test",
        "N": 52,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2236842105263158,
            "2": 0.5567567567567567,
            "3": 0.8097686375321337
        },
        "rouge1": {
            "precision": 0.76974,
            "recall": 0.76346,
            "fmeasure": 0.75066
        },
        "rouge2": {
            "precision": 0.56786,
            "recall": 0.53316,
            "fmeasure": 0.53934
        },
        "rougeL": {
            "precision": 0.72084,
            "recall": 0.71224,
            "fmeasure": 0.70195
        },
        "rougeLsum": {
            "precision": 0.72084,
            "recall": 0.71224,
            "fmeasure": 0.70195
        },
        "nist": 6.874471764079287,
        "bleu": 50.30951,
        "nubia": {
            "semantic_relation": 4.18756,
            "contradiction": 10.06929,
            "irrelevancy": 28.75666,
            "logical_agreement": 61.17405,
            "grammar_ref": 5.15177,
            "grammar_hyp": 5.04577,
            "nubia_score": 0.70902
        },
        "bertscore": {
            "precision": 0.941,
            "recall": 0.94312,
            "f1": 0.9396
        },
        "meteor": 0.42390840034654903,
        "bleurt": 0.4283
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.05263157894736842,
            "2": 0.2,
            "3": 0.8589743589743589
        },
        "rouge1": {
            "precision": 0.85112,
            "recall": 0.82575,
            "fmeasure": 0.82815
        },
        "rouge2": {
            "precision": 0.65864,
            "recall": 0.62673,
            "fmeasure": 0.63583
        },
        "rougeL": {
            "precision": 0.70574,
            "recall": 0.68978,
            "fmeasure": 0.68904
        },
        "rougeLsum": {
            "precision": 0.70574,
            "recall": 0.68978,
            "fmeasure": 0.68904
        },
        "nist": 5.490058611097751,
        "bleu": 58.00433,
        "nubia": {
            "semantic_relation": 4.65806,
            "contradiction": 16.82696,
            "irrelevancy": 8.6819,
            "logical_agreement": 74.49113,
            "grammar_ref": 4.66241,
            "grammar_hyp": 5.01936,
            "nubia_score": 0.83255
        },
        "bertscore": {
            "precision": 0.94922,
            "recall": 0.94289,
            "f1": 0.94162
        },
        "meteor": 0.4521344330956419,
        "bleurt": 0.46058
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "mT5_base/totto_test",
        "N": 17,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16923076923076924,
            "2": 0.38596491228070173,
            "3": 0.8604651162790697
        },
        "rouge1": {
            "precision": 0.77858,
            "recall": 0.76807,
            "fmeasure": 0.76318
        },
        "rouge2": {
            "precision": 0.56882,
            "recall": 0.55778,
            "fmeasure": 0.55669
        },
        "rougeL": {
            "precision": 0.69407,
            "recall": 0.66588,
            "fmeasure": 0.67246
        },
        "rougeLsum": {
            "precision": 0.69407,
            "recall": 0.66588,
            "fmeasure": 0.67246
        },
        "nist": 6.190806357048036,
        "bleu": 47.19403,
        "nubia": {
            "semantic_relation": 4.20626,
            "contradiction": 11.79546,
            "irrelevancy": 25.33049,
            "logical_agreement": 62.87406,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.67136,
            "nubia_score": 0.74099
        },
        "bertscore": {
            "precision": 0.94107,
            "recall": 0.93586,
            "f1": 0.93602
        },
        "meteor": 0.41589818540044826,
        "bleurt": 0.26432
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "mT5_base/totto_test",
        "N": 10,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3870967741935484,
            "2": 0.425,
            "3": 0.7657657657657657
        },
        "rouge1": {
            "precision": 0.75235,
            "recall": 0.74147,
            "fmeasure": 0.7384
        },
        "rouge2": {
            "precision": 0.49833,
            "recall": 0.48986,
            "fmeasure": 0.48845
        },
        "rougeL": {
            "precision": 0.61325,
            "recall": 0.59871,
            "fmeasure": 0.59841
        },
        "rougeLsum": {
            "precision": 0.61325,
            "recall": 0.59871,
            "fmeasure": 0.59841
        },
        "nist": 5.714090666751163,
        "bleu": 41.01813,
        "nubia": {
            "semantic_relation": 4.11164,
            "contradiction": 6.38898,
            "irrelevancy": 50.5551,
            "logical_agreement": 43.05593,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.59129,
            "nubia_score": 0.68226
        },
        "bertscore": {
            "precision": 0.91861,
            "recall": 0.92427,
            "f1": 0.91951
        },
        "meteor": 0.36517131498124733,
        "bleurt": 0.13005
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "rouge2": {
            "precision": 0.27451,
            "recall": 0.48148,
            "fmeasure": 0.34948
        },
        "rougeL": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "rougeLsum": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "nist": 1.5652175776270818,
        "bleu": 16.19557,
        "nubia": {
            "semantic_relation": 3.88405,
            "contradiction": 0.19921,
            "irrelevancy": 36.92861,
            "logical_agreement": 62.87218,
            "grammar_ref": 5.00001,
            "grammar_hyp": 4.04242,
            "nubia_score": 0.54152
        },
        "bertscore": {
            "precision": 0.85721,
            "recall": 0.91088,
            "f1": 0.88323
        },
        "meteor": 0.34268548401630916,
        "bleurt": 0.18764
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "mT5_base/totto_test",
        "N": 25,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23214285714285715,
            "2": 0.3953488372093023,
            "3": 0.8441558441558441
        },
        "rouge1": {
            "precision": 0.83791,
            "recall": 0.80516,
            "fmeasure": 0.81397
        },
        "rouge2": {
            "precision": 0.65546,
            "recall": 0.65004,
            "fmeasure": 0.64909
        },
        "rougeL": {
            "precision": 0.75002,
            "recall": 0.72616,
            "fmeasure": 0.73173
        },
        "rougeLsum": {
            "precision": 0.75002,
            "recall": 0.72616,
            "fmeasure": 0.73173
        },
        "nist": 7.1425062455851505,
        "bleu": 60.80401,
        "nubia": {
            "semantic_relation": 4.31537,
            "contradiction": 11.12275,
            "irrelevancy": 17.44155,
            "logical_agreement": 71.43569,
            "grammar_ref": 4.85173,
            "grammar_hyp": 4.97471,
            "nubia_score": 0.75129
        },
        "bertscore": {
            "precision": 0.95172,
            "recall": 0.94271,
            "f1": 0.94681
        },
        "meteor": 0.45577824438304715,
        "bleurt": 0.41276
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "mT5_base/totto_test",
        "N": 36,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1782178217821782,
            "2": 0.5793650793650794,
            "3": 0.7302052785923754
        },
        "rouge1": {
            "precision": 0.75046,
            "recall": 0.71967,
            "fmeasure": 0.712
        },
        "rouge2": {
            "precision": 0.52592,
            "recall": 0.51571,
            "fmeasure": 0.50282
        },
        "rougeL": {
            "precision": 0.66506,
            "recall": 0.64335,
            "fmeasure": 0.63417
        },
        "rougeLsum": {
            "precision": 0.66506,
            "recall": 0.64335,
            "fmeasure": 0.63417
        },
        "nist": 6.171642556927826,
        "bleu": 41.16759,
        "nubia": {
            "semantic_relation": 3.91549,
            "contradiction": 13.20285,
            "irrelevancy": 39.08542,
            "logical_agreement": 47.71173,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.74409,
            "nubia_score": 0.63983
        },
        "bertscore": {
            "precision": 0.91671,
            "recall": 0.91361,
            "f1": 0.91324
        },
        "meteor": 0.37376726157180057,
        "bleurt": 0.16631
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "mT5_base/totto_test",
        "N": 11,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.30952380952380953,
            "3": 0.6614173228346457
        },
        "rouge1": {
            "precision": 0.67572,
            "recall": 0.66969,
            "fmeasure": 0.66212
        },
        "rouge2": {
            "precision": 0.41651,
            "recall": 0.40356,
            "fmeasure": 0.40108
        },
        "rougeL": {
            "precision": 0.57735,
            "recall": 0.5789,
            "fmeasure": 0.56976
        },
        "rougeLsum": {
            "precision": 0.57735,
            "recall": 0.5789,
            "fmeasure": 0.56976
        },
        "nist": 4.89442213317582,
        "bleu": 32.3231,
        "nubia": {
            "semantic_relation": 3.911,
            "contradiction": 20.0919,
            "irrelevancy": 31.27519,
            "logical_agreement": 48.6329,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.3864,
            "nubia_score": 0.67013
        },
        "bertscore": {
            "precision": 0.89757,
            "recall": 0.90649,
            "f1": 0.89638
        },
        "meteor": 0.31264100388823046,
        "bleurt": 0.12128
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "mT5_base/totto_test",
        "N": 17,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.42857142857142855,
            "3": 0.7365591397849462
        },
        "rouge1": {
            "precision": 0.73301,
            "recall": 0.71203,
            "fmeasure": 0.70755
        },
        "rouge2": {
            "precision": 0.52011,
            "recall": 0.51856,
            "fmeasure": 0.5053
        },
        "rougeL": {
            "precision": 0.66636,
            "recall": 0.64698,
            "fmeasure": 0.64144
        },
        "rougeLsum": {
            "precision": 0.66636,
            "recall": 0.64698,
            "fmeasure": 0.64144
        },
        "nist": 5.801190005268094,
        "bleu": 45.45295,
        "nubia": {
            "semantic_relation": 4.18111,
            "contradiction": 14.65484,
            "irrelevancy": 32.19291,
            "logical_agreement": 53.15226,
            "grammar_ref": 4.21928,
            "grammar_hyp": 4.08881,
            "nubia_score": 0.72499
        },
        "bertscore": {
            "precision": 0.92872,
            "recall": 0.92627,
            "f1": 0.92458
        },
        "meteor": 0.3697634923912389,
        "bleurt": 0.31072
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "mT5_base/totto_test",
        "N": 36,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25675675675675674,
            "2": 0.38202247191011235,
            "3": 0.7336561743341404
        },
        "rouge1": {
            "precision": 0.76022,
            "recall": 0.70075,
            "fmeasure": 0.71709
        },
        "rouge2": {
            "precision": 0.4958,
            "recall": 0.45379,
            "fmeasure": 0.46604
        },
        "rougeL": {
            "precision": 0.6334,
            "recall": 0.58511,
            "fmeasure": 0.5986
        },
        "rougeLsum": {
            "precision": 0.6334,
            "recall": 0.58511,
            "fmeasure": 0.5986
        },
        "nist": 6.382809175186036,
        "bleu": 38.2786,
        "nubia": {
            "semantic_relation": 4.2379,
            "contradiction": 4.08632,
            "irrelevancy": 25.74737,
            "logical_agreement": 70.16631,
            "grammar_ref": 4.82696,
            "grammar_hyp": 5.07913,
            "nubia_score": 0.71056
        },
        "bertscore": {
            "precision": 0.92931,
            "recall": 0.91441,
            "f1": 0.92045
        },
        "meteor": 0.3553920186283268,
        "bleurt": 0.27224
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "mT5_base/totto_test",
        "N": 17,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0625,
            "2": 0.4583333333333333,
            "3": 0.7751196172248804
        },
        "rouge1": {
            "precision": 0.81793,
            "recall": 0.764,
            "fmeasure": 0.78393
        },
        "rouge2": {
            "precision": 0.58989,
            "recall": 0.52455,
            "fmeasure": 0.55011
        },
        "rougeL": {
            "precision": 0.72517,
            "recall": 0.65699,
            "fmeasure": 0.68432
        },
        "rougeLsum": {
            "precision": 0.72517,
            "recall": 0.65699,
            "fmeasure": 0.68432
        },
        "nist": 6.127158184836311,
        "bleu": 48.99769,
        "nubia": {
            "semantic_relation": 4.09683,
            "contradiction": 6.38803,
            "irrelevancy": 23.68024,
            "logical_agreement": 69.93173,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.62686,
            "nubia_score": 0.68675
        },
        "bertscore": {
            "precision": 0.94073,
            "recall": 0.92836,
            "f1": 0.93356
        },
        "meteor": 0.3997540078768458,
        "bleurt": 0.31993
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5925925925925926,
            "2": 0.28125,
            "3": 0.725
        },
        "rouge1": {
            "precision": 0.71421,
            "recall": 0.65321,
            "fmeasure": 0.67451
        },
        "rouge2": {
            "precision": 0.43672,
            "recall": 0.40638,
            "fmeasure": 0.41465
        },
        "rougeL": {
            "precision": 0.54999,
            "recall": 0.51149,
            "fmeasure": 0.52338
        },
        "rougeLsum": {
            "precision": 0.54999,
            "recall": 0.51149,
            "fmeasure": 0.52338
        },
        "nist": 5.1666488414572855,
        "bleu": 39.62076,
        "nubia": {
            "semantic_relation": 3.69822,
            "contradiction": 12.56572,
            "irrelevancy": 34.51317,
            "logical_agreement": 52.92111,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.36558,
            "nubia_score": 0.55814
        },
        "bertscore": {
            "precision": 0.92254,
            "recall": 0.89639,
            "f1": 0.90713
        },
        "meteor": 0.34989837974963856,
        "bleurt": -0.02225
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13636363636363635,
            "2": 0.46153846153846156,
            "3": 0.6724137931034483
        },
        "rouge1": {
            "precision": 0.71799,
            "recall": 0.54841,
            "fmeasure": 0.60995
        },
        "rouge2": {
            "precision": 0.37685,
            "recall": 0.30794,
            "fmeasure": 0.33356
        },
        "rougeL": {
            "precision": 0.54214,
            "recall": 0.43238,
            "fmeasure": 0.46777
        },
        "rougeLsum": {
            "precision": 0.54214,
            "recall": 0.43238,
            "fmeasure": 0.46777
        },
        "nist": 3.911495569283396,
        "bleu": 32.66028,
        "nubia": {
            "semantic_relation": 3.98661,
            "contradiction": 0.3548,
            "irrelevancy": 41.78796,
            "logical_agreement": 57.85724,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.63936,
            "nubia_score": 0.64264
        },
        "bertscore": {
            "precision": 0.92181,
            "recall": 0.8839,
            "f1": 0.90194
        },
        "meteor": 0.3071072974402576,
        "bleurt": 0.17761
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5128205128205128,
            "3": 0.7586206896551724
        },
        "rouge1": {
            "precision": 0.72068,
            "recall": 0.70238,
            "fmeasure": 0.70185
        },
        "rouge2": {
            "precision": 0.4876,
            "recall": 0.46259,
            "fmeasure": 0.46652
        },
        "rougeL": {
            "precision": 0.58689,
            "recall": 0.55842,
            "fmeasure": 0.56405
        },
        "rougeLsum": {
            "precision": 0.58689,
            "recall": 0.55842,
            "fmeasure": 0.56405
        },
        "nist": 5.340997453142719,
        "bleu": 32.49979,
        "nubia": {
            "semantic_relation": 3.92928,
            "contradiction": 15.67167,
            "irrelevancy": 50.11155,
            "logical_agreement": 34.21678,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.41771,
            "nubia_score": 0.65216
        },
        "bertscore": {
            "precision": 0.90628,
            "recall": 0.90442,
            "f1": 0.90433
        },
        "meteor": 0.36797364069102523,
        "bleurt": 0.07647
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "mT5_base/totto_test",
        "N": 12,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08,
            "2": 0.15384615384615385,
            "3": 0.7352941176470589
        },
        "rouge1": {
            "precision": 0.82623,
            "recall": 0.66371,
            "fmeasure": 0.73009
        },
        "rouge2": {
            "precision": 0.58298,
            "recall": 0.4611,
            "fmeasure": 0.5095
        },
        "rougeL": {
            "precision": 0.74875,
            "recall": 0.59414,
            "fmeasure": 0.65595
        },
        "rougeLsum": {
            "precision": 0.74875,
            "recall": 0.59414,
            "fmeasure": 0.65595
        },
        "nist": 4.803616620113749,
        "bleu": 35.58373,
        "nubia": {
            "semantic_relation": 4.06366,
            "contradiction": 3.31799,
            "irrelevancy": 27.92217,
            "logical_agreement": 68.75983,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.38575,
            "nubia_score": 0.71289
        },
        "bertscore": {
            "precision": 0.93686,
            "recall": 0.90964,
            "f1": 0.92045
        },
        "meteor": 0.3376997953613369,
        "bleurt": 0.29652
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "mT5_base/totto_test",
        "N": 78,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2017167381974249,
            "2": 0.4765957446808511,
            "3": 0.7749391727493917
        },
        "rouge1": {
            "precision": 0.79179,
            "recall": 0.71771,
            "fmeasure": 0.74156
        },
        "rouge2": {
            "precision": 0.55627,
            "recall": 0.50114,
            "fmeasure": 0.5194
        },
        "rougeL": {
            "precision": 0.70569,
            "recall": 0.64261,
            "fmeasure": 0.66232
        },
        "rougeLsum": {
            "precision": 0.70569,
            "recall": 0.64261,
            "fmeasure": 0.66232
        },
        "nist": 7.215629998609084,
        "bleu": 48.06192,
        "nubia": {
            "semantic_relation": 4.31175,
            "contradiction": 5.88481,
            "irrelevancy": 27.67238,
            "logical_agreement": 66.44281,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.78945,
            "nubia_score": 0.74935
        },
        "bertscore": {
            "precision": 0.93667,
            "recall": 0.92867,
            "f1": 0.93143
        },
        "meteor": 0.4020476483472338,
        "bleurt": 0.33189
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1794871794871795,
            "2": 0.3888888888888889,
            "3": 0.8253968253968254
        },
        "rouge1": {
            "precision": 0.75631,
            "recall": 0.75579,
            "fmeasure": 0.74904
        },
        "rouge2": {
            "precision": 0.55322,
            "recall": 0.56037,
            "fmeasure": 0.55008
        },
        "rougeL": {
            "precision": 0.65534,
            "recall": 0.64215,
            "fmeasure": 0.6415
        },
        "rougeLsum": {
            "precision": 0.65534,
            "recall": 0.64215,
            "fmeasure": 0.6415
        },
        "nist": 5.135574694880007,
        "bleu": 46.10418,
        "nubia": {
            "semantic_relation": 4.36815,
            "contradiction": 2.30425,
            "irrelevancy": 43.97682,
            "logical_agreement": 53.71893,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.39976,
            "nubia_score": 0.78053
        },
        "bertscore": {
            "precision": 0.93701,
            "recall": 0.94072,
            "f1": 0.93853
        },
        "meteor": 0.41843572661556155,
        "bleurt": 0.19245
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "mT5_base/totto_test",
        "N": 10,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4074074074074074,
            "2": 0.4117647058823529,
            "3": 0.8018867924528302
        },
        "rouge1": {
            "precision": 0.77451,
            "recall": 0.75018,
            "fmeasure": 0.74755
        },
        "rouge2": {
            "precision": 0.4704,
            "recall": 0.46606,
            "fmeasure": 0.45474
        },
        "rougeL": {
            "precision": 0.67901,
            "recall": 0.64591,
            "fmeasure": 0.64946
        },
        "rougeLsum": {
            "precision": 0.67901,
            "recall": 0.64591,
            "fmeasure": 0.64946
        },
        "nist": 5.6695598833803675,
        "bleu": 42.66907,
        "nubia": {
            "semantic_relation": 4.67865,
            "contradiction": 5.89975,
            "irrelevancy": 17.7359,
            "logical_agreement": 76.36435,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.19967,
            "nubia_score": 0.81523
        },
        "bertscore": {
            "precision": 0.93322,
            "recall": 0.93361,
            "f1": 0.93273
        },
        "meteor": 0.39283725877609754,
        "bleurt": 0.40372
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "mT5_base/totto_test",
        "N": 18,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10204081632653061,
            "2": 0.4107142857142857,
            "3": 0.7411764705882353
        },
        "rouge1": {
            "precision": 0.68782,
            "recall": 0.66618,
            "fmeasure": 0.66932
        },
        "rouge2": {
            "precision": 0.41355,
            "recall": 0.41413,
            "fmeasure": 0.40803
        },
        "rougeL": {
            "precision": 0.56,
            "recall": 0.5621,
            "fmeasure": 0.55401
        },
        "rougeLsum": {
            "precision": 0.56,
            "recall": 0.5621,
            "fmeasure": 0.55401
        },
        "nist": 5.383481038976073,
        "bleu": 34.63181,
        "nubia": {
            "semantic_relation": 4.20481,
            "contradiction": 1.93677,
            "irrelevancy": 45.4128,
            "logical_agreement": 52.65042,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.61065,
            "nubia_score": 0.73953
        },
        "bertscore": {
            "precision": 0.91637,
            "recall": 0.91588,
            "f1": 0.91514
        },
        "meteor": 0.35178862757078505,
        "bleurt": 0.25118
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "mT5_base/totto_test",
        "N": 12,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3103448275862069,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.80929,
            "recall": 0.76934,
            "fmeasure": 0.78231
        },
        "rouge2": {
            "precision": 0.59854,
            "recall": 0.54625,
            "fmeasure": 0.56661
        },
        "rougeL": {
            "precision": 0.74393,
            "recall": 0.67532,
            "fmeasure": 0.70307
        },
        "rougeLsum": {
            "precision": 0.74393,
            "recall": 0.67532,
            "fmeasure": 0.70307
        },
        "nist": 5.750746180070532,
        "bleu": 49.22744,
        "nubia": {
            "semantic_relation": 4.5298,
            "contradiction": 7.22401,
            "irrelevancy": 18.70482,
            "logical_agreement": 74.07117,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.12406,
            "nubia_score": 0.85637
        },
        "bertscore": {
            "precision": 0.94996,
            "recall": 0.93853,
            "f1": 0.94212
        },
        "meteor": 0.4071617282154422,
        "bleurt": 0.48096
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "mT5_base/totto_test",
        "N": 37,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2647058823529412,
            "2": 0.3979591836734694,
            "3": 0.7318840579710145
        },
        "rouge1": {
            "precision": 0.71552,
            "recall": 0.71741,
            "fmeasure": 0.70329
        },
        "rouge2": {
            "precision": 0.46022,
            "recall": 0.46432,
            "fmeasure": 0.45396
        },
        "rougeL": {
            "precision": 0.61497,
            "recall": 0.61613,
            "fmeasure": 0.60402
        },
        "rougeLsum": {
            "precision": 0.61497,
            "recall": 0.61613,
            "fmeasure": 0.60402
        },
        "nist": 6.2340155379730735,
        "bleu": 39.29687,
        "nubia": {
            "semantic_relation": 4.01152,
            "contradiction": 11.93948,
            "irrelevancy": 31.76515,
            "logical_agreement": 56.29537,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.79326,
            "nubia_score": 0.67762
        },
        "bertscore": {
            "precision": 0.92049,
            "recall": 0.91668,
            "f1": 0.91778
        },
        "meteor": 0.37963872514655117,
        "bleurt": 0.16367
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.4444444444444444,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.59096,
            "recall": 0.69133,
            "fmeasure": 0.60847
        },
        "rouge2": {
            "precision": 0.45085,
            "recall": 0.43611,
            "fmeasure": 0.44182
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.62697,
            "fmeasure": 0.54285
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.62697,
            "fmeasure": 0.54285
        },
        "nist": 3.2660762520705915,
        "bleu": 40.36818,
        "nubia": {
            "semantic_relation": 4.12478,
            "contradiction": 4.39948,
            "irrelevancy": 44.55689,
            "logical_agreement": 51.04363,
            "grammar_ref": 5.944,
            "grammar_hyp": 5.04305,
            "nubia_score": 0.70715
        },
        "bertscore": {
            "precision": 0.87013,
            "recall": 0.90071,
            "f1": 0.88394
        },
        "meteor": 0.35885852554145764,
        "bleurt": 0.18546
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "mT5_base/totto_test",
        "N": 79,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21543408360128619,
            "2": 0.4041095890410959,
            "3": 0.7312252964426877
        },
        "rouge1": {
            "precision": 0.74186,
            "recall": 0.66138,
            "fmeasure": 0.68175
        },
        "rouge2": {
            "precision": 0.5036,
            "recall": 0.44374,
            "fmeasure": 0.45628
        },
        "rougeL": {
            "precision": 0.6468,
            "recall": 0.57464,
            "fmeasure": 0.59207
        },
        "rougeLsum": {
            "precision": 0.6468,
            "recall": 0.57464,
            "fmeasure": 0.59207
        },
        "nist": 6.675710630748982,
        "bleu": 40.5236,
        "nubia": {
            "semantic_relation": 4.04394,
            "contradiction": 9.28897,
            "irrelevancy": 31.21822,
            "logical_agreement": 59.49281,
            "grammar_ref": 4.80224,
            "grammar_hyp": 5.01451,
            "nubia_score": 0.65478
        },
        "bertscore": {
            "precision": 0.92481,
            "recall": 0.91136,
            "f1": 0.91603
        },
        "meteor": 0.367782315022319,
        "bleurt": 0.14624
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.1111111111111111,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.81154,
            "recall": 0.77096,
            "fmeasure": 0.78615
        },
        "rouge2": {
            "precision": 0.5787,
            "recall": 0.58268,
            "fmeasure": 0.5788
        },
        "rougeL": {
            "precision": 0.69359,
            "recall": 0.669,
            "fmeasure": 0.67825
        },
        "rougeLsum": {
            "precision": 0.69359,
            "recall": 0.669,
            "fmeasure": 0.67825
        },
        "nist": 5.036873382935153,
        "bleu": 60.04538,
        "nubia": {
            "semantic_relation": 4.35012,
            "contradiction": 1.11195,
            "irrelevancy": 42.1077,
            "logical_agreement": 56.78035,
            "grammar_ref": 6.02061,
            "grammar_hyp": 6.05262,
            "nubia_score": 0.73294
        },
        "bertscore": {
            "precision": 0.94874,
            "recall": 0.95207,
            "f1": 0.9501
        },
        "meteor": 0.4230542160405328,
        "bleurt": 0.41038
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8076923076923077
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.8355,
            "fmeasure": 0.88645
        },
        "rouge2": {
            "precision": 0.79412,
            "recall": 0.7,
            "fmeasure": 0.74395
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.69264,
            "fmeasure": 0.7326
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.69264,
            "fmeasure": 0.7326
        },
        "nist": 4.156701580454727,
        "bleu": 52.20162,
        "nubia": {
            "semantic_relation": 4.65298,
            "contradiction": 0.37876,
            "irrelevancy": 0.50364,
            "logical_agreement": 99.11761,
            "grammar_ref": 5.14789,
            "grammar_hyp": 5.50686,
            "nubia_score": 0.84472
        },
        "bertscore": {
            "precision": 0.97823,
            "recall": 0.95489,
            "f1": 0.9664
        },
        "meteor": 0.44576619283593505,
        "bleurt": 0.56864
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "mT5_base/totto_test",
        "N": 21,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.5,
            "3": 0.7268041237113402
        },
        "rouge1": {
            "precision": 0.73338,
            "recall": 0.6699,
            "fmeasure": 0.69196
        },
        "rouge2": {
            "precision": 0.46045,
            "recall": 0.43578,
            "fmeasure": 0.44189
        },
        "rougeL": {
            "precision": 0.59402,
            "recall": 0.54646,
            "fmeasure": 0.56233
        },
        "rougeLsum": {
            "precision": 0.59402,
            "recall": 0.54646,
            "fmeasure": 0.56233
        },
        "nist": 6.128921016812389,
        "bleu": 36.86364,
        "nubia": {
            "semantic_relation": 3.98107,
            "contradiction": 21.90434,
            "irrelevancy": 21.33734,
            "logical_agreement": 56.75832,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.75283,
            "nubia_score": 0.65943
        },
        "bertscore": {
            "precision": 0.92507,
            "recall": 0.91116,
            "f1": 0.91659
        },
        "meteor": 0.3642250325296011,
        "bleurt": 0.22518
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "mT5_base/totto_test",
        "N": 24,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0851063829787234,
            "2": 0.29069767441860467,
            "3": 0.7510548523206751
        },
        "rouge1": {
            "precision": 0.754,
            "recall": 0.68674,
            "fmeasure": 0.70588
        },
        "rouge2": {
            "precision": 0.51302,
            "recall": 0.45961,
            "fmeasure": 0.47638
        },
        "rougeL": {
            "precision": 0.69831,
            "recall": 0.63224,
            "fmeasure": 0.65159
        },
        "rougeLsum": {
            "precision": 0.69831,
            "recall": 0.63224,
            "fmeasure": 0.65159
        },
        "nist": 5.334359666209537,
        "bleu": 38.42652,
        "nubia": {
            "semantic_relation": 4.20186,
            "contradiction": 4.4306,
            "irrelevancy": 28.82674,
            "logical_agreement": 66.74266,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.78048,
            "nubia_score": 0.72008
        },
        "bertscore": {
            "precision": 0.9269,
            "recall": 0.91867,
            "f1": 0.92118
        },
        "meteor": 0.36276767965485895,
        "bleurt": 0.26425
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "mT5_base/totto_test",
        "N": 22,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18666666666666668,
            "2": 0.4909090909090909,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.71049,
            "recall": 0.70158,
            "fmeasure": 0.69604
        },
        "rouge2": {
            "precision": 0.4485,
            "recall": 0.44991,
            "fmeasure": 0.44128
        },
        "rougeL": {
            "precision": 0.60544,
            "recall": 0.59805,
            "fmeasure": 0.59282
        },
        "rougeLsum": {
            "precision": 0.60544,
            "recall": 0.59805,
            "fmeasure": 0.59282
        },
        "nist": 5.743546438228314,
        "bleu": 41.66517,
        "nubia": {
            "semantic_relation": 4.235,
            "contradiction": 6.85886,
            "irrelevancy": 28.58659,
            "logical_agreement": 64.55455,
            "grammar_ref": 5.03776,
            "grammar_hyp": 5.12396,
            "nubia_score": 0.73089
        },
        "bertscore": {
            "precision": 0.90736,
            "recall": 0.91175,
            "f1": 0.90854
        },
        "meteor": 0.3780182570999634,
        "bleurt": 0.14731
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.047619047619047616,
            "2": 0.65,
            "3": 0.7608695652173914
        },
        "rouge1": {
            "precision": 0.6865,
            "recall": 0.74225,
            "fmeasure": 0.70704
        },
        "rouge2": {
            "precision": 0.43501,
            "recall": 0.48039,
            "fmeasure": 0.45125
        },
        "rougeL": {
            "precision": 0.61654,
            "recall": 0.6685,
            "fmeasure": 0.63518
        },
        "rougeLsum": {
            "precision": 0.61654,
            "recall": 0.6685,
            "fmeasure": 0.63518
        },
        "nist": 4.7409979577348516,
        "bleu": 46.16524,
        "nubia": {
            "semantic_relation": 4.04727,
            "contradiction": 5.78316,
            "irrelevancy": 36.98756,
            "logical_agreement": 57.22929,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.46566,
            "nubia_score": 0.73872
        },
        "bertscore": {
            "precision": 0.92254,
            "recall": 0.93511,
            "f1": 0.92751
        },
        "meteor": 0.36519669387308196,
        "bleurt": 0.26169
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "mT5_base/totto_test",
        "N": 41,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25555555555555554,
            "2": 0.45454545454545453,
            "3": 0.7787878787878788
        },
        "rouge1": {
            "precision": 0.76229,
            "recall": 0.73859,
            "fmeasure": 0.74009
        },
        "rouge2": {
            "precision": 0.5434,
            "recall": 0.52567,
            "fmeasure": 0.52708
        },
        "rougeL": {
            "precision": 0.65418,
            "recall": 0.63156,
            "fmeasure": 0.63335
        },
        "rougeLsum": {
            "precision": 0.65418,
            "recall": 0.63156,
            "fmeasure": 0.63335
        },
        "nist": 6.343299324074418,
        "bleu": 45.20729,
        "nubia": {
            "semantic_relation": 3.94144,
            "contradiction": 10.57373,
            "irrelevancy": 32.80664,
            "logical_agreement": 56.61963,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.49167,
            "nubia_score": 0.67274
        },
        "bertscore": {
            "precision": 0.93072,
            "recall": 0.92833,
            "f1": 0.92778
        },
        "meteor": 0.4019237776476949,
        "bleurt": 0.32329
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.75862,
            "recall": 0.75147,
            "fmeasure": 0.75364
        },
        "rouge2": {
            "precision": 0.52083,
            "recall": 0.53111,
            "fmeasure": 0.52456
        },
        "rougeL": {
            "precision": 0.6954,
            "recall": 0.69515,
            "fmeasure": 0.69357
        },
        "rougeLsum": {
            "precision": 0.6954,
            "recall": 0.69515,
            "fmeasure": 0.69357
        },
        "nist": 5.110288795100587,
        "bleu": 69.31235,
        "nubia": {
            "semantic_relation": 4.68809,
            "contradiction": 10.13226,
            "irrelevancy": 3.05633,
            "logical_agreement": 86.81141,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.64501,
            "nubia_score": 0.82668
        },
        "bertscore": {
            "precision": 0.95303,
            "recall": 0.91104,
            "f1": 0.93127
        },
        "meteor": 0.45623566381223796,
        "bleurt": 0.35176
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "mT5_base/totto_test",
        "N": 23,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24,
            "2": 0.5081967213114754,
            "3": 0.7542372881355932
        },
        "rouge1": {
            "precision": 0.75716,
            "recall": 0.74419,
            "fmeasure": 0.74177
        },
        "rouge2": {
            "precision": 0.53721,
            "recall": 0.53104,
            "fmeasure": 0.52595
        },
        "rougeL": {
            "precision": 0.65558,
            "recall": 0.64772,
            "fmeasure": 0.64351
        },
        "rougeLsum": {
            "precision": 0.65558,
            "recall": 0.64772,
            "fmeasure": 0.64351
        },
        "nist": 6.207916613348461,
        "bleu": 44.17398,
        "nubia": {
            "semantic_relation": 4.29167,
            "contradiction": 8.17371,
            "irrelevancy": 26.2731,
            "logical_agreement": 65.55319,
            "grammar_ref": 4.22562,
            "grammar_hyp": 4.20909,
            "nubia_score": 0.77659
        },
        "bertscore": {
            "precision": 0.9198,
            "recall": 0.91826,
            "f1": 0.91777
        },
        "meteor": 0.397308911965516,
        "bleurt": 0.2503
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "nist": 2.0052535157554314,
        "bleu": 16.51582,
        "nubia": {
            "semantic_relation": 3.12986,
            "contradiction": 71.68311,
            "irrelevancy": 20.1839,
            "logical_agreement": 8.133,
            "grammar_ref": 6.80479,
            "grammar_hyp": 6.78582,
            "nubia_score": 0.30685
        },
        "bertscore": {
            "precision": 0.87519,
            "recall": 0.87347,
            "f1": 0.87433
        },
        "meteor": 0.31253823342571707,
        "bleurt": -0.06824
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "mT5_base/totto_test",
        "N": 23,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1643835616438356,
            "2": 0.3023255813953488,
            "3": 0.782051282051282
        },
        "rouge1": {
            "precision": 0.80458,
            "recall": 0.71644,
            "fmeasure": 0.74395
        },
        "rouge2": {
            "precision": 0.58598,
            "recall": 0.5266,
            "fmeasure": 0.54564
        },
        "rougeL": {
            "precision": 0.7092,
            "recall": 0.63915,
            "fmeasure": 0.66066
        },
        "rougeLsum": {
            "precision": 0.7092,
            "recall": 0.63915,
            "fmeasure": 0.66066
        },
        "nist": 5.974009229238176,
        "bleu": 48.44193,
        "nubia": {
            "semantic_relation": 4.29634,
            "contradiction": 1.75762,
            "irrelevancy": 21.62508,
            "logical_agreement": 76.61729,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.72512,
            "nubia_score": 0.7472
        },
        "bertscore": {
            "precision": 0.9372,
            "recall": 0.91674,
            "f1": 0.92389
        },
        "meteor": 0.39308227656317607,
        "bleurt": 0.34749
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "mT5_base/totto_test",
        "N": 31,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18584070796460178,
            "2": 0.45918367346938777,
            "3": 0.8236914600550964
        },
        "rouge1": {
            "precision": 0.79603,
            "recall": 0.77804,
            "fmeasure": 0.7802
        },
        "rouge2": {
            "precision": 0.59079,
            "recall": 0.57847,
            "fmeasure": 0.57984
        },
        "rougeL": {
            "precision": 0.70311,
            "recall": 0.69042,
            "fmeasure": 0.69146
        },
        "rougeLsum": {
            "precision": 0.70311,
            "recall": 0.69042,
            "fmeasure": 0.69146
        },
        "nist": 7.282359505564018,
        "bleu": 56.20672,
        "nubia": {
            "semantic_relation": 4.24482,
            "contradiction": 16.31477,
            "irrelevancy": 22.0853,
            "logical_agreement": 61.59993,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.91091,
            "nubia_score": 0.73114
        },
        "bertscore": {
            "precision": 0.93878,
            "recall": 0.9324,
            "f1": 0.93476
        },
        "meteor": 0.43927050517429445,
        "bleurt": 0.36627
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.42857142857142855,
            "3": 0.8214285714285714
        },
        "rouge1": {
            "precision": 0.84714,
            "recall": 0.77493,
            "fmeasure": 0.80367
        },
        "rouge2": {
            "precision": 0.56561,
            "recall": 0.51597,
            "fmeasure": 0.53464
        },
        "rougeL": {
            "precision": 0.73401,
            "recall": 0.67654,
            "fmeasure": 0.69901
        },
        "rougeLsum": {
            "precision": 0.73401,
            "recall": 0.67654,
            "fmeasure": 0.69901
        },
        "nist": 4.700680187633745,
        "bleu": 43.45045,
        "nubia": {
            "semantic_relation": 4.22003,
            "contradiction": 1.66513,
            "irrelevancy": 35.94936,
            "logical_agreement": 62.38552,
            "grammar_ref": 5.80868,
            "grammar_hyp": 5.86833,
            "nubia_score": 0.71474
        },
        "bertscore": {
            "precision": 0.93098,
            "recall": 0.93476,
            "f1": 0.93168
        },
        "meteor": 0.422724644069693,
        "bleurt": 0.24463
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "mT5_base/totto_test",
        "N": 11,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3111111111111111,
            "2": 0.10344827586206896,
            "3": 0.7204301075268817
        },
        "rouge1": {
            "precision": 0.68267,
            "recall": 0.65659,
            "fmeasure": 0.6548
        },
        "rouge2": {
            "precision": 0.43423,
            "recall": 0.41753,
            "fmeasure": 0.41302
        },
        "rougeL": {
            "precision": 0.60241,
            "recall": 0.5949,
            "fmeasure": 0.58491
        },
        "rougeLsum": {
            "precision": 0.60241,
            "recall": 0.5949,
            "fmeasure": 0.58491
        },
        "nist": 4.912662647225181,
        "bleu": 35.34593,
        "nubia": {
            "semantic_relation": 4.20971,
            "contradiction": 1.62023,
            "irrelevancy": 50.30475,
            "logical_agreement": 48.07502,
            "grammar_ref": 5.00152,
            "grammar_hyp": 5.0104,
            "nubia_score": 0.71152
        },
        "bertscore": {
            "precision": 0.91245,
            "recall": 0.90089,
            "f1": 0.90428
        },
        "meteor": 0.3506208241598287,
        "bleurt": 0.25116
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "mT5_base/totto_test",
        "N": 169,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20711297071129708,
            "2": 0.41123595505617977,
            "3": 0.7622863247863247
        },
        "rouge1": {
            "precision": 0.76429,
            "recall": 0.72893,
            "fmeasure": 0.73453
        },
        "rouge2": {
            "precision": 0.53218,
            "recall": 0.50574,
            "fmeasure": 0.51041
        },
        "rougeL": {
            "precision": 0.66419,
            "recall": 0.63698,
            "fmeasure": 0.63981
        },
        "rougeLsum": {
            "precision": 0.66419,
            "recall": 0.63698,
            "fmeasure": 0.63981
        },
        "nist": 7.639587139937944,
        "bleu": 43.03307,
        "nubia": {
            "semantic_relation": 4.14541,
            "contradiction": 8.62485,
            "irrelevancy": 28.46252,
            "logical_agreement": 62.91263,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.69143,
            "nubia_score": 0.71839
        },
        "bertscore": {
            "precision": 0.9273,
            "recall": 0.91969,
            "f1": 0.92208
        },
        "meteor": 0.3815727542866406,
        "bleurt": 0.28624
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "mT5_base/totto_test",
        "N": 300,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17852975495915985,
            "2": 0.4007682458386684,
            "3": 0.7984756097560975
        },
        "rouge1": {
            "precision": 0.79762,
            "recall": 0.75569,
            "fmeasure": 0.76542
        },
        "rouge2": {
            "precision": 0.55355,
            "recall": 0.52239,
            "fmeasure": 0.52964
        },
        "rougeL": {
            "precision": 0.67549,
            "recall": 0.64066,
            "fmeasure": 0.6484
        },
        "rougeLsum": {
            "precision": 0.67549,
            "recall": 0.64066,
            "fmeasure": 0.6484
        },
        "nist": 8.49946328024869,
        "bleu": 44.81659,
        "nubia": {
            "semantic_relation": 4.38439,
            "contradiction": 5.47232,
            "irrelevancy": 24.92211,
            "logical_agreement": 69.60556,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.90159,
            "nubia_score": 0.77418
        },
        "bertscore": {
            "precision": 0.93942,
            "recall": 0.93414,
            "f1": 0.93554
        },
        "meteor": 0.40238900221980656,
        "bleurt": 0.36602
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "mT5_base/totto_test",
        "N": 81,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22866894197952217,
            "2": 0.46124031007751937,
            "3": 0.7915690866510539
        },
        "rouge1": {
            "precision": 0.76265,
            "recall": 0.73359,
            "fmeasure": 0.73146
        },
        "rouge2": {
            "precision": 0.55999,
            "recall": 0.53424,
            "fmeasure": 0.53456
        },
        "rougeL": {
            "precision": 0.67099,
            "recall": 0.64096,
            "fmeasure": 0.64108
        },
        "rougeLsum": {
            "precision": 0.67099,
            "recall": 0.64096,
            "fmeasure": 0.64108
        },
        "nist": 7.442706841067514,
        "bleu": 50.40528,
        "nubia": {
            "semantic_relation": 4.12172,
            "contradiction": 9.78242,
            "irrelevancy": 27.98737,
            "logical_agreement": 62.23021,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.62646,
            "nubia_score": 0.70185
        },
        "bertscore": {
            "precision": 0.92998,
            "recall": 0.92623,
            "f1": 0.92671
        },
        "meteor": 0.4033087717390636,
        "bleurt": 0.24882
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "mT5_base/totto_test",
        "N": 17,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1527777777777778,
            "2": 0.4262295081967213,
            "3": 0.7080745341614907
        },
        "rouge1": {
            "precision": 0.70749,
            "recall": 0.6508,
            "fmeasure": 0.6724
        },
        "rouge2": {
            "precision": 0.40303,
            "recall": 0.37855,
            "fmeasure": 0.38737
        },
        "rougeL": {
            "precision": 0.56207,
            "recall": 0.53525,
            "fmeasure": 0.54361
        },
        "rougeLsum": {
            "precision": 0.56207,
            "recall": 0.53525,
            "fmeasure": 0.54361
        },
        "nist": 5.112611871416049,
        "bleu": 32.7895,
        "nubia": {
            "semantic_relation": 4.01748,
            "contradiction": 15.88688,
            "irrelevancy": 23.05035,
            "logical_agreement": 61.06277,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.80865,
            "nubia_score": 0.68088
        },
        "bertscore": {
            "precision": 0.92169,
            "recall": 0.91237,
            "f1": 0.91682
        },
        "meteor": 0.33999787161587885,
        "bleurt": 0.2088
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "mT5_base/totto_test",
        "N": 75,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2339622641509434,
            "2": 0.4583333333333333,
            "3": 0.7898089171974523
        },
        "rouge1": {
            "precision": 0.78126,
            "recall": 0.73855,
            "fmeasure": 0.74975
        },
        "rouge2": {
            "precision": 0.57298,
            "recall": 0.54365,
            "fmeasure": 0.55048
        },
        "rougeL": {
            "precision": 0.66824,
            "recall": 0.6356,
            "fmeasure": 0.6434
        },
        "rougeLsum": {
            "precision": 0.66824,
            "recall": 0.6356,
            "fmeasure": 0.6434
        },
        "nist": 7.71382818811285,
        "bleu": 49.34225,
        "nubia": {
            "semantic_relation": 4.18499,
            "contradiction": 11.13506,
            "irrelevancy": 29.39932,
            "logical_agreement": 59.46562,
            "grammar_ref": 4.90125,
            "grammar_hyp": 4.93538,
            "nubia_score": 0.72063
        },
        "bertscore": {
            "precision": 0.93398,
            "recall": 0.92531,
            "f1": 0.92766
        },
        "meteor": 0.4007546814334835,
        "bleurt": 0.2823
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "mT5_base/totto_test",
        "N": 31,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20408163265306123,
            "2": 0.422680412371134,
            "3": 0.8053691275167785
        },
        "rouge1": {
            "precision": 0.78411,
            "recall": 0.73068,
            "fmeasure": 0.74365
        },
        "rouge2": {
            "precision": 0.53932,
            "recall": 0.51205,
            "fmeasure": 0.51389
        },
        "rougeL": {
            "precision": 0.65336,
            "recall": 0.619,
            "fmeasure": 0.62388
        },
        "rougeLsum": {
            "precision": 0.65336,
            "recall": 0.619,
            "fmeasure": 0.62388
        },
        "nist": 6.386617854507188,
        "bleu": 47.43464,
        "nubia": {
            "semantic_relation": 4.29187,
            "contradiction": 9.1477,
            "irrelevancy": 27.33767,
            "logical_agreement": 63.51463,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.52194,
            "nubia_score": 0.75095
        },
        "bertscore": {
            "precision": 0.93568,
            "recall": 0.93585,
            "f1": 0.9346
        },
        "meteor": 0.40420442125931066,
        "bleurt": 0.31524
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.42857142857142855,
            "3": 0.7027027027027027
        },
        "rouge1": {
            "precision": 0.7083,
            "recall": 0.74467,
            "fmeasure": 0.71998
        },
        "rouge2": {
            "precision": 0.40449,
            "recall": 0.43956,
            "fmeasure": 0.41782
        },
        "rougeL": {
            "precision": 0.51662,
            "recall": 0.57146,
            "fmeasure": 0.53669
        },
        "rougeLsum": {
            "precision": 0.51662,
            "recall": 0.57146,
            "fmeasure": 0.53669
        },
        "nist": 3.7954368482095524,
        "bleu": 33.78126,
        "nubia": {
            "semantic_relation": 3.60358,
            "contradiction": 24.40779,
            "irrelevancy": 36.21049,
            "logical_agreement": 39.38172,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.41737,
            "nubia_score": 0.60428
        },
        "bertscore": {
            "precision": 0.89014,
            "recall": 0.90885,
            "f1": 0.89546
        },
        "meteor": 0.3430302779334475,
        "bleurt": 0.13836
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "mT5_base/totto_test",
        "N": 56,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18518518518518517,
            "2": 0.3860759493670886,
            "3": 0.7429906542056075
        },
        "rouge1": {
            "precision": 0.77904,
            "recall": 0.68926,
            "fmeasure": 0.72067
        },
        "rouge2": {
            "precision": 0.54047,
            "recall": 0.47883,
            "fmeasure": 0.50004
        },
        "rougeL": {
            "precision": 0.69368,
            "recall": 0.61446,
            "fmeasure": 0.64175
        },
        "rougeLsum": {
            "precision": 0.69368,
            "recall": 0.61446,
            "fmeasure": 0.64175
        },
        "nist": 6.697831144711238,
        "bleu": 44.55074,
        "nubia": {
            "semantic_relation": 4.18379,
            "contradiction": 9.08755,
            "irrelevancy": 32.12493,
            "logical_agreement": 58.78752,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.91263,
            "nubia_score": 0.70458
        },
        "bertscore": {
            "precision": 0.92732,
            "recall": 0.91588,
            "f1": 0.9201
        },
        "meteor": 0.38553370703508105,
        "bleurt": 0.23676
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.6,
            "3": 0.9183673469387755
        },
        "rouge1": {
            "precision": 0.78616,
            "recall": 0.92583,
            "fmeasure": 0.84102
        },
        "rouge2": {
            "precision": 0.64158,
            "recall": 0.75769,
            "fmeasure": 0.68606
        },
        "rougeL": {
            "precision": 0.71767,
            "recall": 0.82826,
            "fmeasure": 0.76229
        },
        "rougeLsum": {
            "precision": 0.71767,
            "recall": 0.82826,
            "fmeasure": 0.76229
        },
        "nist": 4.922706780194987,
        "bleu": 51.30908,
        "nubia": {
            "semantic_relation": 4.10659,
            "contradiction": 9.48533,
            "irrelevancy": 32.68339,
            "logical_agreement": 57.83129,
            "grammar_ref": 5.56433,
            "grammar_hyp": 5.00449,
            "nubia_score": 0.7519
        },
        "bertscore": {
            "precision": 0.95279,
            "recall": 0.95616,
            "f1": 0.95444
        },
        "meteor": 0.45012977883684124,
        "bleurt": 0.36864
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "mT5_base/totto_test",
        "N": 15,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.2125,
            "3": 0.7309941520467836
        },
        "rouge1": {
            "precision": 0.74146,
            "recall": 0.64438,
            "fmeasure": 0.6828
        },
        "rouge2": {
            "precision": 0.48223,
            "recall": 0.41303,
            "fmeasure": 0.44117
        },
        "rougeL": {
            "precision": 0.62784,
            "recall": 0.54577,
            "fmeasure": 0.57907
        },
        "rougeLsum": {
            "precision": 0.62784,
            "recall": 0.54577,
            "fmeasure": 0.57907
        },
        "nist": 5.076236397117401,
        "bleu": 42.17207,
        "nubia": {
            "semantic_relation": 4.122,
            "contradiction": 1.37221,
            "irrelevancy": 34.85318,
            "logical_agreement": 63.77461,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.89792,
            "nubia_score": 0.6752
        },
        "bertscore": {
            "precision": 0.90194,
            "recall": 0.89821,
            "f1": 0.89908
        },
        "meteor": 0.36493179295885014,
        "bleurt": 0.08256
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_base/totto_test",
        "N": 483,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22047702152414195,
            "2": 0.4038709677419355,
            "3": 0.7535026269702276
        },
        "rouge1": {
            "precision": 0.7579,
            "recall": 0.71531,
            "fmeasure": 0.72541
        },
        "rouge2": {
            "precision": 0.49757,
            "recall": 0.47107,
            "fmeasure": 0.477
        },
        "rougeL": {
            "precision": 0.61128,
            "recall": 0.58047,
            "fmeasure": 0.58644
        },
        "rougeLsum": {
            "precision": 0.61128,
            "recall": 0.58047,
            "fmeasure": 0.58644
        },
        "nist": 8.731454261867778,
        "bleu": 41.02847,
        "nubia": {
            "semantic_relation": 4.11187,
            "contradiction": 12.1958,
            "irrelevancy": 33.63676,
            "logical_agreement": 54.16744,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.3278,
            "nubia_score": 0.7053
        },
        "bertscore": {
            "precision": 0.92378,
            "recall": 0.91701,
            "f1": 0.9186
        },
        "meteor": 0.3804174655101056,
        "bleurt": 0.19055
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "mT5_base/totto_test",
        "N": 14,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.2962962962962963,
            "3": 0.7294117647058823
        },
        "rouge1": {
            "precision": 0.74395,
            "recall": 0.696,
            "fmeasure": 0.70495
        },
        "rouge2": {
            "precision": 0.48519,
            "recall": 0.44289,
            "fmeasure": 0.45567
        },
        "rougeL": {
            "precision": 0.61383,
            "recall": 0.57536,
            "fmeasure": 0.58264
        },
        "rougeLsum": {
            "precision": 0.61383,
            "recall": 0.57536,
            "fmeasure": 0.58264
        },
        "nist": 4.460996421467006,
        "bleu": 33.99699,
        "nubia": {
            "semantic_relation": 4.32237,
            "contradiction": 20.15134,
            "irrelevancy": 6.11247,
            "logical_agreement": 73.73618,
            "grammar_ref": 4.7817,
            "grammar_hyp": 4.9033,
            "nubia_score": 0.7304
        },
        "bertscore": {
            "precision": 0.91948,
            "recall": 0.9217,
            "f1": 0.91967
        },
        "meteor": 0.3599713284503858,
        "bleurt": 0.22904
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "mT5_base/totto_test",
        "N": 12,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.5833333333333334,
            "3": 0.8489208633093526
        },
        "rouge1": {
            "precision": 0.787,
            "recall": 0.77084,
            "fmeasure": 0.77222
        },
        "rouge2": {
            "precision": 0.60431,
            "recall": 0.60492,
            "fmeasure": 0.59993
        },
        "rougeL": {
            "precision": 0.74687,
            "recall": 0.7355,
            "fmeasure": 0.73497
        },
        "rougeLsum": {
            "precision": 0.74687,
            "recall": 0.7355,
            "fmeasure": 0.73497
        },
        "nist": 6.218821681702913,
        "bleu": 60.45669,
        "nubia": {
            "semantic_relation": 3.88284,
            "contradiction": 20.00579,
            "irrelevancy": 27.16251,
            "logical_agreement": 52.8317,
            "grammar_ref": 4.07585,
            "grammar_hyp": 3.94819,
            "nubia_score": 0.67338
        },
        "bertscore": {
            "precision": 0.93487,
            "recall": 0.93292,
            "f1": 0.93271
        },
        "meteor": 0.4421444124056615,
        "bleurt": 0.35013
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "mT5_base/totto_test",
        "N": 50,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22666666666666666,
            "2": 0.48427672955974843,
            "3": 0.6843065693430657
        },
        "rouge1": {
            "precision": 0.77227,
            "recall": 0.68266,
            "fmeasure": 0.7132
        },
        "rouge2": {
            "precision": 0.52027,
            "recall": 0.46959,
            "fmeasure": 0.48459
        },
        "rougeL": {
            "precision": 0.67274,
            "recall": 0.59905,
            "fmeasure": 0.62363
        },
        "rougeLsum": {
            "precision": 0.67274,
            "recall": 0.59905,
            "fmeasure": 0.62363
        },
        "nist": 6.362102375286195,
        "bleu": 38.2415,
        "nubia": {
            "semantic_relation": 4.08017,
            "contradiction": 7.14988,
            "irrelevancy": 28.68629,
            "logical_agreement": 64.16384,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.96074,
            "nubia_score": 0.65764
        },
        "bertscore": {
            "precision": 0.92781,
            "recall": 0.9096,
            "f1": 0.91737
        },
        "meteor": 0.3460401222439995,
        "bleurt": 0.19034
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "mT5_base/totto_test",
        "N": 42,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5053763440860215,
            "3": 0.7665289256198347
        },
        "rouge1": {
            "precision": 0.78681,
            "recall": 0.77047,
            "fmeasure": 0.77112
        },
        "rouge2": {
            "precision": 0.57209,
            "recall": 0.56543,
            "fmeasure": 0.56362
        },
        "rougeL": {
            "precision": 0.68689,
            "recall": 0.67695,
            "fmeasure": 0.67625
        },
        "rougeLsum": {
            "precision": 0.68689,
            "recall": 0.67695,
            "fmeasure": 0.67625
        },
        "nist": 6.922270225197277,
        "bleu": 47.61717,
        "nubia": {
            "semantic_relation": 4.38092,
            "contradiction": 14.05486,
            "irrelevancy": 22.56117,
            "logical_agreement": 63.38397,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.58172,
            "nubia_score": 0.77491
        },
        "bertscore": {
            "precision": 0.93934,
            "recall": 0.93837,
            "f1": 0.93739
        },
        "meteor": 0.4182974667083632,
        "bleurt": 0.39025
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "mT5_base/totto_test",
        "N": 11,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27906976744186046,
            "2": 0.3684210526315789,
            "3": 0.7352941176470589
        },
        "rouge1": {
            "precision": 0.79707,
            "recall": 0.71739,
            "fmeasure": 0.7451
        },
        "rouge2": {
            "precision": 0.56067,
            "recall": 0.49571,
            "fmeasure": 0.5181
        },
        "rougeL": {
            "precision": 0.67657,
            "recall": 0.59702,
            "fmeasure": 0.6239
        },
        "rougeLsum": {
            "precision": 0.67657,
            "recall": 0.59702,
            "fmeasure": 0.6239
        },
        "nist": 5.794976949359883,
        "bleu": 40.89285,
        "nubia": {
            "semantic_relation": 4.15147,
            "contradiction": 17.21815,
            "irrelevancy": 29.5777,
            "logical_agreement": 53.20415,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.61777,
            "nubia_score": 0.71533
        },
        "bertscore": {
            "precision": 0.9192,
            "recall": 0.91805,
            "f1": 0.91725
        },
        "meteor": 0.39942366358732123,
        "bleurt": 0.21984
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.74743,
            "recall": 0.55433,
            "fmeasure": 0.63117
        },
        "rouge2": {
            "precision": 0.41056,
            "recall": 0.31997,
            "fmeasure": 0.35278
        },
        "rougeL": {
            "precision": 0.60988,
            "recall": 0.47831,
            "fmeasure": 0.52811
        },
        "rougeLsum": {
            "precision": 0.60988,
            "recall": 0.47831,
            "fmeasure": 0.52811
        },
        "nist": 4.141837126737293,
        "bleu": 28.57208,
        "nubia": {
            "semantic_relation": 3.77741,
            "contradiction": 10.93781,
            "irrelevancy": 31.97515,
            "logical_agreement": 57.08703,
            "grammar_ref": 4.85958,
            "grammar_hyp": 5.26403,
            "nubia_score": 0.54635
        },
        "bertscore": {
            "precision": 0.89761,
            "recall": 0.85892,
            "f1": 0.87269
        },
        "meteor": 0.2857685478783863,
        "bleurt": -0.027
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "mT5_base/totto_test",
        "N": 14,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2542372881355932,
            "2": 0.21739130434782608,
            "3": 0.696969696969697
        },
        "rouge1": {
            "precision": 0.66008,
            "recall": 0.63675,
            "fmeasure": 0.63531
        },
        "rouge2": {
            "precision": 0.35684,
            "recall": 0.34666,
            "fmeasure": 0.3395
        },
        "rougeL": {
            "precision": 0.51113,
            "recall": 0.51963,
            "fmeasure": 0.50169
        },
        "rougeLsum": {
            "precision": 0.51113,
            "recall": 0.51963,
            "fmeasure": 0.50169
        },
        "nist": 5.068528671279428,
        "bleu": 24.24321,
        "nubia": {
            "semantic_relation": 3.94717,
            "contradiction": 7.58827,
            "irrelevancy": 35.54683,
            "logical_agreement": 56.86491,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.37193,
            "nubia_score": 0.66164
        },
        "bertscore": {
            "precision": 0.89856,
            "recall": 0.89848,
            "f1": 0.89482
        },
        "meteor": 0.3357467070791462,
        "bleurt": 0.02629
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "mT5_base/totto_test",
        "N": 17,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1276595744680851,
            "2": 0.3157894736842105,
            "3": 0.8387096774193549
        },
        "rouge1": {
            "precision": 0.83755,
            "recall": 0.78786,
            "fmeasure": 0.8009
        },
        "rouge2": {
            "precision": 0.648,
            "recall": 0.63134,
            "fmeasure": 0.62877
        },
        "rougeL": {
            "precision": 0.69951,
            "recall": 0.6803,
            "fmeasure": 0.68012
        },
        "rougeLsum": {
            "precision": 0.69951,
            "recall": 0.6803,
            "fmeasure": 0.68012
        },
        "nist": 7.018338004638103,
        "bleu": 63.79531,
        "nubia": {
            "semantic_relation": 4.42814,
            "contradiction": 1.70014,
            "irrelevancy": 17.96007,
            "logical_agreement": 80.33979,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.60415,
            "nubia_score": 0.80624
        },
        "bertscore": {
            "precision": 0.94916,
            "recall": 0.9464,
            "f1": 0.94605
        },
        "meteor": 0.49432451270147615,
        "bleurt": 0.43326
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "mT5_base/totto_test",
        "N": 40,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.35384615384615387,
            "3": 0.7683215130023641
        },
        "rouge1": {
            "precision": 0.77114,
            "recall": 0.73689,
            "fmeasure": 0.73988
        },
        "rouge2": {
            "precision": 0.56433,
            "recall": 0.54469,
            "fmeasure": 0.54256
        },
        "rougeL": {
            "precision": 0.67751,
            "recall": 0.64737,
            "fmeasure": 0.6491
        },
        "rougeLsum": {
            "precision": 0.67751,
            "recall": 0.64737,
            "fmeasure": 0.6491
        },
        "nist": 6.629303855465769,
        "bleu": 50.2182,
        "nubia": {
            "semantic_relation": 4.15771,
            "contradiction": 8.22074,
            "irrelevancy": 25.48676,
            "logical_agreement": 66.2925,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.49665,
            "nubia_score": 0.71241
        },
        "bertscore": {
            "precision": 0.92959,
            "recall": 0.92745,
            "f1": 0.92669
        },
        "meteor": 0.4008626289076088,
        "bleurt": 0.29694
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.4166666666666667,
            "3": 0.9012345679012346
        },
        "rouge1": {
            "precision": 0.8598,
            "recall": 0.82946,
            "fmeasure": 0.84
        },
        "rouge2": {
            "precision": 0.64325,
            "recall": 0.61847,
            "fmeasure": 0.62716
        },
        "rougeL": {
            "precision": 0.80424,
            "recall": 0.77217,
            "fmeasure": 0.78361
        },
        "rougeLsum": {
            "precision": 0.80424,
            "recall": 0.77217,
            "fmeasure": 0.78361
        },
        "nist": 5.57225705461993,
        "bleu": 50.54601,
        "nubia": {
            "semantic_relation": 4.63239,
            "contradiction": 1.41809,
            "irrelevancy": 35.79009,
            "logical_agreement": 62.79182,
            "grammar_ref": 5.04309,
            "grammar_hyp": 5.01259,
            "nubia_score": 0.85068
        },
        "bertscore": {
            "precision": 0.9547,
            "recall": 0.95434,
            "f1": 0.95383
        },
        "meteor": 0.43855741514337104,
        "bleurt": 0.45566
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "mT5_base/totto_test",
        "N": 144,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24708171206225682,
            "2": 0.5033112582781457,
            "3": 0.7361867704280156
        },
        "rouge1": {
            "precision": 0.75502,
            "recall": 0.70002,
            "fmeasure": 0.70947
        },
        "rouge2": {
            "precision": 0.52353,
            "recall": 0.48651,
            "fmeasure": 0.49152
        },
        "rougeL": {
            "precision": 0.65374,
            "recall": 0.61027,
            "fmeasure": 0.61531
        },
        "rougeLsum": {
            "precision": 0.65374,
            "recall": 0.61027,
            "fmeasure": 0.61531
        },
        "nist": 7.484662365817311,
        "bleu": 45.89053,
        "nubia": {
            "semantic_relation": 4.05998,
            "contradiction": 12.44833,
            "irrelevancy": 29.67154,
            "logical_agreement": 57.88013,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.79515,
            "nubia_score": 0.70153
        },
        "bertscore": {
            "precision": 0.9244,
            "recall": 0.91798,
            "f1": 0.91881
        },
        "meteor": 0.3965478360612902,
        "bleurt": 0.25002
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "mT5_base/totto_test",
        "N": 14,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18032786885245902,
            "2": 0.45714285714285713,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.71194,
            "recall": 0.67415,
            "fmeasure": 0.6796
        },
        "rouge2": {
            "precision": 0.43832,
            "recall": 0.42792,
            "fmeasure": 0.42224
        },
        "rougeL": {
            "precision": 0.57544,
            "recall": 0.54234,
            "fmeasure": 0.54696
        },
        "rougeLsum": {
            "precision": 0.57544,
            "recall": 0.54234,
            "fmeasure": 0.54696
        },
        "nist": 5.289730894294401,
        "bleu": 37.92461,
        "nubia": {
            "semantic_relation": 3.99034,
            "contradiction": 8.14866,
            "irrelevancy": 51.67776,
            "logical_agreement": 40.17358,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.49973,
            "nubia_score": 0.67943
        },
        "bertscore": {
            "precision": 0.91136,
            "recall": 0.9002,
            "f1": 0.90409
        },
        "meteor": 0.3578355648197362,
        "bleurt": 0.08039
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "mT5_base/totto_test",
        "N": 32,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20408163265306123,
            "2": 0.39759036144578314,
            "3": 0.8086734693877551
        },
        "rouge1": {
            "precision": 0.77094,
            "recall": 0.74413,
            "fmeasure": 0.74907
        },
        "rouge2": {
            "precision": 0.54842,
            "recall": 0.54101,
            "fmeasure": 0.5383
        },
        "rougeL": {
            "precision": 0.65642,
            "recall": 0.64588,
            "fmeasure": 0.64323
        },
        "rougeLsum": {
            "precision": 0.65642,
            "recall": 0.64588,
            "fmeasure": 0.64323
        },
        "nist": 6.676896923328574,
        "bleu": 46.68322,
        "nubia": {
            "semantic_relation": 4.21952,
            "contradiction": 11.11876,
            "irrelevancy": 36.77895,
            "logical_agreement": 52.10229,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.36388,
            "nubia_score": 0.72814
        },
        "bertscore": {
            "precision": 0.9279,
            "recall": 0.92774,
            "f1": 0.92642
        },
        "meteor": 0.39635300128810697,
        "bleurt": 0.24184
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "mT5_base/totto_test",
        "N": 35,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27835051546391754,
            "2": 0.4144144144144144,
            "3": 0.7094972067039106
        },
        "rouge1": {
            "precision": 0.72825,
            "recall": 0.67003,
            "fmeasure": 0.68713
        },
        "rouge2": {
            "precision": 0.5049,
            "recall": 0.45325,
            "fmeasure": 0.47001
        },
        "rougeL": {
            "precision": 0.64074,
            "recall": 0.58785,
            "fmeasure": 0.60412
        },
        "rougeLsum": {
            "precision": 0.64074,
            "recall": 0.58785,
            "fmeasure": 0.60412
        },
        "nist": 6.605961338081214,
        "bleu": 41.63841,
        "nubia": {
            "semantic_relation": 4.01476,
            "contradiction": 6.00131,
            "irrelevancy": 38.50817,
            "logical_agreement": 55.49052,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.66918,
            "nubia_score": 0.67605
        },
        "bertscore": {
            "precision": 0.92612,
            "recall": 0.912,
            "f1": 0.91762
        },
        "meteor": 0.3590441400372514,
        "bleurt": 0.19539
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.58353,
            "recall": 0.70054,
            "fmeasure": 0.63218
        },
        "rouge2": {
            "precision": 0.36574,
            "recall": 0.42211,
            "fmeasure": 0.39035
        },
        "rougeL": {
            "precision": 0.46586,
            "recall": 0.56492,
            "fmeasure": 0.50652
        },
        "rougeLsum": {
            "precision": 0.46586,
            "recall": 0.56492,
            "fmeasure": 0.50652
        },
        "nist": 3.613695529435839,
        "bleu": 33.39204,
        "nubia": {
            "semantic_relation": 4.08246,
            "contradiction": 0.40943,
            "irrelevancy": 56.1009,
            "logical_agreement": 43.48967,
            "grammar_ref": 4.57112,
            "grammar_hyp": 4.03342,
            "nubia_score": 0.72457
        },
        "bertscore": {
            "precision": 0.87606,
            "recall": 0.93279,
            "f1": 0.90155
        },
        "meteor": 0.4347803072842033,
        "bleurt": 0.06482
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.88426,
            "fmeasure": 0.74127
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.5119,
            "fmeasure": 0.42495
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.61111,
            "fmeasure": 0.51429
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.61111,
            "fmeasure": 0.51429
        },
        "nist": 2.5350160711195047,
        "bleu": 15.3965,
        "nubia": {
            "semantic_relation": 4.68526,
            "contradiction": 0.99027,
            "irrelevancy": 4.08504,
            "logical_agreement": 94.9247,
            "grammar_ref": 4.0172,
            "grammar_hyp": 3.87141,
            "nubia_score": 0.81595
        },
        "bertscore": {
            "precision": 0.90632,
            "recall": 0.91482,
            "f1": 0.91055
        },
        "meteor": 0.4046872031241953,
        "bleurt": 0.04535
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "mT5_base/totto_test",
        "N": 48,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15436241610738255,
            "2": 0.4375,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.81003,
            "recall": 0.74162,
            "fmeasure": 0.76629
        },
        "rouge2": {
            "precision": 0.54962,
            "recall": 0.51193,
            "fmeasure": 0.52419
        },
        "rougeL": {
            "precision": 0.64655,
            "recall": 0.59643,
            "fmeasure": 0.61305
        },
        "rougeLsum": {
            "precision": 0.64655,
            "recall": 0.59643,
            "fmeasure": 0.61305
        },
        "nist": 6.992675396803463,
        "bleu": 43.28499,
        "nubia": {
            "semantic_relation": 4.28055,
            "contradiction": 10.77745,
            "irrelevancy": 21.31635,
            "logical_agreement": 67.9062,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.90241,
            "nubia_score": 0.74872
        },
        "bertscore": {
            "precision": 0.93784,
            "recall": 0.93006,
            "f1": 0.93272
        },
        "meteor": 0.390581780197379,
        "bleurt": 0.29478
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "mT5_base/totto_test",
        "N": 114,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.208955223880597,
            "2": 0.4517766497461929,
            "3": 0.7348551360842844
        },
        "rouge1": {
            "precision": 0.73019,
            "recall": 0.68071,
            "fmeasure": 0.68916
        },
        "rouge2": {
            "precision": 0.46718,
            "recall": 0.43437,
            "fmeasure": 0.4398
        },
        "rougeL": {
            "precision": 0.61591,
            "recall": 0.57532,
            "fmeasure": 0.58183
        },
        "rougeLsum": {
            "precision": 0.61591,
            "recall": 0.57532,
            "fmeasure": 0.58183
        },
        "nist": 7.051419977587582,
        "bleu": 36.77158,
        "nubia": {
            "semantic_relation": 4.0526,
            "contradiction": 10.86343,
            "irrelevancy": 33.53629,
            "logical_agreement": 55.60027,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.67225,
            "nubia_score": 0.6773
        },
        "bertscore": {
            "precision": 0.9163,
            "recall": 0.91168,
            "f1": 0.91257
        },
        "meteor": 0.3623309195117626,
        "bleurt": 0.1773
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.7272727272727273,
            "3": 0.4230769230769231
        },
        "rouge1": {
            "precision": 0.65513,
            "recall": 0.53424,
            "fmeasure": 0.55797
        },
        "rouge2": {
            "precision": 0.36607,
            "recall": 0.31944,
            "fmeasure": 0.32251
        },
        "rougeL": {
            "precision": 0.52179,
            "recall": 0.46972,
            "fmeasure": 0.47101
        },
        "rougeLsum": {
            "precision": 0.52179,
            "recall": 0.46972,
            "fmeasure": 0.47101
        },
        "nist": 2.0543405202628784,
        "bleu": 13.02978,
        "nubia": {
            "semantic_relation": 3.3962,
            "contradiction": 48.12986,
            "irrelevancy": 49.9992,
            "logical_agreement": 1.87095,
            "grammar_ref": 4.83168,
            "grammar_hyp": 5.34441,
            "nubia_score": 0.33745
        },
        "bertscore": {
            "precision": 0.87625,
            "recall": 0.83177,
            "f1": 0.85191
        },
        "meteor": 0.23513728534292486,
        "bleurt": -0.53085
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.765588169540507,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.57996,
            "irrelevancy": 0.56765,
            "logical_agreement": 98.85239,
            "grammar_ref": 4.84371,
            "grammar_hyp": 5.00972,
            "nubia_score": 0.98571
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.95406
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "mT5_base/totto_test",
        "N": 24,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.44086021505376344,
            "3": 0.8395061728395061
        },
        "rouge1": {
            "precision": 0.77147,
            "recall": 0.73586,
            "fmeasure": 0.74507
        },
        "rouge2": {
            "precision": 0.48805,
            "recall": 0.47024,
            "fmeasure": 0.47279
        },
        "rougeL": {
            "precision": 0.65603,
            "recall": 0.63309,
            "fmeasure": 0.6379
        },
        "rougeLsum": {
            "precision": 0.65603,
            "recall": 0.63309,
            "fmeasure": 0.6379
        },
        "nist": 6.462996524615164,
        "bleu": 47.05545,
        "nubia": {
            "semantic_relation": 4.1552,
            "contradiction": 6.86639,
            "irrelevancy": 31.41126,
            "logical_agreement": 61.72235,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.42806,
            "nubia_score": 0.74577
        },
        "bertscore": {
            "precision": 0.93105,
            "recall": 0.92213,
            "f1": 0.92514
        },
        "meteor": 0.3990481918774523,
        "bleurt": 0.24688
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "mT5_base/totto_test",
        "N": 18,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24271844660194175,
            "2": 0.3409090909090909,
            "3": 0.6275510204081632
        },
        "rouge1": {
            "precision": 0.68811,
            "recall": 0.60163,
            "fmeasure": 0.61816
        },
        "rouge2": {
            "precision": 0.42601,
            "recall": 0.37873,
            "fmeasure": 0.38431
        },
        "rougeL": {
            "precision": 0.58083,
            "recall": 0.51743,
            "fmeasure": 0.52784
        },
        "rougeLsum": {
            "precision": 0.58083,
            "recall": 0.51743,
            "fmeasure": 0.52784
        },
        "nist": 5.2519802214487905,
        "bleu": 32.28361,
        "nubia": {
            "semantic_relation": 3.77984,
            "contradiction": 10.90081,
            "irrelevancy": 39.55539,
            "logical_agreement": 49.5438,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.64328,
            "nubia_score": 0.59286
        },
        "bertscore": {
            "precision": 0.89557,
            "recall": 0.88355,
            "f1": 0.88768
        },
        "meteor": 0.323928839248472,
        "bleurt": -0.05157
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "mT5_base/totto_test",
        "N": 29,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20388349514563106,
            "2": 0.3953488372093023,
            "3": 0.7715231788079471
        },
        "rouge1": {
            "precision": 0.74032,
            "recall": 0.73461,
            "fmeasure": 0.72123
        },
        "rouge2": {
            "precision": 0.48823,
            "recall": 0.48719,
            "fmeasure": 0.47639
        },
        "rougeL": {
            "precision": 0.62589,
            "recall": 0.62713,
            "fmeasure": 0.61235
        },
        "rougeLsum": {
            "precision": 0.62589,
            "recall": 0.62713,
            "fmeasure": 0.61235
        },
        "nist": 6.2534408879606875,
        "bleu": 37.87058,
        "nubia": {
            "semantic_relation": 4.25458,
            "contradiction": 10.67977,
            "irrelevancy": 32.7556,
            "logical_agreement": 56.56463,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.53668,
            "nubia_score": 0.73048
        },
        "bertscore": {
            "precision": 0.92532,
            "recall": 0.92726,
            "f1": 0.92427
        },
        "meteor": 0.3722904737249933,
        "bleurt": 0.27202
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "mT5_base/totto_test",
        "N": 77,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22178988326848248,
            "2": 0.38372093023255816,
            "3": 0.7594278283485045
        },
        "rouge1": {
            "precision": 0.76286,
            "recall": 0.68783,
            "fmeasure": 0.71282
        },
        "rouge2": {
            "precision": 0.50822,
            "recall": 0.45914,
            "fmeasure": 0.47484
        },
        "rougeL": {
            "precision": 0.66017,
            "recall": 0.60003,
            "fmeasure": 0.61811
        },
        "rougeLsum": {
            "precision": 0.66017,
            "recall": 0.60003,
            "fmeasure": 0.61811
        },
        "nist": 6.963603512645522,
        "bleu": 44.91797,
        "nubia": {
            "semantic_relation": 4.06466,
            "contradiction": 12.39413,
            "irrelevancy": 23.33707,
            "logical_agreement": 64.2688,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.70964,
            "nubia_score": 0.68956
        },
        "bertscore": {
            "precision": 0.92614,
            "recall": 0.91237,
            "f1": 0.91762
        },
        "meteor": 0.3743414957020676,
        "bleurt": 0.19758
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35294117647058826,
            "2": 0.2413793103448276,
            "3": 0.7796610169491526
        },
        "rouge1": {
            "precision": 0.77234,
            "recall": 0.72134,
            "fmeasure": 0.73201
        },
        "rouge2": {
            "precision": 0.59927,
            "recall": 0.54682,
            "fmeasure": 0.56036
        },
        "rougeL": {
            "precision": 0.70118,
            "recall": 0.64973,
            "fmeasure": 0.66114
        },
        "rougeLsum": {
            "precision": 0.70118,
            "recall": 0.64973,
            "fmeasure": 0.66114
        },
        "nist": 4.3076645318811995,
        "bleu": 42.9526,
        "nubia": {
            "semantic_relation": 4.18941,
            "contradiction": 14.56389,
            "irrelevancy": 17.71172,
            "logical_agreement": 67.72439,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.59277,
            "nubia_score": 0.72567
        },
        "bertscore": {
            "precision": 0.92609,
            "recall": 0.91264,
            "f1": 0.91869
        },
        "meteor": 0.3439569121056787,
        "bleurt": 0.28108
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "mT5_base/totto_test",
        "N": 16,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.3,
            "3": 0.8556149732620321
        },
        "rouge1": {
            "precision": 0.78467,
            "recall": 0.78863,
            "fmeasure": 0.77749
        },
        "rouge2": {
            "precision": 0.53713,
            "recall": 0.56701,
            "fmeasure": 0.54414
        },
        "rougeL": {
            "precision": 0.65309,
            "recall": 0.67839,
            "fmeasure": 0.65769
        },
        "rougeLsum": {
            "precision": 0.65309,
            "recall": 0.67839,
            "fmeasure": 0.65769
        },
        "nist": 6.281504676290961,
        "bleu": 45.89695,
        "nubia": {
            "semantic_relation": 4.2388,
            "contradiction": 6.99666,
            "irrelevancy": 32.17998,
            "logical_agreement": 60.82336,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.72761,
            "nubia_score": 0.74375
        },
        "bertscore": {
            "precision": 0.93149,
            "recall": 0.93755,
            "f1": 0.9319
        },
        "meteor": 0.4055002457279709,
        "bleurt": 0.28743
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.37037037037037035,
            "3": 0.6428571428571429
        },
        "rouge1": {
            "precision": 0.72475,
            "recall": 0.67563,
            "fmeasure": 0.692
        },
        "rouge2": {
            "precision": 0.56203,
            "recall": 0.54297,
            "fmeasure": 0.5471
        },
        "rougeL": {
            "precision": 0.64316,
            "recall": 0.61223,
            "fmeasure": 0.62145
        },
        "rougeLsum": {
            "precision": 0.64316,
            "recall": 0.61223,
            "fmeasure": 0.62145
        },
        "nist": 3.1557206173279906,
        "bleu": 34.88999,
        "nubia": {
            "semantic_relation": 4.30085,
            "contradiction": 20.15418,
            "irrelevancy": 23.18714,
            "logical_agreement": 56.65868,
            "grammar_ref": 3.91039,
            "grammar_hyp": 3.62953,
            "nubia_score": 0.80005
        },
        "bertscore": {
            "precision": 0.9192,
            "recall": 0.91287,
            "f1": 0.91462
        },
        "meteor": 0.3253426089072249,
        "bleurt": 0.27105
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "mT5_base/totto_test",
        "N": 18,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.23529411764705882,
            "3": 0.8078602620087336
        },
        "rouge1": {
            "precision": 0.77954,
            "recall": 0.75407,
            "fmeasure": 0.75511
        },
        "rouge2": {
            "precision": 0.56427,
            "recall": 0.54258,
            "fmeasure": 0.5438
        },
        "rougeL": {
            "precision": 0.73118,
            "recall": 0.70048,
            "fmeasure": 0.70541
        },
        "rougeLsum": {
            "precision": 0.73118,
            "recall": 0.70048,
            "fmeasure": 0.70541
        },
        "nist": 6.6105636642871985,
        "bleu": 54.55851,
        "nubia": {
            "semantic_relation": 4.32931,
            "contradiction": 6.02534,
            "irrelevancy": 34.14199,
            "logical_agreement": 59.83267,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.47436,
            "nubia_score": 0.76682
        },
        "bertscore": {
            "precision": 0.93875,
            "recall": 0.93535,
            "f1": 0.93656
        },
        "meteor": 0.42376581361498195,
        "bleurt": 0.34934
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "mT5_base/totto_test",
        "N": 36,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1419753086419753,
            "2": 0.5,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.72226,
            "recall": 0.73132,
            "fmeasure": 0.71717
        },
        "rouge2": {
            "precision": 0.50612,
            "recall": 0.51882,
            "fmeasure": 0.50545
        },
        "rougeL": {
            "precision": 0.59321,
            "recall": 0.60851,
            "fmeasure": 0.59337
        },
        "rougeLsum": {
            "precision": 0.59321,
            "recall": 0.60851,
            "fmeasure": 0.59337
        },
        "nist": 6.489556912174686,
        "bleu": 45.14864,
        "nubia": {
            "semantic_relation": 4.13708,
            "contradiction": 9.54687,
            "irrelevancy": 37.9004,
            "logical_agreement": 52.55273,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.49107,
            "nubia_score": 0.71763
        },
        "bertscore": {
            "precision": 0.91806,
            "recall": 0.91928,
            "f1": 0.91628
        },
        "meteor": 0.3954352247108817,
        "bleurt": 0.21895
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.1,
            "3": 0.7380952380952381
        },
        "rouge1": {
            "precision": 0.7167,
            "recall": 0.6891,
            "fmeasure": 0.69226
        },
        "rouge2": {
            "precision": 0.51119,
            "recall": 0.50369,
            "fmeasure": 0.50012
        },
        "rougeL": {
            "precision": 0.5846,
            "recall": 0.57989,
            "fmeasure": 0.57435
        },
        "rougeLsum": {
            "precision": 0.5846,
            "recall": 0.57989,
            "fmeasure": 0.57435
        },
        "nist": 4.703949794985649,
        "bleu": 42.34153,
        "nubia": {
            "semantic_relation": 3.84446,
            "contradiction": 35.1122,
            "irrelevancy": 9.85211,
            "logical_agreement": 55.03569,
            "grammar_ref": 5.14697,
            "grammar_hyp": 5.23806,
            "nubia_score": 0.60909
        },
        "bertscore": {
            "precision": 0.91945,
            "recall": 0.90745,
            "f1": 0.91183
        },
        "meteor": 0.37922454683994183,
        "bleurt": 0.27312
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.65972,
            "recall": 0.65456,
            "fmeasure": 0.64672
        },
        "rouge2": {
            "precision": 0.47681,
            "recall": 0.43803,
            "fmeasure": 0.44949
        },
        "rougeL": {
            "precision": 0.59343,
            "recall": 0.60684,
            "fmeasure": 0.58709
        },
        "rougeLsum": {
            "precision": 0.59343,
            "recall": 0.60684,
            "fmeasure": 0.58709
        },
        "nist": 3.4774248864084796,
        "bleu": 34.18088,
        "nubia": {
            "semantic_relation": 4.16498,
            "contradiction": 0.28184,
            "irrelevancy": 50.11816,
            "logical_agreement": 49.60001,
            "grammar_ref": 4.99819,
            "grammar_hyp": 4.97372,
            "nubia_score": 0.73639
        },
        "bertscore": {
            "precision": 0.85802,
            "recall": 0.90407,
            "f1": 0.87909
        },
        "meteor": 0.3140629367867944,
        "bleurt": 0.21825
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "mT5_base/totto_test",
        "N": 11,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10810810810810811,
            "2": 0.625,
            "3": 0.7310924369747899
        },
        "rouge1": {
            "precision": 0.69005,
            "recall": 0.70075,
            "fmeasure": 0.67391
        },
        "rouge2": {
            "precision": 0.46919,
            "recall": 0.45593,
            "fmeasure": 0.44756
        },
        "rougeL": {
            "precision": 0.57976,
            "recall": 0.56538,
            "fmeasure": 0.55387
        },
        "rougeLsum": {
            "precision": 0.57976,
            "recall": 0.56538,
            "fmeasure": 0.55387
        },
        "nist": 5.0443259874136155,
        "bleu": 37.94857,
        "nubia": {
            "semantic_relation": 3.61955,
            "contradiction": 17.75741,
            "irrelevancy": 32.88037,
            "logical_agreement": 49.36223,
            "grammar_ref": 4.70623,
            "grammar_hyp": 5.0172,
            "nubia_score": 0.56885
        },
        "bertscore": {
            "precision": 0.90609,
            "recall": 0.90309,
            "f1": 0.90316
        },
        "meteor": 0.3466424336479465,
        "bleurt": -0.00672
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "mT5_base/totto_test",
        "N": 14,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.46153846153846156,
            "3": 0.8412698412698413
        },
        "rouge1": {
            "precision": 0.70688,
            "recall": 0.75134,
            "fmeasure": 0.71282
        },
        "rouge2": {
            "precision": 0.50417,
            "recall": 0.5244,
            "fmeasure": 0.50732
        },
        "rougeL": {
            "precision": 0.59008,
            "recall": 0.61658,
            "fmeasure": 0.5913
        },
        "rougeLsum": {
            "precision": 0.59008,
            "recall": 0.61658,
            "fmeasure": 0.5913
        },
        "nist": 5.381311725616428,
        "bleu": 45.25428,
        "nubia": {
            "semantic_relation": 4.11594,
            "contradiction": 17.91888,
            "irrelevancy": 38.07095,
            "logical_agreement": 44.01018,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.52216,
            "nubia_score": 0.67924
        },
        "bertscore": {
            "precision": 0.9079,
            "recall": 0.91726,
            "f1": 0.91125
        },
        "meteor": 0.4143366007862511,
        "bleurt": 0.23834
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "mT5_base/totto_test",
        "N": 76,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1705685618729097,
            "2": 0.4634146341463415,
            "3": 0.7437673130193906
        },
        "rouge1": {
            "precision": 0.74452,
            "recall": 0.68351,
            "fmeasure": 0.6977
        },
        "rouge2": {
            "precision": 0.4815,
            "recall": 0.44649,
            "fmeasure": 0.45052
        },
        "rougeL": {
            "precision": 0.63265,
            "recall": 0.59439,
            "fmeasure": 0.59859
        },
        "rougeLsum": {
            "precision": 0.63265,
            "recall": 0.59439,
            "fmeasure": 0.59859
        },
        "nist": 6.867862833710593,
        "bleu": 40.09375,
        "nubia": {
            "semantic_relation": 4.08746,
            "contradiction": 5.57572,
            "irrelevancy": 32.98085,
            "logical_agreement": 61.44343,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.87322,
            "nubia_score": 0.66617
        },
        "bertscore": {
            "precision": 0.92222,
            "recall": 0.91709,
            "f1": 0.91751
        },
        "meteor": 0.3706663918959034,
        "bleurt": 0.20295
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7647058823529411
        },
        "rouge1": {
            "precision": 0.82353,
            "recall": 0.73684,
            "fmeasure": 0.77778
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.27778,
            "fmeasure": 0.29412
        },
        "rougeL": {
            "precision": 0.52941,
            "recall": 0.47368,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.52941,
            "recall": 0.47368,
            "fmeasure": 0.5
        },
        "nist": 2.9716596044897803,
        "bleu": 14.37669,
        "nubia": {
            "semantic_relation": 4.6022,
            "contradiction": 0.49095,
            "irrelevancy": 9.78033,
            "logical_agreement": 89.72872,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.36812,
            "nubia_score": 0.88212
        },
        "bertscore": {
            "precision": 0.90967,
            "recall": 0.8922,
            "f1": 0.90085
        },
        "meteor": 0.34402054695013684,
        "bleurt": 0.18437
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.67407,
            "fmeasure": 0.67789
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.42857,
            "fmeasure": 0.42967
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.67407,
            "fmeasure": 0.67789
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.67407,
            "fmeasure": 0.67789
        },
        "nist": 1.9877836651684964,
        "bleu": 41.72261,
        "nubia": {
            "semantic_relation": 4.14875,
            "contradiction": 0.05561,
            "irrelevancy": 34.18796,
            "logical_agreement": 65.75644,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.32832,
            "nubia_score": 0.69679
        },
        "bertscore": {
            "precision": 0.95353,
            "recall": 0.96991,
            "f1": 0.96165
        },
        "meteor": 0.3832699063476993,
        "bleurt": 0.43554
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "mT5_base/totto_test",
        "N": 47,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22758620689655173,
            "2": 0.381294964028777,
            "3": 0.7440860215053764
        },
        "rouge1": {
            "precision": 0.73553,
            "recall": 0.74278,
            "fmeasure": 0.72491
        },
        "rouge2": {
            "precision": 0.47669,
            "recall": 0.48805,
            "fmeasure": 0.47352
        },
        "rougeL": {
            "precision": 0.64341,
            "recall": 0.64791,
            "fmeasure": 0.6332
        },
        "rougeLsum": {
            "precision": 0.64341,
            "recall": 0.64791,
            "fmeasure": 0.6332
        },
        "nist": 6.3837294504782465,
        "bleu": 44.06974,
        "nubia": {
            "semantic_relation": 4.02118,
            "contradiction": 10.99643,
            "irrelevancy": 29.14507,
            "logical_agreement": 59.8585,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.36518,
            "nubia_score": 0.69166
        },
        "bertscore": {
            "precision": 0.91967,
            "recall": 0.92183,
            "f1": 0.91871
        },
        "meteor": 0.37681088286285586,
        "bleurt": 0.25724
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.8799,
            "fmeasure": 0.75843
        },
        "rouge2": {
            "precision": 0.4127,
            "recall": 0.60635,
            "fmeasure": 0.49101
        },
        "rougeL": {
            "precision": 0.48485,
            "recall": 0.65359,
            "fmeasure": 0.55625
        },
        "rougeLsum": {
            "precision": 0.48485,
            "recall": 0.65359,
            "fmeasure": 0.55625
        },
        "nist": 2.7385192638376314,
        "bleu": 21.99206,
        "nubia": {
            "semantic_relation": 4.78774,
            "contradiction": 58.52506,
            "irrelevancy": 20.62044,
            "logical_agreement": 20.8545,
            "grammar_ref": 5.18542,
            "grammar_hyp": 3.87972,
            "nubia_score": 0.96692
        },
        "bertscore": {
            "precision": 0.88871,
            "recall": 0.94108,
            "f1": 0.91303
        },
        "meteor": 0.3999213772345519,
        "bleurt": 0.3423
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.88928,
            "recall": 0.77975,
            "fmeasure": 0.82991
        },
        "rouge2": {
            "precision": 0.64506,
            "recall": 0.56092,
            "fmeasure": 0.59925
        },
        "rougeL": {
            "precision": 0.72437,
            "recall": 0.63679,
            "fmeasure": 0.677
        },
        "rougeLsum": {
            "precision": 0.72437,
            "recall": 0.63679,
            "fmeasure": 0.677
        },
        "nist": 4.640035669941657,
        "bleu": 48.25924,
        "nubia": {
            "semantic_relation": 4.77117,
            "contradiction": 1.24388,
            "irrelevancy": 20.87314,
            "logical_agreement": 77.88298,
            "grammar_ref": 5.15044,
            "grammar_hyp": 5.36672,
            "nubia_score": 0.88988
        },
        "bertscore": {
            "precision": 0.97021,
            "recall": 0.96967,
            "f1": 0.96992
        },
        "meteor": 0.4710679022806461,
        "bleurt": 0.53015
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "mT5_base/totto_test",
        "N": 51,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21354166666666666,
            "2": 0.43478260869565216,
            "3": 0.7992766726943942
        },
        "rouge1": {
            "precision": 0.78418,
            "recall": 0.75611,
            "fmeasure": 0.75918
        },
        "rouge2": {
            "precision": 0.56025,
            "recall": 0.54348,
            "fmeasure": 0.54439
        },
        "rougeL": {
            "precision": 0.66674,
            "recall": 0.64967,
            "fmeasure": 0.64912
        },
        "rougeLsum": {
            "precision": 0.66674,
            "recall": 0.64967,
            "fmeasure": 0.64912
        },
        "nist": 7.324641917748286,
        "bleu": 52.28754,
        "nubia": {
            "semantic_relation": 4.23235,
            "contradiction": 10.79844,
            "irrelevancy": 27.7056,
            "logical_agreement": 61.49596,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.88982,
            "nubia_score": 0.71789
        },
        "bertscore": {
            "precision": 0.939,
            "recall": 0.93259,
            "f1": 0.93415
        },
        "meteor": 0.4106208687603627,
        "bleurt": 0.29707
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "mT5_base/totto_test",
        "N": 31,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.42168674698795183,
            "3": 0.768
        },
        "rouge1": {
            "precision": 0.76142,
            "recall": 0.70736,
            "fmeasure": 0.7256
        },
        "rouge2": {
            "precision": 0.5003,
            "recall": 0.46362,
            "fmeasure": 0.4764
        },
        "rougeL": {
            "precision": 0.64376,
            "recall": 0.60108,
            "fmeasure": 0.61571
        },
        "rougeLsum": {
            "precision": 0.64376,
            "recall": 0.60108,
            "fmeasure": 0.61571
        },
        "nist": 6.6807063164357805,
        "bleu": 44.50764,
        "nubia": {
            "semantic_relation": 4.1399,
            "contradiction": 15.06564,
            "irrelevancy": 30.06938,
            "logical_agreement": 54.86498,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.8054,
            "nubia_score": 0.71895
        },
        "bertscore": {
            "precision": 0.92926,
            "recall": 0.92147,
            "f1": 0.92396
        },
        "meteor": 0.38083189284366536,
        "bleurt": 0.25035
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "mT5_base/totto_test",
        "N": 57,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20276497695852536,
            "2": 0.4975609756097561,
            "3": 0.8102466793168881
        },
        "rouge1": {
            "precision": 0.75863,
            "recall": 0.74562,
            "fmeasure": 0.74105
        },
        "rouge2": {
            "precision": 0.53662,
            "recall": 0.54109,
            "fmeasure": 0.53032
        },
        "rougeL": {
            "precision": 0.66312,
            "recall": 0.6487,
            "fmeasure": 0.64661
        },
        "rougeLsum": {
            "precision": 0.66312,
            "recall": 0.6487,
            "fmeasure": 0.64661
        },
        "nist": 7.031659927244031,
        "bleu": 46.98924,
        "nubia": {
            "semantic_relation": 4.2269,
            "contradiction": 8.14566,
            "irrelevancy": 34.49045,
            "logical_agreement": 57.36389,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.74279,
            "nubia_score": 0.72789
        },
        "bertscore": {
            "precision": 0.93108,
            "recall": 0.92927,
            "f1": 0.92777
        },
        "meteor": 0.4119117682228387,
        "bleurt": 0.30161
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "mT5_base/totto_test",
        "N": 29,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2153846153846154,
            "2": 0.40816326530612246,
            "3": 0.7970149253731343
        },
        "rouge1": {
            "precision": 0.85424,
            "recall": 0.77803,
            "fmeasure": 0.80983
        },
        "rouge2": {
            "precision": 0.63928,
            "recall": 0.60497,
            "fmeasure": 0.61293
        },
        "rougeL": {
            "precision": 0.75132,
            "recall": 0.6928,
            "fmeasure": 0.71172
        },
        "rougeLsum": {
            "precision": 0.75132,
            "recall": 0.6928,
            "fmeasure": 0.71172
        },
        "nist": 7.055160795921444,
        "bleu": 54.74133,
        "nubia": {
            "semantic_relation": 4.58311,
            "contradiction": 8.92646,
            "irrelevancy": 9.55493,
            "logical_agreement": 81.51861,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.75299,
            "nubia_score": 0.84133
        },
        "bertscore": {
            "precision": 0.95399,
            "recall": 0.94389,
            "f1": 0.94649
        },
        "meteor": 0.43411465924021214,
        "bleurt": 0.45161
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "mT5_base/totto_test",
        "N": 18,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.3,
            "3": 0.7474747474747475
        },
        "rouge1": {
            "precision": 0.75298,
            "recall": 0.71674,
            "fmeasure": 0.71485
        },
        "rouge2": {
            "precision": 0.52146,
            "recall": 0.5091,
            "fmeasure": 0.49601
        },
        "rougeL": {
            "precision": 0.6331,
            "recall": 0.62142,
            "fmeasure": 0.61247
        },
        "rougeLsum": {
            "precision": 0.6331,
            "recall": 0.62142,
            "fmeasure": 0.61247
        },
        "nist": 6.270402868117879,
        "bleu": 45.80851,
        "nubia": {
            "semantic_relation": 4.02569,
            "contradiction": 8.50855,
            "irrelevancy": 25.38737,
            "logical_agreement": 66.10408,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.57248,
            "nubia_score": 0.65306
        },
        "bertscore": {
            "precision": 0.92349,
            "recall": 0.91714,
            "f1": 0.91472
        },
        "meteor": 0.4103559774342334,
        "bleurt": 0.16663
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.39316,
            "recall": 1.0,
            "fmeasure": 0.56398
        },
        "rouge2": {
            "precision": 0.22807,
            "recall": 0.55686,
            "fmeasure": 0.32338
        },
        "rougeL": {
            "precision": 0.32479,
            "recall": 0.76389,
            "fmeasure": 0.4555
        },
        "rougeLsum": {
            "precision": 0.32479,
            "recall": 0.76389,
            "fmeasure": 0.4555
        },
        "nist": 1.8706767864354414,
        "bleu": 15.67073,
        "nubia": {
            "semantic_relation": 3.47172,
            "contradiction": 8.36053,
            "irrelevancy": 50.49323,
            "logical_agreement": 41.14624,
            "grammar_ref": 3.66146,
            "grammar_hyp": 2.48734,
            "nubia_score": 0.21243
        },
        "bertscore": {
            "precision": 0.87616,
            "recall": 0.94957,
            "f1": 0.91139
        },
        "meteor": 0.41579379461924054,
        "bleurt": 0.26402
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "nist": 2.415947705372627,
        "bleu": 25.21194,
        "nubia": {
            "semantic_relation": 3.9393,
            "contradiction": 0.50698,
            "irrelevancy": 97.97126,
            "logical_agreement": 1.52176,
            "grammar_ref": 6.33221,
            "grammar_hyp": 5.93182,
            "nubia_score": 0.68311
        },
        "bertscore": {
            "precision": 0.93993,
            "recall": 0.96605,
            "f1": 0.95235
        },
        "meteor": 0.4235494540099438,
        "bleurt": 0.64341
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "mT5_base/totto_test",
        "N": 9,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.5909090909090909,
            "3": 0.7910447761194029
        },
        "rouge1": {
            "precision": 0.71417,
            "recall": 0.71422,
            "fmeasure": 0.70416
        },
        "rouge2": {
            "precision": 0.43116,
            "recall": 0.42605,
            "fmeasure": 0.42167
        },
        "rougeL": {
            "precision": 0.61366,
            "recall": 0.61057,
            "fmeasure": 0.60238
        },
        "rougeLsum": {
            "precision": 0.61366,
            "recall": 0.61057,
            "fmeasure": 0.60238
        },
        "nist": 4.922239533572444,
        "bleu": 29.05099,
        "nubia": {
            "semantic_relation": 4.33058,
            "contradiction": 7.20878,
            "irrelevancy": 25.44049,
            "logical_agreement": 67.35073,
            "grammar_ref": 5.14381,
            "grammar_hyp": 5.14794,
            "nubia_score": 0.72161
        },
        "bertscore": {
            "precision": 0.92277,
            "recall": 0.92281,
            "f1": 0.92172
        },
        "meteor": 0.3683675705938781,
        "bleurt": 0.26863
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "mT5_base/totto_test",
        "N": 18,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.4745762711864407,
            "3": 0.7515527950310559
        },
        "rouge1": {
            "precision": 0.71206,
            "recall": 0.69234,
            "fmeasure": 0.68957
        },
        "rouge2": {
            "precision": 0.46248,
            "recall": 0.44859,
            "fmeasure": 0.44595
        },
        "rougeL": {
            "precision": 0.59865,
            "recall": 0.5718,
            "fmeasure": 0.57325
        },
        "rougeLsum": {
            "precision": 0.59865,
            "recall": 0.5718,
            "fmeasure": 0.57325
        },
        "nist": 6.159550196584965,
        "bleu": 41.556,
        "nubia": {
            "semantic_relation": 4.20441,
            "contradiction": 1.15138,
            "irrelevancy": 45.32396,
            "logical_agreement": 53.52466,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.57061,
            "nubia_score": 0.76857
        },
        "bertscore": {
            "precision": 0.91903,
            "recall": 0.91901,
            "f1": 0.91592
        },
        "meteor": 0.38003154069640227,
        "bleurt": 0.20553
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "mT5_base/totto_test",
        "N": 55,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3235294117647059,
            "2": 0.3879781420765027,
            "3": 0.7453531598513011
        },
        "rouge1": {
            "precision": 0.7384,
            "recall": 0.69028,
            "fmeasure": 0.70264
        },
        "rouge2": {
            "precision": 0.49027,
            "recall": 0.45971,
            "fmeasure": 0.46676
        },
        "rougeL": {
            "precision": 0.64278,
            "recall": 0.60001,
            "fmeasure": 0.61113
        },
        "rougeLsum": {
            "precision": 0.64278,
            "recall": 0.60001,
            "fmeasure": 0.61113
        },
        "nist": 6.979966836029236,
        "bleu": 45.99376,
        "nubia": {
            "semantic_relation": 4.02267,
            "contradiction": 7.77072,
            "irrelevancy": 37.17506,
            "logical_agreement": 55.05422,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.91282,
            "nubia_score": 0.66757
        },
        "bertscore": {
            "precision": 0.91994,
            "recall": 0.91356,
            "f1": 0.91578
        },
        "meteor": 0.3726404101808841,
        "bleurt": 0.13664
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "mT5_base/totto_test",
        "N": 17,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16,
            "2": 0.30952380952380953,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.71326,
            "recall": 0.71314,
            "fmeasure": 0.70201
        },
        "rouge2": {
            "precision": 0.47739,
            "recall": 0.48645,
            "fmeasure": 0.47396
        },
        "rougeL": {
            "precision": 0.61807,
            "recall": 0.61191,
            "fmeasure": 0.60187
        },
        "rougeLsum": {
            "precision": 0.61807,
            "recall": 0.61191,
            "fmeasure": 0.60187
        },
        "nist": 5.75086934426175,
        "bleu": 43.86285,
        "nubia": {
            "semantic_relation": 3.97004,
            "contradiction": 7.03276,
            "irrelevancy": 42.78468,
            "logical_agreement": 50.18257,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.62455,
            "nubia_score": 0.63066
        },
        "bertscore": {
            "precision": 0.91397,
            "recall": 0.91799,
            "f1": 0.91446
        },
        "meteor": 0.38635291752334616,
        "bleurt": 0.10216
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "mT5_base/totto_test",
        "N": 11,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.6129032258064516,
            "3": 0.782608695652174
        },
        "rouge1": {
            "precision": 0.78327,
            "recall": 0.7146,
            "fmeasure": 0.73851
        },
        "rouge2": {
            "precision": 0.59392,
            "recall": 0.54709,
            "fmeasure": 0.56175
        },
        "rougeL": {
            "precision": 0.69046,
            "recall": 0.64394,
            "fmeasure": 0.65616
        },
        "rougeLsum": {
            "precision": 0.69046,
            "recall": 0.64394,
            "fmeasure": 0.65616
        },
        "nist": 5.9215415774463835,
        "bleu": 52.11531,
        "nubia": {
            "semantic_relation": 3.88465,
            "contradiction": 11.93745,
            "irrelevancy": 31.75339,
            "logical_agreement": 56.30916,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.33014,
            "nubia_score": 0.68045
        },
        "bertscore": {
            "precision": 0.94194,
            "recall": 0.93257,
            "f1": 0.93629
        },
        "meteor": 0.413960756308633,
        "bleurt": 0.24627
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "mT5_base/totto_test",
        "N": 11,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.2631578947368421,
            "3": 0.7428571428571429
        },
        "rouge1": {
            "precision": 0.76691,
            "recall": 0.72062,
            "fmeasure": 0.73155
        },
        "rouge2": {
            "precision": 0.5101,
            "recall": 0.46632,
            "fmeasure": 0.48014
        },
        "rougeL": {
            "precision": 0.67347,
            "recall": 0.62096,
            "fmeasure": 0.63762
        },
        "rougeLsum": {
            "precision": 0.67347,
            "recall": 0.62096,
            "fmeasure": 0.63762
        },
        "nist": 5.341427751165362,
        "bleu": 41.78367,
        "nubia": {
            "semantic_relation": 4.03693,
            "contradiction": 36.8568,
            "irrelevancy": 23.93264,
            "logical_agreement": 39.21057,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.36905,
            "nubia_score": 0.6619
        },
        "bertscore": {
            "precision": 0.92223,
            "recall": 0.90832,
            "f1": 0.91428
        },
        "meteor": 0.3943896325446193,
        "bleurt": 0.08982
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "mT5_base/totto_test",
        "N": 13,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.37037037037037035,
            "2": 0.36363636363636365,
            "3": 0.881578947368421
        },
        "rouge1": {
            "precision": 0.85616,
            "recall": 0.83974,
            "fmeasure": 0.83896
        },
        "rouge2": {
            "precision": 0.64736,
            "recall": 0.6599,
            "fmeasure": 0.64753
        },
        "rougeL": {
            "precision": 0.76256,
            "recall": 0.74397,
            "fmeasure": 0.744
        },
        "rougeLsum": {
            "precision": 0.76256,
            "recall": 0.74397,
            "fmeasure": 0.744
        },
        "nist": 6.655552739167266,
        "bleu": 61.22531,
        "nubia": {
            "semantic_relation": 4.69308,
            "contradiction": 0.44887,
            "irrelevancy": 17.09956,
            "logical_agreement": 82.45157,
            "grammar_ref": 5.1809,
            "grammar_hyp": 5.06319,
            "nubia_score": 0.8917
        },
        "bertscore": {
            "precision": 0.96281,
            "recall": 0.95962,
            "f1": 0.95951
        },
        "meteor": 0.4882895018327715,
        "bleurt": 0.5573
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "mT5_base/totto_test",
        "N": 44,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22772277227722773,
            "2": 0.56,
            "3": 0.7840172786177105
        },
        "rouge1": {
            "precision": 0.7504,
            "recall": 0.75235,
            "fmeasure": 0.73971
        },
        "rouge2": {
            "precision": 0.50681,
            "recall": 0.51516,
            "fmeasure": 0.50296
        },
        "rougeL": {
            "precision": 0.66536,
            "recall": 0.66717,
            "fmeasure": 0.65611
        },
        "rougeLsum": {
            "precision": 0.66536,
            "recall": 0.66717,
            "fmeasure": 0.65611
        },
        "nist": 6.926600344373644,
        "bleu": 49.35828,
        "nubia": {
            "semantic_relation": 4.24841,
            "contradiction": 5.97446,
            "irrelevancy": 26.64703,
            "logical_agreement": 67.37851,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.68115,
            "nubia_score": 0.75805
        },
        "bertscore": {
            "precision": 0.92826,
            "recall": 0.92526,
            "f1": 0.9254
        },
        "meteor": 0.40784851994376425,
        "bleurt": 0.32503
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "mT5_base/totto_test",
        "N": 122,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21123595505617979,
            "2": 0.37388724035608306,
            "3": 0.7401924500370096
        },
        "rouge1": {
            "precision": 0.7487,
            "recall": 0.70399,
            "fmeasure": 0.71449
        },
        "rouge2": {
            "precision": 0.50745,
            "recall": 0.47062,
            "fmeasure": 0.48041
        },
        "rougeL": {
            "precision": 0.64053,
            "recall": 0.5942,
            "fmeasure": 0.60698
        },
        "rougeLsum": {
            "precision": 0.64053,
            "recall": 0.5942,
            "fmeasure": 0.60698
        },
        "nist": 7.411069856108407,
        "bleu": 42.91918,
        "nubia": {
            "semantic_relation": 4.15123,
            "contradiction": 9.30423,
            "irrelevancy": 26.7158,
            "logical_agreement": 63.97998,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.70307,
            "nubia_score": 0.7101
        },
        "bertscore": {
            "precision": 0.92359,
            "recall": 0.91549,
            "f1": 0.91775
        },
        "meteor": 0.3739251847662146,
        "bleurt": 0.22506
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "mT5_base/totto_test",
        "N": 31,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17721518987341772,
            "2": 0.4222222222222222,
            "3": 0.7154929577464789
        },
        "rouge1": {
            "precision": 0.73928,
            "recall": 0.70346,
            "fmeasure": 0.70805
        },
        "rouge2": {
            "precision": 0.52329,
            "recall": 0.49149,
            "fmeasure": 0.4981
        },
        "rougeL": {
            "precision": 0.6231,
            "recall": 0.594,
            "fmeasure": 0.59815
        },
        "rougeLsum": {
            "precision": 0.6231,
            "recall": 0.594,
            "fmeasure": 0.59815
        },
        "nist": 6.080947828914892,
        "bleu": 41.66372,
        "nubia": {
            "semantic_relation": 4.09154,
            "contradiction": 9.35454,
            "irrelevancy": 31.33954,
            "logical_agreement": 59.30593,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.64632,
            "nubia_score": 0.67299
        },
        "bertscore": {
            "precision": 0.92179,
            "recall": 0.91136,
            "f1": 0.91508
        },
        "meteor": 0.3777810862907206,
        "bleurt": 0.20542
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.7272727272727273,
            "3": 0.9555555555555556
        },
        "rouge1": {
            "precision": 0.89405,
            "recall": 0.926,
            "fmeasure": 0.90477
        },
        "rouge2": {
            "precision": 0.72245,
            "recall": 0.74356,
            "fmeasure": 0.72931
        },
        "rougeL": {
            "precision": 0.86438,
            "recall": 0.8877,
            "fmeasure": 0.87203
        },
        "rougeLsum": {
            "precision": 0.86438,
            "recall": 0.8877,
            "fmeasure": 0.87203
        },
        "nist": 5.858394483580906,
        "bleu": 82.86311,
        "nubia": {
            "semantic_relation": 4.62763,
            "contradiction": 3.6457,
            "irrelevancy": 23.26489,
            "logical_agreement": 73.08941,
            "grammar_ref": 4.43427,
            "grammar_hyp": 4.38346,
            "nubia_score": 0.84055
        },
        "bertscore": {
            "precision": 0.9802,
            "recall": 0.98701,
            "f1": 0.98356
        },
        "meteor": 0.5592314872972659,
        "bleurt": 0.66851
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "mT5_base/totto_test",
        "N": 300,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20090805902383654,
            "2": 0.3629943502824859,
            "3": 0.7963163596966414
        },
        "rouge1": {
            "precision": 0.81306,
            "recall": 0.75408,
            "fmeasure": 0.77323
        },
        "rouge2": {
            "precision": 0.55965,
            "recall": 0.51767,
            "fmeasure": 0.53139
        },
        "rougeL": {
            "precision": 0.68756,
            "recall": 0.63558,
            "fmeasure": 0.65276
        },
        "rougeLsum": {
            "precision": 0.68756,
            "recall": 0.63558,
            "fmeasure": 0.65276
        },
        "nist": 8.553565891255033,
        "bleu": 45.54254,
        "nubia": {
            "semantic_relation": 4.39839,
            "contradiction": 6.09531,
            "irrelevancy": 24.03567,
            "logical_agreement": 69.86902,
            "grammar_ref": 4.91577,
            "grammar_hyp": 4.98617,
            "nubia_score": 0.76519
        },
        "bertscore": {
            "precision": 0.9386,
            "recall": 0.93186,
            "f1": 0.93395
        },
        "meteor": 0.4028829549102931,
        "bleurt": 0.32841
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "mT5_base/totto_test",
        "N": 10,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.631578947368421,
            "3": 0.801980198019802
        },
        "rouge1": {
            "precision": 0.69885,
            "recall": 0.73062,
            "fmeasure": 0.70157
        },
        "rouge2": {
            "precision": 0.48125,
            "recall": 0.48983,
            "fmeasure": 0.47973
        },
        "rougeL": {
            "precision": 0.58968,
            "recall": 0.60708,
            "fmeasure": 0.59074
        },
        "rougeLsum": {
            "precision": 0.58968,
            "recall": 0.60708,
            "fmeasure": 0.59074
        },
        "nist": 5.2555818733963315,
        "bleu": 47.25864,
        "nubia": {
            "semantic_relation": 4.3571,
            "contradiction": 8.96763,
            "irrelevancy": 33.05491,
            "logical_agreement": 57.97746,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.52359,
            "nubia_score": 0.7729
        },
        "bertscore": {
            "precision": 0.91246,
            "recall": 0.91533,
            "f1": 0.91309
        },
        "meteor": 0.40955926942524856,
        "bleurt": 0.28032
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "mT5_base/totto_test",
        "N": 59,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2578616352201258,
            "2": 0.46616541353383456,
            "3": 0.7699530516431925
        },
        "rouge1": {
            "precision": 0.7669,
            "recall": 0.72838,
            "fmeasure": 0.74058
        },
        "rouge2": {
            "precision": 0.54391,
            "recall": 0.51734,
            "fmeasure": 0.52447
        },
        "rougeL": {
            "precision": 0.67547,
            "recall": 0.64866,
            "fmeasure": 0.65504
        },
        "rougeLsum": {
            "precision": 0.67547,
            "recall": 0.64866,
            "fmeasure": 0.65504
        },
        "nist": 7.13823303967501,
        "bleu": 46.94569,
        "nubia": {
            "semantic_relation": 4.15562,
            "contradiction": 6.76861,
            "irrelevancy": 26.37881,
            "logical_agreement": 66.85258,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.48399,
            "nubia_score": 0.73463
        },
        "bertscore": {
            "precision": 0.93454,
            "recall": 0.92483,
            "f1": 0.92842
        },
        "meteor": 0.39799457696295204,
        "bleurt": 0.28159
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "mT5_base/totto_test",
        "N": 20,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22,
            "2": 0.45901639344262296,
            "3": 0.7225130890052356
        },
        "rouge1": {
            "precision": 0.73466,
            "recall": 0.70381,
            "fmeasure": 0.70627
        },
        "rouge2": {
            "precision": 0.52708,
            "recall": 0.48942,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.62005,
            "recall": 0.60377,
            "fmeasure": 0.60182
        },
        "rougeLsum": {
            "precision": 0.62005,
            "recall": 0.60377,
            "fmeasure": 0.60182
        },
        "nist": 5.775556207830219,
        "bleu": 47.08874,
        "nubia": {
            "semantic_relation": 4.06671,
            "contradiction": 6.83179,
            "irrelevancy": 24.49504,
            "logical_agreement": 68.67317,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.7096,
            "nubia_score": 0.69951
        },
        "bertscore": {
            "precision": 0.92046,
            "recall": 0.91309,
            "f1": 0.91542
        },
        "meteor": 0.3851995464277428,
        "bleurt": 0.26675
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "mT5_base/totto_test",
        "N": 33,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1375,
            "2": 0.2835820895522388,
            "3": 0.8097560975609757
        },
        "rouge1": {
            "precision": 0.8436,
            "recall": 0.78181,
            "fmeasure": 0.80292
        },
        "rouge2": {
            "precision": 0.61495,
            "recall": 0.57665,
            "fmeasure": 0.58668
        },
        "rougeL": {
            "precision": 0.72297,
            "recall": 0.66957,
            "fmeasure": 0.68769
        },
        "rougeLsum": {
            "precision": 0.72297,
            "recall": 0.66957,
            "fmeasure": 0.68769
        },
        "nist": 7.0850119804629035,
        "bleu": 49.13719,
        "nubia": {
            "semantic_relation": 4.53478,
            "contradiction": 0.89123,
            "irrelevancy": 21.33714,
            "logical_agreement": 77.77163,
            "grammar_ref": 4.92209,
            "grammar_hyp": 5.09573,
            "nubia_score": 0.80976
        },
        "bertscore": {
            "precision": 0.94815,
            "recall": 0.93947,
            "f1": 0.94325
        },
        "meteor": 0.414969543351964,
        "bleurt": 0.37019
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "mT5_base/totto_test",
        "N": 31,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29906542056074764,
            "2": 0.35443037974683544,
            "3": 0.8065268065268065
        },
        "rouge1": {
            "precision": 0.82537,
            "recall": 0.76563,
            "fmeasure": 0.78647
        },
        "rouge2": {
            "precision": 0.59754,
            "recall": 0.56552,
            "fmeasure": 0.57497
        },
        "rougeL": {
            "precision": 0.72183,
            "recall": 0.67633,
            "fmeasure": 0.68887
        },
        "rougeLsum": {
            "precision": 0.72183,
            "recall": 0.67633,
            "fmeasure": 0.68887
        },
        "nist": 7.235498201467574,
        "bleu": 52.82047,
        "nubia": {
            "semantic_relation": 4.37125,
            "contradiction": 4.11377,
            "irrelevancy": 19.06759,
            "logical_agreement": 76.81864,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.70092,
            "nubia_score": 0.77734
        },
        "bertscore": {
            "precision": 0.94424,
            "recall": 0.93929,
            "f1": 0.94075
        },
        "meteor": 0.4235029550113369,
        "bleurt": 0.355
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "mT5_base/totto_test",
        "N": 128,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1393939393939394,
            "2": 0.31561461794019935,
            "3": 0.7691266079891672
        },
        "rouge1": {
            "precision": 0.79755,
            "recall": 0.74562,
            "fmeasure": 0.76261
        },
        "rouge2": {
            "precision": 0.54613,
            "recall": 0.51999,
            "fmeasure": 0.5263
        },
        "rougeL": {
            "precision": 0.66979,
            "recall": 0.63296,
            "fmeasure": 0.64336
        },
        "rougeLsum": {
            "precision": 0.66979,
            "recall": 0.63296,
            "fmeasure": 0.64336
        },
        "nist": 7.31999816569239,
        "bleu": 44.07402,
        "nubia": {
            "semantic_relation": 4.36288,
            "contradiction": 7.42185,
            "irrelevancy": 25.43641,
            "logical_agreement": 67.14174,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.26754,
            "nubia_score": 0.80589
        },
        "bertscore": {
            "precision": 0.93467,
            "recall": 0.92895,
            "f1": 0.92999
        },
        "meteor": 0.39088138275906276,
        "bleurt": 0.34884
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_base/totto_test",
        "N": 379,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2261904761904762,
            "2": 0.3962131837307153,
            "3": 0.7492764109985528
        },
        "rouge1": {
            "precision": 0.75058,
            "recall": 0.70031,
            "fmeasure": 0.71485
        },
        "rouge2": {
            "precision": 0.47936,
            "recall": 0.44728,
            "fmeasure": 0.4563
        },
        "rougeL": {
            "precision": 0.59187,
            "recall": 0.55424,
            "fmeasure": 0.56423
        },
        "rougeLsum": {
            "precision": 0.59187,
            "recall": 0.55424,
            "fmeasure": 0.56423
        },
        "nist": 8.357539898060715,
        "bleu": 38.44524,
        "nubia": {
            "semantic_relation": 4.00974,
            "contradiction": 14.41911,
            "irrelevancy": 28.29094,
            "logical_agreement": 57.28995,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.26036,
            "nubia_score": 0.67587
        },
        "bertscore": {
            "precision": 0.92057,
            "recall": 0.91074,
            "f1": 0.9141
        },
        "meteor": 0.36551773606087595,
        "bleurt": 0.16979
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "mT5_base/totto_test",
        "N": 47,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.234375,
            "2": 0.3333333333333333,
            "3": 0.78
        },
        "rouge1": {
            "precision": 0.78066,
            "recall": 0.7405,
            "fmeasure": 0.75006
        },
        "rouge2": {
            "precision": 0.5607,
            "recall": 0.53335,
            "fmeasure": 0.53852
        },
        "rougeL": {
            "precision": 0.68921,
            "recall": 0.65845,
            "fmeasure": 0.66411
        },
        "rougeLsum": {
            "precision": 0.68921,
            "recall": 0.65845,
            "fmeasure": 0.66411
        },
        "nist": 6.943255029442723,
        "bleu": 49.36849,
        "nubia": {
            "semantic_relation": 4.18591,
            "contradiction": 7.64869,
            "irrelevancy": 28.40762,
            "logical_agreement": 63.94369,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.3104,
            "nubia_score": 0.73908
        },
        "bertscore": {
            "precision": 0.93199,
            "recall": 0.9282,
            "f1": 0.92857
        },
        "meteor": 0.4043496734803456,
        "bleurt": 0.30589
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "mT5_base/totto_test",
        "N": 26,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.5746268656716418,
            "3": 0.6929133858267716
        },
        "rouge1": {
            "precision": 0.72774,
            "recall": 0.68972,
            "fmeasure": 0.69915
        },
        "rouge2": {
            "precision": 0.48244,
            "recall": 0.44959,
            "fmeasure": 0.45913
        },
        "rougeL": {
            "precision": 0.60776,
            "recall": 0.58331,
            "fmeasure": 0.58738
        },
        "rougeLsum": {
            "precision": 0.60776,
            "recall": 0.58331,
            "fmeasure": 0.58738
        },
        "nist": 6.167576416869559,
        "bleu": 42.18047,
        "nubia": {
            "semantic_relation": 4.11865,
            "contradiction": 15.04287,
            "irrelevancy": 31.71808,
            "logical_agreement": 53.23905,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.5034,
            "nubia_score": 0.70495
        },
        "bertscore": {
            "precision": 0.91904,
            "recall": 0.91801,
            "f1": 0.91631
        },
        "meteor": 0.37664614831039006,
        "bleurt": 0.18286
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "mT5_base/totto_test",
        "N": 49,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20103092783505155,
            "2": 0.4508670520231214,
            "3": 0.7495256166982922
        },
        "rouge1": {
            "precision": 0.75908,
            "recall": 0.68688,
            "fmeasure": 0.70576
        },
        "rouge2": {
            "precision": 0.52558,
            "recall": 0.47733,
            "fmeasure": 0.4877
        },
        "rougeL": {
            "precision": 0.65346,
            "recall": 0.59076,
            "fmeasure": 0.6068
        },
        "rougeLsum": {
            "precision": 0.65346,
            "recall": 0.59076,
            "fmeasure": 0.6068
        },
        "nist": 6.768133396073642,
        "bleu": 45.09114,
        "nubia": {
            "semantic_relation": 4.13797,
            "contradiction": 8.62748,
            "irrelevancy": 28.57697,
            "logical_agreement": 62.79556,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.94055,
            "nubia_score": 0.67848
        },
        "bertscore": {
            "precision": 0.93363,
            "recall": 0.91355,
            "f1": 0.92151
        },
        "meteor": 0.36695840791832646,
        "bleurt": 0.22878
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.81746,
            "recall": 0.66939,
            "fmeasure": 0.72493
        },
        "rouge2": {
            "precision": 0.66178,
            "recall": 0.55852,
            "fmeasure": 0.5965
        },
        "rougeL": {
            "precision": 0.73413,
            "recall": 0.62281,
            "fmeasure": 0.66526
        },
        "rougeLsum": {
            "precision": 0.73413,
            "recall": 0.62281,
            "fmeasure": 0.66526
        },
        "nist": 4.133938473365392,
        "bleu": 50.5755,
        "nubia": {
            "semantic_relation": 4.32426,
            "contradiction": 19.87256,
            "irrelevancy": 2.06126,
            "logical_agreement": 78.06618,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.74925,
            "nubia_score": 0.73556
        },
        "bertscore": {
            "precision": 0.96104,
            "recall": 0.91954,
            "f1": 0.9392
        },
        "meteor": 0.3781134101142517,
        "bleurt": 0.46122
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "mT5_base/totto_test",
        "N": 12,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1724137931034483,
            "2": 0.47619047619047616,
            "3": 0.6822429906542056
        },
        "rouge1": {
            "precision": 0.81137,
            "recall": 0.69729,
            "fmeasure": 0.73643
        },
        "rouge2": {
            "precision": 0.51596,
            "recall": 0.42472,
            "fmeasure": 0.4552
        },
        "rougeL": {
            "precision": 0.68504,
            "recall": 0.58247,
            "fmeasure": 0.61938
        },
        "rougeLsum": {
            "precision": 0.68504,
            "recall": 0.58247,
            "fmeasure": 0.61938
        },
        "nist": 4.643026254125195,
        "bleu": 33.26423,
        "nubia": {
            "semantic_relation": 4.13624,
            "contradiction": 17.95587,
            "irrelevancy": 12.87228,
            "logical_agreement": 69.17185,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.49336,
            "nubia_score": 0.63949
        },
        "bertscore": {
            "precision": 0.91602,
            "recall": 0.90214,
            "f1": 0.90668
        },
        "meteor": 0.36040827188777563,
        "bleurt": 0.05634
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "mT5_base/totto_test",
        "N": 12,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.3548387096774194,
            "3": 0.6641221374045801
        },
        "rouge1": {
            "precision": 0.69565,
            "recall": 0.66623,
            "fmeasure": 0.66247
        },
        "rouge2": {
            "precision": 0.50556,
            "recall": 0.49418,
            "fmeasure": 0.48575
        },
        "rougeL": {
            "precision": 0.6221,
            "recall": 0.60205,
            "fmeasure": 0.59448
        },
        "rougeLsum": {
            "precision": 0.6221,
            "recall": 0.60205,
            "fmeasure": 0.59448
        },
        "nist": 5.041275958759414,
        "bleu": 41.89735,
        "nubia": {
            "semantic_relation": 3.78868,
            "contradiction": 13.74214,
            "irrelevancy": 49.49313,
            "logical_agreement": 36.76474,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.92356,
            "nubia_score": 0.56087
        },
        "bertscore": {
            "precision": 0.90406,
            "recall": 0.90346,
            "f1": 0.90244
        },
        "meteor": 0.3555109490980152,
        "bleurt": -0.03955
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.2,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.5679,
            "recall": 0.73935,
            "fmeasure": 0.63821
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.48148,
            "fmeasure": 0.40881
        },
        "rougeL": {
            "precision": 0.4321,
            "recall": 0.56328,
            "fmeasure": 0.4859
        },
        "rougeLsum": {
            "precision": 0.4321,
            "recall": 0.56328,
            "fmeasure": 0.4859
        },
        "nist": 3.4115845957360276,
        "bleu": 34.6442,
        "nubia": {
            "semantic_relation": 3.28999,
            "contradiction": 98.05363,
            "irrelevancy": 1.81874,
            "logical_agreement": 0.12763,
            "grammar_ref": 3.99891,
            "grammar_hyp": 5.0628,
            "nubia_score": 0.40124
        },
        "bertscore": {
            "precision": 0.89963,
            "recall": 0.95158,
            "f1": 0.92487
        },
        "meteor": 0.42097624661335925,
        "bleurt": -0.37252
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "mT5_base/totto_test",
        "N": 30,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17346938775510204,
            "2": 0.32710280373831774,
            "3": 0.764179104477612
        },
        "rouge1": {
            "precision": 0.75202,
            "recall": 0.69773,
            "fmeasure": 0.71338
        },
        "rouge2": {
            "precision": 0.51184,
            "recall": 0.47672,
            "fmeasure": 0.48618
        },
        "rougeL": {
            "precision": 0.60973,
            "recall": 0.56483,
            "fmeasure": 0.57822
        },
        "rougeLsum": {
            "precision": 0.60973,
            "recall": 0.56483,
            "fmeasure": 0.57822
        },
        "nist": 6.169184285016018,
        "bleu": 41.71682,
        "nubia": {
            "semantic_relation": 4.03094,
            "contradiction": 11.33427,
            "irrelevancy": 29.6596,
            "logical_agreement": 59.00613,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.90304,
            "nubia_score": 0.66131
        },
        "bertscore": {
            "precision": 0.92596,
            "recall": 0.91524,
            "f1": 0.91846
        },
        "meteor": 0.38260387088009234,
        "bleurt": 0.20349
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "mT5_base/totto_test",
        "N": 128,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1976401179941003,
            "2": 0.30612244897959184,
            "3": 0.7928475033738192
        },
        "rouge1": {
            "precision": 0.81111,
            "recall": 0.75398,
            "fmeasure": 0.7718
        },
        "rouge2": {
            "precision": 0.5619,
            "recall": 0.52371,
            "fmeasure": 0.53412
        },
        "rougeL": {
            "precision": 0.69619,
            "recall": 0.65476,
            "fmeasure": 0.66569
        },
        "rougeLsum": {
            "precision": 0.69619,
            "recall": 0.65476,
            "fmeasure": 0.66569
        },
        "nist": 7.764322049278163,
        "bleu": 45.39648,
        "nubia": {
            "semantic_relation": 4.42522,
            "contradiction": 6.00406,
            "irrelevancy": 19.42658,
            "logical_agreement": 74.56936,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.68121,
            "nubia_score": 0.79132
        },
        "bertscore": {
            "precision": 0.93694,
            "recall": 0.92944,
            "f1": 0.93161
        },
        "meteor": 0.40236943642807865,
        "bleurt": 0.36695
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "mT5_base/totto_test",
        "N": 16,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14634146341463414,
            "2": 0.34782608695652173,
            "3": 0.7560975609756098
        },
        "rouge1": {
            "precision": 0.76454,
            "recall": 0.72882,
            "fmeasure": 0.74306
        },
        "rouge2": {
            "precision": 0.47963,
            "recall": 0.46287,
            "fmeasure": 0.46884
        },
        "rougeL": {
            "precision": 0.6236,
            "recall": 0.59654,
            "fmeasure": 0.60704
        },
        "rougeLsum": {
            "precision": 0.6236,
            "recall": 0.59654,
            "fmeasure": 0.60704
        },
        "nist": 5.628634911636717,
        "bleu": 37.623,
        "nubia": {
            "semantic_relation": 4.52776,
            "contradiction": 7.96318,
            "irrelevancy": 21.14642,
            "logical_agreement": 70.89039,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.65391,
            "nubia_score": 0.80393
        },
        "bertscore": {
            "precision": 0.92333,
            "recall": 0.92376,
            "f1": 0.9234
        },
        "meteor": 0.3789847208718817,
        "bleurt": 0.37376
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "mT5_base/totto_test",
        "N": 10,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20588235294117646,
            "2": 0.45161290322580644,
            "3": 0.826530612244898
        },
        "rouge1": {
            "precision": 0.77977,
            "recall": 0.72559,
            "fmeasure": 0.72269
        },
        "rouge2": {
            "precision": 0.53439,
            "recall": 0.49375,
            "fmeasure": 0.49237
        },
        "rougeL": {
            "precision": 0.68351,
            "recall": 0.62854,
            "fmeasure": 0.63044
        },
        "rougeLsum": {
            "precision": 0.68351,
            "recall": 0.62854,
            "fmeasure": 0.63044
        },
        "nist": 5.862063249729669,
        "bleu": 52.11077,
        "nubia": {
            "semantic_relation": 4.17533,
            "contradiction": 7.49474,
            "irrelevancy": 36.74831,
            "logical_agreement": 55.75695,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.87024,
            "nubia_score": 0.65605
        },
        "bertscore": {
            "precision": 0.91541,
            "recall": 0.91419,
            "f1": 0.91252
        },
        "meteor": 0.4300129903879751,
        "bleurt": 0.26424
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "mT5_base/totto_test",
        "N": 45,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11333333333333333,
            "2": 0.4453125,
            "3": 0.8137651821862348
        },
        "rouge1": {
            "precision": 0.82227,
            "recall": 0.75389,
            "fmeasure": 0.77631
        },
        "rouge2": {
            "precision": 0.5898,
            "recall": 0.53956,
            "fmeasure": 0.55603
        },
        "rougeL": {
            "precision": 0.66849,
            "recall": 0.61295,
            "fmeasure": 0.63028
        },
        "rougeLsum": {
            "precision": 0.66849,
            "recall": 0.61295,
            "fmeasure": 0.63028
        },
        "nist": 7.176175439390191,
        "bleu": 48.87393,
        "nubia": {
            "semantic_relation": 4.40231,
            "contradiction": 6.71604,
            "irrelevancy": 24.13941,
            "logical_agreement": 69.14455,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.90386,
            "nubia_score": 0.78276
        },
        "bertscore": {
            "precision": 0.9439,
            "recall": 0.9338,
            "f1": 0.93809
        },
        "meteor": 0.4178178323966099,
        "bleurt": 0.36895
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "mT5_base/totto_test",
        "N": 19,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26229508196721313,
            "2": 0.3728813559322034,
            "3": 0.7198067632850241
        },
        "rouge1": {
            "precision": 0.70981,
            "recall": 0.68741,
            "fmeasure": 0.68615
        },
        "rouge2": {
            "precision": 0.45768,
            "recall": 0.43671,
            "fmeasure": 0.43666
        },
        "rougeL": {
            "precision": 0.58873,
            "recall": 0.57613,
            "fmeasure": 0.5702
        },
        "rougeLsum": {
            "precision": 0.58873,
            "recall": 0.57613,
            "fmeasure": 0.5702
        },
        "nist": 5.632210989910421,
        "bleu": 41.19187,
        "nubia": {
            "semantic_relation": 3.86353,
            "contradiction": 11.4627,
            "irrelevancy": 44.6125,
            "logical_agreement": 43.9248,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.39768,
            "nubia_score": 0.64528
        },
        "bertscore": {
            "precision": 0.91369,
            "recall": 0.90906,
            "f1": 0.90895
        },
        "meteor": 0.3505005218720265,
        "bleurt": 0.09638
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "mT5_base/totto_test",
        "N": 13,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.11764705882352941,
            "3": 0.803921568627451
        },
        "rouge1": {
            "precision": 0.75324,
            "recall": 0.73195,
            "fmeasure": 0.73887
        },
        "rouge2": {
            "precision": 0.57631,
            "recall": 0.56254,
            "fmeasure": 0.56648
        },
        "rougeL": {
            "precision": 0.66249,
            "recall": 0.64035,
            "fmeasure": 0.64837
        },
        "rougeLsum": {
            "precision": 0.66249,
            "recall": 0.64035,
            "fmeasure": 0.64837
        },
        "nist": 5.704659322488923,
        "bleu": 48.95483,
        "nubia": {
            "semantic_relation": 4.27024,
            "contradiction": 1.68959,
            "irrelevancy": 21.99514,
            "logical_agreement": 76.31527,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.78438,
            "nubia_score": 0.75912
        },
        "bertscore": {
            "precision": 0.94533,
            "recall": 0.9398,
            "f1": 0.94236
        },
        "meteor": 0.4226728186954934,
        "bleurt": 0.52066
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.72549,
            "recall": 0.49559,
            "fmeasure": 0.58692
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.27692,
            "fmeasure": 0.31746
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.35273,
            "fmeasure": 0.40191
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.35273,
            "fmeasure": 0.40191
        },
        "nist": 1.6750735624264619,
        "bleu": 10.98374,
        "nubia": {
            "semantic_relation": 2.90655,
            "contradiction": 0.15661,
            "irrelevancy": 99.73332,
            "logical_agreement": 0.11007,
            "grammar_ref": 3.87789,
            "grammar_hyp": 4.35487,
            "nubia_score": 0.28313
        },
        "bertscore": {
            "precision": 0.86616,
            "recall": 0.84487,
            "f1": 0.85539
        },
        "meteor": 0.2639115808780018,
        "bleurt": -0.40178
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.2,
            "3": 0.7894736842105263
        },
        "rouge1": {
            "precision": 0.68333,
            "recall": 0.78618,
            "fmeasure": 0.73032
        },
        "rouge2": {
            "precision": 0.34795,
            "recall": 0.45119,
            "fmeasure": 0.3926
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.49842,
            "fmeasure": 0.45337
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.49842,
            "fmeasure": 0.45337
        },
        "nist": 3.8858137668671433,
        "bleu": 30.85696,
        "nubia": {
            "semantic_relation": 4.06505,
            "contradiction": 33.01841,
            "irrelevancy": 36.93324,
            "logical_agreement": 30.04835,
            "grammar_ref": 4.97036,
            "grammar_hyp": 4.74082,
            "nubia_score": 0.66216
        },
        "bertscore": {
            "precision": 0.88979,
            "recall": 0.92157,
            "f1": 0.90533
        },
        "meteor": 0.4087604914846346,
        "bleurt": 0.02376
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "mT5_base/totto_test",
        "N": 43,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2868217054263566,
            "2": 0.6293103448275862,
            "3": 0.8165938864628821
        },
        "rouge1": {
            "precision": 0.82133,
            "recall": 0.78579,
            "fmeasure": 0.79356
        },
        "rouge2": {
            "precision": 0.59617,
            "recall": 0.5722,
            "fmeasure": 0.57695
        },
        "rougeL": {
            "precision": 0.69979,
            "recall": 0.66727,
            "fmeasure": 0.67666
        },
        "rougeLsum": {
            "precision": 0.69979,
            "recall": 0.66727,
            "fmeasure": 0.67666
        },
        "nist": 7.517393150241579,
        "bleu": 52.2974,
        "nubia": {
            "semantic_relation": 4.48852,
            "contradiction": 1.5508,
            "irrelevancy": 23.89358,
            "logical_agreement": 74.55561,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.61583,
            "nubia_score": 0.82274
        },
        "bertscore": {
            "precision": 0.94353,
            "recall": 0.93646,
            "f1": 0.93875
        },
        "meteor": 0.435030005315879,
        "bleurt": 0.39217
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "mT5_base/totto_test",
        "N": 43,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.44360902255639095,
            "3": 0.8419811320754716
        },
        "rouge1": {
            "precision": 0.79917,
            "recall": 0.7904,
            "fmeasure": 0.78415
        },
        "rouge2": {
            "precision": 0.6027,
            "recall": 0.59359,
            "fmeasure": 0.59124
        },
        "rougeL": {
            "precision": 0.70427,
            "recall": 0.70966,
            "fmeasure": 0.69623
        },
        "rougeLsum": {
            "precision": 0.70427,
            "recall": 0.70966,
            "fmeasure": 0.69623
        },
        "nist": 7.20163777768018,
        "bleu": 54.68369,
        "nubia": {
            "semantic_relation": 4.3206,
            "contradiction": 6.2264,
            "irrelevancy": 27.90539,
            "logical_agreement": 65.8682,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.54789,
            "nubia_score": 0.75723
        },
        "bertscore": {
            "precision": 0.93747,
            "recall": 0.9377,
            "f1": 0.93573
        },
        "meteor": 0.4213076845132186,
        "bleurt": 0.31834
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "mT5_base/totto_test",
        "N": 9,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.3125,
            "3": 0.7652173913043478
        },
        "rouge1": {
            "precision": 0.7612,
            "recall": 0.7494,
            "fmeasure": 0.74913
        },
        "rouge2": {
            "precision": 0.46306,
            "recall": 0.46827,
            "fmeasure": 0.46114
        },
        "rougeL": {
            "precision": 0.59844,
            "recall": 0.60249,
            "fmeasure": 0.59549
        },
        "rougeLsum": {
            "precision": 0.59844,
            "recall": 0.60249,
            "fmeasure": 0.59549
        },
        "nist": 5.460817109958018,
        "bleu": 32.87367,
        "nubia": {
            "semantic_relation": 4.34331,
            "contradiction": 0.90254,
            "irrelevancy": 35.15256,
            "logical_agreement": 63.94491,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.54049,
            "nubia_score": 0.78716
        },
        "bertscore": {
            "precision": 0.92691,
            "recall": 0.92946,
            "f1": 0.92793
        },
        "meteor": 0.3670982441889134,
        "bleurt": 0.27655
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "mT5_base/totto_test",
        "N": 150,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.188470066518847,
            "2": 0.4243243243243243,
            "3": 0.7972508591065293
        },
        "rouge1": {
            "precision": 0.83625,
            "recall": 0.76934,
            "fmeasure": 0.79246
        },
        "rouge2": {
            "precision": 0.60137,
            "recall": 0.56244,
            "fmeasure": 0.5746
        },
        "rougeL": {
            "precision": 0.70999,
            "recall": 0.65651,
            "fmeasure": 0.67485
        },
        "rougeLsum": {
            "precision": 0.70999,
            "recall": 0.65651,
            "fmeasure": 0.67485
        },
        "nist": 8.169752972803842,
        "bleu": 49.10398,
        "nubia": {
            "semantic_relation": 4.45173,
            "contradiction": 6.04584,
            "irrelevancy": 24.41328,
            "logical_agreement": 69.54088,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.25973,
            "nubia_score": 0.77523
        },
        "bertscore": {
            "precision": 0.95103,
            "recall": 0.94149,
            "f1": 0.94518
        },
        "meteor": 0.4164646318397066,
        "bleurt": 0.39528
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "mT5_base/totto_test",
        "N": 21,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2318840579710145,
            "2": 0.39622641509433965,
            "3": 0.7872340425531915
        },
        "rouge1": {
            "precision": 0.73037,
            "recall": 0.71862,
            "fmeasure": 0.71572
        },
        "rouge2": {
            "precision": 0.50166,
            "recall": 0.48971,
            "fmeasure": 0.49048
        },
        "rougeL": {
            "precision": 0.64733,
            "recall": 0.64391,
            "fmeasure": 0.63848
        },
        "rougeLsum": {
            "precision": 0.64733,
            "recall": 0.64391,
            "fmeasure": 0.63848
        },
        "nist": 5.720570695301718,
        "bleu": 42.36966,
        "nubia": {
            "semantic_relation": 3.93934,
            "contradiction": 9.11469,
            "irrelevancy": 41.66716,
            "logical_agreement": 49.21815,
            "grammar_ref": 4.80447,
            "grammar_hyp": 4.96322,
            "nubia_score": 0.63417
        },
        "bertscore": {
            "precision": 0.92374,
            "recall": 0.92279,
            "f1": 0.92122
        },
        "meteor": 0.3790573584836621,
        "bleurt": 0.18675
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "mT5_base/totto_test",
        "N": 11,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19444444444444445,
            "2": 0.3181818181818182,
            "3": 0.7380952380952381
        },
        "rouge1": {
            "precision": 0.7959,
            "recall": 0.71275,
            "fmeasure": 0.74353
        },
        "rouge2": {
            "precision": 0.5294,
            "recall": 0.47841,
            "fmeasure": 0.49837
        },
        "rougeL": {
            "precision": 0.62313,
            "recall": 0.56818,
            "fmeasure": 0.58786
        },
        "rougeLsum": {
            "precision": 0.62313,
            "recall": 0.56818,
            "fmeasure": 0.58786
        },
        "nist": 5.2489151031449595,
        "bleu": 42.41115,
        "nubia": {
            "semantic_relation": 4.27063,
            "contradiction": 12.92523,
            "irrelevancy": 16.264,
            "logical_agreement": 70.81077,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.56039,
            "nubia_score": 0.73436
        },
        "bertscore": {
            "precision": 0.93033,
            "recall": 0.91793,
            "f1": 0.92271
        },
        "meteor": 0.3934434813327005,
        "bleurt": 0.23157
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.625,
            "3": 0.6338028169014085
        },
        "rouge1": {
            "precision": 0.77801,
            "recall": 0.65903,
            "fmeasure": 0.70331
        },
        "rouge2": {
            "precision": 0.47752,
            "recall": 0.40057,
            "fmeasure": 0.42811
        },
        "rougeL": {
            "precision": 0.65945,
            "recall": 0.55509,
            "fmeasure": 0.59441
        },
        "rougeLsum": {
            "precision": 0.65945,
            "recall": 0.55509,
            "fmeasure": 0.59441
        },
        "nist": 4.878233089300438,
        "bleu": 32.52478,
        "nubia": {
            "semantic_relation": 4.13481,
            "contradiction": 24.7936,
            "irrelevancy": 21.16894,
            "logical_agreement": 54.03747,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.27337,
            "nubia_score": 0.75573
        },
        "bertscore": {
            "precision": 0.91594,
            "recall": 0.91195,
            "f1": 0.91168
        },
        "meteor": 0.33687912194487996,
        "bleurt": 0.33945
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.5217391304347826,
            "3": 0.543859649122807
        },
        "rouge1": {
            "precision": 0.58694,
            "recall": 0.58771,
            "fmeasure": 0.57076
        },
        "rouge2": {
            "precision": 0.22494,
            "recall": 0.24475,
            "fmeasure": 0.22618
        },
        "rougeL": {
            "precision": 0.39846,
            "recall": 0.42733,
            "fmeasure": 0.40159
        },
        "rougeLsum": {
            "precision": 0.39846,
            "recall": 0.42733,
            "fmeasure": 0.40159
        },
        "nist": 3.6208732831672683,
        "bleu": 15.75221,
        "nubia": {
            "semantic_relation": 3.71453,
            "contradiction": 21.51227,
            "irrelevancy": 50.59264,
            "logical_agreement": 27.8951,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.57983,
            "nubia_score": 0.55302
        },
        "bertscore": {
            "precision": 0.87438,
            "recall": 0.87161,
            "f1": 0.87221
        },
        "meteor": 0.2568133616078547,
        "bleurt": -0.09795
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "mT5_base/totto_test",
        "N": 9,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.21428571428571427,
            "3": 0.7532467532467533
        },
        "rouge1": {
            "precision": 0.6856,
            "recall": 0.70453,
            "fmeasure": 0.67103
        },
        "rouge2": {
            "precision": 0.43317,
            "recall": 0.47171,
            "fmeasure": 0.43423
        },
        "rougeL": {
            "precision": 0.65046,
            "recall": 0.68995,
            "fmeasure": 0.64241
        },
        "rougeLsum": {
            "precision": 0.65046,
            "recall": 0.68995,
            "fmeasure": 0.64241
        },
        "nist": 4.518773273642378,
        "bleu": 34.4513,
        "nubia": {
            "semantic_relation": 4.10469,
            "contradiction": 17.71026,
            "irrelevancy": 18.67757,
            "logical_agreement": 63.61217,
            "grammar_ref": 5.16318,
            "grammar_hyp": 4.8692,
            "nubia_score": 0.68509
        },
        "bertscore": {
            "precision": 0.91924,
            "recall": 0.90399,
            "f1": 0.90974
        },
        "meteor": 0.3274659172356118,
        "bleurt": 0.31905
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "mT5_base/totto_test",
        "N": 11,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21875,
            "2": 0.4375,
            "3": 0.926829268292683
        },
        "rouge1": {
            "precision": 0.83539,
            "recall": 0.87577,
            "fmeasure": 0.85186
        },
        "rouge2": {
            "precision": 0.71188,
            "recall": 0.74387,
            "fmeasure": 0.72448
        },
        "rougeL": {
            "precision": 0.78233,
            "recall": 0.824,
            "fmeasure": 0.79933
        },
        "rougeLsum": {
            "precision": 0.78233,
            "recall": 0.824,
            "fmeasure": 0.79933
        },
        "nist": 5.9988309832339946,
        "bleu": 61.23061,
        "nubia": {
            "semantic_relation": 4.70627,
            "contradiction": 9.36818,
            "irrelevancy": 11.7064,
            "logical_agreement": 78.92542,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.10219,
            "nubia_score": 0.9309
        },
        "bertscore": {
            "precision": 0.9579,
            "recall": 0.96476,
            "f1": 0.96107
        },
        "meteor": 0.4857702729933422,
        "bleurt": 0.57029
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "mT5_base/totto_test",
        "N": 14,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.36666666666666664,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.7706,
            "recall": 0.71666,
            "fmeasure": 0.72919
        },
        "rouge2": {
            "precision": 0.50824,
            "recall": 0.47702,
            "fmeasure": 0.4841
        },
        "rougeL": {
            "precision": 0.69366,
            "recall": 0.64149,
            "fmeasure": 0.65285
        },
        "rougeLsum": {
            "precision": 0.69366,
            "recall": 0.64149,
            "fmeasure": 0.65285
        },
        "nist": 5.376668327834563,
        "bleu": 44.67876,
        "nubia": {
            "semantic_relation": 4.12188,
            "contradiction": 5.11339,
            "irrelevancy": 19.30512,
            "logical_agreement": 75.58149,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.57132,
            "nubia_score": 0.70939
        },
        "bertscore": {
            "precision": 0.92964,
            "recall": 0.91513,
            "f1": 0.92086
        },
        "meteor": 0.4016768680512297,
        "bleurt": 0.25525
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.47058823529411764,
            "3": 0.7246376811594203
        },
        "rouge1": {
            "precision": 0.6715,
            "recall": 0.69128,
            "fmeasure": 0.66998
        },
        "rouge2": {
            "precision": 0.45734,
            "recall": 0.46832,
            "fmeasure": 0.45581
        },
        "rougeL": {
            "precision": 0.60298,
            "recall": 0.61984,
            "fmeasure": 0.60144
        },
        "rougeLsum": {
            "precision": 0.60298,
            "recall": 0.61984,
            "fmeasure": 0.60144
        },
        "nist": 4.123995471676886,
        "bleu": 35.18062,
        "nubia": {
            "semantic_relation": 3.8255,
            "contradiction": 0.58743,
            "irrelevancy": 68.01844,
            "logical_agreement": 31.39413,
            "grammar_ref": 4.06397,
            "grammar_hyp": 3.98514,
            "nubia_score": 0.69343
        },
        "bertscore": {
            "precision": 0.90095,
            "recall": 0.90668,
            "f1": 0.90224
        },
        "meteor": 0.3666170925441367,
        "bleurt": 0.09826
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.2222222222222222,
            "3": 0.78
        },
        "rouge1": {
            "precision": 0.81082,
            "recall": 0.78014,
            "fmeasure": 0.78703
        },
        "rouge2": {
            "precision": 0.68737,
            "recall": 0.67654,
            "fmeasure": 0.67271
        },
        "rougeL": {
            "precision": 0.79138,
            "recall": 0.76495,
            "fmeasure": 0.77016
        },
        "rougeLsum": {
            "precision": 0.79138,
            "recall": 0.76495,
            "fmeasure": 0.77016
        },
        "nist": 5.700076953954029,
        "bleu": 67.71523,
        "nubia": {
            "semantic_relation": 4.44195,
            "contradiction": 8.10252,
            "irrelevancy": 17.87549,
            "logical_agreement": 74.02199,
            "grammar_ref": 4.84964,
            "grammar_hyp": 5.00228,
            "nubia_score": 0.76171
        },
        "bertscore": {
            "precision": 0.95993,
            "recall": 0.94493,
            "f1": 0.95231
        },
        "meteor": 0.44639040126465723,
        "bleurt": 0.3621
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "mT5_base/totto_test",
        "N": 80,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.268361581920904,
            "2": 0.4678362573099415,
            "3": 0.7192755498059509
        },
        "rouge1": {
            "precision": 0.70902,
            "recall": 0.67239,
            "fmeasure": 0.66993
        },
        "rouge2": {
            "precision": 0.44553,
            "recall": 0.43104,
            "fmeasure": 0.42397
        },
        "rougeL": {
            "precision": 0.5823,
            "recall": 0.56998,
            "fmeasure": 0.55835
        },
        "rougeLsum": {
            "precision": 0.5823,
            "recall": 0.56998,
            "fmeasure": 0.55835
        },
        "nist": 6.920535002548172,
        "bleu": 39.62916,
        "nubia": {
            "semantic_relation": 3.85533,
            "contradiction": 10.6309,
            "irrelevancy": 39.23118,
            "logical_agreement": 50.13792,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.55183,
            "nubia_score": 0.62155
        },
        "bertscore": {
            "precision": 0.90701,
            "recall": 0.89967,
            "f1": 0.90095
        },
        "meteor": 0.35130089438904627,
        "bleurt": 0.10025
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17142857142857143,
            "2": 0.4,
            "3": 0.7846153846153846
        },
        "rouge1": {
            "precision": 0.70357,
            "recall": 0.71507,
            "fmeasure": 0.69843
        },
        "rouge2": {
            "precision": 0.51223,
            "recall": 0.49224,
            "fmeasure": 0.49837
        },
        "rougeL": {
            "precision": 0.63718,
            "recall": 0.64614,
            "fmeasure": 0.63241
        },
        "rougeLsum": {
            "precision": 0.63718,
            "recall": 0.64614,
            "fmeasure": 0.63241
        },
        "nist": 4.878828607530009,
        "bleu": 44.21893,
        "nubia": {
            "semantic_relation": 4.09579,
            "contradiction": 14.65865,
            "irrelevancy": 39.23471,
            "logical_agreement": 46.10664,
            "grammar_ref": 5.24762,
            "grammar_hyp": 4.90117,
            "nubia_score": 0.67046
        },
        "bertscore": {
            "precision": 0.89669,
            "recall": 0.91323,
            "f1": 0.90314
        },
        "meteor": 0.3749729932753292,
        "bleurt": 0.11413
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.64167,
            "fmeasure": 0.5609
        },
        "rouge2": {
            "precision": 0.19231,
            "recall": 0.25758,
            "fmeasure": 0.2197
        },
        "rougeL": {
            "precision": 0.32143,
            "recall": 0.41667,
            "fmeasure": 0.36218
        },
        "rougeLsum": {
            "precision": 0.32143,
            "recall": 0.41667,
            "fmeasure": 0.36218
        },
        "nist": 2.2843108337660274,
        "bleu": 20.14942,
        "nubia": {
            "semantic_relation": 4.36276,
            "contradiction": 0.65012,
            "irrelevancy": 1.80793,
            "logical_agreement": 97.54195,
            "grammar_ref": 5.93899,
            "grammar_hyp": 5.37134,
            "nubia_score": 0.70811
        },
        "bertscore": {
            "precision": 0.87144,
            "recall": 0.88937,
            "f1": 0.87723
        },
        "meteor": 0.3739344706464413,
        "bleurt": -0.22311
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "mT5_base/totto_test",
        "N": 9,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.40540540540540543,
            "2": 0.6,
            "3": 0.8117647058823529
        },
        "rouge1": {
            "precision": 0.8832,
            "recall": 0.78669,
            "fmeasure": 0.82429
        },
        "rouge2": {
            "precision": 0.70076,
            "recall": 0.62961,
            "fmeasure": 0.65626
        },
        "rougeL": {
            "precision": 0.80468,
            "recall": 0.73899,
            "fmeasure": 0.7658
        },
        "rougeLsum": {
            "precision": 0.80468,
            "recall": 0.73899,
            "fmeasure": 0.7658
        },
        "nist": 5.852251976641079,
        "bleu": 60.23691,
        "nubia": {
            "semantic_relation": 4.28491,
            "contradiction": 0.53873,
            "irrelevancy": 18.32867,
            "logical_agreement": 81.13259,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.09775,
            "nubia_score": 0.73162
        },
        "bertscore": {
            "precision": 0.96935,
            "recall": 0.94264,
            "f1": 0.95538
        },
        "meteor": 0.4299296316881507,
        "bleurt": 0.39862
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "mT5_base/totto_test",
        "N": 14,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.46511627906976744,
            "3": 0.7883211678832117
        },
        "rouge1": {
            "precision": 0.71178,
            "recall": 0.74113,
            "fmeasure": 0.71717
        },
        "rouge2": {
            "precision": 0.47538,
            "recall": 0.51203,
            "fmeasure": 0.48817
        },
        "rougeL": {
            "precision": 0.6172,
            "recall": 0.64121,
            "fmeasure": 0.62416
        },
        "rougeLsum": {
            "precision": 0.6172,
            "recall": 0.64121,
            "fmeasure": 0.62416
        },
        "nist": 5.818496193274151,
        "bleu": 44.32099,
        "nubia": {
            "semantic_relation": 4.24035,
            "contradiction": 9.96751,
            "irrelevancy": 21.168,
            "logical_agreement": 68.86448,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.43155,
            "nubia_score": 0.7588
        },
        "bertscore": {
            "precision": 0.92898,
            "recall": 0.93729,
            "f1": 0.93139
        },
        "meteor": 0.4117379905797063,
        "bleurt": 0.28703
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "mT5_base/totto_test",
        "N": 22,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.16666666666666666,
            "3": 0.8774703557312253
        },
        "rouge1": {
            "precision": 0.82465,
            "recall": 0.83629,
            "fmeasure": 0.82399
        },
        "rouge2": {
            "precision": 0.66122,
            "recall": 0.66834,
            "fmeasure": 0.65914
        },
        "rougeL": {
            "precision": 0.73446,
            "recall": 0.75068,
            "fmeasure": 0.73685
        },
        "rougeLsum": {
            "precision": 0.73446,
            "recall": 0.75068,
            "fmeasure": 0.73685
        },
        "nist": 6.85783554522103,
        "bleu": 62.47883,
        "nubia": {
            "semantic_relation": 4.40351,
            "contradiction": 1.62681,
            "irrelevancy": 30.91414,
            "logical_agreement": 67.45905,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.30533,
            "nubia_score": 0.82556
        },
        "bertscore": {
            "precision": 0.95071,
            "recall": 0.9502,
            "f1": 0.94949
        },
        "meteor": 0.4846053391066877,
        "bleurt": 0.46019
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.60165,
            "recall": 0.90278,
            "fmeasure": 0.70222
        },
        "rouge2": {
            "precision": 0.44872,
            "recall": 0.68788,
            "fmeasure": 0.52503
        },
        "rougeL": {
            "precision": 0.52473,
            "recall": 0.81439,
            "fmeasure": 0.62
        },
        "rougeLsum": {
            "precision": 0.52473,
            "recall": 0.81439,
            "fmeasure": 0.62
        },
        "nist": 2.676924991271009,
        "bleu": 34.25315,
        "nubia": {
            "semantic_relation": 3.95366,
            "contradiction": 0.44328,
            "irrelevancy": 68.72428,
            "logical_agreement": 30.83245,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.79445,
            "nubia_score": 0.70644
        },
        "bertscore": {
            "precision": 0.86898,
            "recall": 0.92833,
            "f1": 0.89715
        },
        "meteor": 0.4459282252670382,
        "bleurt": 0.07527
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.0,
            "3": 0.7647058823529411
        },
        "rouge1": {
            "precision": 0.70455,
            "recall": 0.61788,
            "fmeasure": 0.65714
        },
        "rouge2": {
            "precision": 0.34815,
            "recall": 0.32906,
            "fmeasure": 0.33474
        },
        "rougeL": {
            "precision": 0.50606,
            "recall": 0.48718,
            "fmeasure": 0.49176
        },
        "rougeLsum": {
            "precision": 0.50606,
            "recall": 0.48718,
            "fmeasure": 0.49176
        },
        "nist": 3.4315544461461838,
        "bleu": 26.76291,
        "nubia": {
            "semantic_relation": 4.22473,
            "contradiction": 9.83809,
            "irrelevancy": 46.50957,
            "logical_agreement": 43.65234,
            "grammar_ref": 5.15434,
            "grammar_hyp": 5.03933,
            "nubia_score": 0.6967
        },
        "bertscore": {
            "precision": 0.90438,
            "recall": 0.88365,
            "f1": 0.89389
        },
        "meteor": 0.3199698095780554,
        "bleurt": 0.19746
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "mT5_base/totto_test",
        "N": 13,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15492957746478872,
            "2": 0.4716981132075472,
            "3": 0.6507936507936508
        },
        "rouge1": {
            "precision": 0.66224,
            "recall": 0.65638,
            "fmeasure": 0.64994
        },
        "rouge2": {
            "precision": 0.38041,
            "recall": 0.38324,
            "fmeasure": 0.37613
        },
        "rougeL": {
            "precision": 0.5425,
            "recall": 0.54056,
            "fmeasure": 0.53371
        },
        "rougeLsum": {
            "precision": 0.5425,
            "recall": 0.54056,
            "fmeasure": 0.53371
        },
        "nist": 4.868936646574225,
        "bleu": 33.3597,
        "nubia": {
            "semantic_relation": 3.7442,
            "contradiction": 28.89152,
            "irrelevancy": 34.10386,
            "logical_agreement": 37.00463,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.21129,
            "nubia_score": 0.6153
        },
        "bertscore": {
            "precision": 0.90613,
            "recall": 0.90207,
            "f1": 0.90273
        },
        "meteor": 0.351243257247929,
        "bleurt": 0.05714
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.90909,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.79259,
            "fmeasure": 0.77895
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.90606,
            "fmeasure": 0.89177
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.90606,
            "fmeasure": 0.89177
        },
        "nist": 3.9319229794768673,
        "bleu": 70.71068,
        "nubia": {
            "semantic_relation": 3.65062,
            "contradiction": 98.65615,
            "irrelevancy": 0.65989,
            "logical_agreement": 0.68396,
            "grammar_ref": 3.16175,
            "grammar_hyp": 3.08864,
            "nubia_score": 0.63956
        },
        "bertscore": {
            "precision": 0.98913,
            "recall": 0.98913,
            "f1": 0.98913
        },
        "meteor": 0.5023397349274512,
        "bleurt": 0.60759
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "mT5_base/totto_test",
        "N": 23,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.4927536231884058,
            "3": 0.8552631578947368
        },
        "rouge1": {
            "precision": 0.75436,
            "recall": 0.77932,
            "fmeasure": 0.76062
        },
        "rouge2": {
            "precision": 0.55321,
            "recall": 0.56872,
            "fmeasure": 0.55642
        },
        "rougeL": {
            "precision": 0.69011,
            "recall": 0.70052,
            "fmeasure": 0.69037
        },
        "rougeLsum": {
            "precision": 0.69011,
            "recall": 0.70052,
            "fmeasure": 0.69037
        },
        "nist": 6.337895967388989,
        "bleu": 49.61973,
        "nubia": {
            "semantic_relation": 4.31735,
            "contradiction": 5.617,
            "irrelevancy": 33.42485,
            "logical_agreement": 60.95815,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.47843,
            "nubia_score": 0.79572
        },
        "bertscore": {
            "precision": 0.93709,
            "recall": 0.94129,
            "f1": 0.93841
        },
        "meteor": 0.43855505004128664,
        "bleurt": 0.33062
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "mT5_base/totto_test",
        "N": 66,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23383084577114427,
            "2": 0.41836734693877553,
            "3": 0.7557471264367817
        },
        "rouge1": {
            "precision": 0.73895,
            "recall": 0.71985,
            "fmeasure": 0.71952
        },
        "rouge2": {
            "precision": 0.51955,
            "recall": 0.512,
            "fmeasure": 0.50794
        },
        "rougeL": {
            "precision": 0.64019,
            "recall": 0.62758,
            "fmeasure": 0.62483
        },
        "rougeLsum": {
            "precision": 0.64019,
            "recall": 0.62758,
            "fmeasure": 0.62483
        },
        "nist": 6.811495335821523,
        "bleu": 41.89546,
        "nubia": {
            "semantic_relation": 4.22748,
            "contradiction": 6.19036,
            "irrelevancy": 37.74322,
            "logical_agreement": 56.06642,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.25957,
            "nubia_score": 0.76044
        },
        "bertscore": {
            "precision": 0.91968,
            "recall": 0.92118,
            "f1": 0.91835
        },
        "meteor": 0.3870789854395567,
        "bleurt": 0.26625
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.4,
            "3": 0.7678571428571429
        },
        "rouge1": {
            "precision": 0.90549,
            "recall": 0.70867,
            "fmeasure": 0.78651
        },
        "rouge2": {
            "precision": 0.70096,
            "recall": 0.53503,
            "fmeasure": 0.59938
        },
        "rougeL": {
            "precision": 0.78798,
            "recall": 0.61611,
            "fmeasure": 0.68377
        },
        "rougeLsum": {
            "precision": 0.78798,
            "recall": 0.61611,
            "fmeasure": 0.68377
        },
        "nist": 4.954126908209955,
        "bleu": 48.99389,
        "nubia": {
            "semantic_relation": 4.48294,
            "contradiction": 1.26662,
            "irrelevancy": 13.92727,
            "logical_agreement": 84.80611,
            "grammar_ref": 4.74509,
            "grammar_hyp": 4.94894,
            "nubia_score": 0.81219
        },
        "bertscore": {
            "precision": 0.95592,
            "recall": 0.92104,
            "f1": 0.93776
        },
        "meteor": 0.40926457102880737,
        "bleurt": 0.31304
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6,
            "3": 0.6428571428571429
        },
        "rouge1": {
            "precision": 0.56322,
            "recall": 0.58333,
            "fmeasure": 0.5731
        },
        "rouge2": {
            "precision": 0.34524,
            "recall": 0.38827,
            "fmeasure": 0.36389
        },
        "rougeL": {
            "precision": 0.37931,
            "recall": 0.48016,
            "fmeasure": 0.42199
        },
        "rougeLsum": {
            "precision": 0.37931,
            "recall": 0.48016,
            "fmeasure": 0.42199
        },
        "nist": 3.227826849995979,
        "bleu": 24.98539,
        "nubia": {
            "semantic_relation": 4.28838,
            "contradiction": 40.37805,
            "irrelevancy": 23.20363,
            "logical_agreement": 36.41832,
            "grammar_ref": 3.5675,
            "grammar_hyp": 3.61747,
            "nubia_score": 0.72064
        },
        "bertscore": {
            "precision": 0.89395,
            "recall": 0.90009,
            "f1": 0.89701
        },
        "meteor": 0.31690557477605513,
        "bleurt": -0.05621
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.23404255319148937,
            "3": 0.8709677419354839
        },
        "rouge1": {
            "precision": 0.85894,
            "recall": 0.65668,
            "fmeasure": 0.72638
        },
        "rouge2": {
            "precision": 0.61279,
            "recall": 0.49455,
            "fmeasure": 0.53631
        },
        "rougeL": {
            "precision": 0.73672,
            "recall": 0.5926,
            "fmeasure": 0.64338
        },
        "rougeLsum": {
            "precision": 0.73672,
            "recall": 0.5926,
            "fmeasure": 0.64338
        },
        "nist": 4.32603293642201,
        "bleu": 51.99011,
        "nubia": {
            "semantic_relation": 3.78867,
            "contradiction": 0.74096,
            "irrelevancy": 46.32194,
            "logical_agreement": 52.93709,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.82468,
            "nubia_score": 0.57955
        },
        "bertscore": {
            "precision": 0.9364,
            "recall": 0.89892,
            "f1": 0.91599
        },
        "meteor": 0.385599554653965,
        "bleurt": 0.10415
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "mT5_base/totto_test",
        "N": 14,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.5454545454545454,
            "3": 0.8357142857142857
        },
        "rouge1": {
            "precision": 0.83529,
            "recall": 0.77495,
            "fmeasure": 0.79873
        },
        "rouge2": {
            "precision": 0.65427,
            "recall": 0.62695,
            "fmeasure": 0.63725
        },
        "rougeL": {
            "precision": 0.71406,
            "recall": 0.67952,
            "fmeasure": 0.69305
        },
        "rougeLsum": {
            "precision": 0.71406,
            "recall": 0.67952,
            "fmeasure": 0.69305
        },
        "nist": 6.261674940463404,
        "bleu": 60.08913,
        "nubia": {
            "semantic_relation": 4.21048,
            "contradiction": 6.04375,
            "irrelevancy": 26.65208,
            "logical_agreement": 67.30417,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.88511,
            "nubia_score": 0.73444
        },
        "bertscore": {
            "precision": 0.95183,
            "recall": 0.9333,
            "f1": 0.94023
        },
        "meteor": 0.43604102239367576,
        "bleurt": 0.41407
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_base/totto_test",
        "N": 124,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21325051759834368,
            "2": 0.417607223476298,
            "3": 0.7160931174089069
        },
        "rouge1": {
            "precision": 0.72751,
            "recall": 0.67366,
            "fmeasure": 0.68988
        },
        "rouge2": {
            "precision": 0.46017,
            "recall": 0.43516,
            "fmeasure": 0.43966
        },
        "rougeL": {
            "precision": 0.5767,
            "recall": 0.54246,
            "fmeasure": 0.55049
        },
        "rougeLsum": {
            "precision": 0.5767,
            "recall": 0.54246,
            "fmeasure": 0.55049
        },
        "nist": 7.418981803731484,
        "bleu": 37.64085,
        "nubia": {
            "semantic_relation": 3.86974,
            "contradiction": 15.16334,
            "irrelevancy": 31.44793,
            "logical_agreement": 53.38872,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.23652,
            "nubia_score": 0.6297
        },
        "bertscore": {
            "precision": 0.91551,
            "recall": 0.90453,
            "f1": 0.90764
        },
        "meteor": 0.35173216078861236,
        "bleurt": 0.10262
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6896551724137931
        },
        "rouge1": {
            "precision": 0.7702,
            "recall": 0.68256,
            "fmeasure": 0.72327
        },
        "rouge2": {
            "precision": 0.49412,
            "recall": 0.43957,
            "fmeasure": 0.46489
        },
        "rougeL": {
            "precision": 0.54293,
            "recall": 0.49025,
            "fmeasure": 0.51494
        },
        "rougeLsum": {
            "precision": 0.54293,
            "recall": 0.49025,
            "fmeasure": 0.51494
        },
        "nist": 3.3966623537957195,
        "bleu": 33.97794,
        "nubia": {
            "semantic_relation": 3.91698,
            "contradiction": 23.36178,
            "irrelevancy": 63.0793,
            "logical_agreement": 13.55892,
            "grammar_ref": 4.49155,
            "grammar_hyp": 4.57342,
            "nubia_score": 0.61657
        },
        "bertscore": {
            "precision": 0.92263,
            "recall": 0.9263,
            "f1": 0.92434
        },
        "meteor": 0.362818326446232,
        "bleurt": 0.39855
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.08333333333333333,
            "3": 0.717948717948718
        },
        "rouge1": {
            "precision": 0.8498,
            "recall": 0.69811,
            "fmeasure": 0.75852
        },
        "rouge2": {
            "precision": 0.64533,
            "recall": 0.53212,
            "fmeasure": 0.57681
        },
        "rougeL": {
            "precision": 0.71495,
            "recall": 0.5906,
            "fmeasure": 0.64054
        },
        "rougeLsum": {
            "precision": 0.71495,
            "recall": 0.5906,
            "fmeasure": 0.64054
        },
        "nist": 5.065986548606417,
        "bleu": 53.22434,
        "nubia": {
            "semantic_relation": 4.26343,
            "contradiction": 0.74506,
            "irrelevancy": 20.52217,
            "logical_agreement": 78.73277,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.25693,
            "nubia_score": 0.74259
        },
        "bertscore": {
            "precision": 0.94234,
            "recall": 0.9127,
            "f1": 0.92637
        },
        "meteor": 0.39717087880472823,
        "bleurt": 0.3094
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "mT5_base/totto_test",
        "N": 11,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.027777777777777776,
            "2": 0.48,
            "3": 0.7446808510638298
        },
        "rouge1": {
            "precision": 0.77556,
            "recall": 0.68852,
            "fmeasure": 0.71824
        },
        "rouge2": {
            "precision": 0.49018,
            "recall": 0.42987,
            "fmeasure": 0.45108
        },
        "rougeL": {
            "precision": 0.66445,
            "recall": 0.58034,
            "fmeasure": 0.60976
        },
        "rougeLsum": {
            "precision": 0.66445,
            "recall": 0.58034,
            "fmeasure": 0.60976
        },
        "nist": 5.308371280501713,
        "bleu": 38.18197,
        "nubia": {
            "semantic_relation": 4.21401,
            "contradiction": 1.73251,
            "irrelevancy": 30.22067,
            "logical_agreement": 68.04682,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.94126,
            "nubia_score": 0.71899
        },
        "bertscore": {
            "precision": 0.92513,
            "recall": 0.91293,
            "f1": 0.9176
        },
        "meteor": 0.37376334975536346,
        "bleurt": 0.23288
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3142857142857143,
            "3": 0.8840579710144928
        },
        "rouge1": {
            "precision": 0.76828,
            "recall": 0.74856,
            "fmeasure": 0.75198
        },
        "rouge2": {
            "precision": 0.51165,
            "recall": 0.50337,
            "fmeasure": 0.50352
        },
        "rougeL": {
            "precision": 0.62656,
            "recall": 0.60342,
            "fmeasure": 0.6098
        },
        "rougeLsum": {
            "precision": 0.62656,
            "recall": 0.60342,
            "fmeasure": 0.6098
        },
        "nist": 5.450570125174829,
        "bleu": 42.21916,
        "nubia": {
            "semantic_relation": 4.22771,
            "contradiction": 26.66244,
            "irrelevancy": 21.74783,
            "logical_agreement": 51.58973,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.45243,
            "nubia_score": 0.74414
        },
        "bertscore": {
            "precision": 0.92156,
            "recall": 0.9338,
            "f1": 0.92679
        },
        "meteor": 0.4216015390342862,
        "bleurt": 0.24992
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.875,
            "3": 0.8157894736842105
        },
        "rouge1": {
            "precision": 0.81376,
            "recall": 0.79836,
            "fmeasure": 0.80294
        },
        "rouge2": {
            "precision": 0.59938,
            "recall": 0.59939,
            "fmeasure": 0.59686
        },
        "rougeL": {
            "precision": 0.7344,
            "recall": 0.73174,
            "fmeasure": 0.73057
        },
        "rougeLsum": {
            "precision": 0.7344,
            "recall": 0.73174,
            "fmeasure": 0.73057
        },
        "nist": 4.919914186267077,
        "bleu": 57.41338,
        "nubia": {
            "semantic_relation": 4.5341,
            "contradiction": 0.50556,
            "irrelevancy": 5.55321,
            "logical_agreement": 93.94123,
            "grammar_ref": 5.12632,
            "grammar_hyp": 4.74754,
            "nubia_score": 0.87688
        },
        "bertscore": {
            "precision": 0.95573,
            "recall": 0.94769,
            "f1": 0.9513
        },
        "meteor": 0.4645118528256588,
        "bleurt": 0.57116
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3181818181818182,
            "2": 0.5,
            "3": 0.7619047619047619
        },
        "rouge1": {
            "precision": 0.84549,
            "recall": 0.73204,
            "fmeasure": 0.77014
        },
        "rouge2": {
            "precision": 0.64128,
            "recall": 0.53483,
            "fmeasure": 0.57077
        },
        "rougeL": {
            "precision": 0.72772,
            "recall": 0.6391,
            "fmeasure": 0.66908
        },
        "rougeLsum": {
            "precision": 0.72772,
            "recall": 0.6391,
            "fmeasure": 0.66908
        },
        "nist": 5.33139568443432,
        "bleu": 55.93422,
        "nubia": {
            "semantic_relation": 4.30534,
            "contradiction": 0.83266,
            "irrelevancy": 36.72865,
            "logical_agreement": 62.43869,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.66296,
            "nubia_score": 0.73886
        },
        "bertscore": {
            "precision": 0.95078,
            "recall": 0.93108,
            "f1": 0.93654
        },
        "meteor": 0.4257340105975063,
        "bleurt": 0.05183
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.45454545454545453,
            "3": 0.8695652173913043
        },
        "rouge1": {
            "precision": 0.75996,
            "recall": 0.74827,
            "fmeasure": 0.7476
        },
        "rouge2": {
            "precision": 0.592,
            "recall": 0.58753,
            "fmeasure": 0.58378
        },
        "rougeL": {
            "precision": 0.70039,
            "recall": 0.68356,
            "fmeasure": 0.68507
        },
        "rougeLsum": {
            "precision": 0.70039,
            "recall": 0.68356,
            "fmeasure": 0.68507
        },
        "nist": 5.386148913248881,
        "bleu": 54.81237,
        "nubia": {
            "semantic_relation": 4.41532,
            "contradiction": 15.57418,
            "irrelevancy": 29.83429,
            "logical_agreement": 54.59152,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.65275,
            "nubia_score": 0.76432
        },
        "bertscore": {
            "precision": 0.94363,
            "recall": 0.93863,
            "f1": 0.94098
        },
        "meteor": 0.44802082291826656,
        "bleurt": 0.45856
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "mT5_base/totto_test",
        "N": 23,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27380952380952384,
            "2": 0.3855421686746988,
            "3": 0.7407407407407407
        },
        "rouge1": {
            "precision": 0.80635,
            "recall": 0.71041,
            "fmeasure": 0.73912
        },
        "rouge2": {
            "precision": 0.55078,
            "recall": 0.50318,
            "fmeasure": 0.5141
        },
        "rougeL": {
            "precision": 0.71524,
            "recall": 0.64673,
            "fmeasure": 0.66449
        },
        "rougeLsum": {
            "precision": 0.71524,
            "recall": 0.64673,
            "fmeasure": 0.66449
        },
        "nist": 6.363090268673897,
        "bleu": 49.07802,
        "nubia": {
            "semantic_relation": 4.1179,
            "contradiction": 9.55371,
            "irrelevancy": 32.33499,
            "logical_agreement": 58.1113,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.55996,
            "nubia_score": 0.69035
        },
        "bertscore": {
            "precision": 0.93347,
            "recall": 0.91557,
            "f1": 0.92241
        },
        "meteor": 0.38153983627582816,
        "bleurt": 0.25259
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "mT5_base/totto_test",
        "N": 19,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2077922077922078,
            "2": 0.2549019607843137,
            "3": 0.6508620689655172
        },
        "rouge1": {
            "precision": 0.76646,
            "recall": 0.64285,
            "fmeasure": 0.68919
        },
        "rouge2": {
            "precision": 0.54904,
            "recall": 0.47391,
            "fmeasure": 0.50273
        },
        "rougeL": {
            "precision": 0.67048,
            "recall": 0.56865,
            "fmeasure": 0.60643
        },
        "rougeLsum": {
            "precision": 0.67048,
            "recall": 0.56865,
            "fmeasure": 0.60643
        },
        "nist": 4.916993069558807,
        "bleu": 46.00837,
        "nubia": {
            "semantic_relation": 3.97639,
            "contradiction": 21.48803,
            "irrelevancy": 21.07043,
            "logical_agreement": 57.44155,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.62501,
            "nubia_score": 0.63135
        },
        "bertscore": {
            "precision": 0.93178,
            "recall": 0.90199,
            "f1": 0.91454
        },
        "meteor": 0.3742246815637106,
        "bleurt": 0.19886
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6875,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.62543,
            "recall": 0.70967,
            "fmeasure": 0.64874
        },
        "rouge2": {
            "precision": 0.39379,
            "recall": 0.45463,
            "fmeasure": 0.41414
        },
        "rougeL": {
            "precision": 0.5568,
            "recall": 0.60361,
            "fmeasure": 0.56541
        },
        "rougeLsum": {
            "precision": 0.5568,
            "recall": 0.60361,
            "fmeasure": 0.56541
        },
        "nist": 3.8763441874980895,
        "bleu": 43.91123,
        "nubia": {
            "semantic_relation": 3.52164,
            "contradiction": 0.43783,
            "irrelevancy": 66.27633,
            "logical_agreement": 33.28585,
            "grammar_ref": 4.86076,
            "grammar_hyp": 4.77446,
            "nubia_score": 0.56071
        },
        "bertscore": {
            "precision": 0.90033,
            "recall": 0.91701,
            "f1": 0.90745
        },
        "meteor": 0.4252368463045525,
        "bleurt": 0.10787
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "mT5_base/totto_test",
        "N": 73,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2372093023255814,
            "2": 0.463855421686747,
            "3": 0.7636363636363637
        },
        "rouge1": {
            "precision": 0.80588,
            "recall": 0.73559,
            "fmeasure": 0.7577
        },
        "rouge2": {
            "precision": 0.57538,
            "recall": 0.5228,
            "fmeasure": 0.53777
        },
        "rougeL": {
            "precision": 0.71808,
            "recall": 0.66279,
            "fmeasure": 0.67818
        },
        "rougeLsum": {
            "precision": 0.71808,
            "recall": 0.66279,
            "fmeasure": 0.67818
        },
        "nist": 7.383639828585996,
        "bleu": 47.49003,
        "nubia": {
            "semantic_relation": 4.18121,
            "contradiction": 10.31607,
            "irrelevancy": 28.48655,
            "logical_agreement": 61.19738,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.66747,
            "nubia_score": 0.7262
        },
        "bertscore": {
            "precision": 0.93871,
            "recall": 0.9238,
            "f1": 0.92964
        },
        "meteor": 0.393759137020715,
        "bleurt": 0.29189
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "mT5_base/totto_test",
        "N": 31,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.3125,
            "3": 0.8540540540540541
        },
        "rouge1": {
            "precision": 0.80855,
            "recall": 0.80004,
            "fmeasure": 0.79805
        },
        "rouge2": {
            "precision": 0.6104,
            "recall": 0.60656,
            "fmeasure": 0.60328
        },
        "rougeL": {
            "precision": 0.69522,
            "recall": 0.69157,
            "fmeasure": 0.68802
        },
        "rougeLsum": {
            "precision": 0.69522,
            "recall": 0.69157,
            "fmeasure": 0.68802
        },
        "nist": 7.459000750056162,
        "bleu": 56.9965,
        "nubia": {
            "semantic_relation": 4.35853,
            "contradiction": 4.79117,
            "irrelevancy": 18.72274,
            "logical_agreement": 76.48609,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.63433,
            "nubia_score": 0.77736
        },
        "bertscore": {
            "precision": 0.94804,
            "recall": 0.94311,
            "f1": 0.94423
        },
        "meteor": 0.44648782203586,
        "bleurt": 0.43539
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9473684210526315
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.91931,
            "fmeasure": 0.84818
        },
        "rouge2": {
            "precision": 0.57292,
            "recall": 0.64828,
            "fmeasure": 0.60215
        },
        "rougeL": {
            "precision": 0.66176,
            "recall": 0.76128,
            "fmeasure": 0.70196
        },
        "rougeLsum": {
            "precision": 0.66176,
            "recall": 0.76128,
            "fmeasure": 0.70196
        },
        "nist": 3.5609276144360043,
        "bleu": 50.31748,
        "nubia": {
            "semantic_relation": 4.47435,
            "contradiction": 0.19412,
            "irrelevancy": 42.60043,
            "logical_agreement": 57.20545,
            "grammar_ref": 5.56806,
            "grammar_hyp": 4.975,
            "nubia_score": 0.87885
        },
        "bertscore": {
            "precision": 0.94301,
            "recall": 0.96216,
            "f1": 0.95238
        },
        "meteor": 0.48703239077973215,
        "bleurt": 0.44635
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "mT5_base/totto_test",
        "N": 29,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2236842105263158,
            "2": 0.5074626865671642,
            "3": 0.8289085545722714
        },
        "rouge1": {
            "precision": 0.84004,
            "recall": 0.81554,
            "fmeasure": 0.82014
        },
        "rouge2": {
            "precision": 0.67285,
            "recall": 0.65037,
            "fmeasure": 0.65579
        },
        "rougeL": {
            "precision": 0.75758,
            "recall": 0.7285,
            "fmeasure": 0.73705
        },
        "rougeLsum": {
            "precision": 0.75758,
            "recall": 0.7285,
            "fmeasure": 0.73705
        },
        "nist": 7.116446674583219,
        "bleu": 56.24106,
        "nubia": {
            "semantic_relation": 4.33811,
            "contradiction": 8.19933,
            "irrelevancy": 24.87745,
            "logical_agreement": 66.92322,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.70932,
            "nubia_score": 0.78657
        },
        "bertscore": {
            "precision": 0.95096,
            "recall": 0.94453,
            "f1": 0.94709
        },
        "meteor": 0.4423197878443253,
        "bleurt": 0.45245
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20754716981132076,
            "2": 0.6216216216216216,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.59154,
            "recall": 0.5961,
            "fmeasure": 0.58418
        },
        "rouge2": {
            "precision": 0.35772,
            "recall": 0.35472,
            "fmeasure": 0.34807
        },
        "rougeL": {
            "precision": 0.43246,
            "recall": 0.45887,
            "fmeasure": 0.43766
        },
        "rougeLsum": {
            "precision": 0.43246,
            "recall": 0.45887,
            "fmeasure": 0.43766
        },
        "nist": 4.382037055402122,
        "bleu": 29.37883,
        "nubia": {
            "semantic_relation": 3.9891,
            "contradiction": 15.24154,
            "irrelevancy": 52.40429,
            "logical_agreement": 32.35417,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.59814,
            "nubia_score": 0.65242
        },
        "bertscore": {
            "precision": 0.90098,
            "recall": 0.91063,
            "f1": 0.90272
        },
        "meteor": 0.33965053263169126,
        "bleurt": 0.03205
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.5,
            "3": 0.810126582278481
        },
        "rouge1": {
            "precision": 0.84401,
            "recall": 0.81535,
            "fmeasure": 0.82348
        },
        "rouge2": {
            "precision": 0.66062,
            "recall": 0.64148,
            "fmeasure": 0.64709
        },
        "rougeL": {
            "precision": 0.70314,
            "recall": 0.68967,
            "fmeasure": 0.69271
        },
        "rougeLsum": {
            "precision": 0.70314,
            "recall": 0.68967,
            "fmeasure": 0.69271
        },
        "nist": 5.412837574073181,
        "bleu": 55.63154,
        "nubia": {
            "semantic_relation": 4.43912,
            "contradiction": 1.01574,
            "irrelevancy": 30.623,
            "logical_agreement": 68.36126,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.6453,
            "nubia_score": 0.81968
        },
        "bertscore": {
            "precision": 0.96149,
            "recall": 0.9506,
            "f1": 0.95558
        },
        "meteor": 0.4286684338785289,
        "bleurt": 0.46218
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.93939,
            "fmeasure": 0.83413
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.80476,
            "fmeasure": 0.70392
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "nist": 2.306664886548115,
        "bleu": 27.09199,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20045,
            "irrelevancy": 22.76085,
            "logical_agreement": 77.0387,
            "grammar_ref": 3.38649,
            "grammar_hyp": 3.17028,
            "nubia_score": 0.92133
        },
        "bertscore": {
            "precision": 0.94572,
            "recall": 0.94055,
            "f1": 0.94053
        },
        "meteor": 0.4912092865802179,
        "bleurt": 0.67831
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.7746,
            "recall": 0.6985,
            "fmeasure": 0.72768
        },
        "rouge2": {
            "precision": 0.68132,
            "recall": 0.61667,
            "fmeasure": 0.64166
        },
        "rougeL": {
            "precision": 0.75079,
            "recall": 0.68263,
            "fmeasure": 0.70863
        },
        "rougeLsum": {
            "precision": 0.75079,
            "recall": 0.68263,
            "fmeasure": 0.70863
        },
        "nist": 4.9734383106619315,
        "bleu": 74.4782,
        "nubia": {
            "semantic_relation": 3.71255,
            "contradiction": 5.67849,
            "irrelevancy": 42.82797,
            "logical_agreement": 51.49354,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.31629,
            "nubia_score": 0.57667
        },
        "bertscore": {
            "precision": 0.93954,
            "recall": 0.90699,
            "f1": 0.92186
        },
        "meteor": 0.39386760798557685,
        "bleurt": 0.08039
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "mT5_base/totto_test",
        "N": 31,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17333333333333334,
            "2": 0.5189873417721519,
            "3": 0.790625
        },
        "rouge1": {
            "precision": 0.77496,
            "recall": 0.74595,
            "fmeasure": 0.74871
        },
        "rouge2": {
            "precision": 0.55467,
            "recall": 0.53344,
            "fmeasure": 0.53709
        },
        "rougeL": {
            "precision": 0.65932,
            "recall": 0.633,
            "fmeasure": 0.63529
        },
        "rougeLsum": {
            "precision": 0.65932,
            "recall": 0.633,
            "fmeasure": 0.63529
        },
        "nist": 6.534252405230619,
        "bleu": 49.10188,
        "nubia": {
            "semantic_relation": 4.3813,
            "contradiction": 2.93434,
            "irrelevancy": 33.3765,
            "logical_agreement": 63.68916,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.68759,
            "nubia_score": 0.77498
        },
        "bertscore": {
            "precision": 0.93187,
            "recall": 0.92754,
            "f1": 0.92811
        },
        "meteor": 0.41400688231507715,
        "bleurt": 0.34426
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.7,
            "fmeasure": 0.65385
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "nist": 3.7574673462380614,
        "bleu": 65.8037,
        "nubia": {
            "semantic_relation": 4.11383,
            "contradiction": 0.4147,
            "irrelevancy": 35.64603,
            "logical_agreement": 63.93928,
            "grammar_ref": 4.09688,
            "grammar_hyp": 3.81746,
            "nubia_score": 0.76218
        },
        "bertscore": {
            "precision": 0.97544,
            "recall": 0.97544,
            "f1": 0.97544
        },
        "meteor": 0.9555555555555555,
        "bleurt": 0.34708
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.6153846153846154,
            "3": 0.8035714285714286
        },
        "rouge1": {
            "precision": 0.81359,
            "recall": 0.78403,
            "fmeasure": 0.7928
        },
        "rouge2": {
            "precision": 0.59459,
            "recall": 0.56599,
            "fmeasure": 0.57539
        },
        "rougeL": {
            "precision": 0.75891,
            "recall": 0.73144,
            "fmeasure": 0.7397
        },
        "rougeLsum": {
            "precision": 0.75891,
            "recall": 0.73144,
            "fmeasure": 0.7397
        },
        "nist": 4.953862007111126,
        "bleu": 51.55145,
        "nubia": {
            "semantic_relation": 4.47912,
            "contradiction": 22.62989,
            "irrelevancy": 18.45058,
            "logical_agreement": 58.91953,
            "grammar_ref": 5.14386,
            "grammar_hyp": 5.15537,
            "nubia_score": 0.78432
        },
        "bertscore": {
            "precision": 0.95213,
            "recall": 0.95492,
            "f1": 0.95334
        },
        "meteor": 0.4279367310829039,
        "bleurt": 0.50132
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.47058823529411764
        },
        "rouge1": {
            "precision": 0.53623,
            "recall": 0.40722,
            "fmeasure": 0.46163
        },
        "rouge2": {
            "precision": 0.20455,
            "recall": 0.16468,
            "fmeasure": 0.18245
        },
        "rougeL": {
            "precision": 0.4058,
            "recall": 0.30131,
            "fmeasure": 0.34474
        },
        "rougeLsum": {
            "precision": 0.4058,
            "recall": 0.30131,
            "fmeasure": 0.34474
        },
        "nist": 1.7805282489590815,
        "bleu": 10.62386,
        "nubia": {
            "semantic_relation": 2.73735,
            "contradiction": 1.30282,
            "irrelevancy": 48.54953,
            "logical_agreement": 50.14765,
            "grammar_ref": 4.82994,
            "grammar_hyp": 5.19159,
            "nubia_score": 0.31607
        },
        "bertscore": {
            "precision": 0.87179,
            "recall": 0.8438,
            "f1": 0.85713
        },
        "meteor": 0.22063232696403104,
        "bleurt": -0.12644
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.66667,
            "fmeasure": 0.63158
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "nist": 3.1221860348123966,
        "bleu": 58.59059,
        "nubia": {
            "semantic_relation": 4.91575,
            "contradiction": 0.24599,
            "irrelevancy": 0.48083,
            "logical_agreement": 99.27318,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.82283,
            "nubia_score": 0.94828
        },
        "bertscore": {
            "precision": 0.97571,
            "recall": 0.97571,
            "f1": 0.97571
        },
        "meteor": 0.47231119431689506,
        "bleurt": 0.8196
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.625,
            "3": 0.8472222222222222
        },
        "rouge1": {
            "precision": 0.77622,
            "recall": 0.81631,
            "fmeasure": 0.79241
        },
        "rouge2": {
            "precision": 0.61997,
            "recall": 0.65544,
            "fmeasure": 0.63379
        },
        "rougeL": {
            "precision": 0.68372,
            "recall": 0.70891,
            "fmeasure": 0.69307
        },
        "rougeLsum": {
            "precision": 0.68372,
            "recall": 0.70891,
            "fmeasure": 0.69307
        },
        "nist": 5.861899713327532,
        "bleu": 62.31589,
        "nubia": {
            "semantic_relation": 4.15436,
            "contradiction": 31.22037,
            "irrelevancy": 20.85545,
            "logical_agreement": 47.92418,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.33137,
            "nubia_score": 0.73256
        },
        "bertscore": {
            "precision": 0.93032,
            "recall": 0.941,
            "f1": 0.93492
        },
        "meteor": 0.4550591422010496,
        "bleurt": 0.38076
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "mT5_base/totto_test",
        "N": 14,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3013698630136986,
            "2": 0.49230769230769234,
            "3": 0.7478260869565218
        },
        "rouge1": {
            "precision": 0.6894,
            "recall": 0.66436,
            "fmeasure": 0.66322
        },
        "rouge2": {
            "precision": 0.48708,
            "recall": 0.45772,
            "fmeasure": 0.46072
        },
        "rougeL": {
            "precision": 0.57324,
            "recall": 0.56027,
            "fmeasure": 0.55483
        },
        "rougeLsum": {
            "precision": 0.57324,
            "recall": 0.56027,
            "fmeasure": 0.55483
        },
        "nist": 5.281791091789416,
        "bleu": 37.4772,
        "nubia": {
            "semantic_relation": 3.85626,
            "contradiction": 9.39288,
            "irrelevancy": 44.86446,
            "logical_agreement": 45.74266,
            "grammar_ref": 4.00042,
            "grammar_hyp": 3.92426,
            "nubia_score": 0.67929
        },
        "bertscore": {
            "precision": 0.91118,
            "recall": 0.91037,
            "f1": 0.90945
        },
        "meteor": 0.34664187647341177,
        "bleurt": 0.01182
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.5,
            "fmeasure": 0.47059
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.14286,
            "fmeasure": 0.13333
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.5,
            "fmeasure": 0.47059
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.5,
            "fmeasure": 0.47059
        },
        "nist": 1.5849625007211563,
        "bleu": 12.54931,
        "nubia": {
            "semantic_relation": 4.68911,
            "contradiction": 0.24592,
            "irrelevancy": 0.53009,
            "logical_agreement": 99.22398,
            "grammar_ref": 5.02153,
            "grammar_hyp": 5.01054,
            "nubia_score": 0.87566
        },
        "bertscore": {
            "precision": 0.90731,
            "recall": 0.92201,
            "f1": 0.9146
        },
        "meteor": 0.29433430871349564,
        "bleurt": 0.62882
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "mT5_base/totto_test",
        "N": 128,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22448979591836735,
            "2": 0.39341085271317827,
            "3": 0.7482993197278912
        },
        "rouge1": {
            "precision": 0.73867,
            "recall": 0.69208,
            "fmeasure": 0.70579
        },
        "rouge2": {
            "precision": 0.4927,
            "recall": 0.46621,
            "fmeasure": 0.47354
        },
        "rougeL": {
            "precision": 0.60847,
            "recall": 0.57784,
            "fmeasure": 0.58533
        },
        "rougeLsum": {
            "precision": 0.60847,
            "recall": 0.57784,
            "fmeasure": 0.58533
        },
        "nist": 7.736340009530037,
        "bleu": 45.83842,
        "nubia": {
            "semantic_relation": 3.75096,
            "contradiction": 15.56238,
            "irrelevancy": 30.80619,
            "logical_agreement": 53.63142,
            "grammar_ref": 4.11595,
            "grammar_hyp": 4.09267,
            "nubia_score": 0.60772
        },
        "bertscore": {
            "precision": 0.91875,
            "recall": 0.90631,
            "f1": 0.91097
        },
        "meteor": 0.37626546254168863,
        "bleurt": 0.09958
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.2222222222222222,
            "3": 0.9027777777777778
        },
        "rouge1": {
            "precision": 0.862,
            "recall": 0.85383,
            "fmeasure": 0.8531
        },
        "rouge2": {
            "precision": 0.67142,
            "recall": 0.67648,
            "fmeasure": 0.66967
        },
        "rougeL": {
            "precision": 0.7656,
            "recall": 0.77961,
            "fmeasure": 0.76535
        },
        "rougeLsum": {
            "precision": 0.7656,
            "recall": 0.77961,
            "fmeasure": 0.76535
        },
        "nist": 6.329340474347217,
        "bleu": 63.07522,
        "nubia": {
            "semantic_relation": 4.50771,
            "contradiction": 13.49364,
            "irrelevancy": 25.0048,
            "logical_agreement": 61.50155,
            "grammar_ref": 4.74863,
            "grammar_hyp": 4.81052,
            "nubia_score": 0.77315
        },
        "bertscore": {
            "precision": 0.96055,
            "recall": 0.96225,
            "f1": 0.96136
        },
        "meteor": 0.4786044923233396,
        "bleurt": 0.30323
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.6666666666666666,
            "3": 0.9574468085106383
        },
        "rouge1": {
            "precision": 0.86228,
            "recall": 0.8882,
            "fmeasure": 0.87073
        },
        "rouge2": {
            "precision": 0.7381,
            "recall": 0.75126,
            "fmeasure": 0.7422
        },
        "rougeL": {
            "precision": 0.76228,
            "recall": 0.81683,
            "fmeasure": 0.78164
        },
        "rougeLsum": {
            "precision": 0.76228,
            "recall": 0.81683,
            "fmeasure": 0.78164
        },
        "nist": 5.46694187270397,
        "bleu": 67.31407,
        "nubia": {
            "semantic_relation": 4.59334,
            "contradiction": 17.79838,
            "irrelevancy": 21.24255,
            "logical_agreement": 60.95907,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.27268,
            "nubia_score": 0.8655
        },
        "bertscore": {
            "precision": 0.97145,
            "recall": 0.97786,
            "f1": 0.97195
        },
        "meteor": 0.5450005642686826,
        "bleurt": 0.62649
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "mT5_base/totto_test",
        "N": 83,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1935483870967742,
            "2": 0.5284552845528455,
            "3": 0.7670940170940171
        },
        "rouge1": {
            "precision": 0.76225,
            "recall": 0.72248,
            "fmeasure": 0.7296
        },
        "rouge2": {
            "precision": 0.52144,
            "recall": 0.49921,
            "fmeasure": 0.50195
        },
        "rougeL": {
            "precision": 0.66362,
            "recall": 0.62631,
            "fmeasure": 0.63359
        },
        "rougeLsum": {
            "precision": 0.66362,
            "recall": 0.62631,
            "fmeasure": 0.63359
        },
        "nist": 7.52359467713937,
        "bleu": 46.66599,
        "nubia": {
            "semantic_relation": 4.27245,
            "contradiction": 8.97957,
            "irrelevancy": 28.29457,
            "logical_agreement": 62.72586,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.68592,
            "nubia_score": 0.73792
        },
        "bertscore": {
            "precision": 0.92853,
            "recall": 0.92386,
            "f1": 0.92513
        },
        "meteor": 0.3942907009457459,
        "bleurt": 0.28369
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "mT5_base/totto_test",
        "N": 12,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19642857142857142,
            "2": 0.25,
            "3": 0.6846153846153846
        },
        "rouge1": {
            "precision": 0.74701,
            "recall": 0.6119,
            "fmeasure": 0.66218
        },
        "rouge2": {
            "precision": 0.47194,
            "recall": 0.38169,
            "fmeasure": 0.41471
        },
        "rougeL": {
            "precision": 0.61357,
            "recall": 0.51424,
            "fmeasure": 0.55128
        },
        "rougeLsum": {
            "precision": 0.61357,
            "recall": 0.51424,
            "fmeasure": 0.55128
        },
        "nist": 4.358822315637781,
        "bleu": 29.09937,
        "nubia": {
            "semantic_relation": 3.85582,
            "contradiction": 4.63384,
            "irrelevancy": 32.42414,
            "logical_agreement": 62.94203,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.93729,
            "nubia_score": 0.66047
        },
        "bertscore": {
            "precision": 0.90906,
            "recall": 0.89201,
            "f1": 0.89967
        },
        "meteor": 0.319684827804272,
        "bleurt": 0.00531
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "mT5_base/totto_test",
        "N": 61,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.42081447963800905,
            "3": 0.6983298538622129
        },
        "rouge1": {
            "precision": 0.70743,
            "recall": 0.6548,
            "fmeasure": 0.66717
        },
        "rouge2": {
            "precision": 0.42134,
            "recall": 0.39873,
            "fmeasure": 0.40225
        },
        "rougeL": {
            "precision": 0.5507,
            "recall": 0.5127,
            "fmeasure": 0.51969
        },
        "rougeLsum": {
            "precision": 0.5507,
            "recall": 0.5127,
            "fmeasure": 0.51969
        },
        "nist": 6.79275098975558,
        "bleu": 38.33389,
        "nubia": {
            "semantic_relation": 3.74012,
            "contradiction": 16.89664,
            "irrelevancy": 31.11272,
            "logical_agreement": 51.99065,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.30476,
            "nubia_score": 0.60199
        },
        "bertscore": {
            "precision": 0.90839,
            "recall": 0.90117,
            "f1": 0.90326
        },
        "meteor": 0.3436630487047435,
        "bleurt": 0.0595
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.64286,
            "fmeasure": 0.53506
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.22381,
            "fmeasure": 0.17374
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.5119,
            "fmeasure": 0.41732
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.5119,
            "fmeasure": 0.41732
        },
        "nist": 3.345780565804145,
        "bleu": 14.9808,
        "nubia": {
            "semantic_relation": 3.3254,
            "contradiction": 57.76472,
            "irrelevancy": 41.63033,
            "logical_agreement": 0.60495,
            "grammar_ref": 5.89248,
            "grammar_hyp": 6.23706,
            "nubia_score": 0.31701
        },
        "bertscore": {
            "precision": 0.8836,
            "recall": 0.92504,
            "f1": 0.88857
        },
        "meteor": 0.33434522693015795,
        "bleurt": -0.36366
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "mT5_base/totto_test",
        "N": 150,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15732758620689655,
            "2": 0.4081081081081081,
            "3": 0.8203737191078964
        },
        "rouge1": {
            "precision": 0.80705,
            "recall": 0.75915,
            "fmeasure": 0.77484
        },
        "rouge2": {
            "precision": 0.56109,
            "recall": 0.52886,
            "fmeasure": 0.53845
        },
        "rougeL": {
            "precision": 0.68232,
            "recall": 0.64547,
            "fmeasure": 0.65676
        },
        "rougeLsum": {
            "precision": 0.68232,
            "recall": 0.64547,
            "fmeasure": 0.65676
        },
        "nist": 8.153386058598274,
        "bleu": 47.40572,
        "nubia": {
            "semantic_relation": 4.42887,
            "contradiction": 5.76939,
            "irrelevancy": 23.25367,
            "logical_agreement": 70.97694,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.91831,
            "nubia_score": 0.78553
        },
        "bertscore": {
            "precision": 0.94129,
            "recall": 0.93701,
            "f1": 0.93798
        },
        "meteor": 0.4139094838239643,
        "bleurt": 0.37376
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12,
            "2": 0.2727272727272727,
            "3": 0.6063829787234043
        },
        "rouge1": {
            "precision": 0.73761,
            "recall": 0.56976,
            "fmeasure": 0.63288
        },
        "rouge2": {
            "precision": 0.4311,
            "recall": 0.34882,
            "fmeasure": 0.3806
        },
        "rougeL": {
            "precision": 0.62237,
            "recall": 0.49677,
            "fmeasure": 0.54561
        },
        "rougeLsum": {
            "precision": 0.62237,
            "recall": 0.49677,
            "fmeasure": 0.54561
        },
        "nist": 3.9310521716008693,
        "bleu": 35.9169,
        "nubia": {
            "semantic_relation": 3.56074,
            "contradiction": 36.71029,
            "irrelevancy": 8.29726,
            "logical_agreement": 54.99245,
            "grammar_ref": 5.01189,
            "grammar_hyp": 5.07252,
            "nubia_score": 0.51116
        },
        "bertscore": {
            "precision": 0.92603,
            "recall": 0.89165,
            "f1": 0.90615
        },
        "meteor": 0.3384125898680824,
        "bleurt": 0.08236
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "mT5_base/totto_test",
        "N": 20,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.3939393939393939,
            "3": 0.8203883495145631
        },
        "rouge1": {
            "precision": 0.82987,
            "recall": 0.7382,
            "fmeasure": 0.77379
        },
        "rouge2": {
            "precision": 0.62453,
            "recall": 0.56098,
            "fmeasure": 0.58323
        },
        "rougeL": {
            "precision": 0.73362,
            "recall": 0.65831,
            "fmeasure": 0.6847
        },
        "rougeLsum": {
            "precision": 0.73362,
            "recall": 0.65831,
            "fmeasure": 0.6847
        },
        "nist": 6.305781805002921,
        "bleu": 52.22678,
        "nubia": {
            "semantic_relation": 4.24187,
            "contradiction": 18.57107,
            "irrelevancy": 21.93715,
            "logical_agreement": 59.49178,
            "grammar_ref": 4.67668,
            "grammar_hyp": 5.04785,
            "nubia_score": 0.68448
        },
        "bertscore": {
            "precision": 0.94517,
            "recall": 0.9275,
            "f1": 0.93447
        },
        "meteor": 0.41881986267846466,
        "bleurt": 0.32571
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "mT5_base/totto_test",
        "N": 105,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23699421965317918,
            "2": 0.34365325077399383,
            "3": 0.6838709677419355
        },
        "rouge1": {
            "precision": 0.65418,
            "recall": 0.60638,
            "fmeasure": 0.61298
        },
        "rouge2": {
            "precision": 0.40277,
            "recall": 0.38021,
            "fmeasure": 0.38174
        },
        "rougeL": {
            "precision": 0.54548,
            "recall": 0.50697,
            "fmeasure": 0.51165
        },
        "rougeLsum": {
            "precision": 0.54548,
            "recall": 0.50697,
            "fmeasure": 0.51165
        },
        "nist": 6.468332589566068,
        "bleu": 36.01537,
        "nubia": {
            "semantic_relation": 3.49736,
            "contradiction": 19.53164,
            "irrelevancy": 28.00489,
            "logical_agreement": 52.46347,
            "grammar_ref": 4.94529,
            "grammar_hyp": 4.965,
            "nubia_score": 0.58989
        },
        "bertscore": {
            "precision": 0.90162,
            "recall": 0.89505,
            "f1": 0.89703
        },
        "meteor": 0.3405952800422905,
        "bleurt": 0.0857
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "mT5_base/totto_test",
        "N": 40,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1643835616438356,
            "2": 0.4260355029585799,
            "3": 0.7236024844720497
        },
        "rouge1": {
            "precision": 0.76841,
            "recall": 0.66418,
            "fmeasure": 0.69734
        },
        "rouge2": {
            "precision": 0.50584,
            "recall": 0.43858,
            "fmeasure": 0.46068
        },
        "rougeL": {
            "precision": 0.60584,
            "recall": 0.52816,
            "fmeasure": 0.55311
        },
        "rougeLsum": {
            "precision": 0.60584,
            "recall": 0.52816,
            "fmeasure": 0.55311
        },
        "nist": 6.492872051778057,
        "bleu": 38.29228,
        "nubia": {
            "semantic_relation": 3.82261,
            "contradiction": 16.7691,
            "irrelevancy": 30.63271,
            "logical_agreement": 52.59819,
            "grammar_ref": 4.29053,
            "grammar_hyp": 4.23229,
            "nubia_score": 0.6204
        },
        "bertscore": {
            "precision": 0.92099,
            "recall": 0.90451,
            "f1": 0.91115
        },
        "meteor": 0.35288135351365413,
        "bleurt": 0.104
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.75,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.82129,
            "recall": 0.84444,
            "fmeasure": 0.81537
        },
        "rouge2": {
            "precision": 0.64006,
            "recall": 0.6713,
            "fmeasure": 0.63856
        },
        "rougeL": {
            "precision": 0.7535,
            "recall": 0.78508,
            "fmeasure": 0.75213
        },
        "rougeLsum": {
            "precision": 0.7535,
            "recall": 0.78508,
            "fmeasure": 0.75213
        },
        "nist": 5.533697621117659,
        "bleu": 55.48055,
        "nubia": {
            "semantic_relation": 4.13054,
            "contradiction": 33.33074,
            "irrelevancy": 23.05012,
            "logical_agreement": 43.61914,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.58162,
            "nubia_score": 0.65423
        },
        "bertscore": {
            "precision": 0.9502,
            "recall": 0.96049,
            "f1": 0.9534
        },
        "meteor": 0.43667844990811916,
        "bleurt": 0.36171
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.6724137931034483
        },
        "rouge1": {
            "precision": 0.83846,
            "recall": 0.73003,
            "fmeasure": 0.75407
        },
        "rouge2": {
            "precision": 0.61781,
            "recall": 0.58371,
            "fmeasure": 0.5803
        },
        "rougeL": {
            "precision": 0.71314,
            "recall": 0.66023,
            "fmeasure": 0.666
        },
        "rougeLsum": {
            "precision": 0.71314,
            "recall": 0.66023,
            "fmeasure": 0.666
        },
        "nist": 3.3233043478355797,
        "bleu": 37.53876,
        "nubia": {
            "semantic_relation": 4.26208,
            "contradiction": 0.97924,
            "irrelevancy": 38.51119,
            "logical_agreement": 60.50957,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.63042,
            "nubia_score": 0.75217
        },
        "bertscore": {
            "precision": 0.93716,
            "recall": 0.91403,
            "f1": 0.91887
        },
        "meteor": 0.354574903900768,
        "bleurt": 0.21551
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "mT5_base/totto_test",
        "N": 18,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11363636363636363,
            "2": 0.25,
            "3": 0.7473684210526316
        },
        "rouge1": {
            "precision": 0.74735,
            "recall": 0.70689,
            "fmeasure": 0.71563
        },
        "rouge2": {
            "precision": 0.53025,
            "recall": 0.48661,
            "fmeasure": 0.50258
        },
        "rougeL": {
            "precision": 0.64936,
            "recall": 0.62321,
            "fmeasure": 0.62626
        },
        "rougeLsum": {
            "precision": 0.64936,
            "recall": 0.62321,
            "fmeasure": 0.62626
        },
        "nist": 5.475322405046594,
        "bleu": 41.47127,
        "nubia": {
            "semantic_relation": 4.1015,
            "contradiction": 2.1639,
            "irrelevancy": 32.39606,
            "logical_agreement": 65.44004,
            "grammar_ref": 5.08526,
            "grammar_hyp": 5.04246,
            "nubia_score": 0.703
        },
        "bertscore": {
            "precision": 0.91799,
            "recall": 0.9147,
            "f1": 0.91501
        },
        "meteor": 0.38526756676615637,
        "bleurt": 0.29708
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.7142857142857143,
            "3": 0.7681159420289855
        },
        "rouge1": {
            "precision": 0.70334,
            "recall": 0.68792,
            "fmeasure": 0.68022
        },
        "rouge2": {
            "precision": 0.47409,
            "recall": 0.45209,
            "fmeasure": 0.45093
        },
        "rougeL": {
            "precision": 0.60331,
            "recall": 0.60305,
            "fmeasure": 0.59181
        },
        "rougeLsum": {
            "precision": 0.60331,
            "recall": 0.60305,
            "fmeasure": 0.59181
        },
        "nist": 5.2589578385101525,
        "bleu": 44.3739,
        "nubia": {
            "semantic_relation": 4.26011,
            "contradiction": 14.17119,
            "irrelevancy": 31.63327,
            "logical_agreement": 54.19555,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.46887,
            "nubia_score": 0.75348
        },
        "bertscore": {
            "precision": 0.9125,
            "recall": 0.90734,
            "f1": 0.90868
        },
        "meteor": 0.3727851903261149,
        "bleurt": 0.11593
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.69444,
            "fmeasure": 0.64286
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.32727,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.51429
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.51429
        },
        "nist": 1.6754530754585606,
        "bleu": 13.35434,
        "nubia": {
            "semantic_relation": 3.68617,
            "contradiction": 0.37648,
            "irrelevancy": 33.24476,
            "logical_agreement": 66.37875,
            "grammar_ref": 6.47099,
            "grammar_hyp": 6.62454,
            "nubia_score": 0.59197
        },
        "bertscore": {
            "precision": 0.91294,
            "recall": 0.89244,
            "f1": 0.90071
        },
        "meteor": 0.3150777603805283,
        "bleurt": 0.00083
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.5291
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "nist": 0.9472807507835431,
        "bleu": 47.87975,
        "nubia": {
            "semantic_relation": 4.92558,
            "contradiction": 0.44819,
            "irrelevancy": 0.47684,
            "logical_agreement": 99.07497,
            "grammar_ref": 3.61542,
            "grammar_hyp": 4.58816,
            "nubia_score": 0.99864
        },
        "bertscore": {
            "precision": 0.9769,
            "recall": 0.93775,
            "f1": 0.95692
        },
        "meteor": 0.4180407844493463,
        "bleurt": 0.78138
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.16666666666666666,
            "3": 0.8518518518518519
        },
        "rouge1": {
            "precision": 0.84058,
            "recall": 0.64213,
            "fmeasure": 0.67903
        },
        "rouge2": {
            "precision": 0.42677,
            "recall": 0.36533,
            "fmeasure": 0.36251
        },
        "rougeL": {
            "precision": 0.58261,
            "recall": 0.4834,
            "fmeasure": 0.49459
        },
        "rougeLsum": {
            "precision": 0.58261,
            "recall": 0.4834,
            "fmeasure": 0.49459
        },
        "nist": 3.641365882418673,
        "bleu": 24.5648,
        "nubia": {
            "semantic_relation": 4.67015,
            "contradiction": 0.90646,
            "irrelevancy": 50.34674,
            "logical_agreement": 48.7468,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.96945,
            "nubia_score": 0.84406
        },
        "bertscore": {
            "precision": 0.91745,
            "recall": 0.92588,
            "f1": 0.91866
        },
        "meteor": 0.32942625470958475,
        "bleurt": 0.14801
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "mT5_base/totto_test",
        "N": 20,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26436781609195403,
            "2": 0.3626373626373626,
            "3": 0.7048192771084337
        },
        "rouge1": {
            "precision": 0.7235,
            "recall": 0.61787,
            "fmeasure": 0.65616
        },
        "rouge2": {
            "precision": 0.43945,
            "recall": 0.38311,
            "fmeasure": 0.4003
        },
        "rougeL": {
            "precision": 0.55345,
            "recall": 0.49291,
            "fmeasure": 0.5106
        },
        "rougeLsum": {
            "precision": 0.55345,
            "recall": 0.49291,
            "fmeasure": 0.5106
        },
        "nist": 5.912591082718584,
        "bleu": 38.43673,
        "nubia": {
            "semantic_relation": 3.5706,
            "contradiction": 14.68367,
            "irrelevancy": 32.34406,
            "logical_agreement": 52.97228,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.26521,
            "nubia_score": 0.54889
        },
        "bertscore": {
            "precision": 0.91325,
            "recall": 0.90389,
            "f1": 0.90181
        },
        "meteor": 0.333983517737355,
        "bleurt": 0.03488
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.8157894736842105
        },
        "rouge1": {
            "precision": 0.80524,
            "recall": 0.66311,
            "fmeasure": 0.71834
        },
        "rouge2": {
            "precision": 0.56231,
            "recall": 0.43945,
            "fmeasure": 0.48612
        },
        "rougeL": {
            "precision": 0.71465,
            "recall": 0.60487,
            "fmeasure": 0.64249
        },
        "rougeLsum": {
            "precision": 0.71465,
            "recall": 0.60487,
            "fmeasure": 0.64249
        },
        "nist": 5.037794333675852,
        "bleu": 43.3637,
        "nubia": {
            "semantic_relation": 4.19893,
            "contradiction": 9.21276,
            "irrelevancy": 18.29908,
            "logical_agreement": 72.48816,
            "grammar_ref": 4.75129,
            "grammar_hyp": 5.10297,
            "nubia_score": 0.73162
        },
        "bertscore": {
            "precision": 0.93211,
            "recall": 0.90668,
            "f1": 0.91581
        },
        "meteor": 0.3802203708964217,
        "bleurt": 0.32642
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "mT5_base/totto_test",
        "N": 12,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.3870967741935484,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.66393,
            "recall": 0.6846,
            "fmeasure": 0.65618
        },
        "rouge2": {
            "precision": 0.42453,
            "recall": 0.45517,
            "fmeasure": 0.42582
        },
        "rougeL": {
            "precision": 0.57088,
            "recall": 0.59811,
            "fmeasure": 0.5688
        },
        "rougeLsum": {
            "precision": 0.57088,
            "recall": 0.59811,
            "fmeasure": 0.5688
        },
        "nist": 4.899459671544738,
        "bleu": 32.76316,
        "nubia": {
            "semantic_relation": 3.92533,
            "contradiction": 11.96483,
            "irrelevancy": 42.65325,
            "logical_agreement": 45.38193,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.51445,
            "nubia_score": 0.66234
        },
        "bertscore": {
            "precision": 0.90154,
            "recall": 0.90484,
            "f1": 0.8997
        },
        "meteor": 0.3492762006156631,
        "bleurt": 0.12743
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "mT5_base/totto_test",
        "N": 25,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20652173913043478,
            "2": 0.5,
            "3": 0.7813620071684588
        },
        "rouge1": {
            "precision": 0.76226,
            "recall": 0.76127,
            "fmeasure": 0.75213
        },
        "rouge2": {
            "precision": 0.54536,
            "recall": 0.54484,
            "fmeasure": 0.53728
        },
        "rougeL": {
            "precision": 0.65694,
            "recall": 0.65406,
            "fmeasure": 0.64695
        },
        "rougeLsum": {
            "precision": 0.65694,
            "recall": 0.65406,
            "fmeasure": 0.64695
        },
        "nist": 6.566812372030714,
        "bleu": 46.51872,
        "nubia": {
            "semantic_relation": 4.27034,
            "contradiction": 13.13845,
            "irrelevancy": 27.32047,
            "logical_agreement": 59.54108,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.67094,
            "nubia_score": 0.75203
        },
        "bertscore": {
            "precision": 0.92956,
            "recall": 0.93157,
            "f1": 0.92784
        },
        "meteor": 0.4043633873489841,
        "bleurt": 0.30213
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17857142857142858,
            "2": 0.44,
            "3": 0.8210526315789474
        },
        "rouge1": {
            "precision": 0.79753,
            "recall": 0.7276,
            "fmeasure": 0.74595
        },
        "rouge2": {
            "precision": 0.51056,
            "recall": 0.45675,
            "fmeasure": 0.46657
        },
        "rougeL": {
            "precision": 0.685,
            "recall": 0.61819,
            "fmeasure": 0.63512
        },
        "rougeLsum": {
            "precision": 0.685,
            "recall": 0.61819,
            "fmeasure": 0.63512
        },
        "nist": 5.489293973538376,
        "bleu": 48.35951,
        "nubia": {
            "semantic_relation": 4.29067,
            "contradiction": 1.15618,
            "irrelevancy": 32.9777,
            "logical_agreement": 65.86611,
            "grammar_ref": 4.94279,
            "grammar_hyp": 5.2779,
            "nubia_score": 0.69308
        },
        "bertscore": {
            "precision": 0.93732,
            "recall": 0.91651,
            "f1": 0.92432
        },
        "meteor": 0.3964991939330324,
        "bleurt": 0.22973
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.70955,
            "fmeasure": 0.71572
        },
        "rouge2": {
            "precision": 0.41176,
            "recall": 0.40414,
            "fmeasure": 0.40784
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.49123,
            "fmeasure": 0.4955
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.49123,
            "fmeasure": 0.4955
        },
        "nist": 2.236571491553526,
        "bleu": 18.00283,
        "nubia": {
            "semantic_relation": 4.90221,
            "contradiction": 0.1687,
            "irrelevancy": 30.05371,
            "logical_agreement": 69.7776,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.76715,
            "nubia_score": 0.91449
        },
        "bertscore": {
            "precision": 0.89727,
            "recall": 0.90304,
            "f1": 0.89928
        },
        "meteor": 0.3385800653634677,
        "bleurt": 0.4316
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.35294117647058826
        },
        "rouge1": {
            "precision": 0.54167,
            "recall": 0.32479,
            "fmeasure": 0.40605
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.12,
            "fmeasure": 0.15
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.30769,
            "fmeasure": 0.38095
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.30769,
            "fmeasure": 0.38095
        },
        "nist": 0.6032441344656199,
        "bleu": 10.35505,
        "nubia": {
            "semantic_relation": 1.85494,
            "contradiction": 93.7596,
            "irrelevancy": 3.4598,
            "logical_agreement": 2.7806,
            "grammar_ref": 4.71547,
            "grammar_hyp": 4.507,
            "nubia_score": 0.11005
        },
        "bertscore": {
            "precision": 0.8081,
            "recall": 0.77724,
            "f1": 0.79237
        },
        "meteor": 0.18818731946379322,
        "bleurt": -1.06218
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "mT5_base/totto_test",
        "N": 103,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20121951219512196,
            "2": 0.4511784511784512,
            "3": 0.7882562277580071
        },
        "rouge1": {
            "precision": 0.76883,
            "recall": 0.7344,
            "fmeasure": 0.73827
        },
        "rouge2": {
            "precision": 0.53787,
            "recall": 0.5159,
            "fmeasure": 0.51765
        },
        "rougeL": {
            "precision": 0.66782,
            "recall": 0.64038,
            "fmeasure": 0.64272
        },
        "rougeLsum": {
            "precision": 0.66782,
            "recall": 0.64038,
            "fmeasure": 0.64272
        },
        "nist": 7.738856503912793,
        "bleu": 48.14011,
        "nubia": {
            "semantic_relation": 4.23494,
            "contradiction": 9.24555,
            "irrelevancy": 28.53543,
            "logical_agreement": 62.21902,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.62071,
            "nubia_score": 0.73969
        },
        "bertscore": {
            "precision": 0.93272,
            "recall": 0.92729,
            "f1": 0.92889
        },
        "meteor": 0.40395392321039875,
        "bleurt": 0.2757
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.7096774193548387,
            "3": 0.691358024691358
        },
        "rouge1": {
            "precision": 0.81752,
            "recall": 0.68341,
            "fmeasure": 0.74022
        },
        "rouge2": {
            "precision": 0.55322,
            "recall": 0.45219,
            "fmeasure": 0.49414
        },
        "rougeL": {
            "precision": 0.71775,
            "recall": 0.5992,
            "fmeasure": 0.64914
        },
        "rougeLsum": {
            "precision": 0.71775,
            "recall": 0.5992,
            "fmeasure": 0.64914
        },
        "nist": 5.08880629817371,
        "bleu": 43.18773,
        "nubia": {
            "semantic_relation": 4.38038,
            "contradiction": 2.89583,
            "irrelevancy": 15.11906,
            "logical_agreement": 81.9851,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.83941,
            "nubia_score": 0.76123
        },
        "bertscore": {
            "precision": 0.92604,
            "recall": 0.89411,
            "f1": 0.9081
        },
        "meteor": 0.3771746415010615,
        "bleurt": 0.21451
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 0.7021276595744681
        },
        "rouge1": {
            "precision": 0.93081,
            "recall": 0.78166,
            "fmeasure": 0.82978
        },
        "rouge2": {
            "precision": 0.82535,
            "recall": 0.71228,
            "fmeasure": 0.74826
        },
        "rougeL": {
            "precision": 0.93081,
            "recall": 0.78166,
            "fmeasure": 0.82978
        },
        "rougeLsum": {
            "precision": 0.93081,
            "recall": 0.78166,
            "fmeasure": 0.82978
        },
        "nist": 3.9482620842084426,
        "bleu": 53.96667,
        "nubia": {
            "semantic_relation": 4.46525,
            "contradiction": 0.47032,
            "irrelevancy": 4.85352,
            "logical_agreement": 94.67616,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.99952,
            "nubia_score": 0.81358
        },
        "bertscore": {
            "precision": 0.97982,
            "recall": 0.93532,
            "f1": 0.95567
        },
        "meteor": 0.44394663537057205,
        "bleurt": 0.58904
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.7692307692307693,
            "3": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.79438,
            "recall": 0.82264,
            "fmeasure": 0.7984
        },
        "rouge2": {
            "precision": 0.54207,
            "recall": 0.5754,
            "fmeasure": 0.55019
        },
        "rougeL": {
            "precision": 0.73634,
            "recall": 0.77172,
            "fmeasure": 0.74415
        },
        "rougeLsum": {
            "precision": 0.73634,
            "recall": 0.77172,
            "fmeasure": 0.74415
        },
        "nist": 4.900141279502296,
        "bleu": 58.34553,
        "nubia": {
            "semantic_relation": 4.54086,
            "contradiction": 3.34193,
            "irrelevancy": 20.16508,
            "logical_agreement": 76.49299,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.57376,
            "nubia_score": 0.76206
        },
        "bertscore": {
            "precision": 0.94992,
            "recall": 0.95385,
            "f1": 0.95134
        },
        "meteor": 0.45576405099585515,
        "bleurt": 0.42844
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "mT5_base/totto_test",
        "N": 20,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17567567567567569,
            "2": 0.5538461538461539,
            "3": 0.868421052631579
        },
        "rouge1": {
            "precision": 0.7962,
            "recall": 0.81862,
            "fmeasure": 0.80092
        },
        "rouge2": {
            "precision": 0.6339,
            "recall": 0.66031,
            "fmeasure": 0.63986
        },
        "rougeL": {
            "precision": 0.70653,
            "recall": 0.71953,
            "fmeasure": 0.70771
        },
        "rougeLsum": {
            "precision": 0.70653,
            "recall": 0.71953,
            "fmeasure": 0.70771
        },
        "nist": 6.481671273987398,
        "bleu": 56.28555,
        "nubia": {
            "semantic_relation": 4.21075,
            "contradiction": 14.07019,
            "irrelevancy": 23.90263,
            "logical_agreement": 62.02718,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.40265,
            "nubia_score": 0.73375
        },
        "bertscore": {
            "precision": 0.9465,
            "recall": 0.94438,
            "f1": 0.94487
        },
        "meteor": 0.4546437127264729,
        "bleurt": 0.38039
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.35714285714285715,
            "3": 0.7419354838709677
        },
        "rouge1": {
            "precision": 0.82242,
            "recall": 0.69147,
            "fmeasure": 0.73964
        },
        "rouge2": {
            "precision": 0.60215,
            "recall": 0.50608,
            "fmeasure": 0.53985
        },
        "rougeL": {
            "precision": 0.77381,
            "recall": 0.65253,
            "fmeasure": 0.69675
        },
        "rougeLsum": {
            "precision": 0.77381,
            "recall": 0.65253,
            "fmeasure": 0.69675
        },
        "nist": 3.245397826109223,
        "bleu": 37.75848,
        "nubia": {
            "semantic_relation": 4.35706,
            "contradiction": 0.45372,
            "irrelevancy": 22.88954,
            "logical_agreement": 76.65673,
            "grammar_ref": 4.09757,
            "grammar_hyp": 3.98028,
            "nubia_score": 0.88773
        },
        "bertscore": {
            "precision": 0.94023,
            "recall": 0.92234,
            "f1": 0.93083
        },
        "meteor": 0.3582111589636288,
        "bleurt": 0.37748
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "mT5_base/totto_test",
        "N": 26,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18333333333333332,
            "2": 0.31932773109243695,
            "3": 0.7665198237885462
        },
        "rouge1": {
            "precision": 0.73537,
            "recall": 0.6708,
            "fmeasure": 0.68573
        },
        "rouge2": {
            "precision": 0.45362,
            "recall": 0.4108,
            "fmeasure": 0.42093
        },
        "rougeL": {
            "precision": 0.57424,
            "recall": 0.51347,
            "fmeasure": 0.52921
        },
        "rougeLsum": {
            "precision": 0.57424,
            "recall": 0.51347,
            "fmeasure": 0.52921
        },
        "nist": 6.603522487367037,
        "bleu": 38.36239,
        "nubia": {
            "semantic_relation": 3.73654,
            "contradiction": 18.31846,
            "irrelevancy": 21.8989,
            "logical_agreement": 59.78264,
            "grammar_ref": 4.04917,
            "grammar_hyp": 3.84874,
            "nubia_score": 0.61022
        },
        "bertscore": {
            "precision": 0.91878,
            "recall": 0.90253,
            "f1": 0.90855
        },
        "meteor": 0.3509212098440524,
        "bleurt": 0.09496
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.1986532337201607,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.99035
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.16666666666666666,
            "3": 0.55
        },
        "rouge1": {
            "precision": 0.70681,
            "recall": 0.50881,
            "fmeasure": 0.58489
        },
        "rouge2": {
            "precision": 0.42917,
            "recall": 0.30347,
            "fmeasure": 0.34839
        },
        "rougeL": {
            "precision": 0.61386,
            "recall": 0.44863,
            "fmeasure": 0.50998
        },
        "rougeLsum": {
            "precision": 0.61386,
            "recall": 0.44863,
            "fmeasure": 0.50998
        },
        "nist": 2.5521008235425935,
        "bleu": 19.84938,
        "nubia": {
            "semantic_relation": 3.84868,
            "contradiction": 6.43202,
            "irrelevancy": 23.99441,
            "logical_agreement": 69.57357,
            "grammar_ref": 4.84918,
            "grammar_hyp": 5.75907,
            "nubia_score": 0.53185
        },
        "bertscore": {
            "precision": 0.92773,
            "recall": 0.88787,
            "f1": 0.90723
        },
        "meteor": 0.2649820018645292,
        "bleurt": -0.01132
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "mT5_base/totto_test",
        "N": 10,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0958904109589041,
            "2": 0.3050847457627119,
            "3": 0.7123287671232876
        },
        "rouge1": {
            "precision": 0.65013,
            "recall": 0.63829,
            "fmeasure": 0.63552
        },
        "rouge2": {
            "precision": 0.38243,
            "recall": 0.39079,
            "fmeasure": 0.38185
        },
        "rougeL": {
            "precision": 0.48365,
            "recall": 0.47738,
            "fmeasure": 0.47415
        },
        "rougeLsum": {
            "precision": 0.48365,
            "recall": 0.47738,
            "fmeasure": 0.47415
        },
        "nist": 5.0443248408832275,
        "bleu": 38.20376,
        "nubia": {
            "semantic_relation": 3.3063,
            "contradiction": 34.49634,
            "irrelevancy": 20.82994,
            "logical_agreement": 44.67372,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.59062,
            "nubia_score": 0.49149
        },
        "bertscore": {
            "precision": 0.90949,
            "recall": 0.88811,
            "f1": 0.8964
        },
        "meteor": 0.3259430635665317,
        "bleurt": -0.10706
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "mT5_base/totto_test",
        "N": 9,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22641509433962265,
            "2": 0.3469387755102041,
            "3": 0.6901408450704225
        },
        "rouge1": {
            "precision": 0.55365,
            "recall": 0.58039,
            "fmeasure": 0.55079
        },
        "rouge2": {
            "precision": 0.25743,
            "recall": 0.28852,
            "fmeasure": 0.26306
        },
        "rougeL": {
            "precision": 0.45046,
            "recall": 0.47363,
            "fmeasure": 0.44737
        },
        "rougeLsum": {
            "precision": 0.45046,
            "recall": 0.47363,
            "fmeasure": 0.44737
        },
        "nist": 3.730589074959855,
        "bleu": 24.88433,
        "nubia": {
            "semantic_relation": 3.57472,
            "contradiction": 11.78541,
            "irrelevancy": 37.11822,
            "logical_agreement": 51.09637,
            "grammar_ref": 4.84583,
            "grammar_hyp": 4.90513,
            "nubia_score": 0.56589
        },
        "bertscore": {
            "precision": 0.86887,
            "recall": 0.8846,
            "f1": 0.87211
        },
        "meteor": 0.2838363964453749,
        "bleurt": 0.02286
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "mT5_base/totto_test",
        "N": 80,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.211864406779661,
            "2": 0.3755868544600939,
            "3": 0.7280799112097669
        },
        "rouge1": {
            "precision": 0.75679,
            "recall": 0.6849,
            "fmeasure": 0.70649
        },
        "rouge2": {
            "precision": 0.49054,
            "recall": 0.44035,
            "fmeasure": 0.45494
        },
        "rougeL": {
            "precision": 0.64557,
            "recall": 0.58152,
            "fmeasure": 0.5999
        },
        "rougeLsum": {
            "precision": 0.64557,
            "recall": 0.58152,
            "fmeasure": 0.5999
        },
        "nist": 6.950483747280084,
        "bleu": 40.09898,
        "nubia": {
            "semantic_relation": 4.16467,
            "contradiction": 8.78786,
            "irrelevancy": 29.3337,
            "logical_agreement": 61.87844,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.93037,
            "nubia_score": 0.69888
        },
        "bertscore": {
            "precision": 0.92226,
            "recall": 0.91294,
            "f1": 0.91559
        },
        "meteor": 0.3616201167379255,
        "bleurt": 0.22728
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.2,
            "3": 0.9310344827586207
        },
        "rouge1": {
            "precision": 0.88201,
            "recall": 0.89523,
            "fmeasure": 0.88811
        },
        "rouge2": {
            "precision": 0.7735,
            "recall": 0.78283,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 0.77151,
            "recall": 0.78341,
            "fmeasure": 0.777
        },
        "rougeLsum": {
            "precision": 0.77151,
            "recall": 0.78341,
            "fmeasure": 0.777
        },
        "nist": 4.7740761818688995,
        "bleu": 67.45643,
        "nubia": {
            "semantic_relation": 4.64521,
            "contradiction": 0.23648,
            "irrelevancy": 22.51553,
            "logical_agreement": 77.24798,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.48709,
            "nubia_score": 0.85291
        },
        "bertscore": {
            "precision": 0.96633,
            "recall": 0.97756,
            "f1": 0.97184
        },
        "meteor": 0.5482935696116095,
        "bleurt": 0.46059
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.875
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.71717,
            "fmeasure": 0.78638
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "nist": 3.7642741174382337,
        "bleu": 81.76129,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.96713,
            "irrelevancy": 0.64693,
            "logical_agreement": 98.38594,
            "grammar_ref": 4.59758,
            "grammar_hyp": 4.52299,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.97871,
            "recall": 0.94782,
            "f1": 0.96301
        },
        "meteor": 0.5064321156600579,
        "bleurt": 0.69712
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.80809,
            "recall": 0.77091,
            "fmeasure": 0.77512
        },
        "rouge2": {
            "precision": 0.61296,
            "recall": 0.55896,
            "fmeasure": 0.57063
        },
        "rougeL": {
            "precision": 0.69896,
            "recall": 0.6656,
            "fmeasure": 0.66781
        },
        "rougeLsum": {
            "precision": 0.69896,
            "recall": 0.6656,
            "fmeasure": 0.66781
        },
        "nist": 4.4914506751455585,
        "bleu": 49.35567,
        "nubia": {
            "semantic_relation": 4.61272,
            "contradiction": 1.09098,
            "irrelevancy": 8.76889,
            "logical_agreement": 90.14013,
            "grammar_ref": 5.35172,
            "grammar_hyp": 5.48234,
            "nubia_score": 0.77835
        },
        "bertscore": {
            "precision": 0.95151,
            "recall": 0.9429,
            "f1": 0.94699
        },
        "meteor": 0.46115100331062164,
        "bleurt": 0.31493
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "mT5_base/totto_test",
        "N": 16,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18518518518518517,
            "2": 0.34146341463414637,
            "3": 0.8378378378378378
        },
        "rouge1": {
            "precision": 0.80854,
            "recall": 0.78898,
            "fmeasure": 0.79078
        },
        "rouge2": {
            "precision": 0.57437,
            "recall": 0.57709,
            "fmeasure": 0.57019
        },
        "rougeL": {
            "precision": 0.72343,
            "recall": 0.70638,
            "fmeasure": 0.70745
        },
        "rougeLsum": {
            "precision": 0.72343,
            "recall": 0.70638,
            "fmeasure": 0.70745
        },
        "nist": 6.767895712068214,
        "bleu": 54.8673,
        "nubia": {
            "semantic_relation": 4.38495,
            "contradiction": 0.59111,
            "irrelevancy": 24.22141,
            "logical_agreement": 75.18749,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.44682,
            "nubia_score": 0.79713
        },
        "bertscore": {
            "precision": 0.95393,
            "recall": 0.95433,
            "f1": 0.9521
        },
        "meteor": 0.4387812349826869,
        "bleurt": 0.46552
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.2,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.85873,
            "recall": 0.78564,
            "fmeasure": 0.81375
        },
        "rouge2": {
            "precision": 0.58062,
            "recall": 0.50536,
            "fmeasure": 0.53484
        },
        "rougeL": {
            "precision": 0.69399,
            "recall": 0.64431,
            "fmeasure": 0.66324
        },
        "rougeLsum": {
            "precision": 0.69399,
            "recall": 0.64431,
            "fmeasure": 0.66324
        },
        "nist": 5.515368732437041,
        "bleu": 43.20039,
        "nubia": {
            "semantic_relation": 4.37816,
            "contradiction": 11.58687,
            "irrelevancy": 17.67396,
            "logical_agreement": 70.73917,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.98596,
            "nubia_score": 0.75591
        },
        "bertscore": {
            "precision": 0.94806,
            "recall": 0.93757,
            "f1": 0.94017
        },
        "meteor": 0.42973842042019234,
        "bleurt": 0.41732
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "mT5_base/totto_test",
        "N": 19,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16176470588235295,
            "2": 0.3516483516483517,
            "3": 0.7283236994219653
        },
        "rouge1": {
            "precision": 0.67277,
            "recall": 0.63909,
            "fmeasure": 0.64044
        },
        "rouge2": {
            "precision": 0.39703,
            "recall": 0.38422,
            "fmeasure": 0.37963
        },
        "rougeL": {
            "precision": 0.55137,
            "recall": 0.53873,
            "fmeasure": 0.52918
        },
        "rougeLsum": {
            "precision": 0.55137,
            "recall": 0.53873,
            "fmeasure": 0.52918
        },
        "nist": 4.901376692484856,
        "bleu": 33.77752,
        "nubia": {
            "semantic_relation": 3.84474,
            "contradiction": 17.30672,
            "irrelevancy": 33.57162,
            "logical_agreement": 49.12166,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.65267,
            "nubia_score": 0.61232
        },
        "bertscore": {
            "precision": 0.88556,
            "recall": 0.89439,
            "f1": 0.88725
        },
        "meteor": 0.3193604275085715,
        "bleurt": 0.09673
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.62912,
            "recall": 0.55144,
            "fmeasure": 0.57959
        },
        "rouge2": {
            "precision": 0.35185,
            "recall": 0.30647,
            "fmeasure": 0.32264
        },
        "rougeL": {
            "precision": 0.55769,
            "recall": 0.50241,
            "fmeasure": 0.52152
        },
        "rougeLsum": {
            "precision": 0.55769,
            "recall": 0.50241,
            "fmeasure": 0.52152
        },
        "nist": 3.5414901096479436,
        "bleu": 34.91584,
        "nubia": {
            "semantic_relation": 3.37451,
            "contradiction": 29.91655,
            "irrelevancy": 49.04548,
            "logical_agreement": 21.03798,
            "grammar_ref": 4.45404,
            "grammar_hyp": 4.35289,
            "nubia_score": 0.39969
        },
        "bertscore": {
            "precision": 0.92726,
            "recall": 0.89947,
            "f1": 0.91239
        },
        "meteor": 0.27772475449527756,
        "bleurt": -0.01914
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.09090909090909091,
            "3": 0.8611111111111112
        },
        "rouge1": {
            "precision": 0.66109,
            "recall": 0.71724,
            "fmeasure": 0.68457
        },
        "rouge2": {
            "precision": 0.42712,
            "recall": 0.44771,
            "fmeasure": 0.43667
        },
        "rougeL": {
            "precision": 0.52559,
            "recall": 0.57804,
            "fmeasure": 0.54804
        },
        "rougeLsum": {
            "precision": 0.52559,
            "recall": 0.57804,
            "fmeasure": 0.54804
        },
        "nist": 4.045201368207636,
        "bleu": 32.61208,
        "nubia": {
            "semantic_relation": 4.37771,
            "contradiction": 0.52527,
            "irrelevancy": 32.02407,
            "logical_agreement": 67.45066,
            "grammar_ref": 5.27719,
            "grammar_hyp": 4.84054,
            "nubia_score": 0.80044
        },
        "bertscore": {
            "precision": 0.91231,
            "recall": 0.93449,
            "f1": 0.9227
        },
        "meteor": 0.4086046247904671,
        "bleurt": 0.1326
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.81237,
            "recall": 0.79225,
            "fmeasure": 0.79595
        },
        "rouge2": {
            "precision": 0.54397,
            "recall": 0.53308,
            "fmeasure": 0.53368
        },
        "rougeL": {
            "precision": 0.64167,
            "recall": 0.64174,
            "fmeasure": 0.63664
        },
        "rougeLsum": {
            "precision": 0.64167,
            "recall": 0.64174,
            "fmeasure": 0.63664
        },
        "nist": 5.062463314934435,
        "bleu": 40.48222,
        "nubia": {
            "semantic_relation": 4.51988,
            "contradiction": 2.43674,
            "irrelevancy": 33.55912,
            "logical_agreement": 64.00414,
            "grammar_ref": 5.40206,
            "grammar_hyp": 4.99746,
            "nubia_score": 0.84643
        },
        "bertscore": {
            "precision": 0.93969,
            "recall": 0.93756,
            "f1": 0.93619
        },
        "meteor": 0.428497231541953,
        "bleurt": 0.35426
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.83611,
            "recall": 0.97037,
            "fmeasure": 0.89206
        },
        "rouge2": {
            "precision": 0.72981,
            "recall": 0.81334,
            "fmeasure": 0.76562
        },
        "rougeL": {
            "precision": 0.80139,
            "recall": 0.89825,
            "fmeasure": 0.84326
        },
        "rougeLsum": {
            "precision": 0.80139,
            "recall": 0.89825,
            "fmeasure": 0.84326
        },
        "nist": 5.2238662286434945,
        "bleu": 62.73171,
        "nubia": {
            "semantic_relation": 4.88715,
            "contradiction": 0.28201,
            "irrelevancy": 38.23619,
            "logical_agreement": 61.48179,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.68858,
            "nubia_score": 0.9215
        },
        "bertscore": {
            "precision": 0.9605,
            "recall": 0.97847,
            "f1": 0.96931
        },
        "meteor": 0.5403511114019082,
        "bleurt": 0.65605
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "mT5_base/totto_test",
        "N": 14,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14705882352941177,
            "2": 0.46875,
            "3": 0.9102564102564102
        },
        "rouge1": {
            "precision": 0.84611,
            "recall": 0.83104,
            "fmeasure": 0.83513
        },
        "rouge2": {
            "precision": 0.69829,
            "recall": 0.68313,
            "fmeasure": 0.688
        },
        "rougeL": {
            "precision": 0.73935,
            "recall": 0.72337,
            "fmeasure": 0.72851
        },
        "rougeLsum": {
            "precision": 0.73935,
            "recall": 0.72337,
            "fmeasure": 0.72851
        },
        "nist": 6.499887246395436,
        "bleu": 65.38043,
        "nubia": {
            "semantic_relation": 4.3282,
            "contradiction": 7.74591,
            "irrelevancy": 18.18061,
            "logical_agreement": 74.07348,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.96514,
            "nubia_score": 0.75737
        },
        "bertscore": {
            "precision": 0.95254,
            "recall": 0.94085,
            "f1": 0.94637
        },
        "meteor": 0.47143488197830696,
        "bleurt": 0.48639
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6176470588235294
        },
        "rouge1": {
            "precision": 0.7703,
            "recall": 0.67143,
            "fmeasure": 0.71654
        },
        "rouge2": {
            "precision": 0.48758,
            "recall": 0.42199,
            "fmeasure": 0.45167
        },
        "rougeL": {
            "precision": 0.5203,
            "recall": 0.46898,
            "fmeasure": 0.49237
        },
        "rougeLsum": {
            "precision": 0.5203,
            "recall": 0.46898,
            "fmeasure": 0.49237
        },
        "nist": 3.3295796440105763,
        "bleu": 17.21855,
        "nubia": {
            "semantic_relation": 4.49293,
            "contradiction": 0.29167,
            "irrelevancy": 33.51906,
            "logical_agreement": 66.18927,
            "grammar_ref": 4.67072,
            "grammar_hyp": 4.54422,
            "nubia_score": 0.86786
        },
        "bertscore": {
            "precision": 0.89316,
            "recall": 0.91459,
            "f1": 0.90355
        },
        "meteor": 0.317275770200656,
        "bleurt": 0.33534
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08,
            "2": 0.8125,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.71042,
            "recall": 0.69916,
            "fmeasure": 0.69618
        },
        "rouge2": {
            "precision": 0.45815,
            "recall": 0.47242,
            "fmeasure": 0.4585
        },
        "rougeL": {
            "precision": 0.62361,
            "recall": 0.64167,
            "fmeasure": 0.6256
        },
        "rougeLsum": {
            "precision": 0.62361,
            "recall": 0.64167,
            "fmeasure": 0.6256
        },
        "nist": 3.86325198228229,
        "bleu": 40.26295,
        "nubia": {
            "semantic_relation": 3.72593,
            "contradiction": 25.27031,
            "irrelevancy": 32.49251,
            "logical_agreement": 42.23718,
            "grammar_ref": 4.75156,
            "grammar_hyp": 4.92894,
            "nubia_score": 0.55207
        },
        "bertscore": {
            "precision": 0.9104,
            "recall": 0.9034,
            "f1": 0.9035
        },
        "meteor": 0.3673573632273267,
        "bleurt": 0.22134
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.75,
            "3": 0.4166666666666667
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.58333,
            "fmeasure": 0.62222
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.43478,
            "fmeasure": 0.46512
        },
        "rougeL": {
            "precision": 0.31746,
            "recall": 0.44444,
            "fmeasure": 0.36094
        },
        "rougeLsum": {
            "precision": 0.31746,
            "recall": 0.44444,
            "fmeasure": 0.36094
        },
        "nist": 2.9664073550026804,
        "bleu": 29.34951,
        "nubia": {
            "semantic_relation": 3.12763,
            "contradiction": 99.39069,
            "irrelevancy": 0.46838,
            "logical_agreement": 0.14093,
            "grammar_ref": 4.791,
            "grammar_hyp": 4.88871,
            "nubia_score": 0.41109
        },
        "bertscore": {
            "precision": 0.86071,
            "recall": 0.83716,
            "f1": 0.84878
        },
        "meteor": 0.276320211602005,
        "bleurt": -0.40217
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "mT5_base/totto_test",
        "N": 17,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.4,
            "3": 0.6775956284153005
        },
        "rouge1": {
            "precision": 0.75196,
            "recall": 0.68485,
            "fmeasure": 0.70193
        },
        "rouge2": {
            "precision": 0.54128,
            "recall": 0.49474,
            "fmeasure": 0.50543
        },
        "rougeL": {
            "precision": 0.67573,
            "recall": 0.61595,
            "fmeasure": 0.63011
        },
        "rougeLsum": {
            "precision": 0.67573,
            "recall": 0.61595,
            "fmeasure": 0.63011
        },
        "nist": 5.570236867468885,
        "bleu": 42.74408,
        "nubia": {
            "semantic_relation": 3.97866,
            "contradiction": 4.0445,
            "irrelevancy": 32.24953,
            "logical_agreement": 63.70597,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.23583,
            "nubia_score": 0.68535
        },
        "bertscore": {
            "precision": 0.92747,
            "recall": 0.91997,
            "f1": 0.92114
        },
        "meteor": 0.3655180376620646,
        "bleurt": 0.18974
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2962962962962963,
            "2": 0.4,
            "3": 0.7435897435897436
        },
        "rouge1": {
            "precision": 0.61273,
            "recall": 0.72826,
            "fmeasure": 0.65425
        },
        "rouge2": {
            "precision": 0.39309,
            "recall": 0.47367,
            "fmeasure": 0.42179
        },
        "rougeL": {
            "precision": 0.54306,
            "recall": 0.65059,
            "fmeasure": 0.5838
        },
        "rougeLsum": {
            "precision": 0.54306,
            "recall": 0.65059,
            "fmeasure": 0.5838
        },
        "nist": 4.6810915400173805,
        "bleu": 43.94593,
        "nubia": {
            "semantic_relation": 3.9388,
            "contradiction": 1.25477,
            "irrelevancy": 38.37097,
            "logical_agreement": 60.37426,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.35992,
            "nubia_score": 0.67843
        },
        "bertscore": {
            "precision": 0.92452,
            "recall": 0.92079,
            "f1": 0.91559
        },
        "meteor": 0.38960381002028305,
        "bleurt": 0.16317
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "mT5_base/totto_test",
        "N": 64,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19658119658119658,
            "2": 0.3832599118942731,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.75853,
            "recall": 0.68027,
            "fmeasure": 0.70738
        },
        "rouge2": {
            "precision": 0.48723,
            "recall": 0.44776,
            "fmeasure": 0.46042
        },
        "rougeL": {
            "precision": 0.63716,
            "recall": 0.57984,
            "fmeasure": 0.59919
        },
        "rougeLsum": {
            "precision": 0.63716,
            "recall": 0.57984,
            "fmeasure": 0.59919
        },
        "nist": 6.6042160207882015,
        "bleu": 40.78625,
        "nubia": {
            "semantic_relation": 4.1244,
            "contradiction": 9.76735,
            "irrelevancy": 29.24415,
            "logical_agreement": 60.9885,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.73769,
            "nubia_score": 0.69204
        },
        "bertscore": {
            "precision": 0.92726,
            "recall": 0.9108,
            "f1": 0.9173
        },
        "meteor": 0.3618118620203407,
        "bleurt": 0.21997
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "mT5_base/totto_test",
        "N": 14,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5072463768115942,
            "3": 0.6694915254237288
        },
        "rouge1": {
            "precision": 0.67462,
            "recall": 0.63757,
            "fmeasure": 0.63017
        },
        "rouge2": {
            "precision": 0.41678,
            "recall": 0.39677,
            "fmeasure": 0.39125
        },
        "rougeL": {
            "precision": 0.57288,
            "recall": 0.54504,
            "fmeasure": 0.53961
        },
        "rougeLsum": {
            "precision": 0.57288,
            "recall": 0.54504,
            "fmeasure": 0.53961
        },
        "nist": 5.472398767987811,
        "bleu": 38.24933,
        "nubia": {
            "semantic_relation": 3.62327,
            "contradiction": 21.35786,
            "irrelevancy": 21.55665,
            "logical_agreement": 57.08549,
            "grammar_ref": 4.37064,
            "grammar_hyp": 4.19112,
            "nubia_score": 0.54
        },
        "bertscore": {
            "precision": 0.90256,
            "recall": 0.88094,
            "f1": 0.89067
        },
        "meteor": 0.33314859615838904,
        "bleurt": 0.0625
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5333333333333333
        },
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.52381,
            "fmeasure": 0.5641
        },
        "rouge2": {
            "precision": 0.41176,
            "recall": 0.34444,
            "fmeasure": 0.37506
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.37518,
            "fmeasure": 0.40684
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.37518,
            "fmeasure": 0.40684
        },
        "nist": 2.3387032976000732,
        "bleu": 21.91608,
        "nubia": {
            "semantic_relation": 3.04559,
            "contradiction": 95.71614,
            "irrelevancy": 3.8703,
            "logical_agreement": 0.41355,
            "grammar_ref": 3.42286,
            "grammar_hyp": 4.44378,
            "nubia_score": 0.32356
        },
        "bertscore": {
            "precision": 0.89605,
            "recall": 0.86221,
            "f1": 0.8788
        },
        "meteor": 0.3171792239195699,
        "bleurt": -0.14776
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9411764705882353
        },
        "rouge1": {
            "precision": 0.79808,
            "recall": 0.73523,
            "fmeasure": 0.76426
        },
        "rouge2": {
            "precision": 0.39087,
            "recall": 0.37215,
            "fmeasure": 0.38083
        },
        "rougeL": {
            "precision": 0.76442,
            "recall": 0.67551,
            "fmeasure": 0.71407
        },
        "rougeLsum": {
            "precision": 0.76442,
            "recall": 0.67551,
            "fmeasure": 0.71407
        },
        "nist": 4.142613303363993,
        "bleu": 38.80411,
        "nubia": {
            "semantic_relation": 4.41542,
            "contradiction": 0.95998,
            "irrelevancy": 0.88682,
            "logical_agreement": 98.1532,
            "grammar_ref": 5.06568,
            "grammar_hyp": 4.93357,
            "nubia_score": 0.81743
        },
        "bertscore": {
            "precision": 0.94143,
            "recall": 0.92446,
            "f1": 0.92954
        },
        "meteor": 0.38202846624701997,
        "bleurt": 0.37049
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.16666666666666666,
            "3": 0.8791208791208791
        },
        "rouge1": {
            "precision": 0.9278,
            "recall": 0.8703,
            "fmeasure": 0.89467
        },
        "rouge2": {
            "precision": 0.75241,
            "recall": 0.71143,
            "fmeasure": 0.72872
        },
        "rougeL": {
            "precision": 0.76697,
            "recall": 0.71569,
            "fmeasure": 0.73816
        },
        "rougeLsum": {
            "precision": 0.76697,
            "recall": 0.71569,
            "fmeasure": 0.73816
        },
        "nist": 6.2428992564840255,
        "bleu": 67.47558,
        "nubia": {
            "semantic_relation": 4.70795,
            "contradiction": 3.21755,
            "irrelevancy": 4.02534,
            "logical_agreement": 92.75711,
            "grammar_ref": 4.9924,
            "grammar_hyp": 5.28077,
            "nubia_score": 0.85065
        },
        "bertscore": {
            "precision": 0.97918,
            "recall": 0.96988,
            "f1": 0.97442
        },
        "meteor": 0.4725474756973067,
        "bleurt": 0.57847
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.59499,
            "fmeasure": 0.58855
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.375,
            "fmeasure": 0.36888
        },
        "rougeL": {
            "precision": 0.51389,
            "recall": 0.52622,
            "fmeasure": 0.51957
        },
        "rougeLsum": {
            "precision": 0.51389,
            "recall": 0.52622,
            "fmeasure": 0.51957
        },
        "nist": 2.465401826553514,
        "bleu": 15.61791,
        "nubia": {
            "semantic_relation": 4.08398,
            "contradiction": 28.07789,
            "irrelevancy": 22.72045,
            "logical_agreement": 49.20166,
            "grammar_ref": 3.96214,
            "grammar_hyp": 5.23415,
            "nubia_score": 0.5249
        },
        "bertscore": {
            "precision": 0.88244,
            "recall": 0.87994,
            "f1": 0.8803
        },
        "meteor": 0.36445271510637184,
        "bleurt": 0.2971
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21739130434782608,
            "2": 0.2692307692307692,
            "3": 0.7788461538461539
        },
        "rouge1": {
            "precision": 0.79492,
            "recall": 0.69036,
            "fmeasure": 0.73219
        },
        "rouge2": {
            "precision": 0.52552,
            "recall": 0.45846,
            "fmeasure": 0.48493
        },
        "rougeL": {
            "precision": 0.59005,
            "recall": 0.50841,
            "fmeasure": 0.54109
        },
        "rougeLsum": {
            "precision": 0.59005,
            "recall": 0.50841,
            "fmeasure": 0.54109
        },
        "nist": 4.474343376405112,
        "bleu": 38.97499,
        "nubia": {
            "semantic_relation": 4.03767,
            "contradiction": 21.59471,
            "irrelevancy": 17.09574,
            "logical_agreement": 61.30955,
            "grammar_ref": 4.47406,
            "grammar_hyp": 5.04181,
            "nubia_score": 0.62747
        },
        "bertscore": {
            "precision": 0.92963,
            "recall": 0.91751,
            "f1": 0.92283
        },
        "meteor": 0.3685213096698059,
        "bleurt": 0.19007
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "mT5_base/totto_test",
        "N": 150,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16706443914081145,
            "2": 0.2862190812720848,
            "3": 0.80343716433942
        },
        "rouge1": {
            "precision": 0.81112,
            "recall": 0.76942,
            "fmeasure": 0.78313
        },
        "rouge2": {
            "precision": 0.56603,
            "recall": 0.53554,
            "fmeasure": 0.54552
        },
        "rougeL": {
            "precision": 0.69631,
            "recall": 0.65748,
            "fmeasure": 0.67085
        },
        "rougeLsum": {
            "precision": 0.69631,
            "recall": 0.65748,
            "fmeasure": 0.67085
        },
        "nist": 8.146391706796607,
        "bleu": 48.06983,
        "nubia": {
            "semantic_relation": 4.45777,
            "contradiction": 6.26975,
            "irrelevancy": 19.97783,
            "logical_agreement": 73.75242,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.68575,
            "nubia_score": 0.79307
        },
        "bertscore": {
            "precision": 0.93879,
            "recall": 0.93463,
            "f1": 0.93582
        },
        "meteor": 0.41268155462574,
        "bleurt": 0.38832
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "mT5_base/totto_test",
        "N": 105,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20253164556962025,
            "2": 0.2923728813559322,
            "3": 0.7728437233134073
        },
        "rouge1": {
            "precision": 0.7947,
            "recall": 0.73382,
            "fmeasure": 0.7531
        },
        "rouge2": {
            "precision": 0.53426,
            "recall": 0.48841,
            "fmeasure": 0.50311
        },
        "rougeL": {
            "precision": 0.67703,
            "recall": 0.62573,
            "fmeasure": 0.64196
        },
        "rougeLsum": {
            "precision": 0.67703,
            "recall": 0.62573,
            "fmeasure": 0.64196
        },
        "nist": 7.303885463722497,
        "bleu": 42.19464,
        "nubia": {
            "semantic_relation": 4.3852,
            "contradiction": 5.99615,
            "irrelevancy": 26.36777,
            "logical_agreement": 67.63608,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.1656,
            "nubia_score": 0.75764
        },
        "bertscore": {
            "precision": 0.93144,
            "recall": 0.92606,
            "f1": 0.92751
        },
        "meteor": 0.38058659539938244,
        "bleurt": 0.32089
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "mT5_base/totto_test",
        "N": 12,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5714285714285714,
            "3": 0.7391304347826086
        },
        "rouge1": {
            "precision": 0.79344,
            "recall": 0.72009,
            "fmeasure": 0.73541
        },
        "rouge2": {
            "precision": 0.56065,
            "recall": 0.48509,
            "fmeasure": 0.50244
        },
        "rougeL": {
            "precision": 0.66305,
            "recall": 0.60124,
            "fmeasure": 0.61529
        },
        "rougeLsum": {
            "precision": 0.66305,
            "recall": 0.60124,
            "fmeasure": 0.61529
        },
        "nist": 5.286620106904498,
        "bleu": 45.24889,
        "nubia": {
            "semantic_relation": 4.23756,
            "contradiction": 1.29546,
            "irrelevancy": 31.56533,
            "logical_agreement": 67.13921,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.41104,
            "nubia_score": 0.76515
        },
        "bertscore": {
            "precision": 0.92652,
            "recall": 0.91644,
            "f1": 0.91974
        },
        "meteor": 0.36707922345694244,
        "bleurt": 0.27026
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.68627,
            "recall": 0.85348,
            "fmeasure": 0.76057
        },
        "rouge2": {
            "precision": 0.35417,
            "recall": 0.46154,
            "fmeasure": 0.40066
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.57143,
            "fmeasure": 0.51613
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.57143,
            "fmeasure": 0.51613
        },
        "nist": 3.2033521556852773,
        "bleu": 21.84182,
        "nubia": {
            "semantic_relation": 4.99919,
            "contradiction": 0.23968,
            "irrelevancy": 71.11973,
            "logical_agreement": 28.64059,
            "grammar_ref": 5.12321,
            "grammar_hyp": 3.42185,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.91147,
            "recall": 0.93501,
            "f1": 0.91864
        },
        "meteor": 0.4290109944388497,
        "bleurt": 0.5048
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "mT5_base/totto_test",
        "N": 25,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2028985507246377,
            "2": 0.42028985507246375,
            "3": 0.7667844522968198
        },
        "rouge1": {
            "precision": 0.78037,
            "recall": 0.71803,
            "fmeasure": 0.73437
        },
        "rouge2": {
            "precision": 0.54925,
            "recall": 0.50331,
            "fmeasure": 0.51463
        },
        "rougeL": {
            "precision": 0.64901,
            "recall": 0.60124,
            "fmeasure": 0.61367
        },
        "rougeLsum": {
            "precision": 0.64901,
            "recall": 0.60124,
            "fmeasure": 0.61367
        },
        "nist": 6.395302165728197,
        "bleu": 45.69323,
        "nubia": {
            "semantic_relation": 3.96975,
            "contradiction": 13.56305,
            "irrelevancy": 25.05756,
            "logical_agreement": 61.37939,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.91214,
            "nubia_score": 0.63886
        },
        "bertscore": {
            "precision": 0.93036,
            "recall": 0.91744,
            "f1": 0.92295
        },
        "meteor": 0.3964225784988109,
        "bleurt": 0.13115
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5384615384615384
        },
        "rouge1": {
            "precision": 0.47059,
            "recall": 0.61538,
            "fmeasure": 0.53333
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.41667,
            "fmeasure": 0.35714
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.61538,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.61538,
            "fmeasure": 0.53333
        },
        "nist": 1.8823529411764706,
        "bleu": 19.3453,
        "nubia": {
            "semantic_relation": 3.633,
            "contradiction": 0.16377,
            "irrelevancy": 99.6995,
            "logical_agreement": 0.13673,
            "grammar_ref": 3.82301,
            "grammar_hyp": 3.86485,
            "nubia_score": 0.65907
        },
        "bertscore": {
            "precision": 0.88196,
            "recall": 0.89007,
            "f1": 0.886
        },
        "meteor": 0.3357291994814012,
        "bleurt": 0.1139
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.18421052631578946,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.65562,
            "recall": 0.43481,
            "fmeasure": 0.49369
        },
        "rouge2": {
            "precision": 0.44129,
            "recall": 0.26949,
            "fmeasure": 0.30123
        },
        "rougeL": {
            "precision": 0.59638,
            "recall": 0.40291,
            "fmeasure": 0.44649
        },
        "rougeLsum": {
            "precision": 0.59638,
            "recall": 0.40291,
            "fmeasure": 0.44649
        },
        "nist": 3.624931477486888,
        "bleu": 42.50036,
        "nubia": {
            "semantic_relation": 3.58805,
            "contradiction": 25.14921,
            "irrelevancy": 28.85635,
            "logical_agreement": 45.99444,
            "grammar_ref": 4.83501,
            "grammar_hyp": 5.50085,
            "nubia_score": 0.53113
        },
        "bertscore": {
            "precision": 0.87037,
            "recall": 0.83448,
            "f1": 0.84117
        },
        "meteor": 0.2750955937504691,
        "bleurt": -0.10413
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0625,
            "2": 0.4,
            "3": 0.8316831683168316
        },
        "rouge1": {
            "precision": 0.80229,
            "recall": 0.80906,
            "fmeasure": 0.79591
        },
        "rouge2": {
            "precision": 0.61897,
            "recall": 0.60071,
            "fmeasure": 0.6026
        },
        "rougeL": {
            "precision": 0.65083,
            "recall": 0.68241,
            "fmeasure": 0.65623
        },
        "rougeLsum": {
            "precision": 0.65083,
            "recall": 0.68241,
            "fmeasure": 0.65623
        },
        "nist": 5.548260406125504,
        "bleu": 50.98121,
        "nubia": {
            "semantic_relation": 4.41535,
            "contradiction": 4.87275,
            "irrelevancy": 28.5661,
            "logical_agreement": 66.56115,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.53089,
            "nubia_score": 0.80201
        },
        "bertscore": {
            "precision": 0.94767,
            "recall": 0.94251,
            "f1": 0.94366
        },
        "meteor": 0.4481211894725318,
        "bleurt": 0.51359
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.9285714285714286
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.89673,
            "fmeasure": 0.94475
        },
        "rouge2": {
            "precision": 0.94872,
            "recall": 0.80357,
            "fmeasure": 0.86931
        },
        "rougeL": {
            "precision": 0.95238,
            "recall": 0.81569,
            "fmeasure": 0.87801
        },
        "rougeLsum": {
            "precision": 0.95238,
            "recall": 0.81569,
            "fmeasure": 0.87801
        },
        "nist": 4.444848093823398,
        "bleu": 87.61152,
        "nubia": {
            "semantic_relation": 4.75019,
            "contradiction": 0.20788,
            "irrelevancy": 0.48822,
            "logical_agreement": 99.3039,
            "grammar_ref": 4.24096,
            "grammar_hyp": 4.49342,
            "nubia_score": 0.89744
        },
        "bertscore": {
            "precision": 0.98553,
            "recall": 0.96737,
            "f1": 0.97418
        },
        "meteor": 0.5389544158792478,
        "bleurt": 0.672
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "mT5_base/totto_test",
        "N": 13,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20588235294117646,
            "2": 0.5686274509803921,
            "3": 0.7317073170731707
        },
        "rouge1": {
            "precision": 0.74506,
            "recall": 0.69436,
            "fmeasure": 0.70624
        },
        "rouge2": {
            "precision": 0.48489,
            "recall": 0.47615,
            "fmeasure": 0.47393
        },
        "rougeL": {
            "precision": 0.59358,
            "recall": 0.56733,
            "fmeasure": 0.57023
        },
        "rougeLsum": {
            "precision": 0.59358,
            "recall": 0.56733,
            "fmeasure": 0.57023
        },
        "nist": 5.767074908054841,
        "bleu": 40.99604,
        "nubia": {
            "semantic_relation": 4.08462,
            "contradiction": 5.4038,
            "irrelevancy": 39.35929,
            "logical_agreement": 55.23691,
            "grammar_ref": 4.86507,
            "grammar_hyp": 4.864,
            "nubia_score": 0.71382
        },
        "bertscore": {
            "precision": 0.90685,
            "recall": 0.89998,
            "f1": 0.90186
        },
        "meteor": 0.37493053026527245,
        "bleurt": 0.04778
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "mT5_base/totto_test",
        "N": 11,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.47368421052631576,
            "3": 0.8064516129032258
        },
        "rouge1": {
            "precision": 0.82592,
            "recall": 0.76736,
            "fmeasure": 0.78815
        },
        "rouge2": {
            "precision": 0.66768,
            "recall": 0.6328,
            "fmeasure": 0.64485
        },
        "rougeL": {
            "precision": 0.74686,
            "recall": 0.69613,
            "fmeasure": 0.71407
        },
        "rougeLsum": {
            "precision": 0.74686,
            "recall": 0.69613,
            "fmeasure": 0.71407
        },
        "nist": 5.854804666866675,
        "bleu": 58.69691,
        "nubia": {
            "semantic_relation": 4.54145,
            "contradiction": 1.0514,
            "irrelevancy": 11.7,
            "logical_agreement": 87.2486,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.50857,
            "nubia_score": 0.85265
        },
        "bertscore": {
            "precision": 0.95249,
            "recall": 0.93898,
            "f1": 0.94398
        },
        "meteor": 0.4503049465217858,
        "bleurt": 0.48433
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "nist": 4.20271956237473,
        "bleu": 91.46912,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.61375,
            "irrelevancy": 0.83168,
            "logical_agreement": 98.55457,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.55122,
            "nubia_score": 0.97788
        },
        "bertscore": {
            "precision": 0.9928,
            "recall": 0.9928,
            "f1": 0.9928
        },
        "meteor": 0.5118198837985161,
        "bleurt": 0.8833
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.625,
            "3": 0.7105263157894737
        },
        "rouge1": {
            "precision": 0.67429,
            "recall": 0.68476,
            "fmeasure": 0.67766
        },
        "rouge2": {
            "precision": 0.3406,
            "recall": 0.32277,
            "fmeasure": 0.32976
        },
        "rougeL": {
            "precision": 0.63143,
            "recall": 0.63714,
            "fmeasure": 0.6326
        },
        "rougeLsum": {
            "precision": 0.63143,
            "recall": 0.63714,
            "fmeasure": 0.6326
        },
        "nist": 3.667418159381051,
        "bleu": 25.62569,
        "nubia": {
            "semantic_relation": 3.6527,
            "contradiction": 3.53346,
            "irrelevancy": 59.52808,
            "logical_agreement": 36.93847,
            "grammar_ref": 5.90284,
            "grammar_hyp": 5.08801,
            "nubia_score": 0.63666
        },
        "bertscore": {
            "precision": 0.91021,
            "recall": 0.90324,
            "f1": 0.90651
        },
        "meteor": 0.354106561503871,
        "bleurt": 0.16274
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.125,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.81389,
            "recall": 0.74724,
            "fmeasure": 0.77269
        },
        "rouge2": {
            "precision": 0.64085,
            "recall": 0.57431,
            "fmeasure": 0.60089
        },
        "rougeL": {
            "precision": 0.76319,
            "recall": 0.67448,
            "fmeasure": 0.71113
        },
        "rougeLsum": {
            "precision": 0.76319,
            "recall": 0.67448,
            "fmeasure": 0.71113
        },
        "nist": 4.371559909375514,
        "bleu": 37.99332,
        "nubia": {
            "semantic_relation": 4.18449,
            "contradiction": 7.64073,
            "irrelevancy": 32.84024,
            "logical_agreement": 59.51903,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.7879,
            "nubia_score": 0.68137
        },
        "bertscore": {
            "precision": 0.93931,
            "recall": 0.92488,
            "f1": 0.93108
        },
        "meteor": 0.36841791981455124,
        "bleurt": 0.12239
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.5416666666666666,
            "3": 0.8125
        },
        "rouge1": {
            "precision": 0.6619,
            "recall": 0.79307,
            "fmeasure": 0.69981
        },
        "rouge2": {
            "precision": 0.51233,
            "recall": 0.59773,
            "fmeasure": 0.53135
        },
        "rougeL": {
            "precision": 0.61252,
            "recall": 0.72539,
            "fmeasure": 0.64252
        },
        "rougeLsum": {
            "precision": 0.61252,
            "recall": 0.72539,
            "fmeasure": 0.64252
        },
        "nist": 4.100589404827936,
        "bleu": 40.15589,
        "nubia": {
            "semantic_relation": 3.95047,
            "contradiction": 7.43822,
            "irrelevancy": 61.74629,
            "logical_agreement": 30.81549,
            "grammar_ref": 4.25456,
            "grammar_hyp": 3.76525,
            "nubia_score": 0.7305
        },
        "bertscore": {
            "precision": 0.89324,
            "recall": 0.92307,
            "f1": 0.90604
        },
        "meteor": 0.4297882603830865,
        "bleurt": 0.12592
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.8571428571428571,
            "3": 0.7727272727272727
        },
        "rouge1": {
            "precision": 0.84274,
            "recall": 0.7498,
            "fmeasure": 0.78905
        },
        "rouge2": {
            "precision": 0.51389,
            "recall": 0.45032,
            "fmeasure": 0.47687
        },
        "rougeL": {
            "precision": 0.6359,
            "recall": 0.56145,
            "fmeasure": 0.59309
        },
        "rougeLsum": {
            "precision": 0.6359,
            "recall": 0.56145,
            "fmeasure": 0.59309
        },
        "nist": 4.6269357915811336,
        "bleu": 50.71951,
        "nubia": {
            "semantic_relation": 4.27802,
            "contradiction": 0.46521,
            "irrelevancy": 0.76642,
            "logical_agreement": 98.76837,
            "grammar_ref": 3.54742,
            "grammar_hyp": 3.17146,
            "nubia_score": 0.8602
        },
        "bertscore": {
            "precision": 0.94379,
            "recall": 0.91473,
            "f1": 0.92843
        },
        "meteor": 0.4000305467170098,
        "bleurt": 0.38169
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36585365853658536,
            "2": 0.5714285714285714,
            "3": 0.7708333333333334
        },
        "rouge1": {
            "precision": 0.62876,
            "recall": 0.70371,
            "fmeasure": 0.65127
        },
        "rouge2": {
            "precision": 0.48157,
            "recall": 0.55102,
            "fmeasure": 0.49939
        },
        "rougeL": {
            "precision": 0.56504,
            "recall": 0.65943,
            "fmeasure": 0.59039
        },
        "rougeLsum": {
            "precision": 0.56504,
            "recall": 0.65943,
            "fmeasure": 0.59039
        },
        "nist": 4.2424369559745045,
        "bleu": 43.9954,
        "nubia": {
            "semantic_relation": 3.68614,
            "contradiction": 34.53863,
            "irrelevancy": 28.52882,
            "logical_agreement": 36.93254,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.61845,
            "nubia_score": 0.59032
        },
        "bertscore": {
            "precision": 0.91176,
            "recall": 0.92674,
            "f1": 0.91706
        },
        "meteor": 0.43762198660150486,
        "bleurt": 0.14944
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 1.0,
            "fmeasure": 0.84615
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.8,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.81818,
            "fmeasure": 0.69231
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.81818,
            "fmeasure": 0.69231
        },
        "nist": 2.856359646279345,
        "bleu": 47.08713,
        "nubia": {
            "semantic_relation": 4.37626,
            "contradiction": 0.08556,
            "irrelevancy": 99.76485,
            "logical_agreement": 0.14959,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.50769,
            "nubia_score": 0.89323
        },
        "bertscore": {
            "precision": 0.87956,
            "recall": 0.93585,
            "f1": 0.90684
        },
        "meteor": 0.4753873593135944,
        "bleurt": 0.07071
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.1,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.56994,
            "recall": 0.6537,
            "fmeasure": 0.59996
        },
        "rouge2": {
            "precision": 0.31966,
            "recall": 0.3502,
            "fmeasure": 0.33109
        },
        "rougeL": {
            "precision": 0.44345,
            "recall": 0.48687,
            "fmeasure": 0.45736
        },
        "rougeLsum": {
            "precision": 0.44345,
            "recall": 0.48687,
            "fmeasure": 0.45736
        },
        "nist": 3.5077059098376884,
        "bleu": 40.12296,
        "nubia": {
            "semantic_relation": 4.07528,
            "contradiction": 0.2895,
            "irrelevancy": 46.718,
            "logical_agreement": 52.9925,
            "grammar_ref": 4.57807,
            "grammar_hyp": 3.90449,
            "nubia_score": 0.76126
        },
        "bertscore": {
            "precision": 0.89619,
            "recall": 0.91275,
            "f1": 0.89974
        },
        "meteor": 0.40179422803733894,
        "bleurt": 0.23584
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.38461538461538464,
            "2": 0.5555555555555556,
            "3": 0.5846153846153846
        },
        "rouge1": {
            "precision": 0.71699,
            "recall": 0.61774,
            "fmeasure": 0.63905
        },
        "rouge2": {
            "precision": 0.46266,
            "recall": 0.39277,
            "fmeasure": 0.40734
        },
        "rougeL": {
            "precision": 0.60565,
            "recall": 0.53329,
            "fmeasure": 0.54573
        },
        "rougeLsum": {
            "precision": 0.60565,
            "recall": 0.53329,
            "fmeasure": 0.54573
        },
        "nist": 4.354954584178253,
        "bleu": 31.969,
        "nubia": {
            "semantic_relation": 4.13651,
            "contradiction": 12.84442,
            "irrelevancy": 26.56929,
            "logical_agreement": 60.5863,
            "grammar_ref": 4.57813,
            "grammar_hyp": 4.23647,
            "nubia_score": 0.71237
        },
        "bertscore": {
            "precision": 0.93011,
            "recall": 0.91193,
            "f1": 0.92035
        },
        "meteor": 0.31008203151792124,
        "bleurt": 0.19219
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16,
            "2": 0.9,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.77146,
            "recall": 0.80207,
            "fmeasure": 0.77992
        },
        "rouge2": {
            "precision": 0.52901,
            "recall": 0.54122,
            "fmeasure": 0.53188
        },
        "rougeL": {
            "precision": 0.63918,
            "recall": 0.64867,
            "fmeasure": 0.63911
        },
        "rougeLsum": {
            "precision": 0.63918,
            "recall": 0.64867,
            "fmeasure": 0.63911
        },
        "nist": 5.112253143163151,
        "bleu": 49.36749,
        "nubia": {
            "semantic_relation": 4.32878,
            "contradiction": 9.23609,
            "irrelevancy": 35.00897,
            "logical_agreement": 55.75495,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.47047,
            "nubia_score": 0.72532
        },
        "bertscore": {
            "precision": 0.93785,
            "recall": 0.94651,
            "f1": 0.94129
        },
        "meteor": 0.4433771096073979,
        "bleurt": 0.34207
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.9583333333333334
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.90455,
            "fmeasure": 0.94987
        },
        "rouge2": {
            "precision": 0.91503,
            "recall": 0.82105,
            "fmeasure": 0.8655
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.90455,
            "fmeasure": 0.94987
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.90455,
            "fmeasure": 0.94987
        },
        "nist": 5.2554159741812,
        "bleu": 90.71221,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.51628,
            "irrelevancy": 0.65538,
            "logical_agreement": 98.82834,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.52589,
            "nubia_score": 0.98378
        },
        "bertscore": {
            "precision": 0.99403,
            "recall": 0.98475,
            "f1": 0.98936
        },
        "meteor": 0.5473198792718016,
        "bleurt": 0.79193
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 0.725
        },
        "rouge1": {
            "precision": 0.70486,
            "recall": 0.71471,
            "fmeasure": 0.70277
        },
        "rouge2": {
            "precision": 0.48696,
            "recall": 0.49782,
            "fmeasure": 0.48611
        },
        "rougeL": {
            "precision": 0.67153,
            "recall": 0.68546,
            "fmeasure": 0.67172
        },
        "rougeLsum": {
            "precision": 0.67153,
            "recall": 0.68546,
            "fmeasure": 0.67172
        },
        "nist": 4.590399500964318,
        "bleu": 50.66551,
        "nubia": {
            "semantic_relation": 4.58325,
            "contradiction": 0.38081,
            "irrelevancy": 25.73118,
            "logical_agreement": 73.88802,
            "grammar_ref": 4.90076,
            "grammar_hyp": 4.89931,
            "nubia_score": 0.84814
        },
        "bertscore": {
            "precision": 0.93159,
            "recall": 0.93283,
            "f1": 0.93197
        },
        "meteor": 0.4512895600254498,
        "bleurt": 0.23364
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.47619,
            "recall": 0.71795,
            "fmeasure": 0.5719
        },
        "rouge2": {
            "precision": 0.275,
            "recall": 0.42262,
            "fmeasure": 0.33272
        },
        "rougeL": {
            "precision": 0.2619,
            "recall": 0.40256,
            "fmeasure": 0.31699
        },
        "rougeLsum": {
            "precision": 0.2619,
            "recall": 0.40256,
            "fmeasure": 0.31699
        },
        "nist": 2.5766812288998513,
        "bleu": 27.409,
        "nubia": {
            "semantic_relation": 3.473,
            "contradiction": 0.09043,
            "irrelevancy": 99.77856,
            "logical_agreement": 0.13101,
            "grammar_ref": 4.56931,
            "grammar_hyp": 2.80482,
            "nubia_score": 0.76144
        },
        "bertscore": {
            "precision": 0.82891,
            "recall": 0.85893,
            "f1": 0.8401
        },
        "meteor": 0.4164788794038261,
        "bleurt": -0.10604
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.16666666666666666,
            "3": 0.9135802469135802
        },
        "rouge1": {
            "precision": 0.87714,
            "recall": 0.88812,
            "fmeasure": 0.87953
        },
        "rouge2": {
            "precision": 0.783,
            "recall": 0.77784,
            "fmeasure": 0.77863
        },
        "rougeL": {
            "precision": 0.8453,
            "recall": 0.85209,
            "fmeasure": 0.84604
        },
        "rougeLsum": {
            "precision": 0.8453,
            "recall": 0.85209,
            "fmeasure": 0.84604
        },
        "nist": 5.752099919645135,
        "bleu": 70.62402,
        "nubia": {
            "semantic_relation": 4.51892,
            "contradiction": 0.7581,
            "irrelevancy": 22.04108,
            "logical_agreement": 77.20082,
            "grammar_ref": 5.07225,
            "grammar_hyp": 4.95995,
            "nubia_score": 0.86245
        },
        "bertscore": {
            "precision": 0.96675,
            "recall": 0.97032,
            "f1": 0.96838
        },
        "meteor": 0.5035917455745204,
        "bleurt": 0.66196
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8846153846153846
        },
        "rouge1": {
            "precision": 0.86364,
            "recall": 0.85837,
            "fmeasure": 0.86094
        },
        "rouge2": {
            "precision": 0.7619,
            "recall": 0.75794,
            "fmeasure": 0.75987
        },
        "rougeL": {
            "precision": 0.71212,
            "recall": 0.70553,
            "fmeasure": 0.70875
        },
        "rougeLsum": {
            "precision": 0.71212,
            "recall": 0.70553,
            "fmeasure": 0.70875
        },
        "nist": 4.2998889356927705,
        "bleu": 59.49634,
        "nubia": {
            "semantic_relation": 4.44446,
            "contradiction": 0.86749,
            "irrelevancy": 19.73137,
            "logical_agreement": 79.40114,
            "grammar_ref": 4.36539,
            "grammar_hyp": 4.60758,
            "nubia_score": 0.77259
        },
        "bertscore": {
            "precision": 0.94426,
            "recall": 0.93718,
            "f1": 0.93846
        },
        "meteor": 0.45300012054501093,
        "bleurt": 0.3835
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6153846153846154,
            "2": 1.0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.67236,
            "fmeasure": 0.68695
        },
        "rouge2": {
            "precision": 0.64444,
            "recall": 0.60948,
            "fmeasure": 0.62346
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.45014,
            "fmeasure": 0.45166
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.45014,
            "fmeasure": 0.45166
        },
        "nist": 4.617647230689446,
        "bleu": 67.78396,
        "nubia": {
            "semantic_relation": 2.79024,
            "contradiction": 0.23086,
            "irrelevancy": 64.44683,
            "logical_agreement": 35.32231,
            "grammar_ref": 4.13721,
            "grammar_hyp": 3.69524,
            "nubia_score": 0.41859
        },
        "bertscore": {
            "precision": 0.94157,
            "recall": 0.89045,
            "f1": 0.91529
        },
        "meteor": 0.44297773537248525,
        "bleurt": -0.4264
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.9230769230769231,
            "3": 0.8148148148148148
        },
        "rouge1": {
            "precision": 0.89773,
            "recall": 0.84975,
            "fmeasure": 0.86926
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.67668,
            "fmeasure": 0.69518
        },
        "rougeL": {
            "precision": 0.89773,
            "recall": 0.84975,
            "fmeasure": 0.86926
        },
        "rougeLsum": {
            "precision": 0.89773,
            "recall": 0.84975,
            "fmeasure": 0.86926
        },
        "nist": 5.146020191530308,
        "bleu": 65.40987,
        "nubia": {
            "semantic_relation": 4.92039,
            "contradiction": 0.31133,
            "irrelevancy": 8.80146,
            "logical_agreement": 90.88721,
            "grammar_ref": 4.97796,
            "grammar_hyp": 5.20908,
            "nubia_score": 0.91549
        },
        "bertscore": {
            "precision": 0.96297,
            "recall": 0.95712,
            "f1": 0.95973
        },
        "meteor": 0.5055209912519533,
        "bleurt": 0.64256
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "mT5_base/totto_test",
        "N": 10,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2391304347826087,
            "2": 0.5925925925925926,
            "3": 0.8105263157894737
        },
        "rouge1": {
            "precision": 0.77547,
            "recall": 0.74494,
            "fmeasure": 0.73897
        },
        "rouge2": {
            "precision": 0.53834,
            "recall": 0.4906,
            "fmeasure": 0.5033
        },
        "rougeL": {
            "precision": 0.65636,
            "recall": 0.61138,
            "fmeasure": 0.61783
        },
        "rougeLsum": {
            "precision": 0.65636,
            "recall": 0.61138,
            "fmeasure": 0.61783
        },
        "nist": 5.664231753773421,
        "bleu": 48.51132,
        "nubia": {
            "semantic_relation": 4.27346,
            "contradiction": 1.97793,
            "irrelevancy": 36.54418,
            "logical_agreement": 61.47789,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.44676,
            "nubia_score": 0.70775
        },
        "bertscore": {
            "precision": 0.91769,
            "recall": 0.91406,
            "f1": 0.91454
        },
        "meteor": 0.39738600570488986,
        "bleurt": 0.22165
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.825,
            "fmeasure": 0.75355
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.56085,
            "fmeasure": 0.50774
        },
        "rougeL": {
            "precision": 0.69697,
            "recall": 0.825,
            "fmeasure": 0.75355
        },
        "rougeLsum": {
            "precision": 0.69697,
            "recall": 0.825,
            "fmeasure": 0.75355
        },
        "nist": 3.033201102543045,
        "bleu": 42.50281,
        "nubia": {
            "semantic_relation": 4.45629,
            "contradiction": 0.41912,
            "irrelevancy": 16.79736,
            "logical_agreement": 82.78352,
            "grammar_ref": 5.68329,
            "grammar_hyp": 5.02659,
            "nubia_score": 0.82233
        },
        "bertscore": {
            "precision": 0.93206,
            "recall": 0.96602,
            "f1": 0.94874
        },
        "meteor": 0.4329119207003679,
        "bleurt": 0.51395
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3548387096774194,
            "3": 0.72
        },
        "rouge1": {
            "precision": 0.68506,
            "recall": 0.59994,
            "fmeasure": 0.61251
        },
        "rouge2": {
            "precision": 0.47176,
            "recall": 0.40224,
            "fmeasure": 0.41438
        },
        "rougeL": {
            "precision": 0.55866,
            "recall": 0.53844,
            "fmeasure": 0.5153
        },
        "rougeLsum": {
            "precision": 0.55866,
            "recall": 0.53844,
            "fmeasure": 0.5153
        },
        "nist": 3.179534928408912,
        "bleu": 26.19719,
        "nubia": {
            "semantic_relation": 3.966,
            "contradiction": 0.38725,
            "irrelevancy": 74.81845,
            "logical_agreement": 24.79431,
            "grammar_ref": 3.62435,
            "grammar_hyp": 3.61721,
            "nubia_score": 0.68095
        },
        "bertscore": {
            "precision": 0.89736,
            "recall": 0.87407,
            "f1": 0.88441
        },
        "meteor": 0.2774449885827459,
        "bleurt": -0.09538
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "mT5_base/totto_test",
        "N": 14,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.14705882352941177,
            "3": 0.5513307984790875
        },
        "rouge1": {
            "precision": 0.61165,
            "recall": 0.54705,
            "fmeasure": 0.56761
        },
        "rouge2": {
            "precision": 0.26026,
            "recall": 0.23922,
            "fmeasure": 0.24619
        },
        "rougeL": {
            "precision": 0.43999,
            "recall": 0.40325,
            "fmeasure": 0.41428
        },
        "rougeLsum": {
            "precision": 0.43999,
            "recall": 0.40325,
            "fmeasure": 0.41428
        },
        "nist": 4.37027003565454,
        "bleu": 17.88011,
        "nubia": {
            "semantic_relation": 3.34555,
            "contradiction": 38.27654,
            "irrelevancy": 29.38297,
            "logical_agreement": 32.34049,
            "grammar_ref": 3.91022,
            "grammar_hyp": 4.05399,
            "nubia_score": 0.50167
        },
        "bertscore": {
            "precision": 0.88238,
            "recall": 0.86294,
            "f1": 0.87111
        },
        "meteor": 0.2700825652705168,
        "bleurt": -0.15976
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.6825396825396826
        },
        "rouge1": {
            "precision": 0.83929,
            "recall": 0.66388,
            "fmeasure": 0.73954
        },
        "rouge2": {
            "precision": 0.55529,
            "recall": 0.43446,
            "fmeasure": 0.48618
        },
        "rougeL": {
            "precision": 0.75397,
            "recall": 0.59022,
            "fmeasure": 0.66051
        },
        "rougeLsum": {
            "precision": 0.75397,
            "recall": 0.59022,
            "fmeasure": 0.66051
        },
        "nist": 4.329227833294331,
        "bleu": 38.87999,
        "nubia": {
            "semantic_relation": 3.85471,
            "contradiction": 6.11099,
            "irrelevancy": 33.86994,
            "logical_agreement": 60.01906,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.9149,
            "nubia_score": 0.64105
        },
        "bertscore": {
            "precision": 0.93021,
            "recall": 0.89222,
            "f1": 0.91042
        },
        "meteor": 0.36107954706435563,
        "bleurt": 0.17211
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.5333333333333333,
            "3": 0.717391304347826
        },
        "rouge1": {
            "precision": 0.7368,
            "recall": 0.64067,
            "fmeasure": 0.67415
        },
        "rouge2": {
            "precision": 0.42762,
            "recall": 0.39449,
            "fmeasure": 0.40599
        },
        "rougeL": {
            "precision": 0.55482,
            "recall": 0.50606,
            "fmeasure": 0.52318
        },
        "rougeLsum": {
            "precision": 0.55482,
            "recall": 0.50606,
            "fmeasure": 0.52318
        },
        "nist": 5.107640809818487,
        "bleu": 37.26108,
        "nubia": {
            "semantic_relation": 3.24833,
            "contradiction": 21.72553,
            "irrelevancy": 37.06386,
            "logical_agreement": 41.21061,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.4103,
            "nubia_score": 0.50373
        },
        "bertscore": {
            "precision": 0.91742,
            "recall": 0.8867,
            "f1": 0.89917
        },
        "meteor": 0.32877340188860715,
        "bleurt": 0.06733
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5384615384615384,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.7096,
            "recall": 0.72506,
            "fmeasure": 0.71472
        },
        "rouge2": {
            "precision": 0.43904,
            "recall": 0.48228,
            "fmeasure": 0.45736
        },
        "rougeL": {
            "precision": 0.48345,
            "recall": 0.54353,
            "fmeasure": 0.50949
        },
        "rougeLsum": {
            "precision": 0.48345,
            "recall": 0.54353,
            "fmeasure": 0.50949
        },
        "nist": 4.748119818342254,
        "bleu": 46.51705,
        "nubia": {
            "semantic_relation": 4.56942,
            "contradiction": 0.25506,
            "irrelevancy": 38.28098,
            "logical_agreement": 61.46395,
            "grammar_ref": 4.38609,
            "grammar_hyp": 3.78777,
            "nubia_score": 0.83185
        },
        "bertscore": {
            "precision": 0.92737,
            "recall": 0.92933,
            "f1": 0.92737
        },
        "meteor": 0.434746594100291,
        "bleurt": 0.37048
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.48484848484848486,
            "2": 0.4722222222222222,
            "3": 0.6637168141592921
        },
        "rouge1": {
            "precision": 0.6381,
            "recall": 0.68251,
            "fmeasure": 0.63847
        },
        "rouge2": {
            "precision": 0.47596,
            "recall": 0.50917,
            "fmeasure": 0.47514
        },
        "rougeL": {
            "precision": 0.54063,
            "recall": 0.58684,
            "fmeasure": 0.54509
        },
        "rougeLsum": {
            "precision": 0.54063,
            "recall": 0.58684,
            "fmeasure": 0.54509
        },
        "nist": 4.178975564053227,
        "bleu": 36.27313,
        "nubia": {
            "semantic_relation": 3.41162,
            "contradiction": 13.96755,
            "irrelevancy": 27.69,
            "logical_agreement": 58.34244,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.08639,
            "nubia_score": 0.53394
        },
        "bertscore": {
            "precision": 0.8885,
            "recall": 0.89475,
            "f1": 0.88897
        },
        "meteor": 0.34654621145565995,
        "bleurt": 0.04605
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.5714285714285714,
            "3": 0.64
        },
        "rouge1": {
            "precision": 0.68086,
            "recall": 0.61631,
            "fmeasure": 0.63253
        },
        "rouge2": {
            "precision": 0.4197,
            "recall": 0.39971,
            "fmeasure": 0.39798
        },
        "rougeL": {
            "precision": 0.51222,
            "recall": 0.49317,
            "fmeasure": 0.49132
        },
        "rougeLsum": {
            "precision": 0.51222,
            "recall": 0.49317,
            "fmeasure": 0.49132
        },
        "nist": 4.595642835046239,
        "bleu": 29.09813,
        "nubia": {
            "semantic_relation": 3.07747,
            "contradiction": 26.10827,
            "irrelevancy": 53.12833,
            "logical_agreement": 20.7634,
            "grammar_ref": 3.87874,
            "grammar_hyp": 4.02498,
            "nubia_score": 0.44013
        },
        "bertscore": {
            "precision": 0.87454,
            "recall": 0.88895,
            "f1": 0.88065
        },
        "meteor": 0.29951991136701145,
        "bleurt": -0.20791
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10810810810810811,
            "2": 0.8,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.90317,
            "recall": 0.74678,
            "fmeasure": 0.80876
        },
        "rouge2": {
            "precision": 0.64984,
            "recall": 0.54508,
            "fmeasure": 0.58443
        },
        "rougeL": {
            "precision": 0.72272,
            "recall": 0.61431,
            "fmeasure": 0.65595
        },
        "rougeLsum": {
            "precision": 0.72272,
            "recall": 0.61431,
            "fmeasure": 0.65595
        },
        "nist": 5.287325427851597,
        "bleu": 47.93989,
        "nubia": {
            "semantic_relation": 4.46508,
            "contradiction": 10.67338,
            "irrelevancy": 6.46096,
            "logical_agreement": 82.86566,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.72609,
            "nubia_score": 0.75638
        },
        "bertscore": {
            "precision": 0.94802,
            "recall": 0.93217,
            "f1": 0.93828
        },
        "meteor": 0.422248307023799,
        "bleurt": 0.3686
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.42424242424242425,
            "3": 0.6285714285714286
        },
        "rouge1": {
            "precision": 0.47457,
            "recall": 0.50695,
            "fmeasure": 0.48104
        },
        "rouge2": {
            "precision": 0.261,
            "recall": 0.27666,
            "fmeasure": 0.26261
        },
        "rougeL": {
            "precision": 0.43821,
            "recall": 0.46412,
            "fmeasure": 0.44221
        },
        "rougeLsum": {
            "precision": 0.43821,
            "recall": 0.46412,
            "fmeasure": 0.44221
        },
        "nist": 3.4097273064615883,
        "bleu": 21.81622,
        "nubia": {
            "semantic_relation": 3.31149,
            "contradiction": 37.70442,
            "irrelevancy": 45.48625,
            "logical_agreement": 16.80932,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.26669,
            "nubia_score": 0.54143
        },
        "bertscore": {
            "precision": 0.86242,
            "recall": 0.87684,
            "f1": 0.8685
        },
        "meteor": 0.27752879688600696,
        "bleurt": -0.08805
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.25,
            "3": 0.6049382716049383
        },
        "rouge1": {
            "precision": 0.69695,
            "recall": 0.48988,
            "fmeasure": 0.55888
        },
        "rouge2": {
            "precision": 0.38391,
            "recall": 0.26632,
            "fmeasure": 0.30361
        },
        "rougeL": {
            "precision": 0.56578,
            "recall": 0.3855,
            "fmeasure": 0.44469
        },
        "rougeLsum": {
            "precision": 0.56578,
            "recall": 0.3855,
            "fmeasure": 0.44469
        },
        "nist": 2.7740520882364574,
        "bleu": 21.03215,
        "nubia": {
            "semantic_relation": 3.21003,
            "contradiction": 7.12981,
            "irrelevancy": 44.76639,
            "logical_agreement": 48.1038,
            "grammar_ref": 4.13756,
            "grammar_hyp": 4.6111,
            "nubia_score": 0.39957
        },
        "bertscore": {
            "precision": 0.91438,
            "recall": 0.85808,
            "f1": 0.8851
        },
        "meteor": 0.2707317281578859,
        "bleurt": -0.13446
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "mT5_base/totto_test",
        "N": 131,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22281167108753316,
            "2": 0.44471153846153844,
            "3": 0.7082748948106592
        },
        "rouge1": {
            "precision": 0.77158,
            "recall": 0.68504,
            "fmeasure": 0.71074
        },
        "rouge2": {
            "precision": 0.50177,
            "recall": 0.44919,
            "fmeasure": 0.4645
        },
        "rougeL": {
            "precision": 0.64793,
            "recall": 0.57816,
            "fmeasure": 0.59827
        },
        "rougeLsum": {
            "precision": 0.64793,
            "recall": 0.57816,
            "fmeasure": 0.59827
        },
        "nist": 7.16324119698325,
        "bleu": 38.86529,
        "nubia": {
            "semantic_relation": 4.09577,
            "contradiction": 13.17584,
            "irrelevancy": 27.55279,
            "logical_agreement": 59.27137,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.80537,
            "nubia_score": 0.67348
        },
        "bertscore": {
            "precision": 0.92578,
            "recall": 0.91248,
            "f1": 0.91777
        },
        "meteor": 0.3606278558227322,
        "bleurt": 0.19167
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6190476190476191
        },
        "rouge1": {
            "precision": 0.61731,
            "recall": 0.62314,
            "fmeasure": 0.61928
        },
        "rouge2": {
            "precision": 0.34055,
            "recall": 0.34917,
            "fmeasure": 0.34422
        },
        "rougeL": {
            "precision": 0.49533,
            "recall": 0.50566,
            "fmeasure": 0.49949
        },
        "rougeLsum": {
            "precision": 0.49533,
            "recall": 0.50566,
            "fmeasure": 0.49949
        },
        "nist": 3.510224812271301,
        "bleu": 19.59159,
        "nubia": {
            "semantic_relation": 3.15443,
            "contradiction": 48.07636,
            "irrelevancy": 48.60062,
            "logical_agreement": 3.32302,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.11793,
            "nubia_score": 0.50963
        },
        "bertscore": {
            "precision": 0.89086,
            "recall": 0.8739,
            "f1": 0.88128
        },
        "meteor": 0.27290313463755955,
        "bleurt": 0.105
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.60012,
            "fmeasure": 0.65501
        },
        "rouge2": {
            "precision": 0.46905,
            "recall": 0.35157,
            "fmeasure": 0.39959
        },
        "rougeL": {
            "precision": 0.65909,
            "recall": 0.52404,
            "fmeasure": 0.58059
        },
        "rougeLsum": {
            "precision": 0.65909,
            "recall": 0.52404,
            "fmeasure": 0.58059
        },
        "nist": 3.0542965129332136,
        "bleu": 24.56179,
        "nubia": {
            "semantic_relation": 3.76714,
            "contradiction": 57.52944,
            "irrelevancy": 6.74712,
            "logical_agreement": 35.72344,
            "grammar_ref": 3.82725,
            "grammar_hyp": 4.15585,
            "nubia_score": 0.574
        },
        "bertscore": {
            "precision": 0.91835,
            "recall": 0.87201,
            "f1": 0.89283
        },
        "meteor": 0.30418960203493467,
        "bleurt": 0.24555
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.51515,
            "recall": 0.36905,
            "fmeasure": 0.42753
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.18893,
            "fmeasure": 0.21989
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.24048,
            "fmeasure": 0.27785
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.24048,
            "fmeasure": 0.27785
        },
        "nist": 0.37021006579631555,
        "bleu": 13.42826,
        "nubia": {
            "semantic_relation": 3.84592,
            "contradiction": 6.46895,
            "irrelevancy": 34.48634,
            "logical_agreement": 59.04472,
            "grammar_ref": 4.03834,
            "grammar_hyp": 4.32844,
            "nubia_score": 0.57028
        },
        "bertscore": {
            "precision": 0.92293,
            "recall": 0.89612,
            "f1": 0.90933
        },
        "meteor": 0.21919465372151856,
        "bleurt": 0.12826
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.375,
            "3": 0.85
        },
        "rouge1": {
            "precision": 0.86905,
            "recall": 0.78463,
            "fmeasure": 0.8225
        },
        "rouge2": {
            "precision": 0.73427,
            "recall": 0.66006,
            "fmeasure": 0.69299
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.70344,
            "fmeasure": 0.74028
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.70344,
            "fmeasure": 0.74028
        },
        "nist": 4.7095159005003255,
        "bleu": 60.05356,
        "nubia": {
            "semantic_relation": 4.63119,
            "contradiction": 0.27899,
            "irrelevancy": 8.7524,
            "logical_agreement": 90.96861,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.4694,
            "nubia_score": 0.89537
        },
        "bertscore": {
            "precision": 0.94566,
            "recall": 0.93048,
            "f1": 0.93566
        },
        "meteor": 0.4631598227295697,
        "bleurt": 0.50461
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "mT5_base/totto_test",
        "N": 162,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1819571865443425,
            "2": 0.3438914027149321,
            "3": 0.7495232040686586
        },
        "rouge1": {
            "precision": 0.74432,
            "recall": 0.69855,
            "fmeasure": 0.70979
        },
        "rouge2": {
            "precision": 0.47763,
            "recall": 0.4447,
            "fmeasure": 0.45225
        },
        "rougeL": {
            "precision": 0.62162,
            "recall": 0.58291,
            "fmeasure": 0.59234
        },
        "rougeLsum": {
            "precision": 0.62162,
            "recall": 0.58291,
            "fmeasure": 0.59234
        },
        "nist": 7.333602978820915,
        "bleu": 40.72044,
        "nubia": {
            "semantic_relation": 4.04811,
            "contradiction": 22.39808,
            "irrelevancy": 21.91577,
            "logical_agreement": 55.68615,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.57885,
            "nubia_score": 0.69381
        },
        "bertscore": {
            "precision": 0.92612,
            "recall": 0.92032,
            "f1": 0.92117
        },
        "meteor": 0.37791419446384755,
        "bleurt": 0.25823
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "nist": 2.9898332363522426,
        "bleu": 61.0195,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        },
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        },
        "meteor": 0.5064321156600579,
        "bleurt": 0.83294
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "mT5_base/totto_test",
        "N": 10,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.5454545454545454,
            "3": 0.9056603773584906
        },
        "rouge1": {
            "precision": 0.91415,
            "recall": 0.90565,
            "fmeasure": 0.90943
        },
        "rouge2": {
            "precision": 0.83466,
            "recall": 0.83497,
            "fmeasure": 0.83354
        },
        "rougeL": {
            "precision": 0.85637,
            "recall": 0.8635,
            "fmeasure": 0.85762
        },
        "rougeLsum": {
            "precision": 0.85637,
            "recall": 0.8635,
            "fmeasure": 0.85762
        },
        "nist": 6.224049301697168,
        "bleu": 71.0927,
        "nubia": {
            "semantic_relation": 4.76918,
            "contradiction": 0.25309,
            "irrelevancy": 11.24548,
            "logical_agreement": 88.50144,
            "grammar_ref": 5.03704,
            "grammar_hyp": 5.12847,
            "nubia_score": 0.91889
        },
        "bertscore": {
            "precision": 0.97466,
            "recall": 0.97282,
            "f1": 0.97255
        },
        "meteor": 0.5247578074864504,
        "bleurt": 0.76768
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.5714285714285714,
            "3": 0.6818181818181818
        },
        "rouge1": {
            "precision": 0.80135,
            "recall": 0.58388,
            "fmeasure": 0.66547
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.29697,
            "fmeasure": 0.33121
        },
        "rougeL": {
            "precision": 0.60471,
            "recall": 0.45725,
            "fmeasure": 0.51258
        },
        "rougeLsum": {
            "precision": 0.60471,
            "recall": 0.45725,
            "fmeasure": 0.51258
        },
        "nist": 3.835597742225528,
        "bleu": 34.55719,
        "nubia": {
            "semantic_relation": 4.15289,
            "contradiction": 0.66263,
            "irrelevancy": 11.69211,
            "logical_agreement": 87.64526,
            "grammar_ref": 4.68806,
            "grammar_hyp": 4.99131,
            "nubia_score": 0.6732
        },
        "bertscore": {
            "precision": 0.92506,
            "recall": 0.87857,
            "f1": 0.90107
        },
        "meteor": 0.322173382794425,
        "bleurt": 0.25033
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.875
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.7875,
            "fmeasure": 0.73889
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.38095,
            "fmeasure": 0.35417
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.5625,
            "fmeasure": 0.52778
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.5625,
            "fmeasure": 0.52778
        },
        "nist": 2.075647700580668,
        "bleu": 24.71244,
        "nubia": {
            "semantic_relation": 4.91698,
            "contradiction": 0.32031,
            "irrelevancy": 0.44982,
            "logical_agreement": 99.22987,
            "grammar_ref": 6.57359,
            "grammar_hyp": 5.36005,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.90375,
            "recall": 0.9514,
            "f1": 0.92696
        },
        "meteor": 0.410497365800436,
        "bleurt": 0.5309
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.59115,
            "fmeasure": 0.69563
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.25265,
            "fmeasure": 0.31288
        },
        "rougeL": {
            "precision": 0.74167,
            "recall": 0.49115,
            "fmeasure": 0.58452
        },
        "rougeLsum": {
            "precision": 0.74167,
            "recall": 0.49115,
            "fmeasure": 0.58452
        },
        "nist": 1.3988430426645675,
        "bleu": 12.06563,
        "nubia": {
            "semantic_relation": 3.01325,
            "contradiction": 28.62118,
            "irrelevancy": 22.30283,
            "logical_agreement": 49.07599,
            "grammar_ref": 5.1114,
            "grammar_hyp": 6.22976,
            "nubia_score": 0.29242
        },
        "bertscore": {
            "precision": 0.93905,
            "recall": 0.88589,
            "f1": 0.91165
        },
        "meteor": 0.27273224077846614,
        "bleurt": -0.15568
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09523809523809523,
            "2": 0.6,
            "3": 0.7878787878787878
        },
        "rouge1": {
            "precision": 0.64576,
            "recall": 0.66481,
            "fmeasure": 0.64391
        },
        "rouge2": {
            "precision": 0.3859,
            "recall": 0.43012,
            "fmeasure": 0.40094
        },
        "rougeL": {
            "precision": 0.60008,
            "recall": 0.63286,
            "fmeasure": 0.60657
        },
        "rougeLsum": {
            "precision": 0.60008,
            "recall": 0.63286,
            "fmeasure": 0.60657
        },
        "nist": 3.9272227921068747,
        "bleu": 37.20932,
        "nubia": {
            "semantic_relation": 3.69799,
            "contradiction": 17.67394,
            "irrelevancy": 47.29021,
            "logical_agreement": 35.03585,
            "grammar_ref": 5.1808,
            "grammar_hyp": 5.46614,
            "nubia_score": 0.52877
        },
        "bertscore": {
            "precision": 0.88644,
            "recall": 0.88458,
            "f1": 0.88462
        },
        "meteor": 0.36514406842089076,
        "bleurt": 0.03496
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.87981,
            "fmeasure": 0.9164
        },
        "rouge2": {
            "precision": 0.84838,
            "recall": 0.77685,
            "fmeasure": 0.81001
        },
        "rougeL": {
            "precision": 0.94167,
            "recall": 0.86592,
            "fmeasure": 0.90125
        },
        "rougeLsum": {
            "precision": 0.94167,
            "recall": 0.86592,
            "fmeasure": 0.90125
        },
        "nist": 5.168441550590951,
        "bleu": 69.29725,
        "nubia": {
            "semantic_relation": 4.64165,
            "contradiction": 1.12239,
            "irrelevancy": 0.74407,
            "logical_agreement": 98.13354,
            "grammar_ref": 5.0449,
            "grammar_hyp": 5.3775,
            "nubia_score": 0.80336
        },
        "bertscore": {
            "precision": 0.98613,
            "recall": 0.96695,
            "f1": 0.97635
        },
        "meteor": 0.4974072147404349,
        "bleurt": 0.79163
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.726027397260274
        },
        "rouge1": {
            "precision": 0.69397,
            "recall": 0.72708,
            "fmeasure": 0.69555
        },
        "rouge2": {
            "precision": 0.45083,
            "recall": 0.47181,
            "fmeasure": 0.45117
        },
        "rougeL": {
            "precision": 0.53072,
            "recall": 0.5466,
            "fmeasure": 0.52905
        },
        "rougeLsum": {
            "precision": 0.53072,
            "recall": 0.5466,
            "fmeasure": 0.52905
        },
        "nist": 4.955122889184162,
        "bleu": 36.99755,
        "nubia": {
            "semantic_relation": 4.2277,
            "contradiction": 4.57908,
            "irrelevancy": 28.92787,
            "logical_agreement": 66.49305,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.52751,
            "nubia_score": 0.76328
        },
        "bertscore": {
            "precision": 0.90131,
            "recall": 0.91635,
            "f1": 0.90626
        },
        "meteor": 0.37143731268033003,
        "bleurt": 0.18923
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.14285714285714285,
            "3": 0.859375
        },
        "rouge1": {
            "precision": 0.8438,
            "recall": 0.87869,
            "fmeasure": 0.84059
        },
        "rouge2": {
            "precision": 0.70418,
            "recall": 0.73843,
            "fmeasure": 0.70921
        },
        "rougeL": {
            "precision": 0.7238,
            "recall": 0.77184,
            "fmeasure": 0.72924
        },
        "rougeLsum": {
            "precision": 0.7238,
            "recall": 0.77184,
            "fmeasure": 0.72924
        },
        "nist": 5.553657784464301,
        "bleu": 65.2791,
        "nubia": {
            "semantic_relation": 4.51278,
            "contradiction": 0.15199,
            "irrelevancy": 29.47221,
            "logical_agreement": 70.3758,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.63159,
            "nubia_score": 0.86799
        },
        "bertscore": {
            "precision": 0.95208,
            "recall": 0.96378,
            "f1": 0.9568
        },
        "meteor": 0.48753843798966523,
        "bleurt": 0.56116
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.68182,
            "fmeasure": 0.63492
        },
        "rouge2": {
            "precision": 0.25926,
            "recall": 0.31905,
            "fmeasure": 0.28509
        },
        "rougeL": {
            "precision": 0.56667,
            "recall": 0.65152,
            "fmeasure": 0.60317
        },
        "rougeLsum": {
            "precision": 0.56667,
            "recall": 0.65152,
            "fmeasure": 0.60317
        },
        "nist": 1.985878630962767,
        "bleu": 14.99111,
        "nubia": {
            "semantic_relation": 3.47112,
            "contradiction": 0.75186,
            "irrelevancy": 98.86364,
            "logical_agreement": 0.3845,
            "grammar_ref": 4.68733,
            "grammar_hyp": 5.65129,
            "nubia_score": 0.45436
        },
        "bertscore": {
            "precision": 0.79495,
            "recall": 0.89304,
            "f1": 0.84115
        },
        "meteor": 0.3322919387981395,
        "bleurt": -0.46126
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "mT5_base/totto_test",
        "N": 79,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19696969696969696,
            "2": 0.42718446601941745,
            "3": 0.790722761596548
        },
        "rouge1": {
            "precision": 0.8118,
            "recall": 0.76902,
            "fmeasure": 0.78125
        },
        "rouge2": {
            "precision": 0.57119,
            "recall": 0.542,
            "fmeasure": 0.54941
        },
        "rougeL": {
            "precision": 0.66594,
            "recall": 0.62394,
            "fmeasure": 0.63737
        },
        "rougeLsum": {
            "precision": 0.66594,
            "recall": 0.62394,
            "fmeasure": 0.63737
        },
        "nist": 7.535274951407126,
        "bleu": 43.90008,
        "nubia": {
            "semantic_relation": 4.42878,
            "contradiction": 7.01643,
            "irrelevancy": 24.89529,
            "logical_agreement": 68.08828,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.87074,
            "nubia_score": 0.78089
        },
        "bertscore": {
            "precision": 0.94147,
            "recall": 0.93534,
            "f1": 0.93739
        },
        "meteor": 0.40691726346643275,
        "bleurt": 0.41727
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.85205,
            "fmeasure": 0.81257
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.575,
            "fmeasure": 0.5471
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.74153,
            "fmeasure": 0.64646
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.74153,
            "fmeasure": 0.64646
        },
        "nist": 4.289021035981255,
        "bleu": 39.20906,
        "nubia": {
            "semantic_relation": 4.66645,
            "contradiction": 1.82598,
            "irrelevancy": 51.29363,
            "logical_agreement": 46.88039,
            "grammar_ref": 5.72031,
            "grammar_hyp": 5.06041,
            "nubia_score": 0.88125
        },
        "bertscore": {
            "precision": 0.92512,
            "recall": 0.93176,
            "f1": 0.92831
        },
        "meteor": 0.44278641660606033,
        "bleurt": 0.2405
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6981132075471698
        },
        "rouge1": {
            "precision": 0.85079,
            "recall": 0.77284,
            "fmeasure": 0.80186
        },
        "rouge2": {
            "precision": 0.69524,
            "recall": 0.64904,
            "fmeasure": 0.66545
        },
        "rougeL": {
            "precision": 0.76508,
            "recall": 0.70737,
            "fmeasure": 0.72856
        },
        "rougeLsum": {
            "precision": 0.76508,
            "recall": 0.70737,
            "fmeasure": 0.72856
        },
        "nist": 4.094073548869143,
        "bleu": 47.72326,
        "nubia": {
            "semantic_relation": 4.28024,
            "contradiction": 0.38447,
            "irrelevancy": 65.46003,
            "logical_agreement": 34.1555,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.5509,
            "nubia_score": 0.72265
        },
        "bertscore": {
            "precision": 0.95599,
            "recall": 0.93788,
            "f1": 0.94659
        },
        "meteor": 0.38121999659547695,
        "bleurt": 0.46358
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.42857142857142855,
            "3": 0.7368421052631579
        },
        "rouge1": {
            "precision": 0.57873,
            "recall": 0.59687,
            "fmeasure": 0.57843
        },
        "rouge2": {
            "precision": 0.32011,
            "recall": 0.31859,
            "fmeasure": 0.31427
        },
        "rougeL": {
            "precision": 0.3888,
            "recall": 0.40208,
            "fmeasure": 0.38909
        },
        "rougeLsum": {
            "precision": 0.3888,
            "recall": 0.40208,
            "fmeasure": 0.38909
        },
        "nist": 3.436489432153014,
        "bleu": 26.89366,
        "nubia": {
            "semantic_relation": 2.99088,
            "contradiction": 50.55289,
            "irrelevancy": 41.34861,
            "logical_agreement": 8.0985,
            "grammar_ref": 4.17,
            "grammar_hyp": 3.62647,
            "nubia_score": 0.44927
        },
        "bertscore": {
            "precision": 0.88855,
            "recall": 0.88639,
            "f1": 0.88734
        },
        "meteor": 0.29970053346684034,
        "bleurt": -0.11306
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.9285714285714286
        },
        "rouge1": {
            "precision": 0.7698,
            "recall": 0.86656,
            "fmeasure": 0.81203
        },
        "rouge2": {
            "precision": 0.59161,
            "recall": 0.67801,
            "fmeasure": 0.62934
        },
        "rougeL": {
            "precision": 0.67216,
            "recall": 0.75809,
            "fmeasure": 0.7097
        },
        "rougeLsum": {
            "precision": 0.67216,
            "recall": 0.75809,
            "fmeasure": 0.7097
        },
        "nist": 4.993300143735061,
        "bleu": 58.03871,
        "nubia": {
            "semantic_relation": 4.49178,
            "contradiction": 0.76676,
            "irrelevancy": 68.63122,
            "logical_agreement": 30.60202,
            "grammar_ref": 4.0888,
            "grammar_hyp": 4.10755,
            "nubia_score": 0.81677
        },
        "bertscore": {
            "precision": 0.92535,
            "recall": 0.9607,
            "f1": 0.94242
        },
        "meteor": 0.5159527582785386,
        "bleurt": 0.20982
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5454545454545454,
            "3": 0.49122807017543857
        },
        "rouge1": {
            "precision": 0.64643,
            "recall": 0.54032,
            "fmeasure": 0.55304
        },
        "rouge2": {
            "precision": 0.40079,
            "recall": 0.36265,
            "fmeasure": 0.36288
        },
        "rougeL": {
            "precision": 0.52587,
            "recall": 0.4443,
            "fmeasure": 0.45352
        },
        "rougeLsum": {
            "precision": 0.52587,
            "recall": 0.4443,
            "fmeasure": 0.45352
        },
        "nist": 4.035730395460027,
        "bleu": 41.17632,
        "nubia": {
            "semantic_relation": 3.16713,
            "contradiction": 8.11765,
            "irrelevancy": 25.61115,
            "logical_agreement": 66.2712,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.64349,
            "nubia_score": 0.43855
        },
        "bertscore": {
            "precision": 0.85443,
            "recall": 0.86289,
            "f1": 0.85372
        },
        "meteor": 0.3094745049332835,
        "bleurt": -0.3625
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.6666666666666666,
            "3": 0.8125
        },
        "rouge1": {
            "precision": 0.91905,
            "recall": 0.87831,
            "fmeasure": 0.89347
        },
        "rouge2": {
            "precision": 0.86905,
            "recall": 0.82051,
            "fmeasure": 0.83818
        },
        "rougeL": {
            "precision": 0.84127,
            "recall": 0.79497,
            "fmeasure": 0.81301
        },
        "rougeLsum": {
            "precision": 0.84127,
            "recall": 0.79497,
            "fmeasure": 0.81301
        },
        "nist": 4.789533127234701,
        "bleu": 81.73128,
        "nubia": {
            "semantic_relation": 4.12903,
            "contradiction": 1.00688,
            "irrelevancy": 24.94923,
            "logical_agreement": 74.04389,
            "grammar_ref": 4.81259,
            "grammar_hyp": 4.42346,
            "nubia_score": 0.78012
        },
        "bertscore": {
            "precision": 0.97184,
            "recall": 0.95119,
            "f1": 0.95819
        },
        "meteor": 0.4984840996461576,
        "bleurt": 0.2528
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.8666666666666667,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.76368,
            "recall": 0.55563,
            "fmeasure": 0.63703
        },
        "rouge2": {
            "precision": 0.48532,
            "recall": 0.33049,
            "fmeasure": 0.38968
        },
        "rougeL": {
            "precision": 0.63761,
            "recall": 0.46023,
            "fmeasure": 0.52899
        },
        "rougeLsum": {
            "precision": 0.63761,
            "recall": 0.46023,
            "fmeasure": 0.52899
        },
        "nist": 2.601885852957449,
        "bleu": 26.1213,
        "nubia": {
            "semantic_relation": 3.89222,
            "contradiction": 37.34296,
            "irrelevancy": 31.99648,
            "logical_agreement": 30.66056,
            "grammar_ref": 3.79025,
            "grammar_hyp": 4.79458,
            "nubia_score": 0.49959
        },
        "bertscore": {
            "precision": 0.92507,
            "recall": 0.90105,
            "f1": 0.9127
        },
        "meteor": 0.2902639253398069,
        "bleurt": 0.0832
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.33333,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.125,
            "fmeasure": 0.15385
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.33333,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.33333,
            "fmeasure": 0.4
        },
        "nist": 1.1102226191048412,
        "bleu": 10.17528,
        "nubia": {
            "semantic_relation": 3.58171,
            "contradiction": 0.16384,
            "irrelevancy": 1.38184,
            "logical_agreement": 98.45431,
            "grammar_ref": 6.68645,
            "grammar_hyp": 6.28924,
            "nubia_score": 0.69878
        },
        "bertscore": {
            "precision": 0.84409,
            "recall": 0.79178,
            "f1": 0.8171
        },
        "meteor": 0.21851367216868106,
        "bleurt": 0.14193
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8962264150943396
        },
        "rouge1": {
            "precision": 0.93197,
            "recall": 0.87247,
            "fmeasure": 0.89315
        },
        "rouge2": {
            "precision": 0.85773,
            "recall": 0.81569,
            "fmeasure": 0.82922
        },
        "rougeL": {
            "precision": 0.90072,
            "recall": 0.85462,
            "fmeasure": 0.87042
        },
        "rougeLsum": {
            "precision": 0.90072,
            "recall": 0.85462,
            "fmeasure": 0.87042
        },
        "nist": 6.286407284544625,
        "bleu": 73.91268,
        "nubia": {
            "semantic_relation": 4.44606,
            "contradiction": 12.47782,
            "irrelevancy": 4.56191,
            "logical_agreement": 82.96026,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.20085,
            "nubia_score": 0.79241
        },
        "bertscore": {
            "precision": 0.97445,
            "recall": 0.95605,
            "f1": 0.96423
        },
        "meteor": 0.5115800040501928,
        "bleurt": 0.60791
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.875,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.78542,
            "recall": 0.83449,
            "fmeasure": 0.80793
        },
        "rouge2": {
            "precision": 0.67018,
            "recall": 0.72157,
            "fmeasure": 0.69314
        },
        "rougeL": {
            "precision": 0.78542,
            "recall": 0.83449,
            "fmeasure": 0.80793
        },
        "rougeLsum": {
            "precision": 0.78542,
            "recall": 0.83449,
            "fmeasure": 0.80793
        },
        "nist": 3.969327090825214,
        "bleu": 59.05923,
        "nubia": {
            "semantic_relation": 3.4499,
            "contradiction": 50.05251,
            "irrelevancy": 44.05005,
            "logical_agreement": 5.89744,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.23252,
            "nubia_score": 0.6313
        },
        "bertscore": {
            "precision": 0.93863,
            "recall": 0.95226,
            "f1": 0.9423
        },
        "meteor": 0.5216231980907343,
        "bleurt": 0.39172
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "mT5_base/totto_test",
        "N": 36,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.34210526315789475,
            "2": 0.5188679245283019,
            "3": 0.7712609970674487
        },
        "rouge1": {
            "precision": 0.74898,
            "recall": 0.75527,
            "fmeasure": 0.74436
        },
        "rouge2": {
            "precision": 0.55396,
            "recall": 0.55327,
            "fmeasure": 0.5484
        },
        "rougeL": {
            "precision": 0.67062,
            "recall": 0.67368,
            "fmeasure": 0.66591
        },
        "rougeLsum": {
            "precision": 0.67062,
            "recall": 0.67368,
            "fmeasure": 0.66591
        },
        "nist": 6.688210365660445,
        "bleu": 50.948,
        "nubia": {
            "semantic_relation": 4.01864,
            "contradiction": 8.85475,
            "irrelevancy": 33.7522,
            "logical_agreement": 57.39305,
            "grammar_ref": 3.9304,
            "grammar_hyp": 3.84172,
            "nubia_score": 0.75119
        },
        "bertscore": {
            "precision": 0.93681,
            "recall": 0.9377,
            "f1": 0.93592
        },
        "meteor": 0.43218676795295824,
        "bleurt": 0.38603
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.16666666666666666,
            "3": 0.7083333333333334
        },
        "rouge1": {
            "precision": 0.77189,
            "recall": 0.69208,
            "fmeasure": 0.7272
        },
        "rouge2": {
            "precision": 0.5661,
            "recall": 0.51875,
            "fmeasure": 0.53954
        },
        "rougeL": {
            "precision": 0.60967,
            "recall": 0.56634,
            "fmeasure": 0.58576
        },
        "rougeLsum": {
            "precision": 0.60967,
            "recall": 0.56634,
            "fmeasure": 0.58576
        },
        "nist": 4.232148505637239,
        "bleu": 36.8023,
        "nubia": {
            "semantic_relation": 3.69215,
            "contradiction": 39.77539,
            "irrelevancy": 27.19786,
            "logical_agreement": 33.02675,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.29707,
            "nubia_score": 0.59849
        },
        "bertscore": {
            "precision": 0.92012,
            "recall": 0.89058,
            "f1": 0.90499
        },
        "meteor": 0.3081117863011908,
        "bleurt": 0.24118
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.55495,
            "fmeasure": 0.66601
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.27885,
            "fmeasure": 0.34048
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.33242,
            "fmeasure": 0.39921
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.33242,
            "fmeasure": 0.39921
        },
        "nist": 1.7445811856532674,
        "bleu": 11.37929,
        "nubia": {
            "semantic_relation": 3.91266,
            "contradiction": 0.62913,
            "irrelevancy": 39.41958,
            "logical_agreement": 59.95129,
            "grammar_ref": 3.57757,
            "grammar_hyp": 4.47306,
            "nubia_score": 0.64753
        },
        "bertscore": {
            "precision": 0.91116,
            "recall": 0.85406,
            "f1": 0.88168
        },
        "meteor": 0.3009545683848916,
        "bleurt": -0.37247
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.125,
            "3": 0.6944444444444444
        },
        "rouge1": {
            "precision": 0.77017,
            "recall": 0.63343,
            "fmeasure": 0.69101
        },
        "rouge2": {
            "precision": 0.48879,
            "recall": 0.38159,
            "fmeasure": 0.42624
        },
        "rougeL": {
            "precision": 0.62434,
            "recall": 0.50089,
            "fmeasure": 0.55217
        },
        "rougeLsum": {
            "precision": 0.62434,
            "recall": 0.50089,
            "fmeasure": 0.55217
        },
        "nist": 3.2401712507867733,
        "bleu": 30.62872,
        "nubia": {
            "semantic_relation": 3.8468,
            "contradiction": 33.43648,
            "irrelevancy": 17.80636,
            "logical_agreement": 48.75716,
            "grammar_ref": 4.10939,
            "grammar_hyp": 4.27659,
            "nubia_score": 0.60751
        },
        "bertscore": {
            "precision": 0.93715,
            "recall": 0.9039,
            "f1": 0.9186
        },
        "meteor": 0.3306711685762215,
        "bleurt": 0.06359
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4
        },
        "rouge1": {
            "precision": 0.375,
            "recall": 0.5,
            "fmeasure": 0.42857
        },
        "rouge2": {
            "precision": 0.13333,
            "recall": 0.18182,
            "fmeasure": 0.15385
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "nist": 1.1949875002403856,
        "bleu": 9.50724,
        "nubia": {
            "semantic_relation": 3.74434,
            "contradiction": 0.11109,
            "irrelevancy": 99.10376,
            "logical_agreement": 0.78515,
            "grammar_ref": 5.68739,
            "grammar_hyp": 4.11067,
            "nubia_score": 0.67419
        },
        "bertscore": {
            "precision": 0.77781,
            "recall": 0.78187,
            "f1": 0.77983
        },
        "meteor": 0.24592478626970687,
        "bleurt": -0.2065
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "mT5_base/totto_test",
        "N": 114,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23466666666666666,
            "2": 0.5073891625615764,
            "3": 0.770593445527015
        },
        "rouge1": {
            "precision": 0.7363,
            "recall": 0.72167,
            "fmeasure": 0.71609
        },
        "rouge2": {
            "precision": 0.48249,
            "recall": 0.47808,
            "fmeasure": 0.47119
        },
        "rougeL": {
            "precision": 0.60936,
            "recall": 0.60285,
            "fmeasure": 0.59461
        },
        "rougeLsum": {
            "precision": 0.60936,
            "recall": 0.60285,
            "fmeasure": 0.59461
        },
        "nist": 7.471038264055371,
        "bleu": 42.12278,
        "nubia": {
            "semantic_relation": 4.18883,
            "contradiction": 10.6655,
            "irrelevancy": 31.83062,
            "logical_agreement": 57.50387,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.76491,
            "nubia_score": 0.72004
        },
        "bertscore": {
            "precision": 0.92161,
            "recall": 0.91736,
            "f1": 0.91802
        },
        "meteor": 0.387484176854525,
        "bleurt": 0.23946
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.6,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.76496,
            "recall": 0.70597,
            "fmeasure": 0.71808
        },
        "rouge2": {
            "precision": 0.51597,
            "recall": 0.47409,
            "fmeasure": 0.48133
        },
        "rougeL": {
            "precision": 0.72486,
            "recall": 0.67387,
            "fmeasure": 0.68119
        },
        "rougeLsum": {
            "precision": 0.72486,
            "recall": 0.67387,
            "fmeasure": 0.68119
        },
        "nist": 3.7331341084611678,
        "bleu": 48.01903,
        "nubia": {
            "semantic_relation": 3.59487,
            "contradiction": 29.77861,
            "irrelevancy": 45.50253,
            "logical_agreement": 24.71886,
            "grammar_ref": 5.36601,
            "grammar_hyp": 5.42302,
            "nubia_score": 0.51776
        },
        "bertscore": {
            "precision": 0.90248,
            "recall": 0.87524,
            "f1": 0.88568
        },
        "meteor": 0.3535421395032653,
        "bleurt": 0.039
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.875,
            "3": 0.7619047619047619
        },
        "rouge1": {
            "precision": 0.90701,
            "recall": 0.75371,
            "fmeasure": 0.80525
        },
        "rouge2": {
            "precision": 0.73452,
            "recall": 0.62045,
            "fmeasure": 0.65453
        },
        "rougeL": {
            "precision": 0.82256,
            "recall": 0.70221,
            "fmeasure": 0.74159
        },
        "rougeLsum": {
            "precision": 0.82256,
            "recall": 0.70221,
            "fmeasure": 0.74159
        },
        "nist": 5.425773758375693,
        "bleu": 64.94805,
        "nubia": {
            "semantic_relation": 4.03753,
            "contradiction": 24.62916,
            "irrelevancy": 17.7398,
            "logical_agreement": 57.63105,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.70034,
            "nubia_score": 0.69021
        },
        "bertscore": {
            "precision": 0.95113,
            "recall": 0.92404,
            "f1": 0.93315
        },
        "meteor": 0.4225664076855384,
        "bleurt": 0.2247
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.73148,
            "recall": 0.50982,
            "fmeasure": 0.59698
        },
        "rouge2": {
            "precision": 0.5625,
            "recall": 0.37756,
            "fmeasure": 0.44769
        },
        "rougeL": {
            "precision": 0.60185,
            "recall": 0.42374,
            "fmeasure": 0.49355
        },
        "rougeLsum": {
            "precision": 0.60185,
            "recall": 0.42374,
            "fmeasure": 0.49355
        },
        "nist": 2.0657900290687894,
        "bleu": 30.95784,
        "nubia": {
            "semantic_relation": 2.81155,
            "contradiction": 92.44353,
            "irrelevancy": 5.74012,
            "logical_agreement": 1.81635,
            "grammar_ref": 5.19402,
            "grammar_hyp": 6.01793,
            "nubia_score": 0.2418
        },
        "bertscore": {
            "precision": 0.89091,
            "recall": 0.8688,
            "f1": 0.87761
        },
        "meteor": 0.2634655713750038,
        "bleurt": -0.54724
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.80952,
            "recall": 0.80952,
            "fmeasure": 0.80952
        },
        "rouge2": {
            "precision": 0.5641,
            "recall": 0.5641,
            "fmeasure": 0.5641
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.64286,
            "fmeasure": 0.64286
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.64286,
            "fmeasure": 0.64286
        },
        "nist": 4.413165144973171,
        "bleu": 50.95859,
        "nubia": {
            "semantic_relation": 4.70456,
            "contradiction": 0.19154,
            "irrelevancy": 0.55046,
            "logical_agreement": 99.25801,
            "grammar_ref": 5.70189,
            "grammar_hyp": 4.9754,
            "nubia_score": 0.94697
        },
        "bertscore": {
            "precision": 0.96879,
            "recall": 0.96076,
            "f1": 0.96476
        },
        "meteor": 0.4548431613371968,
        "bleurt": 0.48152
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.7857142857142857
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.6912,
            "fmeasure": 0.64231
        },
        "rouge2": {
            "precision": 0.36111,
            "recall": 0.41905,
            "fmeasure": 0.38788
        },
        "rougeL": {
            "precision": 0.48,
            "recall": 0.63492,
            "fmeasure": 0.54601
        },
        "rougeLsum": {
            "precision": 0.48,
            "recall": 0.63492,
            "fmeasure": 0.54601
        },
        "nist": 2.7177509393212422,
        "bleu": 25.07378,
        "nubia": {
            "semantic_relation": 3.95333,
            "contradiction": 0.21873,
            "irrelevancy": 66.9064,
            "logical_agreement": 32.87487,
            "grammar_ref": 4.70322,
            "grammar_hyp": 4.58538,
            "nubia_score": 0.6553
        },
        "bertscore": {
            "precision": 0.88017,
            "recall": 0.90006,
            "f1": 0.89
        },
        "meteor": 0.3813567924032814,
        "bleurt": -0.19956
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6666666666666666,
            "3": 0.782608695652174
        },
        "rouge1": {
            "precision": 0.77089,
            "recall": 0.78193,
            "fmeasure": 0.76937
        },
        "rouge2": {
            "precision": 0.53132,
            "recall": 0.53371,
            "fmeasure": 0.52802
        },
        "rougeL": {
            "precision": 0.64338,
            "recall": 0.66415,
            "fmeasure": 0.64794
        },
        "rougeLsum": {
            "precision": 0.64338,
            "recall": 0.66415,
            "fmeasure": 0.64794
        },
        "nist": 5.0703918058355875,
        "bleu": 44.57294,
        "nubia": {
            "semantic_relation": 4.24172,
            "contradiction": 21.4871,
            "irrelevancy": 38.59736,
            "logical_agreement": 39.91554,
            "grammar_ref": 4.9652,
            "grammar_hyp": 4.99243,
            "nubia_score": 0.72814
        },
        "bertscore": {
            "precision": 0.9287,
            "recall": 0.91626,
            "f1": 0.92232
        },
        "meteor": 0.4133845541093011,
        "bleurt": 0.20622
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8387096774193549
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.74435,
            "fmeasure": 0.81651
        },
        "rouge2": {
            "precision": 0.55,
            "recall": 0.46416,
            "fmeasure": 0.50238
        },
        "rougeL": {
            "precision": 0.77273,
            "recall": 0.63896,
            "fmeasure": 0.69789
        },
        "rougeLsum": {
            "precision": 0.77273,
            "recall": 0.63896,
            "fmeasure": 0.69789
        },
        "nist": 5.273516943446383,
        "bleu": 73.71712,
        "nubia": {
            "semantic_relation": 4.08023,
            "contradiction": 0.42268,
            "irrelevancy": 1.1287,
            "logical_agreement": 98.44862,
            "grammar_ref": 5.38335,
            "grammar_hyp": 5.63741,
            "nubia_score": 0.6771
        },
        "bertscore": {
            "precision": 0.94471,
            "recall": 0.92275,
            "f1": 0.93033
        },
        "meteor": 0.40765892459241493,
        "bleurt": 0.21025
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "mT5_base/totto_test",
        "N": 15,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2978723404255319,
            "2": 0.4074074074074074,
            "3": 0.8580645161290322
        },
        "rouge1": {
            "precision": 0.79895,
            "recall": 0.79571,
            "fmeasure": 0.79168
        },
        "rouge2": {
            "precision": 0.63824,
            "recall": 0.62135,
            "fmeasure": 0.62343
        },
        "rougeL": {
            "precision": 0.74261,
            "recall": 0.73394,
            "fmeasure": 0.73336
        },
        "rougeLsum": {
            "precision": 0.74261,
            "recall": 0.73394,
            "fmeasure": 0.73336
        },
        "nist": 6.59130909097903,
        "bleu": 58.01382,
        "nubia": {
            "semantic_relation": 4.43284,
            "contradiction": 13.1291,
            "irrelevancy": 28.20417,
            "logical_agreement": 58.66672,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.70356,
            "nubia_score": 0.79495
        },
        "bertscore": {
            "precision": 0.96432,
            "recall": 0.96239,
            "f1": 0.96099
        },
        "meteor": 0.46811557442550134,
        "bleurt": 0.35636
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "mT5_base/totto_test",
        "N": 26,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.5161290322580645,
            "3": 0.721030042918455
        },
        "rouge1": {
            "precision": 0.75114,
            "recall": 0.7035,
            "fmeasure": 0.71163
        },
        "rouge2": {
            "precision": 0.52051,
            "recall": 0.48487,
            "fmeasure": 0.49202
        },
        "rougeL": {
            "precision": 0.68171,
            "recall": 0.63889,
            "fmeasure": 0.64665
        },
        "rougeLsum": {
            "precision": 0.68171,
            "recall": 0.63889,
            "fmeasure": 0.64665
        },
        "nist": 5.941379797567561,
        "bleu": 45.53954,
        "nubia": {
            "semantic_relation": 3.9613,
            "contradiction": 7.169,
            "irrelevancy": 40.11426,
            "logical_agreement": 52.71674,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.85097,
            "nubia_score": 0.65316
        },
        "bertscore": {
            "precision": 0.9196,
            "recall": 0.91739,
            "f1": 0.91735
        },
        "meteor": 0.36129864493157465,
        "bleurt": 0.12376
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.25,
            "3": 0.8701298701298701
        },
        "rouge1": {
            "precision": 0.92597,
            "recall": 0.80428,
            "fmeasure": 0.8543
        },
        "rouge2": {
            "precision": 0.72246,
            "recall": 0.64404,
            "fmeasure": 0.67638
        },
        "rougeL": {
            "precision": 0.74207,
            "recall": 0.65311,
            "fmeasure": 0.68712
        },
        "rougeLsum": {
            "precision": 0.74207,
            "recall": 0.65311,
            "fmeasure": 0.68712
        },
        "nist": 5.980393878091041,
        "bleu": 64.92403,
        "nubia": {
            "semantic_relation": 4.45794,
            "contradiction": 20.22082,
            "irrelevancy": 0.51871,
            "logical_agreement": 79.26047,
            "grammar_ref": 4.65184,
            "grammar_hyp": 4.83022,
            "nubia_score": 0.82047
        },
        "bertscore": {
            "precision": 0.97106,
            "recall": 0.95678,
            "f1": 0.96313
        },
        "meteor": 0.48627083262230614,
        "bleurt": 0.53828
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "mT5_base/totto_test",
        "N": 10,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.5,
            "3": 0.926605504587156
        },
        "rouge1": {
            "precision": 0.88155,
            "recall": 0.86972,
            "fmeasure": 0.87199
        },
        "rouge2": {
            "precision": 0.71579,
            "recall": 0.71992,
            "fmeasure": 0.71488
        },
        "rougeL": {
            "precision": 0.77165,
            "recall": 0.76555,
            "fmeasure": 0.76548
        },
        "rougeLsum": {
            "precision": 0.77165,
            "recall": 0.76555,
            "fmeasure": 0.76548
        },
        "nist": 6.656237256339715,
        "bleu": 68.95013,
        "nubia": {
            "semantic_relation": 4.57856,
            "contradiction": 4.91242,
            "irrelevancy": 19.54418,
            "logical_agreement": 75.5434,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.97847,
            "nubia_score": 0.84724
        },
        "bertscore": {
            "precision": 0.96919,
            "recall": 0.96612,
            "f1": 0.96525
        },
        "meteor": 0.49124122676205606,
        "bleurt": 0.59584
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.67582,
            "fmeasure": 0.63547
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.26515,
            "fmeasure": 0.23692
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.48718,
            "fmeasure": 0.43915
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.48718,
            "fmeasure": 0.43915
        },
        "nist": 2.398695339162068,
        "bleu": 9.67265,
        "nubia": {
            "semantic_relation": 3.75732,
            "contradiction": 2.76871,
            "irrelevancy": 69.42267,
            "logical_agreement": 27.80861,
            "grammar_ref": 5.03839,
            "grammar_hyp": 5.14418,
            "nubia_score": 0.51428
        },
        "bertscore": {
            "precision": 0.88292,
            "recall": 0.87839,
            "f1": 0.88065
        },
        "meteor": 0.31733606182869906,
        "bleurt": 0.04361
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.6127,
            "recall": 0.74868,
            "fmeasure": 0.67021
        },
        "rouge2": {
            "precision": 0.32326,
            "recall": 0.42774,
            "fmeasure": 0.3642
        },
        "rougeL": {
            "precision": 0.48413,
            "recall": 0.63624,
            "fmeasure": 0.54508
        },
        "rougeLsum": {
            "precision": 0.48413,
            "recall": 0.63624,
            "fmeasure": 0.54508
        },
        "nist": 3.297894848540237,
        "bleu": 14.08213,
        "nubia": {
            "semantic_relation": 3.45765,
            "contradiction": 38.03139,
            "irrelevancy": 37.86255,
            "logical_agreement": 24.10606,
            "grammar_ref": 4.76014,
            "grammar_hyp": 4.58458,
            "nubia_score": 0.49243
        },
        "bertscore": {
            "precision": 0.86166,
            "recall": 0.91889,
            "f1": 0.88543
        },
        "meteor": 0.3709708671011582,
        "bleurt": -0.18356
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.4782608695652174
        },
        "rouge1": {
            "precision": 0.57895,
            "recall": 0.31429,
            "fmeasure": 0.40741
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.11765,
            "fmeasure": 0.15385
        },
        "rougeL": {
            "precision": 0.42105,
            "recall": 0.22857,
            "fmeasure": 0.2963
        },
        "rougeLsum": {
            "precision": 0.42105,
            "recall": 0.22857,
            "fmeasure": 0.2963
        },
        "nist": 0.5834212523653595,
        "bleu": 5.77625,
        "nubia": {
            "semantic_relation": 3.1664,
            "contradiction": 33.92267,
            "irrelevancy": 65.33462,
            "logical_agreement": 0.74271,
            "grammar_ref": 5.19058,
            "grammar_hyp": 4.75609,
            "nubia_score": 0.25179
        },
        "bertscore": {
            "precision": 0.89591,
            "recall": 0.84745,
            "f1": 0.8687
        },
        "meteor": 0.23263384646108526,
        "bleurt": -0.36295
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5625,
            "3": 0.9285714285714286
        },
        "rouge1": {
            "precision": 0.75361,
            "recall": 0.78162,
            "fmeasure": 0.76002
        },
        "rouge2": {
            "precision": 0.62103,
            "recall": 0.62962,
            "fmeasure": 0.61844
        },
        "rougeL": {
            "precision": 0.71583,
            "recall": 0.72094,
            "fmeasure": 0.71182
        },
        "rougeLsum": {
            "precision": 0.71583,
            "recall": 0.72094,
            "fmeasure": 0.71182
        },
        "nist": 4.910910994582479,
        "bleu": 52.80972,
        "nubia": {
            "semantic_relation": 3.98434,
            "contradiction": 28.3018,
            "irrelevancy": 24.47384,
            "logical_agreement": 47.22436,
            "grammar_ref": 4.44265,
            "grammar_hyp": 4.23956,
            "nubia_score": 0.68037
        },
        "bertscore": {
            "precision": 0.94516,
            "recall": 0.93962,
            "f1": 0.93777
        },
        "meteor": 0.43193536759520024,
        "bleurt": 0.34326
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.82639,
            "fmeasure": 0.84926
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.60714,
            "fmeasure": 0.62381
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.71528,
            "fmeasure": 0.73162
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.71528,
            "fmeasure": 0.73162
        },
        "nist": 3.4905844441572156,
        "bleu": 59.69492,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.27456,
            "irrelevancy": 0.45406,
            "logical_agreement": 99.27139,
            "grammar_ref": 6.12307,
            "grammar_hyp": 6.28318,
            "nubia_score": 0.9848
        },
        "bertscore": {
            "precision": 0.97429,
            "recall": 0.97429,
            "f1": 0.97429
        },
        "meteor": 0.9304347826086956,
        "bleurt": 0.74386
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5454545454545454,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.78175,
            "recall": 0.74229,
            "fmeasure": 0.74601
        },
        "rouge2": {
            "precision": 0.41608,
            "recall": 0.45826,
            "fmeasure": 0.43157
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.74753,
            "fmeasure": 0.72089
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.74753,
            "fmeasure": 0.72089
        },
        "nist": 4.116701122742064,
        "bleu": 35.45207,
        "nubia": {
            "semantic_relation": 4.03615,
            "contradiction": 0.28435,
            "irrelevancy": 47.07648,
            "logical_agreement": 52.63916,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.29341,
            "nubia_score": 0.70972
        },
        "bertscore": {
            "precision": 0.91665,
            "recall": 0.93061,
            "f1": 0.91524
        },
        "meteor": 0.411231671144637,
        "bleurt": 0.16338
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07142857142857142,
            "2": 0.8,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.81085,
            "recall": 0.73508,
            "fmeasure": 0.76589
        },
        "rouge2": {
            "precision": 0.49471,
            "recall": 0.46979,
            "fmeasure": 0.47853
        },
        "rougeL": {
            "precision": 0.58264,
            "recall": 0.55623,
            "fmeasure": 0.56607
        },
        "rougeLsum": {
            "precision": 0.58264,
            "recall": 0.55623,
            "fmeasure": 0.56607
        },
        "nist": 4.635420931078138,
        "bleu": 31.58264,
        "nubia": {
            "semantic_relation": 4.31725,
            "contradiction": 3.16508,
            "irrelevancy": 33.78117,
            "logical_agreement": 63.05374,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.66766,
            "nubia_score": 0.68993
        },
        "bertscore": {
            "precision": 0.9245,
            "recall": 0.91951,
            "f1": 0.92181
        },
        "meteor": 0.3646737297631686,
        "bleurt": 0.28939
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "nist": 4.01117167855772,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.66362,
            "contradiction": 2.49017,
            "irrelevancy": 1.24853,
            "logical_agreement": 96.2613,
            "grammar_ref": 6.06085,
            "grammar_hyp": 5.70692,
            "nubia_score": 0.90186
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.77386
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "nist": 2.1055161915432032,
        "bleu": 41.11336,
        "nubia": {
            "semantic_relation": 4.01521,
            "contradiction": 10.23484,
            "irrelevancy": 37.69891,
            "logical_agreement": 52.06625,
            "grammar_ref": 7.84225,
            "grammar_hyp": 7.31486,
            "nubia_score": 0.66591
        },
        "bertscore": {
            "precision": 0.93887,
            "recall": 0.95113,
            "f1": 0.94496
        },
        "meteor": 0.4231469901582543,
        "bleurt": 0.18287
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.76
        },
        "rouge1": {
            "precision": 0.76312,
            "recall": 0.72619,
            "fmeasure": 0.73942
        },
        "rouge2": {
            "precision": 0.52765,
            "recall": 0.47399,
            "fmeasure": 0.49547
        },
        "rougeL": {
            "precision": 0.71767,
            "recall": 0.67989,
            "fmeasure": 0.69339
        },
        "rougeLsum": {
            "precision": 0.71767,
            "recall": 0.67989,
            "fmeasure": 0.69339
        },
        "nist": 4.366549531689148,
        "bleu": 47.62525,
        "nubia": {
            "semantic_relation": 3.96207,
            "contradiction": 22.42457,
            "irrelevancy": 27.17381,
            "logical_agreement": 50.40162,
            "grammar_ref": 4.98306,
            "grammar_hyp": 4.53407,
            "nubia_score": 0.67732
        },
        "bertscore": {
            "precision": 0.93689,
            "recall": 0.92813,
            "f1": 0.93226
        },
        "meteor": 0.3979670148977135,
        "bleurt": 0.34395
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.82143,
            "recall": 0.83791,
            "fmeasure": 0.82937
        },
        "rouge2": {
            "precision": 0.64103,
            "recall": 0.6337,
            "fmeasure": 0.63723
        },
        "rougeL": {
            "precision": 0.80952,
            "recall": 0.79524,
            "fmeasure": 0.80213
        },
        "rougeLsum": {
            "precision": 0.80952,
            "recall": 0.79524,
            "fmeasure": 0.80213
        },
        "nist": 3.7520378449142298,
        "bleu": 58.61517,
        "nubia": {
            "semantic_relation": 4.83868,
            "contradiction": 0.1267,
            "irrelevancy": 16.78336,
            "logical_agreement": 83.08993,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.49182,
            "nubia_score": 0.94145
        },
        "bertscore": {
            "precision": 0.95796,
            "recall": 0.94608,
            "f1": 0.95194
        },
        "meteor": 0.4372058978444577,
        "bleurt": 0.75132
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.875,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "nist": 3.0286497677077553,
        "bleu": 70.16879,
        "nubia": {
            "semantic_relation": 4.89761,
            "contradiction": 0.83309,
            "irrelevancy": 31.2673,
            "logical_agreement": 67.89961,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.86831,
            "nubia_score": 0.98957
        },
        "bertscore": {
            "precision": 0.98524,
            "recall": 0.9921,
            "f1": 0.98866
        },
        "meteor": 0.5613051214200641,
        "bleurt": 0.76221
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.38095238095238093,
            "3": 0.7555555555555555
        },
        "rouge1": {
            "precision": 0.77131,
            "recall": 0.75554,
            "fmeasure": 0.7588
        },
        "rouge2": {
            "precision": 0.57867,
            "recall": 0.5868,
            "fmeasure": 0.57943
        },
        "rougeL": {
            "precision": 0.68265,
            "recall": 0.70659,
            "fmeasure": 0.69115
        },
        "rougeLsum": {
            "precision": 0.68265,
            "recall": 0.70659,
            "fmeasure": 0.69115
        },
        "nist": 5.247983238201804,
        "bleu": 49.34427,
        "nubia": {
            "semantic_relation": 4.14516,
            "contradiction": 14.97205,
            "irrelevancy": 32.5771,
            "logical_agreement": 52.45085,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.75264,
            "nubia_score": 0.69745
        },
        "bertscore": {
            "precision": 0.93817,
            "recall": 0.92927,
            "f1": 0.93237
        },
        "meteor": 0.436251894311862,
        "bleurt": 0.30403
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8421052631578947
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.79545,
            "fmeasure": 0.87482
        },
        "rouge2": {
            "precision": 0.81667,
            "recall": 0.67727,
            "fmeasure": 0.72843
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.79545,
            "fmeasure": 0.87482
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.79545,
            "fmeasure": 0.87482
        },
        "nist": 3.8438138834216162,
        "bleu": 70.86735,
        "nubia": {
            "semantic_relation": 4.3606,
            "contradiction": 1.19225,
            "irrelevancy": 2.2746,
            "logical_agreement": 96.53316,
            "grammar_ref": 5.62679,
            "grammar_hyp": 6.16256,
            "nubia_score": 0.71585
        },
        "bertscore": {
            "precision": 0.91747,
            "recall": 0.8947,
            "f1": 0.9046
        },
        "meteor": 0.4358318132981426,
        "bleurt": 0.38063
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.72464,
            "recall": 0.82038,
            "fmeasure": 0.76912
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.59048,
            "fmeasure": 0.567
        },
        "rougeL": {
            "precision": 0.3913,
            "recall": 0.42208,
            "fmeasure": 0.40606
        },
        "rougeLsum": {
            "precision": 0.3913,
            "recall": 0.42208,
            "fmeasure": 0.40606
        },
        "nist": 3.5097612095823987,
        "bleu": 49.50861,
        "nubia": {
            "semantic_relation": 4.65637,
            "contradiction": 0.18187,
            "irrelevancy": 2.47575,
            "logical_agreement": 97.34238,
            "grammar_ref": 5.09304,
            "grammar_hyp": 3.94671,
            "nubia_score": 0.99239
        },
        "bertscore": {
            "precision": 0.93974,
            "recall": 0.94781,
            "f1": 0.94376
        },
        "meteor": 0.4157895527996179,
        "bleurt": 0.27975
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.5625,
            "3": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.87559,
            "recall": 0.87029,
            "fmeasure": 0.87011
        },
        "rouge2": {
            "precision": 0.69205,
            "recall": 0.67878,
            "fmeasure": 0.68315
        },
        "rougeL": {
            "precision": 0.71863,
            "recall": 0.70601,
            "fmeasure": 0.70981
        },
        "rougeLsum": {
            "precision": 0.71863,
            "recall": 0.70601,
            "fmeasure": 0.70981
        },
        "nist": 5.811511019709526,
        "bleu": 53.13096,
        "nubia": {
            "semantic_relation": 4.36016,
            "contradiction": 8.17001,
            "irrelevancy": 16.4207,
            "logical_agreement": 75.40929,
            "grammar_ref": 4.87577,
            "grammar_hyp": 4.98659,
            "nubia_score": 0.7642
        },
        "bertscore": {
            "precision": 0.94924,
            "recall": 0.95798,
            "f1": 0.95301
        },
        "meteor": 0.47529837983037587,
        "bleurt": 0.42531
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.7714285714285715
        },
        "rouge1": {
            "precision": 0.80733,
            "recall": 0.76573,
            "fmeasure": 0.77824
        },
        "rouge2": {
            "precision": 0.68551,
            "recall": 0.6352,
            "fmeasure": 0.64788
        },
        "rougeL": {
            "precision": 0.60594,
            "recall": 0.5567,
            "fmeasure": 0.57367
        },
        "rougeLsum": {
            "precision": 0.60594,
            "recall": 0.5567,
            "fmeasure": 0.57367
        },
        "nist": 5.197024131085335,
        "bleu": 51.7989,
        "nubia": {
            "semantic_relation": 4.39489,
            "contradiction": 13.58414,
            "irrelevancy": 23.04203,
            "logical_agreement": 63.37383,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.37002,
            "nubia_score": 0.77897
        },
        "bertscore": {
            "precision": 0.93372,
            "recall": 0.92542,
            "f1": 0.92654
        },
        "meteor": 0.42685547849553246,
        "bleurt": 0.30664
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.6521739130434783
        },
        "rouge1": {
            "precision": 0.58056,
            "recall": 0.75675,
            "fmeasure": 0.6567
        },
        "rouge2": {
            "precision": 0.28173,
            "recall": 0.37692,
            "fmeasure": 0.32224
        },
        "rougeL": {
            "precision": 0.475,
            "recall": 0.61916,
            "fmeasure": 0.5373
        },
        "rougeLsum": {
            "precision": 0.475,
            "recall": 0.61916,
            "fmeasure": 0.5373
        },
        "nist": 2.966088371704075,
        "bleu": 16.71501,
        "nubia": {
            "semantic_relation": 4.18677,
            "contradiction": 0.18206,
            "irrelevancy": 71.34891,
            "logical_agreement": 28.46903,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.38905,
            "nubia_score": 0.703
        },
        "bertscore": {
            "precision": 0.9094,
            "recall": 0.92472,
            "f1": 0.91665
        },
        "meteor": 0.3929246801496539,
        "bleurt": 0.0696
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2857142857142857,
            "3": 0.7027027027027027
        },
        "rouge1": {
            "precision": 0.67949,
            "recall": 0.70349,
            "fmeasure": 0.68704
        },
        "rouge2": {
            "precision": 0.46471,
            "recall": 0.50048,
            "fmeasure": 0.47868
        },
        "rougeL": {
            "precision": 0.50866,
            "recall": 0.55492,
            "fmeasure": 0.52714
        },
        "rougeLsum": {
            "precision": 0.50866,
            "recall": 0.55492,
            "fmeasure": 0.52714
        },
        "nist": 3.4485743815720604,
        "bleu": 28.7163,
        "nubia": {
            "semantic_relation": 3.85962,
            "contradiction": 0.22077,
            "irrelevancy": 3.03512,
            "logical_agreement": 96.74411,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.59996,
            "nubia_score": 0.66163
        },
        "bertscore": {
            "precision": 0.89522,
            "recall": 0.89855,
            "f1": 0.89534
        },
        "meteor": 0.36083134849884224,
        "bleurt": 0.0683
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.47058823529411764,
            "3": 0.8125
        },
        "rouge1": {
            "precision": 0.67934,
            "recall": 0.73214,
            "fmeasure": 0.68839
        },
        "rouge2": {
            "precision": 0.50463,
            "recall": 0.51029,
            "fmeasure": 0.4957
        },
        "rougeL": {
            "precision": 0.56725,
            "recall": 0.63161,
            "fmeasure": 0.58363
        },
        "rougeLsum": {
            "precision": 0.56725,
            "recall": 0.63161,
            "fmeasure": 0.58363
        },
        "nist": 3.6074944110366425,
        "bleu": 35.70195,
        "nubia": {
            "semantic_relation": 3.86237,
            "contradiction": 23.89143,
            "irrelevancy": 42.45922,
            "logical_agreement": 33.64934,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.26813,
            "nubia_score": 0.68941
        },
        "bertscore": {
            "precision": 0.9283,
            "recall": 0.93939,
            "f1": 0.93062
        },
        "meteor": 0.3286216184368851,
        "bleurt": 0.37263
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6666666666666666,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.74288,
            "recall": 0.75814,
            "fmeasure": 0.74944
        },
        "rouge2": {
            "precision": 0.54314,
            "recall": 0.55102,
            "fmeasure": 0.54629
        },
        "rougeL": {
            "precision": 0.58405,
            "recall": 0.59674,
            "fmeasure": 0.58977
        },
        "rougeLsum": {
            "precision": 0.58405,
            "recall": 0.59674,
            "fmeasure": 0.58977
        },
        "nist": 4.203197012109597,
        "bleu": 45.4111,
        "nubia": {
            "semantic_relation": 4.26362,
            "contradiction": 0.34279,
            "irrelevancy": 22.46819,
            "logical_agreement": 77.18902,
            "grammar_ref": 4.42501,
            "grammar_hyp": 3.91482,
            "nubia_score": 0.76683
        },
        "bertscore": {
            "precision": 0.92252,
            "recall": 0.91836,
            "f1": 0.91987
        },
        "meteor": 0.39026572721049646,
        "bleurt": 0.26422
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.875,
            "fmeasure": 0.875
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "nist": 4.688416462507053,
        "bleu": 87.25129,
        "nubia": {
            "semantic_relation": 4.91372,
            "contradiction": 0.60581,
            "irrelevancy": 5.68424,
            "logical_agreement": 93.70995,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.58917,
            "nubia_score": 0.95428
        },
        "bertscore": {
            "precision": 0.97138,
            "recall": 0.97922,
            "f1": 0.97528
        },
        "meteor": 0.6075503159367284,
        "bleurt": 0.60787
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.62879,
            "fmeasure": 0.67909
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.28889,
            "fmeasure": 0.30513
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.48485,
            "fmeasure": 0.44796
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.48485,
            "fmeasure": 0.44796
        },
        "nist": 3.479725770024594,
        "bleu": 20.68721,
        "nubia": {
            "semantic_relation": 3.67723,
            "contradiction": 0.4405,
            "irrelevancy": 15.37822,
            "logical_agreement": 84.18128,
            "grammar_ref": 5.84412,
            "grammar_hyp": 6.10217,
            "nubia_score": 0.49839
        },
        "bertscore": {
            "precision": 0.91469,
            "recall": 0.92599,
            "f1": 0.90537
        },
        "meteor": 0.31542929166340156,
        "bleurt": -0.21552
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.8222222222222222
        },
        "rouge1": {
            "precision": 0.68047,
            "recall": 0.77072,
            "fmeasure": 0.71679
        },
        "rouge2": {
            "precision": 0.49935,
            "recall": 0.57282,
            "fmeasure": 0.52766
        },
        "rougeL": {
            "precision": 0.60269,
            "recall": 0.68679,
            "fmeasure": 0.63615
        },
        "rougeLsum": {
            "precision": 0.60269,
            "recall": 0.68679,
            "fmeasure": 0.63615
        },
        "nist": 4.207003662720424,
        "bleu": 43.02723,
        "nubia": {
            "semantic_relation": 3.93388,
            "contradiction": 38.34189,
            "irrelevancy": 34.63128,
            "logical_agreement": 27.02683,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.1101,
            "nubia_score": 0.6628
        },
        "bertscore": {
            "precision": 0.92024,
            "recall": 0.94355,
            "f1": 0.92904
        },
        "meteor": 0.4281660970082915,
        "bleurt": 0.34212
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.8305084745762712
        },
        "rouge1": {
            "precision": 0.87605,
            "recall": 0.87263,
            "fmeasure": 0.87303
        },
        "rouge2": {
            "precision": 0.73194,
            "recall": 0.73446,
            "fmeasure": 0.73242
        },
        "rougeL": {
            "precision": 0.85769,
            "recall": 0.86012,
            "fmeasure": 0.85802
        },
        "rougeLsum": {
            "precision": 0.85769,
            "recall": 0.86012,
            "fmeasure": 0.85802
        },
        "nist": 4.997861160794941,
        "bleu": 56.07313,
        "nubia": {
            "semantic_relation": 4.43698,
            "contradiction": 0.60623,
            "irrelevancy": 0.81988,
            "logical_agreement": 98.57388,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.77829,
            "nubia_score": 0.80338
        },
        "bertscore": {
            "precision": 0.98359,
            "recall": 0.97219,
            "f1": 0.97774
        },
        "meteor": 0.44576682866230893,
        "bleurt": 0.75289
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.0,
            "3": 0.6206896551724138
        },
        "rouge1": {
            "precision": 0.41631,
            "recall": 0.56679,
            "fmeasure": 0.47239
        },
        "rouge2": {
            "precision": 0.1562,
            "recall": 0.21738,
            "fmeasure": 0.17239
        },
        "rougeL": {
            "precision": 0.36823,
            "recall": 0.4441,
            "fmeasure": 0.38636
        },
        "rougeLsum": {
            "precision": 0.36823,
            "recall": 0.4441,
            "fmeasure": 0.38636
        },
        "nist": 2.402452639224013,
        "bleu": 16.66576,
        "nubia": {
            "semantic_relation": 3.31324,
            "contradiction": 37.81319,
            "irrelevancy": 29.11898,
            "logical_agreement": 33.06783,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.4642,
            "nubia_score": 0.47429
        },
        "bertscore": {
            "precision": 0.84153,
            "recall": 0.88197,
            "f1": 0.85405
        },
        "meteor": 0.2707264387481152,
        "bleurt": -0.10736
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.58182,
            "fmeasure": 0.65497
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.32222,
            "fmeasure": 0.36765
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.58182,
            "fmeasure": 0.65497
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.58182,
            "fmeasure": 0.65497
        },
        "nist": 1.6859821415801794,
        "bleu": 18.70274,
        "nubia": {
            "semantic_relation": 4.76896,
            "contradiction": 0.36801,
            "irrelevancy": 0.48887,
            "logical_agreement": 99.14313,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.51085,
            "nubia_score": 0.97047
        },
        "bertscore": {
            "precision": 0.96794,
            "recall": 0.94168,
            "f1": 0.95463
        },
        "meteor": 0.41354683345108245,
        "bleurt": 0.61365
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.5,
            "3": 0.92
        },
        "rouge1": {
            "precision": 0.90891,
            "recall": 0.87979,
            "fmeasure": 0.8938
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.62368,
            "fmeasure": 0.63099
        },
        "rougeL": {
            "precision": 0.77733,
            "recall": 0.75678,
            "fmeasure": 0.76667
        },
        "rougeLsum": {
            "precision": 0.77733,
            "recall": 0.75678,
            "fmeasure": 0.76667
        },
        "nist": 4.541788519032162,
        "bleu": 43.92176,
        "nubia": {
            "semantic_relation": 4.72139,
            "contradiction": 0.19076,
            "irrelevancy": 0.49311,
            "logical_agreement": 99.31613,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.5134,
            "nubia_score": 0.9251
        },
        "bertscore": {
            "precision": 0.97065,
            "recall": 0.96492,
            "f1": 0.96739
        },
        "meteor": 0.43736286253584683,
        "bleurt": 0.54369
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0975609756097561,
            "2": 0.28,
            "3": 0.8260869565217391
        },
        "rouge1": {
            "precision": 0.62822,
            "recall": 0.64414,
            "fmeasure": 0.62633
        },
        "rouge2": {
            "precision": 0.41358,
            "recall": 0.40954,
            "fmeasure": 0.40594
        },
        "rougeL": {
            "precision": 0.54478,
            "recall": 0.54175,
            "fmeasure": 0.53455
        },
        "rougeLsum": {
            "precision": 0.54478,
            "recall": 0.54175,
            "fmeasure": 0.53455
        },
        "nist": 4.529075525914673,
        "bleu": 36.42415,
        "nubia": {
            "semantic_relation": 3.45036,
            "contradiction": 1.85586,
            "irrelevancy": 64.23609,
            "logical_agreement": 33.90805,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.73254,
            "nubia_score": 0.53421
        },
        "bertscore": {
            "precision": 0.88308,
            "recall": 0.89713,
            "f1": 0.88678
        },
        "meteor": 0.34847035532203124,
        "bleurt": -0.05665
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.6086956521739131,
            "3": 0.47058823529411764
        },
        "rouge1": {
            "precision": 0.53643,
            "recall": 0.61877,
            "fmeasure": 0.56127
        },
        "rouge2": {
            "precision": 0.21277,
            "recall": 0.28509,
            "fmeasure": 0.23679
        },
        "rougeL": {
            "precision": 0.46058,
            "recall": 0.53066,
            "fmeasure": 0.48248
        },
        "rougeLsum": {
            "precision": 0.46058,
            "recall": 0.53066,
            "fmeasure": 0.48248
        },
        "nist": 3.3745261355036456,
        "bleu": 9.39884,
        "nubia": {
            "semantic_relation": 3.91915,
            "contradiction": 0.28463,
            "irrelevancy": 34.05342,
            "logical_agreement": 65.66196,
            "grammar_ref": 4.61531,
            "grammar_hyp": 4.12466,
            "nubia_score": 0.73666
        },
        "bertscore": {
            "precision": 0.86898,
            "recall": 0.89089,
            "f1": 0.87669
        },
        "meteor": 0.2851010991559123,
        "bleurt": 0.08189
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.90476,
            "recall": 0.98333,
            "fmeasure": 0.94228
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.91033,
            "fmeasure": 0.87
        },
        "rougeL": {
            "precision": 0.90476,
            "recall": 0.98333,
            "fmeasure": 0.94228
        },
        "rougeLsum": {
            "precision": 0.90476,
            "recall": 0.98333,
            "fmeasure": 0.94228
        },
        "nist": 4.42671590035255,
        "bleu": 80.37775,
        "nubia": {
            "semantic_relation": 4.46087,
            "contradiction": 9.20511,
            "irrelevancy": 74.0107,
            "logical_agreement": 16.7842,
            "grammar_ref": 3.98302,
            "grammar_hyp": 4.29738,
            "nubia_score": 0.74005
        },
        "bertscore": {
            "precision": 0.97364,
            "recall": 0.99148,
            "f1": 0.97774
        },
        "meteor": 0.5771004211718296,
        "bleurt": 0.35978
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.926829268292683
        },
        "rouge1": {
            "precision": 0.97222,
            "recall": 0.91634,
            "fmeasure": 0.94115
        },
        "rouge2": {
            "precision": 0.94662,
            "recall": 0.89242,
            "fmeasure": 0.91633
        },
        "rougeL": {
            "precision": 0.97222,
            "recall": 0.91634,
            "fmeasure": 0.94115
        },
        "rougeLsum": {
            "precision": 0.97222,
            "recall": 0.91634,
            "fmeasure": 0.94115
        },
        "nist": 5.45592403310349,
        "bleu": 82.68119,
        "nubia": {
            "semantic_relation": 4.6558,
            "contradiction": 0.25137,
            "irrelevancy": 8.76846,
            "logical_agreement": 90.98017,
            "grammar_ref": 5.18336,
            "grammar_hyp": 5.11893,
            "nubia_score": 0.88669
        },
        "bertscore": {
            "precision": 0.99576,
            "recall": 0.98403,
            "f1": 0.98914
        },
        "meteor": 0.5898569848157251,
        "bleurt": 0.71471
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.7
        },
        "rouge1": {
            "precision": 0.49481,
            "recall": 0.51225,
            "fmeasure": 0.48
        },
        "rouge2": {
            "precision": 0.31702,
            "recall": 0.33518,
            "fmeasure": 0.31062
        },
        "rougeL": {
            "precision": 0.41545,
            "recall": 0.39459,
            "fmeasure": 0.38986
        },
        "rougeLsum": {
            "precision": 0.41545,
            "recall": 0.39459,
            "fmeasure": 0.38986
        },
        "nist": 3.5136699403609737,
        "bleu": 36.69138,
        "nubia": {
            "semantic_relation": 3.05312,
            "contradiction": 32.38686,
            "irrelevancy": 49.54844,
            "logical_agreement": 18.0647,
            "grammar_ref": 5.06451,
            "grammar_hyp": 4.99811,
            "nubia_score": 0.40627
        },
        "bertscore": {
            "precision": 0.88499,
            "recall": 0.89673,
            "f1": 0.89015
        },
        "meteor": 0.3004889973865658,
        "bleurt": -0.3058
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5294117647058824
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.46072,
            "fmeasure": 0.54382
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.15657,
            "fmeasure": 0.18618
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.19832,
            "fmeasure": 0.23369
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.19832,
            "fmeasure": 0.23369
        },
        "nist": 2.0845914450340994,
        "bleu": 8.50942,
        "nubia": {
            "semantic_relation": 3.51036,
            "contradiction": 0.96324,
            "irrelevancy": 18.57955,
            "logical_agreement": 80.45722,
            "grammar_ref": 4.86737,
            "grammar_hyp": 5.70109,
            "nubia_score": 0.40313
        },
        "bertscore": {
            "precision": 0.83055,
            "recall": 0.79833,
            "f1": 0.81412
        },
        "meteor": 0.2596890560942003,
        "bleurt": -0.35309
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.0,
            "3": 0.65
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.59952,
            "fmeasure": 0.62975
        },
        "rouge2": {
            "precision": 0.40972,
            "recall": 0.36726,
            "fmeasure": 0.38617
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.57828,
            "fmeasure": 0.59839
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.57828,
            "fmeasure": 0.59839
        },
        "nist": 3.5955327436389823,
        "bleu": 32.19071,
        "nubia": {
            "semantic_relation": 4.28479,
            "contradiction": 0.79591,
            "irrelevancy": 49.67093,
            "logical_agreement": 49.53316,
            "grammar_ref": 5.35082,
            "grammar_hyp": 5.02871,
            "nubia_score": 0.87683
        },
        "bertscore": {
            "precision": 0.92381,
            "recall": 0.90025,
            "f1": 0.91185
        },
        "meteor": 0.3502962613619016,
        "bleurt": 0.25574
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.27381,
            "fmeasure": 0.35
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.16667,
            "recall": 0.09127,
            "fmeasure": 0.11667
        },
        "rougeLsum": {
            "precision": 0.16667,
            "recall": 0.09127,
            "fmeasure": 0.11667
        },
        "nist": 0.2610807622399525,
        "bleu": 4.88087,
        "nubia": {
            "semantic_relation": 3.10114,
            "contradiction": 0.39931,
            "irrelevancy": 30.69539,
            "logical_agreement": 68.9053,
            "grammar_ref": 5.77141,
            "grammar_hyp": 8.13281,
            "nubia_score": 0.22479
        },
        "bertscore": {
            "precision": 0.85683,
            "recall": 0.84295,
            "f1": 0.84983
        },
        "meteor": 0.11914893617021279,
        "bleurt": -0.25444
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.08333333333333333,
            "3": 0.38461538461538464
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.32909,
            "fmeasure": 0.46222
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.13056,
            "fmeasure": 0.18751
        },
        "rougeL": {
            "precision": 0.59259,
            "recall": 0.24072,
            "fmeasure": 0.34216
        },
        "rougeLsum": {
            "precision": 0.59259,
            "recall": 0.24072,
            "fmeasure": 0.34216
        },
        "nist": 0.193107577443919,
        "bleu": 6.25093,
        "nubia": {
            "semantic_relation": 3.28458,
            "contradiction": 3.26552,
            "irrelevancy": 95.85193,
            "logical_agreement": 0.88255,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.63138,
            "nubia_score": 0.23866
        },
        "bertscore": {
            "precision": 0.88831,
            "recall": 0.81195,
            "f1": 0.84841
        },
        "meteor": 0.17366086577616233,
        "bleurt": -0.63649
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4666666666666667
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.52941,
            "fmeasure": 0.5625
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.25,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.41176,
            "fmeasure": 0.4375
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.41176,
            "fmeasure": 0.4375
        },
        "nist": 2.053656798309003,
        "bleu": 24.79798,
        "nubia": {
            "semantic_relation": 3.34671,
            "contradiction": 29.74159,
            "irrelevancy": 57.79893,
            "logical_agreement": 12.45948,
            "grammar_ref": 3.58521,
            "grammar_hyp": 2.80984,
            "nubia_score": 0.60297
        },
        "bertscore": {
            "precision": 0.86957,
            "recall": 0.85886,
            "f1": 0.86418
        },
        "meteor": 0.24368954577157195,
        "bleurt": -0.00384
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.3764992953429935,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.91462
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.84259,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.54762,
            "fmeasure": 0.60073
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "nist": 2.9487445430153727,
        "bleu": 51.31108,
        "nubia": {
            "semantic_relation": 4.91614,
            "contradiction": 0.68707,
            "irrelevancy": 0.60509,
            "logical_agreement": 98.70784,
            "grammar_ref": 5.94246,
            "grammar_hyp": 6.87586,
            "nubia_score": 0.87589
        },
        "bertscore": {
            "precision": 0.98804,
            "recall": 0.97187,
            "f1": 0.97989
        },
        "meteor": 0.4561301812414779,
        "bleurt": 0.59368
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.50789957099271,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.89367
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.90456,
            "recall": 0.71832,
            "fmeasure": 0.78902
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.56273,
            "fmeasure": 0.60949
        },
        "rougeL": {
            "precision": 0.75641,
            "recall": 0.6326,
            "fmeasure": 0.68032
        },
        "rougeLsum": {
            "precision": 0.75641,
            "recall": 0.6326,
            "fmeasure": 0.68032
        },
        "nist": 3.705673658197534,
        "bleu": 51.59163,
        "nubia": {
            "semantic_relation": 4.34872,
            "contradiction": 0.41237,
            "irrelevancy": 0.58279,
            "logical_agreement": 99.00484,
            "grammar_ref": 5.26806,
            "grammar_hyp": 4.82322,
            "nubia_score": 0.79553
        },
        "bertscore": {
            "precision": 0.96065,
            "recall": 0.93264,
            "f1": 0.94576
        },
        "meteor": 0.39681345172517646,
        "bleurt": 0.4433
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9375
        },
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "nist": 4.514053391810574,
        "bleu": 90.3602,
        "nubia": {
            "semantic_relation": 3.74862,
            "contradiction": 97.6993,
            "irrelevancy": 1.77644,
            "logical_agreement": 0.52426,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.18253,
            "nubia_score": 0.52622
        },
        "bertscore": {
            "precision": 0.98423,
            "recall": 0.98839,
            "f1": 0.98631
        },
        "meteor": 0.572472684946071,
        "bleurt": 0.72398
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.9375,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.57143,
            "fmeasure": 0.42105
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.75,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.75,
            "fmeasure": 0.57143
        },
        "nist": 1.8828142865384643,
        "bleu": 14.94975,
        "nubia": {
            "semantic_relation": 3.44647,
            "contradiction": 1.57248,
            "irrelevancy": 97.04705,
            "logical_agreement": 1.38047,
            "grammar_ref": 5.1072,
            "grammar_hyp": 5.47347,
            "nubia_score": 0.37154
        },
        "bertscore": {
            "precision": 0.84077,
            "recall": 0.92624,
            "f1": 0.88144
        },
        "meteor": 0.39525100254513373,
        "bleurt": -1.08455
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.7537,
            "recall": 0.62684,
            "fmeasure": 0.67948
        },
        "rouge2": {
            "precision": 0.4764,
            "recall": 0.40772,
            "fmeasure": 0.43521
        },
        "rougeL": {
            "precision": 0.6537,
            "recall": 0.53551,
            "fmeasure": 0.58386
        },
        "rougeLsum": {
            "precision": 0.6537,
            "recall": 0.53551,
            "fmeasure": 0.58386
        },
        "nist": 3.1658950390937024,
        "bleu": 24.07204,
        "nubia": {
            "semantic_relation": 4.12188,
            "contradiction": 2.71758,
            "irrelevancy": 11.05407,
            "logical_agreement": 86.22834,
            "grammar_ref": 4.73268,
            "grammar_hyp": 5.23527,
            "nubia_score": 0.65994
        },
        "bertscore": {
            "precision": 0.93027,
            "recall": 0.89464,
            "f1": 0.91201
        },
        "meteor": 0.40218886239712054,
        "bleurt": 0.13168
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.3333333333333333,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.85417,
            "recall": 0.69474,
            "fmeasure": 0.76614
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.4213,
            "fmeasure": 0.44249
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.68111,
            "fmeasure": 0.71342
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.68111,
            "fmeasure": 0.71342
        },
        "nist": 3.5168593685078835,
        "bleu": 38.25786,
        "nubia": {
            "semantic_relation": 4.5649,
            "contradiction": 0.39017,
            "irrelevancy": 10.7793,
            "logical_agreement": 88.83053,
            "grammar_ref": 3.79365,
            "grammar_hyp": 4.34857,
            "nubia_score": 0.80564
        },
        "bertscore": {
            "precision": 0.91493,
            "recall": 0.89043,
            "f1": 0.90024
        },
        "meteor": 0.37392377543471234,
        "bleurt": 0.25609
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.7368421052631579
        },
        "rouge1": {
            "precision": 0.88333,
            "recall": 0.78636,
            "fmeasure": 0.8311
        },
        "rouge2": {
            "precision": 0.62963,
            "recall": 0.5596,
            "fmeasure": 0.59181
        },
        "rougeL": {
            "precision": 0.88333,
            "recall": 0.78636,
            "fmeasure": 0.8311
        },
        "rougeLsum": {
            "precision": 0.88333,
            "recall": 0.78636,
            "fmeasure": 0.8311
        },
        "nist": 4.116445486096015,
        "bleu": 48.99586,
        "nubia": {
            "semantic_relation": 4.67332,
            "contradiction": 2.26223,
            "irrelevancy": 0.92856,
            "logical_agreement": 96.80922,
            "grammar_ref": 4.16906,
            "grammar_hyp": 4.72409,
            "nubia_score": 0.81084
        },
        "bertscore": {
            "precision": 0.97433,
            "recall": 0.95679,
            "f1": 0.96544
        },
        "meteor": 0.4475364492829483,
        "bleurt": 0.80922
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.4375,
            "recall": 0.63889,
            "fmeasure": 0.51333
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.30288,
            "fmeasure": 0.23758
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.63889,
            "fmeasure": 0.51333
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.63889,
            "fmeasure": 0.51333
        },
        "nist": 1.604586579812756,
        "bleu": 7.12696,
        "nubia": {
            "semantic_relation": 3.02702,
            "contradiction": 47.47449,
            "irrelevancy": 52.14851,
            "logical_agreement": 0.377,
            "grammar_ref": 5.58883,
            "grammar_hyp": 4.45407,
            "nubia_score": 0.42411
        },
        "bertscore": {
            "precision": 0.81485,
            "recall": 0.89487,
            "f1": 0.85299
        },
        "meteor": 0.3224374700477271,
        "bleurt": 0.25836
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5384615384615384,
            "3": 0.8809523809523809
        },
        "rouge1": {
            "precision": 0.89266,
            "recall": 0.86221,
            "fmeasure": 0.87534
        },
        "rouge2": {
            "precision": 0.7597,
            "recall": 0.73986,
            "fmeasure": 0.74742
        },
        "rougeL": {
            "precision": 0.87877,
            "recall": 0.84864,
            "fmeasure": 0.86168
        },
        "rougeLsum": {
            "precision": 0.87877,
            "recall": 0.84864,
            "fmeasure": 0.86168
        },
        "nist": 5.7610382810746605,
        "bleu": 73.61201,
        "nubia": {
            "semantic_relation": 4.08129,
            "contradiction": 22.53305,
            "irrelevancy": 22.42684,
            "logical_agreement": 55.04011,
            "grammar_ref": 4.0718,
            "grammar_hyp": 4.00994,
            "nubia_score": 0.76111
        },
        "bertscore": {
            "precision": 0.97532,
            "recall": 0.96748,
            "f1": 0.97136
        },
        "meteor": 0.4857173758881296,
        "bleurt": 0.60268
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.5384615384615384,
            "3": 0.64
        },
        "rouge1": {
            "precision": 0.79815,
            "recall": 0.66929,
            "fmeasure": 0.72602
        },
        "rouge2": {
            "precision": 0.58995,
            "recall": 0.47589,
            "fmeasure": 0.52526
        },
        "rougeL": {
            "precision": 0.68704,
            "recall": 0.56016,
            "fmeasure": 0.61602
        },
        "rougeLsum": {
            "precision": 0.68704,
            "recall": 0.56016,
            "fmeasure": 0.61602
        },
        "nist": 4.297003652796645,
        "bleu": 46.56912,
        "nubia": {
            "semantic_relation": 4.37302,
            "contradiction": 0.56229,
            "irrelevancy": 9.3878,
            "logical_agreement": 90.0499,
            "grammar_ref": 4.28129,
            "grammar_hyp": 4.51124,
            "nubia_score": 0.8104
        },
        "bertscore": {
            "precision": 0.9469,
            "recall": 0.90525,
            "f1": 0.92534
        },
        "meteor": 0.36366991136303867,
        "bleurt": 0.35138
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "mT5_base/totto_test",
        "N": 39,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12781954887218044,
            "2": 0.6031746031746031,
            "3": 0.7270471464019851
        },
        "rouge1": {
            "precision": 0.78694,
            "recall": 0.69274,
            "fmeasure": 0.72418
        },
        "rouge2": {
            "precision": 0.53075,
            "recall": 0.47821,
            "fmeasure": 0.49461
        },
        "rougeL": {
            "precision": 0.6514,
            "recall": 0.58537,
            "fmeasure": 0.60585
        },
        "rougeLsum": {
            "precision": 0.6514,
            "recall": 0.58537,
            "fmeasure": 0.60585
        },
        "nist": 6.621898881901246,
        "bleu": 44.36142,
        "nubia": {
            "semantic_relation": 4.15944,
            "contradiction": 12.13432,
            "irrelevancy": 25.44523,
            "logical_agreement": 62.42045,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.30406,
            "nubia_score": 0.71926
        },
        "bertscore": {
            "precision": 0.93303,
            "recall": 0.91851,
            "f1": 0.92458
        },
        "meteor": 0.37864266985958495,
        "bleurt": 0.3279
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.23529411764705882,
            "3": 0.8611111111111112
        },
        "rouge1": {
            "precision": 0.81051,
            "recall": 0.79272,
            "fmeasure": 0.79907
        },
        "rouge2": {
            "precision": 0.51481,
            "recall": 0.49869,
            "fmeasure": 0.50495
        },
        "rougeL": {
            "precision": 0.52829,
            "recall": 0.52026,
            "fmeasure": 0.52216
        },
        "rougeLsum": {
            "precision": 0.52829,
            "recall": 0.52026,
            "fmeasure": 0.52216
        },
        "nist": 3.9073479733835748,
        "bleu": 40.66824,
        "nubia": {
            "semantic_relation": 4.39733,
            "contradiction": 4.61939,
            "irrelevancy": 18.12854,
            "logical_agreement": 77.25207,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.45021,
            "nubia_score": 0.77633
        },
        "bertscore": {
            "precision": 0.93828,
            "recall": 0.93121,
            "f1": 0.93467
        },
        "meteor": 0.39424804972762595,
        "bleurt": 0.27927
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.5416666666666666,
            "3": 0.7391304347826086
        },
        "rouge1": {
            "precision": 0.6606,
            "recall": 0.66457,
            "fmeasure": 0.64963
        },
        "rouge2": {
            "precision": 0.31863,
            "recall": 0.34228,
            "fmeasure": 0.32208
        },
        "rougeL": {
            "precision": 0.52357,
            "recall": 0.53976,
            "fmeasure": 0.52038
        },
        "rougeLsum": {
            "precision": 0.52357,
            "recall": 0.53976,
            "fmeasure": 0.52038
        },
        "nist": 3.9101930942607073,
        "bleu": 22.4621,
        "nubia": {
            "semantic_relation": 4.25354,
            "contradiction": 12.6344,
            "irrelevancy": 41.89791,
            "logical_agreement": 45.46768,
            "grammar_ref": 5.09695,
            "grammar_hyp": 4.50936,
            "nubia_score": 0.78551
        },
        "bertscore": {
            "precision": 0.91881,
            "recall": 0.91446,
            "f1": 0.91606
        },
        "meteor": 0.3233183549517865,
        "bleurt": 0.23601
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "rouge1": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.69697,
            "fmeasure": 0.68116
        },
        "rougeL": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "rougeLsum": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "nist": 3.16333702950726,
        "bleu": 61.15381,
        "nubia": {
            "semantic_relation": 2.93771,
            "contradiction": 99.61531,
            "irrelevancy": 0.21663,
            "logical_agreement": 0.16806,
            "grammar_ref": 3.96979,
            "grammar_hyp": 3.3943,
            "nubia_score": 0.42969
        },
        "bertscore": {
            "precision": 0.96825,
            "recall": 0.94243,
            "f1": 0.95517
        },
        "meteor": 0.451369116507126,
        "bleurt": 0.528
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "nist": 3.5579098675041347,
        "bleu": 73.48889,
        "nubia": {
            "semantic_relation": 4.61305,
            "contradiction": 1.00975,
            "irrelevancy": 33.27064,
            "logical_agreement": 65.71961,
            "grammar_ref": 4.85143,
            "grammar_hyp": 4.81815,
            "nubia_score": 0.82757
        },
        "bertscore": {
            "precision": 0.98143,
            "recall": 0.98247,
            "f1": 0.98195
        },
        "meteor": 0.9384615384615386,
        "bleurt": 0.54425
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.44388,
            "recall": 0.69276,
            "fmeasure": 0.51786
        },
        "rouge2": {
            "precision": 0.18244,
            "recall": 0.3254,
            "fmeasure": 0.21822
        },
        "rougeL": {
            "precision": 0.38145,
            "recall": 0.63784,
            "fmeasure": 0.45587
        },
        "rougeLsum": {
            "precision": 0.38145,
            "recall": 0.63784,
            "fmeasure": 0.45587
        },
        "nist": 2.471522397951131,
        "bleu": 14.41417,
        "nubia": {
            "semantic_relation": 3.50164,
            "contradiction": 11.16563,
            "irrelevancy": 65.54464,
            "logical_agreement": 23.28973,
            "grammar_ref": 4.63208,
            "grammar_hyp": 4.14941,
            "nubia_score": 0.42263
        },
        "bertscore": {
            "precision": 0.80233,
            "recall": 0.90125,
            "f1": 0.84178
        },
        "meteor": 0.3388834941768657,
        "bleurt": -0.11147
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9354838709677419
        },
        "rouge1": {
            "precision": 0.86012,
            "recall": 0.90331,
            "fmeasure": 0.88047
        },
        "rouge2": {
            "precision": 0.79088,
            "recall": 0.86061,
            "fmeasure": 0.82096
        },
        "rougeL": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "rougeLsum": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "nist": 5.020945219921343,
        "bleu": 77.16836,
        "nubia": {
            "semantic_relation": 4.5356,
            "contradiction": 0.50583,
            "irrelevancy": 46.81276,
            "logical_agreement": 52.68141,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.822,
            "nubia_score": 0.83797
        },
        "bertscore": {
            "precision": 0.96702,
            "recall": 0.97968,
            "f1": 0.97166
        },
        "meteor": 0.5769639229603134,
        "bleurt": 0.65711
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9629629629629629
        },
        "rouge1": {
            "precision": 0.96875,
            "recall": 0.94118,
            "fmeasure": 0.95455
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.84375,
            "fmeasure": 0.85484
        },
        "rougeL": {
            "precision": 0.9375,
            "recall": 0.91176,
            "fmeasure": 0.92424
        },
        "rougeLsum": {
            "precision": 0.9375,
            "recall": 0.91176,
            "fmeasure": 0.92424
        },
        "nist": 4.936714161769126,
        "bleu": 84.11526,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.36301,
            "irrelevancy": 0.5467,
            "logical_agreement": 99.09029,
            "grammar_ref": 5.04945,
            "grammar_hyp": 5.19102,
            "nubia_score": 0.97019
        },
        "bertscore": {
            "precision": 0.99201,
            "recall": 0.98462,
            "f1": 0.98774
        },
        "meteor": 0.5591842651549158,
        "bleurt": 0.82939
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.7197,
            "recall": 0.72252,
            "fmeasure": 0.71609
        },
        "rouge2": {
            "precision": 0.58229,
            "recall": 0.5962,
            "fmeasure": 0.58574
        },
        "rougeL": {
            "precision": 0.71212,
            "recall": 0.71657,
            "fmeasure": 0.70942
        },
        "rougeLsum": {
            "precision": 0.71212,
            "recall": 0.71657,
            "fmeasure": 0.70942
        },
        "nist": 4.046635765483898,
        "bleu": 51.72666,
        "nubia": {
            "semantic_relation": 4.14544,
            "contradiction": 22.14934,
            "irrelevancy": 11.66371,
            "logical_agreement": 66.18695,
            "grammar_ref": 4.6519,
            "grammar_hyp": 4.74366,
            "nubia_score": 0.68983
        },
        "bertscore": {
            "precision": 0.91146,
            "recall": 0.91792,
            "f1": 0.91154
        },
        "meteor": 0.3991726002336106,
        "bleurt": 0.31586
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.90476,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "nist": 3.2853166560349347,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.6471,
            "contradiction": 0.87539,
            "irrelevancy": 0.67186,
            "logical_agreement": 98.45275,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.32137,
            "nubia_score": 0.82841
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.58619
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.8125,
            "fmeasure": 0.76471
        },
        "rouge2": {
            "precision": 0.5098,
            "recall": 0.72323,
            "fmeasure": 0.59524
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.84028,
            "fmeasure": 0.70458
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.84028,
            "fmeasure": 0.70458
        },
        "nist": 2.763819131706362,
        "bleu": 26.68173,
        "nubia": {
            "semantic_relation": 4.249,
            "contradiction": 0.6484,
            "irrelevancy": 37.98953,
            "logical_agreement": 61.36206,
            "grammar_ref": 4.67419,
            "grammar_hyp": 4.05826,
            "nubia_score": 0.79134
        },
        "bertscore": {
            "precision": 0.90204,
            "recall": 0.97063,
            "f1": 0.92451
        },
        "meteor": 0.43067097914530694,
        "bleurt": 0.62807
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.06666666666666667,
            "3": 0.7575757575757576
        },
        "rouge1": {
            "precision": 0.73604,
            "recall": 0.68232,
            "fmeasure": 0.69609
        },
        "rouge2": {
            "precision": 0.48677,
            "recall": 0.4626,
            "fmeasure": 0.46661
        },
        "rougeL": {
            "precision": 0.63756,
            "recall": 0.62299,
            "fmeasure": 0.62307
        },
        "rougeLsum": {
            "precision": 0.63756,
            "recall": 0.62299,
            "fmeasure": 0.62307
        },
        "nist": 4.044515428404783,
        "bleu": 42.96,
        "nubia": {
            "semantic_relation": 3.45675,
            "contradiction": 49.02342,
            "irrelevancy": 48.78345,
            "logical_agreement": 2.19313,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.49362,
            "nubia_score": 0.55518
        },
        "bertscore": {
            "precision": 0.90346,
            "recall": 0.92,
            "f1": 0.91142
        },
        "meteor": 0.38898453831675595,
        "bleurt": 0.15106
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.3333333333333333,
            "3": 0.7666666666666667
        },
        "rouge1": {
            "precision": 0.72138,
            "recall": 0.70157,
            "fmeasure": 0.6811
        },
        "rouge2": {
            "precision": 0.5404,
            "recall": 0.50227,
            "fmeasure": 0.49817
        },
        "rougeL": {
            "precision": 0.65657,
            "recall": 0.633,
            "fmeasure": 0.61933
        },
        "rougeLsum": {
            "precision": 0.65657,
            "recall": 0.633,
            "fmeasure": 0.61933
        },
        "nist": 3.55049943312263,
        "bleu": 48.55545,
        "nubia": {
            "semantic_relation": 3.81995,
            "contradiction": 0.25886,
            "irrelevancy": 63.06169,
            "logical_agreement": 36.67945,
            "grammar_ref": 4.66623,
            "grammar_hyp": 4.60379,
            "nubia_score": 0.63896
        },
        "bertscore": {
            "precision": 0.9203,
            "recall": 0.90258,
            "f1": 0.89622
        },
        "meteor": 0.3587343422177048,
        "bleurt": 0.01901
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6,
            "3": 0.7014925373134329
        },
        "rouge1": {
            "precision": 0.82464,
            "recall": 0.74928,
            "fmeasure": 0.77012
        },
        "rouge2": {
            "precision": 0.45527,
            "recall": 0.40235,
            "fmeasure": 0.41746
        },
        "rougeL": {
            "precision": 0.65357,
            "recall": 0.6,
            "fmeasure": 0.61315
        },
        "rougeLsum": {
            "precision": 0.65357,
            "recall": 0.6,
            "fmeasure": 0.61315
        },
        "nist": 4.172859524985425,
        "bleu": 28.2925,
        "nubia": {
            "semantic_relation": 4.1744,
            "contradiction": 0.41479,
            "irrelevancy": 32.05329,
            "logical_agreement": 67.53192,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.75392,
            "nubia_score": 0.66305
        },
        "bertscore": {
            "precision": 0.9289,
            "recall": 0.89716,
            "f1": 0.91161
        },
        "meteor": 0.3558254659960543,
        "bleurt": 0.09892
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.45238,
            "fmeasure": 0.49391
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.1993,
            "fmeasure": 0.22153
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.375,
            "fmeasure": 0.41043
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.375,
            "fmeasure": 0.41043
        },
        "nist": 2.075916753354159,
        "bleu": 14.8071,
        "nubia": {
            "semantic_relation": 3.42304,
            "contradiction": 1.63274,
            "irrelevancy": 40.65518,
            "logical_agreement": 57.71208,
            "grammar_ref": 5.74657,
            "grammar_hyp": 4.52208,
            "nubia_score": 0.56296
        },
        "bertscore": {
            "precision": 0.88836,
            "recall": 0.85077,
            "f1": 0.86916
        },
        "meteor": 0.24641528784542965,
        "bleurt": -0.00952
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.782608695652174
        },
        "rouge1": {
            "precision": 0.82781,
            "recall": 0.74525,
            "fmeasure": 0.78299
        },
        "rouge2": {
            "precision": 0.59975,
            "recall": 0.54393,
            "fmeasure": 0.56946
        },
        "rougeL": {
            "precision": 0.763,
            "recall": 0.69412,
            "fmeasure": 0.72585
        },
        "rougeLsum": {
            "precision": 0.763,
            "recall": 0.69412,
            "fmeasure": 0.72585
        },
        "nist": 4.689434733413541,
        "bleu": 58.71778,
        "nubia": {
            "semantic_relation": 4.49999,
            "contradiction": 4.11838,
            "irrelevancy": 5.8308,
            "logical_agreement": 90.05082,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.80584,
            "nubia_score": 0.81064
        },
        "bertscore": {
            "precision": 0.96515,
            "recall": 0.9515,
            "f1": 0.95611
        },
        "meteor": 0.4560928340404555,
        "bleurt": 0.47998
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.91667,
            "fmeasure": 0.93333
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "nist": 4.251192788981044,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.42679,
            "contradiction": 6.87785,
            "irrelevancy": 1.70123,
            "logical_agreement": 91.42092,
            "grammar_ref": 7.10682,
            "grammar_hyp": 7.20763,
            "nubia_score": 0.72464
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.64779
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "mT5_base/totto_test",
        "N": 158,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23851590106007067,
            "2": 0.4268774703557312,
            "3": 0.7326236693800877
        },
        "rouge1": {
            "precision": 0.75051,
            "recall": 0.6955,
            "fmeasure": 0.70925
        },
        "rouge2": {
            "precision": 0.50471,
            "recall": 0.46511,
            "fmeasure": 0.47533
        },
        "rougeL": {
            "precision": 0.63953,
            "recall": 0.59746,
            "fmeasure": 0.60623
        },
        "rougeLsum": {
            "precision": 0.63953,
            "recall": 0.59746,
            "fmeasure": 0.60623
        },
        "nist": 7.566833762446018,
        "bleu": 42.19357,
        "nubia": {
            "semantic_relation": 4.0874,
            "contradiction": 9.12274,
            "irrelevancy": 29.51688,
            "logical_agreement": 61.36038,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.69317,
            "nubia_score": 0.70544
        },
        "bertscore": {
            "precision": 0.92656,
            "recall": 0.91422,
            "f1": 0.9189
        },
        "meteor": 0.3804524331456341,
        "bleurt": 0.20631
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.73016,
            "recall": 0.60164,
            "fmeasure": 0.6476
        },
        "rouge2": {
            "precision": 0.46633,
            "recall": 0.37117,
            "fmeasure": 0.40201
        },
        "rougeL": {
            "precision": 0.5812,
            "recall": 0.53355,
            "fmeasure": 0.54046
        },
        "rougeLsum": {
            "precision": 0.5812,
            "recall": 0.53355,
            "fmeasure": 0.54046
        },
        "nist": 4.3169749920838,
        "bleu": 37.72292,
        "nubia": {
            "semantic_relation": 3.43269,
            "contradiction": 41.76758,
            "irrelevancy": 24.52946,
            "logical_agreement": 33.70295,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.66186,
            "nubia_score": 0.49219
        },
        "bertscore": {
            "precision": 0.90722,
            "recall": 0.89261,
            "f1": 0.89977
        },
        "meteor": 0.37350578008953467,
        "bleurt": 0.02048
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.65377,
            "recall": 0.61527,
            "fmeasure": 0.61183
        },
        "rouge2": {
            "precision": 0.42063,
            "recall": 0.4375,
            "fmeasure": 0.4196
        },
        "rougeL": {
            "precision": 0.62202,
            "recall": 0.61289,
            "fmeasure": 0.60257
        },
        "rougeLsum": {
            "precision": 0.62202,
            "recall": 0.61289,
            "fmeasure": 0.60257
        },
        "nist": 2.8973028260569205,
        "bleu": 40.9283,
        "nubia": {
            "semantic_relation": 3.52843,
            "contradiction": 59.85672,
            "irrelevancy": 15.21171,
            "logical_agreement": 24.93158,
            "grammar_ref": 4.11451,
            "grammar_hyp": 5.69677,
            "nubia_score": 0.41462
        },
        "bertscore": {
            "precision": 0.90705,
            "recall": 0.90782,
            "f1": 0.90728
        },
        "meteor": 0.28797549784882837,
        "bleurt": 0.01908
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69841,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.50183,
            "fmeasure": 0.59816
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "nist": 2.6330370023236713,
        "bleu": 42.95749,
        "nubia": {
            "semantic_relation": 4.97277,
            "contradiction": 0.35627,
            "irrelevancy": 0.48729,
            "logical_agreement": 99.15644,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.85358,
            "nubia_score": 0.74277
        },
        "bertscore": {
            "precision": 0.98201,
            "recall": 0.93212,
            "f1": 0.95641
        },
        "meteor": 0.42350497485471644,
        "bleurt": 0.45492
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rouge2": {
            "precision": 0.92593,
            "recall": 0.75926,
            "fmeasure": 0.83069
        },
        "rougeL": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rougeLsum": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "nist": 2.8936441277848375,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.57319,
            "contradiction": 0.20028,
            "irrelevancy": 0.43256,
            "logical_agreement": 99.36716,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.18715,
            "nubia_score": 0.88792
        },
        "bertscore": {
            "precision": 0.98107,
            "recall": 0.98047,
            "f1": 0.98047
        },
        "meteor": 0.9652173913043478,
        "bleurt": 0.55466
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.490498678107601,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.92254
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5833333333333334
        },
        "rouge1": {
            "precision": 0.54762,
            "recall": 0.60435,
            "fmeasure": 0.56818
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.32468,
            "fmeasure": 0.30812
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.51594,
            "fmeasure": 0.4899
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.51594,
            "fmeasure": 0.4899
        },
        "nist": 3.7150120414568857,
        "bleu": 32.67142,
        "nubia": {
            "semantic_relation": 3.54434,
            "contradiction": 12.35453,
            "irrelevancy": 80.06458,
            "logical_agreement": 7.58089,
            "grammar_ref": 5.51157,
            "grammar_hyp": 5.24155,
            "nubia_score": 0.5014
        },
        "bertscore": {
            "precision": 0.90674,
            "recall": 0.91502,
            "f1": 0.91086
        },
        "meteor": 0.3162090976488524,
        "bleurt": -0.24503
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.71429,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.4359,
            "fmeasure": 0.49275
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "nist": 3.4595216280661427,
        "bleu": 38.14156,
        "nubia": {
            "semantic_relation": 4.61109,
            "contradiction": 3.09482,
            "irrelevancy": 8.3594,
            "logical_agreement": 88.54578,
            "grammar_ref": 4.18993,
            "grammar_hyp": 4.96442,
            "nubia_score": 0.74324
        },
        "bertscore": {
            "precision": 0.96123,
            "recall": 0.92567,
            "f1": 0.94312
        },
        "meteor": 0.3918734238227112,
        "bleurt": 0.44858
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.8666666666666667,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.80229,
            "recall": 0.78492,
            "fmeasure": 0.79039
        },
        "rouge2": {
            "precision": 0.61837,
            "recall": 0.59636,
            "fmeasure": 0.60393
        },
        "rougeL": {
            "precision": 0.80229,
            "recall": 0.78492,
            "fmeasure": 0.79039
        },
        "rougeLsum": {
            "precision": 0.80229,
            "recall": 0.78492,
            "fmeasure": 0.79039
        },
        "nist": 4.431040626240198,
        "bleu": 56.38256,
        "nubia": {
            "semantic_relation": 3.46626,
            "contradiction": 50.74588,
            "irrelevancy": 0.89009,
            "logical_agreement": 48.36404,
            "grammar_ref": 4.13759,
            "grammar_hyp": 4.10204,
            "nubia_score": 0.53234
        },
        "bertscore": {
            "precision": 0.97051,
            "recall": 0.95393,
            "f1": 0.954
        },
        "meteor": 0.42780130284655143,
        "bleurt": 0.61084
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "mT5_base/totto_test",
        "N": 35,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16091954022988506,
            "2": 0.4423076923076923,
            "3": 0.8069164265129684
        },
        "rouge1": {
            "precision": 0.78702,
            "recall": 0.76622,
            "fmeasure": 0.76769
        },
        "rouge2": {
            "precision": 0.56411,
            "recall": 0.54265,
            "fmeasure": 0.54785
        },
        "rougeL": {
            "precision": 0.68341,
            "recall": 0.66472,
            "fmeasure": 0.66625
        },
        "rougeLsum": {
            "precision": 0.68341,
            "recall": 0.66472,
            "fmeasure": 0.66625
        },
        "nist": 6.569807814840608,
        "bleu": 50.98041,
        "nubia": {
            "semantic_relation": 4.23794,
            "contradiction": 4.26421,
            "irrelevancy": 20.43918,
            "logical_agreement": 75.29661,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.0283,
            "nubia_score": 0.80165
        },
        "bertscore": {
            "precision": 0.9419,
            "recall": 0.9381,
            "f1": 0.93891
        },
        "meteor": 0.4315823365068822,
        "bleurt": 0.46268
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "mT5_base/totto_test",
        "N": 36,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.47058823529411764,
            "3": 0.7135678391959799
        },
        "rouge1": {
            "precision": 0.7367,
            "recall": 0.65572,
            "fmeasure": 0.68583
        },
        "rouge2": {
            "precision": 0.42692,
            "recall": 0.37563,
            "fmeasure": 0.39431
        },
        "rougeL": {
            "precision": 0.59361,
            "recall": 0.52783,
            "fmeasure": 0.55245
        },
        "rougeLsum": {
            "precision": 0.59361,
            "recall": 0.52783,
            "fmeasure": 0.55245
        },
        "nist": 6.2101361653664044,
        "bleu": 34.79376,
        "nubia": {
            "semantic_relation": 4.04526,
            "contradiction": 14.72213,
            "irrelevancy": 28.75904,
            "logical_agreement": 56.51883,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.96987,
            "nubia_score": 0.67357
        },
        "bertscore": {
            "precision": 0.91348,
            "recall": 0.90768,
            "f1": 0.90953
        },
        "meteor": 0.34396866952945004,
        "bleurt": 0.17218
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "mT5_base/totto_test",
        "N": 110,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21957671957671956,
            "2": 0.5092838196286472,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.75685,
            "recall": 0.70031,
            "fmeasure": 0.71389
        },
        "rouge2": {
            "precision": 0.52584,
            "recall": 0.48662,
            "fmeasure": 0.49577
        },
        "rougeL": {
            "precision": 0.65131,
            "recall": 0.60582,
            "fmeasure": 0.6157
        },
        "rougeLsum": {
            "precision": 0.65131,
            "recall": 0.60582,
            "fmeasure": 0.6157
        },
        "nist": 7.316220976777127,
        "bleu": 44.77828,
        "nubia": {
            "semantic_relation": 4.04986,
            "contradiction": 12.9332,
            "irrelevancy": 26.00127,
            "logical_agreement": 61.06552,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.90137,
            "nubia_score": 0.67599
        },
        "bertscore": {
            "precision": 0.92932,
            "recall": 0.92028,
            "f1": 0.92366
        },
        "meteor": 0.3819788576706906,
        "bleurt": 0.21177
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.73684,
            "recall": 1.0,
            "fmeasure": 0.84848
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.76923,
            "fmeasure": 0.64516
        },
        "rougeL": {
            "precision": 0.68421,
            "recall": 0.92857,
            "fmeasure": 0.78788
        },
        "rougeLsum": {
            "precision": 0.68421,
            "recall": 0.92857,
            "fmeasure": 0.78788
        },
        "nist": 2.60283922618523,
        "bleu": 45.83034,
        "nubia": {
            "semantic_relation": 3.8007,
            "contradiction": 0.15758,
            "irrelevancy": 99.74505,
            "logical_agreement": 0.09738,
            "grammar_ref": 4.76643,
            "grammar_hyp": 3.7782,
            "nubia_score": 0.71692
        },
        "bertscore": {
            "precision": 0.91731,
            "recall": 0.96154,
            "f1": 0.9389
        },
        "meteor": 0.4840606541446009,
        "bleurt": 0.33762
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.4642857142857143,
            "3": 0.7681159420289855
        },
        "rouge1": {
            "precision": 0.76513,
            "recall": 0.75028,
            "fmeasure": 0.73925
        },
        "rouge2": {
            "precision": 0.56998,
            "recall": 0.55975,
            "fmeasure": 0.54816
        },
        "rougeL": {
            "precision": 0.69081,
            "recall": 0.68757,
            "fmeasure": 0.67147
        },
        "rougeLsum": {
            "precision": 0.69081,
            "recall": 0.68757,
            "fmeasure": 0.67147
        },
        "nist": 4.8880337766850985,
        "bleu": 44.91023,
        "nubia": {
            "semantic_relation": 3.92708,
            "contradiction": 19.66433,
            "irrelevancy": 54.96419,
            "logical_agreement": 25.37148,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.42456,
            "nubia_score": 0.67068
        },
        "bertscore": {
            "precision": 0.92582,
            "recall": 0.92482,
            "f1": 0.92144
        },
        "meteor": 0.39415259877026426,
        "bleurt": 0.33286
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.9615384615384616
        },
        "rouge1": {
            "precision": 0.85897,
            "recall": 0.89899,
            "fmeasure": 0.87778
        },
        "rouge2": {
            "precision": 0.76389,
            "recall": 0.79545,
            "fmeasure": 0.77866
        },
        "rougeL": {
            "precision": 0.85897,
            "recall": 0.89899,
            "fmeasure": 0.87778
        },
        "rougeLsum": {
            "precision": 0.85897,
            "recall": 0.89899,
            "fmeasure": 0.87778
        },
        "nist": 5.126393013600408,
        "bleu": 84.32728,
        "nubia": {
            "semantic_relation": 4.99122,
            "contradiction": 0.25103,
            "irrelevancy": 1.47777,
            "logical_agreement": 98.2712,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.62517,
            "nubia_score": 0.99237
        },
        "bertscore": {
            "precision": 0.97635,
            "recall": 0.98161,
            "f1": 0.97897
        },
        "meteor": 0.6021033812809709,
        "bleurt": 0.78449
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.44048,
            "fmeasure": 0.36594
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.14444,
            "fmeasure": 0.12063
        },
        "rougeL": {
            "precision": 0.20833,
            "recall": 0.2619,
            "fmeasure": 0.22464
        },
        "rougeLsum": {
            "precision": 0.20833,
            "recall": 0.2619,
            "fmeasure": 0.22464
        },
        "nist": 1.2671131093267114,
        "bleu": 5.65304,
        "nubia": {
            "semantic_relation": 3.33196,
            "contradiction": 0.33125,
            "irrelevancy": 82.65665,
            "logical_agreement": 17.0121,
            "grammar_ref": 4.92688,
            "grammar_hyp": 3.6716,
            "nubia_score": 0.40817
        },
        "bertscore": {
            "precision": 0.71649,
            "recall": 0.77892,
            "f1": 0.71421
        },
        "meteor": 0.24704253628256037,
        "bleurt": -0.16926
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.6530437207411035,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34259,
            "irrelevancy": 0.55688,
            "logical_agreement": 99.10053,
            "grammar_ref": 6.12532,
            "grammar_hyp": 6.14583,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.9828
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.64935,
            "fmeasure": 0.68364
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "nist": 3.8107815848368243,
        "bleu": 71.38958,
        "nubia": {
            "semantic_relation": 4.6448,
            "contradiction": 0.52652,
            "irrelevancy": 0.67281,
            "logical_agreement": 98.80067,
            "grammar_ref": 5.25223,
            "grammar_hyp": 5.73563,
            "nubia_score": 0.8067
        },
        "bertscore": {
            "precision": 0.98905,
            "recall": 0.98905,
            "f1": 0.98905
        },
        "meteor": 0.9233576642335767,
        "bleurt": 0.61973
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5555555555555556,
            "3": 0.782608695652174
        },
        "rouge1": {
            "precision": 0.66117,
            "recall": 0.71432,
            "fmeasure": 0.66443
        },
        "rouge2": {
            "precision": 0.33135,
            "recall": 0.37684,
            "fmeasure": 0.33899
        },
        "rougeL": {
            "precision": 0.5793,
            "recall": 0.59077,
            "fmeasure": 0.56468
        },
        "rougeLsum": {
            "precision": 0.5793,
            "recall": 0.59077,
            "fmeasure": 0.56468
        },
        "nist": 4.246392706745082,
        "bleu": 39.93359,
        "nubia": {
            "semantic_relation": 3.67762,
            "contradiction": 1.68244,
            "irrelevancy": 31.02937,
            "logical_agreement": 67.28819,
            "grammar_ref": 4.9362,
            "grammar_hyp": 3.9618,
            "nubia_score": 0.64841
        },
        "bertscore": {
            "precision": 0.90407,
            "recall": 0.92566,
            "f1": 0.90686
        },
        "meteor": 0.35903161477035184,
        "bleurt": 0.17314
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.0,
            "3": 0.8048780487804879
        },
        "rouge1": {
            "precision": 0.78977,
            "recall": 0.69273,
            "fmeasure": 0.73435
        },
        "rouge2": {
            "precision": 0.56108,
            "recall": 0.48742,
            "fmeasure": 0.51925
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.62918,
            "fmeasure": 0.6694
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.62918,
            "fmeasure": 0.6694
        },
        "nist": 3.562636172342254,
        "bleu": 42.7425,
        "nubia": {
            "semantic_relation": 3.72946,
            "contradiction": 62.93139,
            "irrelevancy": 1.96884,
            "logical_agreement": 35.09976,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.56833,
            "nubia_score": 0.56098
        },
        "bertscore": {
            "precision": 0.93225,
            "recall": 0.89507,
            "f1": 0.91327
        },
        "meteor": 0.361390464653082,
        "bleurt": -0.06989
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.5098,
            "recall": 0.42607,
            "fmeasure": 0.46394
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.16374,
            "fmeasure": 0.17479
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.2782,
            "fmeasure": 0.30312
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.2782,
            "fmeasure": 0.30312
        },
        "nist": 2.136670295627014,
        "bleu": 14.33662,
        "nubia": {
            "semantic_relation": 3.6882,
            "contradiction": 0.08253,
            "irrelevancy": 99.75192,
            "logical_agreement": 0.16555,
            "grammar_ref": 4.46991,
            "grammar_hyp": 4.44561,
            "nubia_score": 0.5736
        },
        "bertscore": {
            "precision": 0.82352,
            "recall": 0.80653,
            "f1": 0.81494
        },
        "meteor": 0.24216725228009212,
        "bleurt": -0.36668
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.40179,
            "fmeasure": 0.34314
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "nist": 1.1227137604546689,
        "bleu": 14.99111,
        "nubia": {
            "semantic_relation": 3.78915,
            "contradiction": 2.88897,
            "irrelevancy": 55.44136,
            "logical_agreement": 41.66967,
            "grammar_ref": 4.73918,
            "grammar_hyp": 3.671,
            "nubia_score": 0.66998
        },
        "bertscore": {
            "precision": 0.82556,
            "recall": 0.86442,
            "f1": 0.84455
        },
        "meteor": 0.2731132551770082,
        "bleurt": 0.34221
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.38596,
            "recall": 0.59091,
            "fmeasure": 0.46349
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.26667,
            "fmeasure": 0.20346
        },
        "rougeL": {
            "precision": 0.29825,
            "recall": 0.34804,
            "fmeasure": 0.32116
        },
        "rougeLsum": {
            "precision": 0.29825,
            "recall": 0.34804,
            "fmeasure": 0.32116
        },
        "nist": 2.718796541532612,
        "bleu": 8.24802,
        "nubia": {
            "semantic_relation": 3.79955,
            "contradiction": 0.11853,
            "irrelevancy": 99.60354,
            "logical_agreement": 0.27793,
            "grammar_ref": 4.84054,
            "grammar_hyp": 4.67754,
            "nubia_score": 0.61408
        },
        "bertscore": {
            "precision": 0.8408,
            "recall": 0.88125,
            "f1": 0.85016
        },
        "meteor": 0.3082042370744828,
        "bleurt": -0.36143
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.47058823529411764
        },
        "rouge1": {
            "precision": 0.60417,
            "recall": 0.37717,
            "fmeasure": 0.45798
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.20602,
            "fmeasure": 0.27409
        },
        "rougeL": {
            "precision": 0.54167,
            "recall": 0.32717,
            "fmeasure": 0.40242
        },
        "rougeLsum": {
            "precision": 0.54167,
            "recall": 0.32717,
            "fmeasure": 0.40242
        },
        "nist": 1.7497979817183589,
        "bleu": 26.30457,
        "nubia": {
            "semantic_relation": 3.96816,
            "contradiction": 49.53131,
            "irrelevancy": 0.56563,
            "logical_agreement": 49.90306,
            "grammar_ref": 4.56502,
            "grammar_hyp": 6.01912,
            "nubia_score": 0.57313
        },
        "bertscore": {
            "precision": 0.91226,
            "recall": 0.8827,
            "f1": 0.89426
        },
        "meteor": 0.2796919913498787,
        "bleurt": 0.32574
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.78175,
            "recall": 0.92037,
            "fmeasure": 0.83816
        },
        "rouge2": {
            "precision": 0.6641,
            "recall": 0.80833,
            "fmeasure": 0.71905
        },
        "rougeL": {
            "precision": 0.78175,
            "recall": 0.92037,
            "fmeasure": 0.83816
        },
        "rougeLsum": {
            "precision": 0.78175,
            "recall": 0.92037,
            "fmeasure": 0.83816
        },
        "nist": 3.7374922733925366,
        "bleu": 68.0971,
        "nubia": {
            "semantic_relation": 4.57648,
            "contradiction": 6.95906,
            "irrelevancy": 38.1223,
            "logical_agreement": 54.91864,
            "grammar_ref": 5.35128,
            "grammar_hyp": 5.24021,
            "nubia_score": 0.83489
        },
        "bertscore": {
            "precision": 0.93427,
            "recall": 0.95632,
            "f1": 0.94502
        },
        "meteor": 0.5682213889075267,
        "bleurt": 0.22485
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.4375
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.57895,
            "fmeasure": 0.70968
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.44444,
            "fmeasure": 0.55172
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.57895,
            "fmeasure": 0.70968
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.57895,
            "fmeasure": 0.70968
        },
        "nist": 0.5310590331001919,
        "bleu": 12.13507,
        "nubia": {
            "semantic_relation": 4.03663,
            "contradiction": 0.25928,
            "irrelevancy": 0.48192,
            "logical_agreement": 99.2588,
            "grammar_ref": 4.21408,
            "grammar_hyp": 5.10792,
            "nubia_score": 0.60101
        },
        "bertscore": {
            "precision": 0.95248,
            "recall": 0.9078,
            "f1": 0.92956
        },
        "meteor": 0.37390796166741197,
        "bleurt": 0.3765
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.9697,
            "recall": 0.77244,
            "fmeasure": 0.85802
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.57778,
            "fmeasure": 0.64485
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.73077,
            "fmeasure": 0.80864
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.73077,
            "fmeasure": 0.80864
        },
        "nist": 4.301974791538034,
        "bleu": 66.5813,
        "nubia": {
            "semantic_relation": 4.29048,
            "contradiction": 0.15644,
            "irrelevancy": 0.54266,
            "logical_agreement": 99.30089,
            "grammar_ref": 4.55634,
            "grammar_hyp": 4.35341,
            "nubia_score": 0.82485
        },
        "bertscore": {
            "precision": 0.99249,
            "recall": 0.9567,
            "f1": 0.97426
        },
        "meteor": 0.4647250072677854,
        "bleurt": 0.56183
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6333333333333333
        },
        "rouge1": {
            "precision": 0.69658,
            "recall": 0.61228,
            "fmeasure": 0.65092
        },
        "rouge2": {
            "precision": 0.42157,
            "recall": 0.3963,
            "fmeasure": 0.40811
        },
        "rougeL": {
            "precision": 0.50214,
            "recall": 0.43421,
            "fmeasure": 0.46505
        },
        "rougeLsum": {
            "precision": 0.50214,
            "recall": 0.43421,
            "fmeasure": 0.46505
        },
        "nist": 3.3794947268616204,
        "bleu": 37.59625,
        "nubia": {
            "semantic_relation": 3.18583,
            "contradiction": 0.15463,
            "irrelevancy": 50.407,
            "logical_agreement": 49.43837,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.6649,
            "nubia_score": 0.45429
        },
        "bertscore": {
            "precision": 0.8833,
            "recall": 0.84547,
            "f1": 0.86164
        },
        "meteor": 0.35065085818075764,
        "bleurt": -0.06852
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.71296,
            "recall": 0.67775,
            "fmeasure": 0.69334
        },
        "rouge2": {
            "precision": 0.45792,
            "recall": 0.43639,
            "fmeasure": 0.44561
        },
        "rougeL": {
            "precision": 0.57253,
            "recall": 0.56985,
            "fmeasure": 0.5692
        },
        "rougeLsum": {
            "precision": 0.57253,
            "recall": 0.56985,
            "fmeasure": 0.5692
        },
        "nist": 4.83865074719171,
        "bleu": 48.17016,
        "nubia": {
            "semantic_relation": 3.81913,
            "contradiction": 45.5815,
            "irrelevancy": 8.54831,
            "logical_agreement": 45.87018,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.70411,
            "nubia_score": 0.63869
        },
        "bertscore": {
            "precision": 0.90877,
            "recall": 0.88112,
            "f1": 0.8911
        },
        "meteor": 0.3444745426121302,
        "bleurt": 0.09673
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.57778,
            "recall": 0.84175,
            "fmeasure": 0.68376
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.39899
        },
        "rougeL": {
            "precision": 0.37778,
            "recall": 0.54882,
            "fmeasure": 0.44658
        },
        "rougeLsum": {
            "precision": 0.37778,
            "recall": 0.54882,
            "fmeasure": 0.44658
        },
        "nist": 2.1748807645574812,
        "bleu": 14.24779,
        "nubia": {
            "semantic_relation": 4.13123,
            "contradiction": 2.64056,
            "irrelevancy": 91.77276,
            "logical_agreement": 5.58668,
            "grammar_ref": 6.0554,
            "grammar_hyp": 5.28074,
            "nubia_score": 0.58418
        },
        "bertscore": {
            "precision": 0.86525,
            "recall": 0.92581,
            "f1": 0.89451
        },
        "meteor": 0.40462877954847637,
        "bleurt": -0.34345
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.93333,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.52632,
            "recall": 0.71429,
            "fmeasure": 0.60606
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.53333,
            "fmeasure": 0.45714
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.53333,
            "fmeasure": 0.45714
        },
        "nist": 2.8622464330522663,
        "bleu": 42.6622,
        "nubia": {
            "semantic_relation": 4.6019,
            "contradiction": 0.18326,
            "irrelevancy": 10.04657,
            "logical_agreement": 89.77017,
            "grammar_ref": 4.08392,
            "grammar_hyp": 3.45215,
            "nubia_score": 0.93768
        },
        "bertscore": {
            "precision": 0.93124,
            "recall": 0.96552,
            "f1": 0.94807
        },
        "meteor": 0.4722241150762613,
        "bleurt": 0.45645
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.90476,
            "fmeasure": 0.85348
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "nist": 4.018549068142959,
        "bleu": 69.85342,
        "nubia": {
            "semantic_relation": 4.40194,
            "contradiction": 0.18499,
            "irrelevancy": 63.6692,
            "logical_agreement": 36.14582,
            "grammar_ref": 5.29735,
            "grammar_hyp": 4.41374,
            "nubia_score": 0.97573
        },
        "bertscore": {
            "precision": 0.95785,
            "recall": 0.97999,
            "f1": 0.96524
        },
        "meteor": 0.5255759325753065,
        "bleurt": 0.6035
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.768492245572466,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.373,
            "irrelevancy": 0.51156,
            "logical_agreement": 99.11544,
            "grammar_ref": 5.07856,
            "grammar_hyp": 5.22425,
            "nubia_score": 0.9763
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.97268
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "mT5_base/totto_test",
        "N": 10,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4444444444444444,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.79871,
            "recall": 0.7418,
            "fmeasure": 0.76196
        },
        "rouge2": {
            "precision": 0.61629,
            "recall": 0.57627,
            "fmeasure": 0.58925
        },
        "rougeL": {
            "precision": 0.6797,
            "recall": 0.62291,
            "fmeasure": 0.64287
        },
        "rougeLsum": {
            "precision": 0.6797,
            "recall": 0.62291,
            "fmeasure": 0.64287
        },
        "nist": 5.30550546991166,
        "bleu": 48.4362,
        "nubia": {
            "semantic_relation": 4.16604,
            "contradiction": 26.03436,
            "irrelevancy": 12.16565,
            "logical_agreement": 61.79999,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.33614,
            "nubia_score": 0.71584
        },
        "bertscore": {
            "precision": 0.94234,
            "recall": 0.93277,
            "f1": 0.93679
        },
        "meteor": 0.401190474067281,
        "bleurt": 0.36426
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.85
        },
        "rouge1": {
            "precision": 0.67436,
            "recall": 0.84965,
            "fmeasure": 0.74928
        },
        "rouge2": {
            "precision": 0.39143,
            "recall": 0.54512,
            "fmeasure": 0.44947
        },
        "rougeL": {
            "precision": 0.49744,
            "recall": 0.69719,
            "fmeasure": 0.57334
        },
        "rougeLsum": {
            "precision": 0.49744,
            "recall": 0.69719,
            "fmeasure": 0.57334
        },
        "nist": 3.055987575800129,
        "bleu": 20.95142,
        "nubia": {
            "semantic_relation": 4.77521,
            "contradiction": 9.65537,
            "irrelevancy": 13.62613,
            "logical_agreement": 76.7185,
            "grammar_ref": 4.12394,
            "grammar_hyp": 3.92241,
            "nubia_score": 0.81362
        },
        "bertscore": {
            "precision": 0.90137,
            "recall": 0.93501,
            "f1": 0.9159
        },
        "meteor": 0.4315413346136417,
        "bleurt": 0.26361
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.52564,
            "fmeasure": 0.55282
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.33333,
            "fmeasure": 0.34783
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.51282,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.51282,
            "fmeasure": 0.53333
        },
        "nist": 2.12673944588942,
        "bleu": 22.43453,
        "nubia": {
            "semantic_relation": 2.77182,
            "contradiction": 10.90102,
            "irrelevancy": 86.0666,
            "logical_agreement": 3.03238,
            "grammar_ref": 5.35534,
            "grammar_hyp": 5.07131,
            "nubia_score": 0.27172
        },
        "bertscore": {
            "precision": 0.89382,
            "recall": 0.87157,
            "f1": 0.88255
        },
        "meteor": 0.2699545970612829,
        "bleurt": -0.36133
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.42105263157894735,
            "3": 0.6481481481481481
        },
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.58318,
            "fmeasure": 0.57863
        },
        "rouge2": {
            "precision": 0.30866,
            "recall": 0.24726,
            "fmeasure": 0.265
        },
        "rougeL": {
            "precision": 0.52515,
            "recall": 0.45036,
            "fmeasure": 0.46248
        },
        "rougeLsum": {
            "precision": 0.52515,
            "recall": 0.45036,
            "fmeasure": 0.46248
        },
        "nist": 3.7750173595683503,
        "bleu": 31.62323,
        "nubia": {
            "semantic_relation": 3.63254,
            "contradiction": 20.00918,
            "irrelevancy": 50.98062,
            "logical_agreement": 29.0102,
            "grammar_ref": 4.54253,
            "grammar_hyp": 4.35603,
            "nubia_score": 0.50929
        },
        "bertscore": {
            "precision": 0.87122,
            "recall": 0.84734,
            "f1": 0.85314
        },
        "meteor": 0.3145372114973466,
        "bleurt": -0.12669
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.78125
        },
        "rouge1": {
            "precision": 0.84063,
            "recall": 0.80787,
            "fmeasure": 0.80467
        },
        "rouge2": {
            "precision": 0.60833,
            "recall": 0.6111,
            "fmeasure": 0.59361
        },
        "rougeL": {
            "precision": 0.74972,
            "recall": 0.72269,
            "fmeasure": 0.71738
        },
        "rougeLsum": {
            "precision": 0.74972,
            "recall": 0.72269,
            "fmeasure": 0.71738
        },
        "nist": 3.2823707374834297,
        "bleu": 46.08214,
        "nubia": {
            "semantic_relation": 3.98111,
            "contradiction": 0.75044,
            "irrelevancy": 58.48657,
            "logical_agreement": 40.76299,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.86546,
            "nubia_score": 0.61112
        },
        "bertscore": {
            "precision": 0.92831,
            "recall": 0.93897,
            "f1": 0.93277
        },
        "meteor": 0.42936558319999213,
        "bleurt": 0.10769
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.71821,
            "fmeasure": 0.77949
        },
        "rouge2": {
            "precision": 0.73611,
            "recall": 0.60684,
            "fmeasure": 0.65989
        },
        "rougeL": {
            "precision": 0.82667,
            "recall": 0.68112,
            "fmeasure": 0.74048
        },
        "rougeLsum": {
            "precision": 0.82667,
            "recall": 0.68112,
            "fmeasure": 0.74048
        },
        "nist": 2.1326508714910997,
        "bleu": 55.42375,
        "nubia": {
            "semantic_relation": 2.7173,
            "contradiction": 98.46634,
            "irrelevancy": 0.60717,
            "logical_agreement": 0.92649,
            "grammar_ref": 3.4256,
            "grammar_hyp": 3.37706,
            "nubia_score": 0.28576
        },
        "bertscore": {
            "precision": 0.96158,
            "recall": 0.91668,
            "f1": 0.93859
        },
        "meteor": 0.4362280240375045,
        "bleurt": 0.09982
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "nist": 4.090634124990776,
        "bleu": 76.11606,
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        },
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        },
        "meteor": 0.5715186082473627,
        "bleurt": 0.48581
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.25
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.32479,
            "fmeasure": 0.43636
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.07937,
            "fmeasure": 0.10741
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.29402,
            "fmeasure": 0.38788
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.29402,
            "fmeasure": 0.38788
        },
        "nist": 0.22125202633764687,
        "bleu": 4.42014,
        "nubia": {
            "semantic_relation": 2.77856,
            "contradiction": 5.43097,
            "irrelevancy": 30.9441,
            "logical_agreement": 63.62493,
            "grammar_ref": 4.61776,
            "grammar_hyp": 5.17462,
            "nubia_score": 0.22176
        },
        "bertscore": {
            "precision": 0.84326,
            "recall": 0.76332,
            "f1": 0.8013
        },
        "meteor": 0.14078298802960232,
        "bleurt": -0.86803
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.77576,
            "fmeasure": 0.63179
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.5037,
            "fmeasure": 0.40097
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.77576,
            "fmeasure": 0.63179
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.77576,
            "fmeasure": 0.63179
        },
        "nist": 1.4586137819039766,
        "bleu": 6.76023,
        "nubia": {
            "semantic_relation": 3.59735,
            "contradiction": 4.4446,
            "irrelevancy": 94.92243,
            "logical_agreement": 0.63297,
            "grammar_ref": 4.055,
            "grammar_hyp": 4.37612,
            "nubia_score": 0.48565
        },
        "bertscore": {
            "precision": 0.83286,
            "recall": 0.92341,
            "f1": 0.87559
        },
        "meteor": 0.31476453269113247,
        "bleurt": -0.35537
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.75,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.68333,
            "recall": 0.68333,
            "fmeasure": 0.68333
        },
        "rouge2": {
            "precision": 0.4386,
            "recall": 0.44542,
            "fmeasure": 0.44192
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.62105,
            "fmeasure": 0.61026
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.62105,
            "fmeasure": 0.61026
        },
        "nist": 3.7086478196432457,
        "bleu": 24.96109,
        "nubia": {
            "semantic_relation": 3.89915,
            "contradiction": 0.60987,
            "irrelevancy": 85.67519,
            "logical_agreement": 13.71495,
            "grammar_ref": 5.26752,
            "grammar_hyp": 4.46956,
            "nubia_score": 0.67733
        },
        "bertscore": {
            "precision": 0.89592,
            "recall": 0.91119,
            "f1": 0.90349
        },
        "meteor": 0.38113363620822577,
        "bleurt": 0.01627
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5833333333333334
        },
        "rouge1": {
            "precision": 0.48889,
            "recall": 0.44,
            "fmeasure": 0.45517
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.13287,
            "fmeasure": 0.1358
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.24845,
            "fmeasure": 0.25408
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.24845,
            "fmeasure": 0.25408
        },
        "nist": 1.5571414956748417,
        "bleu": 8.22596,
        "nubia": {
            "semantic_relation": 3.74442,
            "contradiction": 0.05797,
            "irrelevancy": 99.53914,
            "logical_agreement": 0.40289,
            "grammar_ref": 4.57081,
            "grammar_hyp": 5.15866,
            "nubia_score": 0.4867
        },
        "bertscore": {
            "precision": 0.85587,
            "recall": 0.85739,
            "f1": 0.85663
        },
        "meteor": 0.2552772874919791,
        "bleurt": -0.04438
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.79487,
            "recall": 0.5103,
            "fmeasure": 0.62037
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.37691,
            "fmeasure": 0.44904
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 0.49123,
            "fmeasure": 0.5746
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 0.49123,
            "fmeasure": 0.5746
        },
        "nist": 1.994475133804124,
        "bleu": 26.09364,
        "nubia": {
            "semantic_relation": 3.55364,
            "contradiction": 92.10958,
            "irrelevancy": 5.28862,
            "logical_agreement": 2.60179,
            "grammar_ref": 4.95426,
            "grammar_hyp": 4.55377,
            "nubia_score": 0.4646
        },
        "bertscore": {
            "precision": 0.92898,
            "recall": 0.8641,
            "f1": 0.89537
        },
        "meteor": 0.29572180090471145,
        "bleurt": 0.02492
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.8,
            "fmeasure": 0.80702
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.7037,
            "fmeasure": 0.70588
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.76667,
            "fmeasure": 0.77193
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.76667,
            "fmeasure": 0.77193
        },
        "nist": 3.923549743383573,
        "bleu": 68.14154,
        "nubia": {
            "semantic_relation": 4.61187,
            "contradiction": 0.42729,
            "irrelevancy": 5.39194,
            "logical_agreement": 94.18077,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.90122,
            "nubia_score": 0.84762
        },
        "bertscore": {
            "precision": 0.96383,
            "recall": 0.95023,
            "f1": 0.95687
        },
        "meteor": 0.48383703309871473,
        "bleurt": 0.66684
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.83502,
            "fmeasure": 0.73982
        },
        "rouge2": {
            "precision": 0.30303,
            "recall": 0.41667,
            "fmeasure": 0.35088
        },
        "rougeL": {
            "precision": 0.47222,
            "recall": 0.62963,
            "fmeasure": 0.53968
        },
        "rougeLsum": {
            "precision": 0.47222,
            "recall": 0.62963,
            "fmeasure": 0.53968
        },
        "nist": 3.096827195661354,
        "bleu": 22.35509,
        "nubia": {
            "semantic_relation": 4.81615,
            "contradiction": 0.34467,
            "irrelevancy": 41.7688,
            "logical_agreement": 57.88652,
            "grammar_ref": 6.26263,
            "grammar_hyp": 5.64642,
            "nubia_score": 0.86662
        },
        "bertscore": {
            "precision": 0.93091,
            "recall": 0.92721,
            "f1": 0.92906
        },
        "meteor": 0.3288628544146203,
        "bleurt": 0.45277
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.94872,
            "fmeasure": 0.89316
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.88889,
            "fmeasure": 0.82828
        },
        "rougeL": {
            "precision": 0.79487,
            "recall": 0.89744,
            "fmeasure": 0.84188
        },
        "rougeLsum": {
            "precision": 0.79487,
            "recall": 0.89744,
            "fmeasure": 0.84188
        },
        "nist": 4.687577194687257,
        "bleu": 85.55262,
        "nubia": {
            "semantic_relation": 4.8635,
            "contradiction": 0.60277,
            "irrelevancy": 54.28501,
            "logical_agreement": 45.11222,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.77462,
            "nubia_score": 0.88115
        },
        "bertscore": {
            "precision": 0.93951,
            "recall": 0.97507,
            "f1": 0.95571
        },
        "meteor": 0.6100257941925625,
        "bleurt": 0.14719
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_base/totto_test",
        "N": 898,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23343974461292896,
            "2": 0.5230987917555082,
            "3": 0.7314592195302386
        },
        "rouge1": {
            "precision": 0.75407,
            "recall": 0.70358,
            "fmeasure": 0.71203
        },
        "rouge2": {
            "precision": 0.55463,
            "recall": 0.52125,
            "fmeasure": 0.52504
        },
        "rougeL": {
            "precision": 0.71183,
            "recall": 0.66897,
            "fmeasure": 0.67488
        },
        "rougeLsum": {
            "precision": 0.71183,
            "recall": 0.66897,
            "fmeasure": 0.67488
        },
        "nist": 8.541124888896505,
        "bleu": 49.12565,
        "nubia": {
            "semantic_relation": 4.0344,
            "contradiction": 11.2058,
            "irrelevancy": 29.20764,
            "logical_agreement": 59.58656,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.17334,
            "nubia_score": 0.68296
        },
        "bertscore": {
            "precision": 0.93169,
            "recall": 0.92162,
            "f1": 0.92519
        },
        "meteor": 0.3957481293283168,
        "bleurt": 0.29309
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.8,
            "3": 0.64
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.67858,
            "fmeasure": 0.74733
        },
        "rouge2": {
            "precision": 0.43968,
            "recall": 0.33763,
            "fmeasure": 0.38148
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.46948,
            "fmeasure": 0.51123
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.46948,
            "fmeasure": 0.51123
        },
        "nist": 2.9132940955222284,
        "bleu": 15.47187,
        "nubia": {
            "semantic_relation": 4.30463,
            "contradiction": 0.27427,
            "irrelevancy": 0.4939,
            "logical_agreement": 99.23183,
            "grammar_ref": 4.18803,
            "grammar_hyp": 3.97371,
            "nubia_score": 0.85877
        },
        "bertscore": {
            "precision": 0.91471,
            "recall": 0.84931,
            "f1": 0.87787
        },
        "meteor": 0.32471046507373447,
        "bleurt": 0.24703
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "mT5_base/totto_test",
        "N": 79,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.44565217391304346,
            "3": 0.8088737201365188
        },
        "rouge1": {
            "precision": 0.76573,
            "recall": 0.7396,
            "fmeasure": 0.74445
        },
        "rouge2": {
            "precision": 0.55492,
            "recall": 0.53721,
            "fmeasure": 0.54073
        },
        "rougeL": {
            "precision": 0.6658,
            "recall": 0.64923,
            "fmeasure": 0.65088
        },
        "rougeLsum": {
            "precision": 0.6658,
            "recall": 0.64923,
            "fmeasure": 0.65088
        },
        "nist": 7.451126715514847,
        "bleu": 51.64274,
        "nubia": {
            "semantic_relation": 4.09107,
            "contradiction": 13.55496,
            "irrelevancy": 27.0057,
            "logical_agreement": 59.43934,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.40596,
            "nubia_score": 0.71664
        },
        "bertscore": {
            "precision": 0.9326,
            "recall": 0.9271,
            "f1": 0.92766
        },
        "meteor": 0.39954497746838724,
        "bleurt": 0.29386
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.35,
            "recall": 0.53472,
            "fmeasure": 0.4213
        },
        "rouge2": {
            "precision": 0.05263,
            "recall": 0.08283,
            "fmeasure": 0.06405
        },
        "rougeL": {
            "precision": 0.15,
            "recall": 0.22917,
            "fmeasure": 0.18056
        },
        "rougeLsum": {
            "precision": 0.15,
            "recall": 0.22917,
            "fmeasure": 0.18056
        },
        "nist": 1.4570960005977136,
        "bleu": 4.88533,
        "nubia": {
            "semantic_relation": 3.76491,
            "contradiction": 2.42338,
            "irrelevancy": 90.49624,
            "logical_agreement": 7.08039,
            "grammar_ref": 5.53377,
            "grammar_hyp": 4.30944,
            "nubia_score": 0.68904
        },
        "bertscore": {
            "precision": 0.79642,
            "recall": 0.82706,
            "f1": 0.80733
        },
        "meteor": 0.2188482587531048,
        "bleurt": -0.25405
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.88095,
            "recall": 0.725,
            "fmeasure": 0.79346
        },
        "rouge2": {
            "precision": 0.76923,
            "recall": 0.62924,
            "fmeasure": 0.69048
        },
        "rougeL": {
            "precision": 0.7381,
            "recall": 0.60833,
            "fmeasure": 0.66536
        },
        "rougeLsum": {
            "precision": 0.7381,
            "recall": 0.60833,
            "fmeasure": 0.66536
        },
        "nist": 2.8727902935965313,
        "bleu": 61.47866,
        "nubia": {
            "semantic_relation": 4.6505,
            "contradiction": 0.21801,
            "irrelevancy": 0.62946,
            "logical_agreement": 99.15253,
            "grammar_ref": 3.95052,
            "grammar_hyp": 4.66898,
            "nubia_score": 0.85809
        },
        "bertscore": {
            "precision": 0.96371,
            "recall": 0.93754,
            "f1": 0.95044
        },
        "meteor": 0.497328366166536,
        "bleurt": 0.46544
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.42619,
            "recall": 0.70255,
            "fmeasure": 0.48498
        },
        "rouge2": {
            "precision": 0.2278,
            "recall": 0.35466,
            "fmeasure": 0.25609
        },
        "rougeL": {
            "precision": 0.37024,
            "recall": 0.61748,
            "fmeasure": 0.42245
        },
        "rougeLsum": {
            "precision": 0.37024,
            "recall": 0.61748,
            "fmeasure": 0.42245
        },
        "nist": 0.7271001767805476,
        "bleu": 4.84102,
        "nubia": {
            "semantic_relation": 4.18567,
            "contradiction": 1.7592,
            "irrelevancy": 36.50489,
            "logical_agreement": 61.73591,
            "grammar_ref": 4.46901,
            "grammar_hyp": 2.53715,
            "nubia_score": 0.60644
        },
        "bertscore": {
            "precision": 0.82781,
            "recall": 0.91025,
            "f1": 0.86499
        },
        "meteor": 0.2277696045874285,
        "bleurt": 0.17418
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.67708,
            "recall": 0.51832,
            "fmeasure": 0.57058
        },
        "rouge2": {
            "precision": 0.39048,
            "recall": 0.24466,
            "fmeasure": 0.29581
        },
        "rougeL": {
            "precision": 0.64583,
            "recall": 0.47985,
            "fmeasure": 0.5361
        },
        "rougeLsum": {
            "precision": 0.64583,
            "recall": 0.47985,
            "fmeasure": 0.5361
        },
        "nist": 2.4189275814406175,
        "bleu": 25.76648,
        "nubia": {
            "semantic_relation": 3.50652,
            "contradiction": 0.22416,
            "irrelevancy": 48.17167,
            "logical_agreement": 51.60417,
            "grammar_ref": 4.47266,
            "grammar_hyp": 3.86625,
            "nubia_score": 0.63411
        },
        "bertscore": {
            "precision": 0.87171,
            "recall": 0.84095,
            "f1": 0.85565
        },
        "meteor": 0.269556323796831,
        "bleurt": -0.19248
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.90741,
            "recall": 0.76944,
            "fmeasure": 0.83124
        },
        "rouge2": {
            "precision": 0.58824,
            "recall": 0.4958,
            "fmeasure": 0.53704
        },
        "rougeL": {
            "precision": 0.53704,
            "recall": 0.56667,
            "fmeasure": 0.55005
        },
        "rougeLsum": {
            "precision": 0.53704,
            "recall": 0.56667,
            "fmeasure": 0.55005
        },
        "nist": 4.199430449946261,
        "bleu": 51.01365,
        "nubia": {
            "semantic_relation": 3.98754,
            "contradiction": 78.9885,
            "irrelevancy": 17.67447,
            "logical_agreement": 3.33703,
            "grammar_ref": 4.75667,
            "grammar_hyp": 4.29336,
            "nubia_score": 0.65714
        },
        "bertscore": {
            "precision": 0.91115,
            "recall": 0.89552,
            "f1": 0.90233
        },
        "meteor": 0.4142154030452011,
        "bleurt": -0.17819
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "mT5_base/totto_test",
        "N": 8,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.6486486486486487,
            "3": 0.7123287671232876
        },
        "rouge1": {
            "precision": 0.80468,
            "recall": 0.68471,
            "fmeasure": 0.72873
        },
        "rouge2": {
            "precision": 0.55934,
            "recall": 0.4894,
            "fmeasure": 0.51483
        },
        "rougeL": {
            "precision": 0.70965,
            "recall": 0.61415,
            "fmeasure": 0.64907
        },
        "rougeLsum": {
            "precision": 0.70965,
            "recall": 0.61415,
            "fmeasure": 0.64907
        },
        "nist": 4.51790914189366,
        "bleu": 43.38458,
        "nubia": {
            "semantic_relation": 3.51777,
            "contradiction": 34.75723,
            "irrelevancy": 35.09794,
            "logical_agreement": 30.14483,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.59794,
            "nubia_score": 0.49705
        },
        "bertscore": {
            "precision": 0.92467,
            "recall": 0.90038,
            "f1": 0.91122
        },
        "meteor": 0.3692477659170488,
        "bleurt": 0.07421
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.72222,
            "fmeasure": 0.73529
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.27381,
            "fmeasure": 0.27937
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.48148,
            "fmeasure": 0.4902
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.48148,
            "fmeasure": 0.4902
        },
        "nist": 2.412470857297462,
        "bleu": 21.72186,
        "nubia": {
            "semantic_relation": 4.23406,
            "contradiction": 33.24587,
            "irrelevancy": 10.78097,
            "logical_agreement": 55.97316,
            "grammar_ref": 5.1757,
            "grammar_hyp": 5.40653,
            "nubia_score": 0.53524
        },
        "bertscore": {
            "precision": 0.8827,
            "recall": 0.87253,
            "f1": 0.87654
        },
        "meteor": 0.35565132245924147,
        "bleurt": 0.01312
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 0.9473684210526315
        },
        "rouge1": {
            "precision": 0.84375,
            "recall": 0.9213,
            "fmeasure": 0.8772
        },
        "rouge2": {
            "precision": 0.72381,
            "recall": 0.8006,
            "fmeasure": 0.75661
        },
        "rougeL": {
            "precision": 0.78125,
            "recall": 0.84437,
            "fmeasure": 0.80823
        },
        "rougeLsum": {
            "precision": 0.78125,
            "recall": 0.84437,
            "fmeasure": 0.80823
        },
        "nist": 4.145207810016658,
        "bleu": 62.89636,
        "nubia": {
            "semantic_relation": 4.50418,
            "contradiction": 0.29538,
            "irrelevancy": 35.21478,
            "logical_agreement": 64.48984,
            "grammar_ref": 5.10267,
            "grammar_hyp": 5.09075,
            "nubia_score": 0.82042
        },
        "bertscore": {
            "precision": 0.94255,
            "recall": 0.94118,
            "f1": 0.93871
        },
        "meteor": 0.49203544048895936,
        "bleurt": 0.35965
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3125,
            "2": 0.5,
            "3": 0.8421052631578947
        },
        "rouge1": {
            "precision": 0.67273,
            "recall": 0.7663,
            "fmeasure": 0.7091
        },
        "rouge2": {
            "precision": 0.41964,
            "recall": 0.47362,
            "fmeasure": 0.44199
        },
        "rougeL": {
            "precision": 0.51648,
            "recall": 0.6116,
            "fmeasure": 0.55358
        },
        "rougeLsum": {
            "precision": 0.51648,
            "recall": 0.6116,
            "fmeasure": 0.55358
        },
        "nist": 4.448504880985607,
        "bleu": 51.71273,
        "nubia": {
            "semantic_relation": 4.63488,
            "contradiction": 4.84185,
            "irrelevancy": 20.02684,
            "logical_agreement": 75.1313,
            "grammar_ref": 4.54108,
            "grammar_hyp": 4.19405,
            "nubia_score": 0.82277
        },
        "bertscore": {
            "precision": 0.92255,
            "recall": 0.92162,
            "f1": 0.92058
        },
        "meteor": 0.4191870399669689,
        "bleurt": 0.53315
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.803921568627451
        },
        "rouge1": {
            "precision": 0.92577,
            "recall": 0.83737,
            "fmeasure": 0.87691
        },
        "rouge2": {
            "precision": 0.84205,
            "recall": 0.76067,
            "fmeasure": 0.79676
        },
        "rougeL": {
            "precision": 0.91188,
            "recall": 0.82547,
            "fmeasure": 0.86409
        },
        "rougeLsum": {
            "precision": 0.91188,
            "recall": 0.82547,
            "fmeasure": 0.86409
        },
        "nist": 4.434654462797027,
        "bleu": 61.37874,
        "nubia": {
            "semantic_relation": 4.18346,
            "contradiction": 43.76754,
            "irrelevancy": 4.25661,
            "logical_agreement": 51.97585,
            "grammar_ref": 3.98368,
            "grammar_hyp": 4.17929,
            "nubia_score": 0.73187
        },
        "bertscore": {
            "precision": 0.9788,
            "recall": 0.95889,
            "f1": 0.96859
        },
        "meteor": 0.457352648112712,
        "bleurt": 0.60022
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.6923076923076923,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.77071,
            "fmeasure": 0.85081
        },
        "rouge2": {
            "precision": 0.74286,
            "recall": 0.58712,
            "fmeasure": 0.654
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.73182,
            "fmeasure": 0.809
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.73182,
            "fmeasure": 0.809
        },
        "nist": 2.9845311415425684,
        "bleu": 58.99293,
        "nubia": {
            "semantic_relation": 4.42644,
            "contradiction": 1.88588,
            "irrelevancy": 2.28457,
            "logical_agreement": 95.82955,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.8148,
            "nubia_score": 0.80287
        },
        "bertscore": {
            "precision": 0.98964,
            "recall": 0.94926,
            "f1": 0.96903
        },
        "meteor": 0.43214718476299563,
        "bleurt": 0.55946
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6875,
            "3": 0.9130434782608695
        },
        "rouge1": {
            "precision": 0.85641,
            "recall": 0.82164,
            "fmeasure": 0.83587
        },
        "rouge2": {
            "precision": 0.69048,
            "recall": 0.66361,
            "fmeasure": 0.67453
        },
        "rougeL": {
            "precision": 0.70171,
            "recall": 0.67622,
            "fmeasure": 0.68665
        },
        "rougeLsum": {
            "precision": 0.70171,
            "recall": 0.67622,
            "fmeasure": 0.68665
        },
        "nist": 4.554706280400218,
        "bleu": 57.01513,
        "nubia": {
            "semantic_relation": 4.23129,
            "contradiction": 3.80875,
            "irrelevancy": 62.45663,
            "logical_agreement": 33.73462,
            "grammar_ref": 4.8308,
            "grammar_hyp": 5.24166,
            "nubia_score": 0.65635
        },
        "bertscore": {
            "precision": 0.94265,
            "recall": 0.95284,
            "f1": 0.9469
        },
        "meteor": 0.47634846086954064,
        "bleurt": 0.33778
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.1699250014423126,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.99428
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.7333333333333333
        },
        "rouge1": {
            "precision": 0.6197,
            "recall": 0.65705,
            "fmeasure": 0.62349
        },
        "rouge2": {
            "precision": 0.32222,
            "recall": 0.32727,
            "fmeasure": 0.31674
        },
        "rougeL": {
            "precision": 0.49848,
            "recall": 0.55235,
            "fmeasure": 0.51117
        },
        "rougeLsum": {
            "precision": 0.49848,
            "recall": 0.55235,
            "fmeasure": 0.51117
        },
        "nist": 3.1976593195230096,
        "bleu": 27.52895,
        "nubia": {
            "semantic_relation": 3.70224,
            "contradiction": 0.31396,
            "irrelevancy": 66.18604,
            "logical_agreement": 33.5,
            "grammar_ref": 5.09196,
            "grammar_hyp": 4.71605,
            "nubia_score": 0.63219
        },
        "bertscore": {
            "precision": 0.88295,
            "recall": 0.90509,
            "f1": 0.89311
        },
        "meteor": 0.37300510381025653,
        "bleurt": -0.21548
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.34119,
            "fmeasure": 0.46358
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.2674,
            "fmeasure": 0.36918
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.29854,
            "fmeasure": 0.40564
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.29854,
            "fmeasure": 0.40564
        },
        "nist": 0.19432195860366142,
        "bleu": 17.92681,
        "nubia": {
            "semantic_relation": 3.33397,
            "contradiction": 5.86135,
            "irrelevancy": 1.66517,
            "logical_agreement": 92.47349,
            "grammar_ref": 5.07625,
            "grammar_hyp": 5.6356,
            "nubia_score": 0.31744
        },
        "bertscore": {
            "precision": 0.87739,
            "recall": 0.81951,
            "f1": 0.84746
        },
        "meteor": 0.2526845694782849,
        "bleurt": -0.29666
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.8333333333333334,
            "3": 0.3
        },
        "rouge1": {
            "precision": 0.59524,
            "recall": 0.5085,
            "fmeasure": 0.54802
        },
        "rouge2": {
            "precision": 0.28205,
            "recall": 0.25758,
            "fmeasure": 0.26724
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.37582,
            "fmeasure": 0.36394
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.37582,
            "fmeasure": 0.36394
        },
        "nist": 2.4018126657915033,
        "bleu": 18.84239,
        "nubia": {
            "semantic_relation": 2.57881,
            "contradiction": 27.85279,
            "irrelevancy": 17.26797,
            "logical_agreement": 54.87925,
            "grammar_ref": 4.69116,
            "grammar_hyp": 3.96188,
            "nubia_score": 0.35126
        },
        "bertscore": {
            "precision": 0.81557,
            "recall": 0.85272,
            "f1": 0.83093
        },
        "meteor": 0.2514199821343277,
        "bleurt": -0.33594
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8235294117647058
        },
        "rouge1": {
            "precision": 0.86364,
            "recall": 0.87593,
            "fmeasure": 0.84997
        },
        "rouge2": {
            "precision": 0.68889,
            "recall": 0.71098,
            "fmeasure": 0.67993
        },
        "rougeL": {
            "precision": 0.77273,
            "recall": 0.75093,
            "fmeasure": 0.74471
        },
        "rougeLsum": {
            "precision": 0.77273,
            "recall": 0.75093,
            "fmeasure": 0.74471
        },
        "nist": 3.391493406274191,
        "bleu": 50.37456,
        "nubia": {
            "semantic_relation": 4.29193,
            "contradiction": 2.1512,
            "irrelevancy": 45.93071,
            "logical_agreement": 51.91809,
            "grammar_ref": 4.99735,
            "grammar_hyp": 5.70944,
            "nubia_score": 0.59868
        },
        "bertscore": {
            "precision": 0.92816,
            "recall": 0.94525,
            "f1": 0.9353
        },
        "meteor": 0.48205658721990624,
        "bleurt": 0.27477
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.74306,
            "recall": 0.5327,
            "fmeasure": 0.61659
        },
        "rouge2": {
            "precision": 0.44048,
            "recall": 0.30972,
            "fmeasure": 0.36145
        },
        "rougeL": {
            "precision": 0.74306,
            "recall": 0.5327,
            "fmeasure": 0.61659
        },
        "rougeLsum": {
            "precision": 0.74306,
            "recall": 0.5327,
            "fmeasure": 0.61659
        },
        "nist": 1.6086100122836855,
        "bleu": 23.38843,
        "nubia": {
            "semantic_relation": 4.80336,
            "contradiction": 0.38653,
            "irrelevancy": 0.71119,
            "logical_agreement": 98.90228,
            "grammar_ref": 4.6711,
            "grammar_hyp": 5.39239,
            "nubia_score": 0.87267
        },
        "bertscore": {
            "precision": 0.96603,
            "recall": 0.93316,
            "f1": 0.94928
        },
        "meteor": 0.3755939325969165,
        "bleurt": 0.36432
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.81481,
            "fmeasure": 0.78974
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.64286,
            "fmeasure": 0.61111
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.81481,
            "fmeasure": 0.78974
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.81481,
            "fmeasure": 0.78974
        },
        "nist": 4.1294709175589395,
        "bleu": 48.68357,
        "nubia": {
            "semantic_relation": 4.4182,
            "contradiction": 0.25512,
            "irrelevancy": 1.02065,
            "logical_agreement": 98.72424,
            "grammar_ref": 4.01628,
            "grammar_hyp": 3.55868,
            "nubia_score": 0.90114
        },
        "bertscore": {
            "precision": 0.95241,
            "recall": 0.97474,
            "f1": 0.96345
        },
        "meteor": 0.5220503747508378,
        "bleurt": 0.64203
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.423065265165703,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.94038
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.16666666666666666,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.78611,
            "recall": 0.8343,
            "fmeasure": 0.80081
        },
        "rouge2": {
            "precision": 0.73653,
            "recall": 0.78056,
            "fmeasure": 0.74201
        },
        "rougeL": {
            "precision": 0.78611,
            "recall": 0.8343,
            "fmeasure": 0.80081
        },
        "rougeLsum": {
            "precision": 0.78611,
            "recall": 0.8343,
            "fmeasure": 0.80081
        },
        "nist": 4.781356789546917,
        "bleu": 71.32717,
        "nubia": {
            "semantic_relation": 4.49717,
            "contradiction": 0.87809,
            "irrelevancy": 46.63152,
            "logical_agreement": 52.49038,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.50047,
            "nubia_score": 0.8408
        },
        "bertscore": {
            "precision": 0.96028,
            "recall": 0.97054,
            "f1": 0.96397
        },
        "meteor": 0.5090572727970035,
        "bleurt": 0.57377
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.4,
            "3": 0.782608695652174
        },
        "rouge1": {
            "precision": 0.53885,
            "recall": 0.69887,
            "fmeasure": 0.59986
        },
        "rouge2": {
            "precision": 0.38782,
            "recall": 0.63345,
            "fmeasure": 0.46927
        },
        "rougeL": {
            "precision": 0.49092,
            "recall": 0.74619,
            "fmeasure": 0.58179
        },
        "rougeLsum": {
            "precision": 0.49092,
            "recall": 0.74619,
            "fmeasure": 0.58179
        },
        "nist": 3.716975128246908,
        "bleu": 41.02744,
        "nubia": {
            "semantic_relation": 4.36788,
            "contradiction": 0.75049,
            "irrelevancy": 50.36974,
            "logical_agreement": 48.87977,
            "grammar_ref": 4.39403,
            "grammar_hyp": 3.63414,
            "nubia_score": 0.82995
        },
        "bertscore": {
            "precision": 0.88802,
            "recall": 0.9571,
            "f1": 0.92092
        },
        "meteor": 0.3958296658625483,
        "bleurt": 0.27688
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "nist": 4.048415664983272,
        "bleu": 67.03421,
        "nubia": {
            "semantic_relation": 4.20744,
            "contradiction": 61.82775,
            "irrelevancy": 32.46797,
            "logical_agreement": 5.70428,
            "grammar_ref": 5.3705,
            "grammar_hyp": 4.88808,
            "nubia_score": 0.61372
        },
        "bertscore": {
            "precision": 0.97259,
            "recall": 0.98308,
            "f1": 0.97766
        },
        "meteor": 0.5091857548700987,
        "bleurt": 0.58965
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.82353,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70238
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "nist": 4.306797170061882,
        "bleu": 69.04427,
        "nubia": {
            "semantic_relation": 4.27928,
            "contradiction": 0.25448,
            "irrelevancy": 0.49291,
            "logical_agreement": 99.25261,
            "grammar_ref": 4.29821,
            "grammar_hyp": 4.38971,
            "nubia_score": 0.78008
        },
        "bertscore": {
            "precision": 0.97265,
            "recall": 0.97025,
            "f1": 0.97145
        },
        "meteor": 0.5500501807094148,
        "bleurt": 0.47554
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7419354838709677
        },
        "rouge1": {
            "precision": 0.70846,
            "recall": 0.7904,
            "fmeasure": 0.73634
        },
        "rouge2": {
            "precision": 0.5216,
            "recall": 0.55253,
            "fmeasure": 0.52953
        },
        "rougeL": {
            "precision": 0.69091,
            "recall": 0.76178,
            "fmeasure": 0.7146
        },
        "rougeLsum": {
            "precision": 0.69091,
            "recall": 0.76178,
            "fmeasure": 0.7146
        },
        "nist": 3.2434264707562352,
        "bleu": 38.24246,
        "nubia": {
            "semantic_relation": 4.1542,
            "contradiction": 6.30428,
            "irrelevancy": 25.26156,
            "logical_agreement": 68.43416,
            "grammar_ref": 3.77014,
            "grammar_hyp": 3.88425,
            "nubia_score": 0.73329
        },
        "bertscore": {
            "precision": 0.918,
            "recall": 0.95126,
            "f1": 0.93344
        },
        "meteor": 0.39054909785223685,
        "bleurt": 0.44158
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.98889,
            "recall": 0.90814,
            "fmeasure": 0.94675
        },
        "rouge2": {
            "precision": 0.97701,
            "recall": 0.89449,
            "fmeasure": 0.93388
        },
        "rougeL": {
            "precision": 0.98889,
            "recall": 0.90814,
            "fmeasure": 0.94675
        },
        "rougeLsum": {
            "precision": 0.98889,
            "recall": 0.90814,
            "fmeasure": 0.94675
        },
        "nist": 5.2122482882381895,
        "bleu": 76.98514,
        "nubia": {
            "semantic_relation": 3.79978,
            "contradiction": 0.12695,
            "irrelevancy": 0.64836,
            "logical_agreement": 99.22469,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.32939,
            "nubia_score": 0.71143
        },
        "bertscore": {
            "precision": 0.99453,
            "recall": 0.97156,
            "f1": 0.98291
        },
        "meteor": 0.511296800179274,
        "bleurt": 0.60241
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.47348,
            "fmeasure": 0.52696
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.27706,
            "fmeasure": 0.30682
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.34091,
            "fmeasure": 0.36765
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.34091,
            "fmeasure": 0.36765
        },
        "nist": 1.7386156069440368,
        "bleu": 32.55964,
        "nubia": {
            "semantic_relation": 3.03325,
            "contradiction": 1.19389,
            "irrelevancy": 96.31422,
            "logical_agreement": 2.49189,
            "grammar_ref": 4.87259,
            "grammar_hyp": 5.63324,
            "nubia_score": 0.27012
        },
        "bertscore": {
            "precision": 0.91053,
            "recall": 0.90578,
            "f1": 0.90815
        },
        "meteor": 0.3371785849569357,
        "bleurt": -0.37615
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5882352941176471
        },
        "rouge1": {
            "precision": 0.82353,
            "recall": 0.62714,
            "fmeasure": 0.71197
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.46032,
            "fmeasure": 0.53011
        },
        "rougeL": {
            "precision": 0.80392,
            "recall": 0.60277,
            "fmeasure": 0.68889
        },
        "rougeLsum": {
            "precision": 0.80392,
            "recall": 0.60277,
            "fmeasure": 0.68889
        },
        "nist": 2.029998654650492,
        "bleu": 36.71749,
        "nubia": {
            "semantic_relation": 4.17117,
            "contradiction": 75.41755,
            "irrelevancy": 6.21062,
            "logical_agreement": 18.37183,
            "grammar_ref": 3.0511,
            "grammar_hyp": 3.20579,
            "nubia_score": 0.75999
        },
        "bertscore": {
            "precision": 0.93287,
            "recall": 0.90297,
            "f1": 0.91767
        },
        "meteor": 0.3387915147539267,
        "bleurt": 0.25363
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.2857142857142857,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.62222,
            "recall": 0.80912,
            "fmeasure": 0.69841
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.33333,
            "fmeasure": 0.25874
        },
        "rougeL": {
            "precision": 0.42222,
            "recall": 0.6,
            "fmeasure": 0.48889
        },
        "rougeLsum": {
            "precision": 0.42222,
            "recall": 0.6,
            "fmeasure": 0.48889
        },
        "nist": 3.123464258221674,
        "bleu": 14.9808,
        "nubia": {
            "semantic_relation": 4.54723,
            "contradiction": 0.48017,
            "irrelevancy": 1.75286,
            "logical_agreement": 97.76698,
            "grammar_ref": 5.94843,
            "grammar_hyp": 5.60479,
            "nubia_score": 0.78293
        },
        "bertscore": {
            "precision": 0.88687,
            "recall": 0.89982,
            "f1": 0.89052
        },
        "meteor": 0.3619497799234601,
        "bleurt": 0.32483
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "rouge2": {
            "precision": 0.69444,
            "recall": 0.89744,
            "fmeasure": 0.77333
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "nist": 3.355696015088277,
        "bleu": 66.06329,
        "nubia": {
            "semantic_relation": 4.58606,
            "contradiction": 3.57286,
            "irrelevancy": 34.47091,
            "logical_agreement": 61.95623,
            "grammar_ref": 6.35753,
            "grammar_hyp": 6.86944,
            "nubia_score": 0.69479
        },
        "bertscore": {
            "precision": 0.94539,
            "recall": 0.99449,
            "f1": 0.95378
        },
        "meteor": 0.5257043737612862,
        "bleurt": 0.5014
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.4,
            "3": 0.7333333333333333
        },
        "rouge1": {
            "precision": 0.77617,
            "recall": 0.67254,
            "fmeasure": 0.71097
        },
        "rouge2": {
            "precision": 0.44931,
            "recall": 0.41749,
            "fmeasure": 0.43119
        },
        "rougeL": {
            "precision": 0.72182,
            "recall": 0.61819,
            "fmeasure": 0.65662
        },
        "rougeLsum": {
            "precision": 0.72182,
            "recall": 0.61819,
            "fmeasure": 0.65662
        },
        "nist": 4.156952956120604,
        "bleu": 43.19952,
        "nubia": {
            "semantic_relation": 4.19823,
            "contradiction": 2.81392,
            "irrelevancy": 2.96494,
            "logical_agreement": 94.22114,
            "grammar_ref": 4.34153,
            "grammar_hyp": 5.42129,
            "nubia_score": 0.6935
        },
        "bertscore": {
            "precision": 0.92052,
            "recall": 0.87215,
            "f1": 0.89524
        },
        "meteor": 0.37130552005331136,
        "bleurt": 0.21389
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.875,
            "3": 0.4
        },
        "rouge1": {
            "precision": 0.6131,
            "recall": 0.70833,
            "fmeasure": 0.64375
        },
        "rouge2": {
            "precision": 0.3042,
            "recall": 0.4212,
            "fmeasure": 0.34762
        },
        "rougeL": {
            "precision": 0.57738,
            "recall": 0.67824,
            "fmeasure": 0.61111
        },
        "rougeLsum": {
            "precision": 0.57738,
            "recall": 0.67824,
            "fmeasure": 0.61111
        },
        "nist": 2.4416319106069624,
        "bleu": 19.43848,
        "nubia": {
            "semantic_relation": 3.92022,
            "contradiction": 0.69013,
            "irrelevancy": 63.81614,
            "logical_agreement": 35.49374,
            "grammar_ref": 4.27476,
            "grammar_hyp": 4.24144,
            "nubia_score": 0.60294
        },
        "bertscore": {
            "precision": 0.88838,
            "recall": 0.89842,
            "f1": 0.89194
        },
        "meteor": 0.3054739169430222,
        "bleurt": 0.10479
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.59259,
            "recall": 0.47619,
            "fmeasure": 0.52479
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.25874,
            "fmeasure": 0.30576
        },
        "rougeL": {
            "precision": 0.59259,
            "recall": 0.47619,
            "fmeasure": 0.52479
        },
        "rougeLsum": {
            "precision": 0.59259,
            "recall": 0.47619,
            "fmeasure": 0.52479
        },
        "nist": 1.6585348934394,
        "bleu": 15.8271,
        "nubia": {
            "semantic_relation": 3.59812,
            "contradiction": 8.1895,
            "irrelevancy": 23.07297,
            "logical_agreement": 68.73753,
            "grammar_ref": 4.72922,
            "grammar_hyp": 5.92066,
            "nubia_score": 0.39465
        },
        "bertscore": {
            "precision": 0.92893,
            "recall": 0.88062,
            "f1": 0.90125
        },
        "meteor": 0.27004591964226465,
        "bleurt": 0.19228
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.35714,
            "recall": 0.47222,
            "fmeasure": 0.40598
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.10438,
            "fmeasure": 0.08838
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.37778,
            "fmeasure": 0.32479
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.37778,
            "fmeasure": 0.32479
        },
        "nist": 0.9340000908077821,
        "bleu": 3.7165,
        "nubia": {
            "semantic_relation": 2.94696,
            "contradiction": 0.1727,
            "irrelevancy": 99.70037,
            "logical_agreement": 0.12692,
            "grammar_ref": 4.40566,
            "grammar_hyp": 4.1309,
            "nubia_score": 0.37806
        },
        "bertscore": {
            "precision": 0.75976,
            "recall": 0.79365,
            "f1": 0.77634
        },
        "meteor": 0.2020323171963811,
        "bleurt": -0.41494
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.3157894736842105
        },
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.38384,
            "fmeasure": 0.45614
        },
        "rouge2": {
            "precision": 0.28889,
            "recall": 0.19255,
            "fmeasure": 0.23099
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.17918,
            "fmeasure": 0.20873
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.17918,
            "fmeasure": 0.20873
        },
        "nist": 1.507891586371933,
        "bleu": 8.75054,
        "nubia": {
            "semantic_relation": 3.35518,
            "contradiction": 54.35696,
            "irrelevancy": 33.36856,
            "logical_agreement": 12.27448,
            "grammar_ref": 4.34096,
            "grammar_hyp": 5.01747,
            "nubia_score": 0.33108
        },
        "bertscore": {
            "precision": 0.89814,
            "recall": 0.84884,
            "f1": 0.87279
        },
        "meteor": 0.22344673727665806,
        "bleurt": -0.19656
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.45454545454545453
        },
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.47857,
            "fmeasure": 0.54615
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.21703,
            "fmeasure": 0.25181
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.34048,
            "fmeasure": 0.38923
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.34048,
            "fmeasure": 0.38923
        },
        "nist": 3.0006339511684827,
        "bleu": 34.55764,
        "nubia": {
            "semantic_relation": 4.06878,
            "contradiction": 72.51704,
            "irrelevancy": 10.46826,
            "logical_agreement": 17.0147,
            "grammar_ref": 4.95834,
            "grammar_hyp": 5.30912,
            "nubia_score": 0.55376
        },
        "bertscore": {
            "precision": 0.92493,
            "recall": 0.90004,
            "f1": 0.91232
        },
        "meteor": 0.37056685299787695,
        "bleurt": 0.23778
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "nist": 2.456435556800404,
        "bleu": 50.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.0697,
            "irrelevancy": 0.59577,
            "logical_agreement": 98.33453,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.1752,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.98601,
            "recall": 0.99497,
            "f1": 0.99047
        },
        "meteor": 0.5277006683854432,
        "bleurt": 0.93658
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.48148,
            "fmeasure": 0.43665
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.6,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.6,
            "fmeasure": 0.57143
        },
        "nist": 2.5368420449956286,
        "bleu": 19.72941,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23086,
            "irrelevancy": 0.41185,
            "logical_agreement": 99.35729,
            "grammar_ref": 4.16465,
            "grammar_hyp": 3.70185,
            "nubia_score": 0.99438
        },
        "bertscore": {
            "precision": 0.94827,
            "recall": 0.94681,
            "f1": 0.94754
        },
        "meteor": 0.42367222196762794,
        "bleurt": 0.63543
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.14285714285714285,
            "3": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.73958,
            "recall": 0.70278,
            "fmeasure": 0.7195
        },
        "rouge2": {
            "precision": 0.4254,
            "recall": 0.40477,
            "fmeasure": 0.4141
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.61111,
            "fmeasure": 0.64542
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.61111,
            "fmeasure": 0.64542
        },
        "nist": 4.466611450577229,
        "bleu": 46.01026,
        "nubia": {
            "semantic_relation": 4.6595,
            "contradiction": 0.15331,
            "irrelevancy": 0.76762,
            "logical_agreement": 99.07906,
            "grammar_ref": 4.56769,
            "grammar_hyp": 4.8571,
            "nubia_score": 0.88157
        },
        "bertscore": {
            "precision": 0.95346,
            "recall": 0.95493,
            "f1": 0.95337
        },
        "meteor": 0.46551554356260927,
        "bleurt": 0.561
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.64583,
            "recall": 0.63743,
            "fmeasure": 0.63963
        },
        "rouge2": {
            "precision": 0.31111,
            "recall": 0.27407,
            "fmeasure": 0.29091
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.52865,
            "fmeasure": 0.553
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.52865,
            "fmeasure": 0.553
        },
        "nist": 2.8263383500306656,
        "bleu": 20.94841,
        "nubia": {
            "semantic_relation": 4.01953,
            "contradiction": 0.21907,
            "irrelevancy": 0.66064,
            "logical_agreement": 99.1203,
            "grammar_ref": 5.46955,
            "grammar_hyp": 4.77101,
            "nubia_score": 0.74322
        },
        "bertscore": {
            "precision": 0.90444,
            "recall": 0.86128,
            "f1": 0.88233
        },
        "meteor": 0.3043266771563659,
        "bleurt": 0.2475
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6363636363636364,
            "3": 0.9444444444444444
        },
        "rouge1": {
            "precision": 0.75833,
            "recall": 0.75532,
            "fmeasure": 0.75551
        },
        "rouge2": {
            "precision": 0.56725,
            "recall": 0.60859,
            "fmeasure": 0.57937
        },
        "rougeL": {
            "precision": 0.65833,
            "recall": 0.6481,
            "fmeasure": 0.65205
        },
        "rougeLsum": {
            "precision": 0.65833,
            "recall": 0.6481,
            "fmeasure": 0.65205
        },
        "nist": 3.7667231342129157,
        "bleu": 49.66603,
        "nubia": {
            "semantic_relation": 4.74158,
            "contradiction": 18.01753,
            "irrelevancy": 16.36151,
            "logical_agreement": 65.62097,
            "grammar_ref": 3.87403,
            "grammar_hyp": 3.69973,
            "nubia_score": 0.91624
        },
        "bertscore": {
            "precision": 0.95786,
            "recall": 0.95685,
            "f1": 0.95613
        },
        "meteor": 0.4886530026966582,
        "bleurt": 0.44446
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.43478,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.28409,
            "fmeasure": 0.34792
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.43478,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.43478,
            "fmeasure": 0.57143
        },
        "nist": 1.1611528151260602,
        "bleu": 31.55118,
        "nubia": {
            "semantic_relation": 3.82183,
            "contradiction": 33.80952,
            "irrelevancy": 2.2444,
            "logical_agreement": 63.94608,
            "grammar_ref": 4.20692,
            "grammar_hyp": 5.10487,
            "nubia_score": 0.47024
        },
        "bertscore": {
            "precision": 0.96949,
            "recall": 0.90853,
            "f1": 0.93049
        },
        "meteor": 0.3080289252406045,
        "bleurt": 0.22867
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.25,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "nist": 2.701365143577265,
        "bleu": 16.89227,
        "nubia": {
            "semantic_relation": 4.80773,
            "contradiction": 11.64205,
            "irrelevancy": 1.76848,
            "logical_agreement": 86.58947,
            "grammar_ref": 4.80739,
            "grammar_hyp": 4.33638,
            "nubia_score": 0.81756
        },
        "bertscore": {
            "precision": 0.89413,
            "recall": 0.87117,
            "f1": 0.8825
        },
        "meteor": 0.3323632080037802,
        "bleurt": 0.34222
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.84295,
            "fmeasure": 0.85833
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "nist": 3.8535769082186824,
        "bleu": 76.74162,
        "nubia": {
            "semantic_relation": 3.73103,
            "contradiction": 47.93643,
            "irrelevancy": 1.84919,
            "logical_agreement": 50.21438,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.4164,
            "nubia_score": 0.6985
        },
        "bertscore": {
            "precision": 0.9822,
            "recall": 0.97494,
            "f1": 0.97856
        },
        "meteor": 0.5426177315437225,
        "bleurt": 0.39021
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7,
            "2": 0.0,
            "3": 0.8421052631578947
        },
        "rouge1": {
            "precision": 0.86684,
            "recall": 0.76695,
            "fmeasure": 0.78912
        },
        "rouge2": {
            "precision": 0.6768,
            "recall": 0.58797,
            "fmeasure": 0.61043
        },
        "rougeL": {
            "precision": 0.81041,
            "recall": 0.70133,
            "fmeasure": 0.73024
        },
        "rougeLsum": {
            "precision": 0.81041,
            "recall": 0.70133,
            "fmeasure": 0.73024
        },
        "nist": 5.3142544639467735,
        "bleu": 58.40614,
        "nubia": {
            "semantic_relation": 4.2102,
            "contradiction": 0.58155,
            "irrelevancy": 18.0117,
            "logical_agreement": 81.40674,
            "grammar_ref": 5.76985,
            "grammar_hyp": 6.12865,
            "nubia_score": 0.61367
        },
        "bertscore": {
            "precision": 0.96121,
            "recall": 0.92605,
            "f1": 0.94174
        },
        "meteor": 0.4708023078714124,
        "bleurt": 0.10106
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "rouge1": {
            "precision": 0.76471,
            "recall": 0.66249,
            "fmeasure": 0.70955
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.26852,
            "fmeasure": 0.28867
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.29605,
            "fmeasure": 0.29461
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.29605,
            "fmeasure": 0.29461
        },
        "nist": 2.6843130612011175,
        "bleu": 15.31025,
        "nubia": {
            "semantic_relation": 3.86123,
            "contradiction": 0.10162,
            "irrelevancy": 39.14297,
            "logical_agreement": 60.75541,
            "grammar_ref": 4.42639,
            "grammar_hyp": 4.70911,
            "nubia_score": 0.59698
        },
        "bertscore": {
            "precision": 0.88526,
            "recall": 0.87807,
            "f1": 0.88165
        },
        "meteor": 0.28865450753842,
        "bleurt": -0.06532
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.05263157894736842,
            "2": 0.65,
            "3": 0.7407407407407407
        },
        "rouge1": {
            "precision": 0.77629,
            "recall": 0.66841,
            "fmeasure": 0.70299
        },
        "rouge2": {
            "precision": 0.53626,
            "recall": 0.46832,
            "fmeasure": 0.48523
        },
        "rougeL": {
            "precision": 0.687,
            "recall": 0.62258,
            "fmeasure": 0.6396
        },
        "rougeLsum": {
            "precision": 0.687,
            "recall": 0.62258,
            "fmeasure": 0.6396
        },
        "nist": 4.230248127043485,
        "bleu": 47.51217,
        "nubia": {
            "semantic_relation": 3.62061,
            "contradiction": 41.31046,
            "irrelevancy": 24.50608,
            "logical_agreement": 34.18345,
            "grammar_ref": 4.43752,
            "grammar_hyp": 4.69284,
            "nubia_score": 0.53203
        },
        "bertscore": {
            "precision": 0.93543,
            "recall": 0.93472,
            "f1": 0.93478
        },
        "meteor": 0.41480471288021414,
        "bleurt": 0.11977
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9333333333333333
        },
        "rouge1": {
            "precision": 0.94737,
            "recall": 0.94737,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.77778,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 0.78947,
            "recall": 0.78947,
            "fmeasure": 0.78947
        },
        "rougeLsum": {
            "precision": 0.78947,
            "recall": 0.78947,
            "fmeasure": 0.78947
        },
        "nist": 4.2033161282874065,
        "bleu": 63.3263,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.1265,
            "irrelevancy": 0.44775,
            "logical_agreement": 99.42575,
            "grammar_ref": 3.47563,
            "grammar_hyp": 3.44746,
            "nubia_score": 0.99797
        },
        "bertscore": {
            "precision": 0.9844,
            "recall": 0.9844,
            "f1": 0.9844
        },
        "meteor": 0.5620866573937521,
        "bleurt": 0.77138
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.3
        },
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.31313,
            "fmeasure": 0.39181
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.06061,
            "fmeasure": 0.07843
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.26515,
            "fmeasure": 0.32749
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.26515,
            "fmeasure": 0.32749
        },
        "nist": 0.8149595620358655,
        "bleu": 10.01735,
        "nubia": {
            "semantic_relation": 3.5189,
            "contradiction": 0.9084,
            "irrelevancy": 46.94639,
            "logical_agreement": 52.14521,
            "grammar_ref": 4.53537,
            "grammar_hyp": 4.875,
            "nubia_score": 0.47984
        },
        "bertscore": {
            "precision": 0.88399,
            "recall": 0.81863,
            "f1": 0.84964
        },
        "meteor": 0.16015434242729853,
        "bleurt": -0.23599
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.44106,
            "fmeasure": 0.53549
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.28109,
            "fmeasure": 0.34316
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.32077,
            "fmeasure": 0.38945
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.32077,
            "fmeasure": 0.38945
        },
        "nist": 1.5248051278932206,
        "bleu": 28.1982,
        "nubia": {
            "semantic_relation": 3.80499,
            "contradiction": 19.92413,
            "irrelevancy": 2.70093,
            "logical_agreement": 77.37494,
            "grammar_ref": 3.59602,
            "grammar_hyp": 3.9979,
            "nubia_score": 0.56913
        },
        "bertscore": {
            "precision": 0.92751,
            "recall": 0.88181,
            "f1": 0.90408
        },
        "meteor": 0.2878104291239948,
        "bleurt": 0.08129
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.44444,
            "fmeasure": 0.44444
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.44444,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.44444,
            "fmeasure": 0.44444
        },
        "nist": 1.761129984239132,
        "bleu": 12.75931,
        "nubia": {
            "semantic_relation": 4.88855,
            "contradiction": 0.17122,
            "irrelevancy": 0.46446,
            "logical_agreement": 99.36432,
            "grammar_ref": 3.99081,
            "grammar_hyp": 3.00674,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.90665,
            "recall": 0.91628,
            "f1": 0.91144
        },
        "meteor": 0.30179000434079917,
        "bleurt": 0.62116
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.69231,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.38462,
            "recall": 0.41667,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.69231,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.69231,
            "fmeasure": 0.66667
        },
        "nist": 2.5769245637870895,
        "bleu": 30.93459,
        "nubia": {
            "semantic_relation": 4.26137,
            "contradiction": 8.14639,
            "irrelevancy": 24.61367,
            "logical_agreement": 67.23994,
            "grammar_ref": 4.23153,
            "grammar_hyp": 4.44846,
            "nubia_score": 0.6852
        },
        "bertscore": {
            "precision": 0.90151,
            "recall": 0.90601,
            "f1": 0.90376
        },
        "meteor": 0.4093656786664235,
        "bleurt": 0.16782
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.97619,
            "fmeasure": 0.95556
        },
        "rougeL": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "rougeLsum": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "nist": 4.503310677983855,
        "bleu": 81.53551,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.16036,
            "irrelevancy": 2.58913,
            "logical_agreement": 97.25051,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.06363,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.99266,
            "recall": 0.99927,
            "f1": 0.99595
        },
        "meteor": 1.0,
        "bleurt": 0.83419
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.67917,
            "fmeasure": 0.50871
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "nist": 2.955116912262305,
        "bleu": 57.58522,
        "nubia": {
            "semantic_relation": 2.89108,
            "contradiction": 0.54,
            "irrelevancy": 98.75045,
            "logical_agreement": 0.70956,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.79961,
            "nubia_score": 0.34265
        },
        "bertscore": {
            "precision": 0.89616,
            "recall": 0.94973,
            "f1": 0.92216
        },
        "meteor": 0.5139078546685881,
        "bleurt": -0.33255
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "nist": 3.898626692302749,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.371,
            "irrelevancy": 0.46802,
            "logical_agreement": 99.16099,
            "grammar_ref": 5.30755,
            "grammar_hyp": 5.2666,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.90186
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.2,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.54386,
            "recall": 0.7381,
            "fmeasure": 0.62626
        },
        "rouge2": {
            "precision": 0.37037,
            "recall": 0.51282,
            "fmeasure": 0.43011
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.71429,
            "fmeasure": 0.60606
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.71429,
            "fmeasure": 0.60606
        },
        "nist": 2.9627587637506867,
        "bleu": 38.27674,
        "nubia": {
            "semantic_relation": 3.21107,
            "contradiction": 0.24388,
            "irrelevancy": 99.43461,
            "logical_agreement": 0.32151,
            "grammar_ref": 3.90604,
            "grammar_hyp": 2.98244,
            "nubia_score": 0.64391
        },
        "bertscore": {
            "precision": 0.82207,
            "recall": 0.9127,
            "f1": 0.85884
        },
        "meteor": 0.3980387917893527,
        "bleurt": -0.01732
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.5333333333333333
        },
        "rouge1": {
            "precision": 0.77526,
            "recall": 0.57778,
            "fmeasure": 0.65552
        },
        "rouge2": {
            "precision": 0.53472,
            "recall": 0.37178,
            "fmeasure": 0.43615
        },
        "rougeL": {
            "precision": 0.68024,
            "recall": 0.47963,
            "fmeasure": 0.55946
        },
        "rougeLsum": {
            "precision": 0.68024,
            "recall": 0.47963,
            "fmeasure": 0.55946
        },
        "nist": 2.4810093688150507,
        "bleu": 31.46522,
        "nubia": {
            "semantic_relation": 3.95776,
            "contradiction": 3.14182,
            "irrelevancy": 52.7173,
            "logical_agreement": 44.14088,
            "grammar_ref": 4.16263,
            "grammar_hyp": 4.24422,
            "nubia_score": 0.62533
        },
        "bertscore": {
            "precision": 0.91329,
            "recall": 0.8442,
            "f1": 0.87292
        },
        "meteor": 0.24338635374680495,
        "bleurt": -0.1425
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.7857142857142857,
            "3": 0.7608695652173914
        },
        "rouge1": {
            "precision": 0.88571,
            "recall": 0.82405,
            "fmeasure": 0.84637
        },
        "rouge2": {
            "precision": 0.70256,
            "recall": 0.66796,
            "fmeasure": 0.68022
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.75965,
            "fmeasure": 0.73271
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.75965,
            "fmeasure": 0.73271
        },
        "nist": 5.256191470797785,
        "bleu": 58.18552,
        "nubia": {
            "semantic_relation": 4.44058,
            "contradiction": 1.52544,
            "irrelevancy": 7.121,
            "logical_agreement": 91.35356,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.85694,
            "nubia_score": 0.81222
        },
        "bertscore": {
            "precision": 0.94909,
            "recall": 0.94422,
            "f1": 0.94634
        },
        "meteor": 0.44118867206296963,
        "bleurt": 0.50443
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.6428571428571429
        },
        "rouge1": {
            "precision": 0.80392,
            "recall": 0.67251,
            "fmeasure": 0.73197
        },
        "rouge2": {
            "precision": 0.60417,
            "recall": 0.47619,
            "fmeasure": 0.53253
        },
        "rougeL": {
            "precision": 0.68627,
            "recall": 0.5368,
            "fmeasure": 0.60234
        },
        "rougeLsum": {
            "precision": 0.68627,
            "recall": 0.5368,
            "fmeasure": 0.60234
        },
        "nist": 3.7079400898575674,
        "bleu": 43.76977,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20724,
            "irrelevancy": 1.27341,
            "logical_agreement": 98.51935,
            "grammar_ref": 3.4928,
            "grammar_hyp": 4.74556,
            "nubia_score": 0.89744
        },
        "bertscore": {
            "precision": 0.9454,
            "recall": 0.92225,
            "f1": 0.93368
        },
        "meteor": 0.35989789761019425,
        "bleurt": 0.40369
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.9354838709677419
        },
        "rouge1": {
            "precision": 0.84232,
            "recall": 0.8683,
            "fmeasure": 0.85329
        },
        "rouge2": {
            "precision": 0.62103,
            "recall": 0.65697,
            "fmeasure": 0.63681
        },
        "rougeL": {
            "precision": 0.6152,
            "recall": 0.65136,
            "fmeasure": 0.63174
        },
        "rougeLsum": {
            "precision": 0.6152,
            "recall": 0.65136,
            "fmeasure": 0.63174
        },
        "nist": 4.825490743725046,
        "bleu": 59.30051,
        "nubia": {
            "semantic_relation": 4.42666,
            "contradiction": 0.96147,
            "irrelevancy": 51.07666,
            "logical_agreement": 47.96187,
            "grammar_ref": 5.15251,
            "grammar_hyp": 5.0458,
            "nubia_score": 0.7894
        },
        "bertscore": {
            "precision": 0.94916,
            "recall": 0.94577,
            "f1": 0.94739
        },
        "meteor": 0.4749649477917698,
        "bleurt": 0.09547
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.57857,
            "fmeasure": 0.7
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "nist": 0.6179519972810469,
        "bleu": 30.67489,
        "nubia": {
            "semantic_relation": 4.15284,
            "contradiction": 0.35397,
            "irrelevancy": 0.51105,
            "logical_agreement": 99.13498,
            "grammar_ref": 2.70093,
            "grammar_hyp": 2.8924,
            "nubia_score": 0.88513
        },
        "bertscore": {
            "precision": 0.97564,
            "recall": 0.89184,
            "f1": 0.93186
        },
        "meteor": 0.4466946348571188,
        "bleurt": 0.26056
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.45454545454545453,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.38087,
            "fmeasure": 0.50502
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.04419,
            "fmeasure": 0.05945
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.1913,
            "fmeasure": 0.24286
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.1913,
            "fmeasure": 0.24286
        },
        "nist": 1.5328652465386627,
        "bleu": 7.00938,
        "nubia": {
            "semantic_relation": 2.32178,
            "contradiction": 33.97432,
            "irrelevancy": 31.67462,
            "logical_agreement": 34.35105,
            "grammar_ref": 3.96534,
            "grammar_hyp": 4.13417,
            "nubia_score": 0.19465
        },
        "bertscore": {
            "precision": 0.8898,
            "recall": 0.81949,
            "f1": 0.8532
        },
        "meteor": 0.2362142869870308,
        "bleurt": -0.80885
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.42857142857142855,
            "3": 0.631578947368421
        },
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.63068,
            "fmeasure": 0.75304
        },
        "rouge2": {
            "precision": 0.76984,
            "recall": 0.5,
            "fmeasure": 0.60539
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 0.52178,
            "fmeasure": 0.62011
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 0.52178,
            "fmeasure": 0.62011
        },
        "nist": 2.356308324216479,
        "bleu": 43.59835,
        "nubia": {
            "semantic_relation": 4.50478,
            "contradiction": 0.19613,
            "irrelevancy": 17.03458,
            "logical_agreement": 82.76929,
            "grammar_ref": 4.70595,
            "grammar_hyp": 6.6719,
            "nubia_score": 0.60614
        },
        "bertscore": {
            "precision": 0.91907,
            "recall": 0.86089,
            "f1": 0.88321
        },
        "meteor": 0.35111808459824734,
        "bleurt": 0.10856
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.44
        },
        "rouge1": {
            "precision": 0.72639,
            "recall": 0.64762,
            "fmeasure": 0.65689
        },
        "rouge2": {
            "precision": 0.60714,
            "recall": 0.59149,
            "fmeasure": 0.57553
        },
        "rougeL": {
            "precision": 0.67083,
            "recall": 0.62356,
            "fmeasure": 0.6231
        },
        "rougeLsum": {
            "precision": 0.67083,
            "recall": 0.62356,
            "fmeasure": 0.6231
        },
        "nist": 1.7848099891040519,
        "bleu": 25.14955,
        "nubia": {
            "semantic_relation": 4.09843,
            "contradiction": 0.24848,
            "irrelevancy": 50.258,
            "logical_agreement": 49.49352,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.48864,
            "nubia_score": 0.75755
        },
        "bertscore": {
            "precision": 0.92583,
            "recall": 0.88303,
            "f1": 0.9033
        },
        "meteor": 0.2593396187336393,
        "bleurt": 0.10928
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.1111111111111111,
            "3": 0.5294117647058824
        },
        "rouge1": {
            "precision": 0.53571,
            "recall": 0.48434,
            "fmeasure": 0.50538
        },
        "rouge2": {
            "precision": 0.33173,
            "recall": 0.29236,
            "fmeasure": 0.30872
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.47601,
            "fmeasure": 0.49557
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.47601,
            "fmeasure": 0.49557
        },
        "nist": 2.2911836228577456,
        "bleu": 32.42058,
        "nubia": {
            "semantic_relation": 3.32758,
            "contradiction": 45.93606,
            "irrelevancy": 52.98148,
            "logical_agreement": 1.08246,
            "grammar_ref": 4.30067,
            "grammar_hyp": 4.79198,
            "nubia_score": 0.43763
        },
        "bertscore": {
            "precision": 0.86374,
            "recall": 0.86896,
            "f1": 0.86617
        },
        "meteor": 0.28670702735320563,
        "bleurt": -0.07664
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.80952,
            "recall": 0.84444,
            "fmeasure": 0.81992
        },
        "rouge2": {
            "precision": 0.69231,
            "recall": 0.70899,
            "fmeasure": 0.69473
        },
        "rougeL": {
            "precision": 0.80952,
            "recall": 0.84444,
            "fmeasure": 0.81992
        },
        "rougeLsum": {
            "precision": 0.80952,
            "recall": 0.84444,
            "fmeasure": 0.81992
        },
        "nist": 5.165553613984095,
        "bleu": 77.84139,
        "nubia": {
            "semantic_relation": 4.54353,
            "contradiction": 1.02654,
            "irrelevancy": 53.38705,
            "logical_agreement": 45.58642,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.1312,
            "nubia_score": 0.74211
        },
        "bertscore": {
            "precision": 0.98365,
            "recall": 0.97128,
            "f1": 0.97742
        },
        "meteor": 0.5704809169762273,
        "bleurt": 0.40339
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 1.0,
            "3": 0.29411764705882354
        },
        "rouge1": {
            "precision": 0.58974,
            "recall": 0.31944,
            "fmeasure": 0.41441
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.17391,
            "fmeasure": 0.22857
        },
        "rougeL": {
            "precision": 0.58974,
            "recall": 0.31944,
            "fmeasure": 0.41441
        },
        "rougeLsum": {
            "precision": 0.58974,
            "recall": 0.31944,
            "fmeasure": 0.41441
        },
        "nist": 0.7316927883046063,
        "bleu": 9.49107,
        "nubia": {
            "semantic_relation": 2.58845,
            "contradiction": 91.64915,
            "irrelevancy": 3.68005,
            "logical_agreement": 4.6708,
            "grammar_ref": 3.8277,
            "grammar_hyp": 5.58842,
            "nubia_score": 0.14073
        },
        "bertscore": {
            "precision": 0.8413,
            "recall": 0.7682,
            "f1": 0.80301
        },
        "meteor": 0.15348396967143724,
        "bleurt": -0.13951
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.4,
            "fmeasure": 0.38095
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "nist": 1.629358976048761,
        "bleu": 9.42516,
        "nubia": {
            "semantic_relation": 3.80351,
            "contradiction": 1.62983,
            "irrelevancy": 1.66872,
            "logical_agreement": 96.70145,
            "grammar_ref": 3.90557,
            "grammar_hyp": 3.68543,
            "nubia_score": 0.65747
        },
        "bertscore": {
            "precision": 0.89807,
            "recall": 0.87333,
            "f1": 0.88468
        },
        "meteor": 0.20248556899341844,
        "bleurt": 0.22483
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.9166666666666666,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.49123,
            "recall": 0.69991,
            "fmeasure": 0.57724
        },
        "rouge2": {
            "precision": 0.32432,
            "recall": 0.47385,
            "fmeasure": 0.38505
        },
        "rougeL": {
            "precision": 0.4386,
            "recall": 0.62488,
            "fmeasure": 0.51538
        },
        "rougeLsum": {
            "precision": 0.4386,
            "recall": 0.62488,
            "fmeasure": 0.51538
        },
        "nist": 2.384742139910246,
        "bleu": 30.20676,
        "nubia": {
            "semantic_relation": 3.29785,
            "contradiction": 34.99307,
            "irrelevancy": 62.56937,
            "logical_agreement": 2.43756,
            "grammar_ref": 4.65446,
            "grammar_hyp": 4.13634,
            "nubia_score": 0.4057
        },
        "bertscore": {
            "precision": 0.85318,
            "recall": 0.91513,
            "f1": 0.88116
        },
        "meteor": 0.3596824593627849,
        "bleurt": -0.2084
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.87879,
            "fmeasure": 0.87879
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.53333,
            "fmeasure": 0.53333
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.78788,
            "fmeasure": 0.78788
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.78788,
            "fmeasure": 0.78788
        },
        "nist": 3.6909379535219213,
        "bleu": 55.20582,
        "nubia": {
            "semantic_relation": 4.9379,
            "contradiction": 0.37274,
            "irrelevancy": 0.6688,
            "logical_agreement": 98.95846,
            "grammar_ref": 4.98843,
            "grammar_hyp": 4.97872,
            "nubia_score": 0.94952
        },
        "bertscore": {
            "precision": 0.97555,
            "recall": 0.96089,
            "f1": 0.96816
        },
        "meteor": 0.47229158568017576,
        "bleurt": 0.56975
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.23529411764705882,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.56225,
            "fmeasure": 0.68498
        },
        "rouge2": {
            "precision": 0.62868,
            "recall": 0.40583,
            "fmeasure": 0.48536
        },
        "rougeL": {
            "precision": 0.75926,
            "recall": 0.46225,
            "fmeasure": 0.5641
        },
        "rougeLsum": {
            "precision": 0.75926,
            "recall": 0.46225,
            "fmeasure": 0.5641
        },
        "nist": 1.0374887526659178,
        "bleu": 35.12051,
        "nubia": {
            "semantic_relation": 3.89155,
            "contradiction": 0.17658,
            "irrelevancy": 1.88663,
            "logical_agreement": 97.93679,
            "grammar_ref": 3.63495,
            "grammar_hyp": 4.18796,
            "nubia_score": 0.62182
        },
        "bertscore": {
            "precision": 0.94336,
            "recall": 0.89285,
            "f1": 0.9152
        },
        "meteor": 0.31207781092121817,
        "bleurt": 0.14439
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.91667,
            "fmeasure": 0.88
        },
        "rouge2": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.91667,
            "fmeasure": 0.88
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.91667,
            "fmeasure": 0.88
        },
        "nist": 4.1190148250798675,
        "bleu": 76.70387,
        "nubia": {
            "semantic_relation": 4.42772,
            "contradiction": 0.37303,
            "irrelevancy": 33.58886,
            "logical_agreement": 66.03811,
            "grammar_ref": 4.00353,
            "grammar_hyp": 3.79877,
            "nubia_score": 0.84586
        },
        "bertscore": {
            "precision": 0.95708,
            "recall": 0.96861,
            "f1": 0.94711
        },
        "meteor": 0.5530511702257642,
        "bleurt": 0.52496
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "nist": 2.7109047337507373,
        "bleu": 53.10725,
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        },
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        },
        "meteor": 0.5033950705050299,
        "bleurt": 0.22576
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.4,
            "3": 0.4722222222222222
        },
        "rouge1": {
            "precision": 0.72011,
            "recall": 0.59198,
            "fmeasure": 0.63355
        },
        "rouge2": {
            "precision": 0.401,
            "recall": 0.37619,
            "fmeasure": 0.37923
        },
        "rougeL": {
            "precision": 0.66296,
            "recall": 0.55741,
            "fmeasure": 0.59066
        },
        "rougeLsum": {
            "precision": 0.66296,
            "recall": 0.55741,
            "fmeasure": 0.59066
        },
        "nist": 2.0285129163836984,
        "bleu": 25.28399,
        "nubia": {
            "semantic_relation": 3.88241,
            "contradiction": 14.43696,
            "irrelevancy": 12.05537,
            "logical_agreement": 73.50767,
            "grammar_ref": 4.46773,
            "grammar_hyp": 4.71521,
            "nubia_score": 0.58813
        },
        "bertscore": {
            "precision": 0.91858,
            "recall": 0.86863,
            "f1": 0.8917
        },
        "meteor": 0.2850043239116826,
        "bleurt": 0.09568
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.3888888888888889,
            "3": 0.9444444444444444
        },
        "rouge1": {
            "precision": 0.66947,
            "recall": 0.71382,
            "fmeasure": 0.68246
        },
        "rouge2": {
            "precision": 0.48457,
            "recall": 0.50387,
            "fmeasure": 0.48844
        },
        "rougeL": {
            "precision": 0.55056,
            "recall": 0.56992,
            "fmeasure": 0.5537
        },
        "rougeLsum": {
            "precision": 0.55056,
            "recall": 0.56992,
            "fmeasure": 0.5537
        },
        "nist": 4.0580771683362755,
        "bleu": 40.58442,
        "nubia": {
            "semantic_relation": 3.94361,
            "contradiction": 2.14944,
            "irrelevancy": 77.61247,
            "logical_agreement": 20.23809,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.24233,
            "nubia_score": 0.65866
        },
        "bertscore": {
            "precision": 0.91035,
            "recall": 0.90213,
            "f1": 0.90275
        },
        "meteor": 0.39629652491989026,
        "bleurt": -0.11455
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.8461538461538461,
            "3": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.73237,
            "recall": 0.84202,
            "fmeasure": 0.77045
        },
        "rouge2": {
            "precision": 0.62222,
            "recall": 0.67659,
            "fmeasure": 0.63989
        },
        "rougeL": {
            "precision": 0.73237,
            "recall": 0.84202,
            "fmeasure": 0.77045
        },
        "rougeLsum": {
            "precision": 0.73237,
            "recall": 0.84202,
            "fmeasure": 0.77045
        },
        "nist": 4.237054596070422,
        "bleu": 57.98806,
        "nubia": {
            "semantic_relation": 4.58518,
            "contradiction": 0.37984,
            "irrelevancy": 33.60673,
            "logical_agreement": 66.01343,
            "grammar_ref": 5.27099,
            "grammar_hyp": 4.96687,
            "nubia_score": 0.90836
        },
        "bertscore": {
            "precision": 0.91856,
            "recall": 0.95598,
            "f1": 0.93376
        },
        "meteor": 0.48211646963074073,
        "bleurt": 0.50145
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "mT5_base/totto_test",
        "N": 136,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2597402597402597,
            "2": 0.42857142857142855,
            "3": 0.7871598046057222
        },
        "rouge1": {
            "precision": 0.75082,
            "recall": 0.74969,
            "fmeasure": 0.73954
        },
        "rouge2": {
            "precision": 0.52954,
            "recall": 0.52777,
            "fmeasure": 0.52105
        },
        "rougeL": {
            "precision": 0.65177,
            "recall": 0.65332,
            "fmeasure": 0.64318
        },
        "rougeLsum": {
            "precision": 0.65177,
            "recall": 0.65332,
            "fmeasure": 0.64318
        },
        "nist": 7.6303316584337075,
        "bleu": 50.44473,
        "nubia": {
            "semantic_relation": 4.21281,
            "contradiction": 6.62507,
            "irrelevancy": 25.73589,
            "logical_agreement": 67.63904,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.40685,
            "nubia_score": 0.75615
        },
        "bertscore": {
            "precision": 0.92835,
            "recall": 0.92716,
            "f1": 0.92614
        },
        "meteor": 0.4087975824022973,
        "bleurt": 0.35818
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.375,
            "recall": 0.6,
            "fmeasure": 0.46154
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.4,
            "fmeasure": 0.30769
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.4,
            "fmeasure": 0.30769
        },
        "nist": 0.861654166907052,
        "bleu": 4.78923,
        "nubia": {
            "semantic_relation": 4.2478,
            "contradiction": 0.09206,
            "irrelevancy": 99.77749,
            "logical_agreement": 0.13045,
            "grammar_ref": 6.34893,
            "grammar_hyp": 4.59931,
            "nubia_score": 0.99591
        },
        "bertscore": {
            "precision": 0.85783,
            "recall": 0.92265,
            "f1": 0.88906
        },
        "meteor": 0.342253569857732,
        "bleurt": 0.33978
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.40625,
            "recall": 0.4375,
            "fmeasure": 0.42083
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.18205,
            "fmeasure": 0.17381
        },
        "rougeL": {
            "precision": 0.34375,
            "recall": 0.36607,
            "fmeasure": 0.35417
        },
        "rougeLsum": {
            "precision": 0.34375,
            "recall": 0.36607,
            "fmeasure": 0.35417
        },
        "nist": 1.646309471283056,
        "bleu": 12.14918,
        "nubia": {
            "semantic_relation": 3.73975,
            "contradiction": 73.56935,
            "irrelevancy": 6.77145,
            "logical_agreement": 19.65921,
            "grammar_ref": 3.06207,
            "grammar_hyp": 3.53513,
            "nubia_score": 0.63479
        },
        "bertscore": {
            "precision": 0.85564,
            "recall": 0.87292,
            "f1": 0.8642
        },
        "meteor": 0.3378783804748052,
        "bleurt": 0.3558
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.26984,
            "fmeasure": 0.32727
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "nist": 1.8094988549899862,
        "bleu": 24.59813,
        "nubia": {
            "semantic_relation": 4.18837,
            "contradiction": 0.38664,
            "irrelevancy": 0.58445,
            "logical_agreement": 99.02891,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.86986,
            "nubia_score": 0.75842
        },
        "bertscore": {
            "precision": 0.97738,
            "recall": 0.94093,
            "f1": 0.95881
        },
        "meteor": 0.3010544205973617,
        "bleurt": 0.30353
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80828,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.4902,
            "fmeasure": 0.5276
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "nist": 2.7910011142063147,
        "bleu": 33.40891,
        "nubia": {
            "semantic_relation": 4.98459,
            "contradiction": 0.13212,
            "irrelevancy": 0.41925,
            "logical_agreement": 99.44863,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.453,
            "nubia_score": 0.98464
        },
        "bertscore": {
            "precision": 0.96668,
            "recall": 0.9373,
            "f1": 0.95176
        },
        "meteor": 0.424582730950162,
        "bleurt": 0.50996
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.18519,
            "fmeasure": 0.27778
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.03846,
            "fmeasure": 0.05882
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.14815,
            "fmeasure": 0.22222
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.14815,
            "fmeasure": 0.22222
        },
        "nist": 0.002270944143998867,
        "bleu": 0.55359,
        "nubia": {
            "semantic_relation": 1.88849,
            "contradiction": 8.91703,
            "irrelevancy": 32.63464,
            "logical_agreement": 58.44833,
            "grammar_ref": 4.95946,
            "grammar_hyp": 7.96833,
            "nubia_score": 0.06791
        },
        "bertscore": {
            "precision": 0.8677,
            "recall": 0.7982,
            "f1": 0.8315
        },
        "meteor": 0.0940145769402394,
        "bleurt": -0.62612
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.93333,
            "fmeasure": 0.85213
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.92593,
            "fmeasure": 0.83591
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.93333,
            "fmeasure": 0.85213
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.93333,
            "fmeasure": 0.85213
        },
        "nist": 2.4387218755408675,
        "bleu": 27.09199,
        "nubia": {
            "semantic_relation": 4.29138,
            "contradiction": 0.0997,
            "irrelevancy": 37.84711,
            "logical_agreement": 62.05319,
            "grammar_ref": 3.90726,
            "grammar_hyp": 2.83517,
            "nubia_score": 0.87853
        },
        "bertscore": {
            "precision": 0.9315,
            "recall": 0.96902,
            "f1": 0.94989
        },
        "meteor": 0.5367034139459188,
        "bleurt": 0.34658
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5789473684210527
        },
        "rouge1": {
            "precision": 0.49544,
            "recall": 0.56358,
            "fmeasure": 0.48684
        },
        "rouge2": {
            "precision": 0.23401,
            "recall": 0.29509,
            "fmeasure": 0.23013
        },
        "rougeL": {
            "precision": 0.36581,
            "recall": 0.43989,
            "fmeasure": 0.36075
        },
        "rougeLsum": {
            "precision": 0.36581,
            "recall": 0.43989,
            "fmeasure": 0.36075
        },
        "nist": 2.0670536249016385,
        "bleu": 9.25844,
        "nubia": {
            "semantic_relation": 3.20271,
            "contradiction": 3.6908,
            "irrelevancy": 61.54399,
            "logical_agreement": 34.76521,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.03015,
            "nubia_score": 0.36926
        },
        "bertscore": {
            "precision": 0.84702,
            "recall": 0.85996,
            "f1": 0.85246
        },
        "meteor": 0.2587589314235812,
        "bleurt": -0.26316
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.14814814814814814,
            "3": 0.4482758620689655
        },
        "rouge1": {
            "precision": 0.58254,
            "recall": 0.40994,
            "fmeasure": 0.45365
        },
        "rouge2": {
            "precision": 0.26259,
            "recall": 0.21004,
            "fmeasure": 0.22063
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.37242,
            "fmeasure": 0.38999
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.37242,
            "fmeasure": 0.38999
        },
        "nist": 1.989576193282372,
        "bleu": 20.97141,
        "nubia": {
            "semantic_relation": 3.9534,
            "contradiction": 26.13864,
            "irrelevancy": 46.86781,
            "logical_agreement": 26.99355,
            "grammar_ref": 5.44243,
            "grammar_hyp": 6.24508,
            "nubia_score": 0.50828
        },
        "bertscore": {
            "precision": 0.883,
            "recall": 0.84262,
            "f1": 0.85026
        },
        "meteor": 0.20652713874692633,
        "bleurt": -0.22625
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.65132,
            "fmeasure": 0.73491
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.56667,
            "fmeasure": 0.64444
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.65132,
            "fmeasure": 0.73491
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.65132,
            "fmeasure": 0.73491
        },
        "nist": 2.675685609399386,
        "bleu": 58.37979,
        "nubia": {
            "semantic_relation": 4.26657,
            "contradiction": 0.55879,
            "irrelevancy": 0.75427,
            "logical_agreement": 98.68695,
            "grammar_ref": 4.542,
            "grammar_hyp": 4.47229,
            "nubia_score": 0.76502
        },
        "bertscore": {
            "precision": 0.94428,
            "recall": 0.89488,
            "f1": 0.91892
        },
        "meteor": 0.38913136461761244,
        "bleurt": 0.03426
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.47619047619047616
        },
        "rouge1": {
            "precision": 0.46023,
            "recall": 0.38561,
            "fmeasure": 0.4155
        },
        "rouge2": {
            "precision": 0.24537,
            "recall": 0.21116,
            "fmeasure": 0.22397
        },
        "rougeL": {
            "precision": 0.32873,
            "recall": 0.28608,
            "fmeasure": 0.30233
        },
        "rougeLsum": {
            "precision": 0.32873,
            "recall": 0.28608,
            "fmeasure": 0.30233
        },
        "nist": 2.65494223688282,
        "bleu": 19.80816,
        "nubia": {
            "semantic_relation": 3.16908,
            "contradiction": 8.83745,
            "irrelevancy": 56.83305,
            "logical_agreement": 34.3295,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.6383,
            "nubia_score": 0.44583
        },
        "bertscore": {
            "precision": 0.89012,
            "recall": 0.84848,
            "f1": 0.8688
        },
        "meteor": 0.1955671791042719,
        "bleurt": -0.28344
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.76781,
            "fmeasure": 0.80066
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.65278,
            "fmeasure": 0.61111
        },
        "rougeL": {
            "precision": 0.82051,
            "recall": 0.74929,
            "fmeasure": 0.77916
        },
        "rougeLsum": {
            "precision": 0.82051,
            "recall": 0.74929,
            "fmeasure": 0.77916
        },
        "nist": 3.915557858577524,
        "bleu": 57.30574,
        "nubia": {
            "semantic_relation": 3.99612,
            "contradiction": 2.77083,
            "irrelevancy": 94.75278,
            "logical_agreement": 2.47638,
            "grammar_ref": 5.3293,
            "grammar_hyp": 5.5786,
            "nubia_score": 0.54077
        },
        "bertscore": {
            "precision": 0.9514,
            "recall": 0.96739,
            "f1": 0.95933
        },
        "meteor": 0.48687087564906883,
        "bleurt": -0.07928
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8
        },
        "rouge1": {
            "precision": 0.4,
            "recall": 0.58333,
            "fmeasure": 0.47222
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.2,
            "fmeasure": 0.14286
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.375,
            "fmeasure": 0.29861
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.375,
            "fmeasure": 0.29861
        },
        "nist": 1.1742048081915697,
        "bleu": 4.61922,
        "nubia": {
            "semantic_relation": 2.54433,
            "contradiction": 32.15963,
            "irrelevancy": 67.09205,
            "logical_agreement": 0.74831,
            "grammar_ref": 7.18676,
            "grammar_hyp": 6.03651,
            "nubia_score": 0.22053
        },
        "bertscore": {
            "precision": 0.76151,
            "recall": 0.78386,
            "f1": 0.77253
        },
        "meteor": 0.22570532915360506,
        "bleurt": -0.76415
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.3125,
            "fmeasure": 0.40724
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "nist": 1.0909514646162273,
        "bleu": 31.85036,
        "nubia": {
            "semantic_relation": 3.4502,
            "contradiction": 1.65058,
            "irrelevancy": 0.74865,
            "logical_agreement": 97.60076,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.46862,
            "nubia_score": 0.42783
        },
        "bertscore": {
            "precision": 0.94653,
            "recall": 0.89087,
            "f1": 0.91786
        },
        "meteor": 0.3769465296142278,
        "bleurt": 0.09535
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.6551724137931034
        },
        "rouge1": {
            "precision": 0.53546,
            "recall": 0.62987,
            "fmeasure": 0.55966
        },
        "rouge2": {
            "precision": 0.27137,
            "recall": 0.28615,
            "fmeasure": 0.26913
        },
        "rougeL": {
            "precision": 0.40676,
            "recall": 0.41133,
            "fmeasure": 0.40117
        },
        "rougeLsum": {
            "precision": 0.40676,
            "recall": 0.41133,
            "fmeasure": 0.40117
        },
        "nist": 2.744402336347684,
        "bleu": 7.05196,
        "nubia": {
            "semantic_relation": 3.64309,
            "contradiction": 25.16379,
            "irrelevancy": 56.76428,
            "logical_agreement": 18.07193,
            "grammar_ref": 5.969,
            "grammar_hyp": 5.61612,
            "nubia_score": 0.51736
        },
        "bertscore": {
            "precision": 0.88179,
            "recall": 0.90377,
            "f1": 0.89109
        },
        "meteor": 0.2837318826186074,
        "bleurt": -0.04741
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.79365,
            "fmeasure": 0.78559
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.47949,
            "fmeasure": 0.50952
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.50794,
            "fmeasure": 0.57658
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.50794,
            "fmeasure": 0.57658
        },
        "nist": 4.777583596602156,
        "bleu": 50.49568,
        "nubia": {
            "semantic_relation": 4.16095,
            "contradiction": 0.18842,
            "irrelevancy": 33.57264,
            "logical_agreement": 66.23894,
            "grammar_ref": 3.68983,
            "grammar_hyp": 4.11429,
            "nubia_score": 0.7504
        },
        "bertscore": {
            "precision": 0.95557,
            "recall": 0.93776,
            "f1": 0.92831
        },
        "meteor": 0.4330580898713541,
        "bleurt": 0.10636
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.4
        },
        "rouge1": {
            "precision": 0.40909,
            "recall": 0.23797,
            "fmeasure": 0.29978
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.16518,
            "fmeasure": 0.21216
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.23797,
            "fmeasure": 0.29978
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.23797,
            "fmeasure": 0.29978
        },
        "nist": 0.757496128676349,
        "bleu": 14.01972,
        "nubia": {
            "semantic_relation": 2.06108,
            "contradiction": 0.19788,
            "irrelevancy": 99.64539,
            "logical_agreement": 0.15672,
            "grammar_ref": 3.66593,
            "grammar_hyp": 3.68107,
            "nubia_score": 0.18093
        },
        "bertscore": {
            "precision": 0.82685,
            "recall": 0.78296,
            "f1": 0.80431
        },
        "meteor": 0.24711214356648392,
        "bleurt": -0.76665
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "mT5_base/totto_test",
        "N": 6,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35,
            "2": 0.55,
            "3": 0.7741935483870968
        },
        "rouge1": {
            "precision": 0.85999,
            "recall": 0.78599,
            "fmeasure": 0.80423
        },
        "rouge2": {
            "precision": 0.64679,
            "recall": 0.59594,
            "fmeasure": 0.60996
        },
        "rougeL": {
            "precision": 0.77244,
            "recall": 0.71882,
            "fmeasure": 0.73109
        },
        "rougeLsum": {
            "precision": 0.77244,
            "recall": 0.71882,
            "fmeasure": 0.73109
        },
        "nist": 4.974110556237643,
        "bleu": 54.67312,
        "nubia": {
            "semantic_relation": 4.40673,
            "contradiction": 5.01963,
            "irrelevancy": 25.16497,
            "logical_agreement": 69.8154,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.59109,
            "nubia_score": 0.76659
        },
        "bertscore": {
            "precision": 0.94363,
            "recall": 0.92195,
            "f1": 0.9314
        },
        "meteor": 0.41698802920795053,
        "bleurt": 0.24827
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.57778,
            "fmeasure": 0.66263
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.21481,
            "fmeasure": 0.2792
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.57778,
            "fmeasure": 0.66263
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.57778,
            "fmeasure": 0.66263
        },
        "nist": 1.0840739693530494,
        "bleu": 45.48019,
        "nubia": {
            "semantic_relation": 4.19595,
            "contradiction": 17.4893,
            "irrelevancy": 4.34732,
            "logical_agreement": 78.16338,
            "grammar_ref": 7.45181,
            "grammar_hyp": 8.32632,
            "nubia_score": 0.59376
        },
        "bertscore": {
            "precision": 0.92324,
            "recall": 0.90326,
            "f1": 0.91314
        },
        "meteor": 0.4011806382969706,
        "bleurt": -0.37477
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.44444,
            "fmeasure": 0.44071
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.09091,
            "fmeasure": 0.10526
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.25,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.25,
            "fmeasure": 0.28571
        },
        "nist": 1.2409119936655402,
        "bleu": 11.33958,
        "nubia": {
            "semantic_relation": 3.4521,
            "contradiction": 0.15434,
            "irrelevancy": 99.68669,
            "logical_agreement": 0.15898,
            "grammar_ref": 5.08958,
            "grammar_hyp": 5.23502,
            "nubia_score": 0.50154
        },
        "bertscore": {
            "precision": 0.79748,
            "recall": 0.8591,
            "f1": 0.82715
        },
        "meteor": 0.1880197745154705,
        "bleurt": -0.37917
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.57143,
            "fmeasure": 0.61538
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.30769,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57143,
            "fmeasure": 0.61538
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57143,
            "fmeasure": 0.61538
        },
        "nist": 2.0817848558318826,
        "bleu": 10.59427,
        "nubia": {
            "semantic_relation": 3.74238,
            "contradiction": 0.34299,
            "irrelevancy": 0.86677,
            "logical_agreement": 98.79024,
            "grammar_ref": 5.0526,
            "grammar_hyp": 5.18764,
            "nubia_score": 0.57141
        },
        "bertscore": {
            "precision": 0.92385,
            "recall": 0.89283,
            "f1": 0.90808
        },
        "meteor": 0.33681569537423095,
        "bleurt": 0.28588
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.4666666666666667
        },
        "rouge1": {
            "precision": 0.63158,
            "recall": 0.54762,
            "fmeasure": 0.58605
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.35,
            "fmeasure": 0.36842
        },
        "rougeL": {
            "precision": 0.42105,
            "recall": 0.36508,
            "fmeasure": 0.3907
        },
        "rougeLsum": {
            "precision": 0.42105,
            "recall": 0.36508,
            "fmeasure": 0.3907
        },
        "nist": 2.7366830858106486,
        "bleu": 21.08445,
        "nubia": {
            "semantic_relation": 3.91563,
            "contradiction": 16.55751,
            "irrelevancy": 40.2924,
            "logical_agreement": 43.1501,
            "grammar_ref": 6.02354,
            "grammar_hyp": 5.82003,
            "nubia_score": 0.56524
        },
        "bertscore": {
            "precision": 0.85326,
            "recall": 0.84096,
            "f1": 0.84367
        },
        "meteor": 0.31904769139161276,
        "bleurt": -0.27284
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.82353,
            "fmeasure": 0.75676
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.5,
            "fmeasure": 0.45714
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.82353,
            "fmeasure": 0.75676
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.82353,
            "fmeasure": 0.75676
        },
        "nist": 3.0569179721950586,
        "bleu": 26.18226,
        "nubia": {
            "semantic_relation": 4.35312,
            "contradiction": 0.3727,
            "irrelevancy": 7.3807,
            "logical_agreement": 92.2466,
            "grammar_ref": 4.8802,
            "grammar_hyp": 5.57707,
            "nubia_score": 0.64375
        },
        "bertscore": {
            "precision": 0.9544,
            "recall": 0.96729,
            "f1": 0.9608
        },
        "meteor": 0.4825510954596701,
        "bleurt": 0.52533
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.42892,
            "fmeasure": 0.55282
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.19583,
            "fmeasure": 0.25725
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.2451,
            "fmeasure": 0.3159
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.2451,
            "fmeasure": 0.3159
        },
        "nist": 0.3990587441826788,
        "bleu": 8.6861,
        "nubia": {
            "semantic_relation": 3.27891,
            "contradiction": 20.15678,
            "irrelevancy": 7.21878,
            "logical_agreement": 72.62443,
            "grammar_ref": 4.86284,
            "grammar_hyp": 5.71174,
            "nubia_score": 0.30694
        },
        "bertscore": {
            "precision": 0.89143,
            "recall": 0.83187,
            "f1": 0.86062
        },
        "meteor": 0.22749628750641995,
        "bleurt": -0.00902
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 1.0,
            "3": 0.9565217391304348
        },
        "rouge1": {
            "precision": 0.95593,
            "recall": 0.94118,
            "fmeasure": 0.94788
        },
        "rouge2": {
            "precision": 0.84167,
            "recall": 0.80787,
            "fmeasure": 0.8225
        },
        "rougeL": {
            "precision": 0.86218,
            "recall": 0.85294,
            "fmeasure": 0.85697
        },
        "rougeLsum": {
            "precision": 0.86218,
            "recall": 0.85294,
            "fmeasure": 0.85697
        },
        "nist": 5.234042405509209,
        "bleu": 75.03712,
        "nubia": {
            "semantic_relation": 4.68382,
            "contradiction": 0.36312,
            "irrelevancy": 33.3614,
            "logical_agreement": 66.27547,
            "grammar_ref": 4.08754,
            "grammar_hyp": 4.24165,
            "nubia_score": 0.87981
        },
        "bertscore": {
            "precision": 0.98573,
            "recall": 0.9837,
            "f1": 0.98446
        },
        "meteor": 0.5339831827968969,
        "bleurt": 0.52905
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.4,
            "3": 0.45
        },
        "rouge1": {
            "precision": 0.52874,
            "recall": 0.49298,
            "fmeasure": 0.50893
        },
        "rouge2": {
            "precision": 0.17857,
            "recall": 0.16667,
            "fmeasure": 0.17196
        },
        "rougeL": {
            "precision": 0.26437,
            "recall": 0.22861,
            "fmeasure": 0.24456
        },
        "rougeLsum": {
            "precision": 0.26437,
            "recall": 0.22861,
            "fmeasure": 0.24456
        },
        "nist": 2.5365095520087686,
        "bleu": 11.62211,
        "nubia": {
            "semantic_relation": 2.75828,
            "contradiction": 23.41297,
            "irrelevancy": 8.49859,
            "logical_agreement": 68.08845,
            "grammar_ref": 5.53052,
            "grammar_hyp": 4.28787,
            "nubia_score": 0.46044
        },
        "bertscore": {
            "precision": 0.84649,
            "recall": 0.81009,
            "f1": 0.82664
        },
        "meteor": 0.24474017518115537,
        "bleurt": -0.44335
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.48148,
            "fmeasure": 0.60073
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.25084,
            "fmeasure": 0.31622
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.39773,
            "fmeasure": 0.47817
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.39773,
            "fmeasure": 0.47817
        },
        "nist": 0.7999347178501995,
        "bleu": 8.60455,
        "nubia": {
            "semantic_relation": 3.67928,
            "contradiction": 0.23727,
            "irrelevancy": 33.29774,
            "logical_agreement": 66.46499,
            "grammar_ref": 3.86337,
            "grammar_hyp": 3.48263,
            "nubia_score": 0.67135
        },
        "bertscore": {
            "precision": 0.95392,
            "recall": 0.87706,
            "f1": 0.91196
        },
        "meteor": 0.2827484493643407,
        "bleurt": 0.05383
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.875
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.77273,
            "fmeasure": 0.87179
        },
        "rouge2": {
            "precision": 0.85417,
            "recall": 0.65079,
            "fmeasure": 0.73874
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.72727,
            "fmeasure": 0.82051
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.72727,
            "fmeasure": 0.82051
        },
        "nist": 4.1338259274987,
        "bleu": 66.49438,
        "nubia": {
            "semantic_relation": 4.41068,
            "contradiction": 0.25383,
            "irrelevancy": 33.28628,
            "logical_agreement": 66.45989,
            "grammar_ref": 3.23206,
            "grammar_hyp": 3.26591,
            "nubia_score": 0.87103
        },
        "bertscore": {
            "precision": 0.97205,
            "recall": 0.93675,
            "f1": 0.95407
        },
        "meteor": 0.45532127755528956,
        "bleurt": 0.05712
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.85606,
            "fmeasure": 0.82971
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.58182,
            "fmeasure": 0.56277
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.79545,
            "fmeasure": 0.77174
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.79545,
            "fmeasure": 0.77174
        },
        "nist": 3.5555964901320434,
        "bleu": 37.09723,
        "nubia": {
            "semantic_relation": 4.8905,
            "contradiction": 1.73274,
            "irrelevancy": 1.56022,
            "logical_agreement": 96.70704,
            "grammar_ref": 6.27756,
            "grammar_hyp": 6.71932,
            "nubia_score": 0.79865
        },
        "bertscore": {
            "precision": 0.96083,
            "recall": 0.97242,
            "f1": 0.96659
        },
        "meteor": 0.46092770841539843,
        "bleurt": 0.27745
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.45801,
            "fmeasure": 0.51349
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.17704,
            "fmeasure": 0.25384
        },
        "rougeL": {
            "precision": 0.71212,
            "recall": 0.40385,
            "fmeasure": 0.4642
        },
        "rougeLsum": {
            "precision": 0.71212,
            "recall": 0.40385,
            "fmeasure": 0.4642
        },
        "nist": 1.4137155876526264,
        "bleu": 20.77473,
        "nubia": {
            "semantic_relation": 3.0798,
            "contradiction": 25.36182,
            "irrelevancy": 14.21013,
            "logical_agreement": 60.42805,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.71361,
            "nubia_score": 0.35417
        },
        "bertscore": {
            "precision": 0.91376,
            "recall": 0.85261,
            "f1": 0.88003
        },
        "meteor": 0.23559465972491475,
        "bleurt": -0.26784
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.39167,
            "fmeasure": 0.53755
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.20952,
            "fmeasure": 0.29524
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.38431,
            "fmeasure": 0.5303
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.38431,
            "fmeasure": 0.5303
        },
        "nist": 0.2841455313229504,
        "bleu": 7.56238,
        "nubia": {
            "semantic_relation": 3.65233,
            "contradiction": 0.32311,
            "irrelevancy": 1.26008,
            "logical_agreement": 98.41681,
            "grammar_ref": 4.68072,
            "grammar_hyp": 5.64189,
            "nubia_score": 0.52633
        },
        "bertscore": {
            "precision": 0.89426,
            "recall": 0.7758,
            "f1": 0.83082
        },
        "meteor": 0.18866647190206598,
        "bleurt": -0.36155
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.26786,
            "fmeasure": 0.35253
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.11396,
            "fmeasure": 0.15238
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.26786,
            "fmeasure": 0.35253
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.26786,
            "fmeasure": 0.35253
        },
        "nist": 0.32971717980745036,
        "bleu": 18.60045,
        "nubia": {
            "semantic_relation": 3.02872,
            "contradiction": 59.57404,
            "irrelevancy": 10.35713,
            "logical_agreement": 30.06883,
            "grammar_ref": 3.10421,
            "grammar_hyp": 4.18885,
            "nubia_score": 0.30005
        },
        "bertscore": {
            "precision": 0.85482,
            "recall": 0.82963,
            "f1": 0.84203
        },
        "meteor": 0.21129147767180276,
        "bleurt": -0.10552
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.36363636363636365,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.72917,
            "recall": 0.64087,
            "fmeasure": 0.66222
        },
        "rouge2": {
            "precision": 0.56825,
            "recall": 0.49194,
            "fmeasure": 0.50935
        },
        "rougeL": {
            "precision": 0.72917,
            "recall": 0.64087,
            "fmeasure": 0.66222
        },
        "rougeLsum": {
            "precision": 0.72917,
            "recall": 0.64087,
            "fmeasure": 0.66222
        },
        "nist": 2.9833545476435477,
        "bleu": 46.28426,
        "nubia": {
            "semantic_relation": 3.74983,
            "contradiction": 4.63832,
            "irrelevancy": 59.24606,
            "logical_agreement": 36.11563,
            "grammar_ref": 4.3679,
            "grammar_hyp": 4.80092,
            "nubia_score": 0.54697
        },
        "bertscore": {
            "precision": 0.94584,
            "recall": 0.86327,
            "f1": 0.90118
        },
        "meteor": 0.35959187540431625,
        "bleurt": -0.01973
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.46898,
            "fmeasure": 0.48393
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.40238,
            "fmeasure": 0.36208
        },
        "rougeL": {
            "precision": 0.35,
            "recall": 0.42222,
            "fmeasure": 0.38049
        },
        "rougeLsum": {
            "precision": 0.35,
            "recall": 0.42222,
            "fmeasure": 0.38049
        },
        "nist": 1.9019346047903833,
        "bleu": 10.65728,
        "nubia": {
            "semantic_relation": 3.5855,
            "contradiction": 16.47333,
            "irrelevancy": 76.85294,
            "logical_agreement": 6.67373,
            "grammar_ref": 3.44293,
            "grammar_hyp": 3.25836,
            "nubia_score": 0.60463
        },
        "bertscore": {
            "precision": 0.75593,
            "recall": 0.90397,
            "f1": 0.81114
        },
        "meteor": 0.23070887965432194,
        "bleurt": -0.27047
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.375
        },
        "rouge1": {
            "precision": 0.12903,
            "recall": 0.34231,
            "fmeasure": 0.18681
        },
        "rouge2": {
            "precision": 0.01667,
            "recall": 0.04167,
            "fmeasure": 0.02381
        },
        "rougeL": {
            "precision": 0.09677,
            "recall": 0.25385,
            "fmeasure": 0.13969
        },
        "rougeLsum": {
            "precision": 0.09677,
            "recall": 0.25385,
            "fmeasure": 0.13969
        },
        "nist": 0.8424860321672787,
        "bleu": 2.80486,
        "nubia": {
            "semantic_relation": 1.86541,
            "contradiction": 77.60935,
            "irrelevancy": 21.52543,
            "logical_agreement": 0.86522,
            "grammar_ref": 4.19915,
            "grammar_hyp": 4.51255,
            "nubia_score": 0.0
        },
        "bertscore": {
            "precision": 0.70826,
            "recall": 0.72187,
            "f1": 0.715
        },
        "meteor": 0.1382900378733038,
        "bleurt": -1.24751
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.125,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.63333,
            "fmeasure": 0.54815
        },
        "rouge2": {
            "precision": 0.30303,
            "recall": 0.38095,
            "fmeasure": 0.32889
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.55,
            "fmeasure": 0.48148
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.55,
            "fmeasure": 0.48148
        },
        "nist": 2.789662895211779,
        "bleu": 25.82107,
        "nubia": {
            "semantic_relation": 3.91472,
            "contradiction": 0.12672,
            "irrelevancy": 99.7532,
            "logical_agreement": 0.12008,
            "grammar_ref": 4.70243,
            "grammar_hyp": 5.13247,
            "nubia_score": 0.57563
        },
        "bertscore": {
            "precision": 0.89259,
            "recall": 0.95256,
            "f1": 0.9216
        },
        "meteor": 0.3507908682921562,
        "bleurt": -0.48831
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.25,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.85897,
            "recall": 0.743,
            "fmeasure": 0.7727
        },
        "rouge2": {
            "precision": 0.61806,
            "recall": 0.54548,
            "fmeasure": 0.55896
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.68161,
            "fmeasure": 0.70345
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.68161,
            "fmeasure": 0.70345
        },
        "nist": 4.059756313732968,
        "bleu": 40.32889,
        "nubia": {
            "semantic_relation": 4.21766,
            "contradiction": 37.00486,
            "irrelevancy": 2.03061,
            "logical_agreement": 60.96453,
            "grammar_ref": 4.07172,
            "grammar_hyp": 4.43353,
            "nubia_score": 0.72925
        },
        "bertscore": {
            "precision": 0.92379,
            "recall": 0.9339,
            "f1": 0.92814
        },
        "meteor": 0.44766003323467496,
        "bleurt": 0.34162
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.90741,
            "recall": 0.65833,
            "fmeasure": 0.72596
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.57414,
            "fmeasure": 0.60826
        },
        "rougeL": {
            "precision": 0.7963,
            "recall": 0.61905,
            "fmeasure": 0.669
        },
        "rougeLsum": {
            "precision": 0.7963,
            "recall": 0.61905,
            "fmeasure": 0.669
        },
        "nist": 0.984227753547181,
        "bleu": 43.57376,
        "nubia": {
            "semantic_relation": 4.02616,
            "contradiction": 0.54268,
            "irrelevancy": 1.10207,
            "logical_agreement": 98.35526,
            "grammar_ref": 4.54027,
            "grammar_hyp": 5.04957,
            "nubia_score": 0.62894
        },
        "bertscore": {
            "precision": 0.95475,
            "recall": 0.89548,
            "f1": 0.92305
        },
        "meteor": 0.31822607983418594,
        "bleurt": 0.09408
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.125
        },
        "rouge1": {
            "precision": 0.2,
            "recall": 0.22222,
            "fmeasure": 0.21053
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.2,
            "recall": 0.22222,
            "fmeasure": 0.21053
        },
        "rougeLsum": {
            "precision": 0.2,
            "recall": 0.22222,
            "fmeasure": 0.21053
        },
        "nist": 0.7556783850707262,
        "bleu": 4.52136,
        "nubia": {
            "semantic_relation": 2.20213,
            "contradiction": 44.38642,
            "irrelevancy": 47.34288,
            "logical_agreement": 8.27071,
            "grammar_ref": 5.49813,
            "grammar_hyp": 6.57348,
            "nubia_score": 0.10571
        },
        "bertscore": {
            "precision": 0.83278,
            "recall": 0.82565,
            "f1": 0.8292
        },
        "meteor": 0.08893040635217189,
        "bleurt": -0.14551
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.80952,
            "fmeasure": 0.79487
        },
        "rouge2": {
            "precision": 0.69744,
            "recall": 0.71717,
            "fmeasure": 0.70455
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.80952,
            "fmeasure": 0.79487
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.80952,
            "fmeasure": 0.79487
        },
        "nist": 3.2231407849274794,
        "bleu": 60.53095,
        "nubia": {
            "semantic_relation": 4.91496,
            "contradiction": 1.09717,
            "irrelevancy": 1.94027,
            "logical_agreement": 96.96256,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.0553,
            "nubia_score": 0.89633
        },
        "bertscore": {
            "precision": 0.97689,
            "recall": 0.97417,
            "f1": 0.97553
        },
        "meteor": 0.49196555602877623,
        "bleurt": 0.72166
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7916666666666666
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.76923,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.78947,
            "recall": 0.6,
            "fmeasure": 0.68182
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.69231,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.69231,
            "fmeasure": 0.78261
        },
        "nist": 3.8138568954638643,
        "bleu": 56.26585,
        "nubia": {
            "semantic_relation": 3.71512,
            "contradiction": 0.23803,
            "irrelevancy": 0.41381,
            "logical_agreement": 99.34816,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.62474,
            "nubia_score": 0.60063
        },
        "bertscore": {
            "precision": 0.9644,
            "recall": 0.94721,
            "f1": 0.95573
        },
        "meteor": 0.46724035025858557,
        "bleurt": 0.16259
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.87273,
            "fmeasure": 0.93158
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.75185,
            "fmeasure": 0.80828
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.87273,
            "fmeasure": 0.93158
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.87273,
            "fmeasure": 0.93158
        },
        "nist": 4.152419323361069,
        "bleu": 90.48374,
        "nubia": {
            "semantic_relation": 4.67576,
            "contradiction": 0.51934,
            "irrelevancy": 1.7644,
            "logical_agreement": 97.71627,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.86927,
            "nubia_score": 0.85404
        },
        "bertscore": {
            "precision": 0.99025,
            "recall": 0.97126,
            "f1": 0.98066
        },
        "meteor": 0.5064321156600579,
        "bleurt": 0.66242
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.53737,
            "fmeasure": 0.67429
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.25714,
            "fmeasure": 0.3324
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.45455,
            "fmeasure": 0.52632
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.45455,
            "fmeasure": 0.52632
        },
        "nist": 2.054254086979044,
        "bleu": 27.69591,
        "nubia": {
            "semantic_relation": 3.60355,
            "contradiction": 0.18326,
            "irrelevancy": 1.0045,
            "logical_agreement": 98.81224,
            "grammar_ref": 4.59968,
            "grammar_hyp": 5.39202,
            "nubia_score": 0.52783
        },
        "bertscore": {
            "precision": 0.92112,
            "recall": 0.85085,
            "f1": 0.88365
        },
        "meteor": 0.2986631954929169,
        "bleurt": -0.07368
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.625,
            "fmeasure": 0.52632
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.14286,
            "fmeasure": 0.11765
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.5,
            "fmeasure": 0.42105
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.5,
            "fmeasure": 0.42105
        },
        "nist": 1.660964047443681,
        "bleu": 5.30016,
        "nubia": {
            "semantic_relation": 3.95228,
            "contradiction": 0.09396,
            "irrelevancy": 99.75979,
            "logical_agreement": 0.14625,
            "grammar_ref": 5.51883,
            "grammar_hyp": 5.00912,
            "nubia_score": 0.73251
        },
        "bertscore": {
            "precision": 0.80894,
            "recall": 0.83694,
            "f1": 0.82095
        },
        "meteor": 0.32216502991942075,
        "bleurt": 0.03697
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.64583,
            "recall": 0.61111,
            "fmeasure": 0.62309
        },
        "rouge2": {
            "precision": 0.48889,
            "recall": 0.45455,
            "fmeasure": 0.46598
        },
        "rougeL": {
            "precision": 0.64583,
            "recall": 0.61111,
            "fmeasure": 0.62309
        },
        "rougeLsum": {
            "precision": 0.64583,
            "recall": 0.61111,
            "fmeasure": 0.62309
        },
        "nist": 2.2875609451369536,
        "bleu": 44.11536,
        "nubia": {
            "semantic_relation": 3.20349,
            "contradiction": 15.6237,
            "irrelevancy": 83.961,
            "logical_agreement": 0.4153,
            "grammar_ref": 4.44297,
            "grammar_hyp": 5.37646,
            "nubia_score": 0.2519
        },
        "bertscore": {
            "precision": 0.86888,
            "recall": 0.90916,
            "f1": 0.88857
        },
        "meteor": 0.35557879339266296,
        "bleurt": -0.03326
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.14285714285714285,
            "3": 0.631578947368421
        },
        "rouge1": {
            "precision": 0.60641,
            "recall": 0.62239,
            "fmeasure": 0.60895
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.31071,
            "fmeasure": 0.29749
        },
        "rougeL": {
            "precision": 0.40128,
            "recall": 0.42391,
            "fmeasure": 0.4098
        },
        "rougeLsum": {
            "precision": 0.40128,
            "recall": 0.42391,
            "fmeasure": 0.4098
        },
        "nist": 2.735508467717592,
        "bleu": 19.08249,
        "nubia": {
            "semantic_relation": 3.76496,
            "contradiction": 2.59833,
            "irrelevancy": 7.7329,
            "logical_agreement": 89.66877,
            "grammar_ref": 4.70186,
            "grammar_hyp": 4.81729,
            "nubia_score": 0.58784
        },
        "bertscore": {
            "precision": 0.89799,
            "recall": 0.87998,
            "f1": 0.88856
        },
        "meteor": 0.3110377408341222,
        "bleurt": 0.17736
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.86111,
            "fmeasure": 0.71212
        },
        "rouge2": {
            "precision": 0.37037,
            "recall": 0.59394,
            "fmeasure": 0.44762
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.72222,
            "fmeasure": 0.59848
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.72222,
            "fmeasure": 0.59848
        },
        "nist": 3.2231086688195565,
        "bleu": 21.83418,
        "nubia": {
            "semantic_relation": 4.37388,
            "contradiction": 9.95059,
            "irrelevancy": 70.10601,
            "logical_agreement": 19.94339,
            "grammar_ref": 5.75818,
            "grammar_hyp": 5.17175,
            "nubia_score": 0.73579
        },
        "bertscore": {
            "precision": 0.86422,
            "recall": 0.94535,
            "f1": 0.90005
        },
        "meteor": 0.42919650333815856,
        "bleurt": 0.10378
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.68704,
            "recall": 0.73333,
            "fmeasure": 0.70686
        },
        "rouge2": {
            "precision": 0.52546,
            "recall": 0.56296,
            "fmeasure": 0.53989
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.73333,
            "fmeasure": 0.68333
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.73333,
            "fmeasure": 0.68333
        },
        "nist": 3.6066135650348863,
        "bleu": 59.40637,
        "nubia": {
            "semantic_relation": 4.06955,
            "contradiction": 0.27083,
            "irrelevancy": 49.93805,
            "logical_agreement": 49.79112,
            "grammar_ref": 5.47595,
            "grammar_hyp": 5.31876,
            "nubia_score": 0.7286
        },
        "bertscore": {
            "precision": 0.92478,
            "recall": 0.92847,
            "f1": 0.92662
        },
        "meteor": 0.43115560515334744,
        "bleurt": 0.18971
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.84565,
            "fmeasure": 0.7621
        },
        "rouge2": {
            "precision": 0.4893,
            "recall": 0.55919,
            "fmeasure": 0.5153
        },
        "rougeL": {
            "precision": 0.60648,
            "recall": 0.70311,
            "fmeasure": 0.64408
        },
        "rougeLsum": {
            "precision": 0.60648,
            "recall": 0.70311,
            "fmeasure": 0.64408
        },
        "nist": 3.6128838616985886,
        "bleu": 45.30371,
        "nubia": {
            "semantic_relation": 3.90357,
            "contradiction": 85.7701,
            "irrelevancy": 13.44697,
            "logical_agreement": 0.78293,
            "grammar_ref": 5.29605,
            "grammar_hyp": 5.19195,
            "nubia_score": 0.52279
        },
        "bertscore": {
            "precision": 0.90481,
            "recall": 0.92106,
            "f1": 0.91265
        },
        "meteor": 0.44465830872243317,
        "bleurt": -0.198
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.35714285714285715
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.46053,
            "fmeasure": 0.38668
        },
        "rouge2": {
            "precision": 0.13462,
            "recall": 0.1886,
            "fmeasure": 0.15707
        },
        "rougeL": {
            "precision": 0.14815,
            "recall": 0.20526,
            "fmeasure": 0.17206
        },
        "rougeLsum": {
            "precision": 0.14815,
            "recall": 0.20526,
            "fmeasure": 0.17206
        },
        "nist": 1.7225727788525504,
        "bleu": 5.00782,
        "nubia": {
            "semantic_relation": 3.04078,
            "contradiction": 8.69839,
            "irrelevancy": 84.88407,
            "logical_agreement": 6.41754,
            "grammar_ref": 4.38153,
            "grammar_hyp": 4.74468,
            "nubia_score": 0.41737
        },
        "bertscore": {
            "precision": 0.77376,
            "recall": 0.81246,
            "f1": 0.79264
        },
        "meteor": 0.20174603556259307,
        "bleurt": -0.60589
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.28333,
            "recall": 0.41818,
            "fmeasure": 0.3361
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.29091,
            "fmeasure": 0.2046
        },
        "rougeL": {
            "precision": 0.28333,
            "recall": 0.41818,
            "fmeasure": 0.3361
        },
        "rougeLsum": {
            "precision": 0.28333,
            "recall": 0.41818,
            "fmeasure": 0.3361
        },
        "nist": 1.6485668969893084,
        "bleu": 18.87952,
        "nubia": {
            "semantic_relation": 3.06192,
            "contradiction": 5.05299,
            "irrelevancy": 93.65425,
            "logical_agreement": 1.29276,
            "grammar_ref": 5.20931,
            "grammar_hyp": 4.63936,
            "nubia_score": 0.4342
        },
        "bertscore": {
            "precision": 0.76545,
            "recall": 0.80401,
            "f1": 0.78198
        },
        "meteor": 0.23982153375389115,
        "bleurt": -0.73377
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.42094,
            "recall": 0.57967,
            "fmeasure": 0.48751
        },
        "rouge2": {
            "precision": 0.26716,
            "recall": 0.37447,
            "fmeasure": 0.31169
        },
        "rougeL": {
            "precision": 0.42094,
            "recall": 0.57967,
            "fmeasure": 0.48751
        },
        "rougeLsum": {
            "precision": 0.42094,
            "recall": 0.57967,
            "fmeasure": 0.48751
        },
        "nist": 2.2565008016453847,
        "bleu": 24.48718,
        "nubia": {
            "semantic_relation": 4.16286,
            "contradiction": 6.95043,
            "irrelevancy": 27.79844,
            "logical_agreement": 65.25112,
            "grammar_ref": 5.01983,
            "grammar_hyp": 4.53289,
            "nubia_score": 0.68658
        },
        "bertscore": {
            "precision": 0.90329,
            "recall": 0.92609,
            "f1": 0.9145
        },
        "meteor": 0.38306781219121433,
        "bleurt": 0.33406
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "nist": 3.0881978509745025,
        "bleu": 68.94026,
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        },
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97492
        },
        "meteor": 0.81809314801268,
        "bleurt": 0.64449
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.05263157894736842,
            "2": 1.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.78846,
            "fmeasure": 0.8373
        },
        "rouge2": {
            "precision": 0.85714,
            "recall": 0.57937,
            "fmeasure": 0.6817
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.61859,
            "fmeasure": 0.71627
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.61859,
            "fmeasure": 0.71627
        },
        "nist": 0.8351153554755218,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.10262,
            "contradiction": 0.21014,
            "irrelevancy": 0.43462,
            "logical_agreement": 99.35524,
            "grammar_ref": 4.62626,
            "grammar_hyp": 5.05142,
            "nubia_score": 0.66188
        },
        "bertscore": {
            "precision": 0.96585,
            "recall": 0.95146,
            "f1": 0.95114
        },
        "meteor": 0.46756519067015256,
        "bleurt": 0.14409
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.81818,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.54545,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.54545,
            "fmeasure": 0.5
        },
        "nist": 2.749392935937563,
        "bleu": 29.42096,
        "nubia": {
            "semantic_relation": 4.44897,
            "contradiction": 0.23046,
            "irrelevancy": 99.4262,
            "logical_agreement": 0.34334,
            "grammar_ref": 5.42176,
            "grammar_hyp": 4.55703,
            "nubia_score": 0.843
        },
        "bertscore": {
            "precision": 0.91844,
            "recall": 0.94556,
            "f1": 0.9318
        },
        "meteor": 0.4294445532848442,
        "bleurt": 0.432
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.5,
            "3": 0.6842105263157895
        },
        "rouge1": {
            "precision": 0.81101,
            "recall": 0.69949,
            "fmeasure": 0.74626
        },
        "rouge2": {
            "precision": 0.59444,
            "recall": 0.5043,
            "fmeasure": 0.54141
        },
        "rougeL": {
            "precision": 0.71726,
            "recall": 0.62626,
            "fmeasure": 0.66422
        },
        "rougeLsum": {
            "precision": 0.71726,
            "recall": 0.62626,
            "fmeasure": 0.66422
        },
        "nist": 5.059332784119328,
        "bleu": 59.36359,
        "nubia": {
            "semantic_relation": 4.14014,
            "contradiction": 6.09971,
            "irrelevancy": 21.69645,
            "logical_agreement": 72.20384,
            "grammar_ref": 6.00658,
            "grammar_hyp": 5.74684,
            "nubia_score": 0.73593
        },
        "bertscore": {
            "precision": 0.93888,
            "recall": 0.89609,
            "f1": 0.91693
        },
        "meteor": 0.3978196127251017,
        "bleurt": -0.21282
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.60784,
            "recall": 0.66214,
            "fmeasure": 0.63137
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.36111,
            "fmeasure": 0.34524
        },
        "rougeL": {
            "precision": 0.4902,
            "recall": 0.53243,
            "fmeasure": 0.5085
        },
        "rougeLsum": {
            "precision": 0.4902,
            "recall": 0.53243,
            "fmeasure": 0.5085
        },
        "nist": 2.4661638335346288,
        "bleu": 12.84619,
        "nubia": {
            "semantic_relation": 4.14264,
            "contradiction": 1.28828,
            "irrelevancy": 53.17715,
            "logical_agreement": 45.53457,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.66333,
            "nubia_score": 0.65909
        },
        "bertscore": {
            "precision": 0.90896,
            "recall": 0.90061,
            "f1": 0.90207
        },
        "meteor": 0.2915000841486297,
        "bleurt": 0.20781
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5714285714285714,
            "3": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.3871,
            "fmeasure": 0.43636
        },
        "rouge2": {
            "precision": 0.21739,
            "recall": 0.16667,
            "fmeasure": 0.18868
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.35484,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.35484,
            "fmeasure": 0.4
        },
        "nist": 3.2200284517077997,
        "bleu": 15.02086,
        "nubia": {
            "semantic_relation": 2.06646,
            "contradiction": 61.01435,
            "irrelevancy": 25.16239,
            "logical_agreement": 13.82326,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.64625,
            "nubia_score": 0.16097
        },
        "bertscore": {
            "precision": 0.92051,
            "recall": 0.88204,
            "f1": 0.90087
        },
        "meteor": 0.25665832586274206,
        "bleurt": -0.05648
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.3684210526315789
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.38788,
            "fmeasure": 0.46555
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.07143,
            "fmeasure": 0.08689
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.26182,
            "fmeasure": 0.30809
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.26182,
            "fmeasure": 0.30809
        },
        "nist": 1.963806525298406,
        "bleu": 6.10522,
        "nubia": {
            "semantic_relation": 2.23079,
            "contradiction": 0.17919,
            "irrelevancy": 99.29825,
            "logical_agreement": 0.52255,
            "grammar_ref": 4.82125,
            "grammar_hyp": 4.07082,
            "nubia_score": 0.19916
        },
        "bertscore": {
            "precision": 0.83344,
            "recall": 0.76114,
            "f1": 0.79565
        },
        "meteor": 0.19504689452064153,
        "bleurt": -0.75172
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.098214829261011,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2797,
            "irrelevancy": 0.5863,
            "logical_agreement": 99.13399,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.67996,
            "nubia_score": 0.98883
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.94053
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.53289,
            "fmeasure": 0.56357
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.13056,
            "fmeasure": 0.1364
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.2838,
            "fmeasure": 0.30637
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.2838,
            "fmeasure": 0.30637
        },
        "nist": 2.201592201681259,
        "bleu": 8.49475,
        "nubia": {
            "semantic_relation": 2.71445,
            "contradiction": 1.29067,
            "irrelevancy": 73.12784,
            "logical_agreement": 25.5815,
            "grammar_ref": 3.5564,
            "grammar_hyp": 2.91465,
            "nubia_score": 0.43773
        },
        "bertscore": {
            "precision": 0.87229,
            "recall": 0.86629,
            "f1": 0.86928
        },
        "meteor": 0.2801702212694374,
        "bleurt": -0.0022
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.56667,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "nist": 1.7990385038524417,
        "bleu": 20.16495,
        "nubia": {
            "semantic_relation": 4.21377,
            "contradiction": 0.17851,
            "irrelevancy": 33.78877,
            "logical_agreement": 66.03272,
            "grammar_ref": 5.27628,
            "grammar_hyp": 4.69427,
            "nubia_score": 0.81239
        },
        "bertscore": {
            "precision": 0.94225,
            "recall": 0.97743,
            "f1": 0.95951
        },
        "meteor": 0.861811391223156,
        "bleurt": 0.49066
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.45454545454545453
        },
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.38095,
            "fmeasure": 0.4692
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.11264,
            "fmeasure": 0.14069
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.38095,
            "fmeasure": 0.4692
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.38095,
            "fmeasure": 0.4692
        },
        "nist": 1.5119230280433509,
        "bleu": 17.89408,
        "nubia": {
            "semantic_relation": 4.87233,
            "contradiction": 0.11701,
            "irrelevancy": 0.53715,
            "logical_agreement": 99.34584,
            "grammar_ref": 5.03823,
            "grammar_hyp": 6.04668,
            "nubia_score": 0.86861
        },
        "bertscore": {
            "precision": 0.93328,
            "recall": 0.88014,
            "f1": 0.90593
        },
        "meteor": 0.35896959276645535,
        "bleurt": 0.5064
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.69048,
            "recall": 0.60644,
            "fmeasure": 0.64439
        },
        "rouge2": {
            "precision": 0.4359,
            "recall": 0.37821,
            "fmeasure": 0.40407
        },
        "rougeL": {
            "precision": 0.61905,
            "recall": 0.54342,
            "fmeasure": 0.57757
        },
        "rougeLsum": {
            "precision": 0.61905,
            "recall": 0.54342,
            "fmeasure": 0.57757
        },
        "nist": 3.3866361506881995,
        "bleu": 35.63055,
        "nubia": {
            "semantic_relation": 3.96355,
            "contradiction": 26.84465,
            "irrelevancy": 68.27678,
            "logical_agreement": 4.87857,
            "grammar_ref": 4.48877,
            "grammar_hyp": 4.27607,
            "nubia_score": 0.64292
        },
        "bertscore": {
            "precision": 0.91236,
            "recall": 0.87479,
            "f1": 0.88405
        },
        "meteor": 0.3411020054215811,
        "bleurt": -0.04671
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "rouge1": {
            "precision": 0.87729,
            "recall": 0.88828,
            "fmeasure": 0.88177
        },
        "rouge2": {
            "precision": 0.70406,
            "recall": 0.71902,
            "fmeasure": 0.71056
        },
        "rougeL": {
            "precision": 0.83883,
            "recall": 0.85165,
            "fmeasure": 0.84425
        },
        "rougeLsum": {
            "precision": 0.83883,
            "recall": 0.85165,
            "fmeasure": 0.84425
        },
        "nist": 4.297916759630754,
        "bleu": 59.36359,
        "nubia": {
            "semantic_relation": 4.55699,
            "contradiction": 0.18665,
            "irrelevancy": 48.93316,
            "logical_agreement": 50.88018,
            "grammar_ref": 4.97173,
            "grammar_hyp": 5.02737,
            "nubia_score": 0.78269
        },
        "bertscore": {
            "precision": 0.95626,
            "recall": 0.96789,
            "f1": 0.9602
        },
        "meteor": 0.5083614283050566,
        "bleurt": 0.52652
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.0,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.55079,
            "irrelevancy": 0.53693,
            "logical_agreement": 98.91228,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.38626,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 1.00232
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "nist": 2.4929182263680483,
        "bleu": 19.43406,
        "nubia": {
            "semantic_relation": 4.25211,
            "contradiction": 0.57776,
            "irrelevancy": 0.52541,
            "logical_agreement": 98.89683,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.57554,
            "nubia_score": 0.83281
        },
        "bertscore": {
            "precision": 0.96843,
            "recall": 0.92985,
            "f1": 0.94874
        },
        "meteor": 0.38388402914845343,
        "bleurt": 0.5593
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.47619047619047616
        },
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.54348,
            "fmeasure": 0.68514
        },
        "rouge2": {
            "precision": 0.76923,
            "recall": 0.43636,
            "fmeasure": 0.55639
        },
        "rougeL": {
            "precision": 0.92857,
            "recall": 0.54348,
            "fmeasure": 0.68514
        },
        "rougeLsum": {
            "precision": 0.92857,
            "recall": 0.54348,
            "fmeasure": 0.68514
        },
        "nist": 0.5230454028516153,
        "bleu": 20.2362,
        "nubia": {
            "semantic_relation": 4.42806,
            "contradiction": 0.1765,
            "irrelevancy": 0.43401,
            "logical_agreement": 99.38949,
            "grammar_ref": 3.26294,
            "grammar_hyp": 3.2568,
            "nubia_score": 0.90992
        },
        "bertscore": {
            "precision": 0.95762,
            "recall": 0.84624,
            "f1": 0.89849
        },
        "meteor": 0.3272942874634928,
        "bleurt": 0.36014
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9047619047619048
        },
        "rouge1": {
            "precision": 0.95652,
            "recall": 0.81481,
            "fmeasure": 0.88
        },
        "rouge2": {
            "precision": 0.86364,
            "recall": 0.73077,
            "fmeasure": 0.79167
        },
        "rougeL": {
            "precision": 0.95652,
            "recall": 0.81481,
            "fmeasure": 0.88
        },
        "rougeLsum": {
            "precision": 0.95652,
            "recall": 0.81481,
            "fmeasure": 0.88
        },
        "nist": 3.467258952997759,
        "bleu": 62.86102,
        "nubia": {
            "semantic_relation": 4.24894,
            "contradiction": 0.13552,
            "irrelevancy": 9.62716,
            "logical_agreement": 90.23731,
            "grammar_ref": 4.19464,
            "grammar_hyp": 4.49828,
            "nubia_score": 0.69269
        },
        "bertscore": {
            "precision": 0.97265,
            "recall": 0.94448,
            "f1": 0.95781
        },
        "meteor": 0.4972635721787356,
        "bleurt": 0.31997
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.125,
            "3": 0.8947368421052632
        },
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.78301,
            "fmeasure": 0.76891
        },
        "rouge2": {
            "precision": 0.54464,
            "recall": 0.55006,
            "fmeasure": 0.54215
        },
        "rougeL": {
            "precision": 0.57778,
            "recall": 0.59497,
            "fmeasure": 0.5821
        },
        "rougeLsum": {
            "precision": 0.57778,
            "recall": 0.59497,
            "fmeasure": 0.5821
        },
        "nist": 3.328211816128447,
        "bleu": 53.42748,
        "nubia": {
            "semantic_relation": 3.78956,
            "contradiction": 0.83833,
            "irrelevancy": 0.92737,
            "logical_agreement": 98.2343,
            "grammar_ref": 4.25678,
            "grammar_hyp": 4.16158,
            "nubia_score": 0.63074
        },
        "bertscore": {
            "precision": 0.94233,
            "recall": 0.94462,
            "f1": 0.94348
        },
        "meteor": 0.4653854190614951,
        "bleurt": 0.32746
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.45,
            "recall": 0.57937,
            "fmeasure": 0.50464
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.45833,
            "fmeasure": 0.38431
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.57937,
            "fmeasure": 0.50464
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.57937,
            "fmeasure": 0.50464
        },
        "nist": 1.977891793650449,
        "bleu": 36.72056,
        "nubia": {
            "semantic_relation": 3.23206,
            "contradiction": 0.21495,
            "irrelevancy": 85.72121,
            "logical_agreement": 14.06384,
            "grammar_ref": 4.8549,
            "grammar_hyp": 5.43948,
            "nubia_score": 0.38436
        },
        "bertscore": {
            "precision": 0.89075,
            "recall": 0.93343,
            "f1": 0.91052
        },
        "meteor": 0.37146259355923894,
        "bleurt": 0.36213
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "nist": 1.2775418301849517,
        "bleu": 11.33958,
        "nubia": {
            "semantic_relation": 3.94411,
            "contradiction": 0.52809,
            "irrelevancy": 90.87595,
            "logical_agreement": 8.59595,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.74554,
            "nubia_score": 0.60532
        },
        "bertscore": {
            "precision": 0.8573,
            "recall": 0.88842,
            "f1": 0.87258
        },
        "meteor": 0.31127891035349853,
        "bleurt": -0.04695
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.6,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "nist": 2.425622163887878,
        "bleu": 51.15078,
        "nubia": {
            "semantic_relation": 4.03933,
            "contradiction": 14.76512,
            "irrelevancy": 1.30136,
            "logical_agreement": 83.93352,
            "grammar_ref": 6.21263,
            "grammar_hyp": 7.12865,
            "nubia_score": 0.54196
        },
        "bertscore": {
            "precision": 0.99151,
            "recall": 0.95959,
            "f1": 0.97529
        },
        "meteor": 0.42750933026297866,
        "bleurt": 0.50807
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.38462,
            "fmeasure": 0.47619
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.2037,
            "fmeasure": 0.23684
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.38462,
            "fmeasure": 0.47619
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.38462,
            "fmeasure": 0.47619
        },
        "nist": 0.9572871299785921,
        "bleu": 8.59132,
        "nubia": {
            "semantic_relation": 3.81986,
            "contradiction": 15.07903,
            "irrelevancy": 79.31522,
            "logical_agreement": 5.60576,
            "grammar_ref": 5.35395,
            "grammar_hyp": 4.82406,
            "nubia_score": 0.5347
        },
        "bertscore": {
            "precision": 0.92188,
            "recall": 0.85467,
            "f1": 0.88701
        },
        "meteor": 0.28038886196955204,
        "bleurt": -0.26662
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2222222222222222,
            "3": 0.1111111111111111
        },
        "rouge1": {
            "precision": 0.20833,
            "recall": 0.16043,
            "fmeasure": 0.18075
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.0831,
            "fmeasure": 0.09491
        },
        "rougeL": {
            "precision": 0.20833,
            "recall": 0.16043,
            "fmeasure": 0.18075
        },
        "rougeLsum": {
            "precision": 0.20833,
            "recall": 0.16043,
            "fmeasure": 0.18075
        },
        "nist": 1.4863142588445788,
        "bleu": 8.66853,
        "nubia": {
            "semantic_relation": 2.48,
            "contradiction": 89.73135,
            "irrelevancy": 8.5876,
            "logical_agreement": 1.68105,
            "grammar_ref": 5.24053,
            "grammar_hyp": 3.54263,
            "nubia_score": 0.35882
        },
        "bertscore": {
            "precision": 0.80058,
            "recall": 0.75273,
            "f1": 0.77592
        },
        "meteor": 0.11412944422542862,
        "bleurt": -0.86087
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.7333333333333333
        },
        "rouge1": {
            "precision": 0.69152,
            "recall": 0.66646,
            "fmeasure": 0.67836
        },
        "rouge2": {
            "precision": 0.41558,
            "recall": 0.39706,
            "fmeasure": 0.40583
        },
        "rougeL": {
            "precision": 0.45029,
            "recall": 0.43525,
            "fmeasure": 0.4424
        },
        "rougeLsum": {
            "precision": 0.45029,
            "recall": 0.43525,
            "fmeasure": 0.4424
        },
        "nist": 3.6005477657490967,
        "bleu": 24.86207,
        "nubia": {
            "semantic_relation": 4.72192,
            "contradiction": 0.14853,
            "irrelevancy": 0.56336,
            "logical_agreement": 99.28811,
            "grammar_ref": 4.13564,
            "grammar_hyp": 4.20988,
            "nubia_score": 0.88732
        },
        "bertscore": {
            "precision": 0.91195,
            "recall": 0.90803,
            "f1": 0.90897
        },
        "meteor": 0.37397790826543825,
        "bleurt": 0.3468
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.65625,
            "fmeasure": 0.57857
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "nist": 2.8441645853579183,
        "bleu": 44.5345,
        "nubia": {
            "semantic_relation": 4.19399,
            "contradiction": 0.18495,
            "irrelevancy": 94.22535,
            "logical_agreement": 5.5897,
            "grammar_ref": 5.6106,
            "grammar_hyp": 4.31806,
            "nubia_score": 0.76494
        },
        "bertscore": {
            "precision": 0.89821,
            "recall": 0.93375,
            "f1": 0.91564
        },
        "meteor": 0.4505163353501177,
        "bleurt": 0.30287
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8235294117647058
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.78384,
            "fmeasure": 0.87473
        },
        "rouge2": {
            "precision": 0.84524,
            "recall": 0.64352,
            "fmeasure": 0.72639
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.78384,
            "fmeasure": 0.87473
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.78384,
            "fmeasure": 0.87473
        },
        "nist": 3.3475106969243034,
        "bleu": 60.57479,
        "nubia": {
            "semantic_relation": 4.83788,
            "contradiction": 0.59678,
            "irrelevancy": 0.53861,
            "logical_agreement": 98.86461,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.90481,
            "nubia_score": 0.9704
        },
        "bertscore": {
            "precision": 0.99164,
            "recall": 0.9597,
            "f1": 0.97395
        },
        "meteor": 0.4684327774899376,
        "bleurt": 0.76635
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "mT5_base/totto_test",
        "N": 5,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.8431372549019608,
            "3": 0.8285714285714286
        },
        "rouge1": {
            "precision": 0.71296,
            "recall": 0.80189,
            "fmeasure": 0.74091
        },
        "rouge2": {
            "precision": 0.54526,
            "recall": 0.60386,
            "fmeasure": 0.56259
        },
        "rougeL": {
            "precision": 0.6142,
            "recall": 0.67388,
            "fmeasure": 0.6315
        },
        "rougeLsum": {
            "precision": 0.6142,
            "recall": 0.67388,
            "fmeasure": 0.6315
        },
        "nist": 5.375851347078738,
        "bleu": 57.43263,
        "nubia": {
            "semantic_relation": 4.07299,
            "contradiction": 15.94236,
            "irrelevancy": 37.08497,
            "logical_agreement": 46.97266,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.33114,
            "nubia_score": 0.76498
        },
        "bertscore": {
            "precision": 0.92342,
            "recall": 0.94748,
            "f1": 0.93263
        },
        "meteor": 0.49536434497981124,
        "bleurt": 0.14849
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rouge2": {
            "precision": 0.85,
            "recall": 0.81818,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "nist": 4.190572262757721,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.98748,
            "contradiction": 0.44405,
            "irrelevancy": 0.50174,
            "logical_agreement": 99.05421,
            "grammar_ref": 4.19853,
            "grammar_hyp": 3.68353,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.83087
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.9
        },
        "rouge1": {
            "precision": 0.70588,
            "recall": 1.0,
            "fmeasure": 0.82619
        },
        "rouge2": {
            "precision": 0.59375,
            "recall": 0.85833,
            "fmeasure": 0.70055
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 1.0,
            "fmeasure": 0.82619
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 1.0,
            "fmeasure": 0.82619
        },
        "nist": 3.10738098714625,
        "bleu": 50.1413,
        "nubia": {
            "semantic_relation": 4.14019,
            "contradiction": 0.47018,
            "irrelevancy": 81.86249,
            "logical_agreement": 17.66733,
            "grammar_ref": 4.75081,
            "grammar_hyp": 3.68485,
            "nubia_score": 0.77508
        },
        "bertscore": {
            "precision": 0.91137,
            "recall": 0.97758,
            "f1": 0.94331
        },
        "meteor": 0.5103416375985329,
        "bleurt": 0.3654
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.7
        },
        "rouge1": {
            "precision": 0.9,
            "recall": 0.66484,
            "fmeasure": 0.76449
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.39744,
            "fmeasure": 0.4632
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.51648,
            "fmeasure": 0.5942
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.51648,
            "fmeasure": 0.5942
        },
        "nist": 1.5014114750764194,
        "bleu": 22.79494,
        "nubia": {
            "semantic_relation": 3.94461,
            "contradiction": 0.29674,
            "irrelevancy": 1.15725,
            "logical_agreement": 98.54601,
            "grammar_ref": 4.1674,
            "grammar_hyp": 4.5447,
            "nubia_score": 0.67281
        },
        "bertscore": {
            "precision": 0.96899,
            "recall": 0.88829,
            "f1": 0.92688
        },
        "meteor": 0.3648865473781653,
        "bleurt": 0.17252
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7058823529411765
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.71678,
            "fmeasure": 0.69069
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.36765,
            "fmeasure": 0.34958
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.57734,
            "fmeasure": 0.55055
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.57734,
            "fmeasure": 0.55055
        },
        "nist": 3.1953391170709278,
        "bleu": 25.73453,
        "nubia": {
            "semantic_relation": 3.57882,
            "contradiction": 0.71473,
            "irrelevancy": 87.446,
            "logical_agreement": 11.83928,
            "grammar_ref": 4.84215,
            "grammar_hyp": 4.34989,
            "nubia_score": 0.55244
        },
        "bertscore": {
            "precision": 0.88309,
            "recall": 0.90761,
            "f1": 0.89518
        },
        "meteor": 0.35915012182129735,
        "bleurt": -0.05786
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "nist": 2.32249814589546,
        "bleu": 41.10546,
        "nubia": {
            "semantic_relation": 4.62868,
            "contradiction": 0.5038,
            "irrelevancy": 0.54324,
            "logical_agreement": 98.95296,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.03961,
            "nubia_score": 0.96227
        },
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.9307,
            "f1": 0.94796
        },
        "meteor": 0.8569614896318238,
        "bleurt": 0.65075
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.77632,
            "fmeasure": 0.76282
        },
        "rouge2": {
            "precision": 0.5614,
            "recall": 0.58285,
            "fmeasure": 0.57183
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.77632,
            "fmeasure": 0.76282
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.77632,
            "fmeasure": 0.76282
        },
        "nist": 3.555099738276094,
        "bleu": 50.32882,
        "nubia": {
            "semantic_relation": 4.76626,
            "contradiction": 0.22441,
            "irrelevancy": 2.68499,
            "logical_agreement": 97.0906,
            "grammar_ref": 4.62058,
            "grammar_hyp": 4.50532,
            "nubia_score": 0.90622
        },
        "bertscore": {
            "precision": 0.9598,
            "recall": 0.95976,
            "f1": 0.95978
        },
        "meteor": 0.4546337124532775,
        "bleurt": 0.63533
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.64706,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.25,
            "fmeasure": 0.25806
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.35294,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.35294,
            "fmeasure": 0.36364
        },
        "nist": 2.6125318472910277,
        "bleu": 12.72806,
        "nubia": {
            "semantic_relation": 3.51684,
            "contradiction": 59.2848,
            "irrelevancy": 25.18995,
            "logical_agreement": 15.52525,
            "grammar_ref": 4.71038,
            "grammar_hyp": 4.41511,
            "nubia_score": 0.48836
        },
        "bertscore": {
            "precision": 0.90425,
            "recall": 0.89679,
            "f1": 0.9005
        },
        "meteor": 0.27394142879445865,
        "bleurt": 0.01495
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 1.0,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.86349,
            "fmeasure": 0.75223
        },
        "rouge2": {
            "precision": 0.25926,
            "recall": 0.34066,
            "fmeasure": 0.29435
        },
        "rougeL": {
            "precision": 0.40351,
            "recall": 0.52222,
            "fmeasure": 0.45514
        },
        "rougeLsum": {
            "precision": 0.40351,
            "recall": 0.52222,
            "fmeasure": 0.45514
        },
        "nist": 3.6977630594838904,
        "bleu": 14.02578,
        "nubia": {
            "semantic_relation": 3.98779,
            "contradiction": 36.91231,
            "irrelevancy": 30.61447,
            "logical_agreement": 32.47323,
            "grammar_ref": 4.11472,
            "grammar_hyp": 3.13508,
            "nubia_score": 0.78102
        },
        "bertscore": {
            "precision": 0.90093,
            "recall": 0.91262,
            "f1": 0.89588
        },
        "meteor": 0.40459813916792836,
        "bleurt": 0.1692
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "total_length": 1822,
        "mean_pred_length": 28.92063492063492,
        "std_pred_length": 8.521311448552094,
        "median_pred_length": 28.0,
        "min_pred_length": 10,
        "max_pred_length": 48,
        "distinct-1": 0.4796926454445664,
        "vocab_size-1": 874,
        "unique-1": 705,
        "entropy-1": 8.434650194459573,
        "distinct-2": 0.9101762364980103,
        "vocab_size-2": 1601,
        "unique-2": 1528,
        "entropy-2": 10.52102989835569,
        "cond_entropy-2": 1.9491277519954129,
        "distinct-3": 0.9823113207547169,
        "vocab_size-3": 1666,
        "unique-3": 1657,
        "entropy-3": 10.667310792110927,
        "cond_entropy-3": 0.15297259290303938,
        "total_length-nopunct": 1619,
        "mean_pred_length-nopunct": 25.6984126984127,
        "std_pred_length-nopunct": 7.531173142946929,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5342804200123533,
        "vocab_size-1-nopunct": 865,
        "unique-1-nopunct": 703,
        "entropy-1-nopunct": 8.666291217383838,
        "distinct-2-nopunct": 0.9434447300771208,
        "vocab_size-2-nopunct": 1468,
        "unique-2-nopunct": 1414,
        "entropy-2-nopunct": 10.462913642262844,
        "cond_entropy-2-nopunct": 1.8566185155255317,
        "distinct-3-nopunct": 0.9979906229068989,
        "vocab_size-3-nopunct": 1490,
        "unique-3-nopunct": 1487,
        "entropy-3-nopunct": 10.539979695948551,
        "cond_entropy-3-nopunct": 0.08233390383414466,
        "msttr-100": 0.74944,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.0326530612244898,
            "2": 0.2185792349726776,
            "3": 0.5,
            "4": 0.6932515337423313,
            "5": 0.7844311377245509,
            "6": 0.8978494623655914,
            "7": 0.927710843373494,
            "8": 0.9534883720930233,
            "9": 0.9655172413793104,
            "10": 0.9861111111111112
        },
        "rouge1": {
            "precision": 0.89156,
            "recall": 0.92443,
            "fmeasure": 0.90521
        },
        "rouge2": {
            "precision": 0.80206,
            "recall": 0.83718,
            "fmeasure": 0.81634
        },
        "rougeL": {
            "precision": 0.8815,
            "recall": 0.91916,
            "fmeasure": 0.89733
        },
        "rougeLsum": {
            "precision": 0.8815,
            "recall": 0.91916,
            "fmeasure": 0.89733
        },
        "nist": 11.57701864738528,
        "bleu": 87.84605,
        "nubia": {
            "semantic_relation": 4.33867,
            "contradiction": 1.13515,
            "irrelevancy": 42.90621,
            "logical_agreement": 55.95864,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.50101,
            "nubia_score": 0.64578
        },
        "bertscore": {
            "precision": 0.9708,
            "recall": 0.98365,
            "f1": 0.9756
        },
        "meteor": 0.5822739379898311,
        "bleurt": 0.23734
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.56863,
            "recall": 0.80556,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.39583,
            "recall": 0.57576,
            "fmeasure": 0.46914
        },
        "rougeL": {
            "precision": 0.56863,
            "recall": 0.80556,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.56863,
            "recall": 0.80556,
            "fmeasure": 0.66667
        },
        "nist": 2.2752605244252586,
        "bleu": 35.75297,
        "nubia": {
            "semantic_relation": 3.96907,
            "contradiction": 0.39,
            "irrelevancy": 98.44399,
            "logical_agreement": 1.16602,
            "grammar_ref": 5.64121,
            "grammar_hyp": 4.40132,
            "nubia_score": 0.74842
        },
        "bertscore": {
            "precision": 0.85978,
            "recall": 0.93321,
            "f1": 0.89499
        },
        "meteor": 0.4491223499501472,
        "bleurt": -0.07345
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "total_length": 2951,
        "mean_pred_length": 16.95977011494253,
        "std_pred_length": 7.3456212583613905,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.4415452389020671,
        "vocab_size-1": 1303,
        "unique-1": 1016,
        "entropy-1": 8.574501486575329,
        "distinct-2": 0.871083903492978,
        "vocab_size-2": 2419,
        "unique-2": 2279,
        "entropy-2": 11.012844820142393,
        "cond_entropy-2": 2.150469027863229,
        "distinct-3": 0.9708029197080292,
        "vocab_size-3": 2527,
        "unique-3": 2488,
        "entropy-3": 11.263016063117862,
        "cond_entropy-3": 0.2701617426491524,
        "total_length-nopunct": 2601,
        "mean_pred_length-nopunct": 14.948275862068966,
        "std_pred_length-nopunct": 6.390786508698455,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.497116493656286,
        "vocab_size-1-nopunct": 1293,
        "unique-1-nopunct": 1014,
        "entropy-1-nopunct": 8.893049356206177,
        "distinct-2-nopunct": 0.8854552946023898,
        "vocab_size-2-nopunct": 2149,
        "unique-2-nopunct": 2038,
        "entropy-2-nopunct": 10.863390792011279,
        "cond_entropy-2-nopunct": 2.107225596250456,
        "distinct-3-nopunct": 0.9835774522858411,
        "vocab_size-3-nopunct": 2216,
        "unique-3-nopunct": 2186,
        "entropy-3-nopunct": 11.102223503467815,
        "cond_entropy-3-nopunct": 0.26149268153925115,
        "msttr-100": 0.71897,
        "msttr-100_nopunct": 0.76923,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04197271773347324,
            "2": 0.1716171617161716,
            "3": 0.42328042328042326,
            "4": 0.5887096774193549,
            "5": 0.7058823529411765,
            "6": 0.8044776119402985,
            "7": 0.8928270042194093
        },
        "rouge1": {
            "precision": 0.8854,
            "recall": 0.83557,
            "fmeasure": 0.84922
        },
        "rouge2": {
            "precision": 0.75541,
            "recall": 0.71452,
            "fmeasure": 0.72408
        },
        "rougeL": {
            "precision": 0.85453,
            "recall": 0.80974,
            "fmeasure": 0.82085
        },
        "rougeLsum": {
            "precision": 0.85453,
            "recall": 0.80974,
            "fmeasure": 0.82085
        },
        "nist": 10.646595747351752,
        "bleu": 72.92699,
        "nubia": {
            "semantic_relation": 4.41657,
            "contradiction": 4.0854,
            "irrelevancy": 15.02063,
            "logical_agreement": 80.89397,
            "grammar_ref": 4.58509,
            "grammar_hyp": 5.02846,
            "nubia_score": 0.72542
        },
        "bertscore": {
            "precision": 0.96329,
            "recall": 0.95368,
            "f1": 0.95634
        },
        "meteor": 0.4923564700497229,
        "bleurt": 0.2922
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.2857142857142857
        },
        "rouge1": {
            "precision": 0.2,
            "recall": 0.21267,
            "fmeasure": 0.20536
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.2,
            "recall": 0.21267,
            "fmeasure": 0.20536
        },
        "rougeLsum": {
            "precision": 0.2,
            "recall": 0.21267,
            "fmeasure": 0.20536
        },
        "nist": 0.953845820409259,
        "bleu": 3.45859,
        "nubia": {
            "semantic_relation": 1.00568,
            "contradiction": 13.56988,
            "irrelevancy": 85.27418,
            "logical_agreement": 1.15594,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.56858,
            "nubia_score": 0.09515
        },
        "bertscore": {
            "precision": 0.6743,
            "recall": 0.67224,
            "f1": 0.67327
        },
        "meteor": 0.10104728975907513,
        "bleurt": -0.49268
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.8461538461538461
        },
        "rouge1": {
            "precision": 0.96667,
            "recall": 0.8303,
            "fmeasure": 0.88772
        },
        "rouge2": {
            "precision": 0.60714,
            "recall": 0.54286,
            "fmeasure": 0.56933
        },
        "rougeL": {
            "precision": 0.80833,
            "recall": 0.70606,
            "fmeasure": 0.74912
        },
        "rougeLsum": {
            "precision": 0.80833,
            "recall": 0.70606,
            "fmeasure": 0.74912
        },
        "nist": 4.953486450262615,
        "bleu": 62.47441,
        "nubia": {
            "semantic_relation": 4.85244,
            "contradiction": 0.27538,
            "irrelevancy": 0.53369,
            "logical_agreement": 99.19094,
            "grammar_ref": 3.76682,
            "grammar_hyp": 4.11084,
            "nubia_score": 0.96105
        },
        "bertscore": {
            "precision": 0.97595,
            "recall": 0.95553,
            "f1": 0.96557
        },
        "meteor": 0.481390988510715,
        "bleurt": 0.61584
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.3219280948873626,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.97683
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.125,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.40741,
            "recall": 0.65887,
            "fmeasure": 0.48982
        },
        "rouge2": {
            "precision": 0.17647,
            "recall": 0.30556,
            "fmeasure": 0.21714
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.54971,
            "fmeasure": 0.4044
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.54971,
            "fmeasure": 0.4044
        },
        "nist": 2.2473008258863483,
        "bleu": 15.82438,
        "nubia": {
            "semantic_relation": 4.51396,
            "contradiction": 0.07007,
            "irrelevancy": 5.56725,
            "logical_agreement": 94.36269,
            "grammar_ref": 3.44041,
            "grammar_hyp": 3.20092,
            "nubia_score": 0.7756
        },
        "bertscore": {
            "precision": 0.90952,
            "recall": 0.93926,
            "f1": 0.92415
        },
        "meteor": 0.3950781204079888,
        "bleurt": 0.39417
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "nist": 2.4156844010247407,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.64096,
            "contradiction": 0.21793,
            "irrelevancy": 0.49368,
            "logical_agreement": 99.2884,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.3673,
            "nubia_score": 0.85584
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.6432
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "nist": 3.0088906840841796,
        "bleu": 58.33511,
        "nubia": {
            "semantic_relation": 4.98921,
            "contradiction": 0.42473,
            "irrelevancy": 22.33974,
            "logical_agreement": 77.23553,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.79251,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.97213,
            "recall": 0.96481,
            "f1": 0.96846
        },
        "meteor": 0.4630505936482093,
        "bleurt": 0.7528
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.74603,
            "fmeasure": 0.82828
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "nist": 2.1126567718249225,
        "bleu": 84.64817,
        "nubia": {
            "semantic_relation": 3.69006,
            "contradiction": 0.31517,
            "irrelevancy": 0.57051,
            "logical_agreement": 99.11432,
            "grammar_ref": 6.37596,
            "grammar_hyp": 5.64518,
            "nubia_score": 0.75233
        },
        "bertscore": {
            "precision": 0.9793,
            "recall": 0.9326,
            "f1": 0.95538
        },
        "meteor": 0.507208078598044,
        "bleurt": -0.15862
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "rouge1": {
            "precision": 0.28571,
            "recall": 0.26667,
            "fmeasure": 0.27586
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.07143,
            "fmeasure": 0.07407
        },
        "rougeL": {
            "precision": 0.21429,
            "recall": 0.2,
            "fmeasure": 0.2069
        },
        "rougeLsum": {
            "precision": 0.21429,
            "recall": 0.2,
            "fmeasure": 0.2069
        },
        "nist": 1.0600905711694244,
        "bleu": 5.85516,
        "nubia": {
            "semantic_relation": 2.48306,
            "contradiction": 0.21333,
            "irrelevancy": 95.8174,
            "logical_agreement": 3.96927,
            "grammar_ref": 5.48676,
            "grammar_hyp": 5.85039,
            "nubia_score": 0.21353
        },
        "bertscore": {
            "precision": 0.77277,
            "recall": 0.78441,
            "f1": 0.77855
        },
        "meteor": 0.11564440949896566,
        "bleurt": -0.17104
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.69259,
            "fmeasure": 0.71111
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.33613,
            "fmeasure": 0.34562
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.51111,
            "fmeasure": 0.52121
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.51111,
            "fmeasure": 0.52121
        },
        "nist": 3.1479942509933165,
        "bleu": 40.02917,
        "nubia": {
            "semantic_relation": 4.29646,
            "contradiction": 0.16946,
            "irrelevancy": 22.42525,
            "logical_agreement": 77.40529,
            "grammar_ref": 4.4151,
            "grammar_hyp": 5.26246,
            "nubia_score": 0.64251
        },
        "bertscore": {
            "precision": 0.91768,
            "recall": 0.90819,
            "f1": 0.91291
        },
        "meteor": 0.3519741169349362,
        "bleurt": 0.02211
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.75,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "nist": 2.659005565642719,
        "bleu": 32.64971,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.4082,
            "irrelevancy": 0.76883,
            "logical_agreement": 98.82297,
            "grammar_ref": 4.6206,
            "grammar_hyp": 4.37368,
            "nubia_score": 0.96322
        },
        "bertscore": {
            "precision": 0.94619,
            "recall": 0.97387,
            "f1": 0.95983
        },
        "meteor": 0.9051319272478866,
        "bleurt": 0.74939
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.2857142857142857,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.56863,
            "recall": 0.63119,
            "fmeasure": 0.58832
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.47824,
            "fmeasure": 0.43787
        },
        "rougeL": {
            "precision": 0.5098,
            "recall": 0.56526,
            "fmeasure": 0.52718
        },
        "rougeLsum": {
            "precision": 0.5098,
            "recall": 0.56526,
            "fmeasure": 0.52718
        },
        "nist": 3.9225016303677047,
        "bleu": 48.98565,
        "nubia": {
            "semantic_relation": 3.93599,
            "contradiction": 31.67651,
            "irrelevancy": 46.50274,
            "logical_agreement": 21.82075,
            "grammar_ref": 3.56015,
            "grammar_hyp": 3.22893,
            "nubia_score": 0.76764
        },
        "bertscore": {
            "precision": 0.87277,
            "recall": 0.9084,
            "f1": 0.88863
        },
        "meteor": 0.384933287911945,
        "bleurt": -0.13206
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.875,
            "fmeasure": 0.90323
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.49231,
            "fmeasure": 0.48361
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.34226,
            "fmeasure": 0.33741
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.34226,
            "fmeasure": 0.33741
        },
        "nist": 3.9427950465634054,
        "bleu": 29.61517,
        "nubia": {
            "semantic_relation": 4.7494,
            "contradiction": 0.24521,
            "irrelevancy": 33.5672,
            "logical_agreement": 66.18759,
            "grammar_ref": 4.41465,
            "grammar_hyp": 5.01939,
            "nubia_score": 0.82759
        },
        "bertscore": {
            "precision": 0.94698,
            "recall": 0.91733,
            "f1": 0.93192
        },
        "meteor": 0.43170776462300553,
        "bleurt": 0.3074
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.854285871987245,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32615,
            "irrelevancy": 0.47325,
            "logical_agreement": 99.2006,
            "grammar_ref": 5.00662,
            "grammar_hyp": 5.00662,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.94692
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.76923,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.4246,
            "fmeasure": 0.48485
        },
        "rougeL": {
            "precision": 0.75758,
            "recall": 0.57949,
            "fmeasure": 0.65598
        },
        "rougeLsum": {
            "precision": 0.75758,
            "recall": 0.57949,
            "fmeasure": 0.65598
        },
        "nist": 2.8199704929024274,
        "bleu": 24.9928,
        "nubia": {
            "semantic_relation": 4.91939,
            "contradiction": 0.34978,
            "irrelevancy": 0.54329,
            "logical_agreement": 99.10693,
            "grammar_ref": 4.20051,
            "grammar_hyp": 5.32123,
            "nubia_score": 0.8472
        },
        "bertscore": {
            "precision": 0.94753,
            "recall": 0.92289,
            "f1": 0.93505
        },
        "meteor": 0.36317858433577194,
        "bleurt": 0.36646
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.9375
        },
        "rouge1": {
            "precision": 0.92105,
            "recall": 0.875,
            "fmeasure": 0.89744
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.68421,
            "fmeasure": 0.7027
        },
        "rougeL": {
            "precision": 0.71053,
            "recall": 0.675,
            "fmeasure": 0.69231
        },
        "rougeLsum": {
            "precision": 0.71053,
            "recall": 0.675,
            "fmeasure": 0.69231
        },
        "nist": 3.9767865386982915,
        "bleu": 59.00962,
        "nubia": {
            "semantic_relation": 4.87887,
            "contradiction": 0.22901,
            "irrelevancy": 0.47504,
            "logical_agreement": 99.29595,
            "grammar_ref": 4.55046,
            "grammar_hyp": 4.72911,
            "nubia_score": 0.91093
        },
        "bertscore": {
            "precision": 0.94263,
            "recall": 0.95072,
            "f1": 0.94666
        },
        "meteor": 0.47928551418313564,
        "bleurt": 0.3887
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.79545,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.60119,
            "fmeasure": 0.53431
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "nist": 3.4957542283149174,
        "bleu": 44.63236,
        "nubia": {
            "semantic_relation": 2.68132,
            "contradiction": 17.19599,
            "irrelevancy": 81.17821,
            "logical_agreement": 1.62579,
            "grammar_ref": 3.66596,
            "grammar_hyp": 2.66483,
            "nubia_score": 0.47416
        },
        "bertscore": {
            "precision": 0.90491,
            "recall": 0.92394,
            "f1": 0.91433
        },
        "meteor": 0.49043387317825937,
        "bleurt": 0.11895
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.4375,
            "recall": 0.35172,
            "fmeasure": 0.38712
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.30147,
            "fmeasure": 0.33182
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.30147,
            "fmeasure": 0.33182
        },
        "nist": 1.6093361784613909,
        "bleu": 5.91803,
        "nubia": {
            "semantic_relation": 3.82891,
            "contradiction": 4.69072,
            "irrelevancy": 10.79132,
            "logical_agreement": 84.51796,
            "grammar_ref": 4.95035,
            "grammar_hyp": 4.7098,
            "nubia_score": 0.58965
        },
        "bertscore": {
            "precision": 0.84009,
            "recall": 0.87079,
            "f1": 0.8536
        },
        "meteor": 0.1776973041157689,
        "bleurt": -0.00361
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.2857142857142857
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.22222,
            "fmeasure": 0.30769
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.22222,
            "fmeasure": 0.30769
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.22222,
            "fmeasure": 0.30769
        },
        "nist": 0.07244148523266615,
        "bleu": 3.46679,
        "nubia": {
            "semantic_relation": 4.14456,
            "contradiction": 0.27389,
            "irrelevancy": 0.59965,
            "logical_agreement": 99.12646,
            "grammar_ref": 4.6877,
            "grammar_hyp": 7.45749,
            "nubia_score": 0.5439
        },
        "bertscore": {
            "precision": 0.80845,
            "recall": 0.68672,
            "f1": 0.74263
        },
        "meteor": 0.14358974358974358,
        "bleurt": 0.2229
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92063,
            "fmeasure": 0.95495
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.79444,
            "fmeasure": 0.8254
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.69048,
            "fmeasure": 0.71622
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.69048,
            "fmeasure": 0.71622
        },
        "nist": 3.7572430839560402,
        "bleu": 63.55653,
        "nubia": {
            "semantic_relation": 4.15465,
            "contradiction": 0.14855,
            "irrelevancy": 33.53611,
            "logical_agreement": 66.31534,
            "grammar_ref": 3.89472,
            "grammar_hyp": 3.94612,
            "nubia_score": 0.76938
        },
        "bertscore": {
            "precision": 0.98637,
            "recall": 0.98222,
            "f1": 0.98429
        },
        "meteor": 0.539377660435147,
        "bleurt": 0.35221
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "total_length": 1245,
        "mean_pred_length": 21.46551724137931,
        "std_pred_length": 9.032919712117716,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 49,
        "distinct-1": 0.5124497991967871,
        "vocab_size-1": 638,
        "unique-1": 521,
        "entropy-1": 8.107420545097147,
        "distinct-2": 0.9258635214827295,
        "vocab_size-2": 1099,
        "unique-2": 1052,
        "entropy-2": 10.018058920747526,
        "cond_entropy-2": 1.7237146603579785,
        "distinct-3": 0.9849424269264836,
        "vocab_size-3": 1112,
        "unique-3": 1103,
        "entropy-3": 10.10095417289123,
        "cond_entropy-3": 0.09291529407076039,
        "total_length-nopunct": 1121,
        "mean_pred_length-nopunct": 19.32758620689655,
        "std_pred_length-nopunct": 8.303277149113004,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.5619982158786797,
        "vocab_size-1-nopunct": 630,
        "unique-1-nopunct": 519,
        "entropy-1-nopunct": 8.28413179732369,
        "distinct-2-nopunct": 0.9426152398871119,
        "vocab_size-2-nopunct": 1002,
        "unique-2-nopunct": 962,
        "entropy-2-nopunct": 9.911806128178647,
        "cond_entropy-2-nopunct": 1.7177698344327488,
        "distinct-3-nopunct": 0.9940298507462687,
        "vocab_size-3-nopunct": 999,
        "unique-3-nopunct": 993,
        "entropy-3-nopunct": 9.961039487558903,
        "cond_entropy-3-nopunct": 0.057435295394553665,
        "msttr-100": 0.72917,
        "msttr-100_nopunct": 0.77455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04337631887456037,
            "2": 0.176056338028169,
            "3": 0.37662337662337664,
            "4": 0.5769230769230769,
            "5": 0.6871508379888268,
            "6": 0.8387096774193549,
            "7": 0.8967136150234741
        },
        "rouge1": {
            "precision": 0.85367,
            "recall": 0.80815,
            "fmeasure": 0.82513
        },
        "rouge2": {
            "precision": 0.72981,
            "recall": 0.69359,
            "fmeasure": 0.70596
        },
        "rougeL": {
            "precision": 0.83864,
            "recall": 0.79685,
            "fmeasure": 0.81214
        },
        "rougeLsum": {
            "precision": 0.83864,
            "recall": 0.79685,
            "fmeasure": 0.81214
        },
        "nist": 9.634277284325606,
        "bleu": 71.08745,
        "nubia": {
            "semantic_relation": 4.41479,
            "contradiction": 4.99716,
            "irrelevancy": 17.0529,
            "logical_agreement": 77.94994,
            "grammar_ref": 4.54049,
            "grammar_hyp": 4.81161,
            "nubia_score": 0.74368
        },
        "bertscore": {
            "precision": 0.95604,
            "recall": 0.95159,
            "f1": 0.95208
        },
        "meteor": 0.48025441088032744,
        "bleurt": 0.22874
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.8465578035643277,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.69325,
            "irrelevancy": 0.54497,
            "logical_agreement": 98.76179,
            "grammar_ref": 7.00423,
            "grammar_hyp": 7.45225,
            "nubia_score": 0.93405
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.87565
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6842105263157895
        },
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.68527,
            "fmeasure": 0.65801
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.43468,
            "fmeasure": 0.41515
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.68527,
            "fmeasure": 0.65801
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.68527,
            "fmeasure": 0.65801
        },
        "nist": 3.030090311001858,
        "bleu": 21.22554,
        "nubia": {
            "semantic_relation": 4.36086,
            "contradiction": 25.68519,
            "irrelevancy": 20.86202,
            "logical_agreement": 53.45279,
            "grammar_ref": 6.17452,
            "grammar_hyp": 5.92787,
            "nubia_score": 0.73898
        },
        "bertscore": {
            "precision": 0.90505,
            "recall": 0.91826,
            "f1": 0.91027
        },
        "meteor": 0.32460139624744194,
        "bleurt": 0.24935
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "total_length": 501,
        "mean_pred_length": 22.772727272727273,
        "std_pred_length": 9.746476371124723,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 41,
        "distinct-1": 0.5848303393213573,
        "vocab_size-1": 293,
        "unique-1": 240,
        "entropy-1": 7.389510147848456,
        "distinct-2": 0.9331941544885177,
        "vocab_size-2": 447,
        "unique-2": 427,
        "entropy-2": 8.73993753464436,
        "cond_entropy-2": 1.212373673187832,
        "distinct-3": 0.9890590809628009,
        "vocab_size-3": 452,
        "unique-3": 447,
        "entropy-3": 8.814168516983706,
        "cond_entropy-3": 0.082123268650076,
        "total_length-nopunct": 446,
        "mean_pred_length-nopunct": 20.272727272727273,
        "std_pred_length-nopunct": 8.587421129354992,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6434977578475336,
        "vocab_size-1-nopunct": 287,
        "unique-1-nopunct": 240,
        "entropy-1-nopunct": 7.510832773420997,
        "distinct-2-nopunct": 0.9363207547169812,
        "vocab_size-2-nopunct": 397,
        "unique-2-nopunct": 381,
        "entropy-2-nopunct": 8.56807508307548,
        "cond_entropy-2-nopunct": 1.1133661640937629,
        "distinct-3-nopunct": 0.9925373134328358,
        "vocab_size-3-nopunct": 399,
        "unique-3-nopunct": 396,
        "entropy-3-nopunct": 8.636126318044552,
        "cond_entropy-3-nopunct": 0.07431142942870733,
        "msttr-100": 0.728,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.02666666666666667,
            "2": 0.1694915254237288,
            "3": 0.5625,
            "4": 0.5306122448979592,
            "5": 0.7297297297297297,
            "6": 0.797979797979798,
            "7": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.86605,
            "recall": 0.83166,
            "fmeasure": 0.83621
        },
        "rouge2": {
            "precision": 0.72668,
            "recall": 0.70405,
            "fmeasure": 0.70591
        },
        "rougeL": {
            "precision": 0.84262,
            "recall": 0.81197,
            "fmeasure": 0.81485
        },
        "rougeLsum": {
            "precision": 0.84262,
            "recall": 0.81197,
            "fmeasure": 0.81485
        },
        "nist": 8.77267209002988,
        "bleu": 75.14765,
        "nubia": {
            "semantic_relation": 4.43231,
            "contradiction": 2.45189,
            "irrelevancy": 14.09281,
            "logical_agreement": 83.4553,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.83852,
            "nubia_score": 0.74003
        },
        "bertscore": {
            "precision": 0.96265,
            "recall": 0.95566,
            "f1": 0.95699
        },
        "meteor": 0.4852034703106639,
        "bleurt": 0.30291
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.69841,
            "fmeasure": 0.68132
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.37778,
            "fmeasure": 0.35354
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.69841,
            "fmeasure": 0.68132
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.69841,
            "fmeasure": 0.68132
        },
        "nist": 1.7597043473957215,
        "bleu": 27.77619,
        "nubia": {
            "semantic_relation": 3.13035,
            "contradiction": 52.0515,
            "irrelevancy": 21.36661,
            "logical_agreement": 26.58189,
            "grammar_ref": 6.44614,
            "grammar_hyp": 6.8527,
            "nubia_score": 0.30241
        },
        "bertscore": {
            "precision": 0.91483,
            "recall": 0.92157,
            "f1": 0.91621
        },
        "meteor": 0.2965287659086432,
        "bleurt": -0.67842
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.76923,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.5,
            "fmeasure": 0.52174
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.76923,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.76923,
            "fmeasure": 0.8
        },
        "nist": 2.102818394333117,
        "bleu": 22.82547,
        "nubia": {
            "semantic_relation": 4.31256,
            "contradiction": 0.09449,
            "irrelevancy": 1.57396,
            "logical_agreement": 98.33155,
            "grammar_ref": 3.76485,
            "grammar_hyp": 3.48444,
            "nubia_score": 0.95474
        },
        "bertscore": {
            "precision": 0.94177,
            "recall": 0.95407,
            "f1": 0.94788
        },
        "meteor": 0.44244997683677156,
        "bleurt": 0.34038
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.5303,
            "recall": 0.5627,
            "fmeasure": 0.54596
        },
        "rouge2": {
            "precision": 0.26984,
            "recall": 0.28772,
            "fmeasure": 0.27846
        },
        "rougeL": {
            "precision": 0.30303,
            "recall": 0.32222,
            "fmeasure": 0.31229
        },
        "rougeLsum": {
            "precision": 0.30303,
            "recall": 0.32222,
            "fmeasure": 0.31229
        },
        "nist": 3.4516909335500774,
        "bleu": 28.20005,
        "nubia": {
            "semantic_relation": 3.51097,
            "contradiction": 5.96992,
            "irrelevancy": 71.96968,
            "logical_agreement": 22.0604,
            "grammar_ref": 5.50536,
            "grammar_hyp": 4.41423,
            "nubia_score": 0.59587
        },
        "bertscore": {
            "precision": 0.85167,
            "recall": 0.87615,
            "f1": 0.86278
        },
        "meteor": 0.3193916187455391,
        "bleurt": -0.17643
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 9.899494936611665,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 34,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 52,
        "unique-1": 45,
        "entropy-1": 5.627642470572459,
        "distinct-2": 0.9824561403508771,
        "vocab_size-2": 56,
        "unique-2": 55,
        "entropy-2": 5.797802294866491,
        "cond_entropy-2": 0.10143801504745138,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": -0.04096547496423607,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 8.956685895029603,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.599541531706474,
        "distinct-2-nopunct": 0.9807692307692307,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.661978179679557,
        "cond_entropy-2-nopunct": 0.053695389231817145,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.044913547495271544,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.02564102564102564,
            "2": 0.3333333333333333,
            "3": 0.25,
            "4": 0.7142857142857143,
            "5": 0.6666666666666666,
            "6": 0.8571428571428571,
            "7": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.8331,
            "recall": 0.80055,
            "fmeasure": 0.81115
        },
        "rouge2": {
            "precision": 0.59894,
            "recall": 0.57633,
            "fmeasure": 0.58275
        },
        "rougeL": {
            "precision": 0.7331,
            "recall": 0.71073,
            "fmeasure": 0.71653
        },
        "rougeLsum": {
            "precision": 0.7331,
            "recall": 0.71073,
            "fmeasure": 0.71653
        },
        "nist": 6.053896167593934,
        "bleu": 62.07006,
        "nubia": {
            "semantic_relation": 4.77243,
            "contradiction": 0.25676,
            "irrelevancy": 17.25748,
            "logical_agreement": 82.48575,
            "grammar_ref": 4.54431,
            "grammar_hyp": 4.93574,
            "nubia_score": 0.84182
        },
        "bertscore": {
            "precision": 0.94924,
            "recall": 0.95155,
            "f1": 0.9493
        },
        "meteor": 0.4995612734248125,
        "bleurt": 0.43745
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.1,
            "3": 0.45454545454545453
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.34921,
            "fmeasure": 0.34109
        },
        "rouge2": {
            "precision": 0.09524,
            "recall": 0.1,
            "fmeasure": 0.09756
        },
        "rougeL": {
            "precision": 0.30303,
            "recall": 0.31746,
            "fmeasure": 0.31008
        },
        "rougeLsum": {
            "precision": 0.30303,
            "recall": 0.31746,
            "fmeasure": 0.31008
        },
        "nist": 1.8528937378213481,
        "bleu": 5.70421,
        "nubia": {
            "semantic_relation": 3.31588,
            "contradiction": 59.24646,
            "irrelevancy": 36.25917,
            "logical_agreement": 4.49437,
            "grammar_ref": 3.9898,
            "grammar_hyp": 4.31524,
            "nubia_score": 0.43463
        },
        "bertscore": {
            "precision": 0.83725,
            "recall": 0.82996,
            "f1": 0.83359
        },
        "meteor": 0.23205703488082613,
        "bleurt": -0.16915
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "total_length": 738,
        "mean_pred_length": 24.6,
        "std_pred_length": 10.71634265969505,
        "median_pred_length": 23.0,
        "min_pred_length": 6,
        "max_pred_length": 52,
        "distinct-1": 0.5271002710027101,
        "vocab_size-1": 389,
        "unique-1": 312,
        "entropy-1": 7.692894328342547,
        "distinct-2": 0.9096045197740112,
        "vocab_size-2": 644,
        "unique-2": 598,
        "entropy-2": 9.263645623538075,
        "cond_entropy-2": 1.4347423358037696,
        "distinct-3": 0.976401179941003,
        "vocab_size-3": 662,
        "unique-3": 648,
        "entropy-3": 9.355717016227235,
        "cond_entropy-3": 0.09814631569284593,
        "total_length-nopunct": 655,
        "mean_pred_length-nopunct": 21.833333333333332,
        "std_pred_length-nopunct": 9.462499082636091,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.583206106870229,
        "vocab_size-1-nopunct": 382,
        "unique-1-nopunct": 312,
        "entropy-1-nopunct": 7.819876588728819,
        "distinct-2-nopunct": 0.9248,
        "vocab_size-2-nopunct": 578,
        "unique-2-nopunct": 543,
        "entropy-2-nopunct": 9.119097854773036,
        "cond_entropy-2-nopunct": 1.3609370774595626,
        "distinct-3-nopunct": 0.9831932773109243,
        "vocab_size-3-nopunct": 585,
        "unique-3-nopunct": 575,
        "entropy-3-nopunct": 9.18313241281715,
        "cond_entropy-3-nopunct": 0.07085545845300652,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.76333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.05656108597285068,
            "2": 0.16049382716049382,
            "3": 0.4067796610169492,
            "4": 0.4492753623188406,
            "5": 0.6413043478260869,
            "6": 0.7922077922077922,
            "7": 0.9041095890410958
        },
        "rouge1": {
            "precision": 0.76946,
            "recall": 0.75807,
            "fmeasure": 0.7524
        },
        "rouge2": {
            "precision": 0.6028,
            "recall": 0.58473,
            "fmeasure": 0.58189
        },
        "rougeL": {
            "precision": 0.73906,
            "recall": 0.7236,
            "fmeasure": 0.71909
        },
        "rougeLsum": {
            "precision": 0.73906,
            "recall": 0.7236,
            "fmeasure": 0.71909
        },
        "nist": 8.23014835429964,
        "bleu": 60.34195,
        "nubia": {
            "semantic_relation": 4.25263,
            "contradiction": 2.07536,
            "irrelevancy": 21.61952,
            "logical_agreement": 76.30513,
            "grammar_ref": 4.65355,
            "grammar_hyp": 4.95503,
            "nubia_score": 0.67319
        },
        "bertscore": {
            "precision": 0.93969,
            "recall": 0.942,
            "f1": 0.93798
        },
        "meteor": 0.4504717153901906,
        "bleurt": 0.0965
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "total_length": 265,
        "mean_pred_length": 29.444444444444443,
        "std_pred_length": 22.276600135124905,
        "median_pred_length": 22.0,
        "min_pred_length": 13,
        "max_pred_length": 90,
        "distinct-1": 0.47547169811320755,
        "vocab_size-1": 126,
        "unique-1": 95,
        "entropy-1": 6.0958545954701915,
        "distinct-2": 0.6640625,
        "vocab_size-2": 170,
        "unique-2": 151,
        "entropy-2": 6.841076941674211,
        "cond_entropy-2": 0.6940914580662151,
        "distinct-3": 0.708502024291498,
        "vocab_size-3": 175,
        "unique-3": 159,
        "entropy-3": 6.985183718050536,
        "cond_entropy-3": 0.17418899307644992,
        "total_length-nopunct": 221,
        "mean_pred_length-nopunct": 24.555555555555557,
        "std_pred_length-nopunct": 17.10172902961771,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.5384615384615384,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.10461654528688,
        "distinct-2-nopunct": 0.7028301886792453,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 136,
        "entropy-2-nopunct": 6.716507056332493,
        "cond_entropy-2-nopunct": 0.6644828418330503,
        "distinct-3-nopunct": 0.7487684729064039,
        "vocab_size-3-nopunct": 152,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 6.875205115024554,
        "cond_entropy-3-nopunct": 0.18876072166781108,
        "msttr-100": 0.515,
        "msttr-100_nopunct": 0.555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.05185185185185185,
            "2": 0.13636363636363635,
            "3": 0.0,
            "4": 0.6,
            "5": 0.4117647058823529,
            "6": 0.62,
            "7": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.70342,
            "recall": 0.7034,
            "fmeasure": 0.69856
        },
        "rouge2": {
            "precision": 0.54906,
            "recall": 0.54305,
            "fmeasure": 0.5411
        },
        "rougeL": {
            "precision": 0.6704,
            "recall": 0.64452,
            "fmeasure": 0.65014
        },
        "rougeLsum": {
            "precision": 0.6704,
            "recall": 0.64452,
            "fmeasure": 0.65014
        },
        "nist": 4.547093754556303,
        "bleu": 35.7739,
        "nubia": {
            "semantic_relation": 3.9621,
            "contradiction": 6.45591,
            "irrelevancy": 29.51301,
            "logical_agreement": 64.03108,
            "grammar_ref": 4.59683,
            "grammar_hyp": 4.68082,
            "nubia_score": 0.53127
        },
        "bertscore": {
            "precision": 0.89424,
            "recall": 0.89791,
            "f1": 0.89372
        },
        "meteor": 0.3681387106270613,
        "bleurt": -0.0893
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.5,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "nist": 1.5,
        "bleu": 10.60031,
        "nubia": {
            "semantic_relation": 4.7181,
            "contradiction": 0.18101,
            "irrelevancy": 42.50259,
            "logical_agreement": 57.31642,
            "grammar_ref": 5.74517,
            "grammar_hyp": 3.91475,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 0.88921,
            "recall": 0.94805,
            "f1": 0.91769
        },
        "meteor": 0.44519131687853003,
        "bleurt": 0.68944
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "total_length": 1732,
        "mean_pred_length": 27.49206349206349,
        "std_pred_length": 8.15888456403828,
        "median_pred_length": 28.0,
        "min_pred_length": 6,
        "max_pred_length": 52,
        "distinct-1": 0.4630484988452656,
        "vocab_size-1": 802,
        "unique-1": 623,
        "entropy-1": 8.34790712846283,
        "distinct-2": 0.8969442780107849,
        "vocab_size-2": 1497,
        "unique-2": 1416,
        "entropy-2": 10.390440859764391,
        "cond_entropy-2": 1.894205009464322,
        "distinct-3": 0.9694894146948941,
        "vocab_size-3": 1557,
        "unique-3": 1543,
        "entropy-3": 10.534855840950422,
        "cond_entropy-3": 0.15363205772036487,
        "total_length-nopunct": 1541,
        "mean_pred_length-nopunct": 24.46031746031746,
        "std_pred_length-nopunct": 7.468081066770357,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.5146009085009734,
        "vocab_size-1-nopunct": 793,
        "unique-1-nopunct": 621,
        "entropy-1-nopunct": 8.562485578779821,
        "distinct-2-nopunct": 0.9330175913396481,
        "vocab_size-2-nopunct": 1379,
        "unique-2-nopunct": 1313,
        "entropy-2-nopunct": 10.364060529476124,
        "cond_entropy-2-nopunct": 1.8649746814038237,
        "distinct-3-nopunct": 0.995053003533569,
        "vocab_size-3-nopunct": 1408,
        "unique-3-nopunct": 1401,
        "entropy-3-nopunct": 10.456692344786243,
        "cond_entropy-3-nopunct": 0.09675432347523757,
        "msttr-100": 0.73941,
        "msttr-100_nopunct": 0.78133,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.048216007714561235,
            "2": 0.19254658385093168,
            "3": 0.425531914893617,
            "4": 0.582089552238806,
            "5": 0.7137254901960784,
            "6": 0.7556675062972292,
            "7": 0.8773584905660378
        },
        "rouge1": {
            "precision": 0.79254,
            "recall": 0.78748,
            "fmeasure": 0.78203
        },
        "rouge2": {
            "precision": 0.65239,
            "recall": 0.65303,
            "fmeasure": 0.6447
        },
        "rougeL": {
            "precision": 0.76922,
            "recall": 0.76792,
            "fmeasure": 0.75966
        },
        "rougeLsum": {
            "precision": 0.76922,
            "recall": 0.76792,
            "fmeasure": 0.75966
        },
        "nist": 9.048609769036194,
        "bleu": 62.53005,
        "nubia": {
            "semantic_relation": 4.25965,
            "contradiction": 5.01711,
            "irrelevancy": 22.47329,
            "logical_agreement": 72.50959,
            "grammar_ref": 4.43738,
            "grammar_hyp": 4.82957,
            "nubia_score": 0.66881
        },
        "bertscore": {
            "precision": 0.93756,
            "recall": 0.94373,
            "f1": 0.93842
        },
        "meteor": 0.4506645112787029,
        "bleurt": 0.14592
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.9,
            "recall": 0.63426,
            "fmeasure": 0.73909
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.40963,
            "fmeasure": 0.48077
        },
        "rougeL": {
            "precision": 0.85,
            "recall": 0.60417,
            "fmeasure": 0.70155
        },
        "rougeLsum": {
            "precision": 0.85,
            "recall": 0.60417,
            "fmeasure": 0.70155
        },
        "nist": 2.0297955880268317,
        "bleu": 22.97812,
        "nubia": {
            "semantic_relation": 4.82058,
            "contradiction": 0.68344,
            "irrelevancy": 2.18573,
            "logical_agreement": 97.13083,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.22931,
            "nubia_score": 0.96211
        },
        "bertscore": {
            "precision": 0.94274,
            "recall": 0.90123,
            "f1": 0.92123
        },
        "meteor": 0.3685126369576308,
        "bleurt": 0.46728
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9565217391304348
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.725958657424895,
        "bleu": 88.23314,
        "nubia": {
            "semantic_relation": 4.59491,
            "contradiction": 0.51227,
            "irrelevancy": 10.44657,
            "logical_agreement": 89.04116,
            "grammar_ref": 4.1188,
            "grammar_hyp": 4.00862,
            "nubia_score": 0.9067
        },
        "bertscore": {
            "precision": 0.99215,
            "recall": 0.94723,
            "f1": 0.96862
        },
        "meteor": 0.5463176402057991,
        "bleurt": 0.56181
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.59091,
            "recall": 0.43333,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.07143,
            "fmeasure": 0.08333
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.3,
            "fmeasure": 0.34615
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.3,
            "fmeasure": 0.34615
        },
        "nist": 2.066689308560068,
        "bleu": 6.963,
        "nubia": {
            "semantic_relation": 3.58205,
            "contradiction": 10.82816,
            "irrelevancy": 40.45264,
            "logical_agreement": 48.7192,
            "grammar_ref": 5.62728,
            "grammar_hyp": 6.13521,
            "nubia_score": 0.4125
        },
        "bertscore": {
            "precision": 0.877,
            "recall": 0.87867,
            "f1": 0.87783
        },
        "meteor": 0.2838462258033557,
        "bleurt": -0.71184
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.36364,
            "recall": 0.37607,
            "fmeasure": 0.36667
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.10417,
            "fmeasure": 0.10101
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.37607,
            "fmeasure": 0.36667
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.37607,
            "fmeasure": 0.36667
        },
        "nist": 1.517587931023639,
        "bleu": 8.51659,
        "nubia": {
            "semantic_relation": 1.98656,
            "contradiction": 0.355,
            "irrelevancy": 98.82785,
            "logical_agreement": 0.81714,
            "grammar_ref": 4.60771,
            "grammar_hyp": 5.37183,
            "nubia_score": 0.12732
        },
        "bertscore": {
            "precision": 0.76058,
            "recall": 0.78227,
            "f1": 0.7699
        },
        "meteor": 0.13378114353730247,
        "bleurt": -0.49283
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "mT5_base/totto_test",
        "N": 111,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1393939393939394,
            "2": 0.4148148148148148,
            "3": 0.7685554668794893
        },
        "rouge1": {
            "precision": 0.79242,
            "recall": 0.7304,
            "fmeasure": 0.74924
        },
        "rouge2": {
            "precision": 0.58022,
            "recall": 0.53129,
            "fmeasure": 0.5472
        },
        "rougeL": {
            "precision": 0.69756,
            "recall": 0.64237,
            "fmeasure": 0.65929
        },
        "rougeLsum": {
            "precision": 0.69756,
            "recall": 0.64237,
            "fmeasure": 0.65929
        },
        "nist": 7.420102931200358,
        "bleu": 50.8911,
        "nubia": {
            "semantic_relation": 4.19385,
            "contradiction": 10.12606,
            "irrelevancy": 17.44262,
            "logical_agreement": 72.43132,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.58324,
            "nubia_score": 0.73345
        },
        "bertscore": {
            "precision": 0.93811,
            "recall": 0.92874,
            "f1": 0.93195
        },
        "meteor": 0.40521956777379103,
        "bleurt": 0.37676
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "nist": 1.3934338964335204,
        "bleu": 28.6419,
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.30154,
            "irrelevancy": 0.49604,
            "logical_agreement": 99.20242,
            "grammar_ref": 5.72796,
            "grammar_hyp": 7.07513,
            "nubia_score": 0.79132
        },
        "bertscore": {
            "precision": 0.97397,
            "recall": 0.93815,
            "f1": 0.95573
        },
        "meteor": 0.4307001776843669,
        "bleurt": 0.82527
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.59524,
            "recall": 0.6713,
            "fmeasure": 0.59878
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.36957,
            "fmeasure": 0.38624
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.64815,
            "fmeasure": 0.55163
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.64815,
            "fmeasure": 0.55163
        },
        "nist": 3.7253123887180073,
        "bleu": 48.11256,
        "nubia": {
            "semantic_relation": 3.7669,
            "contradiction": 0.22606,
            "irrelevancy": 97.08829,
            "logical_agreement": 2.68565,
            "grammar_ref": 4.62828,
            "grammar_hyp": 4.55703,
            "nubia_score": 0.57435
        },
        "bertscore": {
            "precision": 0.91746,
            "recall": 0.93418,
            "f1": 0.87762
        },
        "meteor": 0.36863596446896896,
        "bleurt": -0.05932
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.36364,
            "recall": 0.38182,
            "fmeasure": 0.37229
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.21111,
            "fmeasure": 0.20526
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.38182,
            "fmeasure": 0.37229
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.38182,
            "fmeasure": 0.37229
        },
        "nist": 1.4681508150237554,
        "bleu": 10.12799,
        "nubia": {
            "semantic_relation": 3.38613,
            "contradiction": 84.74841,
            "irrelevancy": 8.28866,
            "logical_agreement": 6.96293,
            "grammar_ref": 4.7527,
            "grammar_hyp": 4.41687,
            "nubia_score": 0.42424
        },
        "bertscore": {
            "precision": 0.85093,
            "recall": 0.8549,
            "f1": 0.85291
        },
        "meteor": 0.2725173614306475,
        "bleurt": 0.37422
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rouge2": {
            "precision": 0.79464,
            "recall": 0.72685,
            "fmeasure": 0.75776
        },
        "rougeL": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rougeLsum": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "nist": 4.451815875634701,
        "bleu": 69.05636,
        "nubia": {
            "semantic_relation": 4.99611,
            "contradiction": 0.40178,
            "irrelevancy": 0.5141,
            "logical_agreement": 99.08412,
            "grammar_ref": 4.85767,
            "grammar_hyp": 5.20195,
            "nubia_score": 0.97201
        },
        "bertscore": {
            "precision": 0.98549,
            "recall": 0.97733,
            "f1": 0.98137
        },
        "meteor": 0.9489775258149422,
        "bleurt": 0.78257
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.5,
            "fmeasure": 0.52174
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.36364,
            "fmeasure": 0.38095
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.5,
            "fmeasure": 0.52174
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.5,
            "fmeasure": 0.52174
        },
        "nist": 2.0802215064466125,
        "bleu": 31.72722,
        "nubia": {
            "semantic_relation": 3.8852,
            "contradiction": 4.75345,
            "irrelevancy": 80.78575,
            "logical_agreement": 14.4608,
            "grammar_ref": 4.44512,
            "grammar_hyp": 4.59247,
            "nubia_score": 0.56843
        },
        "bertscore": {
            "precision": 0.88956,
            "recall": 0.88248,
            "f1": 0.88427
        },
        "meteor": 0.3112821930463293,
        "bleurt": -0.2438
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.61275,
            "fmeasure": 0.56614
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.19583,
            "fmeasure": 0.18004
        },
        "rougeL": {
            "precision": 0.31579,
            "recall": 0.36765,
            "fmeasure": 0.33968
        },
        "rougeLsum": {
            "precision": 0.31579,
            "recall": 0.36765,
            "fmeasure": 0.33968
        },
        "nist": 2.7591911318728655,
        "bleu": 8.20181,
        "nubia": {
            "semantic_relation": 4.06358,
            "contradiction": 0.10401,
            "irrelevancy": 1.38807,
            "logical_agreement": 98.50792,
            "grammar_ref": 5.85115,
            "grammar_hyp": 4.68539,
            "nubia_score": 0.83237
        },
        "bertscore": {
            "precision": 0.88477,
            "recall": 0.8781,
            "f1": 0.88142
        },
        "meteor": 0.3000627765256596,
        "bleurt": 0.11458
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.81481,
            "fmeasure": 0.77193
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "nist": 3.6961650890339652,
        "bleu": 76.11606,
        "nubia": {
            "semantic_relation": 4.94183,
            "contradiction": 0.26546,
            "irrelevancy": 2.07729,
            "logical_agreement": 97.65725,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.255,
            "nubia_score": 0.96846
        },
        "bertscore": {
            "precision": 0.97599,
            "recall": 0.99403,
            "f1": 0.98493
        },
        "meteor": 0.5715186082473627,
        "bleurt": 0.74566
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.72549,
            "recall": 0.82633,
            "fmeasure": 0.77103
        },
        "rouge2": {
            "precision": 0.5625,
            "recall": 0.64904,
            "fmeasure": 0.60129
        },
        "rougeL": {
            "precision": 0.72549,
            "recall": 0.82633,
            "fmeasure": 0.77103
        },
        "rougeLsum": {
            "precision": 0.72549,
            "recall": 0.82633,
            "fmeasure": 0.77103
        },
        "nist": 3.2116356821236627,
        "bleu": 48.06604,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.45509,
            "irrelevancy": 0.47361,
            "logical_agreement": 99.0713,
            "grammar_ref": 5.90677,
            "grammar_hyp": 5.57869,
            "nubia_score": 0.9631
        },
        "bertscore": {
            "precision": 0.9577,
            "recall": 0.98427,
            "f1": 0.968
        },
        "meteor": 0.48298572499265624,
        "bleurt": 0.63267
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.5333333333333333
        },
        "rouge1": {
            "precision": 0.42172,
            "recall": 0.50926,
            "fmeasure": 0.46032
        },
        "rouge2": {
            "precision": 0.14545,
            "recall": 0.16319,
            "fmeasure": 0.1527
        },
        "rougeL": {
            "precision": 0.38005,
            "recall": 0.4537,
            "fmeasure": 0.4127
        },
        "rougeLsum": {
            "precision": 0.38005,
            "recall": 0.4537,
            "fmeasure": 0.4127
        },
        "nist": 1.9999415446899682,
        "bleu": 6.9973,
        "nubia": {
            "semantic_relation": 3.83578,
            "contradiction": 33.2116,
            "irrelevancy": 49.55236,
            "logical_agreement": 17.23604,
            "grammar_ref": 5.12311,
            "grammar_hyp": 4.44968,
            "nubia_score": 0.57474
        },
        "bertscore": {
            "precision": 0.83004,
            "recall": 0.82729,
            "f1": 0.82852
        },
        "meteor": 0.21051200597936792,
        "bleurt": 0.04074
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6296296296296297
        },
        "rouge1": {
            "precision": 0.84192,
            "recall": 0.70203,
            "fmeasure": 0.74757
        },
        "rouge2": {
            "precision": 0.65644,
            "recall": 0.56852,
            "fmeasure": 0.59611
        },
        "rougeL": {
            "precision": 0.84192,
            "recall": 0.70203,
            "fmeasure": 0.74757
        },
        "rougeLsum": {
            "precision": 0.84192,
            "recall": 0.70203,
            "fmeasure": 0.74757
        },
        "nist": 2.601576231601971,
        "bleu": 42.42009,
        "nubia": {
            "semantic_relation": 3.8183,
            "contradiction": 79.25645,
            "irrelevancy": 16.74064,
            "logical_agreement": 4.00291,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.4923,
            "nubia_score": 0.53516
        },
        "bertscore": {
            "precision": 0.96528,
            "recall": 0.90887,
            "f1": 0.93431
        },
        "meteor": 0.4491197324159756,
        "bleurt": 0.32949
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 1.0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.85897,
            "recall": 0.89404,
            "fmeasure": 0.8753
        },
        "rouge2": {
            "precision": 0.68056,
            "recall": 0.74899,
            "fmeasure": 0.7119
        },
        "rougeL": {
            "precision": 0.78205,
            "recall": 0.81245,
            "fmeasure": 0.79624
        },
        "rougeLsum": {
            "precision": 0.78205,
            "recall": 0.81245,
            "fmeasure": 0.79624
        },
        "nist": 4.237199714637244,
        "bleu": 53.24222,
        "nubia": {
            "semantic_relation": 4.29234,
            "contradiction": 16.49835,
            "irrelevancy": 61.79404,
            "logical_agreement": 21.70761,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.6143,
            "nubia_score": 0.64816
        },
        "bertscore": {
            "precision": 0.90199,
            "recall": 0.96801,
            "f1": 0.93205
        },
        "meteor": 0.4759886149142972,
        "bleurt": -0.08946
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "nist": 2.9991662387674958,
        "bleu": 54.45179,
        "nubia": {
            "semantic_relation": 4.29853,
            "contradiction": 10.83902,
            "irrelevancy": 85.02242,
            "logical_agreement": 4.13857,
            "grammar_ref": 4.85772,
            "grammar_hyp": 5.23792,
            "nubia_score": 0.56981
        },
        "bertscore": {
            "precision": 0.97343,
            "recall": 0.97664,
            "f1": 0.97503
        },
        "meteor": 0.5777337135978416,
        "bleurt": 0.49208
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 1.0,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.85185,
            "recall": 0.94444,
            "fmeasure": 0.88889
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94118
        },
        "nist": 3.276287077976025,
        "bleu": 58.77284,
        "nubia": {
            "semantic_relation": 4.86235,
            "contradiction": 0.89405,
            "irrelevancy": 60.76008,
            "logical_agreement": 38.34587,
            "grammar_ref": 6.57473,
            "grammar_hyp": 5.18446,
            "nubia_score": 0.99266
        },
        "bertscore": {
            "precision": 0.99179,
            "recall": 0.95164,
            "f1": 0.9713
        },
        "meteor": 0.5054764086193895,
        "bleurt": 0.4663
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.66667,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42857
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.66667,
            "fmeasure": 0.75
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.66667,
            "fmeasure": 0.75
        },
        "nist": 2.8045330046640538,
        "bleu": 34.66668,
        "nubia": {
            "semantic_relation": 4.82331,
            "contradiction": 0.93144,
            "irrelevancy": 0.65741,
            "logical_agreement": 98.41114,
            "grammar_ref": 5.69157,
            "grammar_hyp": 6.14878,
            "nubia_score": 0.83549
        },
        "bertscore": {
            "precision": 0.95557,
            "recall": 0.92279,
            "f1": 0.9389
        },
        "meteor": 0.47818878613286225,
        "bleurt": 0.66772
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.78,
            "fmeasure": 0.81978
        },
        "rouge2": {
            "precision": 0.65556,
            "recall": 0.61802,
            "fmeasure": 0.63408
        },
        "rougeL": {
            "precision": 0.73958,
            "recall": 0.68406,
            "fmeasure": 0.70798
        },
        "rougeLsum": {
            "precision": 0.73958,
            "recall": 0.68406,
            "fmeasure": 0.70798
        },
        "nist": 3.816128355232186,
        "bleu": 51.13158,
        "nubia": {
            "semantic_relation": 4.62646,
            "contradiction": 32.03934,
            "irrelevancy": 2.76159,
            "logical_agreement": 65.19908,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.60037,
            "nubia_score": 0.8327
        },
        "bertscore": {
            "precision": 0.951,
            "recall": 0.94281,
            "f1": 0.94687
        },
        "meteor": 0.42891859414311245,
        "bleurt": 0.62476
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "mT5_base/totto_test",
        "N": 4,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5454545454545454,
            "3": 0.4594594594594595
        },
        "rouge1": {
            "precision": 0.61979,
            "recall": 0.58515,
            "fmeasure": 0.59581
        },
        "rouge2": {
            "precision": 0.39028,
            "recall": 0.38896,
            "fmeasure": 0.38752
        },
        "rougeL": {
            "precision": 0.47812,
            "recall": 0.44524,
            "fmeasure": 0.45809
        },
        "rougeLsum": {
            "precision": 0.47812,
            "recall": 0.44524,
            "fmeasure": 0.45809
        },
        "nist": 3.6739302944208574,
        "bleu": 27.44162,
        "nubia": {
            "semantic_relation": 3.13057,
            "contradiction": 45.19413,
            "irrelevancy": 7.13287,
            "logical_agreement": 47.673,
            "grammar_ref": 4.12218,
            "grammar_hyp": 4.26308,
            "nubia_score": 0.44133
        },
        "bertscore": {
            "precision": 0.88764,
            "recall": 0.87728,
            "f1": 0.88215
        },
        "meteor": 0.28537078910948455,
        "bleurt": 0.12076
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.47872969366552,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.20451,
            "irrelevancy": 0.76191,
            "logical_agreement": 98.03358,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.01604,
            "nubia_score": 0.98068
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.9148
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.125,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.51389,
            "recall": 0.64141,
            "fmeasure": 0.56936
        },
        "rouge2": {
            "precision": 0.21739,
            "recall": 0.28867,
            "fmeasure": 0.24797
        },
        "rougeL": {
            "precision": 0.29167,
            "recall": 0.38207,
            "fmeasure": 0.33075
        },
        "rougeLsum": {
            "precision": 0.29167,
            "recall": 0.38207,
            "fmeasure": 0.33075
        },
        "nist": 2.9011574112834,
        "bleu": 18.64185,
        "nubia": {
            "semantic_relation": 3.29803,
            "contradiction": 67.33318,
            "irrelevancy": 30.10533,
            "logical_agreement": 2.56149,
            "grammar_ref": 4.78465,
            "grammar_hyp": 5.49729,
            "nubia_score": 0.40711
        },
        "bertscore": {
            "precision": 0.88869,
            "recall": 0.90583,
            "f1": 0.89718
        },
        "meteor": 0.30693309811610603,
        "bleurt": -0.22748
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.7046,
            "fmeasure": 0.79036
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.61869,
            "fmeasure": 0.67269
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.58525,
            "fmeasure": 0.62098
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.58525,
            "fmeasure": 0.62098
        },
        "nist": 2.4927498718293672,
        "bleu": 47.88017,
        "nubia": {
            "semantic_relation": 4.29968,
            "contradiction": 6.1376,
            "irrelevancy": 1.50504,
            "logical_agreement": 92.35736,
            "grammar_ref": 4.56621,
            "grammar_hyp": 5.07348,
            "nubia_score": 0.63963
        },
        "bertscore": {
            "precision": 0.95317,
            "recall": 0.90141,
            "f1": 0.92322
        },
        "meteor": 0.412628103560951,
        "bleurt": 0.27184
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.71795,
            "recall": 0.50446,
            "fmeasure": 0.59048
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.27381,
            "fmeasure": 0.33766
        },
        "rougeL": {
            "precision": 0.64103,
            "recall": 0.45009,
            "fmeasure": 0.52698
        },
        "rougeLsum": {
            "precision": 0.64103,
            "recall": 0.45009,
            "fmeasure": 0.52698
        },
        "nist": 2.1390910261281615,
        "bleu": 25.39662,
        "nubia": {
            "semantic_relation": 4.0328,
            "contradiction": 6.2083,
            "irrelevancy": 27.61846,
            "logical_agreement": 66.17325,
            "grammar_ref": 3.28677,
            "grammar_hyp": 4.01525,
            "nubia_score": 0.66544
        },
        "bertscore": {
            "precision": 0.91854,
            "recall": 0.90296,
            "f1": 0.90715
        },
        "meteor": 0.26318413290781634,
        "bleurt": 0.24349
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.35714,
            "fmeasure": 0.3125
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "nist": 2.9110840865659036,
        "bleu": 29.98221,
        "nubia": {
            "semantic_relation": 4.27949,
            "contradiction": 0.24155,
            "irrelevancy": 87.10961,
            "logical_agreement": 12.64884,
            "grammar_ref": 5.57872,
            "grammar_hyp": 4.89448,
            "nubia_score": 0.80619
        },
        "bertscore": {
            "precision": 0.93251,
            "recall": 0.9667,
            "f1": 0.9493
        },
        "meteor": 0.48661903868199247,
        "bleurt": 0.38368
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "nist": 3.2544789837508556,
        "bleu": 82.65168,
        "nubia": {
            "semantic_relation": 4.37248,
            "contradiction": 0.31688,
            "irrelevancy": 96.54524,
            "logical_agreement": 3.13788,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.47724,
            "nubia_score": 0.89041
        },
        "bertscore": {
            "precision": 0.94318,
            "recall": 0.98431,
            "f1": 0.9633
        },
        "meteor": 0.5690637876265101,
        "bleurt": 0.56358
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.4,
            "recall": 0.92857,
            "fmeasure": 0.55844
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.63333,
            "fmeasure": 0.35789
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.77381,
            "fmeasure": 0.46537
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.77381,
            "fmeasure": 0.46537
        },
        "nist": 1.3261216249756291,
        "bleu": 10.65728,
        "nubia": {
            "semantic_relation": 4.55823,
            "contradiction": 0.87866,
            "irrelevancy": 37.88945,
            "logical_agreement": 61.23189,
            "grammar_ref": 7.77345,
            "grammar_hyp": 4.78372,
            "nubia_score": 0.90368
        },
        "bertscore": {
            "precision": 0.84514,
            "recall": 0.91334,
            "f1": 0.8778
        },
        "meteor": 0.3658733952590983,
        "bleurt": 0.47139
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.56061,
            "fmeasure": 0.69412
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.35,
            "fmeasure": 0.44103
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.4697,
            "fmeasure": 0.57647
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.4697,
            "fmeasure": 0.57647
        },
        "nist": 1.5447607115929036,
        "bleu": 46.0637,
        "nubia": {
            "semantic_relation": 4.26244,
            "contradiction": 0.28276,
            "irrelevancy": 0.50733,
            "logical_agreement": 99.20992,
            "grammar_ref": 5.60099,
            "grammar_hyp": 6.83551,
            "nubia_score": 0.66752
        },
        "bertscore": {
            "precision": 0.88781,
            "recall": 0.84007,
            "f1": 0.86328
        },
        "meteor": 0.3533609585395231,
        "bleurt": 0.26304
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9230769230769231
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.92857,
            "recall": 0.86667,
            "fmeasure": 0.89655
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "nist": 4.373609831586596,
        "bleu": 85.22457,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.35488,
            "irrelevancy": 10.42506,
            "logical_agreement": 89.22006,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.15345,
            "nubia_score": 0.98846
        },
        "bertscore": {
            "precision": 0.99784,
            "recall": 0.98969,
            "f1": 0.99375
        },
        "meteor": 0.5747920211718521,
        "bleurt": 0.78906
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.66111,
            "fmeasure": 0.56838
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.31313,
            "fmeasure": 0.26515
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.56667,
            "fmeasure": 0.48718
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.56667,
            "fmeasure": 0.48718
        },
        "nist": 1.6125614894488898,
        "bleu": 11.25133,
        "nubia": {
            "semantic_relation": 4.50081,
            "contradiction": 0.22919,
            "irrelevancy": 25.95401,
            "logical_agreement": 73.8168,
            "grammar_ref": 5.64952,
            "grammar_hyp": 4.10004,
            "nubia_score": 0.84519
        },
        "bertscore": {
            "precision": 0.87037,
            "recall": 0.90416,
            "f1": 0.88189
        },
        "meteor": 0.27346211201708037,
        "bleurt": 0.25182
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.8963,
            "fmeasure": 0.92788
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.49537,
            "fmeasure": 0.51716
        },
        "rougeL": {
            "precision": 0.85185,
            "recall": 0.79259,
            "fmeasure": 0.82066
        },
        "rougeLsum": {
            "precision": 0.85185,
            "recall": 0.79259,
            "fmeasure": 0.82066
        },
        "nist": 3.7456398254417365,
        "bleu": 55.62833,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18796,
            "irrelevancy": 0.48475,
            "logical_agreement": 99.32729,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.58474,
            "nubia_score": 0.95724
        },
        "bertscore": {
            "precision": 0.97269,
            "recall": 0.95351,
            "f1": 0.963
        },
        "meteor": 0.46736318340128513,
        "bleurt": 0.70029
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.29412,
            "fmeasure": 0.35714
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.25,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.29412,
            "fmeasure": 0.35714
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.29412,
            "fmeasure": 0.35714
        },
        "nist": 0.8768600701346063,
        "bleu": 18.51604,
        "nubia": {
            "semantic_relation": 2.35408,
            "contradiction": 12.75157,
            "irrelevancy": 85.33699,
            "logical_agreement": 1.91145,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.57034,
            "nubia_score": 0.16146
        },
        "bertscore": {
            "precision": 0.86295,
            "recall": 0.7723,
            "f1": 0.81511
        },
        "meteor": 0.194296409135584,
        "bleurt": -0.22243
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.867976246918685,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.73788
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.81667,
            "fmeasure": 0.79463
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.66138,
            "fmeasure": 0.64052
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.81667,
            "fmeasure": 0.79463
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.81667,
            "fmeasure": 0.79463
        },
        "nist": 2.763324482612094,
        "bleu": 59.69492,
        "nubia": {
            "semantic_relation": 4.7524,
            "contradiction": 0.47097,
            "irrelevancy": 34.77542,
            "logical_agreement": 64.7536,
            "grammar_ref": 4.01433,
            "grammar_hyp": 3.85489,
            "nubia_score": 0.9587
        },
        "bertscore": {
            "precision": 0.9562,
            "recall": 0.96304,
            "f1": 0.95635
        },
        "meteor": 0.875399822034102,
        "bleurt": 0.67156
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.19394,
            "fmeasure": 0.20702
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "nist": 1.2418318179195795,
        "bleu": 8.91377,
        "nubia": {
            "semantic_relation": 2.77982,
            "contradiction": 0.27781,
            "irrelevancy": 96.86995,
            "logical_agreement": 2.85225,
            "grammar_ref": 4.79209,
            "grammar_hyp": 4.14194,
            "nubia_score": 0.37188
        },
        "bertscore": {
            "precision": 0.77928,
            "recall": 0.76132,
            "f1": 0.7702
        },
        "meteor": 0.24478644006080186,
        "bleurt": -0.66816
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5263157894736842,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.6346,
            "fmeasure": 0.68182
        },
        "rouge2": {
            "precision": 0.45227,
            "recall": 0.38317,
            "fmeasure": 0.40883
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.48359,
            "fmeasure": 0.52208
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.48359,
            "fmeasure": 0.52208
        },
        "nist": 3.24584435104623,
        "bleu": 19.1406,
        "nubia": {
            "semantic_relation": 4.32176,
            "contradiction": 54.02546,
            "irrelevancy": 9.83611,
            "logical_agreement": 36.13843,
            "grammar_ref": 5.11675,
            "grammar_hyp": 5.24389,
            "nubia_score": 0.62426
        },
        "bertscore": {
            "precision": 0.91931,
            "recall": 0.90679,
            "f1": 0.91295
        },
        "meteor": 0.33456431256819785,
        "bleurt": 0.15731
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.73333,
            "fmeasure": 0.77193
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.48148,
            "fmeasure": 0.5098
        },
        "rougeL": {
            "precision": 0.81481,
            "recall": 0.73333,
            "fmeasure": 0.77193
        },
        "rougeLsum": {
            "precision": 0.81481,
            "recall": 0.73333,
            "fmeasure": 0.77193
        },
        "nist": 3.3015782866651606,
        "bleu": 45.56162,
        "nubia": {
            "semantic_relation": 4.69771,
            "contradiction": 7.56786,
            "irrelevancy": 6.63859,
            "logical_agreement": 85.79355,
            "grammar_ref": 5.6957,
            "grammar_hyp": 5.76217,
            "nubia_score": 0.71801
        },
        "bertscore": {
            "precision": 0.98659,
            "recall": 0.97404,
            "f1": 0.98027
        },
        "meteor": 0.48117686361121714,
        "bleurt": 0.13518
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "mT5_base/totto_test",
        "N": 48,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.525,
            "3": 0.8224852071005917
        },
        "rouge1": {
            "precision": 0.85491,
            "recall": 0.79393,
            "fmeasure": 0.81313
        },
        "rouge2": {
            "precision": 0.6739,
            "recall": 0.63273,
            "fmeasure": 0.64545
        },
        "rougeL": {
            "precision": 0.77094,
            "recall": 0.71924,
            "fmeasure": 0.73614
        },
        "rougeLsum": {
            "precision": 0.77094,
            "recall": 0.71924,
            "fmeasure": 0.73614
        },
        "nist": 7.4094847645197355,
        "bleu": 63.69576,
        "nubia": {
            "semantic_relation": 4.46905,
            "contradiction": 6.45096,
            "irrelevancy": 6.11765,
            "logical_agreement": 87.43139,
            "grammar_ref": 4.06325,
            "grammar_hyp": 4.19172,
            "nubia_score": 0.84748
        },
        "bertscore": {
            "precision": 0.95797,
            "recall": 0.94553,
            "f1": 0.95037
        },
        "meteor": 0.45082160675952415,
        "bleurt": 0.57586
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.14285714285714285,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.52963,
            "fmeasure": 0.62393
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.28105,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.52422
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.52422
        },
        "nist": 0.6720027070852478,
        "bleu": 25.43314,
        "nubia": {
            "semantic_relation": 3.97598,
            "contradiction": 0.24545,
            "irrelevancy": 3.51789,
            "logical_agreement": 96.23665,
            "grammar_ref": 3.74426,
            "grammar_hyp": 4.16414,
            "nubia_score": 0.7061
        },
        "bertscore": {
            "precision": 0.95289,
            "recall": 0.89204,
            "f1": 0.92146
        },
        "meteor": 0.29905304748723316,
        "bleurt": 0.29567
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3684210526315789
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.26884,
            "fmeasure": 0.36667
        },
        "rouge2": {
            "precision": 0.22727,
            "recall": 0.09718,
            "fmeasure": 0.13561
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.26884,
            "fmeasure": 0.36667
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.26884,
            "fmeasure": 0.36667
        },
        "nist": 0.2674542855081153,
        "bleu": 7.49757,
        "nubia": {
            "semantic_relation": 3.76115,
            "contradiction": 16.88458,
            "irrelevancy": 5.08011,
            "logical_agreement": 78.03531,
            "grammar_ref": 4.294,
            "grammar_hyp": 4.04419,
            "nubia_score": 0.51566
        },
        "bertscore": {
            "precision": 0.88525,
            "recall": 0.79901,
            "f1": 0.83992
        },
        "meteor": 0.19585567619863312,
        "bleurt": -0.20763
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.40909,
            "fmeasure": 0.40909
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.40909,
            "fmeasure": 0.40909
        },
        "nist": 1.7924812503605787,
        "bleu": 14.99111,
        "nubia": {
            "semantic_relation": 3.53995,
            "contradiction": 0.27078,
            "irrelevancy": 99.48551,
            "logical_agreement": 0.24371,
            "grammar_ref": 4.25346,
            "grammar_hyp": 4.45875,
            "nubia_score": 0.53846
        },
        "bertscore": {
            "precision": 0.83259,
            "recall": 0.83636,
            "f1": 0.83198
        },
        "meteor": 0.23352312920470394,
        "bleurt": -0.34932
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.886868538598291,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2217,
            "irrelevancy": 0.43077,
            "logical_agreement": 99.34753,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.86832,
            "nubia_score": 0.98747
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.88843
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.37777777777777777
        },
        "rouge1": {
            "precision": 0.84127,
            "recall": 0.39681,
            "fmeasure": 0.51849
        },
        "rouge2": {
            "precision": 0.26638,
            "recall": 0.09805,
            "fmeasure": 0.13901
        },
        "rougeL": {
            "precision": 0.53968,
            "recall": 0.23909,
            "fmeasure": 0.31923
        },
        "rougeLsum": {
            "precision": 0.53968,
            "recall": 0.23909,
            "fmeasure": 0.31923
        },
        "nist": 1.0232476745070866,
        "bleu": 7.15168,
        "nubia": {
            "semantic_relation": 3.56522,
            "contradiction": 3.46734,
            "irrelevancy": 50.19549,
            "logical_agreement": 46.33717,
            "grammar_ref": 4.73012,
            "grammar_hyp": 5.46669,
            "nubia_score": 0.42304
        },
        "bertscore": {
            "precision": 0.92328,
            "recall": 0.82559,
            "f1": 0.86655
        },
        "meteor": 0.2265826103291572,
        "bleurt": -0.13807
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5714285714285714,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.67857,
            "recall": 0.64236,
            "fmeasure": 0.64128
        },
        "rouge2": {
            "precision": 0.27949,
            "recall": 0.31372,
            "fmeasure": 0.28568
        },
        "rougeL": {
            "precision": 0.54762,
            "recall": 0.57702,
            "fmeasure": 0.53801
        },
        "rougeLsum": {
            "precision": 0.54762,
            "recall": 0.57702,
            "fmeasure": 0.53801
        },
        "nist": 3.3632090673557617,
        "bleu": 23.91141,
        "nubia": {
            "semantic_relation": 3.98238,
            "contradiction": 17.00585,
            "irrelevancy": 17.98585,
            "logical_agreement": 65.00829,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.2598,
            "nubia_score": 0.6325
        },
        "bertscore": {
            "precision": 0.87226,
            "recall": 0.85961,
            "f1": 0.86207
        },
        "meteor": 0.35037331077684325,
        "bleurt": 0.15908
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.69697,
            "fmeasure": 0.54253
        },
        "rouge2": {
            "precision": 0.29412,
            "recall": 0.47727,
            "fmeasure": 0.36376
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.69697,
            "fmeasure": 0.54253
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.69697,
            "fmeasure": 0.54253
        },
        "nist": 1.7318850957412437,
        "bleu": 16.67955,
        "nubia": {
            "semantic_relation": 4.39609,
            "contradiction": 0.10806,
            "irrelevancy": 97.99349,
            "logical_agreement": 1.89845,
            "grammar_ref": 5.10481,
            "grammar_hyp": 4.15449,
            "nubia_score": 0.80225
        },
        "bertscore": {
            "precision": 0.8681,
            "recall": 0.91675,
            "f1": 0.89176
        },
        "meteor": 0.3338749261051948,
        "bleurt": 0.04102
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.64706,
            "fmeasure": 0.6875
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4375,
            "fmeasure": 0.46667
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.41176,
            "fmeasure": 0.4375
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.41176,
            "fmeasure": 0.4375
        },
        "nist": 2.878186341626348,
        "bleu": 27.25184,
        "nubia": {
            "semantic_relation": 3.93468,
            "contradiction": 0.04394,
            "irrelevancy": 99.5488,
            "logical_agreement": 0.40725,
            "grammar_ref": 3.64996,
            "grammar_hyp": 3.78592,
            "nubia_score": 0.76886
        },
        "bertscore": {
            "precision": 0.92368,
            "recall": 0.8871,
            "f1": 0.90502
        },
        "meteor": 0.3677907320222521,
        "bleurt": 0.29423
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.67194,
            "fmeasure": 0.69239
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.44567,
            "fmeasure": 0.47013
        },
        "rougeL": {
            "precision": 0.61905,
            "recall": 0.58235,
            "fmeasure": 0.60007
        },
        "rougeLsum": {
            "precision": 0.61905,
            "recall": 0.58235,
            "fmeasure": 0.60007
        },
        "nist": 2.6806719935185854,
        "bleu": 30.34056,
        "nubia": {
            "semantic_relation": 4.92274,
            "contradiction": 0.20622,
            "irrelevancy": 5.41098,
            "logical_agreement": 94.3828,
            "grammar_ref": 3.13705,
            "grammar_hyp": 3.42814,
            "nubia_score": 0.97046
        },
        "bertscore": {
            "precision": 0.93127,
            "recall": 0.93024,
            "f1": 0.93018
        },
        "meteor": 0.3380992754171435,
        "bleurt": 0.2578
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5882352941176471
        },
        "rouge1": {
            "precision": 0.84524,
            "recall": 0.46948,
            "fmeasure": 0.59641
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.31738,
            "fmeasure": 0.40926
        },
        "rougeL": {
            "precision": 0.84524,
            "recall": 0.46948,
            "fmeasure": 0.59641
        },
        "rougeLsum": {
            "precision": 0.84524,
            "recall": 0.46948,
            "fmeasure": 0.59641
        },
        "nist": 0.4047734520424602,
        "bleu": 24.57723,
        "nubia": {
            "semantic_relation": 3.8784,
            "contradiction": 57.89649,
            "irrelevancy": 14.86952,
            "logical_agreement": 27.23398,
            "grammar_ref": 3.80999,
            "grammar_hyp": 5.74402,
            "nubia_score": 0.46482
        },
        "bertscore": {
            "precision": 0.94617,
            "recall": 0.85086,
            "f1": 0.8955
        },
        "meteor": 0.26273487353217273,
        "bleurt": 0.16611
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.4,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "nist": 2.926766623731375,
        "bleu": 29.84746,
        "nubia": {
            "semantic_relation": 4.61608,
            "contradiction": 5.42022,
            "irrelevancy": 3.15195,
            "logical_agreement": 91.42783,
            "grammar_ref": 5.78237,
            "grammar_hyp": 7.05881,
            "nubia_score": 0.65246
        },
        "bertscore": {
            "precision": 0.96153,
            "recall": 0.96153,
            "f1": 0.96153
        },
        "meteor": 0.4457217621413936,
        "bleurt": 0.29658
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.0,
            "3": 0.4117647058823529
        },
        "rouge1": {
            "precision": 0.6161,
            "recall": 0.36414,
            "fmeasure": 0.45261
        },
        "rouge2": {
            "precision": 0.22549,
            "recall": 0.13986,
            "fmeasure": 0.1719
        },
        "rougeL": {
            "precision": 0.40954,
            "recall": 0.25486,
            "fmeasure": 0.31156
        },
        "rougeLsum": {
            "precision": 0.40954,
            "recall": 0.25486,
            "fmeasure": 0.31156
        },
        "nist": 0.4483843775619041,
        "bleu": 3.65929,
        "nubia": {
            "semantic_relation": 2.92931,
            "contradiction": 40.13311,
            "irrelevancy": 3.58563,
            "logical_agreement": 56.28125,
            "grammar_ref": 3.44707,
            "grammar_hyp": 3.75775,
            "nubia_score": 0.37804
        },
        "bertscore": {
            "precision": 0.87403,
            "recall": 0.82465,
            "f1": 0.84429
        },
        "meteor": 0.16579009004712192,
        "bleurt": -0.15788
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.1699250014423126,
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.45873,
            "irrelevancy": 0.46812,
            "logical_agreement": 99.07315,
            "grammar_ref": 5.85687,
            "grammar_hyp": 5.85687,
            "nubia_score": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.95702
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.41071,
            "fmeasure": 0.45055
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "nist": 2.8610927314735184,
        "bleu": 33.12203,
        "nubia": {
            "semantic_relation": 4.56442,
            "contradiction": 2.44907,
            "irrelevancy": 2.37459,
            "logical_agreement": 95.17634,
            "grammar_ref": 5.6187,
            "grammar_hyp": 6.50772,
            "nubia_score": 0.67533
        },
        "bertscore": {
            "precision": 0.95923,
            "recall": 0.93678,
            "f1": 0.94787
        },
        "meteor": 0.3707878006073302,
        "bleurt": 0.35902
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "total_length": 3012,
        "mean_pred_length": 18.14457831325301,
        "std_pred_length": 7.675077065066539,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.4438911022576361,
        "vocab_size-1": 1337,
        "unique-1": 1053,
        "entropy-1": 8.589068886505943,
        "distinct-2": 0.8612087139845397,
        "vocab_size-2": 2451,
        "unique-2": 2300,
        "entropy-2": 11.01207580824911,
        "cond_entropy-2": 2.158642955706218,
        "distinct-3": 0.9630597014925373,
        "vocab_size-3": 2581,
        "unique-3": 2526,
        "entropy-3": 11.284598641745879,
        "cond_entropy-3": 0.29113257769463824,
        "total_length-nopunct": 2634,
        "mean_pred_length-nopunct": 15.867469879518072,
        "std_pred_length-nopunct": 6.5726176852943885,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5045558086560364,
        "vocab_size-1-nopunct": 1329,
        "unique-1-nopunct": 1053,
        "entropy-1-nopunct": 8.914784967865064,
        "distinct-2-nopunct": 0.8808752025931929,
        "vocab_size-2-nopunct": 2174,
        "unique-2-nopunct": 2055,
        "entropy-2-nopunct": 10.872629367245276,
        "cond_entropy-2-nopunct": 2.0908183974211414,
        "distinct-3-nopunct": 0.9795829713292789,
        "vocab_size-3-nopunct": 2255,
        "unique-3-nopunct": 2215,
        "entropy-3-nopunct": 11.125542573164992,
        "cond_entropy-3-nopunct": 0.2724890817991303,
        "msttr-100": 0.71267,
        "msttr-100_nopunct": 0.75846,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.032528339083292265,
            "2": 0.15770609318996415,
            "3": 0.398576512455516,
            "4": 0.5879828326180258,
            "5": 0.6912442396313364,
            "6": 0.8825757575757576,
            "7": 0.9190140845070423,
            "8": 0.9292604501607717,
            "9": 0.946969696969697,
            "10": 0.9867986798679867
        },
        "rouge1": {
            "precision": 0.8944,
            "recall": 0.9253,
            "fmeasure": 0.90559
        },
        "rouge2": {
            "precision": 0.80068,
            "recall": 0.84252,
            "fmeasure": 0.81563
        },
        "rougeL": {
            "precision": 0.88512,
            "recall": 0.91523,
            "fmeasure": 0.8962
        },
        "rougeLsum": {
            "precision": 0.88512,
            "recall": 0.91523,
            "fmeasure": 0.8962
        },
        "nist": 12.16985817047993,
        "bleu": 87.55665,
        "nubia": {
            "semantic_relation": 4.46347,
            "contradiction": 2.79866,
            "irrelevancy": 30.84708,
            "logical_agreement": 66.35427,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.77436,
            "nubia_score": 0.72974
        },
        "bertscore": {
            "precision": 0.97527,
            "recall": 0.98184,
            "f1": 0.97603
        },
        "meteor": 0.5619279376023819,
        "bleurt": 0.37219
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "total_length": 1346,
        "mean_pred_length": 23.20689655172414,
        "std_pred_length": 8.527356830022995,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 43,
        "distinct-1": 0.49405646359583955,
        "vocab_size-1": 665,
        "unique-1": 532,
        "entropy-1": 8.126670729486182,
        "distinct-2": 0.906832298136646,
        "vocab_size-2": 1168,
        "unique-2": 1115,
        "entropy-2": 10.06210774744281,
        "cond_entropy-2": 1.764395683275562,
        "distinct-3": 0.9780487804878049,
        "vocab_size-3": 1203,
        "unique-3": 1190,
        "entropy-3": 10.200167275002118,
        "cond_entropy-3": 0.14944649266366233,
        "total_length-nopunct": 1190,
        "mean_pred_length-nopunct": 20.517241379310345,
        "std_pred_length-nopunct": 7.629889905904199,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5512605042016807,
        "vocab_size-1-nopunct": 656,
        "unique-1-nopunct": 531,
        "entropy-1-nopunct": 8.326631971625098,
        "distinct-2-nopunct": 0.9337455830388692,
        "vocab_size-2-nopunct": 1057,
        "unique-2-nopunct": 1014,
        "entropy-2-nopunct": 9.973939066788812,
        "cond_entropy-2-nopunct": 1.734433071683744,
        "distinct-3-nopunct": 0.9925512104283054,
        "vocab_size-3-nopunct": 1066,
        "unique-3-nopunct": 1058,
        "entropy-3-nopunct": 10.053880698842063,
        "cond_entropy-3-nopunct": 0.08823000468895521,
        "msttr-100": 0.72462,
        "msttr-100_nopunct": 0.75818,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.035106382978723406,
            "2": 0.20155038759689922,
            "3": 0.4105960264900662,
            "4": 0.5545454545454546,
            "5": 0.7925925925925926,
            "6": 0.8557692307692307,
            "7": 0.9473684210526315,
            "8": 0.9659863945578231,
            "9": 0.9803921568627451,
            "10": 0.9859154929577465
        },
        "rouge1": {
            "precision": 0.90838,
            "recall": 0.92818,
            "fmeasure": 0.91603
        },
        "rouge2": {
            "precision": 0.82063,
            "recall": 0.84326,
            "fmeasure": 0.8288
        },
        "rougeL": {
            "precision": 0.90228,
            "recall": 0.9195,
            "fmeasure": 0.90839
        },
        "rougeLsum": {
            "precision": 0.90228,
            "recall": 0.9195,
            "fmeasure": 0.90839
        },
        "nist": 11.33764515721799,
        "bleu": 87.90961,
        "nubia": {
            "semantic_relation": 4.42594,
            "contradiction": 2.52636,
            "irrelevancy": 32.37639,
            "logical_agreement": 65.09725,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.67682,
            "nubia_score": 0.70606
        },
        "bertscore": {
            "precision": 0.97139,
            "recall": 0.98113,
            "f1": 0.97499
        },
        "meteor": 0.5586131078640377,
        "bleurt": 0.29487
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "total_length": 729,
        "mean_pred_length": 22.78125,
        "std_pred_length": 8.64484808643275,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 41,
        "distinct-1": 0.5404663923182441,
        "vocab_size-1": 394,
        "unique-1": 315,
        "entropy-1": 7.65925078956111,
        "distinct-2": 0.9024390243902439,
        "vocab_size-2": 629,
        "unique-2": 594,
        "entropy-2": 9.196474602802192,
        "cond_entropy-2": 1.3830118579645931,
        "distinct-3": 0.968421052631579,
        "vocab_size-3": 644,
        "unique-3": 632,
        "entropy-3": 9.299053886101222,
        "cond_entropy-3": 0.11303535514596402,
        "total_length-nopunct": 636,
        "mean_pred_length-nopunct": 19.875,
        "std_pred_length-nopunct": 7.338894671542848,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6069182389937107,
        "vocab_size-1-nopunct": 386,
        "unique-1-nopunct": 314,
        "entropy-1-nopunct": 7.841910956079825,
        "distinct-2-nopunct": 0.9221854304635762,
        "vocab_size-2-nopunct": 557,
        "unique-2-nopunct": 531,
        "entropy-2-nopunct": 9.042810425604147,
        "cond_entropy-2-nopunct": 1.262962617659737,
        "distinct-3-nopunct": 0.9842657342657343,
        "vocab_size-3-nopunct": 563,
        "unique-3-nopunct": 555,
        "entropy-3-nopunct": 9.127083071914521,
        "cond_entropy-3-nopunct": 0.09346673379116614,
        "msttr-100": 0.70857,
        "msttr-100_nopunct": 0.74833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03285420944558522,
            "2": 0.2336448598130841,
            "3": 0.30985915492957744,
            "4": 0.6875,
            "5": 0.8,
            "6": 0.8970588235294118,
            "7": 0.9545454545454546,
            "8": 0.9841269841269841,
            "9": 0.9761904761904762,
            "10": 0.9919354838709677
        },
        "rouge1": {
            "precision": 0.92298,
            "recall": 0.92901,
            "fmeasure": 0.92227
        },
        "rouge2": {
            "precision": 0.81743,
            "recall": 0.83266,
            "fmeasure": 0.82102
        },
        "rougeL": {
            "precision": 0.90622,
            "recall": 0.9118,
            "fmeasure": 0.90506
        },
        "rougeLsum": {
            "precision": 0.90622,
            "recall": 0.9118,
            "fmeasure": 0.90506
        },
        "nist": 10.52463792051781,
        "bleu": 90.16078,
        "nubia": {
            "semantic_relation": 4.50895,
            "contradiction": 3.15609,
            "irrelevancy": 34.4188,
            "logical_agreement": 62.42511,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.5273,
            "nubia_score": 0.7266
        },
        "bertscore": {
            "precision": 0.97183,
            "recall": 0.98149,
            "f1": 0.97514
        },
        "meteor": 0.5607970760157527,
        "bleurt": 0.32674
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "total_length": 78,
        "mean_pred_length": 15.6,
        "std_pred_length": 4.17612260356422,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 60,
        "unique-1": 50,
        "entropy-1": 5.697270129363186,
        "distinct-2": 1.0,
        "vocab_size-2": 73,
        "unique-2": 73,
        "entropy-2": 6.189824558880028,
        "cond_entropy-2": 0.3738012784628425,
        "distinct-3": 1.0,
        "vocab_size-3": 68,
        "unique-3": 68,
        "entropy-3": 6.087462841250345,
        "cond_entropy-3": -0.10236171762967769,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 14.6,
        "std_pred_length-nopunct": 4.17612260356422,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8082191780821918,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.720445620434949,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.087462841250345,
        "cond_entropy-2-nopunct": 0.3868244957010638,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 5.97727992349992,
        "cond_entropy-3-nopunct": -0.11018291775042297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.027777777777777776,
            "2": 0.047619047619047616,
            "3": 0.25,
            "4": 0.4,
            "5": 0.42857142857142855,
            "6": 0.9230769230769231,
            "7": 1.0,
            "8": 1.0,
            "9": 0.875,
            "10": 1.0
        },
        "rouge1": {
            "precision": 0.91708,
            "recall": 0.90635,
            "fmeasure": 0.90888
        },
        "rouge2": {
            "precision": 0.90317,
            "recall": 0.8133,
            "fmeasure": 0.85137
        },
        "rougeL": {
            "precision": 0.91542,
            "recall": 0.90802,
            "fmeasure": 0.90873
        },
        "rougeLsum": {
            "precision": 0.91542,
            "recall": 0.90802,
            "fmeasure": 0.90873
        },
        "nist": 7.400641895529392,
        "bleu": 92.53106,
        "nubia": {
            "semantic_relation": 4.5127,
            "contradiction": 0.18292,
            "irrelevancy": 24.47539,
            "logical_agreement": 75.34169,
            "grammar_ref": 5.04038,
            "grammar_hyp": 5.3954,
            "nubia_score": 0.76314
        },
        "bertscore": {
            "precision": 0.99291,
            "recall": 0.9897,
            "f1": 0.98809
        },
        "meteor": 0.6058887658476703,
        "bleurt": 0.46486
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.61538,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.61538,
            "fmeasure": 0.72727
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.61538,
            "fmeasure": 0.72727
        },
        "nist": 1.7136563235793887,
        "bleu": 42.88819,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 4.36088,
            "irrelevancy": 1.21054,
            "logical_agreement": 94.42858,
            "grammar_ref": 3.94537,
            "grammar_hyp": 4.87325,
            "nubia_score": 0.90707
        },
        "bertscore": {
            "precision": 0.96184,
            "recall": 0.88586,
            "f1": 0.92229
        },
        "meteor": 0.35984860195205803,
        "bleurt": 0.62333
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8461538461538461
        },
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.91296,
            "fmeasure": 0.83651
        },
        "rouge2": {
            "precision": 0.46032,
            "recall": 0.52735,
            "fmeasure": 0.49123
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.64444,
            "fmeasure": 0.59048
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.64444,
            "fmeasure": 0.59048
        },
        "nist": 3.3008052848153095,
        "bleu": 21.62601,
        "nubia": {
            "semantic_relation": 4.65312,
            "contradiction": 0.93942,
            "irrelevancy": 88.15923,
            "logical_agreement": 10.90135,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.44552,
            "nubia_score": 0.83958
        },
        "bertscore": {
            "precision": 0.92685,
            "recall": 0.93313,
            "f1": 0.92998
        },
        "meteor": 0.4076490471161051,
        "bleurt": 0.2713
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "total_length": 708,
        "mean_pred_length": 25.285714285714285,
        "std_pred_length": 9.490059245852784,
        "median_pred_length": 23.5,
        "min_pred_length": 10,
        "max_pred_length": 52,
        "distinct-1": 0.5621468926553672,
        "vocab_size-1": 398,
        "unique-1": 330,
        "entropy-1": 7.762290825544698,
        "distinct-2": 0.9308823529411765,
        "vocab_size-2": 633,
        "unique-2": 602,
        "entropy-2": 9.245348472870695,
        "cond_entropy-2": 1.3492801702616268,
        "distinct-3": 0.9831288343558282,
        "vocab_size-3": 641,
        "unique-3": 632,
        "entropy-3": 9.312670217107739,
        "cond_entropy-3": 0.07129902793587217,
        "total_length-nopunct": 629,
        "mean_pred_length-nopunct": 22.464285714285715,
        "std_pred_length-nopunct": 8.287176595099645,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.6216216216216216,
        "vocab_size-1-nopunct": 391,
        "unique-1-nopunct": 330,
        "entropy-1-nopunct": 7.886571503046452,
        "distinct-2-nopunct": 0.9467554076539102,
        "vocab_size-2-nopunct": 569,
        "unique-2-nopunct": 546,
        "entropy-2-nopunct": 9.105140585851325,
        "cond_entropy-2-nopunct": 1.2740095598528856,
        "distinct-3-nopunct": 0.9947643979057592,
        "vocab_size-3-nopunct": 570,
        "unique-3-nopunct": 567,
        "entropy-3-nopunct": 9.15192012456842,
        "cond_entropy-3-nopunct": 0.04945014370159619,
        "msttr-100": 0.74143,
        "msttr-100_nopunct": 0.77333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02697495183044316,
            "2": 0.15789473684210525,
            "3": 0.3684210526315789,
            "4": 0.6451612903225806,
            "5": 0.7258064516129032,
            "6": 0.873015873015873,
            "7": 0.9506172839506173,
            "8": 0.9838709677419355,
            "9": 0.9636363636363636,
            "10": 0.9883720930232558
        },
        "rouge1": {
            "precision": 0.91389,
            "recall": 0.90966,
            "fmeasure": 0.90888
        },
        "rouge2": {
            "precision": 0.82756,
            "recall": 0.83345,
            "fmeasure": 0.82563
        },
        "rougeL": {
            "precision": 0.90176,
            "recall": 0.90542,
            "fmeasure": 0.89946
        },
        "rougeLsum": {
            "precision": 0.90176,
            "recall": 0.90542,
            "fmeasure": 0.89946
        },
        "nist": 10.225838331982759,
        "bleu": 86.50181,
        "nubia": {
            "semantic_relation": 4.39358,
            "contradiction": 2.20618,
            "irrelevancy": 32.10586,
            "logical_agreement": 65.68795,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.80046,
            "nubia_score": 0.68656
        },
        "bertscore": {
            "precision": 0.97863,
            "recall": 0.98152,
            "f1": 0.97763
        },
        "meteor": 0.5574042709069034,
        "bleurt": 0.25232
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "total_length": 172,
        "mean_pred_length": 24.571428571428573,
        "std_pred_length": 4.10077145554495,
        "median_pred_length": 26.0,
        "min_pred_length": 17,
        "max_pred_length": 31,
        "distinct-1": 0.7151162790697675,
        "vocab_size-1": 123,
        "unique-1": 109,
        "entropy-1": 6.516832287332481,
        "distinct-2": 0.9575757575757575,
        "vocab_size-2": 158,
        "unique-2": 155,
        "entropy-2": 7.255022044690656,
        "cond_entropy-2": 0.6494990135495972,
        "distinct-3": 1.0,
        "vocab_size-3": 158,
        "unique-3": 158,
        "entropy-3": 7.303780748177119,
        "cond_entropy-3": 0.04103149580850417,
        "total_length-nopunct": 154,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 3.116774889895918,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7597402597402597,
        "vocab_size-1-nopunct": 117,
        "unique-1-nopunct": 107,
        "entropy-1-nopunct": 6.484823005710695,
        "distinct-2-nopunct": 0.9591836734693877,
        "vocab_size-2-nopunct": 141,
        "unique-2-nopunct": 139,
        "entropy-2-nopunct": 7.088349025267644,
        "cond_entropy-2-nopunct": 0.640762378365749,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 140,
        "unique-3-nopunct": 140,
        "entropy-3-nopunct": 7.129283016944978,
        "cond_entropy-3-nopunct": 0.04650015765574698,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03529411764705882,
            "2": 0.13636363636363635,
            "3": 0.6666666666666666,
            "4": 0.8333333333333334,
            "5": 0.875,
            "6": 0.75,
            "7": 0.9333333333333333,
            "8": 0.96,
            "9": 1.0,
            "10": 0.9583333333333334
        },
        "rouge1": {
            "precision": 0.91185,
            "recall": 0.93008,
            "fmeasure": 0.91909
        },
        "rouge2": {
            "precision": 0.83314,
            "recall": 0.85893,
            "fmeasure": 0.84337
        },
        "rougeL": {
            "precision": 0.89585,
            "recall": 0.92578,
            "fmeasure": 0.90948
        },
        "rougeLsum": {
            "precision": 0.89585,
            "recall": 0.92578,
            "fmeasure": 0.90948
        },
        "nist": 8.381685882693835,
        "bleu": 86.52313,
        "nubia": {
            "semantic_relation": 4.3801,
            "contradiction": 1.81454,
            "irrelevancy": 42.84629,
            "logical_agreement": 55.33917,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.553,
            "nubia_score": 0.69098
        },
        "bertscore": {
            "precision": 0.97973,
            "recall": 0.98374,
            "f1": 0.98122
        },
        "meteor": 0.5696522117028184,
        "bleurt": 0.29029
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "mT5_base/totto_test",
        "N": 3,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.9444444444444444
        },
        "rouge1": {
            "precision": 0.92157,
            "recall": 0.87677,
            "fmeasure": 0.8969
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.76859,
            "fmeasure": 0.77889
        },
        "rougeL": {
            "precision": 0.88235,
            "recall": 0.84444,
            "fmeasure": 0.86148
        },
        "rougeLsum": {
            "precision": 0.88235,
            "recall": 0.84444,
            "fmeasure": 0.86148
        },
        "nist": 4.739164914127941,
        "bleu": 76.50014,
        "nubia": {
            "semantic_relation": 4.58466,
            "contradiction": 0.49446,
            "irrelevancy": 32.86734,
            "logical_agreement": 66.6382,
            "grammar_ref": 4.141,
            "grammar_hyp": 4.16432,
            "nubia_score": 0.84842
        },
        "bertscore": {
            "precision": 0.96724,
            "recall": 0.96214,
            "f1": 0.96467
        },
        "meteor": 0.5138317080925805,
        "bleurt": 0.74549
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.66138,
            "fmeasure": 0.79365
        },
        "rouge2": {
            "precision": 0.81481,
            "recall": 0.46757,
            "fmeasure": 0.59207
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.5037,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.5037,
            "fmeasure": 0.66667
        },
        "nist": 1.2866252014276134,
        "bleu": 53.41953,
        "nubia": {
            "semantic_relation": 3.33105,
            "contradiction": 91.39293,
            "irrelevancy": 2.01149,
            "logical_agreement": 6.59557,
            "grammar_ref": 3.09217,
            "grammar_hyp": 3.50014,
            "nubia_score": 0.48175
        },
        "bertscore": {
            "precision": 0.9768,
            "recall": 0.89041,
            "f1": 0.9316
        },
        "meteor": 0.37628312161800387,
        "bleurt": -0.19515
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.54444,
            "fmeasure": 0.66957
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.39827,
            "fmeasure": 0.49735
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.52222,
            "fmeasure": 0.64058
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.52222,
            "fmeasure": 0.64058
        },
        "nist": 0.998658318138759,
        "bleu": 21.7929,
        "nubia": {
            "semantic_relation": 3.83037,
            "contradiction": 0.33214,
            "irrelevancy": 0.80058,
            "logical_agreement": 98.86728,
            "grammar_ref": 4.47457,
            "grammar_hyp": 4.87991,
            "nubia_score": 0.65307
        },
        "bertscore": {
            "precision": 0.91326,
            "recall": 0.82764,
            "f1": 0.86606
        },
        "meteor": 0.2985045194114117,
        "bleurt": 0.05518
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "mT5_base/totto_test",
        "N": 123,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23674911660777384,
            "2": 0.39464882943143814,
            "3": 0.7659738260200154
        },
        "rouge1": {
            "precision": 0.77625,
            "recall": 0.74612,
            "fmeasure": 0.74995
        },
        "rouge2": {
            "precision": 0.5442,
            "recall": 0.52881,
            "fmeasure": 0.52989
        },
        "rougeL": {
            "precision": 0.68035,
            "recall": 0.65282,
            "fmeasure": 0.657
        },
        "rougeLsum": {
            "precision": 0.68035,
            "recall": 0.65282,
            "fmeasure": 0.657
        },
        "nist": 7.526674559873936,
        "bleu": 51.70241,
        "nubia": {
            "semantic_relation": 4.21822,
            "contradiction": 10.56224,
            "irrelevancy": 21.99343,
            "logical_agreement": 67.44432,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.72558,
            "nubia_score": 0.74351
        },
        "bertscore": {
            "precision": 0.93226,
            "recall": 0.92638,
            "f1": 0.92779
        },
        "meteor": 0.403902756625312,
        "bleurt": 0.36892
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "mT5_base/totto_test",
        "N": 29,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.175,
            "2": 0.3333333333333333,
            "3": 0.8698224852071006
        },
        "rouge1": {
            "precision": 0.85248,
            "recall": 0.83475,
            "fmeasure": 0.8369
        },
        "rouge2": {
            "precision": 0.70429,
            "recall": 0.69253,
            "fmeasure": 0.69275
        },
        "rougeL": {
            "precision": 0.80232,
            "recall": 0.78688,
            "fmeasure": 0.78811
        },
        "rougeLsum": {
            "precision": 0.80232,
            "recall": 0.78688,
            "fmeasure": 0.78811
        },
        "nist": 6.965602002649073,
        "bleu": 67.26808,
        "nubia": {
            "semantic_relation": 4.32351,
            "contradiction": 7.10219,
            "irrelevancy": 13.01883,
            "logical_agreement": 79.87897,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.29293,
            "nubia_score": 0.79643
        },
        "bertscore": {
            "precision": 0.95369,
            "recall": 0.95296,
            "f1": 0.95169
        },
        "meteor": 0.45493091713010847,
        "bleurt": 0.53525
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "mT5_base/totto_test",
        "N": 112,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19584569732937684,
            "2": 0.44551282051282054,
            "3": 0.7830271216097988
        },
        "rouge1": {
            "precision": 0.76029,
            "recall": 0.71475,
            "fmeasure": 0.72561
        },
        "rouge2": {
            "precision": 0.52007,
            "recall": 0.48134,
            "fmeasure": 0.49332
        },
        "rougeL": {
            "precision": 0.65757,
            "recall": 0.6174,
            "fmeasure": 0.62722
        },
        "rougeLsum": {
            "precision": 0.65757,
            "recall": 0.6174,
            "fmeasure": 0.62722
        },
        "nist": 7.303971814033728,
        "bleu": 43.49822,
        "nubia": {
            "semantic_relation": 4.15343,
            "contradiction": 9.49952,
            "irrelevancy": 24.22336,
            "logical_agreement": 66.27712,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.74122,
            "nubia_score": 0.71213
        },
        "bertscore": {
            "precision": 0.92596,
            "recall": 0.91808,
            "f1": 0.92077
        },
        "meteor": 0.38156664603352264,
        "bleurt": 0.26779
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "mT5_base/totto_test",
        "N": 91,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20270270270270271,
            "2": 0.42105263157894735,
            "3": 0.7531512605042017
        },
        "rouge1": {
            "precision": 0.78538,
            "recall": 0.71932,
            "fmeasure": 0.74185
        },
        "rouge2": {
            "precision": 0.55769,
            "recall": 0.51261,
            "fmeasure": 0.52756
        },
        "rougeL": {
            "precision": 0.68949,
            "recall": 0.63429,
            "fmeasure": 0.65305
        },
        "rougeLsum": {
            "precision": 0.68949,
            "recall": 0.63429,
            "fmeasure": 0.65305
        },
        "nist": 7.264132346591562,
        "bleu": 49.73579,
        "nubia": {
            "semantic_relation": 4.0167,
            "contradiction": 11.98044,
            "irrelevancy": 23.30037,
            "logical_agreement": 64.71919,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.46474,
            "nubia_score": 0.69655
        },
        "bertscore": {
            "precision": 0.93413,
            "recall": 0.91695,
            "f1": 0.92392
        },
        "meteor": 0.3904498847792524,
        "bleurt": 0.29966
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1850,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2195167286245353,
            "2": 0.4614356624665903,
            "3": 0.7707349517791819
        },
        "rouge1": {
            "precision": 0.75618,
            "recall": 0.72151,
            "fmeasure": 0.72483
        },
        "rouge2": {
            "precision": 0.55012,
            "recall": 0.52685,
            "fmeasure": 0.52816
        },
        "rougeL": {
            "precision": 0.68483,
            "recall": 0.65579,
            "fmeasure": 0.65749
        },
        "rougeLsum": {
            "precision": 0.68483,
            "recall": 0.65579,
            "fmeasure": 0.65749
        },
        "nist": 9.412579553211506,
        "bleu": 50.49347,
        "nubia": {
            "semantic_relation": 4.14953,
            "contradiction": 8.18221,
            "irrelevancy": 28.35745,
            "logical_agreement": 63.46034,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.75882,
            "nubia_score": 0.72052
        },
        "bertscore": {
            "precision": 0.92939,
            "recall": 0.92358,
            "f1": 0.92468
        },
        "meteor": 0.4016776709005608,
        "bleurt": 0.31167
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_base/totto_test",
        "N": 2221,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20655829596412556,
            "2": 0.4312150837988827,
            "3": 0.782565671104714
        },
        "rouge1": {
            "precision": 0.78016,
            "recall": 0.73732,
            "fmeasure": 0.74704
        },
        "rouge2": {
            "precision": 0.53982,
            "recall": 0.51124,
            "fmeasure": 0.51696
        },
        "rougeL": {
            "precision": 0.66966,
            "recall": 0.63519,
            "fmeasure": 0.64231
        },
        "rougeLsum": {
            "precision": 0.66966,
            "recall": 0.63519,
            "fmeasure": 0.64231
        },
        "nist": 10.009525269036205,
        "bleu": 46.59447,
        "nubia": {
            "semantic_relation": 4.28487,
            "contradiction": 8.32165,
            "irrelevancy": 26.70825,
            "logical_agreement": 64.9701,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.8426,
            "nubia_score": 0.74226
        },
        "bertscore": {
            "precision": 0.93175,
            "recall": 0.92628,
            "f1": 0.92747
        },
        "meteor": 0.3995334981431325,
        "bleurt": 0.29644
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_base/totto_test",
        "N": 1369,
        "total_length": 122928,
        "mean_pred_length": 15.964675324675325,
        "std_pred_length": 6.7944246785704925,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.17445984641416112,
        "vocab_size-1": 21446,
        "unique-1": 14818,
        "entropy-1": 10.084151649894922,
        "distinct-2": 0.5410403721317735,
        "vocab_size-2": 62343,
        "unique-2": 51947,
        "entropy-2": 14.555554001469453,
        "cond_entropy-2": 4.064184140988243,
        "distinct-3": 0.7684045085931106,
        "vocab_size-3": 82625,
        "unique-3": 74841,
        "entropy-3": 15.82373446928782,
        "cond_entropy-3": 1.2341451186204728,
        "total_length-nopunct": 106766,
        "mean_pred_length-nopunct": 13.865714285714287,
        "std_pred_length-nopunct": 5.749185696958101,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.2006912312908604,
        "vocab_size-1-nopunct": 21427,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.661200622773524,
        "distinct-2-nopunct": 0.5871338299719379,
        "vocab_size-2-nopunct": 58165,
        "unique-2-nopunct": 49559,
        "entropy-2-nopunct": 14.562762454261803,
        "cond_entropy-2-nopunct": 4.067186312268929,
        "distinct-3-nopunct": 0.7958540376069873,
        "vocab_size-3-nopunct": 72714,
        "unique-3-nopunct": 66691,
        "entropy-3-nopunct": 15.697695926524805,
        "cond_entropy-3-nopunct": 1.209453044531636,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77858,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21475935828877005,
            "2": 0.4309797214756902,
            "3": 0.7674938115075771
        },
        "rouge1": {
            "precision": 0.76783,
            "recall": 0.7278,
            "fmeasure": 0.73655
        },
        "rouge2": {
            "precision": 0.52393,
            "recall": 0.49978,
            "fmeasure": 0.50388
        },
        "rougeL": {
            "precision": 0.64189,
            "recall": 0.61314,
            "fmeasure": 0.61799
        },
        "rougeLsum": {
            "precision": 0.64189,
            "recall": 0.61314,
            "fmeasure": 0.61799
        },
        "nist": 9.722965741723106,
        "bleu": 46.16519,
        "nubia": {
            "semantic_relation": 4.18441,
            "contradiction": 11.699,
            "irrelevancy": 28.03176,
            "logical_agreement": 60.26924,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.49608,
            "nubia_score": 0.7235
        },
        "bertscore": {
            "precision": 0.92943,
            "recall": 0.92274,
            "f1": 0.92452
        },
        "meteor": 0.394211251236528,
        "bleurt": 0.25796
    },
    "totto_test": {
        "predictions_file": "mT5_base/totto_test",
        "N": 7700,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21589849608820788,
            "2": 0.44272055627987833,
            "3": 0.7612212091527892
        },
        "rouge1": {
            "precision": 0.76168,
            "recall": 0.71913,
            "fmeasure": 0.72755
        },
        "rouge2": {
            "precision": 0.52925,
            "recall": 0.50212,
            "fmeasure": 0.50643
        },
        "rougeL": {
            "precision": 0.659,
            "recall": 0.62571,
            "fmeasure": 0.63107
        },
        "rougeLsum": {
            "precision": 0.659,
            "recall": 0.62571,
            "fmeasure": 0.63107
        },
        "nist": 10.58236242920845,
        "bleu": 45.48513,
        "nubia": {
            "semantic_relation": 4.14103,
            "contradiction": 10.43442,
            "irrelevancy": 28.4509,
            "logical_agreement": 61.11468,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.69449,
            "nubia_score": 0.71071
        },
        "bertscore": {
            "precision": 0.92827,
            "recall": 0.92125,
            "f1": 0.9231
        },
        "meteor": 0.38835822466355396,
        "bleurt": 0.26422
    },
    "totto_challenge_test_scramble": {
        "predictions_file": "mT5_base/totto_challenge_test_scramble",
        "N": 378
    },
    "wiki_auto_asset_turk_val": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_val",
        "N": 20000,
        "total_length": 421320,
        "mean_pred_length": 21.066,
        "std_pred_length": 8.771752618490789,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 55,
        "distinct-1": 0.021990411088958512,
        "vocab_size-1": 9265,
        "unique-1": 0,
        "entropy-1": 9.840622993957016,
        "distinct-2": 0.07090850194358617,
        "vocab_size-2": 28457,
        "unique-2": 0,
        "entropy-2": 14.057845270076097,
        "cond_entropy-2": 3.93828591506176,
        "distinct-3": 0.09163170040910522,
        "vocab_size-3": 34941,
        "unique-3": 0,
        "entropy-3": 14.911069395470406,
        "cond_entropy-3": 0.8730918407272433,
        "total_length-nopunct": 369560,
        "mean_pred_length-nopunct": 18.478,
        "std_pred_length-nopunct": 7.65725250987585,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.025018941443879207,
        "vocab_size-1-nopunct": 9246,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 10.295215520442074,
        "distinct-2-nopunct": 0.0746080787275432,
        "vocab_size-2-nopunct": 26080,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 14.077103095555051,
        "cond_entropy-2-nopunct": 3.9508251094873708,
        "distinct-3-nopunct": 0.09399198931909213,
        "vocab_size-3-nopunct": 30976,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 14.844840070783075,
        "cond_entropy-3-nopunct": 0.8081663234197153,
        "msttr-100": 0.26793,
        "msttr-100_nopunct": 0.25094,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_val.json",
        "local_recall": {
            "1": 0.7843069907720892
        },
        "rouge1": {
            "precision": 0.7396,
            "recall": 0.79491,
            "fmeasure": 0.75495
        },
        "rouge2": {
            "precision": 0.56644,
            "recall": 0.60602,
            "fmeasure": 0.5762
        },
        "rougeL": {
            "precision": 0.69785,
            "recall": 0.74912,
            "fmeasure": 0.71204
        },
        "rougeLsum": {
            "precision": 0.69785,
            "recall": 0.74912,
            "fmeasure": 0.71204
        },
        "nist": 9.980813531029078,
        "bleu": 48.31955,
        "sari": 50.58865,
        "nubia": {
            "semantic_relation": 4.51679,
            "contradiction": 2.16205,
            "irrelevancy": 26.64823,
            "logical_agreement": 71.18972,
            "grammar_ref": 4.53224,
            "grammar_hyp": 4.70545,
            "nubia_score": 0.7501
        },
        "bertscore": {
            "precision": 0.92587,
            "recall": 0.94095,
            "f1": 0.93278
        },
        "meteor": 0.43230625878102774,
        "bleurt": 0.38156
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7867,
        "mean_pred_length": 21.91364902506964,
        "std_pred_length": 9.115220843732748,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.3683742214312953,
        "vocab_size-1": 2898,
        "unique-1": 2115,
        "entropy-1": 9.25569495775647,
        "distinct-2": 0.8329781566329248,
        "vocab_size-2": 6254,
        "unique-2": 5782,
        "entropy-2": 12.273958823776688,
        "cond_entropy-2": 2.780509633542581,
        "distinct-3": 0.9630717582878724,
        "vocab_size-3": 6885,
        "unique-3": 6757,
        "entropy-3": 12.675655854825958,
        "cond_entropy-3": 0.41767670933395173,
        "total_length-nopunct": 6935,
        "mean_pred_length-nopunct": 19.317548746518106,
        "std_pred_length-nopunct": 8.003446235936336,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4161499639509733,
        "vocab_size-1-nopunct": 2886,
        "unique-1-nopunct": 2112,
        "entropy-1-nopunct": 9.622147464008012,
        "distinct-2-nopunct": 0.8622262773722628,
        "vocab_size-2-nopunct": 5670,
        "unique-2-nopunct": 5286,
        "entropy-2-nopunct": 12.21947682942681,
        "cond_entropy-2-nopunct": 2.725804687530003,
        "distinct-3-nopunct": 0.982628277304166,
        "vocab_size-3-nopunct": 6109,
        "unique-3-nopunct": 6018,
        "entropy-3-nopunct": 12.564821181777965,
        "cond_entropy-3-nopunct": 0.3653786532626024,
        "msttr-100": 0.72846,
        "msttr-100_nopunct": 0.77101,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03252480705622933,
            "2": 0.18396226415094338,
            "3": 0.42168674698795183,
            "4": 0.6253822629969419,
            "5": 0.7496206373292867,
            "6": 0.8816901408450705,
            "7": 0.9330601092896175,
            "8": 0.9517490952955368,
            "9": 0.9608465608465608,
            "10": 0.9868217054263566
        },
        "rouge1": {
            "precision": 0.90089,
            "recall": 0.92456,
            "fmeasure": 0.90926
        },
        "rouge2": {
            "precision": 0.80979,
            "recall": 0.84003,
            "fmeasure": 0.82018
        },
        "rougeL": {
            "precision": 0.89107,
            "recall": 0.91565,
            "fmeasure": 0.89985
        },
        "rougeLsum": {
            "precision": 0.89107,
            "recall": 0.91565,
            "fmeasure": 0.89985
        },
        "nist": 13.468596381208068,
        "bleu": 87.8592,
        "sari": 49.53198,
        "nubia": {
            "semantic_relation": 4.43317,
            "contradiction": 2.39277,
            "irrelevancy": 33.77215,
            "logical_agreement": 63.83507,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.69498,
            "nubia_score": 0.70724
        },
        "bertscore": {
            "precision": 0.97415,
            "recall": 0.98213,
            "f1": 0.9761
        },
        "meteor": 0.5658096710191454,
        "bleurt": 0.32233
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7492,
        "mean_pred_length": 20.86908077994429,
        "std_pred_length": 9.90411506674438,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 90,
        "distinct-1": 0.35811532301121196,
        "vocab_size-1": 2683,
        "unique-1": 1949,
        "entropy-1": 9.162590524770721,
        "distinct-2": 0.8264404878732651,
        "vocab_size-2": 5895,
        "unique-2": 5446,
        "entropy-2": 12.17190860097906,
        "cond_entropy-2": 2.7610947300767554,
        "distinct-3": 0.9523176852671981,
        "vocab_size-3": 6451,
        "unique-3": 6319,
        "entropy-3": 12.557696604334403,
        "cond_entropy-3": 0.4057635451704732,
        "total_length-nopunct": 6640,
        "mean_pred_length-nopunct": 18.4958217270195,
        "std_pred_length-nopunct": 8.6732296697454,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.4022590361445783,
        "vocab_size-1-nopunct": 2671,
        "unique-1-nopunct": 1948,
        "entropy-1-nopunct": 9.508022386708033,
        "distinct-2-nopunct": 0.853844929151409,
        "vocab_size-2-nopunct": 5363,
        "unique-2-nopunct": 4997,
        "entropy-2-nopunct": 12.115390542732557,
        "cond_entropy-2-nopunct": 2.7412498519307693,
        "distinct-3-nopunct": 0.971968929415738,
        "vocab_size-3-nopunct": 5756,
        "unique-3-nopunct": 5656,
        "entropy-3-nopunct": 12.459634595557144,
        "cond_entropy-3-nopunct": 0.3666512106596183,
        "msttr-100": 0.72824,
        "msttr-100_nopunct": 0.76773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.044142614601018676,
            "2": 0.17752234993614305,
            "3": 0.4201312910284464,
            "4": 0.5673534072900158,
            "5": 0.6895119418483905,
            "6": 0.7916666666666666,
            "7": 0.8896525391370752
        },
        "rouge1": {
            "precision": 0.8481,
            "recall": 0.81238,
            "fmeasure": 0.82056
        },
        "rouge2": {
            "precision": 0.7122,
            "recall": 0.68341,
            "fmeasure": 0.68846
        },
        "rougeL": {
            "precision": 0.82098,
            "recall": 0.78829,
            "fmeasure": 0.79468
        },
        "rougeLsum": {
            "precision": 0.82098,
            "recall": 0.78829,
            "fmeasure": 0.79468
        },
        "nist": 11.210690329278748,
        "bleu": 68.27395,
        "sari": 49.60102,
        "nubia": {
            "semantic_relation": 4.36759,
            "contradiction": 4.15557,
            "irrelevancy": 17.5334,
            "logical_agreement": 78.31103,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.93126,
            "nubia_score": 0.71107
        },
        "bertscore": {
            "precision": 0.95374,
            "recall": 0.94932,
            "f1": 0.94939
        },
        "meteor": 0.47285419726840644,
        "bleurt": 0.23223
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "total_length": 7203,
        "mean_pred_length": 20.064066852367688,
        "std_pred_length": 10.811827638604662,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 69,
        "distinct-1": 0.33791475773983065,
        "vocab_size-1": 2434,
        "unique-1": 1747,
        "entropy-1": 8.975991916727365,
        "distinct-2": 0.7957334891876096,
        "vocab_size-2": 5446,
        "unique-2": 4910,
        "entropy-2": 11.984987972950023,
        "cond_entropy-2": 2.750282497801122,
        "distinct-3": 0.9350809560524287,
        "vocab_size-3": 6064,
        "unique-3": 5871,
        "entropy-3": 12.412364766873495,
        "cond_entropy-3": 0.4501082131182487,
        "total_length-nopunct": 6333,
        "mean_pred_length-nopunct": 17.64066852367688,
        "std_pred_length-nopunct": 9.502769899601656,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 63,
        "distinct-1-nopunct": 0.3824411811147955,
        "vocab_size-1-nopunct": 2422,
        "unique-1-nopunct": 1744,
        "entropy-1-nopunct": 9.327172252421551,
        "distinct-2-nopunct": 0.8322731837964513,
        "vocab_size-2-nopunct": 4972,
        "unique-2-nopunct": 4516,
        "entropy-2-nopunct": 12.011749148003023,
        "cond_entropy-2-nopunct": 2.8199727213207737,
        "distinct-3-nopunct": 0.9654496883348175,
        "vocab_size-3-nopunct": 5421,
        "unique-3-nopunct": 5265,
        "entropy-3-nopunct": 12.378440221627871,
        "cond_entropy-3-nopunct": 0.39225300605408037,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.74794,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "local_recall": {
            "1": 0.057391304347826085,
            "2": 0.11813186813186813,
            "3": 0.1910902696365768,
            "4": 0.24220963172804533,
            "5": 0.3187250996015936,
            "6": 0.3805418719211823,
            "7": 0.4691780821917808,
            "8": 0.5426587301587301,
            "9": 0.6705035971223021
        },
        "rouge1": {
            "precision": 0.55322,
            "recall": 0.56338,
            "fmeasure": 0.53669
        },
        "rouge2": {
            "precision": 0.32104,
            "recall": 0.33565,
            "fmeasure": 0.31229
        },
        "rougeL": {
            "precision": 0.49247,
            "recall": 0.51284,
            "fmeasure": 0.48195
        },
        "rougeLsum": {
            "precision": 0.49247,
            "recall": 0.51284,
            "fmeasure": 0.48195
        },
        "nist": 6.462397194009332,
        "bleu": 26.14593,
        "sari": 40.82668,
        "nubia": {
            "semantic_relation": 2.95599,
            "contradiction": 18.59001,
            "irrelevancy": 47.57769,
            "logical_agreement": 33.8323,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.36774,
            "nubia_score": 0.32033
        },
        "bertscore": {
            "precision": 0.86546,
            "recall": 0.87556,
            "f1": 0.8658
        },
        "meteor": 0.27687989778351985,
        "bleurt": -0.44966
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "total_length": 7300,
        "mean_pred_length": 20.33426183844011,
        "std_pred_length": 10.026967617795565,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 64,
        "distinct-1": 0.3552054794520548,
        "vocab_size-1": 2593,
        "unique-1": 1909,
        "entropy-1": 9.081807044058039,
        "distinct-2": 0.802189886183547,
        "vocab_size-2": 5568,
        "unique-2": 5050,
        "entropy-2": 12.038274026808386,
        "cond_entropy-2": 2.702120850164152,
        "distinct-3": 0.9384685505925251,
        "vocab_size-3": 6177,
        "unique-3": 5985,
        "entropy-3": 12.453910712668108,
        "cond_entropy-3": 0.4350073763336341,
        "total_length-nopunct": 6385,
        "mean_pred_length-nopunct": 17.785515320334262,
        "std_pred_length-nopunct": 8.587495716049215,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.4042286609240407,
        "vocab_size-1-nopunct": 2581,
        "unique-1-nopunct": 1906,
        "entropy-1-nopunct": 9.449702985844858,
        "distinct-2-nopunct": 0.8375373382011284,
        "vocab_size-2-nopunct": 5047,
        "unique-2-nopunct": 4605,
        "entropy-2-nopunct": 12.04339898340987,
        "cond_entropy-2-nopunct": 2.7302520016534406,
        "distinct-3-nopunct": 0.9659431798129522,
        "vocab_size-3-nopunct": 5474,
        "unique-3-nopunct": 5320,
        "entropy-3-nopunct": 12.393706744481179,
        "cond_entropy-3-nopunct": 0.37344315128213973,
        "msttr-100": 0.7074,
        "msttr-100_nopunct": 0.74698,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "local_recall": {
            "1": 0.04927536231884058,
            "2": 0.14285714285714285,
            "3": 0.20046893317702227,
            "4": 0.2847025495750708,
            "5": 0.3665338645418327,
            "6": 0.4064039408866995,
            "7": 0.5068493150684932,
            "8": 0.5902777777777778,
            "9": 0.697841726618705
        },
        "rouge1": {
            "precision": 0.5696,
            "recall": 0.58698,
            "fmeasure": 0.55643
        },
        "rouge2": {
            "precision": 0.35628,
            "recall": 0.37889,
            "fmeasure": 0.34894
        },
        "rougeL": {
            "precision": 0.52743,
            "recall": 0.55,
            "fmeasure": 0.51692
        },
        "rougeLsum": {
            "precision": 0.52743,
            "recall": 0.55,
            "fmeasure": 0.51692
        },
        "nist": 6.972443681185443,
        "bleu": 30.85235,
        "sari": 40.80157,
        "nubia": {
            "semantic_relation": 3.12016,
            "contradiction": 14.99204,
            "irrelevancy": 48.67396,
            "logical_agreement": 36.334,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.81382,
            "nubia_score": 0.31558
        },
        "bertscore": {
            "precision": 0.85498,
            "recall": 0.88327,
            "f1": 0.8638
        },
        "meteor": 0.28668756979940563,
        "bleurt": -0.66783
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "total_length": 7211,
        "mean_pred_length": 20.08635097493036,
        "std_pred_length": 10.067781857559922,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 72,
        "distinct-1": 0.4029954236582998,
        "vocab_size-1": 2906,
        "unique-1": 2285,
        "entropy-1": 9.358698832499243,
        "distinct-2": 0.8480735551663747,
        "vocab_size-2": 5811,
        "unique-2": 5423,
        "entropy-2": 12.176116243852803,
        "cond_entropy-2": 2.5441686474505074,
        "distinct-3": 0.9614969967657477,
        "vocab_size-3": 6243,
        "unique-3": 6165,
        "entropy-3": 12.494135641032111,
        "cond_entropy-3": 0.3351462577971298,
        "total_length-nopunct": 6307,
        "mean_pred_length-nopunct": 17.568245125348188,
        "std_pred_length-nopunct": 8.278252542991202,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.45885524020929125,
        "vocab_size-1-nopunct": 2894,
        "unique-1-nopunct": 2283,
        "entropy-1-nopunct": 9.762045201408167,
        "distinct-2-nopunct": 0.886852723604573,
        "vocab_size-2-nopunct": 5275,
        "unique-2-nopunct": 4962,
        "entropy-2-nopunct": 12.179764380842544,
        "cond_entropy-2-nopunct": 2.5424302951416475,
        "distinct-3-nopunct": 0.9883700125246019,
        "vocab_size-3-nopunct": 5524,
        "unique-3-nopunct": 5472,
        "entropy-3-nopunct": 12.422489500910881,
        "cond_entropy-3-nopunct": 0.2613187014557283,
        "msttr-100": 0.73694,
        "msttr-100_nopunct": 0.78238,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "local_recall": {
            "1": 0.05236714975845411,
            "2": 0.10989010989010989,
            "3": 0.20750293083235638,
            "4": 0.2747875354107649,
            "5": 0.3253652058432935,
            "6": 0.3460591133004926,
            "7": 0.4429223744292237,
            "8": 0.5456349206349206,
            "9": 0.6525179856115108
        },
        "rouge1": {
            "precision": 0.52345,
            "recall": 0.54452,
            "fmeasure": 0.51614
        },
        "rouge2": {
            "precision": 0.30829,
            "recall": 0.32366,
            "fmeasure": 0.30093
        },
        "rougeL": {
            "precision": 0.48591,
            "recall": 0.50959,
            "fmeasure": 0.478
        },
        "rougeLsum": {
            "precision": 0.48591,
            "recall": 0.50959,
            "fmeasure": 0.478
        },
        "nist": 6.290611460361318,
        "bleu": 24.96518,
        "sari": 41.29699,
        "nubia": {
            "semantic_relation": 2.90737,
            "contradiction": 17.49414,
            "irrelevancy": 47.12039,
            "logical_agreement": 35.38547,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.38721,
            "nubia_score": 0.24939
        },
        "bertscore": {
            "precision": 0.83004,
            "recall": 0.86734,
            "f1": 0.84369
        },
        "meteor": 0.2566462480577804,
        "bleurt": -0.91201
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "total_length": 7224,
        "mean_pred_length": 20.12256267409471,
        "std_pred_length": 10.754879341229293,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 96,
        "distinct-1": 0.3338870431893688,
        "vocab_size-1": 2412,
        "unique-1": 1665,
        "entropy-1": 8.98705226077168,
        "distinct-2": 0.7877640203932993,
        "vocab_size-2": 5408,
        "unique-2": 4828,
        "entropy-2": 11.978090229857314,
        "cond_entropy-2": 2.741329731707588,
        "distinct-3": 0.9283738087918845,
        "vocab_size-3": 6040,
        "unique-3": 5799,
        "entropy-3": 12.408602253936431,
        "cond_entropy-3": 0.45542098323164676,
        "total_length-nopunct": 6337,
        "mean_pred_length-nopunct": 17.651810584958216,
        "std_pred_length-nopunct": 9.202984305110533,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.3788859081584346,
        "vocab_size-1-nopunct": 2401,
        "unique-1-nopunct": 1663,
        "entropy-1-nopunct": 9.33884801354058,
        "distinct-2-nopunct": 0.8250250920040147,
        "vocab_size-2-nopunct": 4932,
        "unique-2-nopunct": 4434,
        "entropy-2-nopunct": 12.001593546809259,
        "cond_entropy-2-nopunct": 2.8078515622683935,
        "distinct-3-nopunct": 0.9592454173340452,
        "vocab_size-3-nopunct": 5390,
        "unique-3-nopunct": 5198,
        "entropy-3-nopunct": 12.36825960995323,
        "cond_entropy-3-nopunct": 0.39077334558947363,
        "msttr-100": 0.69764,
        "msttr-100_nopunct": 0.73317,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "local_recall": {
            "1": 0.0548792270531401,
            "2": 0.1401098901098901,
            "3": 0.2321219226260258,
            "4": 0.3130311614730878,
            "5": 0.399734395750332,
            "6": 0.46551724137931033,
            "7": 0.5764840182648402,
            "8": 0.6686507936507936,
            "9": 0.8007194244604317
        },
        "rouge1": {
            "precision": 0.64717,
            "recall": 0.65642,
            "fmeasure": 0.62696
        },
        "rouge2": {
            "precision": 0.44373,
            "recall": 0.4635,
            "fmeasure": 0.42977
        },
        "rougeL": {
            "precision": 0.59041,
            "recall": 0.61305,
            "fmeasure": 0.57676
        },
        "rougeLsum": {
            "precision": 0.59041,
            "recall": 0.61305,
            "fmeasure": 0.57676
        },
        "nist": 8.197341104508459,
        "bleu": 40.51879,
        "sari": 41.70742,
        "nubia": {
            "semantic_relation": 3.38854,
            "contradiction": 12.85237,
            "irrelevancy": 44.94573,
            "logical_agreement": 42.20189,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.17434,
            "nubia_score": 0.40559
        },
        "bertscore": {
            "precision": 0.89601,
            "recall": 0.90571,
            "f1": 0.89559
        },
        "meteor": 0.33674663501465335,
        "bleurt": -0.25939
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "total_length": 7719,
        "mean_pred_length": 21.501392757660167,
        "std_pred_length": 10.217924785305714,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 57,
        "distinct-1": 0.3350174893120871,
        "vocab_size-1": 2586,
        "unique-1": 1822,
        "entropy-1": 9.028306672002198,
        "distinct-2": 0.8023097826086957,
        "vocab_size-2": 5905,
        "unique-2": 5353,
        "entropy-2": 12.123096479347774,
        "cond_entropy-2": 2.863881217081821,
        "distinct-3": 0.9411512641051278,
        "vocab_size-3": 6589,
        "unique-3": 6383,
        "entropy-3": 12.562104002836708,
        "cond_entropy-3": 0.454297665657473,
        "total_length-nopunct": 6824,
        "mean_pred_length-nopunct": 19.008356545961004,
        "std_pred_length-nopunct": 9.057072972912566,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.37705158264947247,
        "vocab_size-1-nopunct": 2573,
        "unique-1-nopunct": 1818,
        "entropy-1-nopunct": 9.357205745492136,
        "distinct-2-nopunct": 0.8352668213457076,
        "vocab_size-2-nopunct": 5400,
        "unique-2-nopunct": 4921,
        "entropy-2-nopunct": 12.122903379203047,
        "cond_entropy-2-nopunct": 2.8921262374518864,
        "distinct-3-nopunct": 0.9659351457582706,
        "vocab_size-3-nopunct": 5898,
        "unique-3-nopunct": 5734,
        "entropy-3-nopunct": 12.500190554541012,
        "cond_entropy-3-nopunct": 0.3999822339542938,
        "msttr-100": 0.70701,
        "msttr-100_nopunct": 0.74382,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "local_recall": {
            "1": 0.06960950764006792,
            "2": 0.1698595146871009,
            "3": 0.2844638949671772,
            "4": 0.25673534072900156,
            "5": 0.36656282450674976,
            "6": 0.4577294685990338,
            "7": 0.6300114547537228
        },
        "rouge1": {
            "precision": 0.56598,
            "recall": 0.55538,
            "fmeasure": 0.54122
        },
        "rouge2": {
            "precision": 0.33108,
            "recall": 0.33438,
            "fmeasure": 0.31687
        },
        "rougeL": {
            "precision": 0.50205,
            "recall": 0.5026,
            "fmeasure": 0.48315
        },
        "rougeLsum": {
            "precision": 0.50205,
            "recall": 0.5026,
            "fmeasure": 0.48315
        },
        "nist": 6.557485103877994,
        "bleu": 28.61631,
        "sari": 40.33756,
        "nubia": {
            "semantic_relation": 3.12968,
            "contradiction": 19.55562,
            "irrelevancy": 39.93223,
            "logical_agreement": 40.51215,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.22444,
            "nubia_score": 0.38432
        },
        "bertscore": {
            "precision": 0.86733,
            "recall": 0.87106,
            "f1": 0.86585
        },
        "meteor": 0.27704492555239435,
        "bleurt": -0.37081
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "total_length": 8046,
        "mean_pred_length": 22.41225626740947,
        "std_pred_length": 10.805830737042568,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 59,
        "distinct-1": 0.3642803877703207,
        "vocab_size-1": 2931,
        "unique-1": 2192,
        "entropy-1": 9.262044899585886,
        "distinct-2": 0.8143619097177052,
        "vocab_size-2": 6260,
        "unique-2": 5703,
        "entropy-2": 12.227036581839464,
        "cond_entropy-2": 2.7329886126984935,
        "distinct-3": 0.9428220524017468,
        "vocab_size-3": 6909,
        "unique-3": 6707,
        "entropy-3": 12.620295193682782,
        "cond_entropy-3": 0.4131753146956484,
        "total_length-nopunct": 7061,
        "mean_pred_length-nopunct": 19.668523676880223,
        "std_pred_length-nopunct": 9.37393326410897,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.41339753575980737,
        "vocab_size-1-nopunct": 2919,
        "unique-1-nopunct": 2190,
        "entropy-1-nopunct": 9.639736850433488,
        "distinct-2-nopunct": 0.8506415995225306,
        "vocab_size-2-nopunct": 5701,
        "unique-2-nopunct": 5225,
        "entropy-2-nopunct": 12.235847158328806,
        "cond_entropy-2-nopunct": 2.720541619628699,
        "distinct-3-nopunct": 0.9714646066530033,
        "vocab_size-3-nopunct": 6162,
        "unique-3-nopunct": 6010,
        "entropy-3-nopunct": 12.56845244246989,
        "cond_entropy-3-nopunct": 0.3514072873433242,
        "msttr-100": 0.72025,
        "msttr-100_nopunct": 0.75743,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "local_recall": {
            "1": 0.05560271646859083,
            "2": 0.13665389527458494,
            "3": 0.2735229759299781,
            "4": 0.3977812995245642,
            "5": 0.48494288681204567,
            "6": 0.5591787439613527,
            "7": 0.6746849942726232
        },
        "rouge1": {
            "precision": 0.60889,
            "recall": 0.61067,
            "fmeasure": 0.59108
        },
        "rouge2": {
            "precision": 0.40328,
            "recall": 0.41024,
            "fmeasure": 0.39262
        },
        "rougeL": {
            "precision": 0.56558,
            "recall": 0.57446,
            "fmeasure": 0.55119
        },
        "rougeLsum": {
            "precision": 0.56558,
            "recall": 0.57446,
            "fmeasure": 0.55119
        },
        "nist": 7.2404200588469925,
        "bleu": 34.96054,
        "sari": 40.95991,
        "nubia": {
            "semantic_relation": 3.35613,
            "contradiction": 15.17492,
            "irrelevancy": 38.77856,
            "logical_agreement": 46.04652,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.8869,
            "nubia_score": 0.37525
        },
        "bertscore": {
            "precision": 0.86204,
            "recall": 0.88245,
            "f1": 0.86921
        },
        "meteor": 0.3039591505462107,
        "bleurt": -0.62566
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "total_length": 8056,
        "mean_pred_length": 22.440111420612812,
        "std_pred_length": 12.470629829488622,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 84,
        "distinct-1": 0.39473684210526316,
        "vocab_size-1": 3180,
        "unique-1": 2502,
        "entropy-1": 9.419620149028628,
        "distinct-2": 0.8377289853189555,
        "vocab_size-2": 6448,
        "unique-2": 5989,
        "entropy-2": 12.307681082878524,
        "cond_entropy-2": 2.6521561896246073,
        "distinct-3": 0.9584355410193514,
        "vocab_size-3": 7033,
        "unique-3": 6914,
        "entropy-3": 12.665822985090022,
        "cond_entropy-3": 0.3740671410129733,
        "total_length-nopunct": 7061,
        "mean_pred_length-nopunct": 19.668523676880223,
        "std_pred_length-nopunct": 10.465163635108938,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.4483784166548648,
        "vocab_size-1-nopunct": 3166,
        "unique-1-nopunct": 2499,
        "entropy-1-nopunct": 9.80424417951298,
        "distinct-2-nopunct": 0.8743658609370337,
        "vocab_size-2-nopunct": 5860,
        "unique-2-nopunct": 5482,
        "entropy-2-nopunct": 12.309902768916329,
        "cond_entropy-2-nopunct": 2.6189925658522744,
        "distinct-3-nopunct": 0.983761626990383,
        "vocab_size-3-nopunct": 6240,
        "unique-3-nopunct": 6154,
        "entropy-3-nopunct": 12.595549132203637,
        "cond_entropy-3-nopunct": 0.3034636409340853,
        "msttr-100": 0.73612,
        "msttr-100_nopunct": 0.777,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "local_recall": {
            "1": 0.05114601018675721,
            "2": 0.12260536398467432,
            "3": 0.22975929978118162,
            "4": 0.3074484944532488,
            "5": 0.3811007268951194,
            "6": 0.48007246376811596,
            "7": 0.6040473463153876
        },
        "rouge1": {
            "precision": 0.54,
            "recall": 0.53967,
            "fmeasure": 0.52249
        },
        "rouge2": {
            "precision": 0.31245,
            "recall": 0.32053,
            "fmeasure": 0.30379
        },
        "rougeL": {
            "precision": 0.49565,
            "recall": 0.5007,
            "fmeasure": 0.48084
        },
        "rougeLsum": {
            "precision": 0.49565,
            "recall": 0.5007,
            "fmeasure": 0.48084
        },
        "nist": 5.999994739345563,
        "bleu": 24.18293,
        "sari": 40.28553,
        "nubia": {
            "semantic_relation": 3.05342,
            "contradiction": 20.77564,
            "irrelevancy": 41.06008,
            "logical_agreement": 38.16429,
            "grammar_ref": 4.55265,
            "grammar_hyp": 6.37597,
            "nubia_score": 0.29282
        },
        "bertscore": {
            "precision": 0.8301,
            "recall": 0.85811,
            "f1": 0.84068
        },
        "meteor": 0.2530161118094154,
        "bleurt": -0.91677
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "mT5_base/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "total_length": 7839,
        "mean_pred_length": 21.83565459610028,
        "std_pred_length": 11.775441090351546,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 87,
        "distinct-1": 0.3333333333333333,
        "vocab_size-1": 2613,
        "unique-1": 1820,
        "entropy-1": 9.113867316125736,
        "distinct-2": 0.8049465240641711,
        "vocab_size-2": 6021,
        "unique-2": 5451,
        "entropy-2": 12.147417324925712,
        "cond_entropy-2": 2.811265818963784,
        "distinct-3": 0.9425642465945794,
        "vocab_size-3": 6712,
        "unique-3": 6517,
        "entropy-3": 12.573182764696535,
        "cond_entropy-3": 0.4444966961988888,
        "total_length-nopunct": 6888,
        "mean_pred_length-nopunct": 19.186629526462397,
        "std_pred_length-nopunct": 10.274843636751134,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.37761324041811845,
        "vocab_size-1-nopunct": 2601,
        "unique-1-nopunct": 1819,
        "entropy-1-nopunct": 9.456424010064095,
        "distinct-2-nopunct": 0.842548629192832,
        "vocab_size-2-nopunct": 5501,
        "unique-2-nopunct": 5010,
        "entropy-2-nopunct": 12.171750586984853,
        "cond_entropy-2-nopunct": 2.8363702292513184,
        "distinct-3-nopunct": 0.9709886547811993,
        "vocab_size-3-nopunct": 5991,
        "unique-3-nopunct": 5835,
        "entropy-3-nopunct": 12.52844476390455,
        "cond_entropy-3-nopunct": 0.3791109995048342,
        "msttr-100": 0.72064,
        "msttr-100_nopunct": 0.75132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "local_recall": {
            "1": 0.05730050933786078,
            "2": 0.17624521072796934,
            "3": 0.3150984682713348,
            "4": 0.38510301109350237,
            "5": 0.5088265835929388,
            "6": 0.6141304347826086,
            "7": 0.7426498663612066
        },
        "rouge1": {
            "precision": 0.68307,
            "recall": 0.66471,
            "fmeasure": 0.65346
        },
        "rouge2": {
            "precision": 0.49889,
            "recall": 0.49093,
            "fmeasure": 0.47752
        },
        "rougeL": {
            "precision": 0.63898,
            "recall": 0.62731,
            "fmeasure": 0.61334
        },
        "rougeLsum": {
            "precision": 0.63898,
            "recall": 0.62731,
            "fmeasure": 0.61334
        },
        "nist": 8.385268146331418,
        "bleu": 44.5467,
        "sari": 40.20438,
        "nubia": {
            "semantic_relation": 3.65807,
            "contradiction": 11.45516,
            "irrelevancy": 37.4193,
            "logical_agreement": 51.12554,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.18727,
            "nubia_score": 0.49398
        },
        "bertscore": {
            "precision": 0.90351,
            "recall": 0.90561,
            "f1": 0.90165
        },
        "meteor": 0.35623068142113323,
        "bleurt": -0.15641
    }
}
